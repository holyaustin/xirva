[{"id": "2102.00127", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Liam Li, Eric Xing, Ameet Talwalkar", "title": "On Data Efficiency of Meta-learning", "comments": "Preliminary version. An updated version is to appear in AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning has enabled learning statistical models that can be quickly\nadapted to new prediction tasks. Motivated by use-cases in personalized\nfederated learning, we study the often overlooked aspect of the modern\nmeta-learning algorithms -- their data efficiency. To shed more light on which\nmethods are more efficient, we use techniques from algorithmic stability to\nderive bounds on the transfer risk that have important practical implications,\nindicating how much supervision is needed and how it must be allocated for each\nmethod to attain the desired level of generalization. Further, we introduce a\nnew simple framework for evaluating meta-learning methods under a limit on the\navailable supervision, conduct an empirical study of MAML, Reptile, and\nProtonets, and demonstrate the differences in the behavior of these methods on\nfew-shot and federated learning benchmarks. Finally, we propose active\nmeta-learning, which incorporates active data selection into learning-to-learn,\nleading to better performance of all methods in the limited supervision regime.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 01:44:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Li", "Liam", ""], ["Xing", "Eric", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2102.00135", "submitter": "Guanghui Lan", "authors": "Guanghui Lan", "title": "Policy Mirror Descent for Reinforcement Learning: Linear Convergence,\n  New Sampling Complexity, and Generalized Problem Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new policy mirror descent (PMD) methods for solving reinforcement\nlearning (RL) problems with either strongly convex or general convex\nregularizers. By exploring the structural properties of these overall highly\nnonconvex problems we show that the PMD methods exhibit fast linear rate of\nconvergence to the global optimality. We develop stochastic counterparts of\nthese methods, and establish an ${\\cal O}(1/\\epsilon)$ (resp., ${\\cal\nO}(1/\\epsilon^2)$) sampling complexity for solving these RL problems with\nstrongly (resp., general) convex regularizers using different sampling schemes,\nwhere $\\epsilon$ denote the target accuracy. We further show that the\ncomplexity for computing the gradients of these regularizers, if necessary, can\nbe bounded by ${\\cal O}\\{(\\log_\\gamma \\epsilon) [(1-\\gamma)L/\\mu]^{1/2}\\log\n(1/\\epsilon)\\}$ (resp., ${\\cal O} \\{(\\log_\\gamma \\epsilon )\n(L/\\epsilon)^{1/2}\\}$)for problems with strongly (resp., general) convex\nregularizers. Here $\\gamma$ denotes the discounting factor. To the best of our\nknowledge, these complexity bounds, along with our algorithmic developments,\nappear to be new in both optimization and RL literature. The introduction of\nthese convex regularizers also greatly expands the flexibility and\napplicability of RL models.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 02:30:45 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 01:59:41 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 18:03:56 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 14:11:23 GMT"}, {"version": "v5", "created": "Thu, 6 May 2021 20:11:08 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Lan", "Guanghui", ""]]}, {"id": "2102.00168", "submitter": "Ambedkar Dukkipati", "authors": "Ambedkar Dukkipati, Rajarshi Banerjee, Ranga Shaarad Ayyagari, Dhaval\n  Parmar Udaybhai", "title": "Stay Alive with Many Options: A Reinforcement Learning Approach for\n  Autonomous Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning approaches learn policies based on\nhierarchical decision structures. However, training such methods in practice\nmay lead to poor generalization, with either sub-policies executing actions for\ntoo few time steps or devolving into a single policy altogether. In our work,\nwe introduce an alternative approach to sequentially learn such skills without\nusing an overarching hierarchical policy, in the context of environments in\nwhich an objective of the agent is to prolong the episode for as long as\npossible, or in other words `stay alive'. We demonstrate the utility of our\napproach in a simulated 3D navigation environment which we have built. We show\nthat our method outperforms prior methods such as Soft Actor Critic and Soft\nOption Critic on our environment, as well as the Atari River Raid environment.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 06:55:35 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dukkipati", "Ambedkar", ""], ["Banerjee", "Rajarshi", ""], ["Ayyagari", "Ranga Shaarad", ""], ["Udaybhai", "Dhaval Parmar", ""]]}, {"id": "2102.00179", "submitter": "Tiffany Hwu", "authors": "Tiffany Hwu, Mia Levy, Steven Skorheim, David Huber", "title": "Matching Representations of Explainable Artificial Intelligence and Eye\n  Gaze for Human-Machine Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid non-verbal communication of task-based stimuli is a challenge in\nhuman-machine teaming, particularly in closed-loop interactions such as\ndriving. To achieve this, we must understand the representations of information\nfor both the human and machine, and determine a basis for bridging these\nrepresentations. Techniques of explainable artificial intelligence (XAI) such\nas layer-wise relevance propagation (LRP) provide visual heatmap explanations\nfor high-dimensional machine learning techniques such as deep neural networks.\nOn the side of human cognition, visual attention is driven by the bottom-up and\ntop-down processing of sensory input related to the current task. Since both\nXAI and human cognition should focus on task-related stimuli, there may be\noverlaps between their representations of visual attention, potentially\nproviding a means of nonverbal communication between the human and machine. In\nthis work, we examine the correlations between LRP heatmap explanations of a\nneural network trained to predict driving behavior and eye gaze heatmaps of\nhuman drivers. The analysis is used to determine the feasibility of using such\na technique for enhancing driving performance. We find that LRP heatmaps show\nincreasing levels of similarity with eye gaze according to the task specificity\nof the neural network. We then propose how these findings may assist humans by\nvisually directing attention towards relevant areas. To our knowledge, our work\nprovides the first known analysis of LRP and eye gaze for driving tasks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 07:42:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hwu", "Tiffany", ""], ["Levy", "Mia", ""], ["Skorheim", "Steven", ""], ["Huber", "David", ""]]}, {"id": "2102.00214", "submitter": "Nikita Desai Prof", "authors": "Nikita P. Desai, Prof.(Dr.) Vipul K. Dabhi", "title": "Taxonomic survey of Hindi Language NLP systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural Language processing (NLP) represents the task of automatic handling\nof natural human language by machines.There is large spectrum of possible\napplications of NLP which help in automating tasks like translating text from\none language to other, retrieving and summarizing data from very huge\nrepositories, spam email filtering, identifying fake news in digital media,\nfind sentiment and feedback of people, find political opinions and views of\npeople on various government policies, provide effective medical assistance\nbased on past history records of patient etc. Hindi is the official language of\nIndia with nearly 691 million users in India and 366 million in rest of world.\nAt present, a number of government and private sector projects and researchers\nin India and abroad, are working towards developing NLP applications and\nresources for Indian languages. This survey gives a report of the resources and\napplications available for Hindi language NLP.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 11:53:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Desai", "Nikita P.", "", "Dr."], ["Prof.", "", "", "Dr."], ["Dabhi", "Vipul K.", ""]]}, {"id": "2102.00228", "submitter": "Chengwei Zhang", "authors": "Chengwei Zhang, Yangzhou Jiang, Wei Zhang, Chengyu Gu", "title": "MUSE: Multi-Scale Temporal Features Evolution for Knowledge Tracing", "comments": "the AAAI-2021 workshop on Imagining Post-COVID Education with AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformer based knowledge tracing model is an extensively studied problem\nin the field of computer-aided education. By integrating temporal features into\nthe encoder-decoder structure, transformers can processes the exercise\ninformation and student response information in a natural way. However, current\nstate-of-the-art transformer-based variants still share two limitations. First,\nextremely long temporal features cannot well handled as the complexity of\nself-attention mechanism is O(n2). Second, existing approaches track the\nknowledge drifts under fixed a window size, without considering different\ntemporal-ranges. To conquer these problems, we propose MUSE, which is equipped\nwith multi-scale temporal sensor unit, that takes either local or global\ntemporal features into consideration. The proposed model is capable to capture\nthe dynamic changes in users knowledge states at different temporal-ranges, and\nprovides an efficient and powerful way to combine local and global features to\nmake predictions. Our method won the 5-th place over 3,395 teams in the Riiid\nAIEd Challenge 2020.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 13:52:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhang", "Chengwei", ""], ["Jiang", "Yangzhou", ""], ["Zhang", "Wei", ""], ["Gu", "Chengyu", ""]]}, {"id": "2102.00233", "submitter": "Matheus E. Leusin", "authors": "Matheus E. Leusin, Bjoern Jindra, Daniel S. Hain", "title": "An evolutionary view on the emergence of Artificial Intelligence", "comments": "Keywords: Artificial Intelligence; technological space; evolutionary\n  economic geography; technological relatedness; knowledge complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper draws upon the evolutionary concepts of technological relatedness\nand knowledge complexity to enhance our understanding of the long-term\nevolution of Artificial Intelligence (AI). We reveal corresponding patterns in\nthe emergence of AI - globally and in the context of specific geographies of\nthe US, Japan, South Korea, and China. We argue that AI emergence is associated\nwith increasing related variety due to knowledge commonalities as well as\nincreasing complexity. We use patent-based indicators for the period between\n1974-2018 to analyse the evolution of AI's global technological space, to\nidentify its technological core as well as changes to its overall relatedness\nand knowledge complexity. At the national level, we also measure countries'\noverall specialisations against AI-specific ones. At the global level, we find\nincreasing overall relatedness and complexity of AI. However, for the\ntechnological core of AI, which has been stable over time, we find decreasing\nrelated variety and increasing complexity. This evidence points out that AI\ninnovations related to core technologies are becoming increasingly distinct\nfrom each other. At the country level, we find that the US and Japan have been\nincreasing the overall relatedness of their innovations. The opposite is the\ncase for China and South Korea, which we associate with the fact that these\ncountries are overall less technologically developed than the US and Japan.\nFinally, we observe a stable increasing overall complexity for all countries\napart from China, which we explain by the focus of this country in technologies\nnot strongly linked to AI.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 14:46:23 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Leusin", "Matheus E.", ""], ["Jindra", "Bjoern", ""], ["Hain", "Daniel S.", ""]]}, {"id": "2102.00240", "submitter": "Qing-Long Zhang", "authors": "Qing-Long Zhang Yu-Bin Yang", "title": "SA-Net: Shuffle Attention for Deep Convolutional Neural Networks", "comments": "ICASSP 2021 paper: SA-Net: Shuffle Attention for Deep Convolutional\n  Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention mechanisms, which enable a neural network to accurately focus on\nall the relevant elements of the input, have become an essential component to\nimprove the performance of deep neural networks. There are mainly two attention\nmechanisms widely used in computer vision studies, \\textit{spatial attention}\nand \\textit{channel attention}, which aim to capture the pixel-level pairwise\nrelationship and channel dependency, respectively. Although fusing them\ntogether may achieve better performance than their individual implementations,\nit will inevitably increase the computational overhead. In this paper, we\npropose an efficient Shuffle Attention (SA) module to address this issue, which\nadopts Shuffle Units to combine two types of attention mechanisms effectively.\nSpecifically, SA first groups channel dimensions into multiple sub-features\nbefore processing them in parallel. Then, for each sub-feature, SA utilizes a\nShuffle Unit to depict feature dependencies in both spatial and channel\ndimensions. After that, all sub-features are aggregated and a \"channel shuffle\"\noperator is adopted to enable information communication between different\nsub-features. The proposed SA module is efficient yet effective, e.g., the\nparameters and computations of SA against the backbone ResNet50 are 300 vs.\n25.56M and 2.76e-3 GFLOPs vs. 4.12 GFLOPs, respectively, and the performance\nboost is more than 1.34% in terms of Top-1 accuracy. Extensive experimental\nresults on common-used benchmarks, including ImageNet-1k for classification, MS\nCOCO for object detection, and instance segmentation, demonstrate that the\nproposed SA outperforms the current SOTA methods significantly by achieving\nhigher accuracy while having lower model complexity. The code and models are\navailable at https://github.com/wofmanaf/SA-Net.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 15:23:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yang", "Qing-Long Zhang Yu-Bin", ""]]}, {"id": "2102.00287", "submitter": "Eva Vanmassenhove", "authors": "Eva Vanmassenhove, Dimitar Shterionov, Matthew Gwilliam", "title": "Machine Translationese: Effects of Algorithmic Bias on Linguistic\n  Complexity in Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies in the field of Machine Translation (MT) and Natural Language\nProcessing (NLP) have shown that existing models amplify biases observed in the\ntraining data. The amplification of biases in language technology has mainly\nbeen examined with respect to specific phenomena, such as gender bias. In this\nwork, we go beyond the study of gender in MT and investigate how bias\namplification might affect language in a broader sense. We hypothesize that the\n'algorithmic bias', i.e. an exacerbation of frequently observed patterns in\ncombination with a loss of less frequent ones, not only exacerbates societal\nbiases present in current datasets but could also lead to an artificially\nimpoverished language: 'machine translationese'. We assess the linguistic\nrichness (on a lexical and morphological level) of translations created by\ndifferent data-driven MT paradigms - phrase-based statistical (PB-SMT) and\nneural MT (NMT). Our experiments show that there is a loss of lexical and\nmorphological richness in the translations produced by all investigated MT\nparadigms for two language pairs (EN<=>FR and EN<=>ES).\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 18:49:11 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Vanmassenhove", "Eva", ""], ["Shterionov", "Dimitar", ""], ["Gwilliam", "Matthew", ""]]}, {"id": "2102.00292", "submitter": "Seyed Ziae Mousavi Mojab", "authors": "Seyed Ziae Mousavi Mojab, Seyedmohammad Shams, Hamid Soltanian-Zadeh,\n  Farshad Fotouhi", "title": "Epistocracy Algorithm: A Novel Hyper-heuristic Optimization Strategy for\n  Solving Complex Optimization Problems", "comments": "Computing Conference 2021 proceedings will be published in the\n  Springer series \"Advances in Intelligent Systems and Computing\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes a novel evolutionary algorithm called Epistocracy which\nincorporates human socio-political behavior and intelligence to solve complex\noptimization problems. The inspiration of the Epistocracy algorithm originates\nfrom a political regime where educated people have more voting power than the\nuneducated or less educated. The algorithm is a self-adaptive, and\nmulti-population optimizer in which the evolution process takes place in\nparallel for many populations led by a council of leaders. To avoid stagnation\nin poor local optima and to prevent a premature convergence, the algorithm\nemploys multiple mechanisms such as dynamic and adaptive leadership based on\ngravitational force, dynamic population allocation and diversification,\nvariance-based step-size determination, and regression-based leadership\nadjustment. The algorithm uses a stratified sampling method called Latin\nHypercube Sampling (LHS) to distribute the initial population more evenly for\nexploration of the search space and exploitation of the accumulated knowledge.\nTo investigate the performance and evaluate the reliability of the algorithm,\nwe have used a set of multimodal benchmark functions, and then applied the\nalgorithm to the MNIST dataset to further verify the accuracy, scalability, and\nrobustness of the algorithm. Experimental results show that the Epistocracy\nalgorithm outperforms the tested state-of-the-art evolutionary and swarm\nintelligence algorithms in terms of performance, precision, and convergence.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 19:07:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mojab", "Seyed Ziae Mousavi", ""], ["Shams", "Seyedmohammad", ""], ["Soltanian-Zadeh", "Hamid", ""], ["Fotouhi", "Farshad", ""]]}, {"id": "2102.00311", "submitter": "Violet (Xinying) Chen", "authors": "Violet Xinying Chen, J.N. Hooker", "title": "Fairness through Optimization", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose optimization as a general paradigm for formalizing fairness in\nAI-based decision models. We argue that optimization models allow formulation\nof a wide range of fairness criteria as social welfare functions, while\nenabling AI to take advantage of highly advanced solution technology. We show\nhow optimization models can assist fairness-oriented decision making in the\ncontext of neural networks, support vector machines, and rule-based systems by\nmaximizing a social welfare function subject to appropriate constraints. In\nparticular, we state tractable optimization models for a variety of functions\nthat measure fairness or a combination of fairness and efficiency. These\ninclude several inequality metrics, Rawlsian criteria, the McLoone and Hoover\nindices, alpha fairness, the Nash and Kalai-Smorodinsky bargaining solutions,\ncombinations of Rawlsian and utilitarian criteria, and statistical bias\nmeasures. All of these models can be efficiently solved by linear programming,\nmixed integer/linear programming, or (in two cases) specialized convex\nprogramming methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:11:14 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 01:55:39 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Violet Xinying", ""], ["Hooker", "J. N.", ""]]}, {"id": "2102.00333", "submitter": "Peyman Setoodeh", "authors": "Milad Vaali Esfahaani, Yanbo Xue, and Peyman Setoodeh", "title": "Deep Reinforcement Learning-Based Product Recommender for Online\n  Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, recommender systems try to propose items from a list\nof products to potential customers according to their interests. Such systems\nhave been increasingly deployed in E-commerce due to the rapid growth of\ninformation technology and availability of large datasets. The ever-increasing\nprogress in the field of artificial intelligence has provided powerful tools\nfor dealing with such real-life problems. Deep reinforcement learning (RL) that\ndeploys deep neural networks as universal function approximators can be viewed\nas a valid approach for design and implementation of recommender systems. This\npaper provides a comparative study between value-based and policy-based deep RL\nalgorithms for designing recommender systems for online advertising. The\nRecoGym environment is adopted for training these RL-based recommender systems,\nwhere the long short term memory (LSTM) is deployed to build value and policy\nnetworks in these two approaches, respectively. LSTM is used to take account of\nthe key role that order plays in the sequence of item observations by users.\nThe designed recommender systems aim at maximising the click-through rate (CTR)\nfor the recommended items. Finally, guidelines are provided for choosing proper\nRL algorithms for different scenarios that the recommender system is expected\nto handle.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 23:05:04 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Esfahaani", "Milad Vaali", ""], ["Xue", "Yanbo", ""], ["Setoodeh", "Peyman", ""]]}, {"id": "2102.00337", "submitter": "Jacob Schrum", "authors": "Benjamin Capps and Jacob Schrum", "title": "Using Multiple Generative Adversarial Networks to Build Better-Connected\n  Levels for Mega Man", "comments": "Accepted to Genetic and Evolutionary Computation Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can generate levels for a variety of\ngames. This paper focuses on combining GAN-generated segments in a snaking\npattern to create levels for Mega Man. Adjacent segments in such levels can be\northogonally adjacent in any direction, meaning that an otherwise fine segment\nmight impose a barrier between its neighbor depending on what sorts of segments\nin the training set are being most closely emulated: horizontal, vertical, or\ncorner segments. To pick appropriate segments, multiple GANs were trained on\ndifferent types of segments to ensure better flow between segments. Flow was\nfurther improved by evolving the latent vectors for the segments being joined\nin the level to maximize the length of the level's solution path. Using\nmultiple GANs to represent different types of segments results in significantly\nlonger solution paths than using one GAN for all segment types, and a human\nsubject study verifies that these levels are more fun and have more human-like\ndesign than levels produced by one GAN.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 23:34:15 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:24:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Capps", "Benjamin", ""], ["Schrum", "Jacob", ""]]}, {"id": "2102.00339", "submitter": "Peyman Setoodeh", "authors": "Aref Hakimzadeh, Yanbo Xue, and Peyman Setoodeh", "title": "Enacted Visual Perception: A Computational Model based on Piaget\n  Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Maurice Merleau-Ponty's phenomenology of perception, analysis of\nperception accounts for an element of intentionality, and in effect therefore,\nperception and action cannot be viewed as distinct procedures. In the same line\nof thinking, Alva No\\\"{e} considers perception as a thoughtful activity that\nrelies on capacities for action and thought. Here, by looking into psychology\nas a source of inspiration, we propose a computational model for the action\ninvolved in visual perception based on the notion of equilibrium as defined by\nJean Piaget. In such a model, Piaget's equilibrium reflects the mind's status,\nwhich is used to control the observation process. The proposed model is built\naround a modified version of convolutional neural networks (CNNs) with enhanced\nfilter performance, where characteristics of filters are adaptively adjusted\nvia a high-level control signal that accounts for the thoughtful activity in\nperception. While the CNN plays the role of the visual system, the control\nsignal is assumed to be a product of mind.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 23:52:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hakimzadeh", "Aref", ""], ["Xue", "Yanbo", ""], ["Setoodeh", "Peyman", ""]]}, {"id": "2102.00395", "submitter": "Behrooz Janfada", "authors": "Majid Asgari-Bidhendi, Behrooz Janfada, Amir Havangi, Sayyed Ali\n  Hossayni, Behrouz Minaei-Bidgoli", "title": "An Unsupervised Language-Independent Entity Disambiguation Method and\n  its Evaluation on the English and Persian Languages", "comments": "arXiv admin note: text overlap with arXiv:2004.10816", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Entity Linking is one of the essential tasks of information extraction and\nnatural language understanding. Entity linking mainly consists of two tasks:\nrecognition and disambiguation of named entities. Most studies address these\ntwo tasks separately or focus only on one of them. Moreover, most of the\nstate-of-the -art entity linking algorithms are either supervised, which have\npoor performance in the absence of annotated corpora or language-dependent,\nwhich are not appropriate for multi-lingual applications. In this paper, we\nintroduce an Unsupervised Language-Independent Entity Disambiguation (ULIED),\nwhich utilizes a novel approach to disambiguate and link named entities.\nEvaluation of ULIED on different English entity linking datasets as well as the\nonly available Persian dataset illustrates that ULIED in most of the cases\noutperforms the state-of-the-art unsupervised multi-lingual approaches.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 06:41:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Asgari-Bidhendi", "Majid", ""], ["Janfada", "Behrooz", ""], ["Havangi", "Amir", ""], ["Hossayni", "Sayyed Ali", ""], ["Minaei-Bidgoli", "Behrouz", ""]]}, {"id": "2102.00417", "submitter": "Pranay Lohia", "authors": "Pranay Lohia", "title": "Priority-based Post-Processing Bias Mitigation for Individual and Group\n  Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous post-processing bias mitigation algorithms on both group and\nindividual fairness don't work on regression models and datasets with\nmulti-class numerical labels. We propose a priority-based post-processing bias\nmitigation on both group and individual fairness with the notion that similar\nindividuals should get similar outcomes irrespective of socio-economic factors\nand more the unfairness, more the injustice. We establish this proposition by a\ncase study on tariff allotment in a smart grid. Our novel framework establishes\nit by using a user segmentation algorithm to capture the consumption strategy\nbetter. This process ensures priority-based fair pricing for group and\nindividual facing the maximum injustice. It upholds the notion of fair tariff\nallotment to the entire population taken into consideration without modifying\nthe in-built process for tariff calculation. We also validate our method and\nshow superior performance to previous work on a real-world dataset in criminal\nsentencing.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 09:25:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lohia", "Pranay", ""]]}, {"id": "2102.00431", "submitter": "Longyuan Li", "authors": "Longyuan Li, Jihai Zhang, Junchi Yan, Yaohui Jin, Yunhao Zhang, Yanjie\n  Duan, and Guangjian Tian", "title": "Synergetic Learning of Heterogeneous Temporal Sequences for\n  Multi-Horizon Probabilistic Forecasting", "comments": "Accepted by AAAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series is ubiquitous across applications, such as transportation,\nfinance and healthcare. Time-series is often influenced by external factors,\nespecially in the form of asynchronous events, making forecasting difficult.\nHowever, existing models are mainly designated for either synchronous\ntime-series or asynchronous event sequence, and can hardly provide a synthetic\nway to capture the relation between them. We propose Variational Synergetic\nMulti-Horizon Network (VSMHN), a novel deep conditional generative model. To\nlearn complex correlations across heterogeneous sequences, a tailored encoder\nis devised to combine the advances in deep point processes models and\nvariational recurrent neural networks. In addition, an aligned time coding and\nan auxiliary transition scheme are carefully devised for batched training on\nunaligned sequences. Our model can be trained effectively using stochastic\nvariational inference and generates probabilistic predictions with Monte-Carlo\nsimulation. Furthermore, our model produces accurate, sharp and more realistic\nprobabilistic forecasts. We also show that modeling asynchronous event\nsequences is crucial for multi-horizon time-series forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 11:00:55 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Longyuan", ""], ["Zhang", "Jihai", ""], ["Yan", "Junchi", ""], ["Jin", "Yaohui", ""], ["Zhang", "Yunhao", ""], ["Duan", "Yanjie", ""], ["Tian", "Guangjian", ""]]}, {"id": "2102.00441", "submitter": "Kyung-Wha Park", "authors": "Kyung-Wha Park (1), Jung-Woo Ha (2), JungHoon Lee (3), Sunyoung Kwon\n  (4), Kyung-Min Kim (2), Byoung-Tak Zhang (1 and 5 and 6) ((1)\n  Interdisciplinary Program in Neuroscience, Seoul National University., (2)\n  NAVER AI LAB, NAVER CLOVA., (3) Statistics and Actuarial Science, Soongsil\n  University., (4) School of Biomedical Convergence Engineering, Pusan National\n  University., (5) Department of Computer Science and Engineering, Seoul\n  National University., (6) Surromind Robotics.)", "title": "M2FN: Multi-step Modality Fusion for Advertisement Image Assessment", "comments": "published in Applied Soft Computing", "journal-ref": null, "doi": "10.1016/j.asoc.2021.107116", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Assessing advertisements, specifically on the basis of user preferences and\nad quality, is crucial to the marketing industry. Although recent studies have\nattempted to use deep neural networks for this purpose, these studies have not\nutilized image-related auxiliary attributes, which include embedded text\nfrequently found in ad images. We, therefore, investigated the influence of\nthese attributes on ad image preferences. First, we analyzed large-scale\nreal-world ad log data and, based on our findings, proposed a novel multi-step\nmodality fusion network (M2FN) that determines advertising images likely to\nappeal to user preferences. Our method utilizes auxiliary attributes through\nmultiple steps in the network, which include conditional batch\nnormalization-based low-level fusion and attention-based high-level fusion. We\nverified M2FN on the AVA dataset, which is widely used for aesthetic image\nassessment, and then demonstrated that M2FN can achieve state-of-the-art\nperformance in preference prediction using a real-world ad dataset with rich\nauxiliary attributes.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 12:44:37 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 04:11:47 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 13:05:45 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 08:42:25 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Park", "Kyung-Wha", "", "1 and 5 and 6"], ["Ha", "Jung-Woo", "", "1 and 5 and 6"], ["Lee", "JungHoon", "", "1 and 5 and 6"], ["Kwon", "Sunyoung", "", "1 and 5 and 6"], ["Kim", "Kyung-Min", "", "1 and 5 and 6"], ["Zhang", "Byoung-Tak", "", "1 and 5 and 6"]]}, {"id": "2102.00453", "submitter": "Alexander Bentkamp", "authors": "Alexander Bentkamp, Jasmin Blanchette, Sophie Tourret, Petar\n  Vukmirovi\\'c, Uwe Waldmann", "title": "Superposition with Lambdas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We designed a superposition calculus for a clausal fragment of extensional\npolymorphic higher-order logic that includes anonymous functions but excludes\nBooleans. The inference rules work on $\\beta\\eta$-equivalence classes of\n$\\lambda$-terms and rely on higher-order unification to achieve refutational\ncompleteness. We implemented the calculus in the Zipperposition prover and\nevaluated it on TPTP and Isabelle benchmarks. The results suggest that\nsuperposition is a suitable basis for higher-order reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 13:53:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bentkamp", "Alexander", ""], ["Blanchette", "Jasmin", ""], ["Tourret", "Sophie", ""], ["Vukmirovi\u0107", "Petar", ""], ["Waldmann", "Uwe", ""]]}, {"id": "2102.00466", "submitter": "Matthew McDermott", "authors": "Matthew B. A. McDermott, Brendan Yap, Harry Hsu, Di Jin, Peter\n  Szolovits", "title": "Adversarial Contrastive Pre-training for Protein Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Natural Language Processing (NLP) demonstrate that\nlarge-scale, self-supervised pre-training can be extremely beneficial for\ndownstream tasks. These ideas have been adapted to other domains, including the\nanalysis of the amino acid sequences of proteins. However, to date most\nattempts on protein sequences rely on direct masked language model style\npre-training. In this work, we design a new, adversarial pre-training method\nfor proteins, extending and specializing similar advances in NLP. We show\ncompelling results in comparison to traditional MLM pre-training, though\nfurther development is needed to ensure the gains are worth the significant\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 15:06:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["McDermott", "Matthew B. A.", ""], ["Yap", "Brendan", ""], ["Hsu", "Harry", ""], ["Jin", "Di", ""], ["Szolovits", "Peter", ""]]}, {"id": "2102.00473", "submitter": "Anthony Constantinou", "authors": "Anthony C. Constantinou, Zhigao Guo, Neville K. Kitson", "title": "Information fusion between knowledge and data in Bayesian network\n  structure learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Networks (BNs) have become a powerful technology for reasoning under\nuncertainty, particularly in areas that require causal assumptions that enable\nus to simulate the effect of intervention. The graphical structure of these\nmodels can be determined by causal knowledge, learnt from data, or a\ncombination of both. While it seems plausible that the best approach in\nconstructing a causal graph involves combining knowledge with machine learning,\nthis approach remains underused in practice. We implement and evaluate 10\nknowledge approaches with application to different case studies and BN\nstructure learning algorithms available in the open-source Bayesys structure\nlearning system. The approaches enable us to specify pre-existing knowledge\nthat can be obtained from heterogeneous sources, to constrain or guide\nstructure learning. Each approach is assessed in terms of structure learning\neffectiveness and efficiency, including graphical accuracy, model fitting,\ncomplexity, and runtime; making this the first paper that provides a\ncomparative evaluation of a wide range of knowledge approaches for BN structure\nlearning. Because the value of knowledge depends on what data are available, we\nillustrate the results both with limited and big data. While the overall\nresults show that knowledge becomes less important with big data due to higher\nlearning accuracy rendering knowledge less important, some of the knowledge\napproaches are actually found to be more important with big data. Amongst the\nmain conclusions is the observation that reduced search space obtained from\nknowledge does not always imply reduced computational complexity, perhaps\nbecause the relationships implied by the data and knowledge are in tension.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 15:45:29 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 17:23:10 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Constantinou", "Anthony C.", ""], ["Guo", "Zhigao", ""], ["Kitson", "Neville K.", ""]]}, {"id": "2102.00479", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Masatoshi Uehara", "title": "Fast Rates for the Regret of Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the regret of reinforcement learning from offline data generated by\na fixed behavior policy in an infinite-horizon discounted Markov decision\nprocess (MDP). While existing analyses of common approaches, such as fitted\n$Q$-iteration (FQI), suggest a $O(1/\\sqrt{n})$ convergence for regret,\nempirical behavior exhibits much faster convergence. In this paper, we present\na finer regret analysis that exactly characterizes this phenomenon by providing\nfast rates for the regret convergence. First, we show that given any estimate\nfor the optimal quality function $Q^*$, the regret of the policy it defines\nconverges at a rate given by the exponentiation of the $Q^*$-estimate's\npointwise convergence rate, thus speeding it up. The level of exponentiation\ndepends on the level of noise in the decision-making problem, rather than the\nestimation problem. We establish such noise levels for linear and tabular MDPs\nas examples. Second, we provide new analyses of FQI and Bellman residual\nminimization to establish the correct pointwise convergence guarantees. As\nspecific cases, our results imply $O(1/n)$ regret rates in linear cases and\n$\\exp(-\\Omega(n))$ regret rates in tabular cases.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 16:17:56 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "2102.00511", "submitter": "Edgard Chammas", "authors": "Edgard Chammas, Chafic Mokbel", "title": "Fine-tuning Handwriting Recognition systems with Temporal Dropout", "comments": "5 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a novel method to fine-tune handwriting recognition\nsystems based on Recurrent Neural Networks (RNN). Long Short-Term Memory (LSTM)\nnetworks are good at modeling long sequences but they tend to overfit over\ntime. To improve the system's ability to model sequences, we propose to drop\ninformation at random positions in the sequence. We call our approach Temporal\nDropout (TD). We apply TD at the image level as well to internal network\nrepresentation. We show that TD improves the results on two different datasets.\nOur method outperforms previous state-of-the-art on Rodrigo dataset.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 18:27:08 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chammas", "Edgard", ""], ["Mokbel", "Chafic", ""]]}, {"id": "2102.00521", "submitter": "Saksham Consul", "authors": "Saksham Consul, Lovis Heindrich, Jugoslav Stojcheski, Falk Lieder", "title": "Improving Human Decision-Making by Discovering Efficient Strategies for\n  Hierarchical Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To make good decisions in the real world people need efficient planning\nstrategies because their computational resources are limited. Knowing which\nplanning strategies would work best for people in different situations would be\nvery useful for understanding and improving human decision-making. But our\nability to compute those strategies used to be limited to very small and very\nsimple planning tasks. To overcome this computational bottleneck, we introduce\na cognitively-inspired reinforcement learning method that can overcome this\nlimitation by exploiting the hierarchical structure of human behavior. The\nbasic idea is to decompose sequential decision problems into two sub-problems:\nsetting a goal and planning how to achieve it. This hierarchical decomposition\nenables us to discover optimal strategies for human planning in larger and more\ncomplex tasks than was previously possible. The discovered strategies\noutperform existing planning algorithms and achieve a super-human level of\ncomputational efficiency. We demonstrate that teaching people to use those\nstrategies significantly improves their performance in sequential\ndecision-making tasks that require planning up to eight steps ahead. By\ncontrast, none of the previous approaches was able to improve human performance\non these problems. These findings suggest that our cognitively-informed\napproach makes it possible to leverage reinforcement learning to improve human\ndecision-making in complex sequential decision-problems. Future work can\nleverage our method to develop decision support systems that improve human\ndecision making in the real world.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 19:46:00 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Consul", "Saksham", ""], ["Heindrich", "Lovis", ""], ["Stojcheski", "Jugoslav", ""], ["Lieder", "Falk", ""]]}, {"id": "2102.00534", "submitter": "Siqiao Ruan", "authors": "Siqiao Ruan, Ian Colbert, Ken Kreutz-Delgado, and Srinjoy Das", "title": "Generative and Discriminative Deep Belief Network Classifiers:\n  Comparisons Under an Approximate Computing Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Deep Learning hardware algorithms for embedded applications is\ncharacterized by challenges such as constraints on device power consumption,\navailability of labeled data, and limited internet bandwidth for frequent\ntraining on cloud servers. To enable low power implementations, we consider\nefficient bitwidth reduction and pruning for the class of Deep Learning\nalgorithms known as Discriminative Deep Belief Networks (DDBNs) for\nembedded-device classification tasks. We train DDBNs with both generative and\ndiscriminative objectives under an approximate computing framework and analyze\ntheir power-at-performance for supervised and semi-supervised applications. We\nalso investigate the out-of-distribution performance of DDBNs when the\ninference data has the same class structure yet is statistically different from\nthe training data owing to dynamic real-time operating environments. Based on\nour analysis, we provide novel insights and recommendations for choice of\ntraining objectives, bitwidth values, and accuracy sensitivity with respect to\nthe amount of labeled data for implementing DDBN inference with minimum power\nconsumption on embedded hardware platforms subject to accuracy tolerances.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 20:57:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ruan", "Siqiao", ""], ["Colbert", "Ian", ""], ["Kreutz-Delgado", "Ken", ""], ["Das", "Srinjoy", ""]]}, {"id": "2102.00554", "submitter": "Torsten Hoefler", "authors": "Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, Alexandra\n  Peste", "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference\n  and training in neural networks", "comments": "90 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing energy and performance costs of deep learning have driven the\ncommunity to reduce the size of neural networks by selectively pruning\ncomponents. Similarly to their biological counterparts, sparse networks\ngeneralize just as well, if not better than, the original dense networks.\nSparsity can reduce the memory footprint of regular networks to fit mobile\ndevices, as well as shorten training time for ever growing networks. In this\npaper, we survey prior work on sparsity in deep learning and provide an\nextensive tutorial of sparsification for both inference and training. We\ndescribe approaches to remove and add elements of neural networks, different\ntraining strategies to achieve model sparsity, and mechanisms to exploit\nsparsity in practice. Our work distills ideas from more than 300 research\npapers and provides guidance to practitioners who wish to utilize sparsity\ntoday, as well as to researchers whose goal is to push the frontier forward. We\ninclude the necessary background on mathematical methods in sparsification,\ndescribe phenomena such as early structure adaptation, the intricate relations\nbetween sparsity and the training process, and show techniques for achieving\nacceleration on real hardware. We also define a metric of pruned parameter\nefficiency that could serve as a baseline for comparison of different sparse\nnetworks. We close by speculating on how sparsity can improve future workloads\nand outline major open problems in the field.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 22:48:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hoefler", "Torsten", ""], ["Alistarh", "Dan", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Peste", "Alexandra", ""]]}, {"id": "2102.00565", "submitter": "Mohamed Ibrahim", "authors": "Mohamed R. Ibrahim, James Haworth, Nicola Christie and Tao Cheng", "title": "CyclingNet: Detecting cycling near misses from video streams in complex\n  urban scenes with deep learning", "comments": "13 Pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cycling is a promising sustainable mode for commuting and leisure in cities,\nhowever, the fear of getting hit or fall reduces its wide expansion as a\ncommuting mode. In this paper, we introduce a novel method called CyclingNet\nfor detecting cycling near misses from video streams generated by a mounted\nfrontal camera on a bike regardless of the camera position, the conditions of\nthe built, the visual conditions and without any restrictions on the riding\nbehaviour. CyclingNet is a deep computer vision model based on convolutional\nstructure embedded with self-attention bidirectional long-short term memory\n(LSTM) blocks that aim to understand near misses from both sequential images of\nscenes and their optical flows. The model is trained on scenes of both safe\nrides and near misses. After 42 hours of training on a single GPU, the model\nshows high accuracy on the training, testing and validation sets. The model is\nintended to be used for generating information that can draw significant\nconclusions regarding cycling behaviour in cities and elsewhere, which could\nhelp planners and policy-makers to better understand the requirement of safety\nmeasures when designing infrastructure or drawing policies. As for future work,\nthe model can be pipelined with other state-of-the-art classifiers and object\ndetectors simultaneously to understand the causality of near misses based on\nfactors related to interactions of road-users, the built and the natural\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 23:59:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ibrahim", "Mohamed R.", ""], ["Haworth", "James", ""], ["Christie", "Nicola", ""], ["Cheng", "Tao", ""]]}, {"id": "2102.00567", "submitter": "Hassan Moussa Mr", "authors": "Hassan Moussa", "title": "Using Recursive KMeans and Dijkstra Algorithm to Solve CVRP", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.20970.85447", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capacitated vehicle routing problem (CVRP) is being one of the most common\noptimization problems in our days, considering the wide usage of routing\nalgorithms in multiple fields such as transportation domain, food delivery,\nnetwork routing, ... Capacitated vehicle routing problem is classified as an\nNP-Hard problem, hence normal optimization algorithm can\u00e2\u0080\u0099t solve it. In our\npaper, we discuss a new way to solve the mentioned problem, using a recursive\napproach of the most known clustering algorithm \u00e2\u0080\u009cK-Means\u00e2\u0080\u009d, one of the known\nshortest path algorithm \u00e2\u0080\u009cDijkstra\u00e2\u0080\u009d, and some mathematical operations. In this\npaper, we will show how to implement those methods together in order to get the\nnearest solution of the optimal route, since research and development are still\non go, this research paper may be extended with another one, that will involve\nthe implementational results of this thoric side.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 00:03:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Moussa", "Hassan", ""]]}, {"id": "2102.00572", "submitter": "Peyman Setoodeh", "authors": "Aref Hakimzadeh, Yanbo Xue, and Peyman Setoodeh", "title": "Interpretable Reinforcement Learning Inspired by Piaget's Theory of\n  Cognitive Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endeavors for designing robots with human-level cognitive abilities have led\nto different categories of learning machines. According to Skinner's theory,\nreinforcement learning (RL) plays a key role in human intuition and cognition.\nMajority of the state-of-the-art methods including deep RL algorithms are\nstrongly influenced by the connectionist viewpoint. Such algorithms can\nsignificantly benefit from theories of mind and learning in other disciplines.\nThis paper entertains the idea that theories such as language of thought\nhypothesis (LOTH), script theory, and Piaget's cognitive development theory\nprovide complementary approaches, which will enrich the RL field. Following\nthis line of thinking, a general computational building block is proposed for\nPiaget's schema theory that supports the notions of productivity,\nsystematicity, and inferential coherence as described by Fodor in contrast with\nthe connectionism theory. Abstraction in the proposed method is completely upon\nthe system itself and is not externally constrained by any predefined\narchitecture. The whole process matches the Neisser's perceptual cycle model.\nPerformed experiments on three typical control problems followed by behavioral\nanalysis confirm the interpretability of the proposed method and its\ncompetitiveness compared to the state-of-the-art algorithms. Hence, the\nproposed framework can be viewed as a step towards achieving human-like\ncognition in artificial intelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 00:29:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hakimzadeh", "Aref", ""], ["Xue", "Yanbo", ""], ["Setoodeh", "Peyman", ""]]}, {"id": "2102.00582", "submitter": "Lewis Hammond", "authors": "Lewis Hammond and Alessandro Abate and Julian Gutierrez and Michael\n  Wooldridge", "title": "Multi-Agent Reinforcement Learning with Temporal Logic Specifications", "comments": "Accepted to the 20th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning to satisfy temporal logic\nspecifications with a group of agents in an unknown environment, which may\nexhibit probabilistic behaviour. From a learning perspective these\nspecifications provide a rich formal language with which to capture tasks or\nobjectives, while from a logic and automated verification perspective the\nintroduction of learning capabilities allows for practical applications in\nlarge, stochastic, unknown environments. The existing work in this area is,\nhowever, limited. Of the frameworks that consider full linear temporal logic or\nhave correctness guarantees, all methods thus far consider only the case of a\nsingle temporal logic specification and a single agent. In order to overcome\nthis limitation, we develop the first multi-agent reinforcement learning\ntechnique for temporal logic specifications, which is also novel in its ability\nto handle multiple specifications. We provide correctness and convergence\nguarantees for our main algorithm - ALMANAC (Automaton/Logic Multi-Agent\nNatural Actor-Critic) - even when using function approximation. Alongside our\ntheoretical results, we further demonstrate the applicability of our technique\nvia a set of preliminary experiments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 01:13:03 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 18:57:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hammond", "Lewis", ""], ["Abate", "Alessandro", ""], ["Gutierrez", "Julian", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2102.00617", "submitter": "Hao Zhan", "authors": "Dan Wan and Hao Zhan", "title": "The Controllability of Planning, Responsibility, and Security in\n  Automatic Driving Technology", "comments": "49th International Conference on Computers and Industrial\n  Engineering, CIE 2019. arXiv admin note: substantial text overlap with\n  arXiv:1906.07861", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People hope automated driving technology is always in a stable and\ncontrollable state; specifically, it can be divided into controllable planning,\ncontrollable responsibility, and controllable information. When this\ncontrollability is undermined, it brings about the problems, e.g., trolley\ndilemma, responsibility attribution, information leakage, and security. This\narticle discusses these three types of issues separately and clarifies the\nmisunderstandings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 03:41:37 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Wan", "Dan", ""], ["Zhan", "Hao", ""]]}, {"id": "2102.00621", "submitter": "Yi Shi", "authors": "Yi Shi and Congyi Wang and Yu Chen and Bin Wang", "title": "Polyphone Disambiguition in Mandarin Chinese with Semi-Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of Chinese characters are monophonic, while a special group of\ncharacters, called polyphonic characters, have multiple pronunciations. As a\nprerequisite of performing speech-related generative tasks, the correct\npronunciation must be identified among several candidates. This process is\ncalled Polyphone Disambiguation. Although the problem has been well explored\nwith both knowledge-based and learning-based approaches, it remains challenging\ndue to the lack of publicly available labeled datasets and the irregular nature\nof polyphone in Mandarin Chinese. In this paper, we propose a novel\nsemi-supervised learning (SSL) framework for Mandarin Chinese polyphone\ndisambiguation that can potentially leverage unlimited unlabeled text data. We\nexplore the effect of various proxy labeling strategies including\nentropy-thresholding and lexicon-based labeling. Qualitative and quantitative\nexperiments demonstrate that our method achieves state-of-the-art performance.\nIn addition, we publish a novel dataset specifically for the polyphone\ndisambiguation task to promote further researches.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 03:47:59 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 06:52:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Shi", "Yi", ""], ["Wang", "Congyi", ""], ["Chen", "Yu", ""], ["Wang", "Bin", ""]]}, {"id": "2102.00625", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Nina Grgi\\'c-Hla\\v{c}a, Meeyoung Cha", "title": "Human Perceptions on Moral Responsibility of AI: A Case Study in\n  AI-Assisted Bail Decision-Making", "comments": "17 Pages, 5 Figures, ACM CHI 2021", "journal-ref": null, "doi": "10.1145/3411764.3445260", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to attribute responsibility for autonomous artificial intelligence (AI)\nsystems' actions has been widely debated across the humanities and social\nscience disciplines. This work presents two experiments ($N$=200 each) that\nmeasure people's perceptions of eight different notions of moral responsibility\nconcerning AI and human agents in the context of bail decision-making. Using\nreal-life adapted vignettes, our experiments show that AI agents are held\ncausally responsible and blamed similarly to human agents for an identical\ntask. However, there was a meaningful difference in how people perceived these\nagents' moral responsibility; human agents were ascribed to a higher degree of\npresent-looking and forward-looking notions of responsibility than AI agents.\nWe also found that people expect both AI and human decision-makers and advisors\nto justify their decisions regardless of their nature. We discuss policy and\nHCI implications of these findings, such as the need for explainable AI in\nhigh-stakes scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 04:07:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lima", "Gabriel", ""], ["Grgi\u0107-Hla\u010da", "Nina", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2102.00649", "submitter": "Eadom Dessalene", "authors": "Eadom Dessalene, Chinmaya Devaraj, Michael Maynord, Cornelia\n  Fermuller, and Yiannis Aloimonos", "title": "Forecasting Action through Contact Representations from First Person\n  Video", "comments": "12 pages, 5 figures. in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence, 2021", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3055233", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human actions involving hand manipulations are structured according to the\nmaking and breaking of hand-object contact, and human visual understanding of\naction is reliant on anticipation of contact as is demonstrated by pioneering\nwork in cognitive science. Taking inspiration from this, we introduce\nrepresentations and models centered on contact, which we then use in action\nprediction and anticipation. We annotate a subset of the EPIC Kitchens dataset\nto include time-to-contact between hands and objects, as well as segmentations\nof hands and objects. Using these annotations we train the Anticipation Module,\na module producing Contact Anticipation Maps and Next Active Object\nSegmentations - novel low-level representations providing temporal and spatial\ncharacteristics of anticipated near future action. On top of the Anticipation\nModule we apply Egocentric Object Manipulation Graphs (Ego-OMG), a framework\nfor action anticipation and prediction. Ego-OMG models longer term temporal\nsemantic relations through the use of a graph modeling transitions between\ncontact delineated action states. Use of the Anticipation Module within Ego-OMG\nproduces state-of-the-art results, achieving 1st and 2nd place on the unseen\nand seen test sets, respectively, of the EPIC Kitchens Action Anticipation\nChallenge, and achieving state-of-the-art results on the tasks of action\nanticipation and action prediction over EPIC Kitchens. We perform ablation\nstudies over characteristics of the Anticipation Module to evaluate their\nutility.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 05:52:57 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dessalene", "Eadom", ""], ["Devaraj", "Chinmaya", ""], ["Maynord", "Michael", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2102.00651", "submitter": "Zhicheng Liang", "authors": "Zhicheng Liang and Deborah L. McGuinness", "title": "Commonsense Knowledge Mining from Term Definitions", "comments": "In the Commonsense Knowledge Graphs (CSKGs) Workshop of the 35th AAAI\n  Conference on Artificial Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge has proven to be beneficial to a variety of application\nareas, including question answering and natural language understanding.\nPrevious work explored collecting commonsense knowledge triples automatically\nfrom text to increase the coverage of current commonsense knowledge graphs. We\ninvestigate a few machine learning approaches to mining commonsense knowledge\ntriples using dictionary term definitions as inputs and provide some initial\nevaluation of the results. We start from extracting candidate triples using\npart-of-speech tag patterns from text, and then compare the performance of\nthree existing models for triple scoring. Our experiments show that term\ndefinitions contain some valid and novel commonsense knowledge triples for some\nsemantic relations, and also indicate some challenges with using existing\ntriple scoring models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 05:54:02 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Liang", "Zhicheng", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2102.00662", "submitter": "Yaguan Qian", "authors": "Yaguan Qian, Qiqi Shao, Tengteng Yao, Bin Wang, Shouling Ji, Shaoning\n  Zeng, Zhaoquan Gu and Wassim Swaileh", "title": "Towards Speeding up Adversarial Training in Latent Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is wildly considered as one of the most effective way to\ndefend against adversarial examples. However, existing adversarial training\nmethods consume unbearable time, due to the fact that they need to generate\nadversarial examples in the large input space. To speed up adversarial\ntraining, we propose a novel adversarial training method that does not need to\ngenerate real adversarial examples. By adding perturbations to logits to\ngenerate Endogenous Adversarial Examples (EAEs) -- the adversarial examples in\nthe latent space, the time consuming gradient calculation can be avoided.\nExtensive experiments are conducted on CIFAR-10 and ImageNet, and the results\nshow that comparing to state-of-the-art methods, our EAE adversarial training\nnot only shortens the training time, but also enhances the robustness of the\nmodel and has less impact on the accuracy of clean examples than the existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 06:30:32 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 01:21:44 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Qian", "Yaguan", ""], ["Shao", "Qiqi", ""], ["Yao", "Tengteng", ""], ["Wang", "Bin", ""], ["Ji", "Shouling", ""], ["Zeng", "Shaoning", ""], ["Gu", "Zhaoquan", ""], ["Swaileh", "Wassim", ""]]}, {"id": "2102.00675", "submitter": "Xiaodong Mei", "authors": "Xiaodong Mei, Yuxiang Sun, Yuying Chen, Congcong Liu, Ming Liu", "title": "Autonomous Navigation through intersections with Graph\n  ConvolutionalNetworks and Conditional Imitation Learning for Self-driving\n  Cars", "comments": "Under review status in ICRA2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous driving, navigation through unsignaled intersections with many\ntraffic participants moving around is a challenging task. To provide a solution\nto this problem, we propose a novel branched network G-CIL for the navigation\npolicy learning. Specifically, we firstly represent such dynamic environments\nas graph-structured data and propose an effective strategy for edge definition\nto aggregate surrounding information for the ego-vehicle. Then graph\nconvolutional neural networks are used as the perception module to capture\nglobal and geometric features from the environment. To generate safe and\nefficient navigation policy, we further incorporate it with conditional\nimitation learning algorithm, to learn driving behaviors directly from expert\ndemonstrations. Our proposed network is capable of handling a varying number of\nsurrounding vehicles and generating optimal control actions (e.g., steering\nangle and throttle) according to the given high-level commands (e.g., turn left\ntowards the global goal). Evaluations on unsignaled intersections with various\ntraffic densities demonstrate that our end-to-end trainable neural network\noutperforms the baselines with higher success rate and shorter navigation time.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 07:33:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mei", "Xiaodong", ""], ["Sun", "Yuxiang", ""], ["Chen", "Yuying", ""], ["Liu", "Congcong", ""], ["Liu", "Ming", ""]]}, {"id": "2102.00696", "submitter": "Selim Furkan Tekin", "authors": "Selim Furkan Tekin, Oguzhan Karaahmetoglu, Fatih Ilhan, Ismail Balaban\n  and Suleyman Serdar Kozat", "title": "Spatio-temporal Weather Forecasting and Attention Mechanism on\n  Convolutional LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical weather forecasting on high-resolution physical models consume\nhours of computations on supercomputers. Application of deep learning and\nmachine learning methods in forecasting revealed new solutions in this area. In\nthis paper, we forecast high-resolution numeric weather data using both input\nweather data and observations by providing a novel deep learning architecture.\nWe formulate the problem as spatio-temporal prediction. Our model is composed\nof Convolutional Long-short Term Memory, and Convolutional Neural Network units\nwith encoder-decoder structure. We enhance the short-long term performance and\ninterpretability with an attention and a context matcher mechanism. We perform\nexperiments on high-scale, real-life, benchmark numerical weather dataset, ERA5\nhourly data on pressure levels, and forecast the temperature. The results show\nsignificant improvements in capturing both spatial and temporal correlations\nwith attention matrices focusing on different parts of the input series. Our\nmodel obtains the best validation and the best test score among the baseline\nmodels, including ConvLSTM forecasting network and U-Net. We provide\nqualitative and quantitative results and show that our model forecasts 10 time\nsteps with 3 hour frequency with an average of 2 degrees error. Our code and\nthe data are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 08:30:42 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tekin", "Selim Furkan", ""], ["Karaahmetoglu", "Oguzhan", ""], ["Ilhan", "Fatih", ""], ["Balaban", "Ismail", ""], ["Kozat", "Suleyman Serdar", ""]]}, {"id": "2102.00714", "submitter": "Yang Yu", "authors": "Rongjun Qin, Songyi Gao, Xingyuan Zhang, Zhen Xu, Shengkai Huang,\n  Zewen Li, Weinan Zhang, Yang Yu", "title": "NeoRL: A Near Real-World Benchmark for Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offline reinforcement learning (RL) aims at learning a good policy from a\nbatch of collected data, without extra interactions with the environment during\ntraining. However, current offline RL benchmarks commonly have a large reality\ngap, because they involve large datasets collected by highly exploratory\npolicies, and the trained policy is directly evaluated in the environment. In\nreal-world situations, running a highly exploratory policy is prohibited to\nensure system safety, the data is commonly very limited, and a trained policy\nshould be well validated before deployment. In this paper, we present a near\nreal-world offline RL benchmark, named NeoRL, which contains datasets from\nvarious domains with controlled sizes, and extra test datasets for policy\nvalidation. We evaluate existing offline RL algorithms on NeoRL and argue that\nthe performance of a policy should also be compared with the deterministic\nversion of the behavior policy, instead of the dataset reward. The empirical\nresults demonstrate that the tested offline RL algorithms become less\ncompetitive to the deterministic policy on many datasets, and the offline\npolicy evaluation hardly helps. The NeoRL suit can be found at\nhttp://polixir.ai/research/neorl. We hope this work will shed some light on\nfuture research and draw more attention when deploying RL in real-world\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 09:19:10 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 09:00:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Qin", "Rongjun", ""], ["Gao", "Songyi", ""], ["Zhang", "Xingyuan", ""], ["Xu", "Zhen", ""], ["Huang", "Shengkai", ""], ["Li", "Zewen", ""], ["Zhang", "Weinan", ""], ["Yu", "Yang", ""]]}, {"id": "2102.00735", "submitter": "Qisheng Wang", "authors": "Qisheng Wang, Xiao Li, Shi Jin, and Yijiain Chen", "title": "Hybrid Beamforming for mmWave MU-MISO Systems Exploiting Multi-agent\n  Deep Reinforcement Learning", "comments": "5 pages, 4 figures, journal paper in press for publication", "journal-ref": null, "doi": "10.1109/LWC.2021.3056702", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this letter, we investigate the hybrid beamforming based on deep\nreinforcement learning (DRL) for millimeter Wave (mmWave) multi-user (MU)\nmultiple-input-single-output (MISO) system. A multi-agent DRL method is\nproposed to solve the exploration efficiency problem in DRL. In the proposed\nmethod, prioritized replay buffer and more informative reward are applied to\naccelerate the convergence. Simulation results show that the proposed\narchitecture achieves higher spectral efficiency and less time consumption than\nthe benchmarks, thus is more suitable for practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 10:04:20 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Qisheng", ""], ["Li", "Xiao", ""], ["Jin", "Shi", ""], ["Chen", "Yijiain", ""]]}, {"id": "2102.00760", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes and Alessandro Rudi and Francis Bach", "title": "Fast rates in structured prediction", "comments": "14 main pages, 3 main figures, 43 pages, 4 figures (with appendix)", "journal-ref": "Conference on Learning Theory, PMLR 134, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrete supervised learning problems such as classification are often\ntackled by introducing a continuous surrogate problem akin to regression.\nBounding the original error, between estimate and solution, by the surrogate\nerror endows discrete problems with convergence rates already shown for\ncontinuous instances. Yet, current approaches do not leverage the fact that\ndiscrete problems are essentially predicting a discrete output when continuous\nproblems are predicting a continuous value. In this paper, we tackle this issue\nfor general structured prediction problems, opening the way to \"super fast\"\nrates, that is, convergence rates for the excess risk faster than $n^{-1}$,\nwhere $n$ is the number of observations, with even exponential rates with the\nstrongest assumptions. We first illustrate it for predictors based on nearest\nneighbors, generalizing rates known for binary classification to any discrete\nproblem within the framework of structured prediction. We then consider kernel\nridge regression where we improve known rates in $n^{-1/4}$ to arbitrarily fast\nrates, depending on a parameter characterizing the hardness of the problem,\nthus allowing, under smoothness assumptions, to bypass the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 10:50:04 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 13:02:31 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 15:04:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Rudi", "Alessandro", ""], ["Bach", "Francis", ""]]}, {"id": "2102.00769", "submitter": "Yukai Shi", "authors": "Yukai Shi, Sen Zhang, Chenxing Zhou, Xiaodan Liang, Xiaojun Yang,\n  Liang Lin", "title": "GTAE: Graph-Transformer based Auto-Encoders for Linguistic-Constrained\n  Text Style Transfer", "comments": "The first two authors share equal-authorship;\n  Code:https://github.com/SenZHANG-GitHub/graph-text-style-transfer ;\n  benchmark: https://github.com/ykshi/text-style-transfer-benchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel text style transfer has attracted increasing research interests\nin recent years. Despite successes in transferring the style based on the\nencoder-decoder framework, current approaches still lack the ability to\npreserve the content and even logic of original sentences, mainly due to the\nlarge unconstrained model space or too simplified assumptions on latent\nembedding space. Since language itself is an intelligent product of humans with\ncertain grammars and has a limited rule-based model space by its nature,\nrelieving this problem requires reconciling the model capacity of deep neural\nnetworks with the intrinsic model constraints from human linguistic rules. To\nthis end, we propose a method called Graph Transformer based Auto Encoder\n(GTAE), which models a sentence as a linguistic graph and performs feature\nextraction and style transfer at the graph level, to maximally retain the\ncontent and the linguistic structure of original sentences. Quantitative\nexperiment results on three non-parallel text style transfer tasks show that\nour model outperforms state-of-the-art methods in content preservation, while\nachieving comparable performance on transfer accuracy and sentence naturalness.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 11:08:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Shi", "Yukai", ""], ["Zhang", "Sen", ""], ["Zhou", "Chenxing", ""], ["Liang", "Xiaodan", ""], ["Yang", "Xiaojun", ""], ["Lin", "Liang", ""]]}, {"id": "2102.00781", "submitter": "Sandeep Mathias", "authors": "Rahul Kumar, Sandeep Mathias, Sriparna Saha, Pushpak Bhattacharyya", "title": "Many Hands Make Light Work: Using Essay Traits to Automatically Score\n  Essays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research in the area of automatic essay grading (AEG) is geared towards\nscoring the essay holistically while there has also been some work done on\nscoring individual essay traits. In this paper, we describe a way to score\nessays holistically using a multi-task learning (MTL) approach, where scoring\nthe essay holistically is the primary task, and scoring the essay traits is the\nauxiliary task. We compare our results with a single-task learning (STL)\napproach, using both LSTMs and BiLSTMs. We also compare our results of the\nauxiliary task with such tasks done in other AEG systems. To find out which\ntraits work best for different types of essays, we conduct ablation tests for\neach of the essay traits. We also report the runtime and number of training\nparameters for each system. We find that MTL-based BiLSTM system gives the best\nresults for scoring the essay holistically, as well as performing well on\nscoring the essay traits.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 11:31:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kumar", "Rahul", ""], ["Mathias", "Sandeep", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2102.00801", "submitter": "Kun Yan", "authors": "Kun Yan, Zied Bouraoui, Ping Wang, Shoaib Jameel, Steven Schockaert", "title": "Few-shot Image Classification with Multi-Facet Prototypes", "comments": "Accepted by ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of few-shot learning (FSL) is to learn how to recognize image\ncategories from a small number of training examples. A central challenge is\nthat the available training examples are normally insufficient to determine\nwhich visual features are most characteristic of the considered categories. To\naddress this challenge, we organize these visual features into facets, which\nintuitively group features of the same kind (e.g. features that are relevant to\nshape, color, or texture). This is motivated from the assumption that (i) the\nimportance of each facet differs from category to category and (ii) it is\npossible to predict facet importance from a pre-trained embedding of the\ncategory names. In particular, we propose an adaptive similarity measure,\nrelying on predicted facet importance weights for a given set of categories.\nThis measure can be used in combination with a wide array of existing\nmetric-based methods. Experiments on miniImageNet and CUB show that our\napproach improves the state-of-the-art in metric-based FSL.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 12:43:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yan", "Kun", ""], ["Bouraoui", "Zied", ""], ["Wang", "Ping", ""], ["Jameel", "Shoaib", ""], ["Schockaert", "Steven", ""]]}, {"id": "2102.00813", "submitter": "Inioluwa Deborah Raji", "authors": "Inioluwa Deborah Raji, Genevieve Fried", "title": "About Face: A Survey of Facial Recognition Evaluation", "comments": "Presented at AAAI 2020 Workshop on AI Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We survey over 100 face datasets constructed between 1976 to 2019 of 145\nmillion images of over 17 million subjects from a range of sources,\ndemographics and conditions. Our historical survey reveals that these datasets\nare contextually informed, shaped by changes in political motivations,\ntechnological capability and current norms. We discuss how such influences mask\nspecific practices (some of which may actually be harmful or otherwise\nproblematic) and make a case for the explicit communication of such details in\norder to establish a more grounded understanding of the technology's function\nin the real world.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:05:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Raji", "Inioluwa Deborah", ""], ["Fried", "Genevieve", ""]]}, {"id": "2102.00815", "submitter": "Qinghua Liu", "authors": "Chi Jin, Qinghua Liu, Sobhan Miryoosefi", "title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and\n  Sample-Efficient Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the minimal structural assumptions that empower sample-efficient\nlearning is one of the most important research directions in Reinforcement\nLearning (RL). This paper advances our understanding of this fundamental\nquestion by introducing a new complexity measure -- Bellman Eluder (BE)\ndimension. We show that the family of RL problems of low BE dimension is\nremarkably rich, which subsumes a vast majority of existing tractable RL\nproblems including but not limited to tabular MDPs, linear MDPs, reactive\nPOMDPs, low Bellman rank problems as well as low Eluder dimension problems.\nThis paper further designs a new optimization-based algorithm -- GOLF, and\nreanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang\net al., 2017). We prove that both algorithms learn the near-optimal policies of\nlow BE dimension problems in a number of samples that is polynomial in all\nrelevant parameters, but independent of the size of state-action space. Our\nregret and sample complexity results match or improve the best existing results\nfor several well-known subclasses of low BE dimension problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:13:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 04:48:14 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 01:57:55 GMT"}, {"version": "v4", "created": "Fri, 16 Jul 2021 02:45:23 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jin", "Chi", ""], ["Liu", "Qinghua", ""], ["Miryoosefi", "Sobhan", ""]]}, {"id": "2102.00818", "submitter": "Frank Hannig", "authors": "Frank Hannig, Paolo Meloni, Matteo Spallanzani, Matthias Ziegler", "title": "Proceedings of the DATE Friday Workshop on System-level Design Methods\n  for Deep Learning on Heterogeneous Architectures (SLOHA 2021)", "comments": "Website of the workshop: https://www12.cs.fau.de/ws/sloha2021/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This volume contains the papers accepted at the first DATE Friday Workshop on\nSystem-level Design Methods for Deep Learning on Heterogeneous Architectures\n(SLOHA 2021), held virtually on February 5, 2021. SLOHA 2021 was co-located\nwith the Conference on Design, Automation and Test in Europe (DATE).\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 18:14:02 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hannig", "Frank", ""], ["Meloni", "Paolo", ""], ["Spallanzani", "Matteo", ""], ["Ziegler", "Matthias", ""]]}, {"id": "2102.00820", "submitter": "Ali Mousavi", "authors": "Ali Mousavi, Mehrdad Jalali and Mahdi Yaghoubi", "title": "Adaptive Neuro Fuzzy Networks based on Quantum Subtractive Clustering", "comments": "Proceedings of the International Conference on Data Science\n  (IC-DATA), The Steering Committee of The World Congress in Computer Science,\n  Computer Engineering and Applied Computing (WorldComp), Nevada, USA, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data mining techniques can be used to discover useful patterns by exploring\nand analyzing data and it's feasible to synergitically combine machine learning\ntools to discover fuzzy classification rules.In this paper, an adaptive Neuro\nfuzzy network with TSK fuzzy type and an improved quantum subtractive\nclustering has been developed. Quantum clustering (QC) is an intuition from\nquantum mechanics which uses Schrodinger potential and time-consuming gradient\ndescent method. The principle advantage and shortcoming of QC is analyzed and\nbased on its shortcomings, an improved algorithm through a subtractive\nclustering method is proposed. Cluster centers represent a general model with\nessential characteristics of data which can be use as premise part of fuzzy\nrules.The experimental results revealed that proposed Anfis based on quantum\nsubtractive clustering yielded good approximation and generalization\ncapabilities and impressive decrease in the number of fuzzy rules and network\noutput accuracy in comparison with traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 20:59:48 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mousavi", "Ali", ""], ["Jalali", "Mehrdad", ""], ["Yaghoubi", "Mahdi", ""]]}, {"id": "2102.00824", "submitter": "Nikunj Gupta", "authors": "Nikunj Gupta, G Srinivasaraghavan, Swarup Kumar Mohalik, Matthew E.\n  Taylor", "title": "HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via\n  Learned Messaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Cooperative multi-agent reinforcement learning (MARL) has achieved\nsignificant results, most notably by leveraging the representation learning\nabilities of deep neural networks. However, large centralized approaches\nquickly become infeasible as the number of agents scale, and fully\ndecentralized approaches can miss important opportunities for information\nsharing and coordination. Furthermore, not all agents are equal - in some\ncases, individual agents may not even have the ability to send communication to\nother agents or explicitly model other agents. This paper considers the case\nwhere there is a single, powerful, central agent that can observe the entire\nobservation space, and there are multiple, low powered, local agents that can\nonly receive local observations and cannot communicate with each other. The job\nof the central agent is to learn what message to send to different local\nagents, based on the global observations, not by centrally solving the entire\nproblem and sending action commands, but by determining what additional\ninformation an individual agent should receive so that it can make a better\ndecision. After explaining our MARL algorithm, hammer, and where it would be\nmost applicable, we implement it in the cooperative navigation and multi-agent\nwalker domains. Empirical results show that 1) learned communication does\nindeed improve system performance, 2) results generalize to multiple numbers of\nagents, and 3) results generalize to different reward structures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 19:00:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Gupta", "Nikunj", ""], ["Srinivasaraghavan", "G", ""], ["Mohalik", "Swarup Kumar", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2102.00826", "submitter": "Kaibo Cao", "authors": "Kaibo Cao (1), Chunyang Chen (2), Sebastian Baltes (3), Christoph\n  Treude (3), Xiang Chen (4) ((1) Software Institute, Nanjing University,\n  China, (2) Faculty of Information Technology, Monash University, Australia,\n  (3) School of Computer Science, University of Adelaide, Australia, (4) School\n  of Information Science and Technology, Nantong University, China)", "title": "Automated Query Reformulation for Efficient Search based on Query Logs\n  From Stack Overflow", "comments": "13 pages, 6 figures, accepted in ICSE'21: 43rd IEEE/ACM International\n  Conference on Software Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As a popular Q&A site for programming, Stack Overflow is a treasure for\ndevelopers. However, the amount of questions and answers on Stack Overflow make\nit difficult for developers to efficiently locate the information they are\nlooking for. There are two gaps leading to poor search results: the gap between\nthe user's intention and the textual query, and the semantic gap between the\nquery and the post content. Therefore, developers have to constantly\nreformulate their queries by correcting misspelled words, adding limitations to\ncertain programming languages or platforms, etc. As query reformulation is\ntedious for developers, especially for novices, we propose an automated\nsoftware-specific query reformulation approach based on deep learning. With\nquery logs provided by Stack Overflow, we construct a large-scale query\nreformulation corpus, including the original queries and corresponding\nreformulated ones. Our approach trains a Transformer model that can\nautomatically generate candidate reformulated queries when given the user's\noriginal query. The evaluation results show that our approach outperforms five\nstate-of-the-art baselines, and achieves a 5.6% to 33.5% boost in terms of\n$\\mathit{ExactMatch}$ and a 4.8% to 14.4% boost in terms of $\\mathit{GLEU}$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:31:50 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 11:34:08 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cao", "Kaibo", ""], ["Chen", "Chunyang", ""], ["Baltes", "Sebastian", ""], ["Treude", "Christoph", ""], ["Chen", "Xiang", ""]]}, {"id": "2102.00831", "submitter": "Hobin Ryu", "authors": "Hobin Ryu, Sunghun Kang, Haeyong Kang, and Chang D. Yoo", "title": "Semantic Grouping Network for Video Captioning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers a video caption generating network referred to as\nSemantic Grouping Network (SGN) that attempts (1) to group video frames with\ndiscriminating word phrases of partially decoded caption and then (2) to decode\nthose semantically aligned groups in predicting the next word. As consecutive\nframes are not likely to provide unique information, prior methods have focused\non discarding or merging repetitive information based only on the input video.\nThe SGN learns an algorithm to capture the most discriminating word phrases of\nthe partially decoded caption and a mapping that associates each phrase to the\nrelevant video frames - establishing this mapping allows semantically related\nframes to be clustered, which reduces redundancy. In contrast to the prior\nmethods, the continuous feedback from decoded words enables the SGN to\ndynamically update the video representation that adapts to the partially\ndecoded caption. Furthermore, a contrastive attention loss is proposed to\nfacilitate accurate alignment between a word phrase and video frames without\nmanual annotations. The SGN achieves state-of-the-art performances by\noutperforming runner-up methods by a margin of 2.1%p and 2.4%p in a CIDEr-D\nscore on MSVD and MSR-VTT datasets, respectively. Extensive experiments\ndemonstrate the effectiveness and interpretability of the SGN.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 13:40:56 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 11:53:17 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ryu", "Hobin", ""], ["Kang", "Sunghun", ""], ["Kang", "Haeyong", ""], ["Yoo", "Chang D.", ""]]}, {"id": "2102.00834", "submitter": "Koen Holtman", "authors": "Koen Holtman", "title": "Counterfactual Planning in AGI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present counterfactual planning as a design approach for creating a range\nof safety mechanisms that can be applied in hypothetical future AI systems\nwhich have Artificial General Intelligence.\n  The key step in counterfactual planning is to use an AGI machine learning\nsystem to construct a counterfactual world model, designed to be different from\nthe real world the system is in. A counterfactual planning agent determines the\naction that best maximizes expected utility in this counterfactual planning\nworld, and then performs the same action in the real world.\n  We use counterfactual planning to construct an AGI agent emergency stop\nbutton, and a safety interlock that will automatically stop the agent before it\nundergoes an intelligence explosion. We also construct an agent with an input\nterminal that can be used by humans to iteratively improve the agent's reward\nfunction, where the incentive for the agent to manipulate this improvement\nprocess is suppressed. As an example of counterfactual planning in a non-agent\nAGI system, we construct a counterfactual oracle.\n  As a design approach, counterfactual planning is built around the use of a\ngraphical notation for defining mathematical counterfactuals. This two-diagram\nnotation also provides a compact and readable language for reasoning about the\ncomplex types of self-referencing and indirect representation which are\ntypically present inside machine learning agents.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 13:44:14 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Holtman", "Koen", ""]]}, {"id": "2102.00835", "submitter": "Keping Yu", "authors": "Zhiwei Guo, Keping Yu, Tan Guo, Ali Kashif Bashir, Muhammad Imran,\n  Mohsen Guizani", "title": "Implicit Feedback-based Group Recommender System for Internet of Thing\n  Applications", "comments": "I don't want to share this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the prevalence of Internet of Things (IoT)-based social media\napplications, the distance among people has been greatly shortened. As a\nresult, recommender systems in IoT-based social media need to be developed\noriented to groups of users rather than individual users. However, existing\nmethods were highly dependent on explicit preference feedbacks, ignoring\nscenarios of implicit feedback. To remedy such gap, this paper proposes an\nimplicit feedback-based group recommender system using probabilistic inference\nand non-cooperative game(GREPING) for IoT-based social media. Particularly,\nunknown process variables can be estimated from observable implicit feedbacks\nvia Bayesian posterior probability inference. In addition, the globally optimal\nrecommendation results can be calculated with the aid of non-cooperative game.\nTwo groups of experiments are conducted to assess the GREPING from two aspects:\nefficiency and robustness. Experimental results show obvious promotion and\nconsiderable stability of the GREPING compared to baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 12:33:33 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 16:39:05 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Guo", "Zhiwei", ""], ["Yu", "Keping", ""], ["Guo", "Tan", ""], ["Bashir", "Ali Kashif", ""], ["Imran", "Muhammad", ""], ["Guizani", "Mohsen", ""]]}, {"id": "2102.00847", "submitter": "Carter Blum", "authors": "Carter Blum, Hao Liu, Hui Xiong", "title": "CoordiQ : Coordinated Q-learning for Electric Vehicle Charging\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electric vehicles have been rapidly increasing in usage, but stations to\ncharge them have not always kept up with demand, so efficient routing of\nvehicles to stations is critical to operating at maximum efficiency. Deciding\nwhich stations to recommend drivers to is a complex problem with a multitude of\npossible recommendations, volatile usage patterns and temporally extended\nconsequences of recommendations. Reinforcement learning offers a powerful\nparadigm for solving sequential decision-making problems, but traditional\nmethods may struggle with sample efficiency due to the high number of possible\nactions. By developing a model that allows complex representations of actions,\nwe improve outcomes for users of our system by over 30% when compared to\nexisting baselines in a simulation. If implemented widely, these better\nrecommendations can globally save over 4 million person-hours of waiting and\ndriving each year.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 21:25:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Blum", "Carter", ""], ["Liu", "Hao", ""], ["Xiong", "Hui", ""]]}, {"id": "2102.00898", "submitter": "Mohit Sewak", "authors": "Mohit Sewak and Sanjay K. Sahay and Hemant Rathore", "title": "DRLDO: A novel DRL based De-ObfuscationSystem for Defense against\n  Metamorphic Malware", "comments": null, "journal-ref": "Defence Science Journal, 71(1), 55-65", "doi": "10.14429/dsj.71.15780", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel mechanism to normalize metamorphic and\nobfuscated malware down at the opcode level and hence create an advanced\nmetamorphic malware de-obfuscation and defense system. We name this system\nDRLDO, for Deep Reinforcement Learning based De-Obfuscator. With the inclusion\nof the DRLDO as a sub-component, an existing Intrusion Detection System could\nbe augmented with defensive capabilities against 'zero-day' attacks from\nobfuscated and metamorphic variants of existing malware. This gains importance,\nnot only because there exists no system to date that uses advanced DRL to\nintelligently and automatically normalize obfuscation down even to the opcode\nlevel, but also because the DRLDO system does not mandate any changes to the\nexisting IDS. The DRLDO system does not even mandate the IDS' classifier to be\nretrained with any new dataset containing obfuscated samples. Hence DRLDO could\nbe easily retrofitted into any existing IDS deployment. We designed, developed,\nand conducted experiments on the system to evaluate the same against\nmultiple-simultaneous attacks from obfuscations generated from malware samples\nfrom a standardized dataset that contains multiple generations of malware.\nExperimental results prove that DRLDO was able to successfully make the\notherwise un-detectable obfuscated variants of the malware detectable by an\nexisting pre-trained malware classifier. The detection probability was raised\nwell above the cut-off mark to 0.6 for the classifier to detect the obfuscated\nmalware unambiguously. Further, the de-obfuscated variants generated by DRLDO\nachieved a very high correlation (of 0.99) with the base malware. This\nobservation validates that the DRLDO system is actually learning to\nde-obfuscate and not exploiting a trivial trick.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:16:18 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sewak", "Mohit", ""], ["Sahay", "Sanjay K.", ""], ["Rathore", "Hemant", ""]]}, {"id": "2102.00924", "submitter": "Yida Xin", "authors": "Yida Xin, Henry Lieberman and Peter Chin", "title": "Revisiting the Prepositional-Phrase Attachment Problem Using Explicit\n  Commonsense Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the challenging problem of resolving prepositional-phrase (PP)\nattachment ambiguity. To date, proposed solutions are either rule-based, where\nexplicit grammar rules direct how to resolve ambiguities; or statistical, where\nthe decision is learned from a corpus of labeled examples. We argue that\nexplicit commonsense knowledge bases can provide an essential ingredient for\nmaking good attachment decisions. We implemented a module, named Patch-Comm,\nthat can be used by a variety of conventional parsers, to make attachment\ndecisions. Where the commonsense KB does not provide direct answers, we fall\nback on a more general system that infers \"out-of-knowledge-base\" assertions in\na manner similar to the way some NLP systems handle out-of-vocabulary words.\nOur results suggest that the commonsense knowledge-based approach can provide\nthe best of both worlds, integrating rule-based and statistical techniques. As\nthe field is increasingly coming to recognize the importance of explainability\nin AI, a commonsense approach can enable NLP developers to better understand\nthe behavior of systems, and facilitate natural dialogues with end users.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:48:36 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 17:51:30 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Xin", "Yida", ""], ["Lieberman", "Henry", ""], ["Chin", "Peter", ""]]}, {"id": "2102.00932", "submitter": "Bernhard Klein", "authors": "Bernhard Klein and Christoph Gratl and Manfred M\\\"ucke and Holger\n  Fr\\\"oning", "title": "Understanding Cache Boundness of ML Operators on ARM Processors", "comments": "published at the HiPEAC 2021 Conference, at the 3rd Workshop on\n  Accelerated Machine Learning (AccML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning compilers like TVM allow a fast and flexible deployment on\nembedded CPUs. This enables the use of non-standard operators, which are common\nin ML compression techniques. However, it is necessary to understand the\nlimitations of typical compute-intense operators in ML workloads to design a\nproper solution. This is the first in-detail analysis of dense and convolution\noperators, generated with TVM, that compares to the fundamental hardware limits\nof embedded ARM processors. Thereby it explains the gap between computational\npeak performance, theoretical and measured, and real-world state-of-the-art\nresults, created with TVM and openBLAS. Instead, one can see that\nsingle-precision general matrix multiply (GEMM) and convolutions are bound by\nL1-cache-read bandwidth. Explorations of 8-bit and bit-serial quantized\noperators show that quantization can be used to achieve relevant speedups\ncompared to cache-bound floating-point operators. However, the performance of\nquantized operators highly depends on the interaction between data layout and\nbit packing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:05:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Klein", "Bernhard", ""], ["Gratl", "Christoph", ""], ["M\u00fccke", "Manfred", ""], ["Fr\u00f6ning", "Holger", ""]]}, {"id": "2102.00951", "submitter": "Oana-Iuliana Popescu", "authors": "Oana-Iuliana Popescu, Maha Shadaydeh, Joachim Denzler", "title": "Counterfactual Generation with Knockoffs", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human interpretability of deep neural networks' decisions is crucial,\nespecially in domains where these directly affect human lives. Counterfactual\nexplanations of already trained neural networks can be generated by perturbing\ninput features and attributing importance according to the change in the\nclassifier's outcome after perturbation. Perturbation can be done by replacing\nfeatures using heuristic or generative in-filling methods. The choice of\nin-filling function significantly impacts the number of artifacts, i.e.,\nfalse-positive attributions. Heuristic methods result in false-positive\nartifacts because the image after the perturbation is far from the original\ndata distribution. Generative in-filling methods reduce artifacts by producing\nin-filling values that respect the original data distribution. However, current\ngenerative in-filling methods may also increase false-negatives due to the high\ncorrelation of in-filling values with the original data. In this paper, we\npropose to alleviate this by generating in-fillings with the\nstatistically-grounded Knockoffs framework, which was developed by Barber and\nCand\\`es in 2015 as a tool for variable selection with controllable false\ndiscovery rate. Knockoffs are statistically null-variables as decorrelated as\npossible from the original data, which can be swapped with the originals\nwithout changing the underlying data distribution. A comparison of different\nin-filling methods indicates that in-filling with knockoffs can reveal\nexplanations in a more causal sense while still maintaining the compactness of\nthe explanations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:34:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Popescu", "Oana-Iuliana", ""], ["Shadaydeh", "Maha", ""], ["Denzler", "Joachim", ""]]}, {"id": "2102.00966", "submitter": "Conor F. Hayes", "authors": "Conor F. Hayes, Mathieu Reymond, Diederik M. Roijers, Enda Howley,\n  Patrick Mannion", "title": "Risk Aware and Multi-Objective Decision Making with Distributional Monte\n  Carlo Tree Search", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from the single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. When making a decision, just the expected return -- known\nin reinforcement learning as the value -- cannot account for the potential\nrange of adverse or positive outcomes a decision may have. Our key insight is\nthat we should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time. In\nthis paper, we propose Distributional Monte Carlo Tree Search, an algorithm\nthat learns a posterior distribution over the utility of the different possible\nreturns attainable from individual policy executions, resulting in good\npolicies for both risk-aware and multi-objective settings. Moreover, our\nalgorithm outperforms the state-of-the-art in multi-objective reinforcement\nlearning for the expected utility of the returns.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:47:39 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 14:06:18 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hayes", "Conor F.", ""], ["Reymond", "Mathieu", ""], ["Roijers", "Diederik M.", ""], ["Howley", "Enda", ""], ["Mannion", "Patrick", ""]]}, {"id": "2102.00997", "submitter": "Gorka Azkune", "authors": "Aitzol Elu, Gorka Azkune, Oier Lopez de Lacalle, Ignacio\n  Arganda-Carreras, Aitor Soroa, Eneko Agirre", "title": "Inferring spatial relations from textual descriptions of images", "comments": "Accepted in Pattern Recognition", "journal-ref": "Pattern Recognition, Volume 113, 2021, 107847", "doi": "10.1016/j.patcog.2021.107847", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an image from its textual description requires both a certain\nlevel of language understanding and common sense knowledge about the spatial\nrelations of the physical entities being described. In this work, we focus on\ninferring the spatial relation between entities, a key step in the process of\ncomposing scenes based on text. More specifically, given a caption containing a\nmention to a subject and the location and size of the bounding box of that\nsubject, our goal is to predict the location and size of an object mentioned in\nthe caption. Previous work did not use the caption text information, but a\nmanually provided relation holding between the subject and the object. In fact,\nthe used evaluation datasets contain manually annotated ontological triplets\nbut no captions, making the exercise unrealistic: a manual step was required;\nand systems did not leverage the richer information in captions. Here we\npresent a system that uses the full caption, and Relations in Captions\n(REC-COCO), a dataset derived from MS-COCO which allows to evaluate spatial\nrelation inference from captions directly. Our experiments show that: (1) it is\npossible to infer the size and location of an object with respect to a given\nsubject directly from the caption; (2) the use of full text allows to place the\nobject better than using a manually annotated relation. Our work paves the way\nfor systems that, given a caption, decide which entities need to be depicted\nand their respective location and sizes, in order to then generate the final\nimage.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 17:21:13 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Elu", "Aitzol", ""], ["Azkune", "Gorka", ""], ["de Lacalle", "Oier Lopez", ""], ["Arganda-Carreras", "Ignacio", ""], ["Soroa", "Aitor", ""], ["Agirre", "Eneko", ""]]}, {"id": "2102.01004", "submitter": "Ruben Glatt", "authors": "William A. Dawson, Ruben Glatt, Edward Rusu, Braden C. Soper, Ryan A.\n  Goldhahn", "title": "Hybrid Information-driven Multi-agent Reinforcement Learning", "comments": "Published at Workshop on Challenges and Opportunities for Multi-Agent\n  Reinforcement Learning (COMARL AAAI 2021). This work was performed under the\n  auspices of the U.S. Department of Energy by Lawrence Livermore National\n  Laboratory under contract DE-AC52-07NA27344. Lawrence Livermore National\n  Security, LLC through the support of LDRD 20-SI-005. LLNL-CONF-816423", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Information theoretic sensor management approaches are an ideal solution to\nstate estimation problems when considering the optimal control of multi-agent\nsystems, however they are too computationally intensive for large state spaces,\nespecially when considering the limited computational resources typical of\nlarge-scale distributed multi-agent systems. Reinforcement learning (RL) is a\npromising alternative which can find approximate solutions to distributed\noptimal control problems that take into account the resource constraints\ninherent in many systems of distributed agents. However, the RL training can be\nprohibitively inefficient, especially in low-information environments where\nagents receive little to no feedback in large portions of the state space. We\npropose a hybrid information-driven multi-agent reinforcement learning (MARL)\napproach that utilizes information theoretic models as heuristics to help the\nagents navigate large sparse state spaces, coupled with information based\nrewards in an RL framework to learn higher-level policies. This paper presents\nour ongoing work towards this objective. Our preliminary findings show that\nsuch an approach can result in a system of agents that are approximately three\norders of magnitude more efficient at exploring a sparse state space than naive\nbaseline metrics. While the work is still in its early stages, it provides a\npromising direction for future research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 17:28:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dawson", "William A.", ""], ["Glatt", "Ruben", ""], ["Rusu", "Edward", ""], ["Soper", "Braden C.", ""], ["Goldhahn", "Ryan A.", ""]]}, {"id": "2102.01006", "submitter": "Anjali Balagopal", "authors": "Anjali Balagopal, Dan Nguyen, Maryam Mashayekhi, Howard Morgan,\n  Aurelie Garant, Neil Desai, Raquibul Hannan, Mu-Han Lin, Steve Jiang", "title": "Dosimetric impact of physician style variations in contouring CTV for\n  post-operative prostate cancer: A deep learning-based simulation study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-observer variation is a significant problem in clinical target\nvolume(CTV) segmentation in postoperative settings, where there is no gross\ntumor present. In this scenario, the CTV is not an anatomically established\nstructure, but one determined by the physician based on the clinical guideline\nused, the preferred tradeoff between tumor control and toxicity, their\nexperience and training background, and other factors. This results in high\ninter-observer variability between physicians. This variability has been\nconsidered an issue, but the absence of multiple physician CTV contours for\neach patient and the significant amount of time required for dose planning have\nmade it impractical to study its dosimetric consequences. In this study, we\nanalyze the impact that variations in physician style have on dose to\norgans-at-risk(OAR) by simulating the clinical workflow via deep learning. For\na given patient previously treated by one physician, we use deep learning-based\ntools to simulate how other physicians would contour the CTV and how the\ncorresponding dose distributions would look for this patient. To simulate\nmultiple physician styles, we use a previously developed in-house CTV\nsegmentation model that can produce physician style-aware segmentations. The\ncorresponding dose distribution is predicted using another in-house deep\nlearning tool, which, can predict dose within 3% of the prescription dose, on\naverage, on the test data. For every test patient, four different physician\nstyle CTVs are considered, and four different dose distributions are analyzed.\nOAR dose metrics are compared, showing that even though physician style\nvariations result in organs getting different doses, all the important dose\nmetrics except Maximum Dose point are within the clinically acceptable limit.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 17:34:37 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:09:37 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 16:19:20 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Balagopal", "Anjali", ""], ["Nguyen", "Dan", ""], ["Mashayekhi", "Maryam", ""], ["Morgan", "Howard", ""], ["Garant", "Aurelie", ""], ["Desai", "Neil", ""], ["Hannan", "Raquibul", ""], ["Lin", "Mu-Han", ""], ["Jiang", "Steve", ""]]}, {"id": "2102.01011", "submitter": "Yifeng Li", "authors": "Yifeng Li, Hsu Kiang Ooi, Alain Tchagang", "title": "Deep Evolutionary Learning for Molecular Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep evolutionary learning (DEL) process that\nintegrates fragment-based deep generative model and multi-objective\nevolutionary computation for molecular design. Our approach enables (1)\nevolutionary operations in the latent space of the generative model, rather\nthan the structural space, to generate novel promising molecular structures for\nthe next evolutionary generation, and (2) generative model fine-tuning using\nnewly generated high-quality samples. Thus, DEL implements a data-model\nco-evolution concept which improves both sample population and generative model\nlearning. Experiments on two public datasets indicate that sample population\nobtained by DEL exhibits improved property distributions, and dominates samples\ngenerated by multi-objective Bayesian optimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 03:15:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Yifeng", ""], ["Ooi", "Hsu Kiang", ""], ["Tchagang", "Alain", ""]]}, {"id": "2102.01012", "submitter": "Stefanos Tsimenidis", "authors": "Stefanos Tsimenidis", "title": "Evolutionary Algorithms for Fuzzy Cognitive Maps", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fuzzy Cognitive Maps (FCMs) is a complex systems modeling technique which,\ndue to its unique advantages, has lately risen in popularity. They are based on\ngraphs that represent the causal relationships among the parameters of the\nsystem to be modeled, and they stand out for their interpretability and\nflexibility. With the late popularity of FCMs, a plethora of research efforts\nhave taken place to develop and optimize the model. One of the most important\nelements of FCMs is the learning algorithm they use, and their effectiveness is\nlargely determined by it. The learning algorithms learn the node weights of an\nFCM, with the goal of converging towards the desired behavior. The present\nstudy reviews the genetic algorithms used for training FCMs, as well as gives a\ngeneral overview of the FCM learning algorithms, putting evolutionary computing\ninto the wider context.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 15:17:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tsimenidis", "Stefanos", ""]]}, {"id": "2102.01026", "submitter": "Guillermo Carbajal", "authors": "Guillermo Carbajal, Patricia Vitoria, Mauricio Delbracio, Pablo\n  Mus\\'e, Jos\\'e Lezama", "title": "Non-uniform Blur Kernel Estimation via Adaptive Basis Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion blur estimation remains an important task for scene analysis and image\nrestoration. In recent years, the removal of motion blur in photographs has\nseen impressive progress in the hands of deep learning-based methods, trained\nto map directly from blurry to sharp images. Characterization of the motion\nblur, on the other hand, has received less attention, and progress in\nmodel-based methods for deblurring lags behind that of data-driven end-to-end\napproaches. In this work we revisit the problem of characterizing dense,\nnon-uniform motion blur in a single image and propose a general non-parametric\nmodel for this task. Given a blurry image, a neural network is trained to\nestimate a set of image-adaptive basis motion kernels as well as the mixing\ncoefficients at the pixel level, producing a per-pixel motion blur field. We\nshow that our approach overcomes the limitations of existing non-uniform motion\nblur estimation methods and leads to extremely accurate motion blur kernels.\nWhen applied to real motion-blurred images, a variational non-uniform blur\nremoval method fed with the estimated blur kernels produces high-quality\nrestored images. Qualitative and quantitative evaluation shows that these\nresults are competitive or superior to results obtained with existing\nend-to-end deep learning (DL) based methods, thus bridging the gap between\nmodel-based and data-driven approaches.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 18:02:31 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 19:29:05 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Carbajal", "Guillermo", ""], ["Vitoria", "Patricia", ""], ["Delbracio", "Mauricio", ""], ["Mus\u00e9", "Pablo", ""], ["Lezama", "Jos\u00e9", ""]]}, {"id": "2102.01072", "submitter": "Scott Freitas", "authors": "Scott Freitas, Rahul Duggal, Duen Horng Chau", "title": "MalNet: A Large-Scale Cybersecurity Image Database of Malicious Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is playing an increasingly important role in automated\nmalware detection with to the rise of the image-based binary representation.\nThese binary images are fast to generate, require no feature engineering, and\nare resilient to popular obfuscation methods. Significant research has been\nconducted in this area, however, it has been restricted to small-scale or\nprivate datasets that only a few industry labs and research teams have access\nto. This lack of availability hinders examination of existing work, development\nof new research, and dissemination of ideas. We introduce MalNet, the largest\npublicly available cybersecurity image database, offering 133x more images and\n27x more classes than the only other public binary-image database. MalNet\ncontains over 1.2 million images across a hierarchy of 47 types and 696\nfamilies. We provide extensive analysis of MalNet, discussing its properties\nand provenance. The scale and diversity of MalNet unlocks new and exciting\ncybersecurity opportunities to the computer vision community--enabling\ndiscoveries and research directions that were previously not possible. The\ndatabase is publicly available at www.mal-net.org.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 02:59:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Freitas", "Scott", ""], ["Duggal", "Rahul", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2102.01116", "submitter": "Michael Chary", "authors": "Michael Chary, Ed W Boyer, Michele M Burns", "title": "Diagnosis of Acute Poisoning Using Explainable Artificial Intelligence", "comments": "Parts submitted to HICSS 54", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical toxicology is the clinical specialty that treats the toxic effects of\nsubstances, be it an overdose, a medication error, or a scorpion sting. The\nvolume of toxicological knowledge and research has, as with other medical\nspecialties, outstripped the ability of the individual clinician to entirely\nmaster and stay current with it. The application of machine learning techniques\nto medical toxicology is challenging because initial treatment decisions are\noften based on a few pieces of textual data and rely heavily on prior\nknowledge. ML techniques often do not represent knowledge in a way that is\ntransparent for the physician, raising barriers to usability. Rule-based\nsystems and decision tree learning are more transparent approaches, but often\ngeneralize poorly and require expert curation to implement and maintain. Here,\nwe construct a probabilistic logic network to represent a portion of the\nknowledge base of a medical toxicologist. Our approach transparently mimics the\nknowledge representation and clinical decision-making of practicing clinicians.\nThe software, dubbed Tak, performs comparably to humans on straightforward\ncases and intermediate difficulty cases, but is outperformed by humans on\nchallenging clinical cases. Tak outperforms a decision tree classifier at all\nlevels of difficulty. Probabilistic logic provides one form of explainable\nartificial intelligence that may be more acceptable for use in healthcare, if\nit can achieve acceptable levels of performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 19:16:59 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chary", "Michael", ""], ["Boyer", "Ed W", ""], ["Burns", "Michele M", ""]]}, {"id": "2102.01149", "submitter": "Devorah Kletenik", "authors": "Lisa Hellerstein, Devorah Kletenik and Srinivasan Parthasarathy", "title": "A Tight Bound for Stochastic Submodular Cover", "comments": "This work extends the result of Srinivasan Parthasarathy in his paper\n  arXiv:1803.07639 from the problem of Stochastic Set Cover to that of\n  Stochastic Submodular Cover", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the Adaptive Greedy algorithm of Golovin and Krause (2011)\nachieves an approximation bound of $(\\ln (Q/\\eta)+1)$ for Stochastic Submodular\nCover: here $Q$ is the \"goal value\" and $\\eta$ is the smallest non-zero\nmarginal increase in utility deliverable by an item. (For integer-valued\nutility functions, we show a bound of $H(Q)$, where $H(Q)$ is the $Q^{th}$\nHarmonic number.) Although this bound was claimed by Golovin and Krause in the\noriginal version of their paper, the proof was later shown to be incorrect by\nNan and Saligrama (2017). The subsequent corrected proof of Golovin and Krause\n(2017) gives a quadratic bound of $(\\ln(Q/\\eta) + 1)^2$. Other previous bounds\nfor the problem are $56(\\ln(Q/\\eta) + 1)$, implied by work of Im et al. (2016)\non a related problem, and $k(\\ln (Q/\\eta)+1)$, due to Deshpande et al. (2016)\nand Hellerstein and Kletenik (2018), where $k$ is the number of states. Our\nbound generalizes the well-known $(\\ln~m + 1)$ approximation bound on the\ngreedy algorithm for the classical Set Cover problem, where $m$ is the size of\nthe ground set.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 20:37:40 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hellerstein", "Lisa", ""], ["Kletenik", "Devorah", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "2102.01168", "submitter": "Xin Chen", "authors": "Xin Chen, Guannan Qu, Yujie Tang, Steven Low, Na Li", "title": "Reinforcement Learning for Decision-Making and Control in Power Systems:\n  Tutorial, Review, and Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With large-scale integration of renewable generation and distributed energy\nresources (DERs), modern power systems are confronted with new operational\nchallenges, such as growing complexity, increasing uncertainty, and aggravating\nvolatility. Meanwhile, more and more data are becoming available owing to the\nwidespread deployment of smart meters, smart sensors, and upgraded\ncommunication networks. As a result, data-driven control techniques, especially\nreinforcement learning (RL), have attracted surging attention in recent years.\nIn this paper, we provide a tutorial on various RL techniques and how they can\nbe applied to decision-making in power systems. We illustrate RL-based models\nand solutions in three key applications, frequency regulation, voltage control,\nand energy management. We conclude with three critical issues in the\napplication of RL, i.e., safety, scalability, and data. Several potential\nfuture directions are discussed as well.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2021 03:45:44 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 02:03:56 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 16:44:41 GMT"}, {"version": "v4", "created": "Wed, 28 Jul 2021 02:51:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Xin", ""], ["Qu", "Guannan", ""], ["Tang", "Yujie", ""], ["Low", "Steven", ""], ["Li", "Na", ""]]}, {"id": "2102.01173", "submitter": "Tony Zhao", "authors": "Tony Zhao, Irving Fang, Jeffrey Kim, Gerald Friedland", "title": "Multi-modal Ensemble Models for Predicting Video Memorability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling media memorability has been a consistent challenge in the field of\nmachine learning. The Predicting Media Memorability task in MediaEval2020 is\nthe latest benchmark among similar challenges addressing this topic. Building\nupon techniques developed in previous iterations of the challenge, we developed\nensemble methods with the use of extracted video, image, text, and audio\nfeatures. Critically, in this work we introduce and demonstrate the efficacy\nand high generalizability of extracted audio embeddings as a feature for the\ntask of predicting media memorability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:16:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhao", "Tony", ""], ["Fang", "Irving", ""], ["Kim", "Jeffrey", ""], ["Friedland", "Gerald", ""]]}, {"id": "2102.01189", "submitter": "Youzhi Luo", "authors": "Youzhi Luo, Keqiang Yan, Shuiwang Ji", "title": "GraphDF: A Discrete Flow Model for Molecular Graph Generation", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of molecular graph generation using deep models.\nWhile graphs are discrete, most existing methods use continuous latent\nvariables, resulting in inaccurate modeling of discrete graph structures. In\nthis work, we propose GraphDF, a novel discrete latent variable model for\nmolecular graph generation based on normalizing flow methods. GraphDF uses\ninvertible modulo shift transforms to map discrete latent variables to graph\nnodes and edges. We show that the use of discrete latent variables reduces\ncomputational costs and eliminates the negative effect of dequantization.\nComprehensive experimental results show that GraphDF outperforms prior methods\non random generation, property optimization, and constrained optimization\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:39:41 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 16:15:03 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Luo", "Youzhi", ""], ["Yan", "Keqiang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2102.01190", "submitter": "Weihua Li", "authors": "Xing Su, Yan Kong, Weihua Li", "title": "The 4th International Workshop on Smart Simulation and Modelling for\n  Complex Systems", "comments": "IJCAI2019 workshop", "journal-ref": null, "doi": null, "report-no": "SSMCS2019", "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-based modelling and simulation have become useful tools to\nfacilitate humans to understand systems in different domains, such as physics,\nastrophysics, chemistry, biology, economics, engineering and social science. A\ncomplex system is featured with a large number of interacting components\n(agents, processes, etc.), whose aggregate activities are nonlinear and\nself-organized. Complex systems are hard to be simulated or modelled by using\ntraditional computational approaches due to complex relationships among system\ncomponents, distributed features of resources, and dynamics of environments.\nMeanwhile, smart systems such as multi-agent systems have demonstrated\nadvantages and great potentials in modelling and simulating complex systems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:40:28 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Su", "Xing", ""], ["Kong", "Yan", ""], ["Li", "Weihua", ""]]}, {"id": "2102.01203", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper, Ellen Abrams", "title": "Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research", "comments": "To appear in AIES 2021", "journal-ref": null, "doi": "10.1145/3461702.3462519", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Across machine learning (ML) sub-disciplines, researchers make explicit\nmathematical assumptions in order to facilitate proof-writing. We note that,\nspecifically in the area of fairness-accuracy trade-off optimization\nscholarship, similar attention is not paid to the normative assumptions that\nground this approach. Such assumptions presume that 1) accuracy and fairness\nare in inherent opposition to one another, 2) strict notions of mathematical\nequality can adequately model fairness, 3) it is possible to measure the\naccuracy and fairness of decisions independent from historical context, and 4)\ncollecting more data on marginalized individuals is a reasonable solution to\nmitigate the effects of the trade-off. We argue that such assumptions, which\nare often left implicit and unexamined, lead to inconsistent conclusions: While\nthe intended goal of this work may be to improve the fairness of machine\nlearning models, these unexamined, implicit assumptions can in fact result in\nemergent unfairness. We conclude by suggesting a concrete path forward toward a\npotential resolution.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 22:02:14 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 22:33:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Cooper", "A. Feder", ""], ["Abrams", "Ellen", ""]]}, {"id": "2102.01222", "submitter": "Kaushik Roy", "authors": "Kaushik Roy, Usha Lokala, Vedant Khandelwal, and Amit Sheth", "title": "\"Is depression related to cannabis?\": A knowledge-infused model for\n  Entity and Relation Extraction with Limited Supervision", "comments": "Accepted to AAAI-2021 Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With strong marketing advocacy of the benefits of cannabis use for improved\nmental health, cannabis legalization is a priority among legislators. However,\npreliminary scientific research does not conclusively associate cannabis with\nimproved mental health. In this study, we explore the relationship between\ndepression and consumption of cannabis in a targeted social media corpus\ninvolving personal use of cannabis with the intent to derive its potential\nmental health benefit. We use tweets that contain an association among three\ncategories annotated by domain experts - Reason, Effect, and Addiction. The\nstate-of-the-art Natural Langauge Processing techniques fall short in\nextracting these relationships between cannabis phrases and the depression\nindicators. We seek to address the limitation by using domain knowledge;\nspecifically, the Drug Abuse Ontology for addiction augmented with Diagnostic\nand Statistical Manual of Mental Disorders lexicons for mental health. Because\nof the lack of annotations due to the limited availability of the domain\nexperts' time, we use supervised contrastive learning in conjunction with GPT-3\ntrained on a vast corpus to achieve improved performance even with limited\nsupervision. Experimental results show that our method can significantly\nextract cannabis-depression relationships better than the state-of-the-art\nrelation extractor. High-quality annotations can be provided using a nearest\nneighbor approach using the learned representations that can be used by the\nscientific community to understand the association between cannabis and\ndepression better.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 23:02:43 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Roy", "Kaushik", ""], ["Lokala", "Usha", ""], ["Khandelwal", "Vedant", ""], ["Sheth", "Amit", ""]]}, {"id": "2102.01264", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Nina Chen, Elisa Zhao Hang, Elena L. Glassman,\n  Finale Doshi-Velez", "title": "Evaluating the Interpretability of Generative Models by Interactive\n  Reconstruction", "comments": "CHI 2021 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For machine learning models to be most useful in numerous sociotechnical\nsystems, many have argued that they must be human-interpretable. However,\ndespite increasing interest in interpretability, there remains no firm\nconsensus on how to measure it. This is especially true in representation\nlearning, where interpretability research has focused on \"disentanglement\"\nmeasures only applicable to synthetic datasets and not grounded in human\nfactors. We introduce a task to quantify the human-interpretability of\ngenerative model representations, where users interactively modify\nrepresentations to reconstruct target instances. On synthetic datasets, we find\nperformance on this task much more reliably differentiates entangled and\ndisentangled models than baseline approaches. On a real dataset, we find it\ndifferentiates between representation learning methods widely believed but\nnever shown to produce more or less interpretable models. In both cases, we ran\nsmall-scale think-aloud studies and large-scale experiments on Amazon\nMechanical Turk to confirm that our qualitative and quantitative results\nagreed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 02:38:14 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Chen", "Nina", ""], ["Hang", "Elisa Zhao", ""], ["Glassman", "Elena L.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2102.01287", "submitter": "Fateme Nikseresht", "authors": "Fateme Nikseresht, Runze Yan, Rachel Lew, Yingzheng Liu, Rose\n  M.Sebastian, Afsaneh Doryab", "title": "Detection of Racial Bias from Physiological Responses", "comments": "8 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the evolution of norms and regulations to mitigate the harm from\nbiases, harmful discrimination linked to an individual's unconscious biases\npersists. Our goal is to better understand and detect the physiological and\nbehavioral indicators of implicit biases. This paper investigates whether we\ncan reliably detect racial bias from physiological responses, including heart\nrate, conductive skin response, skin temperature, and micro-body movements. We\nanalyzed data from 46 subjects whose physiological data was collected with\nEmpatica E4 wristband while taking an Implicit Association Test (IAT). Our\nmachine learning and statistical analysis show that implicit bias can be\npredicted from physiological signals with 76.1% accuracy. Our results also show\nthat the EDA signal associated with skin response has the strongest correlation\nwith racial bias and that there are significant differences between the values\nof EDA features for biased and unbiased participants.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 03:52:51 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Nikseresht", "Fateme", ""], ["Yan", "Runze", ""], ["Lew", "Rachel", ""], ["Liu", "Yingzheng", ""], ["Sebastian", "Rose M.", ""], ["Doryab", "Afsaneh", ""]]}, {"id": "2102.01295", "submitter": "Heecheol Kim", "authors": "Heecheol Kim, Yoshiyuki Ohmura, and Yasuo Kuniyoshi", "title": "Gaze-based dual resolution deep imitation learning for high-precision\n  dexterous robot manipulation", "comments": "8 pages. The supplementary video can be found at:\n  https://www.youtube.com/watch?v=ytpChcFqD5g Published in IEEE Robotics and\n  Automation Letters. Replaced to add video url in the manuscript", "journal-ref": "IEEE Robotics and Automation Letters, Vol. 6, No. 2, 2021", "doi": "10.1109/LRA.2021.3059619", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A high-precision manipulation task, such as needle threading, is challenging.\nPhysiological studies have proposed connecting low-resolution peripheral vision\nand fast movement to transport the hand into the vicinity of an object, and\nusing high-resolution foveated vision to achieve the accurate homing of the\nhand to the object. The results of this study demonstrate that a deep imitation\nlearning based method, inspired by the gaze-based dual resolution visuomotor\ncontrol system in humans, can solve the needle threading task. First, we\nrecorded the gaze movements of a human operator who was teleoperating a robot.\nThen, we used only a high-resolution image around the gaze to precisely control\nthe thread position when it was close to the target. We used a low-resolution\nperipheral image to reach the vicinity of the target. The experimental results\nobtained in this study demonstrate that the proposed method enables precise\nmanipulation tasks using a general-purpose robot manipulator and improves\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 04:11:09 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:50:20 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Kim", "Heecheol", ""], ["Ohmura", "Yoshiyuki", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "2102.01331", "submitter": "Longyuan Li", "authors": "Longyuan Li, Junchi Yan, Haiyang Wang, and Yaohui Jin", "title": "Anomaly Detection of Time Series with Smoothness-Inducing Sequential\n  Variational Auto-Encoder", "comments": "Accepted by IEEE Transactions on Neural Network and Learning System\n  (TNNLS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep generative models have demonstrated their effectiveness in learning\nlatent representation and modeling complex dependencies of time series. In this\npaper, we present a Smoothness-Inducing Sequential Variational Auto-Encoder\n(SISVAE) model for robust estimation and anomaly detection of multi-dimensional\ntime series. Our model is based on Variational Auto-Encoder (VAE), and its\nbackbone is fulfilled by a Recurrent Neural Network to capture latent temporal\nstructures of time series for both generative model and inference model.\nSpecifically, our model parameterizes mean and variance for each time-stamp\nwith flexible neural networks, resulting in a non-stationary model that can\nwork without the assumption of constant noise as commonly made by existing\nMarkov models. However, such a flexibility may cause the model fragile to\nanomalies. To achieve robust density estimation which can also benefit\ndetection tasks, we propose a smoothness-inducing prior over possible\nestimations. The proposed prior works as a regularizer that places penalty at\nnon-smooth reconstructions. Our model is learned efficiently with a novel\nstochastic gradient variational Bayes estimator. In particular, we study two\ndecision criteria for anomaly detection: reconstruction probability and\nreconstruction error. We show the effectiveness of our model on both synthetic\ndatasets and public real-world benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:15:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Li", "Longyuan", ""], ["Yan", "Junchi", ""], ["Wang", "Haiyang", ""], ["Jin", "Yaohui", ""]]}, {"id": "2102.01335", "submitter": "Kenton Lee", "authors": "Kenton Lee, Kelvin Guu, Luheng He, Tim Dozat, Hyung Won Chung", "title": "Neural Data Augmentation via Example Extrapolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of machine learning, certain categories of examples may\nbe underrepresented in the training data, causing systems to underperform on\nsuch \"few-shot\" cases at test time. A common remedy is to perform data\naugmentation, such as by duplicating underrepresented examples, or\nheuristically synthesizing new examples. But these remedies often fail to cover\nthe full diversity and complexity of real examples.\n  We propose a data augmentation approach that performs neural Example\nExtrapolation (Ex2). Given a handful of exemplars sampled from some\ndistribution, Ex2 synthesizes new examples that also belong to the same\ndistribution. The Ex2 model is learned by simulating the example generation\nprocedure on data-rich slices of the data, and it is applied to\nunderrepresented, few-shot slices.\n  We apply Ex2 to a range of language understanding tasks and significantly\nimprove over state-of-the-art methods on multiple few-shot learning benchmarks,\nincluding for relation extraction (FewRel) and intent classification + slot\nfilling (SNIPS).\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:20:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lee", "Kenton", ""], ["Guu", "Kelvin", ""], ["He", "Luheng", ""], ["Dozat", "Tim", ""], ["Chung", "Hyung Won", ""]]}, {"id": "2102.01336", "submitter": "Gagandeep Singh", "authors": "Gagandeep Singh, Deepak Mishra", "title": "Probabilistic Trust Intervals for Out of Distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Building neural network classifiers with an ability to distinguish between in\nand out-of distribution inputs is an important step towards faithful deep\nlearning systems. Some of the successful approaches for this, resort to\narchitectural novelties, such as ensembles, with increased complexities in\nterms of the number of parameters and training procedures. Whereas some other\napproaches make use of surrogate samples, which are easy to create and work as\nproxies for actual out-of-distribution (OOD) samples, to train the networks for\nOOD detection. In this paper, we propose a very simple approach for enhancing\nthe ability of a pretrained network to detect OOD inputs without even altering\nthe original parameter values. We define a probabilistic trust interval for\neach weight parameter of the network and optimize its size according to the\nin-distribution (ID) inputs. It allows the network to sample additional weight\nvalues along with the original values at the time of inference and use the\nobserved disagreement among the corresponding outputs for OOD detection. In\norder to capture the disagreement effectively, we also propose a measure and\nestablish its suitability using empirical evidence. Our approach outperforms\nthe existing state-of-the-art methods on various OOD datasets by considerable\nmargins without using any real or surrogate OOD samples. We also analyze the\nperformance of our approach on adversarial and corrupted inputs such as\nCIFAR-10-C and demonstrate its ability to clearly distinguish such inputs as\nwell. By using fundamental theorem of calculus on neural networks, we explain\nwhy our technique doesn't need to observe OOD samples during training to\nachieve results better than the previous works.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:23:04 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 08:32:32 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Gagandeep", ""], ["Mishra", "Deepak", ""]]}, {"id": "2102.01341", "submitter": "Quentin Ducasse", "authors": "Quentin Ducasse, Pascal Cotret, Lo\\\"ic Lagadec, Robert Stewart", "title": "Benchmarking Quantized Neural Networks on FPGAs with FINN", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/03", "categories": "cs.LG cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing cost of both training and inference for state-of-the-art\nneural networks has brought literature to look upon ways to cut off resources\nused with a minimal impact on accuracy. Using lower precision comes at the cost\nof negligible loss in accuracy. While training neural networks may require a\npowerful setup, deploying a network must be possible on low-power and\nlow-resource hardware architectures. Reconfigurable architectures have proven\nto be more powerful and flexible than GPUs when looking at a specific\napplication. This article aims to assess the impact of mixed-precision when\napplied to neural networks deployed on FPGAs. While several frameworks exist\nthat create tools to deploy neural networks using reduced-precision, few of\nthem assess the importance of quantization and the framework quality. FINN and\nBrevitas, two frameworks from Xilinx labs, are used to assess the impact of\nquantization on neural networks using 2 to 8 bit precisions and weights with\nseveral parallelization configurations. Equivalent accuracy can be obtained\nusing lower-precision representation and enough training. However, the\ncompressed network can be better parallelized allowing the deployed network\nthroughput to be 62 times faster. The benchmark set up in this work is\navailable in a public repository (https://github.com/QDucasse/nn benchmark).\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:42:07 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Ducasse", "Quentin", ""], ["Cotret", "Pascal", ""], ["Lagadec", "Lo\u00efc", ""], ["Stewart", "Robert", ""]]}, {"id": "2102.01345", "submitter": "Etienne Dupuis", "authors": "Etienne Dupuis, David Novo, Ian O'Connor, Alberto Bosio", "title": "Fast Exploration of Weight Sharing Opportunities for CNN Compression", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/05", "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational workload involved in Convolutional Neural Networks (CNNs)\nis typically out of reach for low-power embedded devices. There are a large\nnumber of approximation techniques to address this problem. These methods have\nhyper-parameters that need to be optimized for each CNNs using design space\nexploration (DSE). The goal of this work is to demonstrate that the DSE phase\ntime can easily explode for state of the art CNN. We thus propose the use of an\noptimized exploration process to drastically reduce the exploration time\nwithout sacrificing the quality of the output.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:45:56 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Dupuis", "Etienne", ""], ["Novo", "David", ""], ["O'Connor", "Ian", ""], ["Bosio", "Alberto", ""]]}, {"id": "2102.01348", "submitter": "Dainius Jenkus", "authors": "Dainius Jenkus, Fei Xia, Rishad Shafik, Alex Yakovlev", "title": "QoS-Aware Power Minimization of Distributed Many-Core Servers using\n  Transfer Q-Learning", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/07", "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web servers scaled across distributed systems necessitate complex runtime\ncontrols for providing quality of service (QoS) guarantees as well as\nminimizing the energy costs under dynamic workloads. This paper presents a\nQoS-aware runtime controller using horizontal scaling (node allocation) and\nvertical scaling (resource allocation within nodes) methods synergistically to\nprovide adaptation to workloads while minimizing the power consumption under\nQoS constraint (i.e., response time). A horizontal scaling determines the\nnumber of active nodes based on workload demands and the required QoS according\nto a set of rules. Then, it is coupled with vertical scaling using transfer\nQ-learning, which further tunes power/performance based on workload profile\nusing dynamic voltage/frequency scaling (DVFS). It transfers Q-values within\nminimally explored states reducing exploration requirements. In addition, the\napproach exploits a scalable architecture of the many-core server allowing to\nreuse available knowledge from fully or partially explored nodes. When\ncombined, these methods allow to reduce the exploration time and QoS violations\nwhen compared to model-free Q-learning. The technique balances design-time and\nruntime costs to maximize the portability and operational optimality\ndemonstrated through persistent power reductions with minimal QoS violations\nunder different workload scenarios on heterogeneous multi-processing nodes of a\nserver cluster.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:47:58 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Jenkus", "Dainius", ""], ["Xia", "Fei", ""], ["Shafik", "Rishad", ""], ["Yakovlev", "Alex", ""]]}, {"id": "2102.01349", "submitter": "Cristina Chesta", "authors": "Cristina Chesta, Luca Rinelli", "title": "Modular approach to data preprocessing in ALOHA and application to a\n  smart industry use case", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/08", "categories": "cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications in the smart industry domain, such as interaction with\ncollaborative robots using vocal commands or machine vision systems often\nrequires the deployment of deep learning algorithms on heterogeneous low power\ncomputing platforms. The availability of software tools and frameworks to\nautomatize different design steps can support the effective implementation of\nDL algorithms on embedded systems, reducing related effort and costs. One very\nimportant aspect for the acceptance of the framework, is its extensibility,\ni.e. the capability to accommodate different datasets and define customized\npreprocessing, without requiring advanced skills. The paper addresses a modular\napproach, integrated into the ALOHA tool flow, to support the data\npreprocessing and transformation pipeline. This is realized through\ncustomizable plugins and allows the easy extension of the tool flow to\nencompass new use cases. To demonstrate the effectiveness of the approach, we\npresent some experimental results related to a keyword spotting use case and we\noutline possible extensions to different use cases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:48:51 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chesta", "Cristina", ""], ["Rinelli", "Luca", ""]]}, {"id": "2102.01350", "submitter": "Chen Cai", "authors": "Chen Cai, Dingkang Wang, Yusu Wang", "title": "Graph Coarsening with Neural Networks", "comments": "International Conference on Learning Representations 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As large-scale graphs become increasingly more prevalent, it poses\nsignificant computational challenges to process, extract and analyze large\ngraph data. Graph coarsening is one popular technique to reduce the size of a\ngraph while maintaining essential properties. Despite rich graph coarsening\nliterature, there is only limited exploration of data-driven methods in the\nfield. In this work, we leverage the recent progress of deep learning on graphs\nfor graph coarsening. We first propose a framework for measuring the quality of\ncoarsening algorithm and show that depending on the goal, we need to carefully\nchoose the Laplace operator on the coarse graph and associated projection/lift\noperators. Motivated by the observation that the current choice of edge weight\nfor the coarse graph may be sub-optimal, we parametrize the weight assignment\nmap with graph neural networks and train it to improve the coarsening quality\nin an unsupervised way. Through extensive experiments on both synthetic and\nreal networks, we demonstrate that our method significantly improves common\ngraph coarsening methods under various metrics, reduction ratios, graph sizes,\nand graph types. It generalizes to graphs of larger size ($25\\times$ of\ntraining graphs), is adaptive to different losses (differentiable and\nnon-differentiable), and scales to much larger graphs than previous work.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:50:07 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Cai", "Chen", ""], ["Wang", "Dingkang", ""], ["Wang", "Yusu", ""]]}, {"id": "2102.01353", "submitter": "Zhongqiang Ren", "authors": "Zhongqiang Ren, Sivakumar Rathinam and Howie Choset", "title": "Subdimensional Expansion for Multi-objective Multi-agent Path Finding", "comments": "8 pages, RA-L and IROS 2021", "journal-ref": null, "doi": "10.1109/LRA.2021.3096744", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional multi-agent path planners typically determine a path that\noptimizes a single objective, such as path length. Many applications, however,\nmay require multiple objectives, say time-to-completion and fuel use, to be\nsimultaneously optimized in the planning process. Often, these criteria may not\nbe readily compared and sometimes lie in competition with each other. Simply\napplying standard multi-objective search algorithms to multi-agent path finding\nmay prove to be inefficient because the size of the space of possible\nsolutions, i.e., the Pareto-optimal set, can grow exponentially with the number\nof agents (the dimension of the search space). This paper presents an approach\nthat bypasses this so-called curse of dimensionality by leveraging our prior\nmulti-agent work with a framework called subdimensional expansion. One example\nof subdimensional expansion, when applied to A*, is called M* and M* was\nlimited to a single objective function. We combine principles of dominance and\nsubdimensional expansion to create a new algorithm named multi-objective M*\n(MOM*), which dynamically couples agents for planning only when those agents\nhave to \"interact\" with each other. MOM* computes the complete Pareto-optimal\nset for multiple agents efficiently and naturally trades off sub-optimal\napproximations of the Pareto-optimal set and computational efficiency. Our\napproach is able to find the complete Pareto-optimal set for problem instances\nwith hundreds of solutions which the standard multi-objective A* algorithms\ncould not find within a bounded time.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:58:28 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 01:04:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ren", "Zhongqiang", ""], ["Rathinam", "Sivakumar", ""], ["Choset", "Howie", ""]]}, {"id": "2102.01355", "submitter": "Andrew Lensen", "authors": "Andrew Lensen", "title": "Mining Feature Relationships in Data", "comments": "16 pages, accepted in EuroGP '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When faced with a new dataset, most practitioners begin by performing\nexploratory data analysis to discover interesting patterns and characteristics\nwithin data. Techniques such as association rule mining are commonly applied to\nuncover relationships between features (attributes) of the data. However,\nassociation rules are primarily designed for use on binary or categorical data,\ndue to their use of rule-based machine learning. A large proportion of\nreal-world data is continuous in nature, and discretisation of such data leads\nto inaccurate and less informative association rules. In this paper, we propose\nan alternative approach called feature relationship mining (FRM), which uses a\ngenetic programming approach to automatically discover symbolic relationships\nbetween continuous or categorical features in data. To the best of our\nknowledge, our proposed approach is the first such symbolic approach with the\ngoal of explicitly discovering relationships between features. Empirical\ntesting on a variety of real-world datasets shows the proposed method is able\nto find high-quality, simple feature relationships which can be easily\ninterpreted and which provide clear and non-trivial insight into data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 07:06:16 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lensen", "Andrew", ""]]}, {"id": "2102.01356", "submitter": "Tao Bai", "authors": "Tao Bai, Jinqi Luo, Jun Zhao, Bihan Wen, Qian Wang", "title": "Recent Advances in Adversarial Training for Adversarial Robustness", "comments": "accepted by International Joint Conference on Artificial Intelligence\n  (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is one of the most effective approaches defending\nagainst adversarial examples for deep learning models. Unlike other defense\nstrategies, adversarial training aims to promote the robustness of models\nintrinsically. During the last few years, adversarial training has been studied\nand discussed from various aspects. A variety of improvements and developments\nof adversarial training are proposed, which were, however, neglected in\nexisting surveys. For the first time in this survey, we systematically review\nthe recent progress on adversarial training for adversarial robustness with a\nnovel taxonomy. Then we discuss the generalization problems in adversarial\ntraining from three perspectives. Finally, we highlight the challenges which\nare not fully tackled and present potential future directions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 07:10:22 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 07:13:24 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 06:56:07 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 09:49:42 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 01:57:53 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Bai", "Tao", ""], ["Luo", "Jinqi", ""], ["Zhao", "Jun", ""], ["Wen", "Bihan", ""], ["Wang", "Qian", ""]]}, {"id": "2102.01380", "submitter": "Zhong Meng", "authors": "Zhong Meng, Naoyuki Kanda, Yashesh Gaur, Sarangarajan Parthasarathy,\n  Eric Sun, Liang Lu, Xie Chen, Jinyu Li, Yifan Gong", "title": "Internal Language Model Training for Domain-Adaptive End-to-End Speech\n  Recognition", "comments": "5 pages, ICASSP 2021", "journal-ref": "2021 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Toronto, Canada", "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The efficacy of external language model (LM) integration with existing\nend-to-end (E2E) automatic speech recognition (ASR) systems can be improved\nsignificantly using the internal language model estimation (ILME) method. In\nthis method, the internal LM score is subtracted from the score obtained by\ninterpolating the E2E score with the external LM score, during inference. To\nimprove the ILME-based inference, we propose an internal LM training (ILMT)\nmethod to minimize an additional internal LM loss by updating only the E2E\nmodel components that affect the internal LM estimation. ILMT encourages the\nE2E model to form a standalone LM inside its existing components, without\nsacrificing ASR accuracy. After ILMT, the more modular E2E model with matched\ntraining and inference criteria enables a more thorough elimination of the\nsource-domain internal LM, and therefore leads to a more effective integration\nof the target-domain external LM. Experimented with 30K-hour trained recurrent\nneural network transducer and attention-based encoder-decoder models, ILMT with\nILME-based inference achieves up to 31.5% and 11.4% relative word error rate\nreductions from standard E2E training with Shallow Fusion on out-of-domain\nLibriSpeech and in-domain Microsoft production test sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 08:15:02 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 19:16:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Meng", "Zhong", ""], ["Kanda", "Naoyuki", ""], ["Gaur", "Yashesh", ""], ["Parthasarathy", "Sarangarajan", ""], ["Sun", "Eric", ""], ["Lu", "Liang", ""], ["Chen", "Xie", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2102.01381", "submitter": "Dong-Keon Kim", "authors": "Dong-Keon Kim, DongHee Kim, and Kwangsu Kim", "title": "Facial Manipulation Detection Based on the Color Distribution Analysis\n  in Edge Region", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a generalized and robust facial manipulation\ndetection method based on color distribution analysis of the vertical region of\nedge in a manipulated image. Most of the contemporary facial manipulation\nmethod involves pixel correction procedures for reducing awkwardness of pixel\nvalue differences along the facial boundary in a synthesized image. For this\nprocedure, there are distinctive differences in the facial boundary between\nface manipulated image and unforged natural image. Also, in the forged image,\nthere should be distinctive and unnatural features in the gap distribution\nbetween facial boundary and background edge region because it tends to damage\nthe natural effect of lighting. We design the neural network for detecting\nface-manipulated image with these distinctive features in facial boundary and\nbackground edge. Our extensive experiments show that our method outperforms\nother existing face manipulation detection methods on detecting synthesized\nface image in various datasets regardless of whether it has participated in\ntraining.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 08:19:35 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Kim", "Dong-Keon", ""], ["Kim", "DongHee", ""], ["Kim", "Kwangsu", ""]]}, {"id": "2102.01399", "submitter": "Alessandra Toniato Mrs", "authors": "Alessandra Toniato, Philippe Schwaller, Antonio Cardinale, Joppe\n  Geluykens and Teodoro Laino", "title": "Unassisted Noise Reduction of Chemical Reaction Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Existing deep learning models applied to reaction prediction in organic\nchemistry can reach high levels of accuracy (> 90% for Natural Language\nProcessing-based ones). With no chemical knowledge embedded than the\ninformation learnt from reaction data, the quality of the data sets plays a\ncrucial role in the performance of the prediction models. While human curation\nis prohibitively expensive, the need for unaided approaches to remove\nchemically incorrect entries from existing data sets is essential to improve\nartificial intelligence models' performance in synthetic chemistry tasks. Here\nwe propose a machine learning-based, unassisted approach to remove chemically\nwrong entries from chemical reaction collections. We applied this method to the\ncollection of chemical reactions Pistachio and to an open data set, both\nextracted from USPTO (United States Patent Office) patents. Our results show an\nimproved prediction quality for models trained on the cleaned and balanced data\nsets. For the retrosynthetic models, the round-trip accuracy metric grows by 13\npercentage points and the value of the cumulative Jensen Shannon divergence\ndecreases by 30% compared to its original record. The coverage remains high\nwith 97%, and the value of the class-diversity is not affected by the cleaning.\nThe proposed strategy is the first unassisted rule-free technique to address\nautomatic noise reduction in chemical data sets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 09:34:34 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Toniato", "Alessandra", ""], ["Schwaller", "Philippe", ""], ["Cardinale", "Antonio", ""], ["Geluykens", "Joppe", ""], ["Laino", "Teodoro", ""]]}, {"id": "2102.01424", "submitter": "Vladim\\'ir Hol\\'y", "authors": "Ond\\v{r}ej Sokol and Vladim\\'ir Hol\\'y", "title": "Clustering with Penalty for Joint Occurrence of Objects: Computational\n  Aspects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of Hol\\'y, Sokol and \\v{C}ern\\'y (Applied Soft Computing, 2017,\nVol. 60, p. 752-762) clusters objects based on their incidence in a large\nnumber of given sets. The idea is to minimize the occurrence of multiple\nobjects from the same cluster in the same set. In the current paper, we study\ncomputational aspects of the method. First, we prove that the problem of\nfinding the optimal clustering is NP-hard. Second, to numerically find a\nsuitable clustering, we propose to use the genetic algorithm augmented by a\nrenumbering procedure, a fast task-specific local search heuristic and an\ninitial solution based on a simplified model. Third, in a simulation study, we\ndemonstrate that our improvements of the standard genetic algorithm\nsignificantly enhance its computational performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 10:39:27 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Sokol", "Ond\u0159ej", ""], ["Hol\u00fd", "Vladim\u00edr", ""]]}, {"id": "2102.01428", "submitter": "Xue Liu", "authors": "Xue Liu, Wei Wei, Xiangnan Feng, Xiaobo Cao, Dan Sun", "title": "Graph Classification Based on Skeleton and Component Features", "comments": "25 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most existing popular methods for learning graph embedding only consider\nfixed-order global structural features and lack structures hierarchical\nrepresentation. To address this weakness, we propose a novel graph embedding\nalgorithm named GraphCSC that realizes classification based on skeleton\ninformation using fixed-order structures learned in anonymous random walks\nmanner, and component information using different size subgraphs. Two graphs\nare similar if their skeletons and components are both similar, thus in our\nmodel, we integrate both of them together into embeddings as graph homogeneity\ncharacterization. We demonstrate our model on different datasets in comparison\nwith a comprehensive list of up-to-date state-of-the-art baselines, and\nexperiments show that our work is superior in real-world graph classification\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 10:52:17 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Liu", "Xue", ""], ["Wei", "Wei", ""], ["Feng", "Xiangnan", ""], ["Cao", "Xiaobo", ""], ["Sun", "Dan", ""]]}, {"id": "2102.01431", "submitter": "Florian Wirthm\\\"uller", "authors": "Florian Wirthm\\\"uller, Marvin Klimke, Julian Schlechtriemen, Jochen\n  Hipp and Manfred Reichert", "title": "Predicting the Time Until a Vehicle Changes the Lane Using LSTM-based\n  Recurrent Neural Networks", "comments": "the article has been accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L); the article has been submitted to RA-L with IEEE\n  ICRA conference option; if the article will be presented during the\n  conference will be decided independently; 8 pages, 5 figures, 6 tables", "journal-ref": null, "doi": "10.1109/LRA.2021.3058930", "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To plan safe and comfortable trajectories for automated vehicles on highways,\naccurate predictions of traffic situations are needed. So far, a lot of\nresearch effort has been spent on detecting lane change maneuvers rather than\non estimating the point in time a lane change actually happens. In practice,\nhowever, this temporal information might be even more useful. This paper deals\nwith the development of a system that accurately predicts the time to the next\nlane change of surrounding vehicles on highways using long short-term\nmemory-based recurrent neural networks. An extensive evaluation based on a\nlarge real-world data set shows that our approach is able to make reliable\npredictions, even in the most challenging situations, with a root mean squared\nerror around 0.7 seconds. Already 3.5 seconds prior to lane changes the\npredictions become highly accurate, showing a median error of less than 0.25\nseconds. In summary, this article forms a fundamental step towards downstreamed\nhighly accurate position predictions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:04:22 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 09:07:53 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Wirthm\u00fcller", "Florian", ""], ["Klimke", "Marvin", ""], ["Schlechtriemen", "Julian", ""], ["Hipp", "Jochen", ""], ["Reichert", "Manfred", ""]]}, {"id": "2102.01434", "submitter": "Borja Gonzalez Leon", "authors": "Pierre El Mqirmi, Francesco Belardinelli and Borja G. Le\\'on", "title": "An Abstraction-based Method to Check Multi-Agent Deep\n  Reinforcement-Learning Behaviors", "comments": "Extended version of AAMAS publication under the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (RL) often struggles to ensure the safe\nbehaviours of the learning agents, and therefore it is generally not adapted to\nsafety-critical applications. To address this issue, we present a methodology\nthat combines formal verification with (deep) RL algorithms to guarantee the\nsatisfaction of formally-specified safety constraints both in training and\ntesting. The approach we propose expresses the constraints to verify in\nProbabilistic Computation Tree Logic (PCTL) and builds an abstract\nrepresentation of the system to reduce the complexity of the verification step.\nThis abstract model allows for model checking techniques to identify a set of\nabstract policies that meet the safety constraints expressed in PCTL. Then, the\nagents' behaviours are restricted according to these safe abstract policies. We\nprovide formal guarantees that by using this method, the actions of the agents\nalways meet the safety constraints, and provide a procedure to generate an\nabstract model automatically. We empirically evaluate and show the\neffectiveness of our method in a multi-agent environment.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:12:30 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 00:52:59 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Mqirmi", "Pierre El", ""], ["Belardinelli", "Francesco", ""], ["Le\u00f3n", "Borja G.", ""]]}, {"id": "2102.01498", "submitter": "Iuliana Marin", "authors": "Andrei Vasilateanu, Nicolae Goga, Elena-Alice Tanase, Iuliana Marin", "title": "Enterprise domain ontology learning from web-based corpus", "comments": null, "journal-ref": "2015 6th International Conference on Computing, Communication and\n  Networking Technologies (ICCCNT)", "doi": "10.1109/ICCCNT.2015.7395227", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprise knowledge is a key asset in the competing and fast-changing\ncorporate landscape. The ability to learn, store and distribute implicit and\nexplicit knowledge can be the difference between success and failure. While\nenterprise knowledge management is a well-defined research domain, current\nimplementations lack orientation towards small and medium enterprise. We\npropose a semantic search engine for relevant documents in an enterprise, based\non automatic generated domain ontologies. In this paper we focus on the\ncomponent for ontology learning and population.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 17:08:29 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vasilateanu", "Andrei", ""], ["Goga", "Nicolae", ""], ["Tanase", "Elena-Alice", ""], ["Marin", "Iuliana", ""]]}, {"id": "2102.01502", "submitter": "Satyapriya Krishna", "authors": "Satyapriya Krishna, Rahul Gupta, Christophe Dupuy", "title": "ADePT: Auto-encoder based Differentially Private Text Transformation", "comments": null, "journal-ref": "The 16th conference of the European Chapter of the Association for\n  Computational Linguistics (EACL), 2021", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy is an important concern when building statistical models on data\ncontaining personal information. Differential privacy offers a strong\ndefinition of privacy and can be used to solve several privacy concerns (Dwork\net al., 2014). Multiple solutions have been proposed for the\ndifferentially-private transformation of datasets containing sensitive\ninformation. However, such transformation algorithms offer poor utility in\nNatural Language Processing (NLP) tasks due to noise added in the process. In\nthis paper, we address this issue by providing a utility-preserving\ndifferentially private text transformation algorithm using auto-encoders. Our\nalgorithm transforms text to offer robustness against attacks and produces\ntransformations with high semantic quality that perform well on downstream NLP\ntasks. We prove the theoretical privacy guarantee of our algorithm and assess\nits privacy leakage under Membership Inference Attacks(MIA) (Shokri et al.,\n2017) on models trained with transformed data. Our results show that the\nproposed model performs better against MIA attacks while offering lower to no\ndegradation in the utility of the underlying transformation process compared to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 23:15:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Krishna", "Satyapriya", ""], ["Gupta", "Rahul", ""], ["Dupuy", "Christophe", ""]]}, {"id": "2102.01503", "submitter": "Mohammed Elkomy Alaa", "authors": "Mohammed ElKomy", "title": "A Survey On (Stochastic Fractal Search) Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evolutionary Algorithms are naturally inspired approximation optimisation\nalgorithms that usually interfere with science problems when common\nmathematical methods are unable to provide a good solution or finding the exact\nsolution requires an unreasonable amount of time using traditional exhaustive\nsearch algorithms. The success of these population-based frameworks is mainly\ndue to their flexibility and ease of adaptation to the most different and\ncomplex optimisation problems. This paper presents a metaheuristic algorithm\ncalled Stochastic Fractal Search, inspired by the natural phenomenon of growth\nbased on a mathematical concept called the fractal, which is shown to be able\nto explore the search space more efficiently. This paper also focuses on the\nalgorithm steps and some example applications of engineering design\noptimisation problems commonly used in the literature being applied to the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:44:04 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["ElKomy", "Mohammed", ""]]}, {"id": "2102.01511", "submitter": "Yakup Kutlu", "authors": "Emre Demir, Ahmet Gokcen, Yakup Kutlu", "title": "Android Controlled Mobile Robot Design with IP Camera", "comments": "5 pages, in Turkish language, 6 figures, journal of intelligent\n  systems with applications, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study Arduino card based mobile robot design was realized. This robot\ncan serve as a security robot, an auxiliary robot or a control robot. The\ndesigned robot has two operation modes. The first operating mode is autonomous\nmode. In this mode, the robot detects the surroundings with the help of\nultrasonic sensors placed around it, and keeps track of the places it passes by\nusing the encoder. It is able to navigate without hitting any place and passing\nfrom where it passes, and it transmits the patient's pulse and temperature\ncondition to the user by other systems installed on it. Also the IP camera\nsends the scene on the screen. The emergency button to be placed next to the\npatient sends information to the user in emergency situations. If the\nabnormality is detected in the temperature and pulse again, the user gives a\nmessage. When the pre-recorded drug use times come, the system can alert the\npatient. The second mode is manual mode. In this mode, the user can move the\ndesired direction of the robot with the Android operating system. In addition,\nall data received in autonomous mode can be sent to the user. Thus, the user\ncan control the mobile robot with the camera image even if it is not in the\nvicinity of the robot.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 19:16:18 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Demir", "Emre", ""], ["Gokcen", "Ahmet", ""], ["Kutlu", "Yakup", ""]]}, {"id": "2102.01514", "submitter": "Charline Le Lan", "authors": "Charline Le Lan, Marc G. Bellemare, Pablo Samuel Castro", "title": "Metrics and continuity in reinforcement learning", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most practical applications of reinforcement learning, it is untenable to\nmaintain direct estimates for individual states; in continuous-state systems,\nit is impossible. Instead, researchers often leverage state similarity (whether\nexplicitly or implicitly) to build models that can generalize well from a\nlimited set of samples. The notion of state similarity used, and the\nneighbourhoods and topologies they induce, is thus of crucial importance, as it\nwill directly affect the performance of the algorithms. Indeed, a number of\nrecent works introduce algorithms assuming the existence of \"well-behaved\"\nneighbourhoods, but leave the full specification of such topologies for future\nwork. In this paper we introduce a unified formalism for defining these\ntopologies through the lens of metrics. We establish a hierarchy amongst these\nmetrics and demonstrate their theoretical implications on the Markov Decision\nProcess specifying the reinforcement learning problem. We complement our\ntheoretical results with empirical evaluations showcasing the differences\nbetween the metrics considered.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 14:30:41 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lan", "Charline Le", ""], ["Bellemare", "Marc G.", ""], ["Castro", "Pablo Samuel", ""]]}, {"id": "2102.01538", "submitter": "Yuanpeng He", "authors": "Yuanpeng He", "title": "A new distance measure of Pythagorean fuzzy sets based on matrix and and\n  its application in medical diagnosis", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pythagorean fuzzy set (PFS) which is developed based on intuitionistic\nfuzzy set, is more efficient in elaborating and disposing uncertainties in\nindeterminate situations, which is a very reason of that PFS is applied in\nvarious kinds of fields. How to measure the distance between two pythagorean\nfuzzy sets is still an open issue. Mnay kinds of methods have been proposed to\npresent the of the question in former reaserches. However, not all of existing\nmethods can accurately manifest differences among pythagorean fuzzy sets and\nsatisfy the property of similarity. And some other kinds of methods neglect the\nrelationship among three variables of pythagorean fuzzy set. To addrees the\nproplem, a new method of measuring distance is proposed which meets the\nrequirements of axiom of distance measurement and is able to indicate the\ndegree of distinction of PFSs well. Then some numerical examples are offered to\nto verify that the method of measuring distances can avoid the situation that\nsome counter? intuitive and irrational results are produced and is more\neffective, reasonable and advanced than other similar methods. Besides, the\nproposed method of measuring distances between PFSs is applied in a real\nenvironment of application which is the medical diagnosis and is compared with\nother previous methods to demonstrate its superiority and efficiency. And the\nfeasibility of the proposed method in handling uncertainties in practice is\nalso proved at the same time.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 15:59:09 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["He", "Yuanpeng", ""]]}, {"id": "2102.01563", "submitter": "Zhuang Li", "authors": "Shuo Huang, Zhuang Li, Lizhen Qu, Lei Pan", "title": "On Robustness of Neural Semantic Parsers", "comments": "Long Paper, Accepted to EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic parsing maps natural language (NL) utterances into logical forms\n(LFs), which underpins many advanced NLP problems. Semantic parsers gain\nperformance boosts with deep neural networks, but inherit vulnerabilities\nagainst adversarial examples. In this paper, we provide the empirical study on\nthe robustness of semantic parsers in the presence of adversarial attacks.\nFormally, adversaries of semantic parsing are considered to be the perturbed\nutterance-LF pairs, whose utterances have exactly the same meanings as the\noriginal ones. A scalable methodology is proposed to construct robustness test\nsets based on existing benchmark corpora. Our results answered five research\nquestions in measuring the sate-of-the-art parsers' performance on robustness\ntest sets, and evaluating the effect of data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:41:28 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 12:19:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Huang", "Shuo", ""], ["Li", "Zhuang", ""], ["Qu", "Lizhen", ""], ["Pan", "Lei", ""]]}, {"id": "2102.01564", "submitter": "Colin Paterson", "authors": "Richard Hawkins, Colin Paterson, Chiara Picardi, Yan Jia, Radu\n  Calinescu and Ibrahim Habli", "title": "Guidance on the Assurance of Machine Learning in Autonomous Systems\n  (AMLAS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is now used in a range of systems with results that are\nreported to exceed, under certain conditions, human performance. Many of these\nsystems, in domains such as healthcare , automotive and manufacturing, exhibit\nhigh degrees of autonomy and are safety critical. Establishing justified\nconfidence in ML forms a core part of the safety case for these systems. In\nthis document we introduce a methodology for the Assurance of Machine Learning\nfor use in Autonomous Systems (AMLAS). AMLAS comprises a set of safety case\npatterns and a process for (1) systematically integrating safety assurance into\nthe development of ML components and (2) for generating the evidence base for\nexplicitly justifying the acceptable safety of these components when integrated\ninto autonomous system applications.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:41:57 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hawkins", "Richard", ""], ["Paterson", "Colin", ""], ["Picardi", "Chiara", ""], ["Jia", "Yan", ""], ["Calinescu", "Radu", ""], ["Habli", "Ibrahim", ""]]}, {"id": "2102.01565", "submitter": "Juan Pedro Dominguez-Morales", "authors": "Luis J. Mu\\~noz-Molina, Ignacio Cazorla-Pi\\~nar, Juan P.\n  Dominguez-Morales, Fernando Perez-Pe\\~na", "title": "Real-time detection of uncalibrated sensors using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, sensors play a major role in several contexts like science,\nindustry and daily life which benefit of their use. However, the retrieved\ninformation must be reliable. Anomalies in the behavior of sensors can give\nrise to critical consequences such as ruining a scientific project or\njeopardizing the quality of the production in industrial production lines. One\nof the more subtle kind of anomalies are uncalibrations. An uncalibration is\nsaid to take place when the sensor is not adjusted or standardized by\ncalibration according to a ground truth value. In this work, an online\nmachine-learning based uncalibration detector for temperature, humidity and\npressure sensors was developed. This solution integrates an Artificial Neural\nNetwork as main component which learns from the behavior of the sensors under\ncalibrated conditions. Then, after trained and deployed, it detects\nuncalibrations once they take place. The obtained results show that the\nproposed solution is able to detect uncalibrations for deviation values of 0.25\ndegrees, 1% RH and 1.5 Pa, respectively. This solution can be adapted to\ndifferent contexts by means of transfer learning, whose application allows for\nthe addition of new sensors, the deployment into new environments and the\nretraining of the model with minimum amounts of data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 15:44:39 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mu\u00f1oz-Molina", "Luis J.", ""], ["Cazorla-Pi\u00f1ar", "Ignacio", ""], ["Dominguez-Morales", "Juan P.", ""], ["Perez-Pe\u00f1a", "Fernando", ""]]}, {"id": "2102.01579", "submitter": "Xiangyu Xu", "authors": "Xiangyu Xu, Yongrui Ma, Wenxiu Sun, Ming-Hsuan Yang", "title": "Exploiting Raw Images for Real-Scene Super-Resolution", "comments": "A larger version with higher-resolution figures is available at:\n  https://sites.google.com/view/xiangyuxu. arXiv admin note: text overlap with\n  arXiv:1905.12156", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Super-resolution is a fundamental problem in computer vision which aims to\novercome the spatial limitation of camera sensors. While significant progress\nhas been made in single image super-resolution, most algorithms only perform\nwell on synthetic data, which limits their applications in real scenarios. In\nthis paper, we study the problem of real-scene single image super-resolution to\nbridge the gap between synthetic data and real captured images. We focus on two\nissues of existing super-resolution algorithms: lack of realistic training data\nand insufficient utilization of visual information obtained from cameras. To\naddress the first issue, we propose a method to generate more realistic\ntraining data by mimicking the imaging process of digital cameras. For the\nsecond issue, we develop a two-branch convolutional neural network to exploit\nthe radiance information originally-recorded in raw images. In addition, we\npropose a dense channel-attention block for better image restoration as well as\na learning-based guided filter network for effective color correction. Our\nmodel is able to generalize to different cameras without deliberately training\non images from specific camera types. Extensive experiments demonstrate that\nthe proposed algorithm can recover fine details and clear structures, and\nachieve high-quality results for single image super-resolution in real scenes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 16:10:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Xu", "Xiangyu", ""], ["Ma", "Yongrui", ""], ["Sun", "Wenxiu", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2102.01582", "submitter": "Mats Richter", "authors": "Mats L. Richter, Wolf Byttner, Ulf Krumnack, Ludwdig Schallner, Justin\n  Shenk", "title": "Size Matters", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fully convolutional neural networks can process input of arbitrary size by\napplying a combination of downsampling and pooling. However, we find that fully\nconvolutional image classifiers are not agnostic to the input size but rather\nshow significant differences in performance: presenting the same image at\ndifferent scales can result in different outcomes. A closer look reveals that\nthere is no simple relationship between input size and model performance (no\n`bigger is better'), but that each each network has a preferred input size, for\nwhich it shows best results. We investigate this phenomenon by applying\ndifferent methods, including spectral analysis of layer activations and probe\nclassifiers, showing that there are characteristic features depending on the\nnetwork architecture. From this we find that the size of discriminatory\nfeatures is critically influencing how the inference process is distributed\namong the layers.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 16:17:52 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 09:00:14 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Richter", "Mats L.", ""], ["Byttner", "Wolf", ""], ["Krumnack", "Ulf", ""], ["Schallner", "Ludwdig", ""], ["Shenk", "Justin", ""]]}, {"id": "2102.01585", "submitter": "Kai Cui", "authors": "Kai Cui, Heinz Koeppl", "title": "Approximately Solving Mean Field Games via Entropy-Regularized Deep\n  Reinforcement Learning", "comments": "Accepted to the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent mean field game (MFG) formalism facilitates otherwise intractable\ncomputation of approximate Nash equilibria in many-agent settings. In this\npaper, we consider discrete-time finite MFGs subject to finite-horizon\nobjectives. We show that all discrete-time finite MFGs with non-constant fixed\npoint operators fail to be contractive as typically assumed in existing MFG\nliterature, barring convergence via fixed point iteration. Instead, we\nincorporate entropy-regularization and Boltzmann policies into the fixed point\niteration. As a result, we obtain provable convergence to approximate fixed\npoints where existing methods fail, and reach the original goal of approximate\nNash equilibria. All proposed methods are evaluated with respect to their\nexploitability, on both instructive examples with tractable exact solutions and\nhigh-dimensional problems where exact methods become intractable. In\nhigh-dimensional scenarios, we apply established deep reinforcement learning\nmethods and empirically combine fictitious play with our approximations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 16:22:07 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Cui", "Kai", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2102.01611", "submitter": "Hrishikesh Dutta", "authors": "Hrishikesh Dutta and Subir Biswas", "title": "Towards Multi-agent Reinforcement Learning for Wireless Network Protocol\n  Synthesis", "comments": "Accepted and presented in 13th International Conference on\n  COMmunication Systems & NETworkS (COMSNETS) 2021, Bangalore 2021. IEEE, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a multi-agent reinforcement learning based medium access\nframework for wireless networks. The access problem is formulated as a Markov\nDecision Process (MDP), and solved using reinforcement learning with every\nnetwork node acting as a distributed learning agent. The solution components\nare developed step by step, starting from a single-node access scenario in\nwhich a node agent incrementally learns to control MAC layer packet loads for\nreining in self-collisions. The strategy is then scaled up for multi-node\nfully-connected scenarios by using more elaborate reward structures. It also\ndemonstrates preliminary feasibility for more general partially connected\ntopologies. It is shown that by learning to adjust MAC layer transmission\nprobabilities, the protocol is not only able to attain theoretical maximum\nthroughput at an optimal load, but unlike classical approaches, it can also\nretain that maximum throughput at higher loading conditions. Additionally, the\nmechanism is agnostic to heterogeneous loading while preserving that feature.\nIt is also shown that access priorities of the protocol across nodes can be\nparametrically adjusted. Finally, it is also shown that the online learning\nfeature of reinforcement learning is able to make the protocol adapt to\ntime-varying loading conditions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 17:13:37 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dutta", "Hrishikesh", ""], ["Biswas", "Subir", ""]]}, {"id": "2102.01645", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo and Mario G.C.A. Cimino and Gigliola Vaglini", "title": "Generating images from caption and vice versa via CLIP-Guided Generative\n  Latent Space Search", "comments": null, "journal-ref": null, "doi": "10.5220/0010503701660174", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research work we present CLIP-GLaSS, a novel zero-shot framework to\ngenerate an image (or a caption) corresponding to a given caption (or image).\nCLIP-GLaSS is based on the CLIP neural network, which, given an image and a\ndescriptive caption, provides similar embeddings. Differently, CLIP-GLaSS takes\na caption (or an image) as an input, and generates the image (or the caption)\nwhose CLIP embedding is the most similar to the input one. This optimal image\n(or caption) is produced via a generative network, after an exploration by a\ngenetic algorithm. Promising results are shown, based on the experimentation of\nthe image Generators BigGAN and StyleGAN2, and of the text Generator GPT2\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:00:13 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 12:14:49 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:42:49 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "2102.01649", "submitter": "Jinjiang Guo Ph.D.", "authors": "Jinjiang Guo, Jie Li, Dawei Leng and Lurong Pan", "title": "Heterogeneous Graph based Deep Learning for Biomedical Network Link\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-scale biomedical knowledge networks are expanding with emerging\nexperimental technologies that generates multi-scale biomedical big data. Link\nprediction is increasingly used especially in bipartite biomedical networks to\nidentify hidden biological interactions and relationshipts between key entities\nsuch as compounds, targets, gene and diseases. We propose a Graph Neural\nNetworks (GNN) method, namely Graph Pair based Link Prediction model (GPLP),\nfor predicting biomedical network links simply based on their topological\ninteraction information. In GPLP, 1-hop subgraphs extracted from known network\ninteraction matrix is learnt to predict missing links. To evaluate our method,\nthree heterogeneous biomedical networks were used, i.e. Drug-Target Interaction\nnetwork (DTI), Compound-Protein Interaction network (CPI) from NIH Tox21, and\nCompound-Virus Inhibition network (CVI). Our proposed GPLP method significantly\noutperforms over the state-of-the-art baselines. In addition, different network\nincompleteness is analysed with our devised protocol, and we also design an\neffective approach to improve the model robustness towards incomplete networks.\nOur method demonstrates the potential applications in other biomedical\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 07:35:29 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 04:49:10 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 06:56:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Guo", "Jinjiang", ""], ["Li", "Jie", ""], ["Leng", "Dawei", ""], ["Pan", "Lurong", ""]]}, {"id": "2102.01672", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan Sasanka\n  Ammanamanchi, Aremu Anuoluwapo, Antoine Bosselut, Khyathi Raghavi Chandu,\n  Miruna Clinciu, Dipanjan Das, Kaustubh D. Dhole, Wanyu Du, Esin Durmus,\n  Ond\\v{r}ej Du\\v{s}ek, Chris Emezue, Varun Gangal, Cristina Garbacea,\n  Tatsunori Hashimoto, Yufang Hou, Yacine Jernite, Harsh Jhamtani, Yangfeng Ji,\n  Shailza Jolly, Mihir Kale, Dhruv Kumar, Faisal Ladhak, Aman Madaan, Mounica\n  Maddela, Khyati Mahajan, Saad Mahamood, Bodhisattwa Prasad Majumder, Pedro\n  Henrique Martins, Angelina McMillan-Major, Simon Mille, Emiel van Miltenburg,\n  Moin Nadeem, Shashi Narayan, Vitaly Nikolaev, Rubungo Andre Niyongabo,\n  Salomey Osei, Ankur Parikh, Laura Perez-Beltrachini, Niranjan Ramesh Rao,\n  Vikas Raunak, Juan Diego Rodriguez, Sashank Santhanam, Jo\\~ao Sedoc, Thibault\n  Sellam, Samira Shaikh, Anastasia Shimorina, Marco Antonio Sobrevilla\n  Cabezudo, Hendrik Strobelt, Nishant Subramani, Wei Xu, Diyi Yang, Akhila\n  Yerukola, Jiawei Zhou", "title": "The GEM Benchmark: Natural Language Generation, its Evaluation and\n  Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce GEM, a living benchmark for natural language Generation (NLG),\nits Evaluation, and Metrics. Measuring progress in NLG relies on a constantly\nevolving ecosystem of automated metrics, datasets, and human evaluation\nstandards. Due to this moving target, new models often still evaluate on\ndivergent anglo-centric corpora with well-established, but flawed, metrics.\nThis disconnect makes it challenging to identify the limitations of current\nmodels and opportunities for progress. Addressing this limitation, GEM provides\nan environment in which models can easily be applied to a wide set of tasks and\nin which evaluation strategies can be tested. Regular updates to the benchmark\nwill help NLG research become more multilingual and evolve the challenge\nalongside models. This paper serves as the description of the data for which we\nare organizing a shared task at our ACL 2021 Workshop and to which we invite\nthe entire NLG community to participate.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:42:05 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 18:09:36 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 17:42:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Adewumi", "Tosin", ""], ["Aggarwal", "Karmanya", ""], ["Ammanamanchi", "Pawan Sasanka", ""], ["Anuoluwapo", "Aremu", ""], ["Bosselut", "Antoine", ""], ["Chandu", "Khyathi Raghavi", ""], ["Clinciu", "Miruna", ""], ["Das", "Dipanjan", ""], ["Dhole", "Kaustubh D.", ""], ["Du", "Wanyu", ""], ["Durmus", "Esin", ""], ["Du\u0161ek", "Ond\u0159ej", ""], ["Emezue", "Chris", ""], ["Gangal", "Varun", ""], ["Garbacea", "Cristina", ""], ["Hashimoto", "Tatsunori", ""], ["Hou", "Yufang", ""], ["Jernite", "Yacine", ""], ["Jhamtani", "Harsh", ""], ["Ji", "Yangfeng", ""], ["Jolly", "Shailza", ""], ["Kale", "Mihir", ""], ["Kumar", "Dhruv", ""], ["Ladhak", "Faisal", ""], ["Madaan", "Aman", ""], ["Maddela", "Mounica", ""], ["Mahajan", "Khyati", ""], ["Mahamood", "Saad", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["Martins", "Pedro Henrique", ""], ["McMillan-Major", "Angelina", ""], ["Mille", "Simon", ""], ["van Miltenburg", "Emiel", ""], ["Nadeem", "Moin", ""], ["Narayan", "Shashi", ""], ["Nikolaev", "Vitaly", ""], ["Niyongabo", "Rubungo Andre", ""], ["Osei", "Salomey", ""], ["Parikh", "Ankur", ""], ["Perez-Beltrachini", "Laura", ""], ["Rao", "Niranjan Ramesh", ""], ["Raunak", "Vikas", ""], ["Rodriguez", "Juan Diego", ""], ["Santhanam", "Sashank", ""], ["Sedoc", "Jo\u00e3o", ""], ["Sellam", "Thibault", ""], ["Shaikh", "Samira", ""], ["Shimorina", "Anastasia", ""], ["Cabezudo", "Marco Antonio Sobrevilla", ""], ["Strobelt", "Hendrik", ""], ["Subramani", "Nishant", ""], ["Xu", "Wei", ""], ["Yang", "Diyi", ""], ["Yerukola", "Akhila", ""], ["Zhou", "Jiawei", ""]]}, {"id": "2102.01685", "submitter": "Ryan Carey", "authors": "Tom Everitt, Ryan Carey, Eric Langlois, Pedro A Ortega, Shane Legg", "title": "Agent Incentives: A Causal Perspective", "comments": "In Proceedings of the AAAI 2021 Conference. Supersedes\n  arXiv:1902.09980, arXiv:2001.07118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a framework for analysing agent incentives using causal influence\ndiagrams. We establish that a well-known criterion for value of information is\ncomplete. We propose a new graphical criterion for value of control,\nestablishing its soundness and completeness. We also introduce two new concepts\nfor incentive analysis: response incentives indicate which changes in the\nenvironment affect an optimal decision, while instrumental control incentives\nestablish whether an agent can influence its utility via a variable X. For both\nnew concepts, we provide sound and complete graphical criteria. We show by\nexample how these results can help with evaluating the safety and fairness of\nan AI system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:52:41 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 20:08:39 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Everitt", "Tom", ""], ["Carey", "Ryan", ""], ["Langlois", "Eric", ""], ["Ortega", "Pedro A", ""], ["Legg", "Shane", ""]]}, {"id": "2102.01687", "submitter": "Ignacio Laguna", "authors": "Hal Finkel, Ignacio Laguna", "title": "Report of the Workshop on Program Synthesis for Scientific Computing", "comments": "29 pages, workshop website:\n  https://prog-synth-science.github.io/2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Program synthesis is an active research field in academia, national labs, and\nindustry. Yet, work directly applicable to scientific computing, while having\nsome impressive successes, has been limited. This report reviews the relevant\nareas of program synthesis work for scientific computing, discusses successes\nto date, and outlines opportunities for future work. This report is the result\nof the Workshop on Program Synthesis for Scientific Computing was held\nvirtually on August 4-5 2020 (https://prog-synth-science.github.io/2020/).\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:55:23 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Finkel", "Hal", ""], ["Laguna", "Ignacio", ""]]}, {"id": "2102.01732", "submitter": "Selima Curci", "authors": "Selima Curci, Decebal Constantin Mocanu, Mykola Pechenizkiyi", "title": "Truly Sparse Neural Networks at Scale", "comments": "30 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sparse training methods have started to be established as a de\nfacto approach for training and inference efficiency in artificial neural\nnetworks. Yet, this efficiency is just in theory. In practice, everyone uses a\nbinary mask to simulate sparsity since the typical deep learning software and\nhardware are optimized for dense matrix operations. In this paper, we take an\northogonal approach, and we show that we can train truly sparse neural networks\nto harvest their full potential. To achieve this goal, we introduce three novel\ncontributions, specially designed for sparse neural networks: (1) a parallel\ntraining algorithm and its corresponding sparse implementation from scratch,\n(2) an activation function with non-trainable parameters to favour the gradient\nflow, and (3) a hidden neurons importance metric to eliminate redundancies. All\nin one, we are able to break the record and to train the largest neural network\never trained in terms of representational power -- reaching the bat brain size.\nThe results show that our approach has state-of-the-art performance while\nopening the path for an environmentally friendly artificial intelligence era.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 20:06:47 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Curci", "Selima", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiyi", "Mykola", ""]]}, {"id": "2102.01740", "submitter": "Yili Hong", "authors": "Yili Hong and Jie Min and Caleb B. King and William Q. Meeker", "title": "Reliability Analysis of Artificial Intelligence Systems Using Recurrent\n  Events Data from Autonomous Vehicles", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) systems have become increasingly common and the\ntrend will continue. Examples of AI systems include autonomous vehicles (AV),\ncomputer vision, natural language processing, and AI medical experts. To allow\nfor safe and effective deployment of AI systems, the reliability of such\nsystems needs to be assessed. Traditionally, reliability assessment is based on\nreliability test data and the subsequent statistical modeling and analysis. The\navailability of reliability data for AI systems, however, is limited because\nsuch data are typically sensitive and proprietary. The California Department of\nMotor Vehicles (DMV) oversees and regulates an AV testing program, in which\nmany AV manufacturers are conducting AV road tests. Manufacturers participating\nin the program are required to report recurrent disengagement events to\nCalifornia DMV. This information is being made available to the public. In this\npaper, we use recurrent disengagement events as a representation of the\nreliability of the AI system in AV, and propose a statistical framework for\nmodeling and analyzing the recurrent events data from AV driving tests. We use\ntraditional parametric models in software reliability and propose a new\nnonparametric model based on monotonic splines to describe the event process.\nWe develop inference procedures for selecting the best models, quantifying\nuncertainty, and testing heterogeneity in the event process. We then analyze\nthe recurrent events data from four AV manufacturers, and make inferences on\nthe reliability of the AI systems in AV. We also describe how the proposed\nanalysis can be applied to assess the reliability of other AI systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 20:25:23 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Hong", "Yili", ""], ["Min", "Jie", ""], ["King", "Caleb B.", ""], ["Meeker", "William Q.", ""]]}, {"id": "2102.01748", "submitter": "Ming Yin", "authors": "Ming Yin, Yu Bai, Yu-Xiang Wang", "title": "Near-Optimal Offline Reinforcement Learning via Double Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of offline reinforcement learning (RL) -- a\nwell-motivated setting of RL that aims at policy optimization using only\nhistorical data. Despite its wide applicability, theoretical understandings of\noffline RL, such as its optimal sample complexity, remain largely open even in\nbasic settings such as \\emph{tabular} Markov Decision Processes (MDPs).\n  In this paper, we propose Off-Policy Double Variance Reduction (OPDVR), a new\nvariance reduction based algorithm for offline RL. Our main result shows that\nOPDVR provably identifies an $\\epsilon$-optimal policy with\n$\\widetilde{O}(H^2/d_m\\epsilon^2)$ episodes of offline data in the\nfinite-horizon stationary transition setting, where $H$ is the horizon length\nand $d_m$ is the minimal marginal state-action distribution induced by the\nbehavior policy. This improves over the best known upper bound by a factor of\n$H$. Moreover, we establish an information-theoretic lower bound of\n$\\Omega(H^2/d_m\\epsilon^2)$ which certifies that OPDVR is optimal up to\nlogarithmic factors. Lastly, we show that OPDVR also achieves rate-optimal\nsample complexity under alternative settings such as the finite-horizon MDPs\nwith non-stationary transitions and the infinite horizon MDPs with discounted\nrewards.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 20:47:35 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Yin", "Ming", ""], ["Bai", "Yu", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2102.01754", "submitter": "Weiquan Fan", "authors": "Weiquan Fan, Xiangmin Xu, Xiaofen Xing, Weidong Chen, Dongyan Huang", "title": "LSSED: a large-scale dataset and benchmark for speech emotion\n  recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Speech emotion recognition is a vital contributor to the next generation of\nhuman-computer interaction (HCI). However, current existing small-scale\ndatabases have limited the development of related research. In this paper, we\npresent LSSED, a challenging large-scale english speech emotion dataset, which\nhas data collected from 820 subjects to simulate real-world distribution. In\naddition, we release some pre-trained models based on LSSED, which can not only\npromote the development of speech emotion recognition, but can also be\ntransferred to related downstream tasks such as mental health analysis where\ndata is extremely difficult to collect. Finally, our experiments show the\nnecessity of large-scale datasets and the effectiveness of pre-trained models.\nThe dateset will be released on https://github.com/tobefans/LSSED.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 11:15:32 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Fan", "Weiquan", ""], ["Xu", "Xiangmin", ""], ["Xing", "Xiaofen", ""], ["Chen", "Weidong", ""], ["Huang", "Dongyan", ""]]}, {"id": "2102.01761", "submitter": "Sensong An", "authors": "Sensong An, Bowen Zheng, Mikhail Y. Shalaginov, Hong Tang, Hang Li, Li\n  Zhou, Yunxi Dong, Mohammad Haerinia, Anuradha Murthy Agarwal, Clara\n  Rivero-Baleine, Myungkoo Kang, Kathleen A. Richardson, Tian Gu, Juejun Hu,\n  Clayton Fowler and Hualiang Zhang", "title": "Deep Convolutional Neural Networks to Predict Mutual Coupling Effects in\n  Metasurfaces", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metasurfaces have provided a novel and promising platform for the realization\nof compact and large-scale optical devices. The conventional metasurface design\napproach assumes periodic boundary conditions for each element, which is\ninaccurate in most cases since the near-field coupling effects between elements\nwill change when surrounded by non-identical structures. In this paper, we\npropose a deep learning approach to predict the actual electromagnetic (EM)\nresponses of each target meta-atom placed in a large array with near-field\ncoupling effects taken into account. The predicting neural network takes the\nphysical specifications of the target meta-atom and its neighbors as input, and\ncalculates its phase and amplitude in milliseconds. This approach can be\napplied to explain metasurfaces' performance deterioration caused by mutual\ncoupling and further used to optimize their efficiencies once combined with\noptimization algorithms. To demonstrate the efficacy of this methodology, we\nobtain large improvements in efficiency for a beam deflector and a metalens\nover the conventional design approach. Moreover, we show the correlations\nbetween a metasurface's performance and its design errors caused by mutual\ncoupling are not bound to certain specifications (materials, shapes, etc.). As\nsuch, we envision that this approach can be readily applied to explore the\nmutual coupling effects and improve the performance of various metasurface\ndesigns.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 21:27:56 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["An", "Sensong", ""], ["Zheng", "Bowen", ""], ["Shalaginov", "Mikhail Y.", ""], ["Tang", "Hong", ""], ["Li", "Hang", ""], ["Zhou", "Li", ""], ["Dong", "Yunxi", ""], ["Haerinia", "Mohammad", ""], ["Agarwal", "Anuradha Murthy", ""], ["Rivero-Baleine", "Clara", ""], ["Kang", "Myungkoo", ""], ["Richardson", "Kathleen A.", ""], ["Gu", "Tian", ""], ["Hu", "Juejun", ""], ["Fowler", "Clayton", ""], ["Zhang", "Hualiang", ""]]}, {"id": "2102.01775", "submitter": "Chun Kai Ling", "authors": "Chun Kai Ling, Noam Brown", "title": "Safe Search for Stackelberg Equilibria in Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Stackelberg equilibrium is a solution concept in two-player games where the\nleader has commitment rights over the follower. In recent years, it has become\na cornerstone of many security applications, including airport patrolling and\nwildlife poaching prevention. Even though many of these settings are sequential\nin nature, existing techniques pre-compute the entire solution ahead of time.\nIn this paper, we present a theoretically sound and empirically effective way\nto apply search, which leverages extra online computation to improve a\nsolution, to the computation of Stackelberg equilibria in general-sum games.\nInstead of the leader attempting to solve the full game upfront, an approximate\n\"blueprint\" solution is first computed offline and is then improved online for\nthe particular subgames encountered in actual play. We prove that our search\ntechnique is guaranteed to perform no worse than the pre-computed blueprint\nstrategy, and empirically demonstrate that it enables approximately solving\nsignificantly larger games compared to purely offline methods. We also show\nthat our search operation may be cast as a smaller Stackelberg problem, making\nour method complementary to existing algorithms based on strategy generation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 22:01:19 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ling", "Chun Kai", ""], ["Brown", "Noam", ""]]}, {"id": "2102.01780", "submitter": "Daniel Severin Dr.", "authors": "Mauro Lucci, Daniel Sever\\'in, Paula Zabala", "title": "A metaheuristic for crew scheduling in a pickup-and-delivery problem\n  with time windows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vehicle routing and crew scheduling problem (VRCSP) consists of\nsimultaneously planning the routes of a fleet of vehicles and scheduling the\ncrews, where the vehicle-crew correspondence is not fixed through time. This\nallows a greater planning flexibility and a more efficient use of the fleet,\nbut in counterpart, a high synchronisation is demanded. In this work, we\npresent a VRCSP where pickup-and-delivery requests with time windows have to be\nfulfilled over a given planning horizon by using trucks and drivers. Crews can\nbe composed of 1 or 2 drivers and any of them can be relieved in a given set of\nlocations. Moreover, they are allowed to travel among locations with\nnon-company shuttles, at an additional cost that is minimised. As our problem\nconsiders distinct routes for trucks and drivers, we have an additional\nflexibility not contemplated in other previous VRCSP given in the literature\nwhere a crew is handled as an indivisible unit. We tackle this problem with a\ntwo-stage sequential approach: a set of truck routes is computed in the first\nstage and a set of driver routes consistent with the truck routes is obtained\nin the second one. We design and evaluate the performance of a metaheuristic\nbased algorithm for the latter stage. Our algorithm is mainly a GRASP with a\nperturbation procedure that allows reusing solutions already found in case the\nsearch for new solutions becomes difficult. This procedure together with other\nto repair infeasible solutions allow us to find high-quality solutions on\ninstances of 100 requests spread across 15 cities with a fleet of 12-32 trucks\n(depending on the planning horizon) in less than an hour. We also conclude that\nthe possibility of carrying an additional driver leads to a decrease of the\ncost of external shuttles by about 60% on average with respect to individual\ncrews and, in some cases, to remove this cost completely.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 22:14:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Lucci", "Mauro", ""], ["Sever\u00edn", "Daniel", ""], ["Zabala", "Paula", ""]]}, {"id": "2102.01792", "submitter": "Atefeh Shahroudnejad", "authors": "Atefeh Shahroudnejad", "title": "A Survey on Understanding, Visualizations, and Explanation of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in machine learning and signal processing domains have\nresulted in an extensive surge of interest in Deep Neural Networks (DNNs) due\nto their unprecedented performance and high accuracy for different and\nchallenging problems of significant engineering importance. However, when such\ndeep learning architectures are utilized for making critical decisions such as\nthe ones that involve human lives (e.g., in control systems and medical\napplications), it is of paramount importance to understand, trust, and in one\nword \"explain\" the argument behind deep models' decisions. In many\napplications, artificial neural networks (including DNNs) are considered as\nblack-box systems, which do not provide sufficient clue on their internal\nprocessing actions. Although some recent efforts have been initiated to explain\nthe behaviors and decisions of deep networks, explainable artificial\nintelligence (XAI) domain, which aims at reasoning about the behavior and\ndecisions of DNNs, is still in its infancy. The aim of this paper is to provide\na comprehensive overview on Understanding, Visualization, and Explanation of\nthe internal and overall behavior of DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 22:57:22 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Shahroudnejad", "Atefeh", ""]]}, {"id": "2102.01811", "submitter": "Yuval Shahar", "authors": "Yuval Shahar", "title": "The Ethical Implications of Shared Medical Decision Making without\n  Providing Adequate Computational Support to the Care Provider and to the\n  Patient", "comments": "10 pages; no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is a clear need to involve patients in medical decisions. However,\ncognitive psychological research has highlighted the cognitive limitations of\nhumans with respect to 1. Probabilistic assessment of the patient state and of\npotential outcomes of various decisions, 2. Elicitation of the patient utility\nfunction, and 3. Integration of the probabilistic knowledge and of patient\npreferences to determine the optimal strategy. Therefore, without adequate\ncomputational support, current shared decision models have severe ethical\ndeficiencies. An informed consent model unfairly transfers the responsibility\nto a patient who does not have the necessary knowledge, nor the integration\ncapability. A paternalistic model endows with exaggerated power a physician who\nmight not be aware of the patient preferences, is prone to multiple cognitive\nbiases, and whose computational integration capability is bounded. Recent\nprogress in Artificial Intelligence suggests adding a third agent: a computer,\nin all deliberative medical decisions: Non emergency medical decisions in which\nmore than one alternative exists, the patient preferences can be elicited, the\ntherapeutic alternatives might be influenced by these preferences, medical\nknowledge exists regarding the likelihood of the decision outcomes, and there\nis sufficient decision time. Ethical physicians should exploit computational\ndecision support technologies, neither making the decisions solely on their\nown, nor shirking their duty and shifting the responsibility to patients in the\nname of informed consent. The resulting three way (patient, care provider,\ncomputer) human machine model that we suggest emphasizes the patient\npreferences, the physician knowledge, and the computational integration of both\naspects, does not diminish the physician role, but rather brings out the best\nin human and machine.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:30:21 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Shahar", "Yuval", ""]]}, {"id": "2102.01815", "submitter": "Xinqiao Zhang", "authors": "Xinqiao Zhang, Huili Chen and Farinaz Koushanfar", "title": "TAD: Trigger Approximation based Black-box Trojan Detection for AI", "comments": "6 body pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An emerging amount of intelligent applications have been developed with the\nsurge of Machine Learning (ML). Deep Neural Networks (DNNs) have demonstrated\nunprecedented performance across various fields such as medical diagnosis and\nautonomous driving. While DNNs are widely employed in security-sensitive\nfields, they are identified to be vulnerable to Neural Trojan (NT) attacks that\nare controlled and activated by the stealthy trigger. We call this vulnerable\nmodel adversarial artificial intelligence (AI). In this paper, we target to\ndesign a robust Trojan detection scheme that inspects whether a pre-trained AI\nmodel has been Trojaned before its deployment. Prior works are oblivious of the\nintrinsic property of trigger distribution and try to reconstruct the trigger\npattern using simple heuristics, i.e., stimulating the given model to incorrect\noutputs. As a result, their detection time and effectiveness are limited. We\nleverage the observation that the pixel trigger typically features spatial\ndependency and propose TAD, the first trigger approximation based Trojan\ndetection framework that enables fast and scalable search of the trigger in the\ninput space. Furthermore, TAD can also detect Trojans embedded in the feature\nspace where certain filter transformations are used to activate the Trojan. We\nperform extensive experiments to investigate the performance of the TAD across\nvarious datasets and ML models. Empirical results show that TAD achieves a\nROC-AUC score of 0:91 on the public TrojAI dataset 1 and the average detection\ntime per model is 7:1 minutes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:49:50 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 18:45:48 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 21:46:32 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Zhang", "Xinqiao", ""], ["Chen", "Huili", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2102.01862", "submitter": "Zhuotong Chen", "authors": "Zhuotong Chen, Qianxiao Li, Zheng Zhang", "title": "Towards Robust Neural Networks via Close-loop Control", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their success in massive engineering applications, deep neural\nnetworks are vulnerable to various perturbations due to their black-box nature.\nRecent study has shown that a deep neural network can misclassify the data even\nif the input data is perturbed by an imperceptible amount. In this paper, we\naddress the robustness issue of neural networks by a novel close-loop control\nmethod from the perspective of dynamic systems. Instead of modifying the\nparameters in a fixed neural network architecture, a close-loop control process\nis added to generate control signals adaptively for the perturbed or corrupted\ndata. We connect the robustness of neural networks with optimal control using\nthe geometrical information of underlying data to design the control objective.\nThe detailed analysis shows how the embedding manifolds of state trajectory\naffect error estimation of the proposed method. Our approach can simultaneously\nmaintain the performance on clean data and improve the robustness against many\ntypes of data perturbations. It can also further improve the performance of\nrobustly trained neural networks against different perturbations. To the best\nof our knowledge, this is the first work that improves the robustness of neural\nnetworks with close-loop control.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 03:50:35 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 02:45:44 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Chen", "Zhuotong", ""], ["Li", "Qianxiao", ""], ["Zhang", "Zheng", ""]]}, {"id": "2102.01867", "submitter": "Sajad Khodadadian", "authors": "Sajad Khodadadian, AmirEmad Ghassami, Negar Kiyavash", "title": "Impact of Data Processing on Fairness in Supervised Learning", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the impact of pre and post processing for reducing discrimination in\ndata-driven decision makers. We first analyze the fundamental trade-off between\nfairness and accuracy in a pre-processing approach, and propose a design for a\npre-processing module based on a convex optimization program, which can be\nadded before the original classifier. This leads to a fundamental lower bound\non attainable discrimination, given any acceptable distortion in the outcome.\nFurthermore, we reformulate an existing post-processing method in terms of our\naccuracy and fairness measures, which allows comparing post-processing and\npre-processing approaches. We show that under some mild conditions,\npre-processing outperforms post-processing. Finally, we show that by\nappropriate choice of the discrimination measure, the optimization problem for\nboth pre and post processing approaches will reduce to a linear program and\nhence can be solved efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 04:11:39 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Khodadadian", "Sajad", ""], ["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""]]}, {"id": "2102.01868", "submitter": "Yongfeng Zhang", "authors": "Shuyuan Xu, Yingqiang Ge, Yunqi Li, Zuohui Fu, Xu Chen, Yongfeng Zhang", "title": "Causal Collaborative Filtering", "comments": "14 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are important and valuable tools for many personalized\nservices. Collaborative Filtering (CF) algorithms -- among others -- are\nfundamental algorithms driving the underlying mechanism of personalized\nrecommendation. Many of the traditional CF algorithms are designed based on the\nfundamental idea of mining or learning correlative patterns from data for\nmatching, including memory-based methods such as user/item-based CF as well as\nlearning-based methods such as matrix factorization and deep learning models.\nHowever, advancing from correlative learning to causal learning is an important\nproblem, because causal/counterfactual modeling can help us to think outside of\nthe observational data for user modeling and personalization. In this paper, we\npropose Causal Collaborative Filtering (CCF) -- a general framework for\nmodeling causality in collaborative filtering and recommendation. We first\nprovide a unified causal view of CF and mathematically show that many of the\ntraditional CF algorithms are actually special cases of CCF under simplified\ncausal graphs. We then propose a conditional intervention approach for\n$do$-calculus so that we can estimate the causal relations based on\nobservational data. Finally, we further propose a general counterfactual\nconstrained learning framework for estimating the user-item preferences.\nExperiments are conducted on two types of real-world datasets -- traditional\nand randomized trial data -- and results show that our framework can improve\nthe recommendation performance of many CF algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 04:16:11 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 18:31:40 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 16:28:07 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 03:32:42 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Xu", "Shuyuan", ""], ["Ge", "Yingqiang", ""], ["Li", "Yunqi", ""], ["Fu", "Zuohui", ""], ["Chen", "Xu", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2102.01904", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Edward Lam, Peter J. Stuckey, and Joao Marques-Silva", "title": "A Scalable Two Stage Approach to Computing Optimal Decision Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is ubiquitous in modern life. Since it is being\ndeployed in technologies that affect our privacy and safety, it is often\ncrucial to understand the reasoning behind its decisions, warranting the need\nfor explainable AI. Rule-based models, such as decision trees, decision lists,\nand decision sets, are conventionally deemed to be the most interpretable.\nRecent work uses propositional satisfiability (SAT) solving (and its\noptimization variants) to generate minimum-size decision sets. Motivated by\nlimited practical scalability of these earlier methods, this paper proposes a\nnovel approach to learn minimum-size decision sets by enumerating individual\nrules of the target decision set independently of each other, and then solving\na set cover problem to select a subset of rules. The approach makes use of\nmodern maximum satisfiability and integer linear programming technologies.\nExperiments on a wide range of publicly available datasets demonstrate the\nadvantage of the new approach over the state of the art in SAT-based decision\nset learning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 06:51:49 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Lam", "Edward", ""], ["Stuckey", "Peter J.", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2102.01936", "submitter": "Liangxi Liu", "authors": "Liangxi Liu, Feng Zheng, Hong Chen, Guo-Jun Qi, Heng Huang and Ling\n  Shao", "title": "A Bayesian Federated Learning Framework with Online Laplace\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) allows multiple clients to collaboratively learn a\nglobally shared model through cycles of model aggregation and local model\ntraining, without the need to share data. Most existing FL methods train local\nmodels separately on different clients, and then simply average their\nparameters to obtain a centralized model on the server side. However, these\napproaches generally suffer from large aggregation errors and severe local\nforgetting, which are particularly bad in heterogeneous data settings. To\ntackle these issues, in this paper, we propose a novel FL framework that uses\nonline Laplace approximation to approximate posteriors on both the client and\nserver side. On the server side, a multivariate Gaussian product mechanism is\nemployed to construct and maximize a global posterior, largely reducing the\naggregation errors induced by large discrepancies between local models. On the\nclient side, a prior loss that uses the global posterior probabilistic\nparameters delivered from the server is designed to guide the local training.\nBinding such learning constraints from other clients enables our method to\nmitigate local forgetting. Finally, we achieve state-of-the-art results on\nseveral benchmarks, clearly demonstrating the advantages of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 08:36:58 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 16:44:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Liu", "Liangxi", ""], ["Zheng", "Feng", ""], ["Chen", "Hong", ""], ["Qi", "Guo-Jun", ""], ["Huang", "Heng", ""], ["Shao", "Ling", ""]]}, {"id": "2102.01951", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang\n  Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d'Autume,\n  Sebastian Ruder, Dani Yogatama, Kris Cao, Tomas Kocisky, Susannah Young, Phil\n  Blunsom", "title": "Pitfalls of Static Language Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our world is open-ended, non-stationary and constantly evolving; thus what we\ntalk about and how we talk about it changes over time. This inherent dynamic\nnature of language comes in stark contrast to the current static language\nmodelling paradigm, which constructs training and evaluation sets from\noverlapping time periods. Despite recent progress, we demonstrate that\nstate-of-the-art Transformer models perform worse in the realistic setup of\npredicting future utterances from beyond their training period -- a consistent\npattern across three datasets from two domains. We find that, while increasing\nmodel size alone -- a key driver behind recent progress -- does not provide a\nsolution for the temporal generalization problem, having models that\ncontinually update their knowledge with new information can indeed slow down\nthe degradation over time. Hence, given the compilation of ever-larger language\nmodelling training datasets, combined with the growing list of\nlanguage-model-based NLP applications that require up-to-date knowledge about\nthe world, we argue that now is the right time to rethink our static language\nmodelling evaluation protocol, and develop adaptive language models that can\nremain up-to-date with respect to our ever-changing and non-stationary world.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:01:49 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Kuncoro", "Adhiguna", ""], ["Gribovskaya", "Elena", ""], ["Agrawal", "Devang", ""], ["Liska", "Adam", ""], ["Terzi", "Tayfun", ""], ["Gimenez", "Mai", ""], ["d'Autume", "Cyprien de Masson", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""], ["Cao", "Kris", ""], ["Kocisky", "Tomas", ""], ["Young", "Susannah", ""], ["Blunsom", "Phil", ""]]}, {"id": "2102.01968", "submitter": "Claire Theobald", "authors": "Claire Theobald (LORIA), Fr\\'ed\\'eric Pennerath (LORIA), Brieuc\n  Conan-Guez (LORIA), Miguel Couceiro (LORIA), Amedeo Napoli (LORIA)", "title": "A Bayesian Neural Network based on Dropout Regulation", "comments": null, "journal-ref": "Workshop on Uncertainty in Machine Learning (WUML) at ECML-PKDD\n  2020 Conference, Eyke H{\\\"u}llermeier; S{\\'e}bastien Destercke, 2020, N.A.\n  (online), France", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNN) have recently emerged in the Deep Learning\nworld for dealing with uncertainty estimation in classification tasks, and are\nused in many application domains such as astrophysics, autonomous driving...BNN\nassume a prior over the weights of a neural network instead of point estimates,\nenabling in this way the estimation of both aleatoric and epistemic uncertainty\nof the model prediction.Moreover, a particular type of BNN, namely MC Dropout,\nassumes a Bernoulli distribution on the weights by using Dropout.Several\nattempts to optimize the dropout rate exist, e.g. using a variational\napproach.In this paper, we present a new method called \"Dropout Regulation\"\n(DR), which consists of automatically adjusting the dropout rate during\ntraining using a controller as used in automation.DR allows for a precise\nestimation of the uncertainty which is comparable to the state-of-the-art while\nremaining simple to implement.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:39:50 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Theobald", "Claire", "", "LORIA"], ["Pennerath", "Fr\u00e9d\u00e9ric", "", "LORIA"], ["Conan-Guez", "Brieuc", "", "LORIA"], ["Couceiro", "Miguel", "", "LORIA"], ["Napoli", "Amedeo", "", "LORIA"]]}, {"id": "2102.01985", "submitter": "Arushi Jain", "authors": "Arushi Jain, Gandharv Patil, Ayush Jain, Khimya Khetarpal, Doina\n  Precup", "title": "Variance Penalized On-Policy and Off-Policy Actor-Critic", "comments": "Accepted to the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence (AAAI-21), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms are typically geared towards optimizing the\nexpected return of an agent. However, in many practical applications, low\nvariance in the return is desired to ensure the reliability of an algorithm. In\nthis paper, we propose on-policy and off-policy actor-critic algorithms that\noptimize a performance criterion involving both mean and variance in the\nreturn. Previous work uses the second moment of return to estimate the variance\nindirectly. Instead, we use a much simpler recently proposed direct variance\nestimator which updates the estimates incrementally using temporal difference\nmethods. Using the variance-penalized criterion, we guarantee the convergence\nof our algorithm to locally optimal policies for finite state action Markov\ndecision processes. We demonstrate the utility of our algorithm in tabular and\ncontinuous MuJoCo domains. Our approach not only performs on par with\nactor-critic and prior variance-penalization baselines in terms of expected\nreturn, but also generates trajectories which have lower variance in the\nreturn.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 10:06:16 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Jain", "Arushi", ""], ["Patil", "Gandharv", ""], ["Jain", "Ayush", ""], ["Khetarpal", "Khimya", ""], ["Precup", "Doina", ""]]}, {"id": "2102.01998", "submitter": "Guang Yang A", "authors": "Guang Yang, Qinghao Ye, Jun Xia", "title": "Unbox the Black-box for the Medical Explainable AI via Multi-modal and\n  Multi-centre Data Fusion: A Mini-Review, Two Showcases and Beyond", "comments": "68 pages, 19 figures, submitted to the Information Fusion journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is an emerging research topic of\nmachine learning aimed at unboxing how AI systems' black-box choices are made.\nThis research field inspects the measures and models involved in\ndecision-making and seeks solutions to explain them explicitly. Many of the\nmachine learning algorithms can not manifest how and why a decision has been\ncast. This is particularly true of the most popular deep neural network\napproaches currently in use. Consequently, our confidence in AI systems can be\nhindered by the lack of explainability in these black-box models. The XAI\nbecomes more and more crucial for deep learning powered applications,\nespecially for medical and healthcare studies, although in general these deep\nneural networks can return an arresting dividend in performance. The\ninsufficient explainability and transparency in most existing AI systems can be\none of the major reasons that successful implementation and integration of AI\ntools into routine clinical practice are uncommon. In this study, we first\nsurveyed the current progress of XAI and in particular its advances in\nhealthcare applications. We then introduced our solutions for XAI leveraging\nmulti-modal and multi-centre data fusion, and subsequently validated in two\nshowcases following real clinical scenarios. Comprehensive quantitative and\nqualitative analyses can prove the efficacy of our proposed XAI solutions, from\nwhich we can envisage successful applications in a broader range of clinical\nquestions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 10:56:58 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Yang", "Guang", ""], ["Ye", "Qinghao", ""], ["Xia", "Jun", ""]]}, {"id": "2102.02009", "submitter": "Tanvir Alam", "authors": "Tanvir Alam, Jens Schneider", "title": "Social Network Analysis of Hadith Narrators from Sahih Bukhari", "comments": "Social Network Analysis of Hadith Narrators from Sahih Bukhari", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ahadith, prophetic traditions for the Muslims around the world, are\nnarrations originating from the sayings and the deeds of Prophet Muhammad\n(pbuh). They are considered one of the fundamental sources of Islamic\nlegislation along with the Quran. The list of persons involved in the narration\nof each hadith is carefully scrutinized by scholars studying the hadith, with\nrespect to their reputation and authenticity of the hadith. This is due to the\nits legislative importance in Islamic principles. There were many narrators who\ncontributed to this responsibility of preserving prophetic narrations over the\ncenturies. But to date, no systematic and comprehensive study, based on the\nsocial network, has been adapted to understand the contribution of early hadith\nnarrators and the propagation of hadith across generations. In this study, we\nrepresented the chain of narrators of the hadith collection from Sahih Bukhari\nas a social graph. Based on social network analysis (SNA) on this graph, we\nfound that the network of narrators is a scale-free network. We identified a\nlist of influential narrators from the companions as well as the narrators from\nthe second and third-generation who contribute significantly in the propagation\nof hadith collected in Sahih Bukhari. We discovered sixteen communities from\nthe narrators of Sahih Bukhari. In each of these communities, there are other\nnarrators who contributed significantly to the propagation of prophetic\nnarrations. We also found that most narrators were centered in Makkah and\nMadinah in the era of companions and, then, gradually the center of hadith\nnarrators shifted towards Kufa, Baghdad and central Asia over a period of time.\nTo the best of our knowledge, this the first comprehensive and systematic study\nbased on SNA, representing the narrators as a social graph to analyze their\ncontribution to the preservation and propagation of hadith.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 11:24:32 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Alam", "Tanvir", ""], ["Schneider", "Jens", ""]]}, {"id": "2102.02049", "submitter": "Gellert Weisz", "authors": "Gell\\'ert Weisz, Philip Amortila, Barnab\\'as Janzer, Yasin\n  Abbasi-Yadkori, Nan Jiang, Csaba Szepesv\\'ari", "title": "On Query-efficient Planning in MDPs under Linear Realizability of the\n  Optimal State-value Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider local planning in fixed-horizon MDPs with a generative model\nunder the assumption that the optimal value function lies close to the span of\na feature map. The generative model provides a local access to the MDP: The\nplanner can ask for random transitions from previously returned states and\narbitrary actions, and features are only accessible for states that are\nencountered in this process. As opposed to previous work (e.g. Lattimore et al.\n(2020)) where linear realizability of all policies was assumed, we consider the\nsignificantly relaxed assumption of a single linearly realizable\n(deterministic) policy. A recent lower bound by Weisz et al. (2020) established\nthat the related problem when the action-value function of the optimal policy\nis linearly realizable requires an exponential number of queries, either in $H$\n(the horizon of the MDP) or $d$ (the dimension of the feature mapping). Their\nconstruction crucially relies on having an exponentially large action set. In\ncontrast, in this work, we establish that poly$(H,d)$ planning is possible with\nstate value function realizability whenever the action set has a constant size.\nIn particular, we present the TensorPlan algorithm which uses\npoly$((dH/\\delta)^A)$ simulator queries to find a $\\delta$-optimal policy\nrelative to any deterministic policy for which the value function is linearly\nrealizable with some bounded parameter. This is the first algorithm to give a\npolynomial query complexity guarantee using only linear-realizability of a\nsingle competing value function. Whether the computation cost is similarly\nbounded remains an open question. We extend the upper bound to the\nnear-realizable case and to the infinite-horizon discounted setup. We also\npresent a lower bound in the infinite-horizon episodic setting: Planners that\nachieve constant suboptimality need exponentially many queries, either in $d$\nor the number of actions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 13:23:15 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 13:53:07 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 11:37:09 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Amortila", "Philip", ""], ["Janzer", "Barnab\u00e1s", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Jiang", "Nan", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2102.02061", "submitter": "Munyque Mittelmann", "authors": "Munyque Mittelmann, Sylvain Bouveret, Laurent Perrussel", "title": "A General Framework for the Logical Representation of Combinatorial\n  Exchange Protocols", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to propose a framework for representing and\nreasoning about the rules governing a combinatorial exchange. Such a framework\nis at first interest as long as we want to build up digital marketplaces based\non auction, a widely used mechanism for automated transactions. Combinatorial\nexchange is the most general case of auctions, mixing the double and\ncombinatorial variants: agents bid to trade bundles of goods. Hence the\nframework should fulfill two requirements: (i) it should enable bidders to\nexpress their bids on combinations of goods and (ii) it should allow describing\nthe rules governing some market, namely the legal bids, the allocation and\npayment rules. To do so, we define a logical language in the spirit of the Game\nDescription Language: the Combinatorial Exchange Description Language is the\nfirst language for describing combinatorial exchange in a logical framework.\nThe contribution is two-fold: first, we illustrate the general dimension by\nrepresenting different kinds of protocols, and second, we show how to reason\nabout auction properties in this machine-processable language.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 19:16:42 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Mittelmann", "Munyque", ""], ["Bouveret", "Sylvain", ""], ["Perrussel", "Laurent", ""]]}, {"id": "2102.02086", "submitter": "Zahra Ahmadi", "authors": "Patrick Abels, Zahra Ahmadi, Sophie Burkhardt, Benjamin Schiller,\n  Iryna Gurevych, Stefan Kramer", "title": "Focusing Knowledge-based Graph Argument Mining via Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decision-making usually takes five steps: identifying the problem, collecting\ndata, extracting evidence, identifying pro and con arguments, and making\ndecisions. Focusing on extracting evidence, this paper presents a hybrid model\nthat combines latent Dirichlet allocation and word embeddings to obtain\nexternal knowledge from structured and unstructured data. We study the task of\nsentence-level argument mining, as arguments mostly require some degree of\nworld knowledge to be identified and understood. Given a topic and a sentence,\nthe goal is to classify whether a sentence represents an argument in regard to\nthe topic. We use a topic model to extract topic- and sentence-specific\nevidence from the structured knowledge base Wikidata, building a graph based on\nthe cosine similarity between the entity word vectors of Wikidata and the\nvector of the given sentence. Also, we build a second graph based on\ntopic-specific articles found via Google to tackle the general incompleteness\nof structured knowledge bases. Combining these graphs, we obtain a graph-based\nmodel which, as our evaluation shows, successfully capitalizes on both\nstructured and unstructured data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 14:39:58 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Abels", "Patrick", ""], ["Ahmadi", "Zahra", ""], ["Burkhardt", "Sophie", ""], ["Schiller", "Benjamin", ""], ["Gurevych", "Iryna", ""], ["Kramer", "Stefan", ""]]}, {"id": "2102.02094", "submitter": "Philip Doyle", "authors": "Philip R Doyle, Leigh Clark and Benjamin R Cowan", "title": "What Do We See in Them? Identifying Dimensions of Partner Models for\n  Speech Interfaces Using a Psycholexical Approach", "comments": "Pre-print version. 14 pages (inc. bib), 3 figures, 5 tables", "journal-ref": null, "doi": "10.1145/3411764.3445206", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptions of system competence and communicative ability, termed partner\nmodels, play a significant role in speech interface interaction. Yet we do not\nknow what the core dimensions of this concept are. Taking a psycholexical\napproach, our paper is the first to identify the key dimensions that define\npartner models in speech agent interaction. Through a repertory grid study\n(N=21), a review of key subjective questionnaires, an expert review of\nresulting word pairs and an online study of 356 user of speech interfaces, we\nidentify three key dimensions that make up a users' partner model: 1)\nperceptions toward competence and capability; 2) assessment of human-likeness;\nand 3) a system's perceived cognitive flexibility. We discuss the implications\nfor partner modelling as a concept, emphasising the importance of salience and\nthe dynamic nature of these perceptions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 14:57:08 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 09:43:53 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Doyle", "Philip R", ""], ["Clark", "Leigh", ""], ["Cowan", "Benjamin R", ""]]}, {"id": "2102.02100", "submitter": "Ahmet Ercan Tekden", "authors": "Ahmet E. Tekden, Aykut Erdem, Erkut Erdem, Tamim Asfour, Emre Ugur", "title": "Object and Relation Centric Representations for Push Effect Prediction", "comments": "Project Page: https://fzaero.github.io/push_learning/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pushing is an essential non-prehensile manipulation skill used for tasks\nranging from pre-grasp manipulation to scene rearrangement, reasoning about\nobject relations in the scene, and thus pushing actions have been widely\nstudied in robotics. The effective use of pushing actions often requires an\nunderstanding of the dynamics of the manipulated objects and adaptation to the\ndiscrepancies between prediction and reality. For this reason, effect\nprediction and parameter estimation with pushing actions have been heavily\ninvestigated in the literature. However, current approaches are limited because\nthey either model systems with a fixed number of objects or use image-based\nrepresentations whose outputs are not very interpretable and quickly accumulate\nerrors. In this paper, we propose a graph neural network based framework for\neffect prediction and parameter estimation of pushing actions by modeling\nobject relations based on contacts or articulations. Our framework is validated\nboth in real and simulated environments containing different shaped multi-part\nobjects connected via different types of joints and objects with different\nmasses. Our approach enables the robot to predict and adapt the effect of a\npushing action as it observes the scene. Further, we demonstrate 6D effect\nprediction in the lever-up action in the context of robot-based hard-disk\ndisassembly.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 15:09:12 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Tekden", "Ahmet E.", ""], ["Erdem", "Aykut", ""], ["Erdem", "Erkut", ""], ["Asfour", "Tamim", ""], ["Ugur", "Emre", ""]]}, {"id": "2102.02125", "submitter": "Lovis Anderson", "authors": "Lovis Anderson, Mark Turner, Thorsten Koch", "title": "Generative deep learning for decision making in gas networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "ZIB Report 20-38", "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A decision support system relies on frequent re-solving of similar problem\ninstances. While the general structure remains the same in corresponding\napplications, the input parameters are updated on a regular basis. We propose a\ngenerative neural network design for learning integer decision variables of\nmixed-integer linear programming (MILP) formulations of these problems. We\nutilise a deep neural network discriminator and a MILP solver as our oracle to\ntrain our generative neural network. In this article, we present the results of\nour design applied to the transient gas optimisation problem. With the trained\nnetwork we produce a feasible solution in 2.5s, use it as a warm-start\nsolution, and thereby decrease global optimal solution solve time by 60.5%.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:06:45 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Anderson", "Lovis", ""], ["Turner", "Mark", ""], ["Koch", "Thorsten", ""]]}, {"id": "2102.02134", "submitter": "Farouq Zitouni", "authors": "Farouq Zitouni, Saad Harous, Abdelghani Belkeram, Lokman Elhakim Baba\n  Hammou", "title": "The Archerfish Hunting Optimizer: a novel metaheuristic algorithm for\n  global optimization", "comments": "41 pages, 14 figures, 41 pages, 132 references, 30 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Global optimization solves real-world problems numerically or analytically by\nminimizing their objective functions. Most of the analytical algorithms are\ngreedy and computationally intractable. Metaheuristics are nature-inspired\noptimization algorithms. They numerically find a near-optimal solution for\noptimization problems in a reasonable amount of time. We propose a novel\nmetaheuristic algorithm for global optimization. It is based on the shooting\nand jumping behaviors of the archerfish for hunting aerial insects. We name it\nthe Archerfish Hunting Optimizer (AHO). We Perform two sorts of comparisons to\nvalidate the proposed algorithm's performance. First, AHO is compared to the 12\nrecent metaheuristic algorithms (the accepted algorithms for the 2020's\ncompetition on single objective bound-constrained numerical optimization) on\nten test functions of the benchmark CEC 2020 for unconstrained optimization.\nSecond, the performance of AHO and 3 recent metaheuristic algorithms, is\nevaluated using five engineering design problems taken from the benchmark CEC\n2020 for non-convex constrained optimization. The experimental results are\nevaluated using the Wilcoxon signed-rank and the Friedman tests. The\nstatistical indicators illustrate that the Archerfish Hunting Optimizer has an\nexcellent ability to accomplish higher performance in competition with the\nwell-established optimizers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:22:31 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Zitouni", "Farouq", ""], ["Harous", "Saad", ""], ["Belkeram", "Abdelghani", ""], ["Hammou", "Lokman Elhakim Baba", ""]]}, {"id": "2102.02189", "submitter": "Young-Suk Lee Dr.", "authors": "Janaki Sheth and Young-Suk Lee and Ramon Fernandez Astudillo and\n  Tahira Naseem and Radu Florian and Salim Roukos and Todd Ward", "title": "Bootstrapping Multilingual AMR with Contextual Word Alignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We develop high performance multilingualAbstract Meaning Representation (AMR)\nsys-tems by projecting English AMR annotationsto other languages with weak\nsupervision. Weachieve this goal by bootstrapping transformer-based\nmultilingual word embeddings, in partic-ular those from cross-lingual RoBERTa\n(XLM-R large). We develop a novel technique forforeign-text-to-English AMR\nalignment, usingthe contextual word alignment between En-glish and foreign\nlanguage tokens. This wordalignment is weakly supervised and relies onthe\ncontextualized XLM-R word embeddings.We achieve a highly competitive\nperformancethat surpasses the best published results forGerman, Italian,\nSpanish and Chinese.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:35:55 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Sheth", "Janaki", ""], ["Lee", "Young-Suk", ""], ["Astudillo", "Ramon Fernandez", ""], ["Naseem", "Tahira", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""], ["Ward", "Todd", ""]]}, {"id": "2102.02201", "submitter": "Peter Hase", "authors": "Peter Hase, Mohit Bansal", "title": "When Can Models Learn From Explanations? A Formal Framework for\n  Understanding the Roles of Explanation Data", "comments": "25 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods now exist for conditioning model outputs on task instructions,\nretrieved documents, and user-provided explanations and feedback. Rather than\nrelying solely on examples of task inputs and outputs, these approaches use\nvaluable additional data for improving model correctness and aligning learned\nmodels with human priors. Meanwhile, a growing body of evidence suggests that\nsome language models can (1) store a large amount of knowledge in their\nparameters, and (2) perform inference over tasks in textual inputs at test\ntime. These results raise the possibility that, for some tasks, humans cannot\nexplain to a model any more about the task than it already knows or could infer\non its own. In this paper, we study the circumstances under which explanations\nof individual data points can (or cannot) improve modeling performance. In\norder to carefully control important properties of the data and explanations,\nwe introduce a synthetic dataset for experiments, and we also make use of three\nexisting datasets with explanations: e-SNLI, TACRED, and SemEval. We first give\na formal framework for the available modeling approaches, in which explanation\ndata can be used as model inputs, as targets, or as a prior. After arguing that\nthe most promising role for explanation data is as model inputs, we propose to\nuse a retrieval-based method and show that it solves our synthetic task with\naccuracies upwards of 95%, while baselines without explanation data achieve\nbelow 65% accuracy. We then identify properties of datasets for which\nretrieval-based modeling fails. With the three existing datasets, we find no\nimprovements from explanation retrieval. Drawing on findings from our synthetic\ntask, we suggest that at least one of six preconditions for successful modeling\nfails to hold with these datasets. Our code is publicly available at\nhttps://github.com/peterbhase/ExplanationRoles\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:57:08 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 20:26:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hase", "Peter", ""], ["Bansal", "Mohit", ""]]}, {"id": "2102.02274", "submitter": "Pol Moreno", "authors": "Pol Moreno, Edward Hughes, Kevin R. McKee, Bernardo Avila Pires,\n  Th\\'eophane Weber", "title": "Neural Recursive Belief States in Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent reinforcement learning, the problem of learning to act is\nparticularly difficult because the policies of co-players may be heavily\nconditioned on information only observed by them. On the other hand, humans\nreadily form beliefs about the knowledge possessed by their peers and leverage\nbeliefs to inform decision-making. Such abilities underlie individual success\nin a wide range of Markov games, from bluffing in Poker to conditional\ncooperation in the Prisoner's Dilemma, to convention-building in Bridge.\nClassical methods are usually not applicable to complex domains due to the\nintractable nature of hierarchical beliefs (i.e. beliefs of other agents'\nbeliefs). We propose a scalable method to approximate these belief structures\nusing recursive deep generative models, and to use the belief models to obtain\nrepresentations useful to acting in complex tasks. Our agents trained with\nbelief models outperform model-free baselines with equivalent representational\ncapacity using common training paradigms. We also show that higher-order belief\nmodels outperform agents with lower-order models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 20:10:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Moreno", "Pol", ""], ["Hughes", "Edward", ""], ["McKee", "Kevin R.", ""], ["Pires", "Bernardo Avila", ""], ["Weber", "Th\u00e9ophane", ""]]}, {"id": "2102.02295", "submitter": "Pavle Bo\\v{s}koski", "authors": "Pavle Bo\\v{s}koski and Matija Perne and Martina Rame\\v{s}a and Biljana\n  Mileva Boshkoska", "title": "Variational Bayes survival analysis for unemployment modelling", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2021.107335", "report-no": null, "categories": "stat.AP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mathematical modelling of unemployment dynamics attempts to predict the\nprobability of a job seeker finding a job as a function of time. This is\ntypically achieved by using information in unemployment records. These records\nare right censored, making survival analysis a suitable approach for parameter\nestimation. The proposed model uses a deep artificial neural network (ANN) as a\nnon-linear hazard function. Through embedding, high-cardinality categorical\nfeatures are analysed efficiently. The posterior distribution of the ANN\nparameters are estimated using a variational Bayes method. The model is\nevaluated on a time-to-employment data set spanning from 2011 to 2020 provided\nby the Slovenian public employment service. It is used to determine the\nemployment probability over time for each individual on the record. Similar\nmodels could be applied to other questions with multi-dimensional,\nhigh-cardinality categorical data including censored records. Such data is\noften encountered in personal records, for example in medical records.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 21:06:54 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 08:41:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bo\u0161koski", "Pavle", ""], ["Perne", "Matija", ""], ["Rame\u0161a", "Martina", ""], ["Boshkoska", "Biljana Mileva", ""]]}, {"id": "2102.02302", "submitter": "Barbara Rychalska", "authors": "Barbara Rychalska, Piotr B\\k{a}bel, Konrad Go{\\l}uchowski, Andrzej\n  Micha{\\l}owski, Jacek D\\k{a}browski", "title": "Cleora: A Simple, Strong and Scalable Graph Embedding Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The area of graph embeddings is currently dominated by contrastive learning\nmethods, which demand formulation of an explicit objective function and\nsampling of positive and negative examples. This creates a conceptual and\ncomputational overhead. Simple, classic unsupervised approaches like\nMultidimensional Scaling (MSD) or the Laplacian eigenmap skip the necessity of\ntedious objective optimization, directly exploiting data geometry.\nUnfortunately, their reliance on very costly operations such as matrix\neigendecomposition make them unable to scale to large graphs that are common in\ntoday's digital world. In this paper we present Cleora: an algorithm which gets\nthe best of two worlds, being both unsupervised and highly scalable. We show\nthat high quality embeddings can be produced without the popular step-wise\nlearning framework with example sampling. An intuitive learning objective of\nour algorithm is that a node should be similar to its neighbors, without\nexplicitly pushing disconnected nodes apart. The objective is achieved by\niterative weighted averaging of node neigbors' embeddings, followed by\nnormalization across dimensions. Thanks to the averaging operation the\nalgorithm makes rapid strides across the embedding space and usually reaches\noptimal embeddings in just a few iterations. Cleora runs faster than other\nstate-of-the-art CPU algorithms and produces embeddings of competitive quality\nas measured on downstream tasks: link prediction and node classification. We\nshow that Cleora learns a data abstraction that is similar to contrastive\nmethods, yet at much lower computational cost. We open-source Cleora under the\nMIT license allowing commercial use under https://github.com/Synerise/cleora.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 21:25:31 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Rychalska", "Barbara", ""], ["B\u0105bel", "Piotr", ""], ["Go\u0142uchowski", "Konrad", ""], ["Micha\u0142owski", "Andrzej", ""], ["D\u0105browski", "Jacek", ""]]}, {"id": "2102.02304", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Zeki Doruk Erden, Boi Faltings", "title": "Improved Cooperation by Exploiting a Common Signal", "comments": "Accepted to the 20th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can artificial agents benefit from human conventions? Human societies manage\nto successfully self-organize and resolve the tragedy of the commons in\ncommon-pool resources, in spite of the bleak prediction of non-cooperative game\ntheory. On top of that, real-world problems are inherently large-scale and of\nlow observability. One key concept that facilitates human coordination in such\nsettings is the use of conventions. Inspired by human behavior, we investigate\nthe learning dynamics and emergence of temporal conventions, focusing on\ncommon-pool resources. Extra emphasis was given in designing a realistic\nevaluation setting: (a) environment dynamics are modeled on real-world\nfisheries, (b) we assume decentralized learning, where agents can observe only\ntheir own history, and (c) we run large-scale simulations (up to 64 agents).\n  Uncoupled policies and low observability make cooperation hard to achieve; as\nthe number of agents grow, the probability of taking a correct gradient\ndirection decreases exponentially. By introducing an arbitrary common signal\n(e.g., date, time, or any periodic set of numbers) as a means to couple the\nlearning process, we show that temporal conventions can emerge and agents reach\nsustainable harvesting strategies. The introduction of the signal consistently\nimproves the social welfare (by 258% on average, up to 3306%), the range of\nenvironmental parameters where sustainability can be achieved (by 46% on\naverage, up to 300%), and the convergence speed in low abundance settings (by\n13% on average, up to 53%).\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 21:27:53 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Erden", "Zeki Doruk", ""], ["Faltings", "Boi", ""]]}, {"id": "2102.02311", "submitter": "Sander Beckers", "authors": "Sander Beckers", "title": "Causal Sufficiency and Actual Causation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearl opened the door to formally defining actual causation using causal\nmodels. His approach rests on two strategies: first, capturing the widespread\nintuition that X=x causes Y=y iff X=x is a Necessary Element of a Sufficient\nSet for Y=y, and second, showing that his definition gives intuitive answers on\na wide set of problem cases. This inspired dozens of variations of his\ndefinition of actual causation, the most prominent of which are due to Halpern\n& Pearl. Yet all of them ignore Pearl's first strategy, and the second strategy\ntaken by itself is unable to deliver a consensus. This paper offers a way out\nby going back to the first strategy: it offers six formal definitions of causal\nsufficiency and two interpretations of necessity. Combining the two gives\ntwelve new definitions of actual causation. Several interesting results about\nthese definitions and their relation to the various Halpern & Pearl definitions\nare presented. Afterwards the second strategy is evaluated as well. In order to\nmaximize neutrality, the paper relies mostly on the examples and intuitions of\nHalpern & Pearl. One definition comes out as being superior to all others, and\nis therefore suggested as a new definition of actual causation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 22:12:49 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Beckers", "Sander", ""]]}, {"id": "2102.02315", "submitter": "Andrew Bradley", "authors": "Sam Garlick and Andrew Bradley", "title": "Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap\n  Time Simulation Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widespread development of driverless vehicles has led to the formation of\nautonomous racing, where technological development is accelerated by the high\nspeeds and competitive environment of motorsport. A particular challenge for an\nautonomous vehicle is that of identifying a target trajectory - or in the case\nof a racing car, the racing line. Many existing approaches to finding the\nracing line are either not time-optimal solutions, or are computationally\nexpensive, thus rendering them unsuitable for real-time application using\non-board processing hardware. This study describes a machine learning approach\nto generating an accurate prediction of the racing line in real-time on desktop\nprocessing hardware. The proposed algorithm is a feed-forward neural network,\ntrained using a dataset comprising racing lines for a large number of circuits\ncalculated via a traditional optimal control lap time simulation. The network\npredicts the racing line with a mean absolute error of +/-0.27m, meaning that\nthe accuracy outperforms a human driver, and is comparable to autonomous\nvehicle control subsystems. The approach generates predictions within 33ms,\nmaking it over 9,000 times faster than traditional methods of finding the\noptimal trajectory. Results suggest that data-driven approaches to find\nnear-optimal racing lines may be favourable to traditional computational\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 22:34:22 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 10:55:43 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 19:47:50 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Garlick", "Sam", ""], ["Bradley", "Andrew", ""]]}, {"id": "2102.02335", "submitter": "Archita Pathak", "authors": "Archita Pathak, Mohammad Abuzar Shaikh, Rohini Srihari", "title": "Self-Supervised Claim Identification for Automated Fact Checking", "comments": "15 pages, 4 figures, Accepted at ICON 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, attention-based self-supervised approach to identify\n\"claim-worthy\" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:37:09 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Pathak", "Archita", ""], ["Shaikh", "Mohammad Abuzar", ""], ["Srihari", "Rohini", ""]]}, {"id": "2102.02340", "submitter": "Zhen Xu", "authors": "Zhen Xu, David R. So, Andrew M. Dai", "title": "MUFASA: Multimodal Fusion Architecture Search for Electronic Health\n  Records", "comments": "Accepted for publication at the Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important challenge of applying deep learning to electronic health\nrecords (EHR) is the complexity of their multimodal structure. EHR usually\ncontains a mixture of structured (codes) and unstructured (free-text) data with\nsparse and irregular longitudinal features -- all of which doctors utilize when\nmaking decisions. In the deep learning regime, determining how different\nmodality representations should be fused together is a difficult problem, which\nis often addressed by handcrafted modeling and intuition. In this work, we\nextend state-of-the-art neural architecture search (NAS) methods and propose\nMUltimodal Fusion Architecture SeArch (MUFASA) to simultaneously search across\nmultimodal fusion strategies and modality-specific architectures for the first\ntime. We demonstrate empirically that our MUFASA method outperforms established\nunimodal NAS on public EHR data with comparable computation costs. In addition,\nMUFASA produces architectures that outperform Transformer and Evolved\nTransformer. Compared with these baselines on CCS diagnosis code prediction,\nour discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate\nthe ability to generalize to other EHR tasks. Studying our top architecture in\ndepth, we provide empirical evidence that MUFASA's improvements are derived\nfrom its ability to both customize modeling for each data modality and find\neffective fusion strategies.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:48:54 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Xu", "Zhen", ""], ["So", "David R.", ""], ["Dai", "Andrew M.", ""]]}, {"id": "2102.02371", "submitter": "Jiangke Lin", "authors": "Jiangke Lin, Yi Yuan, Zhengxia Zou", "title": "MeInGame: Create a Game Character Face from a Single Portrait", "comments": "Accepted to AAAI 2021. Code is now available at\n  https://github.com/FuxiCV/MeInGame", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning based 3D face reconstruction methods have been proposed\nrecently, however, few of them have applications in games. Current game\ncharacter customization systems either require players to manually adjust\nconsiderable face attributes to obtain the desired face, or have limited\nfreedom of facial shape and texture. In this paper, we propose an automatic\ncharacter face creation method that predicts both facial shape and texture from\na single portrait, and it can be integrated into most existing 3D games.\nAlthough 3D Morphable Face Model (3DMM) based methods can restore accurate 3D\nfaces from single images, the topology of 3DMM mesh is different from the\nmeshes used in most games. To acquire fidelity texture, existing methods\nrequire a large amount of face texture data for training, while building such\ndatasets is time-consuming and laborious. Besides, such a dataset collected\nunder laboratory conditions may not generalized well to in-the-wild situations.\nTo tackle these problems, we propose 1) a low-cost facial texture acquisition\nmethod, 2) a shape transfer algorithm that can transform the shape of a 3DMM\nmesh to games, and 3) a new pipeline for training 3D game face reconstruction\nnetworks. The proposed method not only can produce detailed and vivid game\ncharacters similar to the input portrait, but can also eliminate the influence\nof lighting and occlusions. Experiments show that our method outperforms\nstate-of-the-art methods used in games.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 02:12:19 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 03:27:07 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lin", "Jiangke", ""], ["Yuan", "Yi", ""], ["Zou", "Zhengxia", ""]]}, {"id": "2102.02376", "submitter": "Chengmin Zhou", "authors": "Chengmin Zhou, Bingding Huang, Pasi Fr\\\"anti", "title": "A review of motion planning algorithms for intelligent robotics", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate and analyze principles of typical motion planning algorithms.\nThese include traditional planning algorithms, supervised learning, optimal\nvalue reinforcement learning, policy gradient reinforcement learning.\nTraditional planning algorithms we investigated include graph search\nalgorithms, sampling-based algorithms, and interpolating curve algorithms.\nSupervised learning algorithms include MSVM, LSTM, MCTS and CNN. Optimal value\nreinforcement learning algorithms include Q learning, DQN, double DQN, dueling\nDQN. Policy gradient algorithms include policy gradient method, actor-critic\nalgorithm, A3C, A2C, DPG, DDPG, TRPO and PPO. New general criteria are also\nintroduced to evaluate performance and application of motion planning\nalgorithms by analytical comparisons. Convergence speed and stability of\noptimal value and policy gradient algorithms are specially analyzed. Future\ndirections are presented analytically according to principles and analytical\ncomparisons of motion planning algorithms. This paper provides researchers with\na clear and comprehensive understanding about advantages, disadvantages,\nrelationships, and future of motion planning algorithms in robotics, and paves\nways for better motion planning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 02:24:04 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 12:37:20 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhou", "Chengmin", ""], ["Huang", "Bingding", ""], ["Fr\u00e4nti", "Pasi", ""]]}, {"id": "2102.02384", "submitter": "Jean-Pierre Barriot", "authors": "Jean-Pierre Barriot, Neil Davies, Beno\\^it Stoll, S\\'ebastien Chabrier\n  and Alban Gabillon", "title": "A Possible Artificial Intelligence Ecosystem Avatar: the Moorea case\n  (IDEA)", "comments": "Paper presented at the 10th Indo-Pacific Fish Conference, Tahiti, 2-6\n  October 2017, http://ipfc10.sciencesconf.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI nlin.AO q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  High-throughput data collection techniques and largescale (cloud) computing\nare transforming our understanding of ecosystems at all scales by allowing the\nintegration of multimodal data such as physics, chemistry, biology, ecology,\nfishing, economics and other social sciences in a common computational\nframework. We focus in this paper on a large scale data assimilation and\nprediction backbone based on Deep Stacking Networks (DSN) in the frame of the\nIDEA (Island Digital Ecosystem Avatars) project (Moorea Island), based on the\nsubdivision of the island in watersheds and lagoon units. We also describe\nseveral kinds of raw data that can train and constrain such an ecosystem avatar\nmodel, as well as second level data such as ecological or physical indexes /\nindicators.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 02:53:55 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Barriot", "Jean-Pierre", ""], ["Davies", "Neil", ""], ["Stoll", "Beno\u00eet", ""], ["Chabrier", "S\u00e9bastien", ""], ["Gabillon", "Alban", ""]]}, {"id": "2102.02402", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya", "title": "SAFELearning: Enable Backdoor Detectability In Federated Learning With\n  Secure Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For model privacy, local model parameters in federated learning shall be\nobfuscated before sent to the remote aggregator. This technique is referred to\nas \\emph{secure aggregation}. However, secure aggregation makes model poisoning\nattacks, e.g., to insert backdoors, more convenient given existing anomaly\ndetection methods mostly require access to plaintext local models. This paper\nproposes SAFELearning which supports backdoor detection for secure aggregation.\nWe achieve this through two new primitives - \\emph{oblivious random grouping\n(ORG)} and \\emph{partial parameter disclosure (PPD)}. ORG partitions\nparticipants into one-time random subgroups with group configurations oblivious\nto participants; PPD allows secure partial disclosure of aggregated subgroup\nmodels for anomaly detection without leaking individual model privacy.\nSAFELearning is able to significantly reduce backdoor model accuracy without\njeopardizing the main task accuracy under common backdoor strategies. Extensive\nexperiments show SAFELearning reduces backdoor accuracy from $100\\%$ to $8.2\\%$\nfor ResNet-18 over CIFAR-10 when $10\\%$ participants are malicious.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 04:07:39 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Jiarui", ""], ["Yu", "Shucheng", ""], ["Makaya", "Christian", ""]]}, {"id": "2102.02417", "submitter": "Kai Yuan Tay", "authors": "Kai Yuan Tay, Lynnette Ng, Wei Han Chua, Lucerne Loke, Danqi Ye,\n  Melissa Chua", "title": "Audio Adversarial Examples: Attacks Using Vocal Masks", "comments": "9 pages, 1 figure, 2 tables. Submitted to COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We construct audio adversarial examples on automatic Speech-To-Text systems .\nGiven any audio waveform, we produce an another by overlaying an audio vocal\nmask generated from the original audio. We apply our audio adversarial attack\nto five SOTA STT systems: DeepSpeech, Julius, Kaldi, wav2letter@anywhere and\nCMUSphinx. In addition, we engaged human annotators to transcribe the\nadversarial audio. Our experiments show that these adversarial examples fool\nState-Of-The-Art Speech-To-Text systems, yet humans are able to consistently\npick out the speech. The feasibility of this attack introduces a new domain to\nstudy machine and human perception of speech.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 05:21:10 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 03:31:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tay", "Kai Yuan", ""], ["Ng", "Lynnette", ""], ["Chua", "Wei Han", ""], ["Loke", "Lucerne", ""], ["Ye", "Danqi", ""], ["Chua", "Melissa", ""]]}, {"id": "2102.02441", "submitter": "Francisco Cruz", "authors": "Adam Bignold and Francisco Cruz and Richard Dazeley and Peter Vamplew\n  and Cameron Foale", "title": "Persistent Rule-based Interactive Reinforcement Learning", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive reinforcement learning has allowed speeding up the learning\nprocess in autonomous agents by including a human trainer providing extra\ninformation to the agent in real-time. Current interactive reinforcement\nlearning research has been limited to interactions that offer relevant advice\nto the current state only. Additionally, the information provided by each\ninteraction is not retained and instead discarded by the agent after a\nsingle-use. In this work, we propose a persistent rule-based interactive\nreinforcement learning approach, i.e., a method for retaining and reusing\nprovided knowledge, allowing trainers to give general advice relevant to more\nthan just the current state. Our experimental results show persistent advice\nsubstantially improves the performance of the agent while reducing the number\nof interactions required for the trainer. Moreover, rule-based advice shows\nsimilar performance impact as state-based advice, but with a substantially\nreduced interaction count.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 06:48:57 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Bignold", "Adam", ""], ["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""]]}, {"id": "2102.02454", "submitter": "Mingqi Yuan", "authors": "Mingqi Yuan, Man-On Pun, Yi Chen", "title": "Hybrid Adversarial Inverse Reinforcement Learning", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extrapolating beyond-demonstrator (BD) through the inverse reinforcement\nlearning (IRL) algorithm aims to learn from and outperform the demonstrator. In\nsharp contrast to the conventional reinforcement learning (RL) algorithms,\nBD-IRL can overcome the dilemma incurred in the reward function design and\nimprove the exploration mechanism of RL, which opens new avenues to building\nsuperior expert systems. Most existing BD-IRL algorithms are performed in two\nstages by first inferring a reward function before learning a policy via RL.\nHowever, such two-stage BD-IRL algorithms suffer from high computational\ncomplexity, weak robustness, and large performance variations. In particular, a\npoor reward function derived in the first stage will inevitably incur severe\nperformance loss in the second stage. In this work, we propose a hybrid\nadversarial inverse reinforcement learning (HAIRL) algorithm that is one-stage,\nmodel-free, generative-adversarial (GA) fashion and curiosity-driven. Thanks to\nthe one-stage design, the HAIRL can integrate both the reward function learning\nand the policy optimization into one procedure, which leads to many advantages\nsuch as low computational complexity, high robustness, and strong adaptability.\nMore specifically, HAIRL simultaneously imitates the demonstrator and explores\nBD performance by utilizing hybrid rewards. In particular, the Wasserstein-1\ndistance (WD) is introduced into HAIRL to stabilize the imitation procedure\nwhile a novel end-to-end curiosity module (ECM) is developed to improve the\nexploration. Finally, extensive simulation results confirm that HAIRL can\nachieve higher performance as compared to other similar BD-IRL algorithms. Our\ncode is available at our GitHub website\n\\footnote{\\url{https://github.com/yuanmingqi/HAIRL}}.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 07:27:50 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 03:42:55 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 13:36:37 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 12:26:01 GMT"}, {"version": "v5", "created": "Sat, 17 Apr 2021 06:36:30 GMT"}, {"version": "v6", "created": "Fri, 14 May 2021 08:54:55 GMT"}, {"version": "v7", "created": "Mon, 24 May 2021 06:20:29 GMT"}, {"version": "v8", "created": "Fri, 28 May 2021 03:09:13 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Yuan", "Mingqi", ""], ["Pun", "Man-On", ""], ["Chen", "Yi", ""]]}, {"id": "2102.02463", "submitter": "Juhyung Park", "authors": "Juhung Park, Woojin Jung, Eun-Jung Choi, Se-Hong Oh, Dongmyung Shin,\n  Hongjun An, and Jongho Lee", "title": "DIFFnet: Diffusion parameter mapping network generalized for input\n  diffusion gradient schemes and bvalues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI physics.med-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In MRI, deep neural networks have been proposed to reconstruct diffusion\nmodel parameters. However, the inputs of the networks were designed for a\nspecific diffusion gradient scheme (i.e., diffusion gradient directions and\nnumbers) and a specific b-value that are the same as the training data. In this\nstudy, a new deep neural network, referred to as DIFFnet, is developed to\nfunction as a generalized reconstruction tool of the diffusion-weighted signals\nfor various gradient schemes and b-values. For generalization, diffusion\nsignals are normalized in a q-space and then projected and quantized, producing\na matrix (Qmatrix) as an input for the network. To demonstrate the validity of\nthis approach, DIFFnet is evaluated for diffusion tensor imaging (DIFFnetDTI)\nand for neurite orientation dispersion and density imaging (DIFFnetNODDI). In\neach model, two datasets with different gradient schemes and b-values are\ntested. The results demonstrate accurate reconstruction of the diffusion\nparameters at substantially reduced processing time (approximately 8.7 times\nand 2240 times faster processing time than conventional methods in DTI and\nNODDI, respectively; less than 4% mean normalized root-mean-square errors\n(NRMSE) in DTI and less than 8% in NODDI). The generalization capability of the\nnetworks was further validated using reduced numbers of diffusion signals from\nthe datasets. Different from previously proposed deep neural networks, DIFFnet\ndoes not require any specific gradient scheme and b-value for its input. As a\nresult, it can be adopted as an online reconstruction tool for various complex\ndiffusion imaging.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 07:45:36 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Park", "Juhung", ""], ["Jung", "Woojin", ""], ["Choi", "Eun-Jung", ""], ["Oh", "Se-Hong", ""], ["Shin", "Dongmyung", ""], ["An", "Hongjun", ""], ["Lee", "Jongho", ""]]}, {"id": "2102.02472", "submitter": "Hyejin Park", "authors": "Hyejin Park and Seiyun Shin and Kwang-Sung Jun and Jungseul Ok", "title": "Transfer Learning in Bandits with Latent Continuity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structured stochastic multi-armed bandits provide accelerated regret rates\nover the standard unstructured bandit problems. Most structured bandits,\nhowever, assume the knowledge of the structural parameter such as Lipschitz\ncontinuity, which is often not available. To cope with the latent structural\nparameter, we consider a transfer learning setting in which an agent must learn\nto transfer the structural information from the prior tasks to the next task,\nwhich is inspired by practical problems such as rate adaptation in wireless\nlink. We propose a novel framework to provably and accurately estimate the\nLipschitz constant based on previous tasks and fully exploit it for the new\ntask at hand. We analyze the efficiency of the proposed framework in two folds:\n(i) the sample complexity of our estimator matches with the\ninformation-theoretic fundamental limit; and (ii) our regret bound on the new\ntask is close to that of the oracle algorithm with the full knowledge of the\nLipschitz constant under mild assumptions. Our analysis reveals a set of useful\ninsights on transfer learning for latent Lipschitzconstants such as the\nfundamental challenge a learner faces. Our numerical evaluations confirm our\ntheoretical findings and show the superiority of the proposed framework\ncompared to baselines.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 08:19:12 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 17:28:47 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Park", "Hyejin", ""], ["Shin", "Seiyun", ""], ["Jun", "Kwang-Sung", ""], ["Ok", "Jungseul", ""]]}, {"id": "2102.02551", "submitter": "Yang Zhang", "authors": "Yugeng Liu and Rui Wen and Xinlei He and Ahmed Salem and Zhikun Zhang\n  and Michael Backes and Emiliano De Cristofaro and Mario Fritz and Yang Zhang", "title": "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine\n  Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inference attacks against Machine Learning (ML) models allow adversaries to\nlearn information about training data, model parameters, etc. While researchers\nhave studied these attacks thoroughly, they have done so in isolation. We lack\na comprehensive picture of the risks caused by the attacks, such as the\ndifferent scenarios they can be applied to, the common factors that influence\ntheir performance, the relationship among them, or the effectiveness of defense\ntechniques. In this paper, we fill this gap by presenting a first-of-its-kind\nholistic risk assessment of different inference attacks against machine\nlearning models. We concentrate on four attacks - namely, membership inference,\nmodel inversion, attribute inference, and model stealing - and establish a\nthreat model taxonomy. Our extensive experimental evaluation conducted over\nfive model architectures and four datasets shows that the complexity of the\ntraining dataset plays an important role with respect to the attack's\nperformance, while the effectiveness of model stealing and membership inference\nattacks are negatively correlated. We also show that defenses like DP-SGD and\nKnowledge Distillation can only hope to mitigate some of the inference attacks.\nOur analysis relies on a modular re-usable software, ML-Doctor, which enables\nML model owners to assess the risks of deploying their models, and equally\nserves as a benchmark tool for researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:35:13 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Liu", "Yugeng", ""], ["Wen", "Rui", ""], ["He", "Xinlei", ""], ["Salem", "Ahmed", ""], ["Zhang", "Zhikun", ""], ["Backes", "Michael", ""], ["De Cristofaro", "Emiliano", ""], ["Fritz", "Mario", ""], ["Zhang", "Yang", ""]]}, {"id": "2102.02558", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Aritz D. Martinez and Javier Del Ser", "title": "Evolutionary Multitask Optimization: a Methodological Overview,\n  Challenges and Future Research Directions", "comments": "29 pages, 4 figures, under review for its consideration in Applied\n  Soft Computing journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider multitasking in the context of solving multiple\noptimization problems simultaneously by conducting a single search process. The\nprincipal goal when dealing with this scenario is to dynamically exploit the\nexisting complementarities among the problems (tasks) being optimized, helping\neach other through the exchange of valuable knowledge. Additionally, the\nemerging paradigm of Evolutionary Multitasking tackles multitask optimization\nscenarios by using as inspiration concepts drawn from Evolutionary Computation.\nThe main purpose of this survey is to collect, organize and critically examine\nthe abundant literature published so far in Evolutionary Multitasking, with an\nemphasis on the methodological patterns followed when designing new algorithmic\nproposals in this area (namely, multifactorial optimization and\nmultipopulation-based multitasking). We complement our critical analysis with\nan identification of challenges that remain open to date, along with promising\nresearch directions that can stimulate future efforts in this topic. Our\ndiscussions held throughout this manuscript are offered to the audience as a\nreference of the general trajectory followed by the community working in this\nfield in recent times, as well as a self-contained entry point for newcomers\nand researchers interested to join this exciting research avenue.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:48:11 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Del Ser", "Javier", ""]]}, {"id": "2102.02576", "submitter": "Tom Hanika", "authors": "Tom Hanika and Johannes Hirth", "title": "Exploring Scale-Measures of Data Sets", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurement is a fundamental building block of numerous scientific models and\ntheir creation. This is in particular true for data driven science. Due to the\nhigh complexity and size of modern data sets, the necessity for the development\nof understandable and efficient scaling methods is at hand. A profound theory\nfor scaling data is scale-measures, as developed in the field of formal concept\nanalysis. Recent developments indicate that the set of all scale-measures for a\ngiven data set constitutes a lattice and does hence allow efficient exploring\nalgorithms. In this work we study the properties of said lattice and propose a\nnovel scale-measure exploration algorithm that is based on the well-known and\nproven attribute exploration approach. Our results motivate multiple\napplications in scale recommendation, most prominently (semi-)automatic\nscaling.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 12:29:15 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hanika", "Tom", ""], ["Hirth", "Johannes", ""]]}, {"id": "2102.02586", "submitter": "Bhagya Hettige", "authors": "Bhagya Hettige, Weiqing Wang, Yuan-Fang Li, Suong Le, Wray Buntine", "title": "Temporal Cascade and Structural Modelling of EHRs for Granular\n  Readmission Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting (1) when the next hospital admission occurs and (2) what will\nhappen in the next admission about a patient by mining electronic health record\n(EHR) data can provide granular readmission predictions to assist clinical\ndecision making. Recurrent neural network (RNN) and point process models are\nusually employed in modelling temporal sequential data. Simple RNN models\nassume that sequences of hospital visits follow strict causal dependencies\nbetween consecutive visits. However, in the real-world, a patient may have\nmultiple co-existing chronic medical conditions, i.e., multimorbidity, which\nresults in a cascade of visits where a non-immediate historical visit can be\nmost influential to the next visit. Although a point process (e.g., Hawkes\nprocess) is able to model a cascade temporal relationship, it strongly relies\non a prior generative process assumption. We propose a novel model, MEDCAS, to\naddress these challenges. MEDCAS combines the strengths of RNN-based models and\npoint processes by integrating point processes in modelling visit types and\ntime gaps into an attention-based sequence-to-sequence learning model, which is\nable to capture the temporal cascade relationships. To supplement the patients\nwith short visit sequences, a structural modelling technique with graph-based\nmethods is used to construct the markers of the point process in MEDCAS.\nExtensive experiments on three real-world EHR datasets have been performed and\nthe results demonstrate that \\texttt{MEDCAS} outperforms state-of-the-art\nmodels in both tasks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 13:02:04 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hettige", "Bhagya", ""], ["Wang", "Weiqing", ""], ["Li", "Yuan-Fang", ""], ["Le", "Suong", ""], ["Buntine", "Wray", ""]]}, {"id": "2102.02631", "submitter": "Jian-Jia Chen", "authors": "Mikail Yayla, Mario G\\\"unzel, Burim Ramosaj, and Jian-Jia Chen", "title": "Universal Approximation Theorems of Fully Connected Binarized Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks (NNs) are known for their high predictive accuracy in complex\nlearning problems. Beside practical advantages, NNs also indicate favourable\ntheoretical properties such as universal approximation (UA) theorems. Binarized\nNeural Networks (BNNs) significantly reduce time and memory demands by\nrestricting the weight and activation domains to two values. Despite the\npractical advantages, theoretical guarantees based on UA theorems of BNNs are\nrather sparse in the literature. We close this gap by providing UA theorems for\nfully connected BNNs under the following scenarios: (1) for binarized inputs,\nUA can be constructively achieved under one hidden layer; (2) for inputs with\nreal numbers, UA can not be achieved under one hidden layer but can be\nconstructively achieved under two hidden layers for Lipschitz-continuous\nfunctions. Our results indicate that fully connected BNNs can approximate\nfunctions universally, under certain conditions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:30:24 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yayla", "Mikail", ""], ["G\u00fcnzel", "Mario", ""], ["Ramosaj", "Burim", ""], ["Chen", "Jian-Jia", ""]]}, {"id": "2102.02637", "submitter": "A mallikarjuna Reddy dr", "authors": "Swarajya Lakshmi V Papineni, Snigdha Yarlagadda, Harita Akkineni, A.\n  Mallikarjuna Reddy", "title": "Big Data Analytics Applying the Fusion Approach of Multicriteria\n  Decision Making with Deep Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data is evolving with the rapid progress of population and communication for\nvarious types of devices such as networks, cloud computing, Internet of Things\n(IoT), actuators, and sensors. The increment of data and communication content\ngoes with the equivalence of velocity, speed, size, and value to provide the\nuseful and meaningful knowledge that helps to solve the future challenging\ntasks and latest issues. Besides, multicriteria based decision making is one of\nthe key issues to solve for various issues related to the alternative effects\nin big data analysis. It tends to find a solution based on the latest machine\nlearning techniques that include algorithms like decision making and deep\nlearning mechanism based on multicriteria in providing insights to big data. On\nthe other hand, the derivations are made for it to go with the approximations\nto increase the duality of runtime and improve the entire system's potentiality\nand efficacy. In essence, several fields, including business, agriculture,\ninformation technology, and computer science, use deep learning and\nmulticriteria-based decision-making problems. This paper aims to provide\nvarious applications that involve the concepts of deep learning techniques and\nexploiting the multicriteria approaches for issues that are facing in big data\nanalytics by proposing new studies with the fusion approaches of data-driven\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 05:56:03 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Papineni", "Swarajya Lakshmi V", ""], ["Yarlagadda", "Snigdha", ""], ["Akkineni", "Harita", ""], ["Reddy", "A. Mallikarjuna", ""]]}, {"id": "2102.02638", "submitter": "Letian Zhang", "authors": "Letian Zhang, Lixing Chen, Jie Xu", "title": "Autodidactic Neurosurgeon: Collaborative Deep Inference for Mobile Edge\n  Intelligence via Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in deep learning (DL) have led to the emergence of many\nintelligent mobile applications and services, but in the meanwhile also pose\nunprecedented computing challenges on resource-constrained mobile devices. This\npaper builds a collaborative deep inference system between a\nresource-constrained mobile device and a powerful edge server, aiming at\njoining the power of both on-device processing and computation offloading. The\nbasic idea of this system is to partition a deep neural network (DNN) into a\nfront-end part running on the mobile device and a back-end part running on the\nedge server, with the key challenge being how to locate the optimal partition\npoint to minimize the end-to-end inference delay. Unlike existing efforts on\nDNN partitioning that rely heavily on a dedicated offline profiling stage to\nsearch for the optimal partition point, our system has a built-in online\nlearning module, called Autodidactic Neurosurgeon (ANS), to automatically learn\nthe optimal partition point on-the-fly. Therefore, ANS is able to closely\nfollow the changes of the system environment by generating new knowledge for\nadaptive decision making. The core of ANS is a novel contextual bandit learning\nalgorithm, called $\\mu$LinUCB, which not only has provable theoretical learning\nperformance guarantee but also is ultra-lightweight for easy real-world\nimplementation. We implement our system on a video stream object detection\ntestbed to validate the design of ANS and evaluate its performance. The\nexperiments show that ANS significantly outperforms state-of-the-art benchmarks\nin terms of tracking system changes and reducing the end-to-end inference\ndelay.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:50:06 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Letian", ""], ["Chen", "Lixing", ""], ["Xu", "Jie", ""]]}, {"id": "2102.02639", "submitter": "Matthew Taylor", "authors": "Matthew E. Taylor, Nicholas Nissen, Yuan Wang, Neda Navidi", "title": "Improving Reinforcement Learning with Human Assistance: An Argument for\n  Human Subject Studies with HIPPO Gym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reinforcement learning (RL) is a popular machine learning paradigm for game\nplaying, robotics control, and other sequential decision tasks. However, RL\nagents often have long learning times with high data requirements because they\nbegin by acting randomly. In order to better learn in complex tasks, this\narticle argues that an external teacher can often significantly help the RL\nagent learn.\n  OpenAI Gym is a common framework for RL research, including a large number of\nstandard environments and agents, making RL research significantly more\naccessible. This article introduces our new open-source RL framework, the Human\nInput Parsing Platform for Openai Gym (HIPPO Gym), and the design decisions\nthat went into its creation. The goal of this platform is to facilitate\nhuman-RL research, again lowering the bar so that more researchers can quickly\ninvestigate different ways that human teachers could assist RL agents,\nincluding learning from demonstrations, learning from feedback, or curriculum\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 12:56:02 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Taylor", "Matthew E.", ""], ["Nissen", "Nicholas", ""], ["Wang", "Yuan", ""], ["Navidi", "Neda", ""]]}, {"id": "2102.02649", "submitter": "Kleber Padovani", "authors": "Kleber Padovani, Roberto Xavier, Andre Carvalho, Anna Reali, Annie\n  Chateau, Ronnie Alves", "title": "A step towards a reinforcement learning de novo genome assembler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of reinforcement learning has proven to be very promising for solving\ncomplex activities without human supervision during their learning process.\nHowever, their successful applications are predominantly focused on fictional\nand entertainment problems - such as games. Based on the above, this work aims\nto shed light on the application of reinforcement learning to solve this\nrelevant real-world problem, the genome assembly. By expanding the only\napproach found in the literature that addresses this problem, we carefully\nexplored the aspects of intelligent agent learning, performed by the Q-learning\nalgorithm, to understand its suitability to be applied in scenarios whose\ncharacteristics are more similar to those faced by real genome projects. The\nimprovements proposed here include changing the previously proposed reward\nsystem and including state space exploration optimization strategies based on\ndynamic pruning and mutual collaboration with evolutionary computing. These\ninvestigations were tried on 23 new environments with larger inputs than those\nused previously. All these environments are freely available on the internet\nfor the evolution of this research by the scientific community. The results\nsuggest consistent performance progress using the proposed improvements,\nhowever, they also demonstrate the limitations of them, especially related to\nthe high dimensionality of state and action spaces. We also present, later, the\npaths that can be traced to tackle genome assembly efficiently in real\nscenarios considering recent, successfully reinforcement learning applications\n- including deep reinforcement learning - from other domains dealing with\nhigh-dimensional inputs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 23:43:42 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 23:16:39 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Padovani", "Kleber", ""], ["Xavier", "Roberto", ""], ["Carvalho", "Andre", ""], ["Reali", "Anna", ""], ["Chateau", "Annie", ""], ["Alves", "Ronnie", ""]]}, {"id": "2102.02654", "submitter": "Maximilian Felde", "authors": "Maximilian Felde and Gerd Stumme", "title": "Triadic Exploration and Exploration with Multiple Experts", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal Concept Analysis (FCA) provides a method called attribute exploration\nwhich helps a domain expert discover structural dependencies in knowledge\ndomains that can be represented by a formal context (a cross table of objects\nand attributes). Triadic Concept Analysis is an extension of FCA that\nincorporates the notion of conditions. Many extensions and variants of\nattribute exploration have been studied but only few attempts at incorporating\nmultiple experts have been made. In this paper we present triadic exploration\nbased on Triadic Concept Analysis to explore conditional attribute implications\nin a triadic domain. We then adapt this approach to formulate attribute\nexploration with multiple experts that have different views on a domain.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 14:49:53 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Felde", "Maximilian", ""], ["Stumme", "Gerd", ""]]}, {"id": "2102.02662", "submitter": "Alexey Chernyavskiy", "authors": "Elvira Zainulina, Alexey Chernyavskiy, Dmitry V. Dylov", "title": "No-reference denoising of low-dose CT projections", "comments": "Accepted to ISBI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low-dose computed tomography (LDCT) became a clear trend in radiology with an\naspiration to refrain from delivering excessive X-ray radiation to the\npatients. The reduction of the radiation dose decreases the risks to the\npatients but raises the noise level, affecting the quality of the images and\ntheir ultimate diagnostic value. One mitigation option is to consider pairs of\nlow-dose and high-dose CT projections to train a denoising model using deep\nlearning algorithms; however, such pairs are rarely available in practice. In\nthis paper, we present a new self-supervised method for CT denoising. Unlike\nexisting self-supervised approaches, the proposed method requires only noisy CT\nprojections and exploits the connections between adjacent images. The\nexperiments carried out on an LDCT dataset demonstrate that our method is\nalmost as accurate as the supervised approach, while also outperforming the\nconsidered self-supervised denoising methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 13:51:33 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zainulina", "Elvira", ""], ["Chernyavskiy", "Alexey", ""], ["Dylov", "Dmitry V.", ""]]}, {"id": "2102.02665", "submitter": "Christian Schorr", "authors": "Christian Schorr", "title": "Hybrid consistency and plausibility verification of product data\n  according to FIC", "comments": "42 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The labelling of food products in the EU is regulated by the Food Information\nof Customers (FIC). Companies are required to provide the corresponding\ninformation regarding nutrients and allergens among others. With the rise of\ne-commerce more and more food products are sold online. There are often errors\nin the online product descriptions regarding the FIC-relevant information due\nto low data quality in the vendors' product data base. In this paper we propose\na hybrid approach of both rule-based and machine learning to verify nutrient\ndeclaration and allergen labelling according to FIC requirements. Special focus\nis given to the problem of false negatives in allergen prediction since this\nposes a significant health risk to customers. Results show that a neural net\ntrained on a subset of the ingredients of a product is capable of predicting\nthe allergens contained with a high reliability.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 11:37:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Schorr", "Christian", ""]]}, {"id": "2102.02670", "submitter": "Huiyuan Deng", "authors": "Huiyuan Deng, Xiangzhu Meng, Lin Feng", "title": "Multimodal-Aware Weakly Supervised Metric Learning with Self-weighting\n  Triplet Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, we have witnessed a surge of interests in learning a\nsuitable distance metric from weakly supervised data. Most existing methods aim\nto pull all the similar samples closer while push the dissimilar ones as far as\npossible. However, when some classes of the dataset exhibit multimodal\ndistribution, these goals conflict and thus can hardly be concurrently\nsatisfied. Additionally, to ensure a valid metric, many methods require a\nrepeated eigenvalue decomposition process, which is expensive and numerically\nunstable. Therefore, how to learn an appropriate distance metric from weakly\nsupervised data remains an open but challenging problem. To address this issue,\nin this paper, we propose a novel weakly supervised metric learning algorithm,\nnamed MultimoDal Aware weakly supervised Metric Learning (MDaML). MDaML\npartitions the data space into several clusters and allocates the local cluster\ncenters and weight for each sample. Then, combining it with the weighted\ntriplet loss can further enhance the local separability, which encourages the\nlocal dissimilar samples to keep a large distance from the local similar\nsamples. Meanwhile, MDaML casts the metric learning problem into an\nunconstrained optimization on the SPD manifold, which can be efficiently solved\nby Riemannian Conjugate Gradient Descent (RCGD). Extensive experiments\nconducted on 13 datasets validate the superiority of the proposed MDaML.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 07:27:05 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Deng", "Huiyuan", ""], ["Meng", "Xiangzhu", ""], ["Feng", "Lin", ""]]}, {"id": "2102.02671", "submitter": "Tim Miller", "authors": "Ronal Singh, Paul Dourish, Piers Howe, Tim Miller, Liz Sonenberg,\n  Eduardo Velloso and Frank Vetere", "title": "Directive Explanations for Actionable Explainability in Machine Learning\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the prospects of using directive explanations to\nassist people in achieving recourse of machine learning decisions. Directive\nexplanations list which specific actions an individual needs to take to achieve\ntheir desired outcome. If a machine learning model makes a decision that is\ndetrimental to an individual (e.g. denying a loan application), then it needs\nto both explain why it made that decision and also explain how the individual\ncould obtain their desired outcome (if possible). At present, this is often\ndone using counterfactual explanations, but such explanations generally do not\ntell individuals how to act. We assert that counterfactual explanations can be\nimproved by explicitly providing people with actions they could use to achieve\ntheir desired goal. This paper makes two contributions. First, we present the\nresults of an online study investigating people's perception of directive\nexplanations. Second, we propose a conceptual model to generate such\nexplanations. Our online study showed a significant preference for directive\nexplanations ($p<0.001$). However, the participants' preferred explanation type\nwas affected by multiple factors, such as individual preferences, social\nfactors, and the feasibility of the directives. Our findings highlight the need\nfor a human-centred and context-specific approach for creating directive\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 01:46:55 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Singh", "Ronal", ""], ["Dourish", "Paul", ""], ["Howe", "Piers", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Velloso", "Eduardo", ""], ["Vetere", "Frank", ""]]}, {"id": "2102.02680", "submitter": "Nguyen Vo", "authors": "Nguyen Vo, Kyumin Lee", "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "comments": "EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:18:44 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Vo", "Nguyen", ""], ["Lee", "Kyumin", ""]]}, {"id": "2102.02705", "submitter": "Rajesh Bordawekar", "authors": "Rajesh Bordawekar and Bulent Abali and Ming-Hung Chen", "title": "EFloat: Entropy-coded Floating Point Format for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the EFloat floating-point number format with 4 to 6 additional\nbits of precision and a wider exponent range than the existing floating point\n(FP) formats of any width including FP32, BFloat16, IEEE-Half precision,\nDLFloat, TensorFloat, and 8-bit floats. In a large class of deep learning\nmodels we observe that FP exponent values tend to cluster around few unique\nvalues which presents entropy encoding opportunities. The EFloat format encodes\nfrequent exponent values and signs with Huffman codes to minimize the average\nexponent field width. Saved bits then become available to the mantissa\nincreasing the EFloat numeric precision on average by 4 to 6 bits compared to\nother FP formats of equal width. The proposed encoding concept may be\nbeneficial to low-precision formats including 8-bit floats. Training deep\nlearning models with low precision arithmetic is challenging. EFloat, with its\nincreased precision may provide an opportunity for those tasks as well. We\ncurrently use the EFloat format for compressing and saving memory used in large\nNLP deep learning models. A potential hardware implementation for improving\nPCIe and memory bandwidth limitations of AI accelerators is also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 15:58:01 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Bordawekar", "Rajesh", ""], ["Abali", "Bulent", ""], ["Chen", "Ming-Hung", ""]]}, {"id": "2102.02753", "submitter": "Efthymia Tsamoura", "authors": "Efthymia Tsamoura, David Carral, Enrico Malizia, Jacopo Urbani", "title": "Materializing Knowledge Bases via Trigger Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The chase is a well-established family of algorithms used to materialize\nKnowledge Bases (KBs), like Knowledge Graphs (KGs), to tackle important tasks\nlike query answering under dependencies or data cleaning. A general problem of\nchase algorithms is that they might perform redundant computations. To counter\nthis problem, we introduce the notion of Trigger Graphs (TGs), which guide the\nexecution of the rules avoiding redundant computations. We present the results\nof an extensive theoretical and empirical study that seeks to answer when and\nhow TGs can be computed and what are the benefits of TGs when applied over\nreal-world KBs. Our results include introducing algorithms that compute\n(minimal) TGs. We implemented our approach in a new engine, and our experiments\nshow that it can be significantly more efficient than the chase enabling us to\nmaterialize KBs with 17B facts in less than 40 min on commodity machines.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:31:25 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Tsamoura", "Efthymia", ""], ["Carral", "David", ""], ["Malizia", "Enrico", ""], ["Urbani", "Jacopo", ""]]}, {"id": "2102.02758", "submitter": "Manuel Eggimann", "authors": "Manuel Eggimann, Abbas Rahimi, Luca Benini", "title": "A 5 \\mu W Standard Cell Memory-based Configurable Hyperdimensional\n  Computing Accelerator for Always-on Smart Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperdimensional computing (HDC) is a brain-inspired computing paradigm based\non high-dimensional holistic representations of vectors. It recently gained\nattention for embedded smart sensing due to its inherent error-resiliency and\nsuitability to highly parallel hardware implementations. In this work, we\npropose a programmable all-digital CMOS implementation of a fully autonomous\nHDC accelerator for always-on classification in energy-constrained sensor\nnodes. By using energy-efficient standard cell memory (SCM), the design is\neasily cross-technology mappable. It achieves extremely low power, 5 $\\mu W$ in\ntypical applications, and an energy-efficiency improvement over the\nstate-of-the-art (SoA) digital architectures of up to 3$\\times$ in post-layout\nsimulations for always-on wearable tasks such as EMG gesture recognition. As\npart of the accelerator's architecture, we introduce novel hardware-friendly\nembodiments of common HDC-algorithmic primitives, which results in 3.3$\\times$\ntechnology scaled area reduction over the SoA, achieving the same accuracy\nlevels in all examined targets. The proposed architecture also has a fully\nconfigurable datapath using microcode optimized for HDC stored on an integrated\nSCM based configuration memory, making the design \"general-purpose\" in terms of\nHDC algorithm flexibility. This flexibility allows usage of the accelerator\nacross novel HDC tasks, for instance, a newly designed HDC applied to the task\nof ball bearing fault detection.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:41:29 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Eggimann", "Manuel", ""], ["Rahimi", "Abbas", ""], ["Benini", "Luca", ""]]}, {"id": "2102.02779", "submitter": "Jaemin Cho", "authors": "Jaemin Cho, Jie Lei, Hao Tan, Mohit Bansal", "title": "Unifying Vision-and-Language Tasks via Text Generation", "comments": "ICML 2021 (15 pages, 4 figures, 14 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for vision-and-language learning typically require designing\ntask-specific architectures and objectives for each task. For example, a\nmulti-label answer classifier for visual question answering, a region scorer\nfor referring expression comprehension, and a language decoder for image\ncaptioning, etc. To alleviate these hassles, in this work, we propose a unified\nframework that learns different tasks in a single architecture with the same\nlanguage modeling objective, i.e., multimodal conditional text generation,\nwhere our models learn to generate labels in text based on the visual and\ntextual inputs. On 7 popular vision-and-language benchmarks, including visual\nquestion answering, referring expression comprehension, visual commonsense\nreasoning, most of which have been previously modeled as discriminative tasks,\nour generative approach (with a single unified architecture) reaches comparable\nperformance to recent task-specific state-of-the-art vision-and-language\nmodels. Moreover, our generative approach shows better generalization ability\non questions that have rare answers. Also, we show that our framework allows\nmulti-task learning in a single architecture with a single set of parameters,\nachieving similar performance to separately optimized single-task models. Our\ncode is publicly available at: https://github.com/j-min/VL-T5\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 17:59:30 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 23:12:46 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cho", "Jaemin", ""], ["Lei", "Jie", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2102.02783", "submitter": "Lia Morra", "authors": "F. Gabriele Prattic\\`o, Fabrizio Lamberti, Alberto Cannav\\`o, Lia\n  Morra, Paolo Montuschi", "title": "Comparing State-of-the-Art and Emerging Augmented Reality Interfaces for\n  Autonomous Vehicle-to-Pedestrian Communication", "comments": "Accepted for publication in IEEE Transactions on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing pedestrians and other vulnerable road users with a clear indication\nabout a fully autonomous vehicle status and intentions is crucial to make them\ncoexist. In the last few years, a variety of external interfaces have been\nproposed, leveraging different paradigms and technologies including\nvehicle-mounted devices (like LED panels), short-range on-road projections, and\nroad infrastructure interfaces (e.g., special asphalts with embedded displays).\nThese designs were experimented in different settings, using mockups, specially\nprepared vehicles, or virtual environments, with heterogeneous evaluation\nmetrics. Promising interfaces based on Augmented Reality (AR) have been\nproposed too, but their usability and effectiveness have not been tested yet.\nThis paper aims to complement such body of literature by presenting a\ncomparison of state-of-the-art interfaces and new designs under common\nconditions. To this aim, an immersive Virtual Reality-based simulation was\ndeveloped, recreating a well-known scenario represented by pedestrians crossing\nin urban environments under non-regulated conditions. A user study was then\nperformed to investigate the various dimensions of vehicle-to-pedestrian\ninteraction leveraging objective and subjective metrics. Even though no\ninterface clearly stood out over all the considered dimensions, one of the AR\ndesigns achieved state-of-the-art results in terms of safety and trust, at the\ncost of higher cognitive effort and lower intuitiveness compared to LED panels\nshowing anthropomorphic features. Together with rankings on the various\ndimensions, indications about advantages and drawbacks of the various\nalternatives that emerged from this study could provide important information\nfor next developments in the field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:03:06 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Prattic\u00f2", "F. Gabriele", ""], ["Lamberti", "Fabrizio", ""], ["Cannav\u00f2", "Alberto", ""], ["Morra", "Lia", ""], ["Montuschi", "Paolo", ""]]}, {"id": "2102.02785", "submitter": "Sirin Botan", "authors": "Sirin Botan and Ronald de Haan and Marija Slavkovik and Zoi\n  Terzopoulou", "title": "Egalitarian Judgment Aggregation", "comments": "Extended version of paper in proceedings of the 20th International\n  Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Egalitarian considerations play a central role in many areas of social choice\ntheory. Applications of egalitarian principles range from ensuring everyone\ngets an equal share of a cake when deciding how to divide it, to guaranteeing\nbalance with respect to gender or ethnicity in committee elections. Yet, the\negalitarian approach has received little attention in judgment aggregation -- a\npowerful framework for aggregating logically interconnected issues. We make the\nfirst steps towards filling that gap. We introduce axioms capturing two\nclassical interpretations of egalitarianism in judgment aggregation and situate\nthese within the context of existing axioms in the pertinent framework of\nbelief merging. We then explore the relationship between these axioms and\nseveral notions of strategyproofness from social choice theory at large.\nFinally, a novel egalitarian judgment aggregation rule stems from our analysis;\nwe present complexity results concerning both outcome determination and\nstrategic manipulation for that rule.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:07:31 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 13:23:01 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Botan", "Sirin", ""], ["de Haan", "Ronald", ""], ["Slavkovik", "Marija", ""], ["Terzopoulou", "Zoi", ""]]}, {"id": "2102.02789", "submitter": "Vivien Cabannes", "authors": "Vivien Cabannes, Francis Bach, Alessandro Rudi", "title": "Disambiguation of weak supervision with exponential convergence rates", "comments": "22 pages; 6 figures", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning approached through supervised learning requires expensive\nannotation of data. This motivates weakly supervised learning, where data are\nannotated with incomplete yet discriminative information. In this paper, we\nfocus on partial labelling, an instance of weak supervision where, from a given\ninput, we are given a set of potential targets. We review a disambiguation\nprinciple to recover full supervision from weak supervision, and propose an\nempirical disambiguation algorithm. We prove exponential convergence rates of\nour algorithm under classical learnability assumptions, and we illustrate the\nusefulness of our method on practical examples.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:14:32 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 16:14:29 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:29:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cabannes", "Vivien", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2102.02810", "submitter": "Marco Roberti", "authors": "Cl\\'ement Rebuffel, Marco Roberti, Laure Soulier, Geoffrey\n  Scoutheeten, Rossella Cancelliere, Patrick Gallinari", "title": "Controlling Hallucinations at Word Level in Data-to-Text Generation", "comments": "20 pages, 6 figures, 5 tables (excluding Appendix). Source code:\n  https://github.com/KaijuML/dtt-multi-branch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-to-Text Generation (DTG) is a subfield of Natural Language Generation\naiming at transcribing structured data in natural language descriptions. The\nfield has been recently boosted by the use of neural-based generators which\nexhibit on one side great syntactic skills without the need of hand-crafted\npipelines; on the other side, the quality of the generated text reflects the\nquality of the training data, which in realistic settings only offer\nimperfectly aligned structure-text pairs. Consequently, state-of-art neural\nmodels include misleading statements - usually called hallucinations - in their\noutputs. The control of this phenomenon is today a major challenge for DTG, and\nis the problem addressed in the paper.\n  Previous work deal with this issue at the instance level: using an alignment\nscore for each table-reference pair. In contrast, we propose a finer-grained\napproach, arguing that hallucinations should rather be treated at the word\nlevel. Specifically, we propose a Multi-Branch Decoder which is able to\nleverage word-level labels to learn the relevant parts of each training\ninstance. These labels are obtained following a simple and efficient scoring\nprocedure based on co-occurrence analysis and dependency parsing. Extensive\nevaluations, via automated metrics and human judgment on the standard WikiBio\nbenchmark, show the accuracy of our alignment labels and the effectiveness of\nthe proposed Multi-Branch Decoder. Our model is able to reduce and control\nhallucinations, while keeping fluency and coherence in generated texts. Further\nexperiments on a degraded version of ToTTo show that our model could be\nsuccessfully used on very noisy settings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:58:28 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 16:29:49 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Rebuffel", "Cl\u00e9ment", ""], ["Roberti", "Marco", ""], ["Soulier", "Laure", ""], ["Scoutheeten", "Geoffrey", ""], ["Cancelliere", "Rossella", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2102.02842", "submitter": "Ajitesh Srivastava", "authors": "Ajitesh Srivastava, Tianjian Xu, Viktor K. Prasanna", "title": "The EpiBench Platform to Propel AI/ML-based Epidemic Forecasting: A\n  Prototype Demonstration Reaching Human Expert-level Performance", "comments": "8 pages, 6 figures. Accepted at the 5th International Workshop on\n  Health Intelligence in conjunction with the Thirty-Fifth AAAI Conference on\n  Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, a significant effort has gone into developing\nML-driven epidemic forecasting techniques. However, benchmarks do not exist to\nclaim if a new AI/ML technique is better than the existing ones. The\n\"covid-forecast-hub\" is a collection of more than 30 teams, including us, that\nsubmit their forecasts weekly to the CDC. It is not possible to declare whether\none method is better than the other using those forecasts because each team's\nsubmission may correspond to different techniques over the period and involve\nhuman interventions as the teams are continuously changing/tuning their\napproach. Such forecasts may be considered \"human-expert\" forecasts and do not\nqualify as AI/ML approaches, although they can be used as an indicator of human\nexpert performance. We are interested in supporting AI/ML research in epidemic\nforecasting which can lead to scalable forecasting without human intervention.\nWhich modeling technique, learning strategy, and data pre-processing technique\nwork well for epidemic forecasting is still an open problem. To help advance\nthe state-of-the-art AI/ML applied to epidemiology, a benchmark with a\ncollection of performance points is needed and the current \"state-of-the-art\"\ntechniques need to be identified. We propose EpiBench a platform consisting of\ncommunity-driven benchmarks for AI/ML applied to epidemic forecasting to\nstandardize the challenge with a uniform evaluation protocol. In this paper, we\nintroduce a prototype of EpiBench which is currently running and accepting\nsubmissions for the task of forecasting COVID-19 cases and deaths in the US\nstates and We demonstrate that we can utilize the prototype to develop an\nensemble relying on fully automated epidemic forecasts (no human intervention)\nthat reaches human-expert level ensemble currently being used by the CDC.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 19:21:14 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Srivastava", "Ajitesh", ""], ["Xu", "Tianjian", ""], ["Prasanna", "Viktor K.", ""]]}, {"id": "2102.02850", "submitter": "George Monta\\~nez", "authors": "Sonia Sehra, David Flores, George D. Montanez", "title": "Undecidability of Underfitting in Learning Algorithms", "comments": "Accepted at The 2nd International Conference on Computing and Data\n  Science (CONF-CDS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Using recent machine learning results that present an information-theoretic\nperspective on underfitting and overfitting, we prove that deciding whether an\nencodable learning algorithm will always underfit a dataset, even if given\nunlimited training time, is undecidable. We discuss the importance of this\nresult and potential topics for further research, including\ninformation-theoretic and probabilistic strategies for bounding learning\nalgorithm fit.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 19:35:05 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 17:48:49 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 21:52:02 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sehra", "Sonia", ""], ["Flores", "David", ""], ["Montanez", "George D.", ""]]}, {"id": "2102.02864", "submitter": "Jing Gu", "authors": "Jing Gu, Mostafa Mirshekari, Zhou Yu, Aaron Sisto", "title": "ChainCQG: Flow-Aware Conversational Question Generation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational systems enable numerous valuable applications, and\nquestion-answering is an important component underlying many of these. However,\nconversational question-answering remains challenging due to the lack of\nrealistic, domain-specific training data. Inspired by this bottleneck, we focus\non conversational question generation as a means to generate synthetic\nconversations for training and evaluation purposes. We present a number of\nnovel strategies to improve conversational flow and accommodate varying\nquestion types and overall fluidity. Specifically, we design ChainCQG as a\ntwo-stage architecture that learns question-answer representations across\nmultiple dialogue turns using a flow propagation training strategy.ChainCQG\nsignificantly outperforms both answer-aware and answer-unaware SOTA baselines\n(e.g., up to 48% BLEU-1 improvement). Additionally, our model is able to\ngenerate different types of questions, with improved fluidity and coreference\nalignment.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 19:56:51 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Gu", "Jing", ""], ["Mirshekari", "Mostafa", ""], ["Yu", "Zhou", ""], ["Sisto", "Aaron", ""]]}, {"id": "2102.02881", "submitter": "Francesca Toni", "authors": "Stefan Lauren and Francesco Belardinelli and Francesca Toni", "title": "Aggregating Bipolar Opinions (With Appendix)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method to aggregate Bipolar Argumentation (BA)\nFrameworks expressing opinions by different parties in debates. We use Bipolar\nAssumption-based Argumentation (ABA) as an all-encompassing formalism for BA\nunder different semantics. By leveraging on recent results on judgement\naggregation in Social Choice Theory, we prove several preservation results,\nboth positive and negative, for relevant properties of Bipolar ABA.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:43:30 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Lauren", "Stefan", ""], ["Belardinelli", "Francesco", ""], ["Toni", "Francesca", ""]]}, {"id": "2102.02886", "submitter": "Daniel Lenton", "authors": "Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark", "title": "Ivy: Templated Deep Learning for Inter-Framework Portability", "comments": "Code at https://github.com/ivy-dl/ivy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Ivy, a templated Deep Learning (DL) framework which abstracts\nexisting DL frameworks. Ivy unifies the core functions of these frameworks to\nexhibit consistent call signatures, syntax and input-output behaviour. New\nhigh-level framework-agnostic functions and classes, which are usable alongside\nframework-specific code, can then be implemented as compositions of the unified\nlow-level Ivy functions. Ivy currently supports TensorFlow, PyTorch, MXNet, Jax\nand NumPy. We also release four pure-Ivy libraries for mechanics, 3D vision,\nrobotics, and differentiable environments. Through our evaluations, we show\nthat Ivy can significantly reduce lines of code with a runtime overhead of less\nthan 1% in most cases. We welcome developers to join the Ivy community by\nwriting their own functions, layers and libraries in Ivy, maximizing their\naudience and helping to accelerate DL research through inter-framework\ncodebases. More information can be found at https://ivy-dl.org.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:58:37 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 18:26:14 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 17:59:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lenton", "Daniel", ""], ["Pardo", "Fabio", ""], ["Falck", "Fabian", ""], ["James", "Stephen", ""], ["Clark", "Ronald", ""]]}, {"id": "2102.02887", "submitter": "Shiwei Liu", "authors": "Shiwei Liu, Lu Yin, Decebal Constantin Mocanu, Mykola Pechenizkiy", "title": "Do We Actually Need Dense Over-Parameterization? In-Time\n  Over-Parameterization in Sparse Training", "comments": "16 pages; 10 figures; Published in Proceedings of the 38th\n  International Conference on Machine Learning. Code can be found\n  https://github.com/Shiweiliuiiiiiii/In-Time-Over-Parameterization", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new perspective on training deep neural\nnetworks capable of state-of-the-art performance without the need for the\nexpensive over-parameterization by proposing the concept of In-Time\nOver-Parameterization (ITOP) in sparse training. By starting from a random\nsparse network and continuously exploring sparse connectivities during\ntraining, we can perform an Over-Parameterization in the space-time manifold,\nclosing the gap in the expressibility between sparse training and dense\ntraining. We further use ITOP to understand the underlying mechanism of Dynamic\nSparse Training (DST) and indicate that the benefits of DST come from its\nability to consider across time all possible parameters when searching for the\noptimal sparse connectivity. As long as there are sufficient parameters that\nhave been reliably explored during training, DST can outperform the dense\nneural network by a large margin. We present a series of experiments to support\nour conjecture and achieve the state-of-the-art sparse training performance\nwith ResNet-50 on ImageNet. More impressively, our method achieves dominant\nperformance over the overparameterization-based sparse methods at extreme\nsparsity levels. When trained on CIFAR-100, our method can match the\nperformance of the dense model even at an extreme sparsity (98%). Code can be\nfound https://github.com/Shiweiliuiiiiiii/In-Time-Over-Parameterization.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:59:31 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 23:36:57 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:01:46 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liu", "Shiwei", ""], ["Yin", "Lu", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2102.02895", "submitter": "Hrithwik Shalu", "authors": "Joseph Stember and Hrithwik Shalu", "title": "Deep reinforcement learning-based image classification achieves perfect\n  testing set accuracy for MRI brain tumors with a training set of only 30\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Image classification may be the fundamental task in imaging\nartificial intelligence. We have recently shown that reinforcement learning can\nachieve high accuracy for lesion localization and segmentation even with\nminuscule training sets. Here, we introduce reinforcement learning for image\nclassification. In particular, we apply the approach to normal vs.\ntumor-containing 2D MRI brain images.\n  Materials and Methods: We applied multi-step image classification to allow\nfor combined Deep Q learning and TD(0) Q learning. We trained on a set of 30\nimages (15 normal and 15 tumor-containing). We tested on a separate set of 30\nimages (15 normal and 15 tumor-containing). For comparison, we also trained and\ntested a supervised deep-learning classification network on the same set of\ntraining and testing images.\n  Results: Whereas the supervised approach quickly overfit the training data\nand as expected performed poorly on the testing set (57% accuracy, just over\nrandom guessing), the reinforcement learning approach achieved an accuracy of\n100%.\n  Conclusion: We have shown a proof-of-principle application of reinforcement\nlearning to the classification of brain tumors. We achieved perfect testing set\naccuracy with a training set of merely 30 images.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 21:31:22 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 05:37:21 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Stember", "Joseph", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2102.02917", "submitter": "Allison Lahnala", "authors": "Allison Lahnala, Gauri Kambhatla, Jiajun Peng, Matthew Whitehead,\n  Gillian Minnehan, Eric Guldan, Jonathan K. Kummerfeld, An{\\i}l \\c{C}amc{\\i},\n  Rada Mihalcea", "title": "Chord Embeddings: Analyzing What They Capture and Their Role for Next\n  Chord Prediction and Artist Attribute Prediction", "comments": "16 pages, accepted to EvoMUSART", "journal-ref": "Computational Intelligence in Music, Sound, Art and Design, 10th\n  International Conference, EvoMUSART 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing methods have been applied in a variety of music\nstudies, drawing the connection between music and language. In this paper, we\nexpand those approaches by investigating \\textit{chord embeddings}, which we\napply in two case studies to address two key questions: (1) what musical\ninformation do chord embeddings capture?; and (2) how might musical\napplications benefit from them? In our analysis, we show that they capture\nsimilarities between chords that adhere to important relationships described in\nmusic theory. In the first case study, we demonstrate that using chord\nembeddings in a next chord prediction task yields predictions that more closely\nmatch those by experienced musicians. In the second case study, we show the\npotential benefits of using the representations in tasks related to musical\nstylometrics.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 22:17:17 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Lahnala", "Allison", ""], ["Kambhatla", "Gauri", ""], ["Peng", "Jiajun", ""], ["Whitehead", "Matthew", ""], ["Minnehan", "Gillian", ""], ["Guldan", "Eric", ""], ["Kummerfeld", "Jonathan K.", ""], ["\u00c7amc\u0131", "An\u0131l", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2102.02923", "submitter": "Junfeng Guo", "authors": "Junfeng Guo, Yaswanth Yadlapalli, Thiele Lothar, Ang Li, and Cong Liu", "title": "PredCoin: Defense against Query-based Hard-label Attack", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many adversarial attacks and defenses have recently been proposed for Deep\nNeural Networks (DNNs). While most of them are in the white-box setting, which\nis impractical, a new class of query-based hard-label (QBHL) black-box attacks\npose a significant threat to real-world applications (e.g., Google Cloud,\nTencent API). Till now, there has been no generalizable and practical approach\nproposed to defend against such attacks.\n  This paper proposes and evaluates PredCoin, a practical and generalizable\nmethod for providing robustness against QBHL attacks. PredCoin poisons the\ngradient estimation step, an essential component of most QBHL attacks. PredCoin\nsuccessfully identifies gradient estimation queries crafted by an attacker and\nintroduces uncertainty to the output. Extensive experiments show that PredCoin\nsuccessfully defends against four state-of-the-art QBHL attacks across various\nsettings and tasks while preserving the target model's overall accuracy.\n  PredCoin is also shown to be robust and effective against several\ndefense-aware attacks, which may have full knowledge regarding the internal\nmechanisms of PredCoin.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 22:47:05 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Guo", "Junfeng", ""], ["Yadlapalli", "Yaswanth", ""], ["Lothar", "Thiele", ""], ["Li", "Ang", ""], ["Liu", "Cong", ""]]}, {"id": "2102.02925", "submitter": "A.B. Siddique", "authors": "A.B. Siddique, Fuad Jamour, Luxun Xu, Vagelis Hristidis", "title": "Generalized Zero-shot Intent Detection via Commonsense Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying user intents from natural language utterances is a crucial step\nin conversational systems that has been extensively studied as a supervised\nclassification problem. However, in practice, new intents emerge after\ndeploying an intent detection model. Thus, these models should seamlessly adapt\nand classify utterances with both seen and unseen intents -- unseen intents\nemerge after deployment and they do not have training data. The few existing\nmodels that target this setting rely heavily on the scarcely available training\ndata and overfit to seen intents data, resulting in a bias to misclassify\nutterances with unseen intents into seen ones. We propose RIDE: an intent\ndetection model that leverages commonsense knowledge in an unsupervised fashion\nto overcome the issue of training data scarcity. RIDE computes robust and\ngeneralizable relationship meta-features that capture deep semantic\nrelationships between utterances and intent labels; these features are computed\nby considering how the concepts in an utterance are linked to those in an\nintent label via commonsense knowledge. Our extensive experimental analysis on\nthree widely-used intent detection benchmarks shows that relationship\nmeta-features significantly increase the accuracy of detecting both seen and\nunseen intents and that RIDE outperforms the state-of-the-art model for unseen\nintents.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 23:36:41 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Siddique", "A. B.", ""], ["Jamour", "Fuad", ""], ["Xu", "Luxun", ""], ["Hristidis", "Vagelis", ""]]}, {"id": "2102.02926", "submitter": "Jane Wang", "authors": "Jane X. Wang, Michael King, Nicolas Porcel, Zeb Kurth-Nelson, Tina\n  Zhu, Charlie Deck, Peter Choy, Mary Cassin, Malcolm Reynolds, Francis Song,\n  Gavin Buttimore, David P. Reichert, Neil Rabinowitz, Loic Matthey, Demis\n  Hassabis, Alexander Lerchner, Matthew Botvinick", "title": "Alchemy: A structured task distribution for meta-reinforcement learning", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been rapidly growing interest in meta-learning as a method for\nincreasing the flexibility and sample efficiency of reinforcement learning. One\nproblem in this area of research, however, has been a scarcity of adequate\nbenchmark tasks. In general, the structure underlying past benchmarks has\neither been too simple to be inherently interesting, or too ill-defined to\nsupport principled analysis. In the present work, we introduce a new benchmark\nfor meta-RL research, which combines structural richness with structural\ntransparency. Alchemy is a 3D video game, implemented in Unity, which involves\na latent causal structure that is resampled procedurally from episode to\nepisode, affording structure learning, online inference, hypothesis testing and\naction sequencing based on abstract domain knowledge. We evaluate a pair of\npowerful RL agents on Alchemy and present an in-depth analysis of one of these\nagents. Results clearly indicate a frank and specific failure of meta-learning,\nproviding validation for Alchemy as a challenging benchmark for meta-RL.\nConcurrent with this report, we are releasing Alchemy as public resource,\ntogether with a suite of analysis tools and sample agent trajectories.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 23:40:44 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Wang", "Jane X.", ""], ["King", "Michael", ""], ["Porcel", "Nicolas", ""], ["Kurth-Nelson", "Zeb", ""], ["Zhu", "Tina", ""], ["Deck", "Charlie", ""], ["Choy", "Peter", ""], ["Cassin", "Mary", ""], ["Reynolds", "Malcolm", ""], ["Song", "Francis", ""], ["Buttimore", "Gavin", ""], ["Reichert", "David P.", ""], ["Rabinowitz", "Neil", ""], ["Matthey", "Loic", ""], ["Hassabis", "Demis", ""], ["Lerchner", "Alexander", ""], ["Botvinick", "Matthew", ""]]}, {"id": "2102.02928", "submitter": "Nirav Ajmeri", "authors": "Veljko Dubljevi\\'c (1), George F. List (1), Jovan Milojevich (2),\n  Nirav Ajmeri (3), William Bauer (1), Munindar P. Singh (1), Eleni Bardaka\n  (1), Thomas Birkland (1), Charles Edwards (4), Roger Mayer (1), Ioan Muntean\n  (5), Thomas Powers (6), Hesham Rakha (7), Vance Ricks (8), M. Shoaib Samandar\n  (1) ((1) North Carolina State University, (2) Oklahoma State University, (3)\n  University of Bristol, (4) University of North Carolina at Chapel Hill, (5)\n  University of North Carolina at Asheville, (6) University of Delaware, (7)\n  Virginia Tech, (8) Guilford College)", "title": "Toward a Rational and Ethical Sociotechnical System of Autonomous\n  Vehicles: A Novel Application of Multi-Criteria Decision Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expansion of artificial intelligence (AI) and autonomous systems has\nshown the potential to generate enormous social good while also raising serious\nethical and safety concerns. AI technology is increasingly adopted in\ntransportation. A survey of various in-vehicle technologies found that\napproximately 64% of the respondents used a smartphone application to assist\nwith their travel. The top-used applications were navigation and real-time\ntraffic information systems. Among those who used smartphones during their\ncommutes, the top-used applications were navigation and entertainment. There is\na pressing need to address relevant social concerns to allow for the\ndevelopment of systems of intelligent agents that are informed and cognizant of\nethical standards. Doing so will facilitate the responsible integration of\nthese systems in society. To this end, we have applied Multi-Criteria Decision\nAnalysis (MCDA) to develop a formal Multi-Attribute Impact Assessment (MAIA)\nquestionnaire for examining the social and ethical issues associated with the\nuptake of AI. We have focused on the domain of autonomous vehicles (AVs)\nbecause of their imminent expansion. However, AVs could serve as a stand-in for\nany domain where intelligent, autonomous agents interact with humans, either on\nan individual level (e.g., pedestrians, passengers) or a societal level.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 23:52:31 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Dubljevi\u0107", "Veljko", ""], ["List", "George F.", ""], ["Milojevich", "Jovan", ""], ["Ajmeri", "Nirav", ""], ["Bauer", "William", ""], ["Singh", "Munindar P.", ""], ["Bardaka", "Eleni", ""], ["Birkland", "Thomas", ""], ["Edwards", "Charles", ""], ["Mayer", "Roger", ""], ["Muntean", "Ioan", ""], ["Powers", "Thomas", ""], ["Rakha", "Hesham", ""], ["Ricks", "Vance", ""], ["Samandar", "M. Shoaib", ""]]}, {"id": "2102.02950", "submitter": "Masanori Yamada", "authors": "Masanori Yamada, Sekitoshi Kanai, Tomoharu Iwata, Tomokatsu Takahashi,\n  Yuki Yamanaka, Hiroshi Takahashi, Atsutoshi Kumagai", "title": "Adversarial Training Makes Weight Loss Landscape Sharper in Logistic\n  Regression", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is actively studied for learning robust models against\nadversarial examples. A recent study finds that adversarially trained models\ndegenerate generalization performance on adversarial examples when their weight\nloss landscape, which is loss changes with respect to weights, is sharp.\nUnfortunately, it has been experimentally shown that adversarial training\nsharpens the weight loss landscape, but this phenomenon has not been\ntheoretically clarified. Therefore, we theoretically analyze this phenomenon in\nthis paper. As a first step, this paper proves that adversarial training with\nthe L2 norm constraints sharpens the weight loss landscape in the linear\nlogistic regression model. Our analysis reveals that the sharpness of the\nweight loss landscape is caused by the noise aligned in the direction of\nincreasing the loss, which is used in adversarial training. We theoretically\nand experimentally confirm that the weight loss landscape becomes sharper as\nthe magnitude of the noise of adversarial training increases in the linear\nlogistic regression model. Moreover, we experimentally confirm the same\nphenomena in ResNet18 with softmax as a more general case.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 01:31:01 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yamada", "Masanori", ""], ["Kanai", "Sekitoshi", ""], ["Iwata", "Tomoharu", ""], ["Takahashi", "Tomokatsu", ""], ["Yamanaka", "Yuki", ""], ["Takahashi", "Hiroshi", ""], ["Kumagai", "Atsutoshi", ""]]}, {"id": "2102.02959", "submitter": "Fakrul Islam Tushar", "authors": "Vincent M. D'Anniballe, Fakrul I. Tushar, Khrystyna Faryna, Songyue\n  Han, Maciej A. Mazurowski, Geoffrey D. Rubin, Joseph Y. Lo", "title": "Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text\n  Reports Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: To develop high throughput multi-label annotators for body (chest,\nabdomen, and pelvis) Computed Tomography (CT) reports that can be applied\nacross a variety of abnormalities, organs, and disease states.\n  Approach: We used a dictionary approach to develop rule-based algorithms\n(RBA) for extraction of disease labels from radiology text reports. We targeted\nthree organ systems (lungs/pleura, liver/gallbladder, kidneys/ureters) with\nfour diseases per system based on their prevalence in our dataset. To expand\nthe algorithms beyond pre-defined keywords, attention-guided recurrent neural\nnetworks (RNN) were trained using the RBA-extracted labels to classify reports\nas being positive for one or more diseases or normal for each organ system.\nConfounding effects on model performance were evaluated using random\ninitialization or pre-trained embedding as well as different sizes of training\ndatasets. Performance was evaluated using the receiver operating characteristic\n(ROC) area under the curve (AUC) against 2,158 manually obtained labels.\n  Results: Our models extracted disease labels from 261,229 radiology reports\nof 112,501 unique subjects. Pre-trained models outperformed random\ninitialization across all diseases. As the training dataset size was reduced,\nperformance was robust except for a few diseases with relatively small number\nof cases. Pre-trained classification AUCs achieved > 0.95 for all five disease\noutcomes across all three organ systems.\n  Conclusions: Our label-extracting pipeline was able to encompass a variety of\ncases and diseases by generalizing beyond strict rules with exceptional\naccuracy. This method can be easily adapted to enable automated labeling of\nhospital-scale medical data sets for training image-based disease classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 02:07:39 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:12:11 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 09:37:37 GMT"}, {"version": "v4", "created": "Sat, 12 Jun 2021 11:38:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["D'Anniballe", "Vincent M.", ""], ["Tushar", "Fakrul I.", ""], ["Faryna", "Khrystyna", ""], ["Han", "Songyue", ""], ["Mazurowski", "Maciej A.", ""], ["Rubin", "Geoffrey D.", ""], ["Lo", "Joseph Y.", ""]]}, {"id": "2102.02988", "submitter": "Srivatsan Krishnan", "authors": "Srivatsan Krishnan, Zishen Wan, Kshitij Bharadwaj, Paul Whatmough,\n  Aleksandra Faust, Sabrina Neuman, Gu-Yeon Wei, David Brooks, Vijay Janapa\n  Reddi", "title": "Machine Learning-Based Automated Design Space Exploration for Autonomous\n  Aerial Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building domain-specific architectures for autonomous aerial robots is\nchallenging due to a lack of systematic methodology for designing onboard\ncompute. We introduce a novel performance model called the F-1 roofline to help\narchitects understand how to build a balanced computing system for autonomous\naerial robots considering both its cyber (sensor rate, compute performance) and\nphysical components (body-dynamics) that affect the performance of the machine.\nWe use F-1 to characterize commonly used learning-based autonomy algorithms\nwith onboard platforms to demonstrate the need for cyber-physical co-design. To\nnavigate the cyber-physical design space automatically, we subsequently\nintroduce AutoPilot. This push-button framework automates the co-design of\ncyber-physical components for aerial robots from a high-level specification\nguided by the F-1 model. AutoPilot uses Bayesian optimization to automatically\nco-design the autonomy algorithm and hardware accelerator while considering\nvarious cyber-physical parameters to generate an optimal design under different\ntask level complexities for different robots and sensor framerates. As a\nresult, designs generated by AutoPilot, on average, lower mission time up to 2x\nover baseline approaches, conserving battery energy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 03:50:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Krishnan", "Srivatsan", ""], ["Wan", "Zishen", ""], ["Bharadwaj", "Kshitij", ""], ["Whatmough", "Paul", ""], ["Faust", "Aleksandra", ""], ["Neuman", "Sabrina", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""], ["Reddi", "Vijay Janapa", ""]]}, {"id": "2102.03002", "submitter": "Yiwei Bai", "authors": "Yiwei Bai, Wenting Zhao, Carla P. Gomes", "title": "Zero Training Overhead Portfolios for Learning to Solve Combinatorial\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There has been an increasing interest in harnessing deep learning to tackle\ncombinatorial optimization (CO) problems in recent years. Typical CO deep\nlearning approaches leverage the problem structure in the model architecture.\nNevertheless, the model selection is still mainly based on the conventional\nmachine learning setting. Due to the discrete nature of CO problems, a single\nmodel is unlikely to learn the problem entirely. We introduce ZTop, which\nstands for Zero Training Overhead Portfolio, a simple yet effective model\nselection and ensemble mechanism for learning to solve combinatorial problems.\nZTop is inspired by algorithm portfolios, a popular CO ensembling strategy,\nparticularly restart portfolios, which periodically restart a randomized CO\nalgorithm, de facto exploring the search space with different heuristics. We\nhave observed that well-trained models acquired in the same training\ntrajectory, with similar top validation performance, perform well on very\ndifferent validation instances. Following this observation, ZTop ensembles a\nset of well-trained models, each providing a unique heuristic with zero\ntraining overhead, and applies them, sequentially or in parallel, to solve the\ntest instances. We show how ZTopping, i.e., using a ZTop ensemble strategy with\na given deep learning approach, can significantly improve the performance of\nthe current state-of-the-art deep learning approaches on three prototypical CO\ndomains, the hardest unique-solution Sudoku instances, challenging routing\nproblems, and the graph maximum cut problem, as well as on multi-label\nclassification, a machine learning task with a large combinatorial label space.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 05:23:26 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bai", "Yiwei", ""], ["Zhao", "Wenting", ""], ["Gomes", "Carla P.", ""]]}, {"id": "2102.03012", "submitter": "Huaizheng Zhang", "authors": "Huaizheng Zhang, Meng Shen, Yizheng Huang, Yonggang Wen, Yong Luo,\n  Guanyu Gao, Kyle Guan", "title": "A Serverless Cloud-Fog Platform for DNN-Based Video Analytics with\n  Incremental Learning", "comments": "11 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN-based video analytics have empowered many new applications (e.g.,\nautomated retail). Meanwhile, the proliferation of fog devices provides\ndevelopers with more design options to improve performance and save cost. To\nthe best of our knowledge, this paper presents the first serverless system that\ntakes full advantage of the client-fog-cloud synergy to better serve the\nDNN-based video analytics. Specifically, the system aims to achieve two goals:\n1) Provide the optimal analytics results under the constraints of lower\nbandwidth usage and shorter round-trip time (RTT) by judiciously managing the\ncomputational and bandwidth resources deployed in the client, fog, and cloud\nenvironment. 2) Free developers from tedious administration and operation\ntasks, including DNN deployment, cloud and fog's resource management. To this\nend, we implement a holistic cloud-fog system referred to as VPaaS\n(Video-Platform-as-a-Service). VPaaS adopts serverless computing to enable\ndevelopers to build a video analytics pipeline by simply programming a set of\nfunctions (e.g., model inference), which are then orchestrated to process\nvideos through carefully designed modules. To save bandwidth and reduce RTT,\nVPaaS provides a new video streaming protocol that only sends low-quality video\nto the cloud. The state-of-the-art (SOTA) DNNs deployed at the cloud can\nidentify regions of video frames that need further processing at the fog ends.\nAt the fog ends, misidentified labels in these regions can be corrected using a\nlight-weight DNN model. To address the data drift issues, we incorporate\nlimited human feedback into the system to verify the results and adopt\nincremental learning to improve our system continuously. The evaluation\ndemonstrates that VPaaS is superior to several SOTA systems: it maintains high\naccuracy while reducing bandwidth usage by up to 21%, RTT by up to 62.5%, and\ncloud monetary cost by up to 50%.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 05:59:36 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Huaizheng", ""], ["Shen", "Meng", ""], ["Huang", "Yizheng", ""], ["Wen", "Yonggang", ""], ["Luo", "Yong", ""], ["Gao", "Guanyu", ""], ["Guan", "Kyle", ""]]}, {"id": "2102.03022", "submitter": "Tim Miller", "authors": "Zhengshang Liu, Yue Yang, Tim Miller, and Peta Masters", "title": "Deceptive Reinforcement Learning for Privacy-Preserving Planning", "comments": null, "journal-ref": "Proceedings of the 20th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of deceptive reinforcement learning to\npreserve the privacy of a reward function. Reinforcement learning is the\nproblem of finding a behaviour policy based on rewards received from\nexploratory behaviour. A key ingredient in reinforcement learning is a reward\nfunction, which determines how much reward (negative or positive) is given and\nwhen. However, in some situations, we may want to keep a reward function\nprivate; that is, to make it difficult for an observer to determine the reward\nfunction used. We define the problem of privacy-preserving reinforcement\nlearning, and present two models for solving it. These models are based on\ndissimulation -- a form of deception that `hides the truth'. We evaluate our\nmodels both computationally and via human behavioural experiments. Results show\nthat the resulting policies are indeed deceptive, and that participants can\ndetermine the true reward function less reliably than that of an honest agent.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 06:50:04 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Liu", "Zhengshang", ""], ["Yang", "Yue", ""], ["Miller", "Tim", ""], ["Masters", "Peta", ""]]}, {"id": "2102.03049", "submitter": "Chien-Wen Huang", "authors": "Fu-Shun Hsu, Shang-Ran Huang, Chien-Wen Huang, Chao-Jung Huang,\n  Yuan-Ren Cheng, Chun-Chieh Chen, Jack Hsiao, Chung-Wei Chen, Li-Chin Chen,\n  Yen-Chun Lai, Bi-Fang Hsu, Nian-Jhen Lin, Wan-Lin Tsai, Yi-Lin Wu, Tzu-Ling\n  Tseng, Ching-Ting Tseng, Yi-Tsun Chen, Feipei Lai", "title": "Benchmarking of eight recurrent neural network variants for breath phase\n  and adventitious sound detection on a self-developed open-access lung sound\n  database-HF_Lung_V1", "comments": "48 pages, 8 figures. To be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable, remote, and continuous real-time respiratory sound monitor with\nautomated respiratory sound analysis ability is urgently required in many\nclinical scenarios-such as in monitoring disease progression of coronavirus\ndisease 2019-to replace conventional auscultation with a handheld stethoscope.\nHowever, a robust computerized respiratory sound analysis algorithm has not yet\nbeen validated in practical applications. In this study, we developed a lung\nsound database (HF_Lung_V1) comprising 9,765 audio files of lung sounds\n(duration of 15 s each), 34,095 inhalation labels, 18,349 exhalation labels,\n13,883 continuous adventitious sound (CAS) labels (comprising 8,457 wheeze\nlabels, 686 stridor labels, and 4,740 rhonchi labels), and 15,606 discontinuous\nadventitious sound labels (all crackles). We conducted benchmark tests for long\nshort-term memory (LSTM), gated recurrent unit (GRU), bidirectional LSTM\n(BiLSTM), bidirectional GRU (BiGRU), convolutional neural network (CNN)-LSTM,\nCNN-GRU, CNN-BiLSTM, and CNN-BiGRU models for breath phase detection and\nadventitious sound detection. We also conducted a performance comparison\nbetween the LSTM-based and GRU-based models, between unidirectional and\nbidirectional models, and between models with and without a CNN. The results\nrevealed that these models exhibited adequate performance in lung sound\nanalysis. The GRU-based models outperformed, in terms of F1 scores and areas\nunder the receiver operating characteristic curves, the LSTM-based models in\nmost of the defined tasks. Furthermore, all bidirectional models outperformed\ntheir unidirectional counterparts. Finally, the addition of a CNN improved the\naccuracy of lung sound analysis, especially in the CAS detection tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:21:28 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 15:22:55 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Hsu", "Fu-Shun", ""], ["Huang", "Shang-Ran", ""], ["Huang", "Chien-Wen", ""], ["Huang", "Chao-Jung", ""], ["Cheng", "Yuan-Ren", ""], ["Chen", "Chun-Chieh", ""], ["Hsiao", "Jack", ""], ["Chen", "Chung-Wei", ""], ["Chen", "Li-Chin", ""], ["Lai", "Yen-Chun", ""], ["Hsu", "Bi-Fang", ""], ["Lin", "Nian-Jhen", ""], ["Tsai", "Wan-Lin", ""], ["Wu", "Yi-Lin", ""], ["Tseng", "Tzu-Ling", ""], ["Tseng", "Ching-Ting", ""], ["Chen", "Yi-Tsun", ""], ["Lai", "Feipei", ""]]}, {"id": "2102.03053", "submitter": "Julian Bernhard", "authors": "Julian Bernhard and Alois Knoll", "title": "Risk-Constrained Interactive Safety under Behavior Uncertainty for\n  Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Balancing safety and efficiency when planning in dense traffic is\nchallenging. Interactive behavior planners incorporate prediction uncertainty\nand interactivity inherent to these traffic situations. Yet, their use of\nsingle-objective optimality impedes interpretability of the resulting safety\ngoal. Safety envelopes which restrict the allowed planning region yield\ninterpretable safety under the presence of behavior uncertainty, yet, they\nsacrifice efficiency in dense traffic due to conservative driving. Studies show\nthat humans balance safety and efficiency in dense traffic by accepting a\nprobabilistic risk of violating the safety envelope. In this work, we adopt\nthis safety objective for interactive planning. Specifically, we formalize this\nsafety objective, present the Risk-Constrained Robust Stochastic Bayesian Game\nmodeling interactive decisions satisfying a maximum risk of violating a safety\nenvelope under uncertainty of other traffic participants' behavior and solve it\nusing our variant of Multi-Agent Monte Carlo Tree Search. We demonstrate in\nsimulation that our approach outperforms baselines approaches, and by reaching\nthe specified violation risk level over driven simulation time, provides an\ninterpretable and tunable safety objective for interactive planning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:33:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bernhard", "Julian", ""], ["Knoll", "Alois", ""]]}, {"id": "2102.03054", "submitter": "Sahil Verma", "authors": "Sahil Verma, Michael Ernst, Rene Just", "title": "Removing biased data to improve fairness and accuracy", "comments": "16 pages, 5 Figures, 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning systems are often trained using data collected from\nhistorical decisions. If past decisions were biased, then automated systems\nthat learn from historical data will also be biased. We propose a black-box\napproach to identify and remove biased training data. Machine learning models\ntrained on such debiased data (a subset of the original training data) have low\nindividual discrimination, often 0%. These models also have greater accuracy\nand lower statistical disparity than models trained on the full historical\ndata. We evaluated our methodology in experiments using 6 real-world datasets.\nOur approach outperformed seven previous approaches in terms of individual\ndiscrimination and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:34:45 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Verma", "Sahil", ""], ["Ernst", "Michael", ""], ["Just", "Rene", ""]]}, {"id": "2102.03062", "submitter": "Thomas \\\"Ubellacker", "authors": "Jonas Thiergart, Stefan Huber, Thomas \\\"Ubellacker", "title": "Understanding Emails and Drafting Responses -- An Approach Using GPT-3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing computer systems with the ability to understand and generate\nnatural language has long been a challenge of engineers. Recent progress in\nnatural language processing (NLP), like the GPT-3 language model released by\nOpenAI, has made both possible to an extent. In this paper, we explore the\npossibility of rationalising email communication using GPT-3. First, we\ndemonstrate the technical feasibility of understanding incoming emails and\ngenerating responses, drawing on literature from the disciplines of software\nengineering as well as data science. Second, we apply knowledge from both\nbusiness studies and, again, software engineering to identify ways to tackle\nchallenges we encountered. Third, we argue for the economic viability of such a\nsolution by analysing costs and market demand. We conclude that applying GPT-3\nto rationalising email communication is feasible both technically and\neconomically.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:56:42 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 15:15:38 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 11:11:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Thiergart", "Jonas", ""], ["Huber", "Stefan", ""], ["\u00dcbellacker", "Thomas", ""]]}, {"id": "2102.03064", "submitter": "Yotam Amitai", "authors": "Yotam Amitai and Ofra Amir", "title": "\"I Don't Think So\": Disagreement-Based Policy Summaries for Comparing\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With Artificial Intelligence on the rise, human interaction with autonomous\nagents becomes more frequent. Effective human-agent collaboration requires that\nthe human understands the agent's behavior, as failing to do so may lead to\nreduced productiveness, misuse, frustration and even danger. Agent strategy\nsummarization methods are used to describe the strategy of an agent to its\ndestined user through demonstration. The summary's purpose is to maximize the\nuser's understanding of the agent's aptitude by showcasing its behaviour in a\nset of world states, chosen by some importance criteria. While shown to be\nuseful, we show that these methods are limited in supporting the task of\ncomparing agent behavior, as they independently generate a summary for each\nagent. In this paper, we propose a novel method for generating contrastive\nsummaries that highlight the differences between agent's policies by\nidentifying and ranking states in which the agents disagree on the best course\nof action. We conduct a user study in which participants face an agent\nselection task. Our results show that the novel disagreement-based summaries\nlead to improved user performance compared to summaries generated using\nHIGHLIGHTS, a previous strategy summarization algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 09:09:00 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Amitai", "Yotam", ""], ["Amir", "Ofra", ""]]}, {"id": "2102.03065", "submitter": "Jang-Hyun Kim", "authors": "Jang-Hyun Kim, Wonho Choo, Hosan Jeong, Hyun Oh Song", "title": "Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity", "comments": "Published at ICLR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks show great performance on fitting to the training\ndistribution, improving the networks' generalization performance to the test\ndistribution and robustness to the sensitivity to input perturbations still\nremain as a challenge. Although a number of mixup based augmentation strategies\nhave been proposed to partially address them, it remains unclear as to how to\nbest utilize the supervisory signal within each input data for mixup from the\noptimization perspective. We propose a new perspective on batch mixup and\nformulate the optimal construction of a batch of mixup data maximizing the data\nsaliency measure of each individual mixup data and encouraging the supermodular\ndiversity among the constructed mixup data. This leads to a novel discrete\noptimization problem minimizing the difference between submodular functions. We\nalso propose an efficient modular approximation based iterative submodular\nminimization algorithm for efficient mixup computation per each minibatch\nsuitable for minibatch based neural network training. Our experiments show the\nproposed method achieves the state of the art generalization, calibration, and\nweakly supervised localization results compared to other mixup methods. The\nsource code is available at https://github.com/snu-mllab/Co-Mixup.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 09:12:02 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Choo", "Wonho", ""], ["Jeong", "Hosan", ""], ["Song", "Hyun Oh", ""]]}, {"id": "2102.03082", "submitter": "Harshana Habaragamuwa", "authors": "Harshana Habaragamuwa, Yu Oishi, Kenichi Tanaka", "title": "Achieving Explainability for Plant Disease Classification with\n  Disentangled Variational Autoencoders", "comments": "45 pages, 21 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agricultural image recognition tasks are becoming increasingly dependent on\ndeep learning (DL). Despite its excellent performance, it is difficult to\ncomprehend what type of logic or features DL uses in its decision making. This\nhas become a roadblock for the implementation and development of DL-based image\nrecognition methods because knowing the logic or features used in decision\nmaking, such as in a classification task, is very important for verification,\nalgorithm improvement, training data improvement, knowledge extraction, etc. To\nmitigate such problems, we developed a classification method based on a\nvariational autoencoder architecture that can show not only the location of the\nmost important features but also what variations of that particular feature are\nused. Using the PlantVillage dataset, we achieved an acceptable level of\nexplainability without sacrificing the accuracy of the classification. Although\nthe proposed method was tested for disease diagnosis in some crops, the method\ncan be extended to other crops as well as other image classification tasks. In\nthe future, we hope to use this explainable artificial intelligence algorithm\nin disease identification tasks, such as the identification of potato blackleg\ndisease and potato virus Y (PVY), and other image classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 10:04:00 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 01:26:55 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Habaragamuwa", "Harshana", ""], ["Oishi", "Yu", ""], ["Tanaka", "Kenichi", ""]]}, {"id": "2102.03119", "submitter": "Julian Bernhard", "authors": "Julian Bernhard, Stefan Pollok and Alois Knoll", "title": "Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for\n  Automated Driving using Distributional Reinforcement Learning", "comments": "Published at IEEE IV 2019", "journal-ref": null, "doi": "10.1109/IVS.2019.8813791", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  For highly automated driving above SAE level~3, behavior generation\nalgorithms must reliably consider the inherent uncertainties of the traffic\nenvironment, e.g. arising from the variety of human driving styles. Such\nuncertainties can generate ambiguous decisions, requiring the algorithm to\nappropriately balance low-probability hazardous events, e.g. collisions, and\nhigh-probability beneficial events, e.g. quickly crossing the intersection.\nState-of-the-art behavior generation algorithms lack a distributional treatment\nof decision outcome. This impedes a proper risk evaluation in ambiguous\nsituations, often encouraging either unsafe or conservative behavior. Thus, we\npropose a two-step approach for risk-sensitive behavior generation combining\noffline distribution learning with online risk assessment. Specifically, we\nfirst learn an optimal policy in an uncertain environment with Deep\nDistributional Reinforcement Learning. During execution, the optimal\nrisk-sensitive action is selected by applying established risk criteria, such\nas the Conditional Value at Risk, to the learned state-action return\ndistributions. In intersection crossing scenarios, we evaluate different risk\ncriteria and demonstrate that our approach increases safety, while maintaining\nan active driving style. Our approach shall encourage further studies about the\nbenefits of risk-sensitive approaches for self-driving vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 11:45:12 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bernhard", "Julian", ""], ["Pollok", "Stefan", ""], ["Knoll", "Alois", ""]]}, {"id": "2102.03127", "submitter": "Julian Bernhard", "authors": "Julian Bernhard, Robert Gieselmann, Klemens Esterle and Alois Knoll", "title": "Experience-Based Heuristic Search: Robust Motion Planning with Deep\n  Q-Learning", "comments": "published at IEEE IV 2018", "journal-ref": null, "doi": "10.1109/ITSC.2018.8569436", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Interaction-aware planning for autonomous driving requires an exploration of\na combinatorial solution space when using conventional search- or\noptimization-based motion planners. With Deep Reinforcement Learning, optimal\ndriving strategies for such problems can be derived also for higher-dimensional\nproblems. However, these methods guarantee optimality of the resulting policy\nonly in a statistical sense, which impedes their usage in safety critical\nsystems, such as autonomous vehicles. Thus, we propose the\nExperience-Based-Heuristic-Search algorithm, which overcomes the statistical\nfailure rate of a Deep-reinforcement-learning-based planner and still benefits\ncomputationally from the pre-learned optimal policy. Specifically, we show how\nexperiences in the form of a Deep Q-Network can be integrated as heuristic into\na heuristic search algorithm. We benchmark our algorithm in the field of path\nplanning in semi-structured valet parking scenarios. There, we analyze the\naccuracy of such estimates and demonstrate the computational advantages and\nrobustness of our method. Our method may encourage further investigation of the\napplicability of reinforcement-learning-based planning in the field of\nself-driving vehicles.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:08:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bernhard", "Julian", ""], ["Gieselmann", "Robert", ""], ["Esterle", "Klemens", ""], ["Knoll", "Alois", ""]]}, {"id": "2102.03138", "submitter": "Chengmin Zhou", "authors": "Chengmin Zhou, Bingding Huang, Pasi Fr\\\"anti", "title": "An advantage actor-critic algorithm for robotic motion planning in dense\n  and dynamic scenarios", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent robots provide a new insight into efficiency improvement in\nindustrial and service scenarios to replace human labor. However, these\nscenarios include dense and dynamic obstacles that make motion planning of\nrobots challenging. Traditional algorithms like A* can plan collision-free\ntrajectories in static environment, but their performance degrades and\ncomputational cost increases steeply in dense and dynamic scenarios.\nOptimal-value reinforcement learning algorithms (RL) can address these problems\nbut suffer slow speed and instability in network convergence. Network of policy\ngradient RL converge fast in Atari games where action is discrete and finite,\nbut few works have been done to address problems where continuous actions and\nlarge action space are required. In this paper, we modify existing advantage\nactor-critic algorithm and suit it to complex motion planning, therefore\noptimal speeds and directions of robot are generated. Experimental results\ndemonstrate that our algorithm converges faster and stable than optimal-value\nRL. It achieves higher success rate in motion planning with lesser processing\ntime for robot to reach its goal.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:30:23 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhou", "Chengmin", ""], ["Huang", "Bingding", ""], ["Fr\u00e4nti", "Pasi", ""]]}, {"id": "2102.03140", "submitter": "Giuseppe Paolo Mr", "authors": "Giuseppe Paolo (1 and 2), Alexandre Coninx (1), Stephane Doncieux (1),\n  Alban Laflaqui\\`ere (2) ((1) ISIR, (2) SBRE)", "title": "Sparse Reward Exploration via Novelty Search and Emitters", "comments": "In 2021 Genetic and Evolutionary Computation Conference (GECCO 21),\n  July, 2021, Lille, France. ACM, New York, NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3449639.3459314", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward-based optimization algorithms require both exploration, to find\nrewards, and exploitation, to maximize performance. The need for efficient\nexploration is even more significant in sparse reward settings, in which\nperformance feedback is given sparingly, thus rendering it unsuitable for\nguiding the search process. In this work, we introduce the SparsE Reward\nExploration via Novelty and Emitters (SERENE) algorithm, capable of efficiently\nexploring a search space, as well as optimizing rewards found in potentially\ndisparate areas. Contrary to existing emitters-based approaches, SERENE\nseparates the search space exploration and reward exploitation into two\nalternating processes. The first process performs exploration through Novelty\nSearch, a divergent search algorithm. The second one exploits discovered reward\nareas through emitters, i.e. local instances of population-based optimization\nalgorithms. A meta-scheduler allocates a global computational budget by\nalternating between the two processes, ensuring the discovery and efficient\nexploitation of disjoint reward areas. SERENE returns both a collection of\ndiverse solutions covering the search space and a collection of high-performing\nsolutions for each distinct reward area. We evaluate SERENE on various sparse\nreward environments and show it compares favorably to existing baselines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:34:54 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 08:33:19 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Paolo", "Giuseppe", "", "1 and 2"], ["Coninx", "Alexandre", "", "ISIR"], ["Doncieux", "Stephane", "", "ISIR"], ["Laflaqui\u00e8re", "Alban", "", "SBRE"]]}, {"id": "2102.03159", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Kaibo Zhang, Yingzhen Li, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Active Slices for Sliced Stein Discrepancy", "comments": "22 pages, 7 figures, International Conference on Machine Learning\n  (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced Stein discrepancy (SSD) and its kernelized variants have demonstrated\npromising successes in goodness-of-fit tests and model learning in high\ndimensions. Despite their theoretical elegance, their empirical performance\ndepends crucially on the search of optimal slicing directions to discriminate\nbetween two distributions. Unfortunately, previous gradient-based optimisation\napproaches for this task return sub-optimal results: they are computationally\nexpensive, sensitive to initialization, and they lack theoretical guarantees\nfor convergence. We address these issues in two steps. First, we provide\ntheoretical results stating that the requirement of using optimal slicing\ndirections in the kernelized version of SSD can be relaxed, validating the\nresulting discrepancy with finite random slicing directions. Second, given that\ngood slicing directions are crucial for practical performance, we propose a\nfast algorithm for finding such slicing directions based on ideas of active\nsub-space construction and spectral decomposition. Experiments on\ngoodness-of-fit tests and model learning show that our approach achieves both\nimproved performance and faster convergence. Especially, we demonstrate a\n14-80x speed-up in goodness-of-fit tests when comparing with gradient-based\nalternatives.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 13:33:17 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 12:34:41 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 13:14:19 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Gong", "Wenbo", ""], ["Zhang", "Kaibo", ""], ["Li", "Yingzhen", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2102.03200", "submitter": "Sarod Yatawatta", "authors": "Sarod Yatawatta and Ian M. Avruch", "title": "Deep reinforcement learning for smart calibration of radio telescopes", "comments": "MNRAS Accepted 2021 May 12. Received 2021 May 11; in original form\n  2021 February 5", "journal-ref": null, "doi": "10.1093/mnras/stab1401", "report-no": null, "categories": "astro-ph.IM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern radio telescopes produce unprecedented amounts of data, which are\npassed through many processing pipelines before the delivery of scientific\nresults. Hyperparameters of these pipelines need to be tuned by hand to produce\noptimal results. Because many thousands of observations are taken during a\nlifetime of a telescope and because each observation will have its unique\nsettings, the fine tuning of pipelines is a tedious task. In order to automate\nthis process of hyperparameter selection in data calibration pipelines, we\nintroduce the use of reinforcement learning. We test two reinforcement learning\ntechniques, twin delayed deep deterministic policy gradient (TD3) and soft\nactor-critic (SAC), to train an autonomous agent to perform this fine tuning.\nFor the sake of generalization, we consider the pipeline to be a black-box\nsystem where the summarized state of the performance of the pipeline is used by\nthe autonomous agent. The autonomous agent trained in this manner is able to\ndetermine optimal settings for diverse observations and is therefore able to\nperform 'smart' calibration, minimizing the need for human intervention.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 14:35:28 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 07:57:49 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 17:24:02 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Yatawatta", "Sarod", ""], ["Avruch", "Ian M.", ""]]}, {"id": "2102.03207", "submitter": "Hyeong-Seok Choi", "authors": "Hyeong-Seok Choi, Sungjin Park, Jie Hwan Lee, Hoon Heo, Dongsuk Jeon,\n  Kyogu Lee", "title": "Real-time Denoising and Dereverberation with Tiny Recurrent U-Net", "comments": "5 pages, 2 figures, 2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP). arXiv admin note: text overlap with\n  arXiv:2006.00687", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern deep learning-based models have seen outstanding performance\nimprovement with speech enhancement tasks. The number of parameters of\nstate-of-the-art models, however, is often too large to be deployed on devices\nfor real-world applications. To this end, we propose Tiny Recurrent U-Net\n(TRU-Net), a lightweight online inference model that matches the performance of\ncurrent state-of-the-art models. The size of the quantized version of TRU-Net\nis 362 kilobytes, which is small enough to be deployed on edge devices. In\naddition, we combine the small-sized model with a new masking method called\nphase-aware $\\beta$-sigmoid mask, which enables simultaneous denoising and\ndereverberation. Results of both objective and subjective evaluations have\nshown that our model can achieve competitive performance with the current\nstate-of-the-art models on benchmark datasets using fewer parameters by orders\nof magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 14:46:41 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 09:01:08 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 03:08:42 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Choi", "Hyeong-Seok", ""], ["Park", "Sungjin", ""], ["Lee", "Jie Hwan", ""], ["Heo", "Hoon", ""], ["Jeon", "Dongsuk", ""], ["Lee", "Kyogu", ""]]}, {"id": "2102.03218", "submitter": "Ahmad Ahmadzade", "authors": "Ahmad Ahmadzade and Saber Malekzadeh", "title": "Spell Correction for Azerbaijani Language using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spell correction is used to detect and correct orthographic mistakes in\ntexts. Most of the time, traditional dictionary lookup with string similarity\nmethods is suitable for the languages that have a less complex structure such\nas the English language. However, the Azerbaijani language has a more complex\nstructure and due to its morphological structure, the derivation of words is\nplenty that several words are derived from adding suffices, affixes to the\nwords. Therefore, in this paper sequence to sequence model with an attention\nmechanism is used to develop spelling correction for Azerbaijani. Total 12000\nwrong and correct sentence pairs used for training, and the model is tested on\n1000 real-world misspelled words and F1-score results are 75% for distance 0,\n90% for distance 1, and 96% for distance 2.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:02:35 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Ahmadzade", "Ahmad", ""], ["Malekzadeh", "Saber", ""]]}, {"id": "2102.03243", "submitter": "Rafael Pereira Msc", "authors": "Rafael S. Pereira, Alexis Joly, Patrick Valduriez, Fabio Porto", "title": "Hyperspherical embedding for novel class classification", "comments": "9 pages with 10 figures and 6 tables. Not currently published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have become increasingly useful in many different\nindustries. On the domain of image classification, convolutional neural\nnetworks proved the ability to learn robust features for the closed set\nproblem, as shown in many different datasets, such as MNIST FASHIONMNIST,\nCIFAR10, CIFAR100, and IMAGENET. These approaches use deep neural networks with\ndense layers with softmax activation functions in order to learn features that\ncan separate classes in a latent space. However, this traditional approach is\nnot useful for identifying classes unseen on the training set, known as the\nopen set problem. A similar problem occurs in scenarios involving learning on\nsmall data. To tackle both problems, few-shot learning has been proposed. In\nparticular, metric learning learns features that obey constraints of a metric\ndistance in the latent space in order to perform classification. However, while\nthis approach proves to be useful for the open set problem, current\nimplementation requires pair-wise training, where both positive and negative\nexamples of similar images are presented during the training phase, which\nlimits the applicability of these approaches in large data or large class\nscenarios given the combinatorial nature of the possible inputs.In this paper,\nwe present a constraint-based approach applied to the representations in the\nlatent space under the normalized softmax loss, proposed by[18]. We\nexperimentally validate the proposed approach for the classification of unseen\nclasses on different datasets using both metric learning and the normalized\nsoftmax loss, on disjoint and joint scenarios. Our results show that not only\nour proposed strategy can be efficiently trained on larger set of classes, as\nit does not require pairwise learning, but also present better classification\nresults than the metric learning strategies surpassing its accuracy by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:42:13 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Pereira", "Rafael S.", ""], ["Joly", "Alexis", ""], ["Valduriez", "Patrick", ""], ["Porto", "Fabio", ""]]}, {"id": "2102.03289", "submitter": "Amir Rasouli", "authors": "Amir Rasouli", "title": "Pedestrian Simulation: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on different aspects of pedestrian (crowd) modeling and\nsimulation. The review includes: various modeling criteria, such as\ngranularity, techniques, and factors involved in modeling pedestrian behavior,\nand different pedestrian simulation methods with a more detailed look at two\napproaches for simulating pedestrian behavior in traffic scenes. At the end,\nbenefits and drawbacks of different simulation techniques are discussed and\nrecommendations are made for future research.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:00:10 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Rasouli", "Amir", ""]]}, {"id": "2102.03302", "submitter": "Shuliang Xu", "authors": "Shuliang Xu, Shenglan Liu, Lin Feng", "title": "Self-Supervised Deep Graph Embedding with High-Order Information Fusion\n  for Community Discovery", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep graph embedding is an important approach for community discovery. Deep\ngraph neural network with self-supervised mechanism can obtain the\nlow-dimensional embedding vectors of nodes from unlabeled and unstructured\ngraph data. The high-order information of graph can provide more abundant\nstructure information for the representation learning of nodes. However, most\nself-supervised graph neural networks only use adjacency matrix as the input\ntopology information of graph and cannot obtain too high-order information\nsince the number of layers of graph neural network is fairly limited. If there\nare too many layers, the phenomenon of over smoothing will appear. Therefore\nhow to obtain and fuse high-order information of graph by a shallow graph\nneural network is an important problem. In this paper, a deep graph embedding\nalgorithm with self-supervised mechanism for community discovery is proposed.\nThe proposed algorithm uses self-supervised mechanism and different high-order\ninformation of graph to train multiple deep graph convolution neural networks.\nThe outputs of multiple graph convolution neural networks are fused to extract\nthe representations of nodes which include the attribute and structure\ninformation of a graph. In addition, data augmentation and negative sampling\nare introduced into the training process to facilitate the improvement of\nembedding result. The proposed algorithm and the comparison algorithms are\nconducted on the five experimental data sets. The experimental results show\nthat the proposed algorithm outperforms the comparison algorithms on the most\nexperimental data sets. The experimental results demonstrate that the proposed\nalgorithm is an effective algorithm for community discovery.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:22:28 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 06:38:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Xu", "Shuliang", ""], ["Liu", "Shenglan", ""], ["Feng", "Lin", ""]]}, {"id": "2102.03314", "submitter": "Emiliano De Cristofaro", "authors": "Bristena Oprisanu and Georgi Ganev and Emiliano De Cristofaro", "title": "Measuring Utility and Privacy of Synthetic Genomic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of genomic data is often essential to progress in biomedical\nresearch, personalized medicine, drug development, etc. However, its extreme\nsensitivity makes it problematic, if not outright impossible, to publish or\nshare it. As a result, several initiatives have been launched to experiment\nwith synthetic genomic data, e.g., using generative models to learn the\nunderlying distribution of the real data and generate artificial datasets that\npreserve its salient characteristics without exposing it. This paper provides\nthe first evaluation of the utility and the privacy protection of six\nstate-of-the-art models for generating synthetic genomic data. We assess the\nperformance of the synthetic data on several common tasks, such as allele\npopulation statistics and linkage disequilibrium. We then measure privacy\nthrough the lens of membership inference attacks, i.e., inferring whether a\nrecord was part of the training data. Our experiments show that no single\napproach to generate synthetic genomic data yields both high utility and strong\nprivacy across the board. Also, the size and nature of the training dataset\nmatter. Moreover, while some combinations of datasets and models produce\nsynthetic data with distributions close to the real data, there often are\ntarget data points that are vulnerable to membership inference. Looking\nforward, our techniques can be used by practitioners to assess the risks of\ndeploying synthetic genomic data in the wild and serve as a benchmark for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:41:01 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:23:38 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Oprisanu", "Bristena", ""], ["Ganev", "Georgi", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "2102.03315", "submitter": "Peter Clark", "authors": "Sumithra Bhakthavatsalam, Daniel Khashabi, Tushar Khot, Bhavana Dalvi\n  Mishra, Kyle Richardson, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord,\n  Peter Clark", "title": "Think you have Solved Direct-Answer Question Answering? Try ARC-DA, the\n  Direct-Answer AI2 Reasoning Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the ARC-DA dataset, a direct-answer (\"open response\", \"freeform\")\nversion of the ARC (AI2 Reasoning Challenge) multiple-choice dataset. While ARC\nhas been influential in the community, its multiple-choice format is\nunrepresentative of real-world questions, and multiple choice formats can be\nparticularly susceptible to artifacts. The ARC-DA dataset addresses these\nconcerns by converting questions to direct-answer format using a combination of\ncrowdsourcing and expert review. The resulting dataset contains 2985 questions\nwith a total of 8436 valid answers (questions typically have more than one\nvalid answer). ARC-DA is one of the first DA datasets of natural questions that\noften require reasoning, and where appropriate question decompositions are not\nevident from the questions themselves. We describe the conversion approach\ntaken, appropriate evaluation metrics, and several strong models. Although\nhigh, the best scores (81% GENIE, 61.4% F1, 63.2% ROUGE-L) still leave\nconsiderable room for improvement. In addition, the dataset provides a natural\nsetting for new research on explanation, as many questions require reasoning to\nconstruct answers. We hope the dataset spurs further advances in complex\nquestion-answering by the community. ARC-DA is available at\nhttps://allenai.org/data/arc-da\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:41:43 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Bhakthavatsalam", "Sumithra", ""], ["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Mishra", "Bhavana Dalvi", ""], ["Richardson", "Kyle", ""], ["Sabharwal", "Ashish", ""], ["Schoenick", "Carissa", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""]]}, {"id": "2102.03322", "submitter": "Ana Lucic", "authors": "Ana Lucic, Maartje ter Hoeve, Gabriele Tolomei, Maarten de Rijke,\n  Fabrizio Silvestri", "title": "CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing promise of Graph Neural Networks (GNNs) in real-world\napplications, several methods have been developed for explaining their\npredictions. So far, these methods have primarily focused on generating\nsubgraphs that are especially relevant for a particular prediction. However,\nsuch methods do not provide a clear opportunity for recourse: given a\nprediction, we want to understand how the prediction can be changed in order to\nachieve a more desirable outcome. In this work, we propose a method for\ngenerating counterfactual (CF) explanations for GNNs: the minimal perturbation\nto the input (graph) data such that the prediction changes. Using only edge\ndeletions, we find that our method, CF-GNNExplainer can generate CF\nexplanations for the majority of instances across three widely used datasets\nfor GNN explanations, while removing less than 3 edges on average, with at\nleast 94\\% accuracy. This indicates that CF-GNNExplainer primarily removes\nedges that are crucial for the original predictions, resulting in minimal CF\nexplanations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:58:14 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 15:05:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Lucic", "Ana", ""], ["ter Hoeve", "Maartje", ""], ["Tolomei", "Gabriele", ""], ["de Rijke", "Maarten", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "2102.03357", "submitter": "Xuefei Ning", "authors": "Guyue Huang, Jingbo Hu, Yifan He, Jialong Liu, Mingyuan Ma, Zhaoyang\n  Shen, Juejian Wu, Yuanfan Xu, Hengrui Zhang, Kai Zhong, Xuefei Ning, Yuzhe\n  Ma, Haoyu Yang, Bei Yu, Huazhong Yang, Yu Wang", "title": "Machine Learning for Electronic Design Automation: A Survey", "comments": "Accepted by TODAES. The first 10 authors are ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the down-scaling of CMOS technology, the design complexity of very\nlarge-scale integrated (VLSI) is increasing. Although the application of\nmachine learning (ML) techniques in electronic design automation (EDA) can\ntrace its history back to the 90s, the recent breakthrough of ML and the\nincreasing complexity of EDA tasks have aroused more interests in incorporating\nML to solve EDA tasks. In this paper, we present a comprehensive review of\nexisting ML for EDA studies, organized following the EDA hierarchy.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2021 12:54:37 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 08:18:35 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Huang", "Guyue", ""], ["Hu", "Jingbo", ""], ["He", "Yifan", ""], ["Liu", "Jialong", ""], ["Ma", "Mingyuan", ""], ["Shen", "Zhaoyang", ""], ["Wu", "Juejian", ""], ["Xu", "Yuanfan", ""], ["Zhang", "Hengrui", ""], ["Zhong", "Kai", ""], ["Ning", "Xuefei", ""], ["Ma", "Yuzhe", ""], ["Yang", "Haoyu", ""], ["Yu", "Bei", ""], ["Yang", "Huazhong", ""], ["Wang", "Yu", ""]]}, {"id": "2102.03380", "submitter": "Manuel L\\'opez-Ib\\'a\\~nez", "authors": "Manuel L\\'opez-Ib\\'a\\~nez (University of M\\'alaga, Spain), Juergen\n  Branke (University of Warwick, UK), Lu\\'is Paquete (University of Coimbra,\n  Portugal)", "title": "Reproducibility in Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental studies are prevalent in Evolutionary Computation (EC), and\nconcerns about the reproducibility and replicability of such studies have\nincreased in recent times, reflecting similar concerns in other scientific\nfields. In this article, we discuss, within the context of EC, the different\ntypes of reproducibility and suggest a classification that refines the badge\nsystem of the Association of Computing Machinery (ACM) adopted by ACM\nTransactions on Evolutionary Learning and Optimization\n(https://dlnext.acm.org/journal/telo). We identify cultural and technical\nobstacles to reproducibility in the EC field. Finally, we provide guidelines\nand suggest tools that may help to overcome some of these reproducibility\nobstacles.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:06:35 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 16:24:25 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["L\u00f3pez-Ib\u00e1\u00f1ez", "Manuel", "", "University of M\u00e1laga, Spain"], ["Branke", "Juergen", "", "University of Warwick, UK"], ["Paquete", "Lu\u00eds", "", "University of Coimbra,\n  Portugal"]]}, {"id": "2102.03381", "submitter": "Leffey Xie", "authors": "Lehui Xie, Yaopeng Wang, Jia-Li Yin, and Ximeng Liu", "title": "Robust Single-step Adversarial Training with Regularizer", "comments": "7 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High cost of training time caused by multi-step adversarial example\ngeneration is a major challenge in adversarial training. Previous methods try\nto reduce the computational burden of adversarial training using single-step\nadversarial example generation schemes, which can effectively improve the\nefficiency but also introduce the problem of catastrophic overfitting, where\nthe robust accuracy against Fast Gradient Sign Method (FGSM) can achieve nearby\n100\\% whereas the robust accuracy against Projected Gradient Descent (PGD)\nsuddenly drops to 0\\% over a single epoch. To address this problem, we propose\na novel Fast Gradient Sign Method with PGD Regularization (FGSMPR) to boost the\nefficiency of adversarial training without catastrophic overfitting. Our core\nidea is that single-step adversarial training can not learn robust internal\nrepresentations of FGSM and PGD adversarial examples. Therefore, we design a\nPGD regularization term to encourage similar embeddings of FGSM and PGD\nadversarial examples. The experiments demonstrate that our proposed method can\ntrain a robust deep network for L$_\\infty$-perturbations with FGSM adversarial\ntraining and reduce the gap to multi-step adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:07:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Xie", "Lehui", ""], ["Wang", "Yaopeng", ""], ["Yin", "Jia-Li", ""], ["Liu", "Ximeng", ""]]}, {"id": "2102.03401", "submitter": "Tengchan Zeng", "authors": "Tengchan Zeng, Omid Semiari, Mingzhe Chen, Walid Saad, and Mehdi\n  Bennis", "title": "Federated Learning on the Road: Autonomous Controller Design for\n  Connected and Autonomous Vehicles", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new federated learning (FL) framework enabled by large-scale wireless\nconnectivity is proposed for designing the autonomous controller of connected\nand autonomous vehicles (CAVs). In this framework, the learning models used by\nthe controllers are collaboratively trained among a group of CAVs. To capture\nthe varying CAV participation in the FL training process and the diverse local\ndata quality among CAVs, a novel dynamic federated proximal (DFP) algorithm is\nproposed that accounts for the mobility of CAVs, the wireless fading channels,\nas well as the unbalanced and nonindependent and identically distributed data\nacross CAVs. A rigorous convergence analysis is performed for the proposed\nalgorithm to identify how fast the CAVs converge to using the optimal\nautonomous controller. In particular, the impacts of varying CAV participation\nin the FL process and diverse CAV data quality on the convergence of the\nproposed DFP algorithm are explicitly analyzed. Leveraging this analysis, an\nincentive mechanism based on contract theory is designed to improve the FL\nconvergence speed. Simulation results using real vehicular data traces show\nthat the proposed DFP-based controller can accurately track the target CAV\nspeed over time and under different traffic scenarios. Moreover, the results\nshow that the proposed DFP algorithm has a much faster convergence compared to\npopular FL algorithms such as federated averaging (FedAvg) and federated\nproximal (FedProx). The results also validate the feasibility of the\ncontract-theoretic incentive mechanism and show that the proposed mechanism can\nimprove the convergence speed of the DFP algorithm by 40% compared to the\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:57:47 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zeng", "Tengchan", ""], ["Semiari", "Omid", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2102.03406", "submitter": "Adam Santoro", "authors": "Adam Santoro, Andrew Lampinen, Kory Mathewson, Timothy Lillicrap,\n  David Raposo", "title": "Symbolic Behaviour in Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to use symbols is the pinnacle of human intelligence, but has yet\nto be fully replicated in machines. Here we argue that the path towards\nsymbolically fluent artificial intelligence (AI) begins with a reinterpretation\nof what symbols are, how they come to exist, and how a system behaves when it\nuses them. We begin by offering an interpretation of symbols as entities whose\nmeaning is established by convention. But crucially, something is a symbol only\nfor those who demonstrably and actively participate in this convention. We then\noutline how this interpretation thematically unifies the behavioural traits\nhumans exhibit when they use symbols. This motivates our proposal that the\nfield place a greater emphasis on symbolic behaviour rather than particular\ncomputational mechanisms inspired by more restrictive interpretations of\nsymbols. Finally, we suggest that AI research explore social and cultural\nengagement as a tool to develop the cognitive machinery necessary for symbolic\nbehaviour to emerge. This approach will allow for AI to interpret something as\nsymbolic on its own rather than simply manipulate things that are only symbols\nto human onlookers, and thus will ultimately lead to AI with more human-like\nsymbolic fluency.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 20:07:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Santoro", "Adam", ""], ["Lampinen", "Andrew", ""], ["Mathewson", "Kory", ""], ["Lillicrap", "Timothy", ""], ["Raposo", "David", ""]]}, {"id": "2102.03409", "submitter": "Wei Jiang", "authors": "Wei Jiang, Hans Dieter Schotten", "title": "A Simple Cooperative Diversity Method Based on Deep-Learning-Aided Relay\n  Selection", "comments": "arXiv admin note: text overlap with arXiv:2102.03325", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opportunistic relay selection (ORS) has been recognized as a simple but\nefficient method for mobile nodes to achieve cooperative diversity in slow\nfading channels. However, the wrong selection of the best relay arising from\noutdated channel state information (CSI) in fast time-varying channels\nsubstantially degrades its performance. With the proliferation of high-mobility\napplications and the adoption of higher frequency bands in 5G and beyond\nsystems, the problem of outdated CSI will become more serious. Therefore, the\ndesign of a novel cooperative method that is applicable to not only slow fading\nbut also fast fading is increasingly of importance. To this end, we develop and\nanalyze a deep-learning-aided cooperative method coined predictive relay\nselection (PRS) in this article. It can remarkably improve the quality of CSI\nthrough fading channel prediction while retaining the simplicity of ORS by\nselecting a single opportunistic relay so as to avoid the complexity of\nmulti-relay coordination and synchronization. Information-theoretic analysis\nand numerical results in terms of outage probability and channel capacity\nreveal that PRS achieves full diversity gain in slow fading wireless\nenvironments and substantially outperforms the existing schemes in fast fading\nchannels.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 20:20:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Jiang", "Wei", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "2102.03419", "submitter": "Dora Jambor", "authors": "Dora Jambor, Komal Teru, Joelle Pineau, William L. Hamilton", "title": "Exploring the Limits of Few-Shot Link Prediction in Knowledge Graphs", "comments": "code available at\n  https://github.com/dorajam/few-shot-link-prediction-paper", "journal-ref": "European Chapter of the ACL (EACL), 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world knowledge graphs are often characterized by low-frequency\nrelations - a challenge that has prompted an increasing interest in few-shot\nlink prediction methods. These methods perform link prediction for a set of new\nrelations, unseen during training, given only a few example facts of each\nrelation at test time. In this work, we perform a systematic study on a\nspectrum of models derived by generalizing the current state of the art for\nfew-shot link prediction, with the goal of probing the limits of learning in\nthis few-shot setting. We find that a simple zero-shot baseline - which ignores\nany relation-specific information - achieves surprisingly strong performance.\nMoreover, experiments on carefully crafted synthetic datasets show that having\nonly a few examples of a relation fundamentally limits models from using\nfine-grained structural information and only allows for exploiting the\ncoarse-grained positional information of entities. Together, our findings\nchallenge the implicit assumptions and inductive biases of prior work and\nhighlight new directions for research in this area.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 21:04:31 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Jambor", "Dora", ""], ["Teru", "Komal", ""], ["Pineau", "Joelle", ""], ["Hamilton", "William L.", ""]]}, {"id": "2102.03442", "submitter": "Yan Lu", "authors": "Yan Lu and Yuanchao Shu", "title": "Custom Object Detection via Multi-Camera Self-Supervised Learning", "comments": "7 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes MCSSL, a self-supervised learning approach for building\ncustom object detection models in multi-camera networks. MCSSL associates\nbounding boxes between cameras with overlapping fields of view by leveraging\nepipolar geometry and state-of-the-art tracking and reID algorithms, and\nprudently generates two sets of pseudo-labels to fine-tune backbone and\ndetection networks respectively in an object detection model. To train\neffectively on pseudo-labels,a powerful reID-like pretext task with consistency\nloss is constructed for model customization. Our evaluation shows that compared\nwith legacy selftraining methods, MCSSL improves average mAP by 5.44% and 6.76%\non WildTrack and CityFlow dataset, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 23:11:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lu", "Yan", ""], ["Shu", "Yuanchao", ""]]}, {"id": "2102.03456", "submitter": "Nael Fasfous", "authors": "Nael Fasfous, Manoj-Rohit Vemparala, Alexander Frickenstein, Lukas\n  Frickenstein, Walter Stechele", "title": "BinaryCoP: Binary Neural Network-based COVID-19 Face-Mask Wear and\n  Positioning Predictor on Edge Devices", "comments": "Accepted at IEEE IPDPS-RAW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Face masks have long been used in many areas of everyday life to protect\nagainst the inhalation of hazardous fumes and particles. They also offer an\neffective solution in healthcare for bi-directional protection against\nair-borne diseases. Wearing and positioning the mask correctly is essential for\nits function. Convolutional neural networks (CNNs) offer an excellent solution\nfor face recognition and classification of correct mask wearing and\npositioning. In the context of the ongoing COVID-19 pandemic, such algorithms\ncan be used at entrances to corporate buildings, airports, shopping areas, and\nother indoor locations, to mitigate the spread of the virus. These application\nscenarios impose major challenges to the underlying compute platform. The\ninference hardware must be cheap, small and energy efficient, while providing\nsufficient memory and compute power to execute accurate CNNs at a reasonably\nlow latency. To maintain data privacy of the public, all processing must remain\non the edge-device, without any communication with cloud servers. To address\nthese challenges, we present a low-power binary neural network classifier for\ncorrect facial-mask wear and positioning. The classification task is\nimplemented on an embedded FPGA, performing high-throughput binary operations.\nClassification can take place at up to ~6400 frames-per-second, easily enabling\nmulti-camera, speed-gate settings or statistics collection in crowd settings.\nWhen deployed on a single entrance or gate, the idle power consumption is\nreduced to 1.6W, improving the battery-life of the device. We achieve an\naccuracy of up to 98% for four wearing positions of the MaskedFace-Net dataset.\nTo maintain equivalent classification accuracy for all face structures,\nskin-tones, hair types, and mask types, the algorithms are tested for their\nability to generalize the relevant features over all subjects using the\nGrad-CAM approach.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 00:14:06 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 08:48:39 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Fasfous", "Nael", ""], ["Vemparala", "Manoj-Rohit", ""], ["Frickenstein", "Alexander", ""], ["Frickenstein", "Lukas", ""], ["Stechele", "Walter", ""]]}, {"id": "2102.03467", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave", "title": "Improving Model and Search for Computer Go", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The standard for Deep Reinforcement Learning in games, following Alpha Zero,\nis to use residual networks and to increase the depth of the network to get\nbetter results. We propose to improve mobile networks as an alternative to\nresidual networks and experimentally show the playing strength of the networks\naccording to both their width and their depth. We also propose a generalization\nof the PUCT search algorithm that improves on PUCT.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 01:20:17 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 10:50:20 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Cazenave", "Tristan", ""]]}, {"id": "2102.03479", "submitter": "Jian Hu", "authors": "Jian Hu, Siyang Jiang, Seth Austin Harding, Haibin Wu, Shih-wei Liao", "title": "Rethinking the Implementation Tricks and Monotonicity Constraint in\n  Cooperative Multi-Agent Reinforcement Learning", "comments": "add experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex multi-robot systems such as robot swarms control and autonomous\nvehicle coordination can be modeled as Multi-Agent Reinforcement Learning\n(MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a\nbaseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge\n(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX\ntarget relaxing the monotonicity constraint of QMIX, allowing for performance\nimprovement in SMAC. In this paper, we investigate the code-level optimizations\nof these variants and the monotonicity constraint. (1) We find that such\nimprovements of the variants are significantly affected by various code-level\noptimizations. (2) The experiment results show that QMIX with normalized\noptimizations outperforms other works in SMAC; (3) beyond the common wisdom\nfrom these works, the monotonicity constraint can improve sample efficiency in\nSMAC and DEPP. We also discuss why monotonicity constraints work well in purely\ncooperative tasks with a theoretical analysis. We open-source the code at\n\\url{https://github.com/hijkzzz/pymarl2}.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 02:28:09 GMT"}, {"version": "v10", "created": "Thu, 13 May 2021 13:06:58 GMT"}, {"version": "v11", "created": "Mon, 7 Jun 2021 07:54:45 GMT"}, {"version": "v12", "created": "Thu, 1 Jul 2021 07:37:31 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 14:01:38 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 15:37:05 GMT"}, {"version": "v4", "created": "Tue, 9 Mar 2021 13:46:31 GMT"}, {"version": "v5", "created": "Thu, 11 Mar 2021 08:29:17 GMT"}, {"version": "v6", "created": "Mon, 15 Mar 2021 06:21:44 GMT"}, {"version": "v7", "created": "Fri, 9 Apr 2021 03:39:11 GMT"}, {"version": "v8", "created": "Mon, 19 Apr 2021 09:00:01 GMT"}, {"version": "v9", "created": "Wed, 21 Apr 2021 08:38:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hu", "Jian", ""], ["Jiang", "Siyang", ""], ["Harding", "Seth Austin", ""], ["Wu", "Haibin", ""], ["Liao", "Shih-wei", ""]]}, {"id": "2102.03483", "submitter": "Haowei Sun", "authors": "Haowei Sun, Shuo Feng, Xintao Yan, Henry X. Liu", "title": "Corner Case Generation and Analysis for Safety Assessment of Autonomous\n  Vehicles", "comments": "23 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing and evaluation is a crucial step in the development and deployment of\nConnected and Automated Vehicles (CAVs). To comprehensively evaluate the\nperformance of CAVs, it is of necessity to test the CAVs in safety-critical\nscenarios, which rarely happen in naturalistic driving environment. Therefore,\nhow to purposely and systematically generate these corner cases becomes an\nimportant problem. Most existing studies focus on generating adversarial\nexamples for perception systems of CAVs, whereas limited efforts have been put\non the decision-making systems, which is the highlight of this paper. As the\nCAVs need to interact with numerous background vehicles (BVs) for a long\nduration, variables that define the corner cases are usually high dimensional,\nwhich makes the generation a challenging problem. In this paper, a unified\nframework is proposed to generate corner cases for the decision-making systems.\nTo address the challenge brought by high dimensionality, the driving\nenvironment is formulated based on Markov Decision Process, and the deep\nreinforcement learning techniques are applied to learn the behavior policy of\nBVs. With the learned policy, BVs will behave and interact with the CAVs more\naggressively, resulting in more corner cases. To further analyze the generated\ncorner cases, the techniques of feature extraction and clustering are utilized.\nBy selecting representative cases of each cluster and outliers, the valuable\ncorner cases can be identified from all generated corner cases. Simulation\nresults of a highway driving environment show that the proposed methods can\neffectively generate and identify the valuable corner cases.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 02:48:23 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sun", "Haowei", ""], ["Feng", "Shuo", ""], ["Yan", "Xintao", ""], ["Liu", "Henry X.", ""]]}, {"id": "2102.03494", "submitter": "Jie Lin", "authors": "Yuxiao Lu, Jie Lin, Chao Jin, Zhe Wang, Khin Mi Mi Aung, Xiaoli Li", "title": "FFConv: Fast Factorized Neural Network Inference on Encrypted Data", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homomorphic Encryption (HE), allowing computations on encrypted data\n(ciphertext) without decrypting it first, enables secure but prohibitively slow\nNeural Network (HENN) inference for privacy-preserving applications in clouds.\nTo reduce HENN inference latency, one approach is to pack multiple messages\ninto a single ciphertext in order to reduce the number of ciphertexts and\nsupport massive parallelism of Homomorphic Multiply-Add (HMA) operations\nbetween ciphertexts. However, different ciphertext packing schemes have to be\ndesigned for different convolution layers and each of them introduces overheads\nthat are far more expensive than HMA operations. In this paper, we propose a\nlow-rank factorization method called FFConv to unify convolution and ciphertext\npacking. To our knowledge, FFConv is the first work that is capable of\naccelerating the overheads induced by different ciphertext packing schemes\nsimultaneously, without incurring a significant increase in noise budget.\nCompared to prior art LoLa and Falcon, our method reduces the inference latency\nby up to 87% and 12%, respectively, with comparable accuracy on MNIST and\nCIFAR-10.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 03:10:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lu", "Yuxiao", ""], ["Lin", "Jie", ""], ["Jin", "Chao", ""], ["Wang", "Zhe", ""], ["Aung", "Khin Mi Mi", ""], ["Li", "Xiaoli", ""]]}, {"id": "2102.03502", "submitter": "Zhenhan Huang", "authors": "Zhenhan Huang, Fumihide Tanaka", "title": "MSPM: A Modularized and Scalable Multi-Agent Reinforcement\n  Learning-based System for Financial Portfolio Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.AI cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial portfolio management is one of the most applicable problems in\nreinforcement learning (RL) owing to its sequential decision-making nature.\nExisting RL-based approaches, while inspiring, often lack scalability,\nreusability, or profundity of intake information to accommodate the\never-changing capital markets. In this paper, we propose MSPM, a modularized\nand scalable, multi-agent RL-based system for financial portfolio management.\nMSPM involves two asynchronously updated units: an Evolving Agent Module (EAM)\nand Strategic Agent Module (SAM). A self-sustained EAM produces\nsignal-comprised information for a specific asset using heterogeneous data\ninputs, and each EAM employs its reusability to have connections to multiple\nSAMs. An SAM is responsible for asset reallocation in a portfolio using\nprofound information from the connected EAMs. With the elaborate architecture\nand the multi-step condensation of volatile market information, MSPM aims to\nprovide a customizable, stable, and dedicated solution to portfolio management,\nunlike existing approaches. We also tackle the data-shortage issue of\nnewly-listed stocks by transfer learning, and validate the indispensability of\nEAM with four different portfolios. Experiments on 8-year U.S. stock market\ndata prove the effectiveness of MSPM in profit accumulation, by its\noutperformance over existing benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 04:04:57 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 16:19:01 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:42:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Huang", "Zhenhan", ""], ["Tanaka", "Fumihide", ""]]}, {"id": "2102.03529", "submitter": "Martin Suda", "authors": "Martin Suda", "title": "Vampire With a Brain Is a Good ITP Hammer", "comments": "14.5 pages excluding references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vampire has been for a long time the strongest first-order automatic theorem\nprover, widely used for hammer-style proof automation in ITPs such as Mizar,\nIsabelle, HOL, and Coq. In this work, we considerably improve the performance\nof Vampire in hammering over the full Mizar library by enhancing its saturation\nprocedure with efficient neural guidance. In particular, we employ a recently\nproposed recursive neural network classifying the generated clauses based only\non their derivation history. Compared to previous neural methods based on\nconsidering the logical content of the clauses, our architecture makes\nevaluating a single clause much less time consuming. The resulting system shows\ngood learning capability and improves on the state-of-the-art performance on\nthe Mizar library, while proving many theorems that the related ENIGMA system\ncould not prove in a similar hammering evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 07:24:53 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:52:19 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Suda", "Martin", ""]]}, {"id": "2102.03532", "submitter": "Maheshi Dissanayake", "authors": "Shanaka Ramesh Gunasekara and H.N.T.K.Kaldera and Maheshi B.\n  Dissanayake", "title": "A Systematic Approach for MRI Brain Tumor Localization, and Segmentation\n  using Deep Learning and Active Contouring", "comments": "accepted for publication in Journal of Healthcare Engineering,\n  Hindawi in 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the main requirements of tumor extraction is the annotation and\nsegmentation of tumor boundaries correctly. For this purpose, we present a\nthreefold deep learning architecture. First classifiers are implemented with a\ndeep convolutional neural network(CNN) andsecond a region-based convolutional\nneural network (R-CNN) is performed on the classified images to localize the\ntumor regions of interest. As the third and final stage, the concentratedtumor\nboundary is contoured for the segmentation process by using the\nChan-Vesesegmentation algorithm. As the typical edge detection algorithms based\non gradients of pixel intensity tend to fail in the medical image segmentation\nprocess, an active contour algorithm defined with the level set function is\nproposed. Specifically, Chan- Vese algorithm was applied to detect the tumor\nboundaries for the segmentation process. To evaluate the performance of the\noverall system, Dice Score,Rand Index (RI), Variation of Information (VOI),\nGlobal Consistency Error (GCE), Boundary Displacement Error (BDE), Mean\nabsolute error (MAE), and Peak Signal to Noise Ratio (PSNR) werecalculated by\ncomparing the segmented boundary area which is the final output of the\nproposed, against the demarcations of the subject specialists which is the gold\nstandard. Overall performance of the proposed architecture for both glioma and\nmeningioma segmentation is with average dice score of 0.92, (also, with RI of\n0.9936, VOI of 0.0301, GCE of 0.004, BDE of 2.099, PSNR of 77.076 and MAE of\n52.946), pointing to high reliability of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 07:53:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gunasekara", "Shanaka Ramesh", ""], ["Kaldera", "H. N. T. K.", ""], ["Dissanayake", "Maheshi B.", ""]]}, {"id": "2102.03551", "submitter": "Ernie Chang", "authors": "Ernie Chang, Vera Demberg, Alex Marin", "title": "Jointly Improving Language Understanding and Generation with\n  Quality-Weighted Weak Supervision of Automatic Labeling", "comments": "Accepted at EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural natural language generation (NLG) and understanding (NLU) models are\ndata-hungry and require massive amounts of annotated data to be competitive.\nRecent frameworks address this bottleneck with generative models that\nsynthesize weak labels at scale, where a small amount of training labels are\nexpert-curated and the rest of the data is automatically annotated. We follow\nthat approach, by automatically constructing a large-scale weakly-labeled data\nwith a fine-tuned GPT-2, and employ a semi-supervised framework to jointly\ntrain the NLG and NLU models. The proposed framework adapts the parameter\nupdates to the models according to the estimated label-quality. On both the E2E\nand Weather benchmarks, we show that this weakly supervised training paradigm\nis an effective approach under low resource scenarios and outperforming\nbenchmark systems on both datasets when 100% of training data is used.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 10:06:15 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chang", "Ernie", ""], ["Demberg", "Vera", ""], ["Marin", "Alex", ""]]}, {"id": "2102.03555", "submitter": "Davide Andrea Guastella", "authors": "Davide Andrea Guastella", "title": "Scheduling Plans of Tasks", "comments": "Internship done at LIP6 in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a heuristic algorithm for solving the problem of scheduling plans\nof tasks. The plans are ordered vectors of tasks, and tasks are basic\noperations carried out by resources. Plans are tied by temporal, precedence and\nresource constraints that makes the scheduling problem hard to solve in\npolynomial time. The proposed heuristic, that has a polynomial worst-case time\ncomplexity, searches for a feasible schedule that maximize the number of plans\nscheduled, along a fixed time window, with respect to temporal, precedence and\nresource constraints.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 10:14:54 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Guastella", "Davide Andrea", ""]]}, {"id": "2102.03577", "submitter": "Zhi Zheng", "authors": "Zhi Zheng, Chao Wang, Tong Xu, Dazhong Shen, Penggang Qin, Baoxing\n  Huai, Tongzhu Liu, Enhong Chen", "title": "Drug Package Recommendation via Interaction-aware Graph Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rapid accumulation of massive electronic\nmedical records (EMRs), which highly support the intelligent medical services\nsuch as drug recommendation. However, prior arts mainly follow the traditional\nrecommendation strategies like collaborative filtering, which usually treat\nindividual drugs as mutually independent, while the latent interactions among\ndrugs, e.g., synergistic or antagonistic effect, have been largely ignored. To\nthat end, in this paper, we target at developing a new paradigm for drug\npackage recommendation with considering the interaction effect within drugs, in\nwhich the interaction effects could be affected by patient conditions.\nSpecifically, we first design a pre-training method based on neural\ncollaborative filtering to get the initial embedding of patients and drugs.\nThen, the drug interaction graph will be initialized based on medical records\nand domain knowledge. Along this line, we propose a new Drug Package\nRecommendation (DPR) framework with two variants, respectively DPR on Weighted\nGraph (DPR-WG) and DPR on Attributed Graph (DPR-AG) to solve the problem, in\nwhich each the interactions will be described as signed weights or attribute\nvectors. In detail, a mask layer is utilized to capture the impact of patient\ncondition, and graph neural networks (GNNs) are leveraged for the final graph\ninduction task to embed the package. Extensive experiments on a real-world data\nset from a first-rate hospital demonstrate the effectiveness of our DPR\nframework compared with several competitive baseline methods, and further\nsupport the heuristic study for the drug package generation task with adequate\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 12:51:00 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zheng", "Zhi", ""], ["Wang", "Chao", ""], ["Xu", "Tong", ""], ["Shen", "Dazhong", ""], ["Qin", "Penggang", ""], ["Huai", "Baoxing", ""], ["Liu", "Tongzhu", ""], ["Chen", "Enhong", ""]]}, {"id": "2102.03588", "submitter": "Ayan Sengupta", "authors": "Ayan Sengupta, Yasser Mohammad, Shinji Nakadai", "title": "An Autonomous Negotiating Agent Framework with Reinforcement Learning\n  Based Strategies and Adaptive Strategy Switching Mechanism", "comments": "Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite abundant negotiation strategies in literature, the complexity of\nautomated negotiation forbids a single strategy from being dominant against all\nothers in different negotiation scenarios. To overcome this, one approach is to\nuse mixture of experts, but at the same time, one problem of this method is the\nselection of experts, as this approach is limited by the competency of the\nexperts selected. Another problem with most negotiation strategies is their\nincapability of adapting to dynamic variation of the opponent's behaviour\nwithin a single negotiation session resulting in poor performance. This work\nfocuses on both, solving the problem of expert selection and adapting to the\nopponent's behaviour with our Autonomous Negotiating Agent Framework. This\nframework allows real-time classification of opponent's behaviour and provides\na mechanism to select, switch or combine strategies within a single negotiation\nsession. Additionally, our framework has a reviewer component which enables\nself-enhancement capability by deciding to include new strategies or replace\nold ones with better strategies periodically. We demonstrate an instance of our\nframework by implementing maximum entropy reinforcement learning based\nstrategies with a deep learning based opponent classifier. Finally, we evaluate\nthe performance of our agent against state-of-the-art negotiators under varied\nnegotiation scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 14:38:03 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 11:34:40 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sengupta", "Ayan", ""], ["Mohammad", "Yasser", ""], ["Nakadai", "Shinji", ""]]}, {"id": "2102.03688", "submitter": "Zhou Zhou", "authors": "Zhou Zhou, Kangjun Bai, Nima Mohammadi, Yang Yi, Lingjia Liu", "title": "Making Intelligent Reflecting Surfaces More Intelligent: A Roadmap\n  Through Reservoir Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a neural network-based signal processing framework\nfor intelligent reflecting surface (IRS) aided wireless communications systems.\nBy modeling radio-frequency (RF) impairments inside the \"meta-atoms\" of IRS\n(including nonlinearity and memory effects), we present an approach that\ngeneralizes the entire IRS-aided system as a reservoir computing (RC) system,\nan efficient recurrent neural network (RNN) operating in a state near the \"edge\nof chaos\". This framework enables us to take advantage of the nonlinearity of\nthis \"fabricated\" wireless environment to overcome link degradation due to\nmodel mismatch. Accordingly, the randomness of the wireless channel and RF\nimperfections are naturally embedded into the RC framework, enabling the\ninternal RC dynamics lying on the edge of chaos. Furthermore, several practical\nissues, such as channel state information acquisition, passive beamforming\ndesign, and physical layer reference signal design, are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 23:55:46 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhou", "Zhou", ""], ["Bai", "Kangjun", ""], ["Mohammadi", "Nima", ""], ["Yi", "Yang", ""], ["Liu", "Lingjia", ""]]}, {"id": "2102.03716", "submitter": "Zhuo Feng", "authors": "Wuxinlin Cheng, Chenhui Deng, Zhiqiang Zhao, Yaohui Cai, Zhiru Zhang,\n  Zhuo Feng", "title": "SPADE: A Spectral Method for Black-Box Adversarial Robustness Evaluation", "comments": "The 2021 International Conference on Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A black-box spectral method is introduced for evaluating the adversarial\nrobustness of a given machine learning (ML) model. Our approach, named SPADE,\nexploits bijective distance mapping between the input/output graphs constructed\nfor approximating the manifolds corresponding to the input/output data. By\nleveraging the generalized Courant-Fischer theorem, we propose a SPADE score\nfor evaluating the adversarial robustness of a given model, which is proved to\nbe an upper bound of the best Lipschitz constant under the manifold setting. To\nreveal the most non-robust data samples highly vulnerable to adversarial\nattacks, we develop a spectral graph embedding procedure leveraging dominant\ngeneralized eigenvectors. This embedding step allows assigning each data sample\na robustness score that can be further harnessed for more effective adversarial\ntraining. Our experiments show the proposed SPADE method leads to promising\nempirical results for neural network models that are adversarially trained with\nthe MNIST and CIFAR-10 data sets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 04:41:26 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 16:09:39 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 23:02:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Cheng", "Wuxinlin", ""], ["Deng", "Chenhui", ""], ["Zhao", "Zhiqiang", ""], ["Cai", "Yaohui", ""], ["Zhang", "Zhiru", ""], ["Feng", "Zhuo", ""]]}, {"id": "2102.03719", "submitter": "Siddharth Aravindan", "authors": "Siddharth Aravindan, Wee Sun Lee", "title": "State-Aware Variational Thompson Sampling for Deep Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thompson sampling is a well-known approach for balancing exploration and\nexploitation in reinforcement learning. It requires the posterior distribution\nof value-action functions to be maintained; this is generally intractable for\ntasks that have a high dimensional state-action space. We derive a variational\nThompson sampling approximation for DQNs which uses a deep network whose\nparameters are perturbed by a learned variational noise distribution. We\ninterpret the successful NoisyNets method \\cite{fortunato2018noisy} as an\napproximation to the variational Thompson sampling method that we derive.\nFurther, we propose State Aware Noisy Exploration (SANE) which seeks to improve\non NoisyNets by allowing a non-uniform perturbation, where the amount of\nparameter perturbation is conditioned on the state of the agent. This is done\nwith the help of an auxiliary perturbation module, whose output is state\ndependent and is learnt end to end with gradient descent. We hypothesize that\nsuch state-aware noisy exploration is particularly useful in problems where\nexploration in certain \\textit{high risk} states may result in the agent\nfailing badly. We demonstrate the effectiveness of the state-aware exploration\nmethod in the off-policy setting by augmenting DQNs with the auxiliary\nperturbation module.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 05:06:03 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Aravindan", "Siddharth", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2102.03773", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Andrea Bragagnolo, Francesco Odierna, Attilio\n  Fiandrotti, Marco Grangetto", "title": "SeReNe: Sensitivity based Regularization of Neurons for Structured\n  Sparsity in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks include millions of learnable parameters, making their\ndeployment over resource-constrained devices problematic. SeReNe\n(Sensitivity-based Regularization of Neurons) is a method for learning sparse\ntopologies with a structure, exploiting neural sensitivity as a regularizer. We\ndefine the sensitivity of a neuron as the variation of the network output with\nrespect to the variation of the activity of the neuron. The lower the\nsensitivity of a neuron, the less the network output is perturbed if the neuron\noutput changes. By including the neuron sensitivity in the cost function as a\nregularization term, we areable to prune neurons with low sensitivity. As\nentire neurons are pruned rather then single parameters, practical network\nfootprint reduction becomes possible. Our experimental results on multiple\nnetwork architectures and datasets yield competitive compression ratios with\nrespect to state-of-the-art references.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 10:53:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Bragagnolo", "Andrea", ""], ["Odierna", "Francesco", ""], ["Fiandrotti", "Attilio", ""], ["Grangetto", "Marco", ""]]}, {"id": "2102.03799", "submitter": "Ofir Nabati", "authors": "Ofir Nabati, Tom Zahavy and Shie Mannor", "title": "Online Limited Memory Neural-Linear Bandits with Likelihood Matching", "comments": "ICML 2021. arXiv admin note: text overlap with arXiv:1901.08612", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study neural-linear bandits for solving problems where {\\em both}\nexploration and representation learning play an important role. Neural-linear\nbandits harnesses the representation power of Deep Neural Networks (DNNs) and\ncombines it with efficient exploration mechanisms by leveraging uncertainty\nestimation of the model, designed for linear contextual bandits on top of the\nlast hidden layer. In order to mitigate the problem of representation change\nduring the process, new uncertainty estimations are computed using stored data\nfrom an unlimited buffer. Nevertheless, when the amount of stored data is\nlimited, a phenomenon called catastrophic forgetting emerges. To alleviate\nthis, we propose a likelihood matching algorithm that is resilient to\ncatastrophic forgetting and is completely online. We applied our algorithm,\nLimited Memory Neural-Linear with Likelihood Matching (NeuralLinear-LiM2) on a\nvariety of datasets and observed that our algorithm achieves comparable\nperformance to the unlimited memory approach while exhibits resilience to\ncatastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 14:19:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 12:32:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nabati", "Ofir", ""], ["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.03814", "submitter": "Theerawit Wilaiprasitporn", "authors": "Phairot Autthasan, Rattanaphon Chaisaen, Thapanun Sudhawiyangkul,\n  Phurin Rangpong, Suktipol Kiatthaveephong, Nat Dilokthanakul, Gun\n  Bhakdisongkhram, Huy Phan, Cuntai Guan and Theerawit Wilaiprasitporn", "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor\n  Imagery EEG Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)\nallow control of several applications by decoding neurophysiological phenomena,\nwhich are usually recorded by electroencephalography (EEG) using a non-invasive\ntechnique. Despite great advances in MI-based BCI, EEG rhythms are specific to\na subject and various changes over time. These issues point to significant\nchallenges to enhance the classification performance, especially in a\nsubject-independent manner. To overcome these challenges, we propose MIN2Net, a\nnovel end-to-end multi-task learning to tackle this task. We integrate deep\nmetric learning into a multi-task autoencoder to learn a compact and\ndiscriminative latent representation from EEG and perform classification\nsimultaneously. This approach reduces the complexity in pre-processing, results\nin significant performance improvement on EEG classification. Experimental\nresults in a subject-independent manner show that MIN2Net outperforms the\nstate-of-the-art techniques, achieving an F1-score improvement of 6.72%, and\n2.23% on the SMR-BCI, and OpenBMI datasets, respectively. We demonstrate that\nMIN2Net improves discriminative information in the latent representation. This\nstudy indicates the possibility and practicality of using this model to develop\nMI-based BCI applications for new users without the need for calibration.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 15:20:23 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 08:03:59 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 09:48:47 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Autthasan", "Phairot", ""], ["Chaisaen", "Rattanaphon", ""], ["Sudhawiyangkul", "Thapanun", ""], ["Rangpong", "Phurin", ""], ["Kiatthaveephong", "Suktipol", ""], ["Dilokthanakul", "Nat", ""], ["Bhakdisongkhram", "Gun", ""], ["Phan", "Huy", ""], ["Guan", "Cuntai", ""], ["Wilaiprasitporn", "Theerawit", ""]]}, {"id": "2102.03827", "submitter": "Utkarsh Desai", "authors": "Utkarsh Desai, Sambaran Bandyopadhyay, Srikanth Tamilselvam", "title": "Graph Neural Network to Dilute Outliers for Refactoring Monolith\n  Application", "comments": "Published: AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microservices are becoming the defacto design choice for software\narchitecture. It involves partitioning the software components into finer\nmodules such that the development can happen independently. It also provides\nnatural benefits when deployed on the cloud since resources can be allocated\ndynamically to necessary components based on demand. Therefore, enterprises as\npart of their journey to cloud, are increasingly looking to refactor their\nmonolith application into one or more candidate microservices; wherein each\nservice contains a group of software entities (e.g., classes) that are\nresponsible for a common functionality. Graphs are a natural choice to\nrepresent a software system. Each software entity can be represented as nodes\nand its dependencies with other entities as links. Therefore, this problem of\nrefactoring can be viewed as a graph based clustering task. In this work, we\npropose a novel method to adapt the recent advancements in graph neural\nnetworks in the context of code to better understand the software and apply\nthem in the clustering task. In that process, we also identify the outliers in\nthe graph which can be directly mapped to top refactor candidates in the\nsoftware. Our solution is able to improve state-of-the-art performance compared\nto works from both software engineering and existing graph representation based\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 16:00:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Desai", "Utkarsh", ""], ["Bandyopadhyay", "Sambaran", ""], ["Tamilselvam", "Srikanth", ""]]}, {"id": "2102.03868", "submitter": "M. F. Mridha", "authors": "M. F. Mridha, Abu Quwsar Ohi, M. Ameer Ali, Muhammad Mostafa Monowar,\n  Md. Abdul Hamid", "title": "U-vectors: Generating clusterable speaker embedding from unlabeled data", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker recognition deals with recognizing speakers by their speech.\nStrategies related to speaker recognition may explore speech timbre properties,\naccent, speech patterns and so on. Supervised speaker recognition has been\ndramatically investigated. However, through rigorous excavation, we have found\nthat unsupervised speaker recognition systems mostly depend on domain\nadaptation policy. This paper introduces a speaker recognition strategy dealing\nwith unlabeled data, which generates clusterable embedding vectors from small\nfixed-size speech frames. The unsupervised training strategy involves an\nassumption that a small speech segment should include a single speaker.\nDepending on such a belief, we construct pairwise constraints to train twin\ndeep learning architectures with noise augmentation policies, that generate\nspeaker embeddings. Without relying on domain adaption policy, the process\nunsupervisely produces clusterable speaker embeddings, and we name it\nunsupervised vectors (u-vectors). The evaluation is concluded in two popular\nspeaker recognition datasets for English language, TIMIT, and LibriSpeech.\nAlso, we include a Bengali dataset, Bengali ASR, to illustrate the diversity of\nthe domain shifts for speaker recognition systems. Finally, we conclude that\nthe proposed approach achieves remarkable performance using pairwise\narchitectures.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 18:00:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mridha", "M. F.", ""], ["Ohi", "Abu Quwsar", ""], ["Ali", "M. Ameer", ""], ["Monowar", "Muhammad Mostafa", ""], ["Hamid", "Md. Abdul", ""]]}, {"id": "2102.03870", "submitter": "Punyajoy Saha", "authors": "Punyajoy Saha, Binny Mathew, Kiran Garimella, Animesh Mukherjee", "title": "\"Short is the Road that Leads from Fear to Hate\": Fear Speech in Indian\n  WhatsApp Groups", "comments": "13 pages, 9 figures, 8 tables, Accepted at The Web Conference 2021,\n  code and dataset public at https://github.com/punyajoy/Fear-Speech-analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp is the most popular messaging app in the world. Due to its\npopularity, WhatsApp has become a powerful and cheap tool for political\ncampaigning being widely used during the 2019 Indian general election, where it\nwas used to connect to the voters on a large scale. Along with the campaigning,\nthere have been reports that WhatsApp has also become a breeding ground for\nharmful speech against various protected groups and religious minorities. Many\nsuch messages attempt to instil fear among the population about a specific\n(minority) community. According to research on inter-group conflict, such `fear\nspeech' messages could have a lasting impact and might lead to real offline\nviolence. In this paper, we perform the first large scale study on fear speech\nacross thousands of public WhatsApp groups discussing politics in India. We\ncurate a new dataset and try to characterize fear speech from this dataset. We\nobserve that users writing fear speech messages use various events and symbols\nto create the illusion of fear among the reader about a target community. We\nbuild models to classify fear speech and observe that current state-of-the-art\nNLP models do not perform well at this task. Fear speech messages tend to\nspread faster and could potentially go undetected by classifiers built to\ndetect traditional toxic speech due to their low toxic nature. Finally, using a\nnovel methodology to target users with Facebook ads, we conduct a survey among\nthe users of these WhatsApp groups to understand the types of users who consume\nand share fear speech. We believe that this work opens up new research\nquestions that are very different from tackling hate speech which the research\ncommunity has been traditionally involved in.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 18:14:16 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Saha", "Punyajoy", ""], ["Mathew", "Binny", ""], ["Garimella", "Kiran", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2102.03874", "submitter": "Wlodek Zadrozny", "authors": "Wlodek W. Zadrozny", "title": "A Note on Argumentative Topology: Circularity and Syllogisms as Unsolved\n  Problems", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last couple of years there were a few attempts to apply topological\ndata analysis to text, and in particular to natural language inference. A\nrecent work by Tymochko et al. suggests the possibility of capturing `the\nnotion of logical shape in text,' using `topological delay embeddings,' a\ntechnique derived from dynamical systems, applied to word embeddings.\n  In this note we reconstruct their argument and show, using several old and\nnew examples, that the problem of connecting logic, topology and text is still\nvery much unsolved. We conclude that there is no clear answer to the question:\n``Can we find a circle in a circular argument?'' We point out some possible\navenues of exploration. The code used in our experiment is also shown.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 18:30:37 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zadrozny", "Wlodek W.", ""]]}, {"id": "2102.03896", "submitter": "Simon Zhuang", "authors": "Simon Zhuang, Dylan Hadfield-Menell", "title": "Consequences of Misaligned AI", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI systems often rely on two key components: a specified goal or reward\nfunction and an optimization algorithm to compute the optimal behavior for that\ngoal. This approach is intended to provide value for a principal: the user on\nwhose behalf the agent acts. The objectives given to these agents often refer\nto a partial specification of the principal's goals. We consider the cost of\nthis incompleteness by analyzing a model of a principal and an agent in a\nresource constrained world where the $L$ attributes of the state correspond to\ndifferent sources of utility for the principal. We assume that the reward\nfunction given to the agent only has support on $J < L$ attributes. The\ncontributions of our paper are as follows: 1) we propose a novel model of an\nincomplete principal-agent problem from artificial intelligence; 2) we provide\nnecessary and sufficient conditions under which indefinitely optimizing for any\nincomplete proxy objective leads to arbitrarily low overall utility; and 3) we\nshow how modifying the setup to allow reward functions that reference the full\nstate or allowing the principal to update the proxy objective over time can\nlead to higher utility solutions. The results in this paper argue that we\nshould view the design of reward functions as an interactive and dynamic\nprocess and identifies a theoretical scenario where some degree of\ninteractivity is desirable.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 19:34:04 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhuang", "Simon", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "2102.03909", "submitter": "Yufan Zhou", "authors": "Yufan Zhou, Zhenyi Wang, Jiayi Xian, Changyou Chen, Jinhui Xu", "title": "Meta-Learning with Neural Tangent Kernels", "comments": "Accepted by ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Agnostic Meta-Learning (MAML) has emerged as a standard framework for\nmeta-learning, where a meta-model is learned with the ability of fast adapting\nto new tasks. However, as a double-looped optimization problem, MAML needs to\ndifferentiate through the whole inner-loop optimization path for every\nouter-loop training step, which may lead to both computational inefficiency and\nsub-optimal solutions. In this paper, we generalize MAML to allow meta-learning\nto be defined in function spaces, and propose the first meta-learning paradigm\nin the Reproducing Kernel Hilbert Space (RKHS) induced by the meta-model's\nNeural Tangent Kernel (NTK). Within this paradigm, we introduce two\nmeta-learning algorithms in the RKHS, which no longer need a sub-optimal\niterative inner-loop adaptation as in the MAML framework. We achieve this goal\nby 1) replacing the adaptation with a fast-adaptive regularizer in the RKHS;\nand 2) solving the adaptation analytically based on the NTK theory. Extensive\nexperimental studies demonstrate advantages of our paradigm in both efficiency\nand quality of solutions compared to related meta-learning algorithms. Another\ninteresting feature of our proposed methods is that they are demonstrated to be\nmore robust to adversarial attacks and out-of-distribution adaptation than\npopular baselines, as demonstrated in our experiments.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 20:53:23 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 02:28:15 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhou", "Yufan", ""], ["Wang", "Zhenyi", ""], ["Xian", "Jiayi", ""], ["Chen", "Changyou", ""], ["Xu", "Jinhui", ""]]}, {"id": "2102.03919", "submitter": "Scott Cheng-Hsin Yang", "authors": "Scott Cheng-Hsin Yang, Wai Keen Vong, Ravi B. Sojitra, Tomas Folke,\n  Patrick Shafto", "title": "Mitigating belief projection in explainable artificial intelligence via\n  Bayesian Teaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art deep-learning systems use decision rules that are\nchallenging for humans to model. Explainable AI (XAI) attempts to improve human\nunderstanding but rarely accounts for how people typically reason about\nunfamiliar agents. We propose explicitly modeling the human explainee via\nBayesian Teaching, which evaluates explanations by how much they shift\nexplainees' inferences toward a desired goal. We assess Bayesian Teaching in a\nbinary image classification task across a variety of contexts. Absent\nintervention, participants predict that the AI's classifications will match\ntheir own, but explanations generated by Bayesian Teaching improve their\nability to predict the AI's judgements by moving them away from this prior\nbelief. Bayesian Teaching further allows each case to be broken down into\nsub-examples (here saliency maps). These sub-examples complement whole examples\nby improving error detection for familiar categories, whereas whole examples\nhelp predict correct AI judgements of unfamiliar cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 21:23:24 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 15:05:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yang", "Scott Cheng-Hsin", ""], ["Vong", "Wai Keen", ""], ["Sojitra", "Ravi B.", ""], ["Folke", "Tomas", ""], ["Shafto", "Patrick", ""]]}, {"id": "2102.03921", "submitter": "Roman Malashin", "authors": "Roman Malashin ((1) Pavlov institute of Physiology RAS, (2) State\n  University of Aerospace Instrumentation, Saint-Petersburg, Russia)", "title": "Sparsely ensembled convolutional neural network classifiers via\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider convolutional neural network (CNN) ensemble learning with the\nobjective function inspired by least action principle; it includes resource\nconsumption component. We teach an agent to perceive images through the set of\npre-trained classifiers and want the resulting dynamically configured system to\nunfold the computational graph with the trajectory that refers to the minimal\nnumber of operations and maximal expected accuracy. The proposed agent's\narchitecture implicitly approximates the required classifier selection function\nwith the help of reinforcement learning. Our experimental results prove, that\nif the agent exploits the dynamic (and context-dependent) structure of\ncomputations, it outperforms conventional ensemble learning.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 21:26:57 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Malashin", "Roman", ""]]}, {"id": "2102.03935", "submitter": "Ramin Bostanabad", "authors": "Nicholas Oune, Ramin Bostanabad", "title": "Latent Map Gaussian Processes for Mixed Variable Metamodeling", "comments": "35 Pages, 7 Figures, 14 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are ubiquitously used in sciences and engineering as\nmetamodels. Standard GPs, however, can only handle numerical or quantitative\nvariables. In this paper, we introduce latent map Gaussian processes (LMGPs)\nthat inherit the attractive properties of GPs and are also applicable to mixed\ndata which have both quantitative and qualitative inputs. The core idea behind\nLMGPs is to learn a continuous, low-dimensional latent space or manifold which\nencodes all qualitative inputs. To learn this manifold, we first assign a\nunique prior vector representation to each combination of qualitative inputs.\nWe then use a low-rank linear map to project these priors on a manifold that\ncharacterizes the posterior representations. As the posteriors are\nquantitative, they can be directly used in any standard correlation function\nsuch as the Gaussian or Matern. Hence, the optimal map and the corresponding\nmanifold, along with other hyperparameters of the correlation function, can be\nsystematically learned via maximum likelihood estimation. Through a wide range\nof analytic and real-world examples, we demonstrate the advantages of LMGPs\nover state-of-the-art methods in terms of accuracy and versatility. In\nparticular, we show that LMGPs can handle variable-length inputs, have an\nexplainable neural network interpretation, and provide insights into how\nqualitative inputs affect the response or interact with each other. We also\nemploy LMGPs in Bayesian optimization and illustrate that they can discover\noptimal compound compositions more efficiently than conventional methods that\nconvert compositions to qualitative variables via manual featurization.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 22:21:53 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 19:20:37 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Oune", "Nicholas", ""], ["Bostanabad", "Ramin", ""]]}, {"id": "2102.03957", "submitter": "Ivine Kuruvila", "authors": "Ivine Kuruvila, Jan Muncke, Eghart Fischer, Ulrich Hoppe", "title": "Extracting the Auditory Attention in a Dual-Speaker Scenario from EEG\n  using a Joint CNN-LSTM Model", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain performs remarkably well in segregating a particular speaker from\ninterfering ones in a multi-speaker scenario. It has been recently shown that\nwe can quantitatively evaluate the segregation capability by modelling the\nrelationship between the speech signals present in an auditory scene and the\ncortical signals of the listener measured using electroencephalography (EEG).\nThis has opened up avenues to integrate neuro-feedback into hearing aids\nwhereby the device can infer user's attention and enhance the attended speaker.\nCommonly used algorithms to infer the auditory attention are based on linear\nsystems theory where the speech cues such as envelopes are mapped on to the EEG\nsignals. Here, we present a joint convolutional neural network (CNN) - long\nshort-term memory (LSTM) model to infer the auditory attention. Our joint\nCNN-LSTM model takes the EEG signals and the spectrogram of the multiple\nspeakers as inputs and classifies the attention to one of the speakers. We\nevaluated the reliability of our neural network using three different datasets\ncomprising of 61 subjects where, each subject undertook a dual-speaker\nexperiment. The three datasets analysed corresponded to speech stimuli\npresented in three different languages namely German, Danish and Dutch. Using\nthe proposed joint CNN-LSTM model, we obtained a median decoding accuracy of\n77.2% at a trial duration of three seconds. Furthermore, we evaluated the\namount of sparsity that our model can tolerate by means of magnitude pruning\nand found that the model can tolerate up to 50% sparsity without substantial\nloss of decoding accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 01:06:48 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 02:07:18 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kuruvila", "Ivine", ""], ["Muncke", "Jan", ""], ["Fischer", "Eghart", ""], ["Hoppe", "Ulrich", ""]]}, {"id": "2102.03977", "submitter": "Sainyam Galhotra", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Learning to Generate Fair Clusters from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair clustering is the process of grouping similar entities together, while\nsatisfying a mathematically well-defined fairness metric as a constraint. Due\nto the practical challenges in precise model specification, the prescribed\nfairness constraints are often incomplete and act as proxies to the intended\nfairness requirement, leading to biased outcomes when the system is deployed.\nWe examine how to identify the intended fairness constraint for a problem based\non limited demonstrations from an expert. Each demonstration is a clustering\nover a subset of the data.\n  We present an algorithm to identify the fairness metric from demonstrations\nand generate clusters using existing off-the-shelf clustering techniques, and\nanalyze its theoretical properties. To extend our approach to novel fairness\nmetrics for which clustering algorithms do not currently exist, we present a\ngreedy method for clustering. Additionally, we investigate how to generate\ninterpretable solutions using our approach. Empirical evaluation on three\nreal-world datasets demonstrates the effectiveness of our approach in quickly\nidentifying the underlying fairness and interpretability constraints, which are\nthen used to generate fair and interpretable clusters.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:09:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2102.03983", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zechun Liu and Jie Qin and Marios Savvides and\n  Kwang-Ting Cheng", "title": "Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot\n  Learning", "comments": "AAAI 2021. A search based fine-tuning strategy for few-shot learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot learning is to learn a classifier that can recognize\nunseen classes from limited support data with labels. A common practice for\nthis task is to train a model on the base set first and then transfer to novel\nclasses through fine-tuning (Here fine-tuning procedure is defined as\ntransferring knowledge from base to novel data, i.e. learning to transfer in\nfew-shot scenario.) or meta-learning. However, as the base classes have no\noverlap to the novel set, simply transferring whole knowledge from base data is\nnot an optimal solution since some knowledge in the base model may be biased or\neven harmful to the novel class. In this paper, we propose to transfer partial\nknowledge by freezing or fine-tuning particular layer(s) in the base model.\nSpecifically, layers will be imposed different learning rates if they are\nchosen to be fine-tuned, to control the extent of preserved transferability. To\ndetermine which layers to be recast and what values of learning rates for them,\nwe introduce an evolutionary search based method that is efficient to\nsimultaneously locate the target layers and determine their individual learning\nrates. We conduct extensive experiments on CUB and mini-ImageNet to demonstrate\nthe effectiveness of our proposed method. It achieves the state-of-the-art\nperformance on both meta-learning and non-meta based frameworks. Furthermore,\nwe extend our method to the conventional pre-training + fine-tuning paradigm\nand obtain consistent improvement.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:27:05 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Liu", "Zechun", ""], ["Qin", "Jie", ""], ["Savvides", "Marios", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "2102.03985", "submitter": "Erik Blasch", "authors": "Erik Blasch, James Sung, Tao Nguyen", "title": "Multisource AI Scorecard Table for System Evaluation", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The paper describes a Multisource AI Scorecard Table (MAST) that provides the\ndeveloper and user of an artificial intelligence (AI)/machine learning (ML)\nsystem with a standard checklist focused on the principles of good analysis\nadopted by the intelligence community (IC) to help promote the development of\nmore understandable systems and engender trust in AI outputs. Such a scorecard\nenables a transparent, consistent, and meaningful understanding of AI tools\napplied for commercial and government use. A standard is built on compliance\nand agreement through policy, which requires buy-in from the stakeholders.\nWhile consistency for testing might only exist across a standard data set, the\ncommunity requires discussion on verification and validation approaches which\ncan lead to interpretability, explainability, and proper use. The paper\nexplores how the analytic tradecraft standards outlined in Intelligence\nCommunity Directive (ICD) 203 can provide a framework for assessing the\nperformance of an AI system supporting various operational needs. These include\nsourcing, uncertainty, consistency, accuracy, and visualization. Three use\ncases are presented as notional examples that support security for comparative\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:37:40 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Blasch", "Erik", ""], ["Sung", "James", ""], ["Nguyen", "Tao", ""]]}, {"id": "2102.03986", "submitter": "Jiantao Wu", "authors": "Jiantao Wu, Lin Wang, Bo Yang, Fanqi Li, Chunxiuzi Liu, Jin Zhou", "title": "DEFT: Distilling Entangled Factors by Preventing Information Diffusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentanglement is a highly desirable property of representation owing to its\nsimilarity to human understanding and reasoning. Many works achieve\ndisentanglement upon information bottlenecks (IB). Despite their elegant\nmathematical foundations, the IB branch usually exhibits lower performance. In\norder to provide an insight into the problem, we develop an annealing test to\ncalculate the information freezing point (IFP), which is a transition state to\nfreeze information into the latent variables. We also explore these clues or\ninductive biases for separating the entangled factors according to the\ndifferences in the IFP distributions. We found the existing approaches suffer\nfrom the information diffusion problem, according to which the increased\ninformation diffuses in all latent variables.\n  Based on this insight, we propose a novel disentanglement framework, termed\nthe distilling entangled factor (DEFT), to address the information diffusion\nproblem by scaling backward information. DEFT applies a multistage training\nstrategy, including multigroup encoders with different learning rates and\npiecewise disentanglement pressure, to disentangle the factors stage by stage.\nWe evaluate DEFT on three variants of dSprite and SmallNORB, which show\nlow-variance and high-level disentanglement scores. Furthermore, the experiment\nunder the correlative factors shows incapable of TC-based approaches. DEFT also\nexhibits a competitive performance in the unsupervised setting.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:43:34 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 05:23:33 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 12:45:17 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wu", "Jiantao", ""], ["Wang", "Lin", ""], ["Yang", "Bo", ""], ["Li", "Fanqi", ""], ["Liu", "Chunxiuzi", ""], ["Zhou", "Jin", ""]]}, {"id": "2102.03988", "submitter": "Xiangming Meng", "authors": "Xiangming Meng and Tomoyuki Obuchi and Yoshiyuki Kabashima", "title": "Ising Model Selection Using $\\ell_{1}$-Regularized Linear Regression", "comments": "28 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically investigate the performance of $\\ell_{1}$-regularized linear\nregression ($\\ell_1$-LinR) for the problem of Ising model selection using the\nreplica method from statistical mechanics. The regular random graph is\nconsidered under paramagnetic assumption. Our results show that despite model\nmisspecification, the $\\ell_1$-LinR estimator can successfully recover the\ngraph structure of the Ising model with $N$ variables using\n$M=\\mathcal{O}\\left(\\log N\\right)$ samples, which is of the same order as that\nof $\\ell_{1}$-regularized logistic regression. Moreover, we provide a\ncomputationally efficient method to accurately predict the non-asymptotic\nperformance of the $\\ell_1$-LinR estimator with moderate $M$ and $N$.\nSimulations show an excellent agreement between theoretical predictions and\nexperimental results, which supports our findings.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:45:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Meng", "Xiangming", ""], ["Obuchi", "Tomoyuki", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2102.04009", "submitter": "Liang Ding", "authors": "Di Wu, Liang Ding, Shuo Yang, Dacheng Tao", "title": "SLUA: A Super Lightweight Unsupervised Word Alignment Model via\n  Cross-Lingual Contrastive Learning", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Word alignment is essential for the down-streaming cross-lingual language\nunderstanding and generation tasks. Recently, the performance of the neural\nword alignment models has exceeded that of statistical models. However, they\nheavily rely on sophisticated translation models. In this study, we propose a\nsuper lightweight unsupervised word alignment (SLUA) model, in which\nbidirectional symmetric attention trained with a contrastive learning objective\nis introduced, and an agreement loss is employed to bind the attention maps,\nsuch that the alignments follow mirror-like symmetry hypothesis. Experimental\nresults on several public benchmarks demonstrate that our model achieves\ncompetitive, if not better, performance compared to the state of the art in\nword alignment while significantly reducing the training and decoding time on\naverage. Further ablation analysis and case studies show the superiority of our\nproposed SLUA. Notably, we recognize our model as a pioneer attempt to unify\nbilingual word embedding and word alignments. Encouragingly, our approach\nachieves 16.4x speedup against GIZA++, and 50x parameter compression} compared\nwith the Transformer-based alignment methods. We will release our code to\nfacilitate the community.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 05:54:11 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 17:35:07 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wu", "Di", ""], ["Ding", "Liang", ""], ["Yang", "Shuo", ""], ["Tao", "Dacheng", ""]]}, {"id": "2102.04013", "submitter": "Rohit Kumar Sachan Dr.", "authors": "Sachan Rohit Kumar and Kushwaha Dharmender Singh", "title": "Nature-Inspired Optimization Algorithms: Research Direction and Survey", "comments": "35 pages, 2 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nature-inspired algorithms are commonly used for solving the various\noptimization problems. In past few decades, various researchers have proposed a\nlarge number of nature-inspired algorithms. Some of these algorithms have\nproved to be very efficient as compared to other classical optimization\nmethods. A young researcher attempting to undertake or solve a problem using\nnature-inspired algorithms is bogged down by a plethora of proposals that exist\ntoday. Not every algorithm is suited for all kinds of problem. Some score over\nothers. In this paper, an attempt has been made to summarize various leading\nresearch proposals that shall pave way for any new entrant to easily understand\nthe journey so far. Here, we classify the nature-inspired algorithms as natural\nevolution based, swarm intelligence based, biological based, science based and\nothers. In this survey, widely acknowledged nature-inspired algorithms namely-\nACO, ABC, EAM, FA, FPA, GA, GSA, JAYA, PSO, SFLA, TLBO and WCA, have been\nstudied. The purpose of this review is to present an exhaustive analysis of\nvarious nature-inspired algorithms based on its source of inspiration, basic\noperators, control parameters, features, variants and area of application where\nthese algorithms have been successfully applied. It shall also assist in\nidentifying and short listing the methodologies that are best suited for the\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 06:03:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kumar", "Sachan Rohit", ""], ["Singh", "Kushwaha Dharmender", ""]]}, {"id": "2102.04040", "submitter": "Renqian Luo", "authors": "Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Jinzhu Li, Sheng Zhao, Enhong\n  Chen, Tie-Yan Liu", "title": "LightSpeech: Lightweight and Fast Text to Speech with Neural\n  Architecture Search", "comments": "Accepted to ICASSP 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text to speech (TTS) has been broadly used to synthesize natural and\nintelligible speech in different scenarios. Deploying TTS in various end\ndevices such as mobile phones or embedded devices requires extremely small\nmemory usage and inference latency. While non-autoregressive TTS models such as\nFastSpeech have achieved significantly faster inference speed than\nautoregressive models, their model size and inference latency are still large\nfor the deployment in resource constrained devices. In this paper, we propose\nLightSpeech, which leverages neural architecture search~(NAS) to automatically\ndesign more lightweight and efficient models based on FastSpeech. We first\nprofile the components of current FastSpeech model and carefully design a novel\nsearch space containing various lightweight and potentially effective\narchitectures. Then NAS is utilized to automatically discover well performing\narchitectures within the search space. Experiments show that the model\ndiscovered by our method achieves 15x model compression ratio and 6.5x\ninference speedup on CPU with on par voice quality. Audio demos are provided at\nhttps://speechresearch.github.io/lightspeech.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 07:45:06 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Luo", "Renqian", ""], ["Tan", "Xu", ""], ["Wang", "Rui", ""], ["Qin", "Tao", ""], ["Li", "Jinzhu", ""], ["Zhao", "Sheng", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2102.04062", "submitter": "Chien-Wen Huang", "authors": "Fu-Shun Hsu, Shang-Ran Huang, Chien-Wen Huang, Yuan-Ren Cheng,\n  Chun-Chieh Chen, Jack Hsiao, Chung-Wei Chen, and Feipei Lai", "title": "An Update of a Progressively Expanded Database for Automated Lung Sound\n  Analysis", "comments": "Under review, 8 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A continuous real-time respiratory sound automated analysis system is needed\nin clinical practice. Previously, we established an open access lung sound\ndatabase, HF_Lung_V1, and automated lung sound analysis algorithms capable of\ndetecting inhalation, exhalation, continuous adventitious sounds (CASs) and\ndiscontinuous adventitious sounds (DASs). In this study, HF-Lung-V1 has been\nfurther expanded to HF-Lung-V2 with 1.45 times of increase in audio files. The\nconvolutional neural network (CNN)-bidirectional gated recurrent unit (BiGRU)\nmodel was separately trained with training datasets of HF_Lung_V1 (V1_Train)\nand HF_Lung_V2 (V2_Train), and then were used for the performance comparisons\nof segment detection and event detection on both test datasets of HF_Lung_V1\n(V1_Test) and HF_Lung_V2 (V2_Test). The performance of segment detection was\nmeasured by accuracy, predictive positive value (PPV), sensitivity,\nspecificity, F1 score, receiver operating characteristic (ROC) curve and area\nunder the curve (AUC), whereas that of event detection was evaluated with PPV,\nsensitivity, and F1 score. Results indicate that the model performance trained\nby V2_Train showed improvement on both V1_Test and V2_Test in inhalation, CASs\nand DASs, particularly in CASs, as well as on V1_Test in exhalation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 08:52:17 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 03:22:22 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Hsu", "Fu-Shun", ""], ["Huang", "Shang-Ran", ""], ["Huang", "Chien-Wen", ""], ["Cheng", "Yuan-Ren", ""], ["Chen", "Chun-Chieh", ""], ["Hsiao", "Jack", ""], ["Chen", "Chung-Wei", ""], ["Lai", "Feipei", ""]]}, {"id": "2102.04064", "submitter": "Jinjiang Guo Ph.D.", "authors": "Dawei Leng, Jinjiang Guo, Lurong Pan, Jie Li, Xinyu Wang", "title": "Enhance Information Propagation for Graph Neural Network by\n  Heterogeneous Aggregations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks are emerging as continuation of deep learning success\nw.r.t. graph data. Tens of different graph neural network variants have been\nproposed, most following a neighborhood aggregation scheme, where the node\nfeatures are updated via aggregating features of its neighboring nodes from\nlayer to layer. Though related research surges, the power of GNNs are still not\non-par-with their counterpart CNNs in computer vision and RNNs in natural\nlanguage processing. We rethink this problem from the perspective of\ninformation propagation, and propose to enhance information propagation among\nGNN layers by combining heterogeneous aggregations. We argue that as richer\ninformation are propagated from shallow to deep layers, the discriminative\ncapability of features formulated by GNN can benefit from it. As our first\nattempt in this direction, a new generic GNN layer formulation and upon this a\nnew GNN variant referred as HAG-Net is proposed. We empirically validate the\neffectiveness of HAG-Net on a number of graph classification benchmarks, and\nelaborate all the design options and criterions along with.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 08:57:56 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Leng", "Dawei", ""], ["Guo", "Jinjiang", ""], ["Pan", "Lurong", ""], ["Li", "Jie", ""], ["Wang", "Xinyu", ""]]}, {"id": "2102.04095", "submitter": "Yingtao Luo", "authors": "Yingtao Luo, Qiang Liu, Zhaocheng Liu", "title": "STAN: Spatio-Temporal Attention Network for Next Location Recommendation", "comments": "Accepted to The Web Conference (WWW2021)", "journal-ref": null, "doi": "10.1145/3442381.3449998", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The next location recommendation is at the core of various location-based\napplications. Current state-of-the-art models have attempted to solve spatial\nsparsity with hierarchical gridding and model temporal relation with explicit\ntime intervals, while some vital questions remain unsolved. Non-adjacent\nlocations and non-consecutive visits provide non-trivial correlations for\nunderstanding a user's behavior but were rarely considered. To aggregate all\nrelevant visits from user trajectory and recall the most plausible candidates\nfrom weighted representations, here we propose a Spatio-Temporal Attention\nNetwork (STAN) for location recommendation. STAN explicitly exploits relative\nspatiotemporal information of all the check-ins with self-attention layers\nalong the trajectory. This improvement allows a point-to-point interaction\nbetween non-adjacent locations and non-consecutive check-ins with explicit\nspatiotemporal effect. STAN uses a bi-layer attention architecture that firstly\naggregates spatiotemporal correlation within user trajectory and then recalls\nthe target with consideration of personalized item frequency (PIF). By\nvisualization, we show that STAN is in line with the above intuition.\nExperimental results unequivocally show that our model outperforms the existing\nstate-of-the-art methods by 9-17%.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:04:54 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Luo", "Yingtao", ""], ["Liu", "Qiang", ""], ["Liu", "Zhaocheng", ""]]}, {"id": "2102.04107", "submitter": "Jerome Mengin", "authors": "H\\'el\\`ene Fargier (IRIT-ADRIA), J\\'er\\^ome Mengin (IRIT-ADRIA)", "title": "A Knowledge Compilation Map for Conditional Preference Statements-based\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional preference statements have been used to compactly represent\npreferences over combinatorial domains. They are at the core of CP-nets and\ntheir generalizations, and lexicographic preference trees. Several works have\naddressed the complexity of some queries (optimization, dominance in\nparticular). We extend in this paper some of these results, and study other\nqueries which have not been addressed so far, like equivalence, thereby\ncontributing to a knowledge compilation map for languages based on conditional\npreference statements. We also introduce a new parameterised family of\nlanguages, which enables to balance expressiveness against the complexity of\nsome queries.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:19:40 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fargier", "H\u00e9l\u00e8ne", "", "IRIT-ADRIA"], ["Mengin", "J\u00e9r\u00f4me", "", "IRIT-ADRIA"]]}, {"id": "2102.04114", "submitter": "Luca Pasqualini", "authors": "Andrea Zugarini, Luca Pasqualini, Stefano Melacci, Marco Maggini", "title": "Generate and Revise: Reinforcement Learning in Neural Poetry", "comments": "12 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writers, poets, singers usually do not create their compositions in just one\nbreath. Text is revisited, adjusted, modified, rephrased, even multiple times,\nin order to better convey meanings, emotions and feelings that the author wants\nto express. Amongst the noble written arts, Poetry is probably the one that\nneeds to be elaborated the most, since the composition has to formally respect\npredefined meter and rhyming schemes. In this paper, we propose a framework to\ngenerate poems that are repeatedly revisited and corrected, as humans do, in\norder to improve their overall quality. We frame the problem of revising poems\nin the context of Reinforcement Learning and, in particular, using Proximal\nPolicy Optimization. Our model generates poems from scratch and it learns to\nprogressively adjust the generated text in order to match a target criterion.\nWe evaluate this approach in the case of matching a rhyming scheme, without\nhaving any information on which words are responsible of creating rhymes and on\nhow to coherently alter the poem words. The proposed framework is general and,\nwith an appropriate reward shaping, it can be applied to other text generation\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:35:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zugarini", "Andrea", ""], ["Pasqualini", "Luca", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "2102.04119", "submitter": "Georg Ahnert", "authors": "Georg Ahnert, Ivan Smirnov, Florian Lemmerich, Claudia Wagner, Markus\n  Strohmaier", "title": "The FairCeptron: A Framework for Measuring Human Perceptions of\n  Algorithmic Fairness", "comments": "For source code of the implementation, see\n  https://github.com/cssh-rwth/fairceptron", "journal-ref": null, "doi": "10.1145/3450614.3463291", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measures of algorithmic fairness often do not account for human perceptions\nof fairness that can substantially vary between different sociodemographics and\nstakeholders. The FairCeptron framework is an approach for studying perceptions\nof fairness in algorithmic decision making such as in ranking or\nclassification. It supports (i) studying human perceptions of fairness and (ii)\ncomparing these human perceptions with measures of algorithmic fairness. The\nframework includes fairness scenario generation, fairness perception\nelicitation and fairness perception analysis. We demonstrate the FairCeptron\nframework by applying it to a hypothetical university admission context where\nwe collect human perceptions of fairness in the presence of minorities. An\nimplementation of the FairCeptron framework is openly available, and it can\neasily be adapted to study perceptions of algorithmic fairness in other\napplication contexts. We hope our work paves the way towards elevating the role\nof studies of human fairness perceptions in the process of designing\nalgorithmic decision making systems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:47:24 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ahnert", "Georg", ""], ["Smirnov", "Ivan", ""], ["Lemmerich", "Florian", ""], ["Wagner", "Claudia", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2102.04121", "submitter": "Nicolas Ricka", "authors": "D. Fompeyrine, E. S. Vorm, N. Ricka, F. Rose, G. Pellegrin", "title": "Enhancing Human-Machine Teaming for Medical Prognosis Through Neural\n  Ordinary Differential Equations (NODEs)", "comments": "13 pages, accepted for publication in HISI", "journal-ref": null, "doi": "10.13140/RG.2.2.18067.60963", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) has recently been demonstrated to rival expert-level\nhuman accuracy in prediction and detection tasks in a variety of domains,\nincluding medicine. Despite these impressive findings, however, a key barrier\nto the full realization of ML's potential in medical prognoses is technology\nacceptance. Recent efforts to produce explainable AI (XAI) have made progress\nin improving the interpretability of some ML models, but these efforts suffer\nfrom limitations intrinsic to their design: they work best at identifying why a\nsystem fails, but do poorly at explaining when and why a model's prediction is\ncorrect. We posit that the acceptability of ML predictions in expert domains is\nlimited by two key factors: the machine's horizon of prediction that extends\nbeyond human capability, and the inability for machine predictions to\nincorporate human intuition into their models. We propose the use of a novel ML\narchitecture, Neural Ordinary Differential Equations (NODEs) to enhance human\nunderstanding and encourage acceptability. Our approach prioritizes human\ncognitive intuition at the center of the algorithm design, and offers a\ndistribution of predictions rather than single outputs. We explain how this\napproach may significantly improve human-machine collaboration in prediction\ntasks in expert domains such as medical prognoses. We propose a model and\ndemonstrate, by expanding a concrete example from the literature, how our model\nadvances the vision of future hybrid Human-AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:52:23 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 07:20:03 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Fompeyrine", "D.", ""], ["Vorm", "E. S.", ""], ["Ricka", "N.", ""], ["Rose", "F.", ""], ["Pellegrin", "G.", ""]]}, {"id": "2102.04130", "submitter": "Yuki Asano", "authors": "Hannah Kirk, Yennie Jun, Haider Iqbal, Elias Benussi, Filippo Volpin,\n  Frederic A. Dreyer, Aleksandar Shtedritski, Yuki M. Asano", "title": "How True is GPT-2? An Empirical Analysis of Intersectional Occupational\n  Biases", "comments": "Code is available at https://github.com/oxai/intersectional_gpt2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The capabilities of natural language models trained on large-scale data have\nincreased immensely over the past few years. Downstream applications are at\nrisk of inheriting biases contained in these models, with potential negative\nconsequences especially for marginalized groups. In this paper, we analyze the\noccupational biases of a popular generative language model, GPT-2, intersecting\ngender with five protected categories: religion, sexuality, ethnicity,\npolitical affiliation, and name origin. Using a novel data collection pipeline\nwe collect 396k sentence completions of GPT-2 and find: (i) The\nmachine-predicted jobs are less diverse and more stereotypical for women than\nfor men, especially for intersections; (ii) Fitting 262 logistic models shows\nintersectional interactions to be highly relevant for occupational\nassociations; (iii) For a given job, GPT-2 reflects the societal skew of gender\nand ethnicity in the US, and in some cases, pulls the distribution towards\ngender parity, raising the normative question of what language models _should_\nlearn.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:10:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kirk", "Hannah", ""], ["Jun", "Yennie", ""], ["Iqbal", "Haider", ""], ["Benussi", "Elias", ""], ["Volpin", "Filippo", ""], ["Dreyer", "Frederic A.", ""], ["Shtedritski", "Aleksandar", ""], ["Asano", "Yuki M.", ""]]}, {"id": "2102.04145", "submitter": "Zheng Wang", "authors": "Bruno Abrahao, Zheng Wang, Haider Ahmed, Yuchen Zhu", "title": "Model Rectification via Unknown Unknowns Extraction from Deployment\n  Samples", "comments": "18 pages (7 pages for supplementary materials)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model deficiency that results from incomplete training data is a form of\nstructural blindness that leads to costly errors, oftentimes with high\nconfidence. During the training of classification tasks, underrepresented\nclass-conditional distributions that a given hypothesis space can recognize\nresults in a mismatch between the model and the target space. To mitigate the\nconsequences of this discrepancy, we propose Random Test Sampling and\nCross-Validation (RTSCV) as a general algorithmic framework that aims to\nperform a post-training model rectification at deployment time in a supervised\nway. RTSCV extracts unknown unknowns (u.u.s), i.e., examples from the\nclass-conditional distributions that a classifier is oblivious to, and works in\ncombination with a diverse family of modern prediction models. RTSCV augments\nthe training set with a sample of the test set (or deployment data) and uses\nthis redefined class layout to discover u.u.s via cross-validation, without\nrelying on active learning or budgeted queries to an oracle. We contribute a\ntheoretical analysis that establishes performance guarantees based on the\ndesign bases of modern classifiers. Our experimental evaluation demonstrates\nRTSCV's effectiveness, using 7 benchmark tabular and computer vision datasets,\nby reducing a performance gap as large as 41% from the respective\npre-rectification models. Last we show that RTSCV consistently outperforms\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:46:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Abrahao", "Bruno", ""], ["Wang", "Zheng", ""], ["Ahmed", "Haider", ""], ["Zhu", "Yuchen", ""]]}, {"id": "2102.04150", "submitter": "Ferhat Ozgur Catak", "authors": "Omer Faruk Tuna, Ferhat Ozgur Catak, M. Taner Eskil", "title": "Exploiting epistemic uncertainty of the deep learning models to generate\n  adversarial samples", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network architectures are considered to be robust to random\nperturbations. Nevertheless, it was shown that they could be severely\nvulnerable to slight but carefully crafted perturbations of the input, termed\nas adversarial samples. In recent years, numerous studies have been conducted\nin this new area called \"Adversarial Machine Learning\" to devise new\nadversarial attacks and to defend against these attacks with more robust DNN\narchitectures. However, almost all the research work so far has been\nconcentrated on utilising model loss function to craft adversarial examples or\ncreate robust models. This study explores the usage of quantified epistemic\nuncertainty obtained from Monte-Carlo Dropout Sampling for adversarial attack\npurposes by which we perturb the input to the areas where the model has not\nseen before. We proposed new attack ideas based on the epistemic uncertainty of\nthe model. Our results show that our proposed hybrid attack approach increases\nthe attack success rates from 82.59% to 85.40%, 82.86% to 89.92% and 88.06% to\n90.03% on MNIST Digit, MNIST Fashion and CIFAR-10 datasets, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:59:27 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 18:40:53 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Tuna", "Omer Faruk", ""], ["Catak", "Ferhat Ozgur", ""], ["Eskil", "M. Taner", ""]]}, {"id": "2102.04152", "submitter": "Brian McWilliams", "authors": "Ian Gemp and Brian McWilliams and Claire Vernade and Thore Graepel", "title": "EigenGame Unloaded: When playing games is better than optimizing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build on the recently proposed EigenGame that views eigendecomposition as\na competitive game. EigenGame's updates are biased if computed using\nminibatches of data, which hinders convergence and more sophisticated\nparallelism in the stochastic setting. In this work, we propose an unbiased\nstochastic update that is asymptotically equivalent to EigenGame, enjoys\ngreater parallelism allowing computation on datasets of larger sample sizes,\nand outperforms EigenGame in experiments. We present applications to finding\nthe principal components of massive datasets and performing spectral clustering\nof graphs. We analyze and discuss our proposed update in the context of\nEigenGame and the shift in perspective from optimization to games.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 12:04:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gemp", "Ian", ""], ["McWilliams", "Brian", ""], ["Vernade", "Claire", ""], ["Graepel", "Thore", ""]]}, {"id": "2102.04154", "submitter": "Jan Metzen", "authors": "Jan Hendrik Metzen, Maksym Yatsura", "title": "Efficient Certified Defenses Against Patch Attacks on Image Classifiers", "comments": "accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial patches pose a realistic threat model for physical world attacks\non autonomous systems via their perception component. Autonomous systems in\nsafety-critical domains such as automated driving should thus contain a\nfail-safe fallback component that combines certifiable robustness against\npatches with efficient inference while maintaining high performance on clean\ninputs. We propose BagCert, a novel combination of model architecture and\ncertification procedure that allows efficient certification. We derive a loss\nthat enables end-to-end optimization of certified robustness against patches of\ndifferent sizes and locations. On CIFAR10, BagCert certifies 10.000 examples in\n43 seconds on a single GPU and obtains 86% clean and 60% certified accuracy\nagainst 5x5 patches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 12:11:41 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Metzen", "Jan Hendrik", ""], ["Yatsura", "Maksym", ""]]}, {"id": "2102.04174", "submitter": "Carlos de la Torre-Ortiz", "authors": "Aur\\'elien Nioche, Pierre-Alexandre Murena, Carlos de la Torre-Ortiz,\n  Antti Oulasvirta", "title": "Improving Artificial Teachers by Considering How People Learn and Forget", "comments": "15 pages, 5 figures, to be published in IUI'21", "journal-ref": null, "doi": "10.1145/3397481.3450696", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The paper presents a novel model-based method for intelligent tutoring, with\nparticular emphasis on the problem of selecting teaching interventions in\ninteraction with humans. Whereas previous work has focused on either\npersonalization of teaching or optimization of teaching intervention sequences,\nthe proposed individualized model-based planning approach represents\nconvergence of these two lines of research. Model-based planning picks the best\ninterventions via interactive learning of a user memory model's parameters. The\napproach is novel in its use of a cognitive model that can account for several\nkey individual- and material-specific characteristics related to\nrecall/forgetting, along with a planning technique that considers users'\npractice schedules. Taking a rule-based approach as a baseline, the authors\nevaluated the method's benefits in a controlled study of artificial teaching in\nsecond-language vocabulary learning (N=53).\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 13:05:58 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:48:53 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 12:51:42 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Nioche", "Aur\u00e9lien", ""], ["Murena", "Pierre-Alexandre", ""], ["de la Torre-Ortiz", "Carlos", ""], ["Oulasvirta", "Antti", ""]]}, {"id": "2102.04179", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Jo\\~ao E. Batista, Leonardo Trujillo, Bernardo\n  Duarte, Mario Giacobini, Leonardo Vanneschi, Sara Silva", "title": "Plotting time: On the usage of CNNs for time series classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach for time series classification where we represent\ntime series data as plot images and feed them to a simple CNN, outperforming\nseveral state-of-the-art methods. We propose a simple and highly replicable way\nof plotting the time series, and feed these images as input to a non-optimized\nshallow CNN, without any normalization or residual connections. These\nrepresentations are no more than default line plots using the time series data,\nwhere the only pre-processing applied is to reduce the number of white pixels\nin the image. We compare our method with different state-of-the-art methods\nspecialized in time series classification on two real-world non public\ndatasets, as well as 98 datasets of the UCR dataset collection. The results\nshow that our approach is very promising, achieving the best results on both\nreal-world datasets and matching / beating the best state-of-the-art methods in\nsix UCR datasets. We argue that, if a simple naive design like ours can obtain\nsuch good results, it is worth further exploring the capabilities of using\nimage representation of time series data, along with more powerful CNNs, for\nclassification and other related tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 13:23:01 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Batista", "Jo\u00e3o E.", ""], ["Trujillo", "Leonardo", ""], ["Duarte", "Bernardo", ""], ["Giacobini", "Mario", ""], ["Vanneschi", "Leonardo", ""], ["Silva", "Sara", ""]]}, {"id": "2102.04199", "submitter": "Jaehun Ryu", "authors": "Jaehun Ryu, Hyojin Sung", "title": "MetaTune: Meta-Learning Based Cost Model for Fast and Efficient\n  Auto-tuning Frameworks", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning compiler frameworks are gaining ground as a more portable\nback-end for deep learning applications on increasingly diverse hardware.\nHowever, they face the daunting challenge of matching performance offered by\nhand-tuned target-specific libraries. While auto-tuning frameworks with\nstatistical cost models can provide dynamic and efficient code optimization,\nthey suffer from large space exploration and cost model training overheads.\nThis paper proposes MetaTune, a meta-learning based cost model that more\nquickly and accurately predicts the performance of optimized codes with\npre-trained model parameters. MetaTune encodes convolution kernel codes as\nstructurally similar graphs to facilitate meta-learning, meta-trains a GNN\nmodel with a very small input data set, and then predicts optimization\nparameters for unseen convolution operations with varying sizes and structures\nduring compilation. The resulting framework with MetaTune provides 8 to 13%\nbetter inference time on average for four CNN models with comparable or lower\noptimization time while outperforming transfer learning by 10% in\ncross-platform cases.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 13:59:08 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 06:25:41 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ryu", "Jaehun", ""], ["Sung", "Hyojin", ""]]}, {"id": "2102.04201", "submitter": "Jennifer Cobbe Dr", "authors": "Jennifer Cobbe, Michelle Seng Ah Lee, Jatinder Singh", "title": "Reviewable Automated Decision-Making: A Framework for Accountable\n  Algorithmic Systems", "comments": null, "journal-ref": "ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT 21), March 2021, Virtual Event, Canada", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces reviewability as a framework for improving the\naccountability of automated and algorithmic decision-making (ADM) involving\nmachine learning. We draw on an understanding of ADM as a socio-technical\nprocess involving both human and technical elements, beginning before a\ndecision is made and extending beyond the decision itself. While explanations\nand other model-centric mechanisms may assist some accountability concerns,\nthey often provide insufficient information of these broader ADM processes for\nregulatory oversight and assessments of legal compliance. Reviewability\ninvolves breaking down the ADM process into technical and organisational\nelements to provide a systematic framework for determining the contextually\nappropriate record-keeping mechanisms to facilitate meaningful review - both of\nindividual decisions and of the process as a whole. We argue that a\nreviewability framework, drawing on administrative law's approach to reviewing\nhuman decision-making, offers a practical way forward towards more a more\nholistic and legally-relevant form of accountability for ADM.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 18:15:34 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 11:48:42 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cobbe", "Jennifer", ""], ["Lee", "Michelle Seng Ah", ""], ["Singh", "Jatinder", ""]]}, {"id": "2102.04205", "submitter": "Minghao Wang", "authors": "Minghao Wang, Paolo Mengoni", "title": "How Pandemic Spread in News: Text Analysis Using Topic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researches about COVID-19 has increased largely, no matter in the biology\nfield or the others. This research conducted a text analysis using LDA topic\nmodel. We firstly scraped totally 1127 articles and 5563 comments on SCMP\ncovering COVID-19 from Jan 20 to May 19, then we trained the LDA model and\ntuned parameters based on the Cv coherence as the model evaluation method. With\nthe optimal model, dominant topics, representative documents of each topic and\nthe inconsistence between articles and comments are analyzed. 3 possible\nimprovements are discussed at last.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:33:45 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 08:37:06 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Wang", "Minghao", ""], ["Mengoni", "Paolo", ""]]}, {"id": "2102.04206", "submitter": "Shreekanth Prabhu", "authors": "Shreekanth M Prabhu", "title": "Transforming India's Agricultural Sector using Ontology-based Tantra\n  Framework", "comments": "21 pages, 3 figures, 14 Tables. Submitted to International Journal of\n  Sustainable Agricultural Management and Informatics and under review since\n  April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Food production is a critical activity in which every nation would like to be\nself-sufficient. India is one of the largest producers of food grains in the\nworld. In India, nearly 70 percent of rural households still depend on\nagriculture for their livelihood. Keeping farmers happy is particularly\nimportant in India as farmers form a large vote bank which politicians dare not\ndisappoint. At the same time, Governments need to balance the interest of\nfarmers with consumers, intermediaries and society at large. The whole\nagriculture sector is highly information-intensive. Even with enormous\ncollection of data and statistics from different arms of Government, there\ncontinue to be information gaps. In this paper we look at how Tantra Social\nInformation Management Framework can help analyze the agricultural sector and\ntransform the same using a holistic approach. Advantage of Tantra Framework\napproach is that it looks at societal information as a whole without limiting\nit to only the sector at hand. Tantra Framework makes use of concepts from\nZachman Framework to manage aspects of social information through different\nperspectives and concepts from Unified Foundational Ontology (UFO) to represent\ninterrelationships between aspects. Further, Tantra Framework interoperates\nwith models such as Balanced Scorecard, Theory of Change and Theory of\nSeparations. Finally, we model Indian Agricultural Sector as a business\necosystem and look at approaches to steer transformation from within.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 04:05:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Prabhu", "Shreekanth M", ""]]}, {"id": "2102.04209", "submitter": "Michael Stuart", "authors": "Michael T. Stuart and Markus Kneer", "title": "Guilty Artificial Minds", "comments": "20 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concepts of blameworthiness and wrongness are of fundamental importance\nin human moral life. But to what extent are humans disposed to blame\nartificially intelligent agents, and to what extent will they judge their\nactions to be morally wrong? To make progress on these questions, we adopted\ntwo novel strategies. First, we break down attributions of blame and wrongness\ninto more basic judgments about the epistemic and conative state of the agent,\nand the consequences of the agent's actions. In this way, we are able to\nexamine any differences between the way participants treat artificial agents in\nterms of differences in these more basic judgments. our second strategy is to\ncompare attributions of blame and wrongness across human, artificial, and group\nagents (corporations). Others have compared attributions of blame and wrongness\nbetween human and artificial agents, but the addition of group agents is\nsignificant because these agents seem to provide a clear middle-ground between\nhuman agents (for whom the notions of blame and wrongness were created) and\nartificial agents (for whom the question remains open).\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 21:37:35 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Stuart", "Michael T.", ""], ["Kneer", "Markus", ""]]}, {"id": "2102.04214", "submitter": "Gabriele Sottocornola", "authors": "Gabriele Sottocornola, Fabio Stella, Markus Zanker", "title": "Counterfactual Contextual Multi-Armed Bandit: a Real-World Application\n  to Diagnose Apple Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Post-harvest diseases of apple are one of the major issues in the economical\nsector of apple production, causing severe economical losses to producers.\nThus, we developed DSSApple, a picture-based decision support system able to\nhelp users in the diagnosis of apple diseases. Specifically, this paper\naddresses the problem of sequentially optimizing for the best diagnosis,\nleveraging past interactions with the system and their contextual information\n(i.e. the evidence provided by the users). The problem of learning an online\nmodel while optimizing for its outcome is commonly addressed in the literature\nthrough a stochastic active learning paradigm - i.e. Contextual Multi-Armed\nBandit (CMAB). This methodology interactively updates the decision model\nconsidering the success of each past interaction with respect to the context\nprovided in each round. However, this information is very often partial and\ninadequate to handle such complex decision making problems. On the other hand,\nhuman decisions implicitly include unobserved factors (referred in the\nliterature as unobserved confounders) that significantly contribute to the\nhuman's final decision. In this paper, we take advantage of the information\nembedded in the observed human decisions to marginalize confounding factors and\nimprove the capability of the CMAB model to identify the correct diagnosis.\nSpecifically, we propose a Counterfactual Contextual Multi-Armed Bandit, a\nmodel based on the causal concept of counterfactual. The proposed model is\nvalidated with offline experiments based on data collected through a large user\nstudy on the application. The results prove that our model is able to\noutperform both traditional CMAB algorithms and observed user decisions, in\nreal-world tasks of predicting the correct apple disease.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:11:10 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sottocornola", "Gabriele", ""], ["Stella", "Fabio", ""], ["Zanker", "Markus", ""]]}, {"id": "2102.04216", "submitter": "Anusha Bompelli", "authors": "Anusha Bompelli, Yanshan Wang, Ruyuan Wan, Esha Singh, Yuqi Zhou, Lin\n  Xu, David Oniani, Bhavani Singh Agnikula Kshatriya, Joyce (Joy) E.\n  Balls-Berry, and Rui Zhang", "title": "Social and behavioral determinants of health in the era of artificial\n  intelligence with electronic health records: A scoping review", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: There is growing evidence that social and behavioral determinants\nof health (SBDH) play a substantial effect in a wide range of health outcomes.\nElectronic health records (EHRs) have been widely employed to conduct\nobservational studies in the age of artificial intelligence (AI). However,\nthere has been little research into how to make the most of SBDH information\nfrom EHRs. Methods: A systematic search was conducted in six databases to find\nrelevant peer-reviewed publications that had recently been published. Relevance\nwas determined by screening and evaluating the articles. Based on selected\nrelevant studies, a methodological analysis of AI algorithms leveraging SBDH\ninformation in EHR data was provided. Results: Our synthesis was driven by an\nanalysis of SBDH categories, the relationship between SBDH and\nhealthcare-related statuses, and several NLP approaches for extracting SDOH\nfrom clinical literature. Discussion: The associations between SBDH and health\noutcomes are complicated and diverse; several pathways may be involved. Using\nNatural Language Processing (NLP) technology to support the extraction of SBDH\nand other clinical ideas simplifies the identification and extraction of\nessential concepts from clinical data, efficiently unlocks unstructured data,\nand aids in the resolution of unstructured data-related issues. Conclusion:\nDespite known associations between SBDH and disease, SBDH factors are rarely\ninvestigated as interventions to improve patient outcomes. Gaining knowledge\nabout SBDH and how SBDH data can be collected from EHRs using NLP approaches\nand predictive models improves the chances of influencing health policy change\nfor patient wellness, and ultimately promoting health and health equity.\n  Keywords: Social and Behavioral Determinants of Health, Artificial\nIntelligence, Electronic Health Records, Natural Language Processing,\nPredictive Model\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 09:03:39 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 17:50:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bompelli", "Anusha", "", "Joy"], ["Wang", "Yanshan", "", "Joy"], ["Wan", "Ruyuan", "", "Joy"], ["Singh", "Esha", "", "Joy"], ["Zhou", "Yuqi", "", "Joy"], ["Xu", "Lin", "", "Joy"], ["Oniani", "David", "", "Joy"], ["Kshatriya", "Bhavani Singh Agnikula", "", "Joy"], ["Joyce", "", "", "Joy"], ["Balls-Berry", "E.", ""], ["Zhang", "Rui", ""]]}, {"id": "2102.04219", "submitter": "Larissa Albantakis", "authors": "Larissa Albantakis and Giulio Tononi", "title": "What we are is more than what we do", "comments": "4 pages; German version of this article to appear as a contribution\n  to the anthology \"Artificial Intelligence with Consciousness? Statements\n  2021\" edited by the Karlsruhe Institute of Technology (KIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  If we take the subjective character of consciousness seriously, consciousness\nbecomes a matter of \"being\" rather than \"doing\". Because \"doing\" can be\ndissociated from \"being\", functional criteria alone are insufficient to decide\nwhether a system possesses the necessary requirements for being a physical\nsubstrate of consciousness. The dissociation between \"being\" and \"doing\" is\nmost salient in artificial general intelligence, which may soon replicate any\nhuman capacity: computers can perform complex functions (in the limit\nresembling human behavior) in the absence of consciousness. Complex behavior\nbecomes meaningless if it is not performed by a conscious being.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2021 19:26:15 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Albantakis", "Larissa", ""], ["Tononi", "Giulio", ""]]}, {"id": "2102.04225", "submitter": "Yuanpeng Li", "authors": "Yuanpeng Li", "title": "Concepts, Properties and an Approach for Compositional Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compositional generalization is the capacity to recognize and imagine a large\namount of novel combinations from known components. It is a key in human\nintelligence, but current neural networks generally lack such ability. This\nreport connects a series of our work for compositional generalization, and\nsummarizes an approach. The first part contains concepts and properties. The\nsecond part looks into a machine learning approach. The approach uses\narchitecture design and regularization to regulate information of\nrepresentations. This report focuses on basic ideas with intuitive and\nillustrative explanations. We hope this work would be helpful to clarify\nfundamentals of compositional generalization and lead to advance artificial\nintelligence.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:22:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Li", "Yuanpeng", ""]]}, {"id": "2102.04231", "submitter": "Vadim Liventsev", "authors": "Vadim Liventsev, Aki H\\\"arm\\\"a and Milan Petkovi\\'c", "title": "Neurogenetic Programming Framework for Explainable Reinforcement\n  Learning", "comments": "Source code is available at https://github.com/vadim0x60/cibi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic programming, the task of generating computer programs compliant\nwith a specification without a human developer, is usually tackled either via\ngenetic programming methods based on mutation and recombination of programs, or\nvia neural language models. We propose a novel method that combines both\napproaches using a concept of a virtual neuro-genetic programmer: using\nevolutionary methods as an alternative to gradient descent for neural network\ntraining}, or scrum team. We demonstrate its ability to provide performant and\nexplainable solutions for various OpenAI Gym tasks, as well as inject expert\nknowledge into the otherwise data-driven search for solutions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:26:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liventsev", "Vadim", ""], ["H\u00e4rm\u00e4", "Aki", ""], ["Petkovi\u0107", "Milan", ""]]}, {"id": "2102.04247", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Guan Cuntai", "title": "Convolutional Neural Network Interpretability with General Pattern\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ongoing efforts to understand deep neural networks (DNN) have provided many\ninsights, but DNNs remain incompletely understood. Improving DNN's\ninterpretability has practical benefits, such as more accountable usage, better\nalgorithm maintenance and improvement. The complexity of dataset structure may\ncontribute to the difficulty in solving interpretability problem arising from\nDNN's black-box mechanism. Thus, we propose to use pattern theory formulated by\nUlf Grenander, in which data can be described as configurations of fundamental\nobjects that allow us to investigate convolutional neural network's (CNN)\ninterpretability in a component-wise manner. Specifically, U-Net-like structure\nis formed by attaching expansion blocks (EB) to ResNet, allowing it to perform\nsemantic segmentation-like tasks at its EB output channels designed to be\ncompatible with pattern theory's configurations. Through these modules, some\nheatmap-based explainable artificial intelligence (XAI) methods will be shown\nto extract explanations w.r.t individual generators that make up a single data\nsample, potentially reducing the impact of dataset's complexity to\ninterpretability problem. The MNIST-equivalent dataset containing pattern\ntheory's elements is designed to facilitate smoother entry into this framework,\nalong which the theory's generative aspect is naturally presented.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 07:11:48 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tjoa", "Erico", ""], ["Cuntai", "Guan", ""]]}, {"id": "2102.04250", "submitter": "Duc Kinh Le Tran", "authors": "Duc Kinh Le Tran", "title": "Riiid! Answer Correctness Prediction Kaggle Challenge: 4th Place\n  Solution Summary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents my solution to the challenge \"Riiid! Answer Correctness\nPrediction\" on Kaggle hosted by Riiid Labs (2020), which scores 0.817 (AUC) and\nranks 4th on the final private leaderboard. It is a single transformer-based\nmodel heavily inspired from previous works such as SAKT, SAINT and SAINT+.\nNovel ingredients that I believed to have made a difference are the time-aware\nattention mechanism, the concatenation of the embeddings of the input sequences\nand the embedding of continuous features.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:55:51 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tran", "Duc Kinh Le", ""]]}, {"id": "2102.04252", "submitter": "Tianfan Fu", "authors": "Tianfan Fu, Kexin Huang, Cao Xiao, Lucas M. Glass, Jimeng Sun", "title": "HINT: Hierarchical Interaction Network for Trial Outcome Prediction\n  Leveraging Web Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials are crucial for drug development but are time consuming,\nexpensive, and often burdensome on patients. More importantly, clinical trials\nface uncertain outcomes due to issues with efficacy, safety, or problems with\npatient recruitment. If we were better at predicting the results of clinical\ntrials, we could avoid having to run trials that will inevitably fail more\nresources could be devoted to trials that are likely to succeed. In this paper,\nwe propose Hierarchical INteraction Network (HINT) for more general, clinical\ntrial outcome predictions for all diseases based on a comprehensive and diverse\nset of web data including molecule information of the drugs, target disease\ninformation, trial protocol and biomedical knowledge. HINT first encode these\nmulti-modal data into latent embeddings, where an imputation module is designed\nto handle missing data. Next, these embeddings will be fed into the knowledge\nembedding module to generate knowledge embeddings that are pretrained using\nexternal knowledge on pharmaco-kinetic properties and trial risk from the web.\nThen the interaction graph module will connect all the embedding via domain\nknowledge to fully capture various trial components and their complex relations\nas well as their influences on trial outcomes. Finally, HINT learns a dynamic\nattentive graph neural network to predict trial outcome. Comprehensive\nexperimental results show that HINT achieves strong predictive performance,\nobtaining 0.772, 0.607, 0.623, 0.703 on PR-AUC for Phase I, II, III, and\nindication outcome prediction, respectively. It also consistently outperforms\nthe best baseline method by up to 12.4\\% on PR-AUC.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:09:07 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fu", "Tianfan", ""], ["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2102.04254", "submitter": "Sebastian Gonzalez", "authors": "Sebastian Gonzalez, Davide Salvi, Daniel Baeza, Fabio Antonacci,\n  Augusto Sarti", "title": "A Data-Driven Approach to Violin Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Of all the characteristics of a violin, those that concern its shape are\nprobably the most important ones, as the violin maker has complete control over\nthem. Contemporary violin making, however, is still based more on tradition\nthan understanding, and a definitive scientific study of the specific relations\nthat exist between shape and vibrational properties is yet to come and sorely\nmissed. In this article, using standard statistical learning tools, we show\nthat the modal frequencies of violin tops can, in fact, be predicted from\ngeometric parameters, and that artificial intelligence can be successfully\napplied to traditional violin making. We also study how modal frequencies vary\nwith the thicknesses of the plate (a process often referred to as {\\em plate\ntuning}) and discuss the complexity of this dependency. Finally, we propose a\npredictive tool for plate tuning, which takes into account material and\ngeometric parameters.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:42:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Gonzalez", "Sebastian", ""], ["Salvi", "Davide", ""], ["Baeza", "Daniel", ""], ["Antonacci", "Fabio", ""], ["Sarti", "Augusto", ""]]}, {"id": "2102.04255", "submitter": "Nathan Lambert", "authors": "McKane Andrus, Sarah Dean, Thomas Krendl Gilbert, Nathan Lambert, Tom\n  Zick", "title": "AI Development for the Public Interest: From Abstraction Traps to\n  Sociotechnical Risks", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite interest in communicating ethical problems and social contexts within\nthe undergraduate curriculum to advance Public Interest Technology (PIT) goals,\ninterventions at the graduate level remain largely unexplored. This may be due\nto the conflicting ways through which distinct Artificial Intelligence (AI)\nresearch tracks conceive of their interface with social contexts. In this paper\nwe track the historical emergence of sociotechnical inquiry in three distinct\nsubfields of AI research: AI Safety, Fair Machine Learning (Fair ML) and\nHuman-in-the-Loop (HIL) Autonomy. We show that for each subfield, perceptions\nof PIT stem from the particular dangers faced by past integration of technical\nsystems within a normative social order. We further interrogate how these\nhistories dictate the response of each subfield to conceptual traps, as defined\nin the Science and Technology Studies literature. Finally, through a\ncomparative analysis of these currently siloed fields, we present a roadmap for\na unified approach to sociotechnical graduate pedagogy in AI.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:54:20 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Andrus", "McKane", ""], ["Dean", "Sarah", ""], ["Gilbert", "Thomas Krendl", ""], ["Lambert", "Nathan", ""], ["Zick", "Tom", ""]]}, {"id": "2102.04256", "submitter": "Jack Bandy", "authors": "Jack Bandy", "title": "Problematic Machine Behavior: A Systematic Literature Review of\n  Algorithm Audits", "comments": "To Appear in the Proceedings of the ACM (PACM) Human-Computer\n  Interaction, CSCW '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While algorithm audits are growing rapidly in commonality and public\nimportance, relatively little scholarly work has gone toward synthesizing prior\nwork and strategizing future research in the area. This systematic literature\nreview aims to do just that, following PRISMA guidelines in a review of over\n500 English articles that yielded 62 algorithm audit studies. The studies are\nsynthesized and organized primarily by behavior (discrimination, distortion,\nexploitation, and misjudgement), with codes also provided for domain (e.g.\nsearch, vision, advertising, etc.), organization (e.g. Google, Facebook,\nAmazon, etc.), and audit method (e.g. sock puppet, direct scrape,\ncrowdsourcing, etc.). The review shows how previous audit studies have exposed\npublic-facing algorithms exhibiting problematic behavior, such as search\nalgorithms culpable of distortion and advertising algorithms culpable of\ndiscrimination. Based on the studies reviewed, it also suggests some behaviors\n(e.g. discrimination on the basis of intersectional identities), domains (e.g.\nadvertising algorithms), methods (e.g. code auditing), and organizations (e.g.\nTwitter, TikTok, LinkedIn) that call for future audit attention. The paper\nconcludes by offering the common ingredients of successful audits, and\ndiscussing algorithm auditing in the context of broader research working toward\nalgorithmic justice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 19:21:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bandy", "Jack", ""]]}, {"id": "2102.04257", "submitter": "Kevin McKee", "authors": "Nenad Tomasev, Kevin R. McKee, Jackie Kay, Shakir Mohamed", "title": "Fairness for Unobserved Characteristics: Insights from Technological\n  Impacts on Queer Communities", "comments": "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES 2021)", "journal-ref": null, "doi": "10.1145/3461702.3462540", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in algorithmic fairness have largely omitted sexual orientation and\ngender identity. We explore queer concerns in privacy, censorship, language,\nonline safety, health, and employment to study the positive and negative\neffects of artificial intelligence on queer communities. These issues\nunderscore the need for new directions in fairness research that take into\naccount a multiplicity of considerations, from privacy preservation, context\nsensitivity and process fairness, to an awareness of sociotechnical impact and\nthe increasingly important role of inclusive and participatory research\nprocesses. Most current approaches for algorithmic fairness assume that the\ntarget characteristics for fairness--frequently, race and legal gender--can be\nobserved or recorded. Sexual orientation and gender identity are prototypical\ninstances of unobserved characteristics, which are frequently missing, unknown\nor fundamentally unmeasurable. This paper highlights the importance of\ndeveloping new approaches for algorithmic fairness that break away from the\nprevailing assumption of observed characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:52:54 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:04:58 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 16:39:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tomasev", "Nenad", ""], ["McKee", "Kevin R.", ""], ["Kay", "Jackie", ""], ["Mohamed", "Shakir", ""]]}, {"id": "2102.04293", "submitter": "Miguel Ramalho", "authors": "Miguel Sozinho Ramalho", "title": "High-level Approaches to Detect Malicious Political Activity on Twitter", "comments": "Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our work represents another step into the detection and prevention of these\never-more present political manipulation efforts. We, therefore, start by\nfocusing on understanding what the state-of-the-art approaches lack -- since\nthe problem remains, this is a fair assumption. We find concerning issues\nwithin the current literature and follow a diverging path. Notably, by placing\nemphasis on using data features that are less susceptible to malicious\nmanipulation and also on looking for high-level approaches that avoid a\ngranularity level that is biased towards easy-to-spot and low impact cases.\n  We designed and implemented a framework -- Twitter Watch -- that performs\nstructured Twitter data collection, applying it to the Portuguese\nTwittersphere. We investigate a data snapshot taken on May 2020, with around 5\nmillion accounts and over 120 million tweets (this value has since increased to\nover 175 million). The analyzed time period stretches from August 2019 to May\n2020, with a focus on the Portuguese elections of October 6th, 2019. However,\nthe Covid-19 pandemic showed itself in our data, and we also delve into how it\naffected typical Twitter behavior.\n  We performed three main approaches: content-oriented, metadata-oriented, and\nnetwork interaction-oriented. We learn that Twitter's suspension patterns are\nnot adequate to the type of political trolling found in the Portuguese\nTwittersphere -- identified by this work and by an independent peer - nor to\nfake news posting accounts. We also surmised that the different types of\nmalicious accounts we independently gathered are very similar both in terms of\ncontent and interaction, through two distinct analysis, and are simultaneously\nvery distinct from regular accounts.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 22:54:44 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ramalho", "Miguel Sozinho", ""]]}, {"id": "2102.04307", "submitter": "Alper Kamil Bozkurt", "authors": "Alper Kamil Bozkurt, Yu Wang, Miroslav Pajic", "title": "Learning Optimal Strategies for Temporal Tasks in Stochastic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear temporal logic (LTL) is widely used to formally specify complex tasks\nfor autonomy. Unlike usual tasks defined by reward functions only, LTL tasks\nare noncumulative and require memory-dependent strategies. In this work, we\nintroduce a method to learn optimal controller strategies that maximize the\nsatisfaction probability of LTL specifications of the desired tasks in\nstochastic games, which are natural extensions of Markov Decision Processes\n(MDPs) to systems with adversarial inputs. Our approach constructs a product\ngame using the deterministic automaton derived from the given LTL task and a\nreward machine based on the acceptance condition of the automaton; thus,\nallowing for the use of a model-free RL algorithm to learn an optimal\ncontroller strategy. Since the rewards and the transition probabilities of the\nreward machine do not depend on the number of sets defining the acceptance\ncondition, our approach is scalable to a wide range of LTL tasks, as we\ndemonstrate on several case studies.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:10:50 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bozkurt", "Alper Kamil", ""], ["Wang", "Yu", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2102.04323", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Andre Barreto, Daniel J Mankowitz, Shaobo Hou, Brendan\n  O'Donoghue, Iurii Kemaev and Satinder Baveja Singh", "title": "Discovering a set of policies for the worst case reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of how to construct a set of policies that can be\ncomposed together to solve a collection of reinforcement learning tasks. Each\ntask is a different reward function defined as a linear combination of known\nfeatures. We consider a specific class of policy compositions which we call set\nimproving policies (SIPs): given a set of policies and a set of tasks, a SIP is\nany composition of the former whose performance is at least as good as that of\nits constituents across all the tasks. We focus on the most conservative\ninstantiation of SIPs, set-max policies (SMPs), so our analysis extends to any\nSIP. This includes known policy-composition operators like generalized policy\nimprovement. Our main contribution is a policy iteration algorithm that builds\na set of policies in order to maximize the worst-case performance of the\nresulting SMP on the set of tasks. The algorithm works by successively adding\nnew policies to the set. We show that the worst-case performance of the\nresulting SMP strictly improves at each iteration, and the algorithm only stops\nwhen there does not exist a policy that leads to improved performance. We\nempirically evaluate our algorithm on a grid world and also on a set of domains\nfrom the DeepMind control suite. We confirm our theoretical results regarding\nthe monotonically improving performance of our algorithm. Interestingly, we\nalso show empirically that the sets of policies computed by the algorithm are\ndiverse, leading to different trajectories in the grid world and very distinct\nlocomotion skills in the control suite.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:27:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zahavy", "Tom", ""], ["Barreto", "Andre", ""], ["Mankowitz", "Daniel J", ""], ["Hou", "Shaobo", ""], ["O'Donoghue", "Brendan", ""], ["Kemaev", "Iurii", ""], ["Singh", "Satinder Baveja", ""]]}, {"id": "2102.04351", "submitter": "Sudip Mittal", "authors": "Priyanka Ranade, Aritran Piplai, Sudip Mittal, Anupam Joshi, Tim Finin", "title": "Generating Fake Cyber Threat Intelligence Using Transformer-Based Models", "comments": "In Proceedings of International Joint Conference on Neural Networks\n  2021 (IJCNN 2021), July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cyber-defense systems are being developed to automatically ingest Cyber\nThreat Intelligence (CTI) that contains semi-structured data and/or text to\npopulate knowledge graphs. A potential risk is that fake CTI can be generated\nand spread through Open-Source Intelligence (OSINT) communities or on the Web\nto effect a data poisoning attack on these systems. Adversaries can use fake\nCTI examples as training input to subvert cyber defense systems, forcing the\nmodel to learn incorrect inputs to serve their malicious needs.\n  In this paper, we automatically generate fake CTI text descriptions using\ntransformers. We show that given an initial prompt sentence, a public language\nmodel like GPT-2 with fine-tuning, can generate plausible CTI text with the\nability of corrupting cyber-defense systems. We utilize the generated fake CTI\ntext to perform a data poisoning attack on a Cybersecurity Knowledge Graph\n(CKG) and a cybersecurity corpus. The poisoning attack introduced adverse\nimpacts such as returning incorrect reasoning outputs, representation\npoisoning, and corruption of other dependent AI-based cyber defense systems. We\nevaluate with traditional approaches and conduct a human evaluation study with\ncybersecurity professionals and threat hunters. Based on the study,\nprofessional threat hunters were equally likely to consider our fake generated\nCTI as true.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:54:35 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 14:36:16 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 18:00:10 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ranade", "Priyanka", ""], ["Piplai", "Aritran", ""], ["Mittal", "Sudip", ""], ["Joshi", "Anupam", ""], ["Finin", "Tim", ""]]}, {"id": "2102.04353", "submitter": "Anirban Santara", "authors": "Krzysztof Choromanski, Deepali Jain, Jack Parker-Holder, Xingyou Song,\n  Valerii Likhosherstov, Anirban Santara, Aldo Pacchiano, Yunhao Tang, Adrian\n  Weller", "title": "Unlocking Pixels for Reinforcement Learning via Implicit Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has recently been significant interest in training reinforcement\nlearning (RL) agents in vision-based environments. This poses many challenges,\nsuch as high dimensionality and potential for observational overfitting through\nspurious correlations. A promising approach to solve both of these problems is\na self-attention bottleneck, which provides a simple and effective framework\nfor learning high performing policies, even in the presence of distractions.\nHowever, due to poor scalability of attention architectures, these methods do\nnot scale beyond low resolution visual inputs, using large patches (thus small\nattention matrices). In this paper we make use of new efficient attention\nalgorithms, recently shown to be highly effective for Transformers, and\ndemonstrate that these new techniques can be applied in the RL setting. This\nallows our attention-based controllers to scale to larger visual inputs, and\nfacilitate the use of smaller patches, even individual pixels, improving\ngeneralization. In addition, we propose a new efficient algorithm approximating\nsoftmax attention with what we call hybrid random features, leveraging the\ntheory of angular kernels. We show theoretically and empirically that hybrid\nrandom features is a promising approach when using attention for vision-based\nRL.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:00:26 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 16:07:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 15:53:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Jain", "Deepali", ""], ["Parker-Holder", "Jack", ""], ["Song", "Xingyou", ""], ["Likhosherstov", "Valerii", ""], ["Santara", "Anirban", ""], ["Pacchiano", "Aldo", ""], ["Tang", "Yunhao", ""], ["Weller", "Adrian", ""]]}, {"id": "2102.04362", "submitter": "Chee Seng Chan", "authors": "Ding Sheng Ong, Chee Seng Chan, Kam Woh Ng, Lixin Fan, Qiang Yang", "title": "Protecting Intellectual Property of Generative Adversarial Networks from\n  Ambiguity Attack", "comments": "Accepted at CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ever since Machine Learning as a Service (MLaaS) emerges as a viable business\nthat utilizes deep learning models to generate lucrative revenue, Intellectual\nProperty Right (IPR) has become a major concern because these deep learning\nmodels can easily be replicated, shared, and re-distributed by any unauthorized\nthird parties. To the best of our knowledge, one of the prominent deep learning\nmodels - Generative Adversarial Networks (GANs) which has been widely used to\ncreate photorealistic image are totally unprotected despite the existence of\npioneering IPR protection methodology for Convolutional Neural Networks (CNNs).\nThis paper therefore presents a complete protection framework in both black-box\nand white-box settings to enforce IPR protection on GANs. Empirically, we show\nthat the proposed method does not compromise the original GANs performance\n(i.e. image generation, image super-resolution, style transfer), and at the\nsame time, it is able to withstand both removal and ambiguity attacks against\nembedded watermarks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:12:20 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 03:31:03 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ong", "Ding Sheng", ""], ["Chan", "Chee Seng", ""], ["Ng", "Kam Woh", ""], ["Fan", "Lixin", ""], ["Yang", "Qiang", ""]]}, {"id": "2102.04376", "submitter": "Yannis Flet-Berliac", "authors": "Yannis Flet-Berliac and Johan Ferret and Olivier Pietquin and Philippe\n  Preux and Matthieu Geist", "title": "Adversarially Guided Actor-Critic", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite definite success in deep reinforcement learning problems,\nactor-critic algorithms are still confronted with sample inefficiency in\ncomplex environments, particularly in tasks where efficient exploration is a\nbottleneck. These methods consider a policy (the actor) and a value function\n(the critic) whose respective losses are built using different motivations and\napproaches. This paper introduces a third protagonist: the adversary. While the\nadversary mimics the actor by minimizing the KL-divergence between their\nrespective action distributions, the actor, in addition to learning to solve\nthe task, tries to differentiate itself from the adversary predictions. This\nnovel objective stimulates the actor to follow strategies that could not have\nbeen correctly predicted from previous trajectories, making its behavior\ninnovative in tasks where the reward is extremely rare. Our experimental\nanalysis shows that the resulting Adversarially Guided Actor-Critic (AGAC)\nalgorithm leads to more exhaustive exploration. Notably, AGAC outperforms\ncurrent state-of-the-art methods on a set of various hard-exploration and\nprocedurally-generated tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:31:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Flet-Berliac", "Yannis", ""], ["Ferret", "Johan", ""], ["Pietquin", "Olivier", ""], ["Preux", "Philippe", ""], ["Geist", "Matthieu", ""]]}, {"id": "2102.04394", "submitter": "Fabio Gonzalez", "authors": "Fabio A. Gonz\\'alez, Alejandro Gallego, Santiago Toledo-Cort\\'es,\n  Vladimir Vargas-Calder\\'on", "title": "Learning with Density Matrices and Random Features", "comments": "Submitted to ICML 2021 Supplementary material added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A density matrix describes the statistical state of a quantum system. It is a\npowerful formalism to represent both the quantum and classical uncertainty of\nquantum systems and to express different statistical operations such as\nmeasurement, system combination and expectations as linear algebra operations.\nThis paper explores how density matrices can be used as a building block to\nbuild machine learning models exploiting their ability to straightforwardly\ncombine linear algebra and probability. One of the main results of the paper is\nto show that density matrices coupled with random Fourier features could\napproximate arbitrary probability distributions over $\\mathbb{R}^n$. Based on\nthis finding the paper builds different models for density estimation,\nclassification and regression. These models are differentiable, so it is\npossible to integrate them with other differentiable components, such as deep\nlearning architectures and to learn their parameters using gradient-based\noptimization. In addition, the paper presents optimization-less training\nstrategies based on estimation and model averaging. The models are evaluated in\nbenchmark tasks and the results are reported and discussed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 17:54:59 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 14:40:04 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Gonz\u00e1lez", "Fabio A.", ""], ["Gallego", "Alejandro", ""], ["Toledo-Cort\u00e9s", "Santiago", ""], ["Vargas-Calder\u00f3n", "Vladimir", ""]]}, {"id": "2102.04399", "submitter": "Augustine Mavor-Parker", "authors": "Augustine N. Mavor-Parker, Kimberly A. Young, Caswell Barry, Lewis D.\n  Griffin", "title": "Escaping Stochastic Traps with Aleatoric Mapping Agents", "comments": "Presented at the NeurIPS (2020) Biological and Artificial\n  Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exploration in environments with sparse rewards is difficult for artificial\nagents. Curiosity driven learning -- using feed-forward prediction errors as\nintrinsic rewards -- has achieved some success in these scenarios, but fails\nwhen faced with action-dependent noise sources. We present aleatoric mapping\nagents (AMAs), a neuroscience inspired solution modeled on the cholinergic\nsystem of the mammalian brain. AMAs aim to explicitly ascertain which dynamics\nof the environment are unpredictable, regardless of whether those dynamics are\ninduced by the actions of the agent. This is achieved by generating separate\nforward predictions for the mean and variance of future states and reducing\nintrinsic rewards for those transitions with high aleatoric variance. We show\nAMAs are able to effectively circumvent action-dependent stochastic traps that\nimmobilise conventional curiosity driven agents. The code for all experiments\npresented in this paper is open sourced:\nhttp://github.com/self-supervisor/Escaping-Stochastic-Traps-With-Aleatoric-Mapping-Agents.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:05:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mavor-Parker", "Augustine N.", ""], ["Young", "Kimberly A.", ""], ["Barry", "Caswell", ""], ["Griffin", "Lewis D.", ""]]}, {"id": "2102.04402", "submitter": "Xueguang Lyu", "authors": "Xueguang Lyu, Yuchen Xiao, Brett Daley, Christopher Amato", "title": "Contrasting Centralized and Decentralized Critics in Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Centralized Training for Decentralized Execution, where agents are trained\noffline using centralized information but execute in a decentralized manner\nonline, has gained popularity in the multi-agent reinforcement learning\ncommunity. In particular, actor-critic methods with a centralized critic and\ndecentralized actors are a common instance of this idea. However, the\nimplications of using a centralized critic in this context are not fully\ndiscussed and understood even though it is the standard choice of many\nalgorithms. We therefore formally analyze centralized and decentralized critic\napproaches, providing a deeper understanding of the implications of critic\nchoice. Because our theory makes unrealistic assumptions, we also empirically\ncompare the centralized and decentralized critic methods over a wide set of\nenvironments to validate our theories and to provide practical advice. We show\nthat there exist misconceptions regarding centralized critics in the current\nliterature and show that the centralized critic design is not strictly\nbeneficial, but rather both centralized and decentralized critics have\ndifferent pros and cons that should be taken into account by algorithm\ndesigners.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:08:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lyu", "Xueguang", ""], ["Xiao", "Yuchen", ""], ["Daley", "Brett", ""], ["Amato", "Christopher", ""]]}, {"id": "2102.04432", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, Dirk Weissenborn, Nal Kalchbrenner", "title": "Colorization Transformer", "comments": "ICLR 2021 Camera Ready. See\n  https://openreview.net/forum?id=5NA1PinlGFu for more details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Colorization Transformer, a novel approach for diverse high\nfidelity image colorization based on self-attention. Given a grayscale image,\nthe colorization proceeds in three steps. We first use a conditional\nautoregressive transformer to produce a low resolution coarse coloring of the\ngrayscale image. Our architecture adopts conditional transformer layers to\neffectively condition grayscale input. Two subsequent fully parallel networks\nupsample the coarse colored low resolution image into a finely colored high\nresolution image. Sampling from the Colorization Transformer produces diverse\ncolorings whose fidelity outperforms the previous state-of-the-art on\ncolorising ImageNet based on FID results and based on a human evaluation in a\nMechanical Turk test. Remarkably, in more than 60% of cases human evaluators\nprefer the highest rated among three generated colorings over the ground truth.\nThe code and pre-trained checkpoints for Colorization Transformer are publicly\navailable at\nhttps://github.com/google-research/google-research/tree/master/coltran\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:45:06 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 08:38:49 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kumar", "Manoj", ""], ["Weissenborn", "Dirk", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "2102.04456", "submitter": "Yonghao Song", "authors": "Yonghao Song, Lie Yang, Xueyu Jia and Longhan Xie", "title": "Common Spatial Generative Adversarial Networks based EEG Data\n  Augmentation for Cross-Subject Brain-Computer Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The cross-subject application of EEG-based brain-computer interface (BCI) has\nalways been limited by large individual difference and complex characteristics\nthat are difficult to perceive. Therefore, it takes a long time to collect the\ntraining data of each user for calibration. Even transfer learning method\npre-training with amounts of subject-independent data cannot decode different\nEEG signal categories without enough subject-specific data. Hence, we proposed\na cross-subject EEG classification framework with a generative adversarial\nnetworks (GANs) based method named common spatial GAN (CS-GAN), which used\nadversarial training between a generator and a discriminator to obtain\nhigh-quality data for augmentation. A particular module in the discriminator\nwas employed to maintain the spatial features of the EEG signals and increase\nthe difference between different categories, with two losses for further\nenhancement. Through adaptive training with sufficient augmentation data, our\ncross-subject classification accuracy yielded a significant improvement of\n15.85% than leave-one subject-out (LOO) test and 8.57% than just adapting 100\noriginal samples on the dataset 2a of BCI competition IV. Moreover, We designed\na convolutional neural networks (CNNs) based classification method as a\nbenchmark with a similar spatial enhancement idea, which achieved remarkable\nresults to classify motor imagery EEG data. In summary, our framework provides\na promising way to deal with the cross-subject problem and promote the\npractical application of BCI.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:37:03 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Song", "Yonghao", ""], ["Yang", "Lie", ""], ["Jia", "Xueyu", ""], ["Xie", "Longhan", ""]]}, {"id": "2102.04506", "submitter": "Boliang Zhang", "authors": "Boliang Zhang, Ying Lyu, Ning Ding, Tianhao Shen, Zhaoyang Jia, Kun\n  Han, Kevin Knight", "title": "A Hybrid Task-Oriented Dialog System with Domain and Task Adaptive\n  Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our submission for the End-to-end Multi-domain Task\nCompletion Dialog shared task at the 9th Dialog System Technology Challenge\n(DSTC-9). Participants in the shared task build an end-to-end task completion\ndialog system which is evaluated by human evaluation and a user simulator based\nautomatic evaluation. Different from traditional pipelined approaches where\nmodules are optimized individually and suffer from cascading failure, we\npropose an end-to-end dialog system that 1) uses Generative Pretraining 2\n(GPT-2) as the backbone to jointly solve Natural Language Understanding, Dialog\nState Tracking, and Natural Language Generation tasks, 2) adopts Domain and\nTask Adaptive Pretraining to tailor GPT-2 to the dialog domain before\nfinetuning, 3) utilizes heuristic pre/post-processing rules that greatly\nsimplify the prediction tasks and improve generalizability, and 4) equips a\nfault tolerance module to correct errors and inappropriate responses. Our\nproposed method significantly outperforms baselines and ties for first place in\nthe official evaluation. We make our source code publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:02:30 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhang", "Boliang", ""], ["Lyu", "Ying", ""], ["Ding", "Ning", ""], ["Shen", "Tianhao", ""], ["Jia", "Zhaoyang", ""], ["Han", "Kun", ""], ["Knight", "Kevin", ""]]}, {"id": "2102.04518", "submitter": "Forest Agostinelli", "authors": "Forest Agostinelli, Alexander Shmakov, Stephen McAleer, Roy Fox,\n  Pierre Baldi", "title": "A* Search Without Expansions: Learning Heuristic Functions with Deep\n  Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A* search is an informed search algorithm that uses a heuristic function to\nguide the order in which nodes are expanded. Since the computation required to\nexpand a node and compute the heuristic values for all of its generated\nchildren grows linearly with the size of the action space, A* search can become\nimpractical for problems with large action spaces. This computational burden\nbecomes even more apparent when heuristic functions are learned by general, but\ncomputationally expensive, deep neural networks. To address this problem, we\nintroduce DeepCubeAQ, a deep reinforcement learning and search algorithm that\nbuilds on the DeepCubeA algorithm and deep Q-networks. DeepCubeAQ learns a\nheuristic function that, with a single forward pass through a deep neural\nnetwork, computes the sum of the transition cost and the heuristic value of all\nof the children of a node without explicitly generating any of the children,\neliminating the need for node expansions. DeepCubeAQ then uses a novel variant\nof A* search, called AQ* search, that uses the deep Q-network to guide search.\nWe use DeepCubeAQ to solve the Rubik's cube when formulated with a large action\nspace that includes 1872 meta-actions and show that this 157-fold increase in\nthe size of the action space incurs less than a 4-fold increase in computation\ntime when performing AQ* search and that AQ* search is orders of magnitude\nfaster than A* search.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:36:41 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Agostinelli", "Forest", ""], ["Shmakov", "Alexander", ""], ["McAleer", "Stephen", ""], ["Fox", "Roy", ""], ["Baldi", "Pierre", ""]]}, {"id": "2102.04527", "submitter": "Michael Stuart", "authors": "Markus Kneer and Michael T. Stuart", "title": "Playing the Blame Game with Robots", "comments": "5 pages, 2 figures, 2 tables, HRI'21", "journal-ref": null, "doi": "10.1145/3434074.3447202", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent research shows -- somewhat astonishingly -- that people are willing to\nascribe moral blame to AI-driven systems when they cause harm [1]-[4]. In this\npaper, we explore the moral-psychological underpinnings of these findings. Our\nhypothesis was that the reason why people ascribe moral blame to AI systems is\nthat they consider them capable of entertaining inculpating mental states (what\nis called mens rea in the law). To explore this hypothesis, we created a\nscenario in which an AI system runs a risk of poisoning people by using a novel\ntype of fertilizer. Manipulating the computational (or quasi-cognitive)\nabilities of the AI system in a between-subjects design, we tested whether\npeople's willingness to ascribe knowledge of a substantial risk of harm (i.e.,\nrecklessness) and blame to the AI system. Furthermore, we investigated whether\nthe ascription of recklessness and blame to the AI system would influence the\nperceived blameworthiness of the system's user (or owner). In an experiment\nwith 347 participants, we found (i) that people are willing to ascribe blame to\nAI systems in contexts of recklessness, (ii) that blame ascriptions depend\nstrongly on the willingness to attribute recklessness and (iii) that the\nlatter, in turn, depends on the perceived \"cognitive\" capacities of the system.\nFurthermore, our results suggest (iv) that the higher the computational\nsophistication of the AI system, the more blame is shifted from the human user\nto the AI system.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:53:42 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kneer", "Markus", ""], ["Stuart", "Michael T.", ""]]}, {"id": "2102.04530", "submitter": "Ran Cheng", "authors": "Ran Cheng, Ryan Razani, Ehsan Taghavi, Enxu Li, Bingbing Liu", "title": "(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection\n  for Sparse Semantic Segmentation Network", "comments": "10 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous robotic systems and self driving cars rely on accurate perception\nof their surroundings as the safety of the passengers and pedestrians is the\ntop priority. Semantic segmentation is one the essential components of\nenvironmental perception that provides semantic information of the scene.\nRecently, several methods have been introduced for 3D LiDAR semantic\nsegmentation. While, they can lead to improved performance, they are either\nafflicted by high computational complexity, therefore are inefficient, or lack\nfine details of smaller instances. To alleviate this problem, we propose\nAF2-S3Net, an end-to-end encoder-decoder CNN network for 3D LiDAR semantic\nsegmentation. We present a novel multi-branch attentive feature fusion module\nin the encoder and a unique adaptive feature selection module with feature map\nre-weighting in the decoder. Our AF2-S3Net fuses the voxel based learning and\npoint-based learning into a single framework to effectively process the large\n3D scene. Our experimental results show that the proposed method outperforms\nthe state-of-the-art approaches on the large-scale SemanticKITTI benchmark,\nranking 1st on the competitive public leaderboard competition upon publication.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:04:21 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Cheng", "Ran", ""], ["Razani", "Ryan", ""], ["Taghavi", "Ehsan", ""], ["Li", "Enxu", ""], ["Liu", "Bingbing", ""]]}, {"id": "2102.04534", "submitter": "Jorge Guevara", "authors": "Bianca Zadrozny, Campbell D. Watson, Daniela Szwarcman, Daniel\n  Civitarese, Dario Oliveira, Eduardo Rodrigues, Jorge Guevara", "title": "A modular framework for extreme weather generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme weather events have an enormous impact on society and are expected to\nbecome more frequent and severe with climate change. In this context,\nresilience planning becomes crucial for risk mitigation and coping with these\nextreme events. Machine learning techniques can play a critical role in\nresilience planning through the generation of realistic extreme weather event\nscenarios that can be used to evaluate possible mitigation actions. This paper\nproposes a modular framework that relies on interchangeable components to\nproduce extreme weather event scenarios. We discuss possible alternatives for\neach of the components and show initial results comparing two approaches on the\ntask of generating precipitation scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:12:10 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zadrozny", "Bianca", ""], ["Watson", "Campbell D.", ""], ["Szwarcman", "Daniela", ""], ["Civitarese", "Daniel", ""], ["Oliveira", "Dario", ""], ["Rodrigues", "Eduardo", ""], ["Guevara", "Jorge", ""]]}, {"id": "2102.04540", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, Haipeng Luo", "title": "Last-iterate Convergence of Decentralized Optimistic Gradient\n  Descent/Ascent in Infinite-horizon Competitive Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study infinite-horizon discounted two-player zero-sum Markov games, and\ndevelop a decentralized algorithm that provably converges to the set of Nash\nequilibria under self-play. Our algorithm is based on running an Optimistic\nGradient Descent Ascent algorithm on each state to learn the policies, with a\ncritic that slowly learns the value of each state. To the best of our\nknowledge, this is the first algorithm in this setting that is simultaneously\nrational (converging to the opponent's best response when it uses a stationary\npolicy), convergent (converging to the set of Nash equilibria under self-play),\nagnostic (no need to know the actions played by the opponent), symmetric\n(players taking symmetric roles in the algorithm), and enjoying a finite-time\nlast-iterate convergence guarantee, all of which are desirable properties of\ndecentralized algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:45:56 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 17:16:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Lee", "Chung-Wei", ""], ["Zhang", "Mengxiao", ""], ["Luo", "Haipeng", ""]]}, {"id": "2102.04548", "submitter": "Bonny Banerjee", "authors": "Bonny Banerjee, Masoumeh Heidari Kapourchali, Murchana Baruah, Mousumi\n  Deb, Kenneth Sakauye, Mette Olufsen", "title": "Synthesizing Skeletal Motion and Physiological Signals as a Function of\n  a Virtual Human's Actions and Emotions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Round-the-clock monitoring of human behavior and emotions is required in many\nhealthcare applications which is very expensive but can be automated using\nmachine learning (ML) and sensor technologies. Unfortunately, the lack of\ninfrastructure for collection and sharing of such data is a bottleneck for ML\nresearch applied to healthcare. Our goal is to circumvent this bottleneck by\nsimulating a human body in virtual environment. This will allow generation of\npotentially infinite amounts of shareable data from an individual as a function\nof his actions, interactions and emotions in a care facility or at home, with\nno risk of confidentiality breach or privacy invasion. In this paper, we\ndevelop for the first time a system consisting of computational models for\nsynchronously synthesizing skeletal motion, electrocardiogram, blood pressure,\nrespiration, and skin conductance signals as a function of an open-ended set of\nactions and emotions. Our experimental evaluations, involving user studies,\nbenchmark datasets and comparison to findings in the literature, show that our\nmodels can generate skeletal motion and physiological signals with high\nfidelity. The proposed framework is modular and allows the flexibility to\nexperiment with different models. In addition to facilitating ML research for\nround-the-clock monitoring at a reduced cost, the proposed framework will allow\nreusability of code and data, and may be used as a training tool for ML\npractitioners and healthcare professionals.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:56:15 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 23:58:07 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Banerjee", "Bonny", ""], ["Kapourchali", "Masoumeh Heidari", ""], ["Baruah", "Murchana", ""], ["Deb", "Mousumi", ""], ["Sakauye", "Kenneth", ""], ["Olufsen", "Mette", ""]]}, {"id": "2102.04565", "submitter": "Jakob Schoeffer", "authors": "Jakob Schoeffer, Niklas Kuehl, Isabel Valera", "title": "A Ranking Approach to Fair Classification", "comments": "ACM SIGCAS Conference on Computing and Sustainable Societies\n  (COMPASS), June 28--July 2, 2021, Virtual Event, Australia", "journal-ref": null, "doi": "10.1145/3460112.3471950", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Algorithmic decision systems are increasingly used in areas such as hiring,\nschool admission, or loan approval. Typically, these systems rely on labeled\ndata for training a classification model. However, in many scenarios,\nground-truth labels are unavailable, and instead we have only access to\nimperfect labels as the result of (potentially biased) human-made decisions.\nDespite being imperfect, historical decisions often contain some useful\ninformation on the unobserved true labels. In this paper, we focus on scenarios\nwhere only imperfect labels are available and propose a new fair ranking-based\ndecision system based on monotonic relationships between legitimate features\nand the outcome. Our approach is both intuitive and easy to implement, and thus\nparticularly suitable for adoption in real-world settings. More in detail, we\nintroduce a distance-based decision criterion, which incorporates useful\ninformation from historical decisions and accounts for unwanted correlation\nbetween protected and legitimate features. Through extensive experiments on\nsynthetic and real-world data, we show that our method is fair in the sense\nthat a) it assigns the desirable outcome to the most qualified individuals, and\nb) it removes the effect of stereotypes in decision-making, thereby\noutperforming traditional classification algorithms. Additionally, we are able\nto show theoretically that our method is consistent with a prominent concept of\nindividual fairness which states that \"similar individuals should be treated\nsimilarly.\"\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 22:51:12 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 05:19:56 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Schoeffer", "Jakob", ""], ["Kuehl", "Niklas", ""], ["Valera", "Isabel", ""]]}, {"id": "2102.04593", "submitter": "Gabriele Di Cerbo", "authors": "Gabriele Di Cerbo, Ali Hirsa, Ahmad Shayaan", "title": "Regularized Generative Adversarial Network", "comments": "18 pages. Comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for generating samples from a probability distribution\nthat differs from the probability distribution of the training set. We use an\nadversarial process that simultaneously trains three networks, a generator and\ntwo discriminators. We refer to this new model as regularized generative\nadversarial network (RegGAN). We evaluate RegGAN on a synthetic dataset\ncomposed of gray scale images and we further show that it can be used to learn\nsome pre-specified notions in topology (basic topology properties). The work is\nmotivated by practical problems encountered while using generative methods in\nthe art world.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 01:13:36 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Di Cerbo", "Gabriele", ""], ["Hirsa", "Ali", ""], ["Shayaan", "Ahmad", ""]]}, {"id": "2102.04610", "submitter": "Pengfei Wei", "authors": "Pengfei Wei, Bi Zeng and Wenxiong Liao", "title": "Joint Intent Detection and Slot Filling with Wheel-Graph Attention\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent detection and slot filling are two fundamental tasks for building a\nspoken language understanding (SLU) system. Multiple deep learning-based joint\nmodels have demonstrated excellent results on the two tasks. In this paper, we\npropose a new joint model with a wheel-graph attention network (Wheel-GAT)\nwhich is able to model interrelated connections directly for intent detection\nand slot filling. To construct a graph structure for utterances, we create\nintent nodes, slot nodes, and directed edges. Intent nodes can provide\nutterance-level semantic information for slot filling, while slot nodes can\nalso provide local keyword information for intent. Experiments show that our\nmodel outperforms multiple baselines on two public datasets. Besides, we also\ndemonstrate that using Bidirectional Encoder Representation from Transformer\n(BERT) model further boosts the performance in the SLU task.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 02:37:56 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Wei", "Pengfei", ""], ["Zeng", "Bi", ""], ["Liao", "Wenxiong", ""]]}, {"id": "2102.04615", "submitter": "Jo\\~ao Gabriel Zago", "authors": "Jo\\~ao G. Zago, Fabio L. Baldissera, Eric A. Antonelo and Rodrigo T.\n  Saad", "title": "Benford's law: what does it say on adversarial images?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 02:50:29 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zago", "Jo\u00e3o G.", ""], ["Baldissera", "Fabio L.", ""], ["Antonelo", "Eric A.", ""], ["Saad", "Rodrigo T.", ""]]}, {"id": "2102.04632", "submitter": "Shanshan Huang", "authors": "Shanshan Huang and Kenny Q. Zhu", "title": "Statistically Profiling Biases in Natural Language Reasoning Datasets\n  and Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has indicated that many natural language understanding and\nreasoning datasets contain statistical cues that may be taken advantaged of by\nNLP models whose capability may thus be grossly overestimated. To discover the\npotential weakness in the models, some human-designed stress tests have been\nproposed but they are expensive to create and do not generalize to arbitrary\nmodels. We propose a light-weight and general statistical profiling framework,\nICQ (I-See-Cue), which automatically identifies possible biases in any\nmultiple-choice NLU datasets without the need to create any additional test\ncases, and further evaluates through blackbox testing the extent to which\nmodels may exploit these biases.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 03:51:53 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Huang", "Shanshan", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2102.04640", "submitter": "Zhuo Li", "authors": "Zhuo Li, Weiqing Min, Jiajun Song, Yaohui Zhu, Liping Kang, Xiaoming\n  Wei, Xiaolin Wei, Shuqiang Jiang", "title": "Rethinking the Optimization of Average Precision: Only Penalizing\n  Negative Instances before Positive Ones is Enough", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimising the approximation of Average Precision (AP) has been widely\nstudied for image retrieval. Such methods consider both negative and positive\ninstances ranking before each positive instance. However, we claim that only\npenalizing negative instances before positive ones is enough, because the loss\nonly comes from them. To this end, we propose a novel loss, namely Penalizing\nNegative instances before Positive ones (PNP), which directly minimizes the\nnumber of negative instances before each positive one. Meanwhile, AP-based\nmethods adopt a sub-optimal gradient assignment strategy. We systematically\ninvestigate different gradient assignment solutions via constructing derivative\nfunctions of the loss, resulting in PNP-I with increasing derivative functions\nand PNP-D with decreasing ones. PNP-I focuses more on the hard positive\ninstances by assigning larger gradients to them and tries to make all relevant\ninstances closer. In contrast, considering such instances may belong to another\ncenter of the corresponding category, PNP-D pays less attention to such\ninstances and keeps them as they were. For most real-world data, one class\nusually contains several local clusters. Thus, PNP-D is more suitable for such\nsituation. Experiments on three standard retrieval datasets show consistent\nresults of the above analysis. Extensive evaluations demonstrate that PNP-D\nachieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 04:30:15 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 06:05:32 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Zhuo", ""], ["Min", "Weiqing", ""], ["Song", "Jiajun", ""], ["Zhu", "Yaohui", ""], ["Kang", "Liping", ""], ["Wei", "Xiaoming", ""], ["Wei", "Xiaolin", ""], ["Jiang", "Shuqiang", ""]]}, {"id": "2102.04655", "submitter": "Qi Chang", "authors": "Yikai Zhang, Hui Qu, Qi Chang, Huidong Liu, Dimitris Metaxas and Chao\n  Chen", "title": "Training Federated GANs with Theoretical Guarantees: A Universal\n  Aggregation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Generative Adversarial Networks (GANs) have demonstrated their\npotential in federated learning, i.e., learning a centralized model from data\nprivately hosted by multiple sites. A federatedGAN jointly trains a centralized\ngenerator and multiple private discriminators hosted at different sites. A\nmajor theoretical challenge for the federated GAN is the heterogeneity of the\nlocal data distributions. Traditional approaches cannot guarantee to learn the\ntarget distribution, which isa mixture of the highly different local\ndistributions. This paper tackles this theoretical challenge, and for the first\ntime, provides a provably correct framework for federated GAN. We propose a new\napproach called Universal Aggregation, which simulates a centralized\ndiscriminator via carefully aggregating the mixture of all private\ndiscriminators. We prove that a generator trained with this simulated\ncentralized discriminator can learn the desired target distribution. Through\nsynthetic and real datasets, we show that our method can learn the mixture of\nlargely different distributions where existing federated GAN methods fail.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 05:44:46 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhang", "Yikai", ""], ["Qu", "Hui", ""], ["Chang", "Qi", ""], ["Liu", "Huidong", ""], ["Metaxas", "Dimitris", ""], ["Chen", "Chao", ""]]}, {"id": "2102.04661", "submitter": "Ayodeji Oseni", "authors": "Ayodeji Oseni, Nour Moustafa, Helge Janicke, Peng Liu, Zahir Tari and\n  Athanasios Vasilakos", "title": "Security and Privacy for Artificial Intelligence: Opportunities and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased adoption of Artificial Intelligence (AI) presents an\nopportunity to solve many socio-economic and environmental challenges; however,\nthis cannot happen without securing AI-enabled technologies. In recent years,\nmost AI models are vulnerable to advanced and sophisticated hacking techniques.\nThis challenge has motivated concerted research efforts into adversarial AI,\nwith the aim of developing robust machine and deep learning models that are\nresilient to different types of adversarial scenarios. In this paper, we\npresent a holistic cyber security review that demonstrates adversarial attacks\nagainst AI applications, including aspects such as adversarial knowledge and\ncapabilities, as well as existing methods for generating adversarial examples\nand existing cyber defence models. We explain mathematical AI models,\nespecially new variants of reinforcement and federated learning, to demonstrate\nhow attack vectors would exploit vulnerabilities of AI models. We also propose\na systematic framework for demonstrating attack techniques against AI\napplications and reviewed several cyber defences that would protect AI\napplications against those attacks. We also highlight the importance of\nunderstanding the adversarial goals and their capabilities, especially the\nrecent attacks against industry applications, to develop adaptive defences that\nassess to secure AI applications. Finally, we describe the main challenges and\nfuture research directions in the domain of security and privacy of AI\ntechnologies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 06:06:13 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Oseni", "Ayodeji", ""], ["Moustafa", "Nour", ""], ["Janicke", "Helge", ""], ["Liu", "Peng", ""], ["Tari", "Zahir", ""], ["Vasilakos", "Athanasios", ""]]}, {"id": "2102.04686", "submitter": "Abdur Rahim Mohammad Forkan", "authors": "Abdur Rahim Mohammad Forkan, Yong-Bin Kang, Prem Prakash Jayaraman,\n  Kewen Liao, Rohit Kaul, Graham Morgan, Rajiv Ranjan, Samir Sinha", "title": "CorrDetector: A Framework for Structural Corrosion Detection from Drone\n  Images using Ensemble Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new technique that applies automated image\nanalysis in the area of structural corrosion monitoring and demonstrate\nimproved efficacy compared to existing approaches. Structural corrosion\nmonitoring is the initial step of the risk-based maintenance philosophy and\ndepends on an engineer's assessment regarding the risk of building failure\nbalanced against the fiscal cost of maintenance. This introduces the\nopportunity for human error which is further complicated when restricted to\nassessment using drone captured images for those areas not reachable by humans\ndue to many background noises. The importance of this problem has promoted an\nactive research community aiming to support the engineer through the use of\nartificial intelligence (AI) image analysis for corrosion detection. In this\npaper, we advance this area of research with the development of a framework,\nCorrDetector. CorrDetector uses a novel ensemble deep learning approach\nunderpinned by convolutional neural networks (CNNs) for structural\nidentification and corrosion feature extraction. We provide an empirical\nevaluation using real-world images of a complicated structure (e.g.\ntelecommunication tower) captured by drones, a typical scenario for engineers.\nOur study demonstrates that the ensemble approach of \\model significantly\noutperforms the state-of-the-art in terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 07:27:16 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Forkan", "Abdur Rahim Mohammad", ""], ["Kang", "Yong-Bin", ""], ["Jayaraman", "Prem Prakash", ""], ["Liao", "Kewen", ""], ["Kaul", "Rohit", ""], ["Morgan", "Graham", ""], ["Ranjan", "Rajiv", ""], ["Sinha", "Samir", ""]]}, {"id": "2102.04697", "submitter": "Shucong Zhang", "authors": "Shucong Zhang, Cong-Thanh Do, Rama Doddipatla, Erfan Loweimi, Peter\n  Bell and Steve Renals", "title": "Train your classifier first: Cascade Neural Networks Training from upper\n  layers to lower layers", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the lower layers of a deep neural network learn features which are\ntransferable across datasets, these layers are not transferable within the same\ndataset. That is, in general, freezing the trained feature extractor (the lower\nlayers) and retraining the classifier (the upper layers) on the same dataset\nleads to worse performance. In this paper, for the first time, we show that the\nfrozen classifier is transferable within the same dataset. We develop a novel\ntop-down training method which can be viewed as an algorithm for searching for\nhigh-quality classifiers. We tested this method on automatic speech recognition\n(ASR) tasks and language modelling tasks. The proposed method consistently\nimproves recurrent neural network ASR models on Wall Street Journal,\nself-attention ASR models on Switchboard, and AWD-LSTM language models on\nWikiText-2.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:19:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhang", "Shucong", ""], ["Do", "Cong-Thanh", ""], ["Doddipatla", "Rama", ""], ["Loweimi", "Erfan", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "2102.04700", "submitter": "Peidong Liu", "authors": "Peidong Liu, Gengwei Zhang, Bochao Wang, Hang Xu, Xiaodan Liang, Yong\n  Jiang, Zhenguo Li", "title": "Loss Function Discovery for Object Detection via Convergence-Simulation\n  Driven Search", "comments": "Accepted by ICLR2021 Poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing proper loss functions for vision tasks has been a long-standing\nresearch direction to advance the capability of existing models. For object\ndetection, the well-established classification and regression loss functions\nhave been carefully designed by considering diverse learning challenges.\nInspired by the recent progress in network architecture search, it is\ninteresting to explore the possibility of discovering new loss function\nformulations via directly searching the primitive operation combinations. So\nthat the learned losses not only fit for diverse object detection challenges to\nalleviate huge human efforts, but also have better alignment with evaluation\nmetric and good mathematical convergence property. Beyond the previous\nauto-loss works on face recognition and image classification, our work makes\nthe first attempt to discover new loss functions for the challenging object\ndetection from primitive operation levels. We propose an effective\nconvergence-simulation driven evolutionary search algorithm, called\nCSE-Autoloss, for speeding up the search progress by regularizing the\nmathematical rationality of loss candidates via convergence property\nverification and model optimization simulation. CSE-Autoloss involves the\nsearch space that cover a wide range of the possible variants of existing\nlosses and discovers best-searched loss function combination within a short\ntime (around 1.5 wall-clock days). We conduct extensive evaluations of loss\nfunction search on popular detectors and validate the good generalization\ncapability of searched losses across diverse architectures and datasets. Our\nexperiments show that the best-discovered loss function combinations outperform\ndefault combinations by 1.1% and 0.8% in terms of mAP for two-stage and\none-stage detectors on COCO respectively. Our searched losses are available at\nhttps://github.com/PerdonLiu/CSE-Autoloss.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:34:52 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Liu", "Peidong", ""], ["Zhang", "Gengwei", ""], ["Wang", "Bochao", ""], ["Xu", "Hang", ""], ["Liang", "Xiaodan", ""], ["Jiang", "Yong", ""], ["Li", "Zhenguo", ""]]}, {"id": "2102.04702", "submitter": "Yilmazcan \\\"Ozyurt", "authors": "Yilmazcan \\\"Ozyurt, Mathias Kraus, Tobias Hatt, Stefan Feuerriegel", "title": "AttDMM: An Attentive Deep Markov Model for Risk Scoring in Intensive\n  Care Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical practice in intensive care units (ICUs) requires early warnings when\na patient's condition is about to deteriorate so that preventive measures can\nbe undertaken. To this end, prediction algorithms have been developed that\nestimate the risk of mortality in ICUs. In this work, we propose a novel\ngenerative deep probabilistic model for real-time risk scoring in ICUs.\nSpecifically, we develop an attentive deep Markov model called AttDMM. To the\nbest of our knowledge, AttDMM is the first ICU prediction model that jointly\nlearns both long-term disease dynamics (via attention) and different disease\nstates in health trajectory (via a latent variable model). Our evaluations were\nbased on an established baseline dataset (MIMIC-III) with 53,423 ICU stays. The\nresults confirm that compared to state-of-the-art baselines, our AttDMM was\nsuperior: AttDMM achieved an area under the receiver operating characteristic\ncurve (AUROC) of 0.876, which yielded an improvement over the state-of-the-art\nmethod by 2.2%. In addition, the risk score from the AttDMM provided warnings\nseveral hours earlier. Thereby, our model shows a path towards identifying\npatients at risk so that health practitioners can intervene early and save\npatient lives.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:44:31 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 08:46:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["\u00d6zyurt", "Yilmazcan", ""], ["Kraus", "Mathias", ""], ["Hatt", "Tobias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2102.04714", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou and Juan Carlos Nieves", "title": "Interrogating the Black Box: Transparency through Information-Seeking\n  Dialogues", "comments": "Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is preoccupied with the following question: given a (possibly\nopaque) learning system, how can we understand whether its behaviour adheres to\ngovernance constraints? The answer can be quite simple: we just need to \"ask\"\nthe system about it. We propose to construct an investigator agent to query a\nlearning agent -- the suspect agent -- to investigate its adherence to a given\nethical policy in the context of an information-seeking dialogue, modeled in\nformal argumentation settings. This formal dialogue framework is the main\ncontribution of this paper. Through it, we break down compliance checking\nmechanisms into three modular components, each of which can be tailored to\nvarious needs in a vast amount of ways: an investigator agent, a suspect agent,\nand an acceptance protocol determining whether the responses of the suspect\nagent comply with the policy. This acceptance protocol presents a fundamentally\ndifferent approach to aggregation: rather than using quantitative methods to\ndeal with the non-determinism of a learning system, we leverage the use of\nargumentation semantics to investigate the notion of properties holding\nconsistently. Overall, we argue that the introduced formal dialogue framework\nopens many avenues both in the area of compliance checking and in the analysis\nof properties of opaque systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 09:14:04 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "2102.04736", "submitter": "Gabriel Barth-Maron", "authors": "Albin Cassirer, Gabriel Barth-Maron, Eugene Brevdo, Sabela Ramos, Toby\n  Boyd, Thibault Sottiaux, Manuel Kroiss", "title": "Reverb: A Framework For Experience Replay", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central component of training in Reinforcement Learning (RL) is Experience:\nthe data used for training. The mechanisms used to generate and consume this\ndata have an important effect on the performance of RL algorithms.\n  In this paper, we introduce Reverb: an efficient, extensible, and easy to use\nsystem designed specifically for experience replay in RL. Reverb is designed to\nwork efficiently in distributed configurations with up to thousands of\nconcurrent clients.\n  The flexible API provides users with the tools to easily and accurately\nconfigure the replay buffer. It includes strategies for selecting and removing\nelements from the buffer, as well as options for controlling the ratio between\nsampled and inserted elements. This paper presents the core design of Reverb,\ngives examples of how it can be applied, and provides empirical results of\nReverb's performance characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:03:17 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Cassirer", "Albin", ""], ["Barth-Maron", "Gabriel", ""], ["Brevdo", "Eugene", ""], ["Ramos", "Sabela", ""], ["Boyd", "Toby", ""], ["Sottiaux", "Thibault", ""], ["Kroiss", "Manuel", ""]]}, {"id": "2102.04738", "submitter": "Jinn-Liang Liu", "authors": "Der-Hau Lee and Jinn-Liang Liu", "title": "End-to-End Deep Learning of Lane Detection and Path Prediction for\n  Real-Time Autonomous Driving", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end three-task convolutional neural network (3TCNN)\nhaving two regression branches of bounding boxes and Hu moments and one\nclassification branch of object masks for lane detection and road recognition.\nThe Hu-moment regressor performs lane localization and road guidance using\nlocal and global Hu moments of segmented lane objects, respectively. Based on\n3TCNN, we then propose lateral offset and path prediction (PP) algorithms to\nform an integrated model (3TCNN-PP) that can predict driving path with dynamic\nestimation of lane centerline and path curvature for real-time autonomous\ndriving. We also develop a CNN-PP simulator that can be used to train a CNN by\nreal or artificial traffic images, test it by artificial images, quantify its\ndynamic errors, and visualize its qualitative performance. Simulation results\nshow that 3TCNN-PP is comparable to related CNNs and better than a previous\nCNN-PP, respectively. The code, annotated data, and simulation videos of this\nwork can be found on our website for further research on NN-PP algorithms of\nautonomous driving.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:04:39 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Lee", "Der-Hau", ""], ["Liu", "Jinn-Liang", ""]]}, {"id": "2102.04750", "submitter": "Pedro Vicente", "authors": "Alexandre Almeida, Pedro Vicente, Alexandre Bernardino", "title": "Where is my hand? Deep hand segmentation for visual self-recognition in\n  humanoid robots", "comments": "13 pages, 12 figures, Submitted to Journal of Robotics and Autonomous\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to distinguish between the self and the background is of\nparamount importance for robotic tasks. The particular case of hands, as the\nend effectors of a robotic system that more often enter into contact with other\nelements of the environment, must be perceived and tracked with precision to\nexecute the intended tasks with dexterity and without colliding with obstacles.\nThey are fundamental for several applications, from Human-Robot Interaction\ntasks to object manipulation. Modern humanoid robots are characterized by high\nnumber of degrees of freedom which makes their forward kinematics models very\nsensitive to uncertainty. Thus, resorting to vision sensing can be the only\nsolution to endow these robots with a good perception of the self, being able\nto localize their body parts with precision. In this paper, we propose the use\nof a Convolution Neural Network (CNN) to segment the robot hand from an image\nin an egocentric view. It is known that CNNs require a huge amount of data to\nbe trained. To overcome the challenge of labeling real-world images, we propose\nthe use of simulated datasets exploiting domain randomization techniques. We\nfine-tuned the Mask-RCNN network for the specific task of segmenting the hand\nof the humanoid robot Vizzy. We focus our attention on developing a methodology\nthat requires low amounts of data to achieve reasonable performance while\ngiving detailed insight on how to properly generate variability in the training\ndataset. Moreover, we analyze the fine-tuning process within the complex model\nof Mask-RCNN, understanding which weights should be transferred to the new task\nof segmenting robot hands. Our final model was trained solely on synthetic\nimages and achieves an average IoU of 82% on synthetic validation data and\n56.3% on real test data. These results were achieved with only 1000 training\nimages and 3 hours of training time using a single GPU.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:34:32 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Almeida", "Alexandre", ""], ["Vicente", "Pedro", ""], ["Bernardino", "Alexandre", ""]]}, {"id": "2102.04760", "submitter": "Sahand Sharifzadeh", "authors": "Sahand Sharifzadeh, Sina Moayed Baharlou, Martin Schmitt, Hinrich\n  Sch\\\"utze, Volker Tresp", "title": "Improving Visual Reasoning by Exploiting The Knowledge in Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new framework for training image-based classifiers from\na combination of texts and images with very few labels. We consider a\nclassification framework with three modules: a backbone, a relational reasoning\ncomponent, and a classification component. While the backbone can be trained\nfrom unlabeled images by self-supervised learning, we can fine-tune the\nrelational reasoning and the classification components from external sources of\nknowledge instead of annotated images. By proposing a transformer-based model\nthat creates structured knowledge from textual input, we enable the utilization\nof the knowledge in texts. We show that, compared to the supervised baselines\nwith 1% of the annotated images, we can achieve ~8x more accurate results in\nscene graph classification, ~3x in object classification, and ~1.5x in\npredicate classification.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:21:44 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sharifzadeh", "Sahand", ""], ["Baharlou", "Sina Moayed", ""], ["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""], ["Tresp", "Volker", ""]]}, {"id": "2102.04770", "submitter": "Konstantin Kutzkov", "authors": "Konstantin Kutzkov", "title": "COLOGNE: Coordinated Local Graph Neighborhood Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Representation learning for graphs enables the application of standard\nmachine learning algorithms and data analysis tools to graph data. Replacing\ndiscrete unordered objects such as graph nodes by real-valued vectors is at the\nheart of many approaches to learning from graph data. Such vector\nrepresentations, or embeddings, capture the discrete relationships in the\noriginal data by representing nodes as vectors in a high-dimensional space.\n  In most applications graphs model the relationship between real-life objects\nand often nodes contain valuable meta-information about the original objects.\nWhile being a powerful machine learning tool, embeddings are not able to\npreserve such node attributes. We address this shortcoming and consider the\nproblem of learning discrete node embeddings such that the coordinates of the\nnode vector representations are graph nodes. This opens the door to designing\ninterpretable machine learning algorithms for graphs as all attributes\noriginally present in the nodes are preserved.\n  We present a framework for coordinated local graph neighborhood sampling\n(COLOGNE) such that each node is represented by a fixed number of graph nodes,\ntogether with their attributes. Individual samples are coordinated and they\npreserve the similarity between node neighborhoods. We consider different\nnotions of similarity for which we design scalable algorithms. We show\ntheoretical results for all proposed algorithms. Experiments on benchmark\ngraphs evaluate the quality of the designed embeddings and demonstrate how the\nproposed embeddings can be used in training interpretable machine learning\nalgorithms for graph data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:39:06 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kutzkov", "Konstantin", ""]]}, {"id": "2102.04775", "submitter": "Wenhao Li", "authors": "Wenhao Li, Xiangfeng Wang, Bo Jin, Junjie Sheng, Yun Hua and Hongyuan\n  Zha", "title": "Structured Diversification Emergence via Reinforced Organization Control\n  and Hierarchical Consensus Learning", "comments": "AAMAS 2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When solving a complex task, humans will spontaneously form teams and to\ncomplete different parts of the whole task, respectively. Meanwhile, the\ncooperation between teammates will improve efficiency. However, for current\ncooperative MARL methods, the cooperation team is constructed through either\nheuristics or end-to-end blackbox optimization. In order to improve the\nefficiency of cooperation and exploration, we propose a structured\ndiversification emergence MARL framework named {\\sc{Rochico}} based on\nreinforced organization control and hierarchical consensus learning.\n{\\sc{Rochico}} first learns an adaptive grouping policy through the\norganization control module, which is established by independent multi-agent\nreinforcement learning. Further, the hierarchical consensus module based on the\nhierarchical intentions with consensus constraint is introduced after team\nformation. Simultaneously, utilizing the hierarchical consensus module and a\nself-supervised intrinsic reward enhanced decision module, the proposed\ncooperative MARL algorithm {\\sc{Rochico}} can output the final diversified\nmulti-agent cooperative policy. All three modules are organically combined to\npromote the structured diversification emergence. Comparative experiments on\nfour large-scale cooperation tasks show that {\\sc{Rochico}} is significantly\nbetter than the current SOTA algorithms in terms of exploration efficiency and\ncooperation strength.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:46:12 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Li", "Wenhao", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Sheng", "Junjie", ""], ["Hua", "Yun", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2102.04782", "submitter": "Kang Zhao", "authors": "Kang Zhao, Sida Huang, Pan Pan, Yinghan Li, Yingya Zhang, Zhenyu Gu,\n  Yinghui Xu", "title": "Distribution Adaptive INT8 Quantization for Training CNNs", "comments": "This paper has been accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches have demonstrated that low bit-width (e.g., INT8) quantization can\nbe employed to accelerate the inference process. It makes the gradient\nquantization very promising since the backward propagation requires\napproximately twice more computation than forward one. Due to the variability\nand uncertainty of gradient distribution, a lot of methods have been proposed\nto attain training stability. However, most of them ignore the channel-wise\ngradient distributions and the impact of gradients with different magnitudes,\nresulting in the degradation of final accuracy. In this paper, we propose a\nnovel INT8 quantization training framework for convolutional neural network to\naddress the above issues. Specifically, we adopt Gradient Vectorized\nQuantization to quantize the gradient, based on the observation that layer-wise\ngradients contain multiple distributions along the channel dimension. Then,\nMagnitude-aware Clipping Strategy is introduced by taking the magnitudes of\ngradients into consideration when minimizing the quantization error, and we\npresent a theoretical derivation to solve the quantization parameters of\ndifferent distributions. Experimental results on broad range of computer vision\ntasks, such as image classification, object detection and video classification,\ndemonstrate that the proposed Distribution Adaptive INT8 Quantization training\nmethod has achieved almost lossless training accuracy for different backbones,\nincluding ResNet, MobileNetV2, InceptionV3, VGG and AlexNet, which is superior\nto the state-of-the-art techniques. Moreover, we further implement the INT8\nkernel that can accelerate the training iteration more than 200% under the\nlatest Turing architecture, i.e., our method excels on both training accuracy\nand speed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:58:10 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhao", "Kang", ""], ["Huang", "Sida", ""], ["Pan", "Pan", ""], ["Li", "Yinghan", ""], ["Zhang", "Yingya", ""], ["Gu", "Zhenyu", ""], ["Xu", "Yinghui", ""]]}, {"id": "2102.04805", "submitter": "Gr\\'egoire Menguy", "authors": "Gr\\'egoire Menguy, S\\'ebastien Bardin, Richard Bonichon, Cauim de\n  Souza Lima", "title": "AI-based Blackbox Code Deobfuscation: Understand, Improve and Mitigate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Code obfuscation aims at protecting Intellectual Property and other secrets\nembedded into software from being retrieved. Recent works leverage advances in\nartificial intelligence with the hope of getting blackbox deobfuscators\ncompletely immune to standard (whitebox) protection mechanisms. While\npromising, this new field of AI-based blackbox deobfuscation is still in its\ninfancy. In this article we deepen the state of AI-based blackbox deobfuscation\nin three key directions: understand the current state-of-the-art, improve over\nit and design dedicated protection mechanisms. In particular, we define a novel\ngeneric framework for AI-based blackbox deobfuscation encompassing prior work\nand highlighting key components; we are the first to point out that the search\nspace underlying code deobfuscation is too unstable for simulation-based\nmethods (e.g., Monte Carlo Tres Search used in prior work) and advocate the use\nof robust methods such as S-metaheuritics; we propose the new optimized\nAI-based blackbox deobfuscator Xyntia which significantly outperforms prior\nwork in terms of success rate (especially with small time budget) while being\ncompletely immune to the most recent anti-analysis code obfuscation methods;\nand finally we propose two novel protections against AI-based blackbox\ndeobfuscation, allowing to counter Xyntia's powerful attacks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 12:52:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Menguy", "Gr\u00e9goire", ""], ["Bardin", "S\u00e9bastien", ""], ["Bonichon", "Richard", ""], ["Lima", "Cauim de Souza", ""]]}, {"id": "2102.04848", "submitter": "Yu Liu", "authors": "Yu Liu, Lianghua Huang, Pan Pan, Bin Wang, Yinghui Xu, Rong Jin", "title": "Train a One-Million-Way Instance Classifier for Unsupervised Visual\n  Representation Learning", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple unsupervised visual representation learning\nmethod with a pretext task of discriminating all images in a dataset using a\nparametric, instance-level classifier. The overall framework is a replica of a\nsupervised classification model, where semantic classes (e.g., dog, bird, and\nship) are replaced by instance IDs. However, scaling up the classification task\nfrom thousands of semantic labels to millions of instance labels brings\nspecific challenges including 1) the large-scale softmax computation; 2) the\nslow convergence due to the infrequent visiting of instance samples; and 3) the\nmassive number of negative classes that can be noisy. This work presents\nseveral novel techniques to handle these difficulties. First, we introduce a\nhybrid parallel training framework to make large-scale training feasible.\nSecond, we present a raw-feature initialization mechanism for classification\nweights, which we assume offers a contrastive prior for instance discrimination\nand can clearly speed up converge in our experiments. Finally, we propose to\nsmooth the labels of a few hardest classes to avoid optimizing over very\nsimilar negative pairs. While being conceptually simple, our framework achieves\ncompetitive or superior performance compared to state-of-the-art unsupervised\napproaches, i.e., SimCLR, MoCoV2, and PIC under ImageNet linear evaluation\nprotocol and on several downstream visual tasks, verifying that full instance\nclassification is a strong pretraining technique for many semantic visual\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 14:44:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Liu", "Yu", ""], ["Huang", "Lianghua", ""], ["Pan", "Pan", ""], ["Wang", "Bin", ""], ["Xu", "Yinghui", ""], ["Jin", "Rong", ""]]}, {"id": "2102.04866", "submitter": "Jennifer Hobbs", "authors": "Jennifer Hobbs, Ivan Dozier, Naira Hovakimyan", "title": "Residue Density Segmentation for Monitoring and Optimizing Tillage\n  Practices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"No-till\" and cover cropping are often identified as the leading simple, best\nmanagement practices for carbon sequestration in agriculture. However, the root\nof the problem is more complex, with the potential benefits of these approaches\ndepending on numerous factors including a field's soil type(s), topography, and\nmanagement history. Instead of using computer vision approaches to simply\nclassify a field a still vs. no-till, we instead seek to identify the degree of\nresidue coverage across afield through a probabilistic deep learning\nsegmentation approach to enable more accurate analysis of carbon holding\npotential and realization. This approach will not only provide more precise\ninsights into currently implemented practices, but also enable a more accurate\nidentification process of fields with the greatest potential for adopting new\npractices to significantly impact carbon sequestration in agriculture.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:00:45 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hobbs", "Jennifer", ""], ["Dozier", "Ivan", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "2102.04871", "submitter": "Kenneth Reid", "authors": "Kenneth N. Reid, Iliya Miralavy, Stephen Kelly, Wolfgang Banzhaf,\n  Cedric Gondro", "title": "The Factory Must Grow: Automation in Factorio", "comments": "Submitted to GECCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient optimization of resources is paramount to success in many problems\nfaced today. In the field of operational research the efficient scheduling of\nemployees; packing of vans; routing of vehicles; logistics of airlines and\ntransport of materials can be the difference between emission reduction or\nexcess, profits or losses and feasibility or unworkable solutions. The video\ngame Factorio, by Wube Software, has a myriad of problems which are analogous\nto such real-world problems, and is a useful simulator for developing solutions\nfor these problems. In this paper we define the logistic transport belt problem\nand define mathematical integer programming model of it. We developed an\ninterface to allow optimizers in any programming language to interact with\nFactorio, and we provide an initial benchmark of logistic transport belt\nproblems. We present results for Simulated Annealing, quick Genetic Programming\nand Evolutionary Reinforcement Learning, three different meta-heuristic\ntechniques to optimize this novel problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:14:27 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Reid", "Kenneth N.", ""], ["Miralavy", "Iliya", ""], ["Kelly", "Stephen", ""], ["Banzhaf", "Wolfgang", ""], ["Gondro", "Cedric", ""]]}, {"id": "2102.04897", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Vivek Veeriah, Risto Vuorio, Richard Lewis, Satinder Singh", "title": "Learning State Representations from Random Deep Action-conditional\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study auxiliary prediction tasks defined by\ntemporal-difference networks (TD networks); these networks are a language for\nexpressing a rich space of general value function (GVF) prediction targets that\nmay be learned efficiently with TD. Through analysis in an illustrative domain\nwe show the benefits to learning state representations of exploiting the full\nrichness of TD networks, including both action-conditional predictions and\ntemporally deep predictions. Our main (and perhaps surprising) result is that\ndeep action-conditional TD networks with random structures that create random\nprediction-questions about random features yield state representations that are\ncompetitive with state-of-the-art hand-crafted value prediction and pixel\ncontrol auxiliary tasks in both Atari games and DeepMind Lab tasks. We also\nshow through stop-gradient experiments that learning the state representations\nsolely via these unsupervised random TD network prediction tasks yield agents\nthat outperform the end-to-end-trained actor-critic baseline.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:53:22 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zheng", "Zeyu", ""], ["Veeriah", "Vivek", ""], ["Vuorio", "Risto", ""], ["Lewis", "Richard", ""], ["Singh", "Satinder", ""]]}, {"id": "2102.04907", "submitter": "Chao Gao", "authors": "Chao Gao", "title": "On Computation Complexity of True Proof Number Search", "comments": "5 pages, short. Specific discussion on a narrow topic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We point out that the computation of true \\emph{proof} and \\emph{disproof}\nnumbers for proof number search in arbitrary directed acyclic graphs is\nNP-hard, an important theoretical result for proof number search. The proof\nrequires a reduction from SAT, which demonstrates that finding true\nproof/disproof number for arbitrary DAG is at least as hard as deciding if\narbitrary SAT instance is satisfiable, thus NP-hard.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 06:06:54 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Gao", "Chao", ""]]}, {"id": "2102.04916", "submitter": "Pierre Aumjaud", "authors": "Pierre Aumjaud, David McAuliffe, Francisco Javier Rodr\\'iguez Lera,\n  Philip Cardiff", "title": "rl_reach: Reproducible Reinforcement Learning Experiments for Robotic\n  Reaching Tasks", "comments": "7 pages, 5 figures", "journal-ref": "Software Impacts. 8 (2021) 100061", "doi": "10.1016/j.simpa.2021.100061", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training reinforcement learning agents at solving a given task is highly\ndependent on identifying optimal sets of hyperparameters and selecting suitable\nenvironment input / output configurations. This tedious process could be eased\nwith a straightforward toolbox allowing its user to quickly compare different\ntraining parameter sets. We present rl_reach, a self-contained, open-source and\neasy-to-use software package designed to run reproducible reinforcement\nlearning experiments for customisable robotic reaching tasks. rl_reach packs\ntogether training environments, agents, hyperparameter optimisation tools and\npolicy evaluation scripts, allowing its users to quickly investigate and\nidentify optimal training configurations. rl_reach is publicly available at\nthis URL: https://github.com/PierreExeter/rl_reach.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 16:14:10 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 19:32:01 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Aumjaud", "Pierre", ""], ["McAuliffe", "David", ""], ["Lera", "Francisco Javier Rodr\u00edguez", ""], ["Cardiff", "Philip", ""]]}, {"id": "2102.04932", "submitter": "Hieu Nguyen", "authors": "Kai Zhen (1 and 2), Hieu Duy Nguyen (2), Feng-Ju Chang (2), Athanasios\n  Mouchtaris (2), and Ariya Rastrow (2). ((1) Indiana University Bloomington,\n  (2) Alexa Machine Learning, Amazon, USA)", "title": "Sparsification via Compressed Sensing for Automatic Speech Recognition", "comments": "5 pages, accepted for publication in (ICASSP 2021) 2021 IEEE\n  International Conference on Acoustics, Speech, and Signal Processing. June\n  6-12, 2021. Location: Toronto, ON, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to achieve high accuracy for machine learning (ML) applications, it\nis essential to employ models with a large number of parameters. Certain\napplications, such as Automatic Speech Recognition (ASR), however, require\nreal-time interactions with users, hence compelling the model to have as low\nlatency as possible. Deploying large scale ML applications thus necessitates\nmodel quantization and compression, especially when running ML models on\nresource constrained devices. For example, by forcing some of the model weight\nvalues into zero, it is possible to apply zero-weight compression, which\nreduces both the model size and model reading time from the memory. In the\nliterature, such methods are referred to as sparse pruning. The fundamental\nquestions are when and which weights should be forced to zero, i.e. be pruned.\nIn this work, we propose a compressed sensing based pruning (CSP) approach to\neffectively address those questions. By reformulating sparse pruning as a\nsparsity inducing and compression-error reduction dual problem, we introduce\nthe classic compressed sensing process into the ML model training process.\nUsing ASR task as an example, we show that CSP consistently outperforms\nexisting approaches in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 16:41:31 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhen", "Kai", "", "1 and 2"], ["Nguyen", "Hieu Duy", ""], ["Chang", "Feng-Ju", ""], ["Mouchtaris", "Athanasios", ""], ["Rastrow", "Ariya", ""], [".", "", ""]]}, {"id": "2102.04945", "submitter": "Jordi Pons", "authors": "Xiaoyu Liu and Jordi Pons", "title": "On permutation invariant training for speech source separation", "comments": "In proceedings of ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study permutation invariant training (PIT), which targets at the\npermutation ambiguity problem for speaker independent source separation models.\nWe extend two state-of-the-art PIT strategies. First, we look at the two-stage\nspeaker separation and tracking algorithm based on frame level PIT (tPIT) and\nclustering, which was originally proposed for the STFT domain, and we adapt it\nto work with waveforms and over a learned latent space. Further, we propose an\nefficient clustering loss scalable to waveform models. Second, we extend a\nrecently proposed auxiliary speaker-ID loss with a deep feature loss based on\n\"problem agnostic speech features\", to reduce the local permutation errors made\nby the utterance level PIT (uPIT). Our results show that the proposed\nextensions help reducing permutation ambiguity. However, we also note that the\nstudied STFT-based models are more effective at reducing permutation errors\nthan waveform-based models, a perspective overlooked in recent studies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 16:57:32 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 07:04:59 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liu", "Xiaoyu", ""], ["Pons", "Jordi", ""]]}, {"id": "2102.04958", "submitter": "Robyn Kozierok", "authors": "Robyn Kozierok, John Aberdeen, Cheryl Clark, Christopher Garay,\n  Bradley Goodman, Tonia Korves, Lynette Hirschman, Patricia L. McDermott,\n  Matthew W. Peterson", "title": "Hallmarks of Human-Machine Collaboration: A framework for assessment in\n  the DARPA Communicating with Computers Program", "comments": "20 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": "MITRE Document Number: MTR210002", "categories": "cs.HC cs.AI cs.CL cs.MA cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing desire to create computer systems that can communicate\neffectively to collaborate with humans on complex, open-ended activities.\nAssessing these systems presents significant challenges. We describe a\nframework for evaluating systems engaged in open-ended complex scenarios where\nevaluators do not have the luxury of comparing performance to a single right\nanswer. This framework has been used to evaluate human-machine creative\ncollaborations across story and music generation, interactive block building,\nand exploration of molecular mechanisms in cancer. These activities are\nfundamentally different from the more constrained tasks performed by most\ncontemporary personal assistants as they are generally open-ended, with no\nsingle correct solution, and often no obvious completion criteria.\n  We identified the Key Properties that must be exhibited by successful\nsystems. From there we identified \"Hallmarks\" of success -- capabilities and\nfeatures that evaluators can observe that would be indicative of progress\ntoward achieving a Key Property. In addition to being a framework for\nassessment, the Key Properties and Hallmarks are intended to serve as goals in\nguiding research direction.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 17:13:53 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kozierok", "Robyn", ""], ["Aberdeen", "John", ""], ["Clark", "Cheryl", ""], ["Garay", "Christopher", ""], ["Goodman", "Bradley", ""], ["Korves", "Tonia", ""], ["Hirschman", "Lynette", ""], ["McDermott", "Patricia L.", ""], ["Peterson", "Matthew W.", ""]]}, {"id": "2102.04969", "submitter": "Xiao-Wei Chen", "authors": "Xiao-wei Chen (Sun Yat-sen University)", "title": "Semantic Borrowing for Generalized Zero-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized zero-shot learning (GZSL) is one of the most realistic problems,\nbut also one of the most challenging problems due to the partiality of the\nclassifier to supervised classes. Instance-borrowing methods and synthesizing\nmethods solve this problem to some extent with the help of testing semantics,\nbut therefore neither can be used under the class-inductive instance-inductive\n(CIII) training setting where testing data are not available, and the latter\nrequire the training process of a classifier after generating examples. In\ncontrast, a novel method called Semantic Borrowing for improving GZSL methods\nwith compatibility metric learning under CIII is proposed in this paper. It\nborrows similar semantics in the training set, so that the classifier can model\nthe relationship between the semantics of zero-shot and supervised classes more\naccurately during training. In practice, the information of semantics of unseen\nor unknown classes would not be available for training while this approach does\nNOT need any information of semantics of unseen or unknown classes. The\nexperimental results on representative GZSL benchmark datasets show that it can\nreduce the partiality of the classifier to supervised classes and improve the\nperformance of generalized zero-shot classification.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 12:14:28 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Chen", "Xiao-wei", "", "Sun Yat-sen University"]]}, {"id": "2102.04972", "submitter": "Shane Mueller", "authors": "Shane T. Mueller, Elizabeth S. Veinott, Robert R. Hoffman, Gary Klein,\n  Lamia Alam, Tauseef Mamun, and William J. Clancey", "title": "Principles of Explanation in Human-AI Systems", "comments": "AAAI-2021, Explainable Agency in Artificial Intelligence WS, AAAI,\n  Feb, 2021, Virtual Conference, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (XAI) has re-emerged in response to the\ndevelopment of modern AI and ML systems. These systems are complex and\nsometimes biased, but they nevertheless make decisions that impact our lives.\nXAI systems are frequently algorithm-focused; starting and ending with an\nalgorithm that implements a basic untested idea about explainability. These\nsystems are often not tested to determine whether the algorithm helps users\naccomplish any goals, and so their explainability remains unproven. We propose\nan alternative: to start with human-focused principles for the design, testing,\nand implementation of XAI systems, and implement algorithms to serve that\npurpose. In this paper, we review some of the basic concepts that have been\nused for user-centered XAI systems over the past 40 years of research. Based on\nthese, we describe the \"Self-Explanation Scorecard\", which can help developers\nunderstand how they can empower users by enabling self-explanation. Finally, we\npresent a set of empirically-grounded, user-centered design principles that may\nguide developers to create successful explainable systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 17:43:45 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Mueller", "Shane T.", ""], ["Veinott", "Elizabeth S.", ""], ["Hoffman", "Robert R.", ""], ["Klein", "Gary", ""], ["Alam", "Lamia", ""], ["Mamun", "Tauseef", ""], ["Clancey", "William J.", ""]]}, {"id": "2102.04977", "submitter": "Sutanay Choudhury", "authors": "Logan Ward and Jenna A. Bilbrey and Sutanay Choudhury and Neeraj Kumar\n  and Ganesh Sivaraman", "title": "Benchmarking Deep Graph Generative Models for Optimizing New Drug\n  Molecules for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design of new drug compounds with target properties is a key area of research\nin generative modeling. We present a small drug molecule design pipeline based\non graph-generative models and a comparison study of two state-of-the-art graph\ngenerative models for designing COVID-19 targeted drug candidates: 1) a\nvariational autoencoder-based approach (VAE) that uses prior knowledge of\nmolecules that have been shown to be effective for earlier coronavirus\ntreatments and 2) a deep Q-learning method (DQN) that generates optimized\nmolecules without any proximity constraints. We evaluate the novelty of the\nautomated molecule generation approaches by validating the candidate molecules\nwith drug-protein binding affinity models. The VAE method produced two novel\nmolecules with similar structures to the antiretroviral protease inhibitor\nIndinavir that show potential binding affinity for the SARS-CoV-2 protein\ntarget 3-chymotrypsin-like protease (3CL-protease).\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 17:49:26 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ward", "Logan", ""], ["Bilbrey", "Jenna A.", ""], ["Choudhury", "Sutanay", ""], ["Kumar", "Neeraj", ""], ["Sivaraman", "Ganesh", ""]]}, {"id": "2102.04998", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Philip M. Long, Peter L. Bartlett", "title": "When does gradient descent with logistic loss interpolate using deep\n  networks with smoothed ReLU activations?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish conditions under which gradient descent applied to fixed-width\ndeep networks drives the logistic loss to zero, and prove bounds on the rate of\nconvergence. Our analysis applies for smoothed approximations to the ReLU, such\nas Swish and the Huberized ReLU, proposed in previous applied work. We provide\ntwo sufficient conditions for convergence. The first is simply a bound on the\nloss at initialization. The second is a data separation condition used in prior\nanalyses.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:04:37 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 04:14:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Long", "Philip M.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "2102.04999", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Risto Vuorio, Richard Lewis, Satinder Singh", "title": "Pairwise Weights for Temporal Credit Assignment", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much credit (or blame) should an action taken in a state get for a future\nreward? This is the fundamental temporal credit assignment problem in\nReinforcement Learning (RL). One of the earliest and still most widely used\nheuristics is to assign this credit based on a scalar coefficient $\\lambda$\n(treated as a hyperparameter) raised to the power of the time interval between\nthe state-action and the reward. In this empirical paper, we explore heuristics\nbased on more general pairwise weightings that are functions of the state in\nwhich the action was taken, the state at the time of the reward, as well as the\ntime interval between the two. Of course it isn't clear what these pairwise\nweight functions should be, and because they are too complex to be treated as\nhyperparameters we develop a metagradient procedure for learning these weight\nfunctions during the usual RL training of a policy. Our empirical work shows\nthat it is often possible to learn these pairwise weight functions during\nlearning of the policy to achieve better performance than competing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:06:29 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zheng", "Zeyu", ""], ["Vuorio", "Risto", ""], ["Lewis", "Richard", ""], ["Singh", "Satinder", ""]]}, {"id": "2102.05008", "submitter": "Lewis Hammond", "authors": "Lewis Hammond, James Fox, Tom Everitt, Alessandro Abate, Michael\n  Wooldridge", "title": "Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and\n  Practice", "comments": "Accepted to the 20th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent influence diagrams (MAIDs) are a popular form of graphical model\nthat, for certain classes of games, have been shown to offer key complexity and\nexplainability advantages over traditional extensive form game (EFG)\nrepresentations. In this paper, we extend previous work on MAIDs by introducing\nthe concept of a MAID subgame, as well as subgame perfect and trembling hand\nperfect equilibrium refinements. We then prove several equivalence results\nbetween MAIDs and EFGs. Finally, we describe an open source implementation for\nreasoning about MAIDs and computing their equilibria.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:20:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Hammond", "Lewis", ""], ["Fox", "James", ""], ["Everitt", "Tom", ""], ["Abate", "Alessandro", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2102.05026", "submitter": "Marco Ciccone", "authors": "Federico Cacciamani, Andrea Celli, Marco Ciccone, Nicola Gatti", "title": "Multi-Agent Coordination in Adversarial Environments through Signal\n  Mediated Strategies", "comments": "Accepted at AAMAS 2021 (full paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world scenarios involve teams of agents that have to coordinate\ntheir actions to reach a shared goal. We focus on the setting in which a team\nof agents faces an opponent in a zero-sum, imperfect-information game. Team\nmembers can coordinate their strategies before the beginning of the game, but\nare unable to communicate during the playing phase of the game. This is the\ncase, for example, in Bridge, collusion in poker, and collusion in bidding. In\nthis setting, model-free RL methods are oftentimes unable to capture\ncoordination because agents' policies are executed in a decentralized fashion.\nOur first contribution is a game-theoretic centralized training regimen to\neffectively perform trajectory sampling so as to foster team coordination. When\nteam members can observe each other actions, we show that this approach\nprovably yields equilibrium strategies. Then, we introduce a signaling-based\nframework to represent team coordinated strategies given a buffer of past\nexperiences. Each team member's policy is parametrized as a neural network\nwhose output is conditioned on a suitable exogenous signal, drawn from a\nlearned probability distribution. By combining these two elements, we\nempirically show convergence to coordinated equilibria in cases where previous\nstate-of-the-art multi-agent RL algorithms did not.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:44:16 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Cacciamani", "Federico", ""], ["Celli", "Andrea", ""], ["Ciccone", "Marco", ""], ["Gatti", "Nicola", ""]]}, {"id": "2102.05034", "submitter": "Bahare Fatemi", "authors": "Bahare Fatemi, Layla El Asri, Seyed Mehran Kazemi", "title": "SLAPS: Self-Supervision Improves Structure Learning for Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) work well when the graph structure is provided.\nHowever, this structure may not always be available in real-world applications.\nOne solution to this problem is to infer a task-specific latent structure and\nthen apply a GNN to the inferred graph. Unfortunately, the space of possible\ngraph structures grows super-exponentially with the number of nodes and so the\ntask-specific supervision may be insufficient for learning both the structure\nand the GNN parameters. In this work, we propose the Simultaneous Learning of\nAdjacency and GNN Parameters with Self-supervision, or SLAPS, a method that\nprovides more supervision for inferring a graph structure through\nself-supervision. A comprehensive experimental study demonstrates that SLAPS\nscales to large graphs with hundreds of thousands of nodes and outperforms\nseveral models that have been proposed to learn a task-specific graph structure\non established benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:56:01 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Fatemi", "Bahare", ""], ["Asri", "Layla El", ""], ["Kazemi", "Seyed Mehran", ""]]}, {"id": "2102.05096", "submitter": "Jay Nandy", "authors": "Jay Nandy and Sudipan Saha and Wynne Hsu and Mong Li Lee and Xiao\n  Xiang Zhu", "title": "Adversarially Trained Models with Test-Time Covariate Shift Adaptation", "comments": "An abridged version of this work has been presented at ICLR 2021\n  Workshop on Security and Safety in Machine Learning Systems:\n  https://aisecure-workshop.github.io/aml-iclr2021/papers/2.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically demonstrate that test-time adaptive batch normalization, which\nre-estimates the batch-normalization statistics during inference, can provide\n$\\ell_2$-certification as well as improve the commonly occurring corruption\nrobustness of adversarially trained models while maintaining their\nstate-of-the-art empirical robustness against adversarial attacks. Furthermore,\nwe obtain similar $\\ell_2$-certification as the current state-of-the-art\ncertification models for CIFAR-10 by learning our adversarially trained model\nusing larger $\\ell_2$-bounded adversaries. Therefore our work is a step towards\nbridging the gap between the state-of-the-art certification and empirical\nrobustness. Our results also indicate that improving the empirical adversarial\nrobustness may be sufficient as we achieve certification and corruption\nrobustness as a by-product using test-time adaptive batch normalization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 19:51:56 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 08:16:34 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nandy", "Jay", ""], ["Saha", "Sudipan", ""], ["Hsu", "Wynne", ""], ["Lee", "Mong Li", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2102.05113", "submitter": "Abhishek Sinha", "authors": "Abhishek Sinha, Kumar Ayush, Jiaming Song, Burak Uzkent, Hongxia Jin,\n  Stefano Ermon", "title": "Negative Data Augmentation", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data augmentation is often used to enlarge datasets with synthetic samples\ngenerated in accordance with the underlying data distribution. To enable a\nwider range of augmentations, we explore negative data augmentation strategies\n(NDA)that intentionally create out-of-distribution samples. We show that such\nnegative out-of-distribution samples provide information on the support of the\ndata distribution, and can be leveraged for generative modeling and\nrepresentation learning. We introduce a new GAN training objective where we use\nNDA as an additional source of synthetic data for the discriminator. We prove\nthat under suitable conditions, optimizing the resulting objective still\nrecovers the true data distribution but can directly bias the generator towards\navoiding samples that lack the desired structure. Empirically, models trained\nwith our method achieve improved conditional/unconditional image generation\nalong with improved anomaly detection capabilities. Further, we incorporate the\nsame negative data augmentation strategy in a contrastive learning framework\nfor self-supervised representation learning on images and videos, achieving\nimproved performance on downstream image classification, object detection, and\naction recognition tasks. These results suggest that prior knowledge on what\ndoes not constitute valid data is an effective form of weak supervision across\na range of unsupervised learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 20:28:35 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sinha", "Abhishek", ""], ["Ayush", "Kumar", ""], ["Song", "Jiaming", ""], ["Uzkent", "Burak", ""], ["Jin", "Hongxia", ""], ["Ermon", "Stefano", ""]]}, {"id": "2102.05123", "submitter": "Guangyu Shen", "authors": "Guangyu Shen, Yingqi Liu, Guanhong Tao, Shengwei An, Qiuling Xu,\n  Siyuan Cheng, Shiqing Ma, Xiangyu Zhang", "title": "Backdoor Scanning for Deep Neural Networks through K-Arm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Back-door attack poses a severe threat to deep learning systems. It injects\nhidden malicious behaviors to a model such that any input stamped with a\nspecial pattern can trigger such behaviors. Detecting back-door is hence of\npressing need. Many existing defense techniques use optimization to generate\nthe smallest input pattern that forces the model to misclassify a set of benign\ninputs injected with the pattern to a target label. However, the complexity is\nquadratic to the number of class labels such that they can hardly handle models\nwith many classes. Inspired by Multi-Arm Bandit in Reinforcement Learning, we\npropose a K-Arm optimization method for backdoor detection. By iteratively and\nstochastically selecting the most promising labels for optimization with the\nguidance of an objective function, we substantially reduce the complexity,\nallowing to handle models with many classes. Moreover, by iteratively refining\nthe selection of labels to optimize, it substantially mitigates the uncertainty\nin choosing the right labels, improving detection accuracy. At the time of\nsubmission, the evaluation of our method on over 4000 models in the IARPA\nTrojAI competition from round 1 to the latest round 4 achieves top performance\non the leaderboard. Our technique also supersedes three state-of-the-art\ntechniques in terms of accuracy and the scanning time needed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 20:49:06 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 19:17:09 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Shen", "Guangyu", ""], ["Liu", "Yingqi", ""], ["Tao", "Guanhong", ""], ["An", "Shengwei", ""], ["Xu", "Qiuling", ""], ["Cheng", "Siyuan", ""], ["Ma", "Shiqing", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2102.05126", "submitter": "Jon\\'a\\v{s} Kulh\\'anek", "authors": "Jon\\'a\\v{s} Kulh\\'anek and Vojt\\v{e}ch Hude\\v{c}ek and Tom\\'a\\v{s}\n  Nekvinda and Ond\\v{r}ej Du\\v{s}ek", "title": "AuGPT: Dialogue with Pre-trained Language Models and Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based pre-trained language models such as GPT-2 brought\nconsiderable progress to end-to-end dialogue modelling. However, they also\npresent considerable risks for task-oriented dialogue, such as lack of\nknowledge grounding or diversity. To address these issues, we introduce\nmodified training objectives for language model finetuning, and we employ\nmassive data augmentation via back-translation to increase the diversity of the\ntraining data. We further examine the possibilities of combining data from\nmultiples sources to improve performance on the target dataset. We carefully\nevaluate our contributions with both human and automatic methods. Our model\nachieves state-of-the-art performance on the MultiWOZ data and shows\ncompetitive performance in human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 20:53:34 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Kulh\u00e1nek", "Jon\u00e1\u0161", ""], ["Hude\u010dek", "Vojt\u011bch", ""], ["Nekvinda", "Tom\u00e1\u0161", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2102.05131", "submitter": "Dara Bahri", "authors": "Dara Bahri and Heinrich Jiang and Yi Tay and Donald Metzler", "title": "Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting out-of-distribution (OOD) examples is critical in many\napplications. We propose an unsupervised method to detect OOD samples using a\n$k$-NN density estimate with respect to a classification model's intermediate\nactivations on in-distribution samples. We leverage a recent insight about\nlabel smoothing, which we call the \\emph{Label Smoothed Embedding Hypothesis},\nand show that one of the implications is that the $k$-NN density estimator\nperforms better as an OOD detection method both theoretically and empirically\nwhen the model is trained with label smoothing. Finally, we show that our\nproposal outperforms many OOD baselines and also provide new finite-sample\nhigh-probability statistical results for $k$-NN density estimation's ability to\ndetect OOD examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:04:44 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""], ["Tay", "Yi", ""], ["Metzler", "Donald", ""]]}, {"id": "2102.05140", "submitter": "Dara Bahri", "authors": "Dara Bahri and Heinrich Jiang", "title": "Locally Adaptive Label Smoothing for Predictive Churn", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training modern neural networks is an inherently noisy process that can lead\nto high \\emph{prediction churn} -- disagreements between re-trainings of the\nsame model due to factors such as randomization in the parameter initialization\nand mini-batches -- even when the trained models all attain similar accuracies.\nSuch prediction churn can be very undesirable in practice. In this paper, we\npresent several baselines for reducing churn and show that training on soft\nlabels obtained by adaptively smoothing each example's label based on the\nexample's neighboring labels often outperforms the baselines on churn while\nimproving accuracy on a variety of benchmark classification tasks and model\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:38:37 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 22:36:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""]]}, {"id": "2102.05147", "submitter": "Kolawole Ogunsina", "authors": "Kolawole Ogunsina, Marios Papamichalis, Daniel DeLaurentis", "title": "Uncertainty Quantification and Propagation for Airline Disruption\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Disruption management during the airline scheduling process can be\ncompartmentalized into proactive and reactive processes depending upon the time\nof schedule execution. The state of the art for decision-making in airline\ndisruption management involves a heuristic human-centric approach that does not\ncategorically study uncertainty in proactive and reactive processes for\nmanaging airline schedule disruptions. Hence, this paper introduces an\nuncertainty transfer function model (UTFM) framework that characterizes\nuncertainty for proactive airline disruption management before schedule\nexecution, reactive airline disruption management during schedule execution,\nand proactive airline disruption management after schedule execution to enable\nthe construction of quantitative tools that can allow an intelligent agent to\nrationalize complex interactions and procedures for robust airline disruption\nmanagement. Specifically, we use historical scheduling and operations data from\na major U.S. airline to facilitate the development and assessment of the UTFM,\ndefined by hidden Markov models (a special class of probabilistic graphical\nmodels) that can efficiently perform pattern learning and inference on portions\nof large data sets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 21:57:04 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:35:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ogunsina", "Kolawole", ""], ["Papamichalis", "Marios", ""], ["DeLaurentis", "Daniel", ""]]}, {"id": "2102.05152", "submitter": "Hao Yuan", "authors": "Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, Shuiwang Ji", "title": "On Explainability of Graph Neural Networks via Subgraph Explorations", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of explaining the predictions of graph neural\nnetworks (GNNs), which otherwise are considered as black boxes. Existing\nmethods invariably focus on explaining the importance of graph nodes or edges\nbut ignore the substructures of graphs, which are more intuitive and\nhuman-intelligible. In this work, we propose a novel method, known as\nSubgraphX, to explain GNNs by identifying important subgraphs. Given a trained\nGNN model and an input graph, our SubgraphX explains its predictions by\nefficiently exploring different subgraphs with Monte Carlo tree search. To make\nthe tree search more effective, we propose to use Shapley values as a measure\nof subgraph importance, which can also capture the interactions among different\nsubgraphs. To expedite computations, we propose efficient approximation schemes\nto compute Shapley values for graph data. Our work represents the first attempt\nto explain GNNs via identifying subgraphs explicitly and directly. Experimental\nresults show that our SubgraphX achieves significantly improved explanations,\nwhile keeping computations at a reasonable level.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:12:26 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 21:16:36 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Yuan", "Hao", ""], ["Yu", "Haiyang", ""], ["Wang", "Jie", ""], ["Li", "Kang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2102.05169", "submitter": "Eunsol Choi", "authors": "Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski,\n  Dipanjan Das, Michael Collins", "title": "Decontextualization: Making Sentences Stand-Alone", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Models for question answering, dialogue agents, and summarization often\ninterpret the meaning of a sentence in a rich context and use that meaning in a\nnew context. Taking excerpts of text can be problematic, as key pieces may not\nbe explicit in a local window. We isolate and define the problem of sentence\ndecontextualization: taking a sentence together with its context and rewriting\nit to be interpretable out of context, while preserving its meaning. We\ndescribe an annotation procedure, collect data on the Wikipedia corpus, and use\nthe data to train models to automatically decontextualize sentences. We present\npreliminary studies that show the value of sentence decontextualization in a\nuser facing task, and as preprocessing for systems that perform document\nunderstanding. We argue that decontextualization is an important subtask in\nmany downstream applications, and that the definitions and resources provided\ncan benefit tasks that operate on sentences that occur in a richer context.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:52:37 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Choi", "Eunsol", ""], ["Palomaki", "Jennimaria", ""], ["Lamm", "Matthew", ""], ["Kwiatkowski", "Tom", ""], ["Das", "Dipanjan", ""], ["Collins", "Michael", ""]]}, {"id": "2102.05185", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross and Finale Doshi-Velez", "title": "Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement", "comments": "ICML 2021 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In representation learning, there has been recent interest in developing\nalgorithms to disentangle the ground-truth generative factors behind a dataset,\nand metrics to quantify how fully this occurs. However, these algorithms and\nmetrics often assume that both representations and ground-truth factors are\nflat, continuous, and factorized, whereas many real-world generative processes\ninvolve rich hierarchical structure, mixtures of discrete and continuous\nvariables with dependence between them, and even varying intrinsic\ndimensionality. In this work, we develop benchmarks, algorithms, and metrics\nfor learning such hierarchical representations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 23:34:24 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 15:22:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2102.05246", "submitter": "Yi Luo", "authors": "Yi Luo, Aiguo Chen, Bei Hui, Ke Yan", "title": "Memory-Associated Differential Learning", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Supervised Learning approaches focus on the mapping from input\nfeatures to output labels. After training, the learnt models alone are adapted\nonto testing features to predict testing labels in isolation, with training\ndata wasted and their associations ignored. To take full advantage of the vast\nnumber of training data and their associations, we propose a novel learning\nparadigm called Memory-Associated Differential (MAD) Learning. We first\nintroduce an additional component called Memory to memorize all the training\ndata. Then we learn the differences of labels as well as the associations of\nfeatures in the combination of a differential equation and some sampling\nmethods. Finally, in the evaluating phase, we predict unknown labels by\ninferencing from the memorized facts plus the learnt differences and\nassociations in a geometrically meaningful manner. We gently build this theory\nin unary situations and apply it on Image Recognition, then extend it into Link\nPrediction as a binary situation, in which our method outperforms strong\nstate-of-the-art baselines on ogbl-ddi dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:48:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 06:41:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Luo", "Yi", ""], ["Chen", "Aiguo", ""], ["Hui", "Bei", ""], ["Yan", "Ke", ""]]}, {"id": "2102.05249", "submitter": "Arash Mahyari", "authors": "Arash Mahyari", "title": "Policy Augmentation: An Exploration Strategy for Faster Convergence of\n  Deep Reinforcement Learning Algorithms", "comments": "proceedings of 46th IEEE International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite advancements in deep reinforcement learning algorithms, developing an\neffective exploration strategy is still an open problem. Most existing\nexploration strategies either are based on simple heuristics, or require the\nmodel of the environment, or train additional deep neural networks to generate\nimagination-augmented paths. In this paper, a revolutionary algorithm, called\nPolicy Augmentation, is introduced. Policy Augmentation is based on a newly\ndeveloped inductive matrix completion method. The proposed algorithm augments\nthe values of unexplored state-action pairs, helping the agent take actions\nthat will result in high-value returns while the agent is in the early\nepisodes. Training deep reinforcement learning algorithms with high-value\nrollouts leads to the faster convergence of deep reinforcement learning\nalgorithms. Our experiments show the superior performance of Policy\nAugmentation. The code can be found at:\nhttps://github.com/arashmahyari/PolicyAugmentation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:51:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mahyari", "Arash", ""]]}, {"id": "2102.05261", "submitter": "Shi Dong", "authors": "Shi Dong, Benjamin Van Roy, Zhengyuan Zhou", "title": "Simple Agent, Complex Environment: Efficient Reinforcement Learning with\n  Agent States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a simple reinforcement learning (RL) agent that implements an\noptimistic version of $Q$-learning and establish through regret analysis that\nthis agent can operate with some level of competence in any environment. While\nwe leverage concepts from the literature on provably efficient RL, we consider\na general agent-environment interface and provide a novel agent design and\nanalysis. This level of generality positions our results to inform the design\nof future agents for operation in complex real environments. We establish that,\nas time progresses, our agent performs competitively relative to policies that\nrequire longer times to evaluate. The time it takes to approach asymptotic\nperformance is polynomial in the complexity of the agent's state representation\nand the time required to evaluate the best policy that the agent can represent.\nNotably, there is no dependence on the complexity of the environment. The\nultimate per-period performance loss of the agent is bounded by a constant\nmultiple of a measure of distortion introduced by the agent's state\nrepresentation. This work is the first to establish that an algorithm\napproaches this asymptotic condition within a tractable time frame.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 04:53:12 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:49:32 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 20:20:34 GMT"}, {"version": "v4", "created": "Mon, 8 Mar 2021 17:44:14 GMT"}, {"version": "v5", "created": "Sat, 13 Mar 2021 05:41:21 GMT"}, {"version": "v6", "created": "Wed, 7 Jul 2021 06:31:41 GMT"}, {"version": "v7", "created": "Mon, 12 Jul 2021 02:07:04 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dong", "Shi", ""], ["Van Roy", "Benjamin", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2102.05263", "submitter": "Santiago Ontanon", "authors": "Robert C. Gray, Jichen Zhu, Santiago Onta\\~n\\'on", "title": "Regression Oracles and Exploration Strategies for Short-Horizon\n  Multi-Armed Bandits", "comments": "8 pages", "journal-ref": "In proceedings of the 2020 IEEE Conference on Games (CoG) (pp.\n  312-319)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores multi-armed bandit (MAB) strategies in very short horizon\nscenarios, i.e., when the bandit strategy is only allowed very few interactions\nwith the environment. This is an understudied setting in the MAB literature\nwith many applications in the context of games, such as player modeling.\nSpecifically, we pursue three different ideas. First, we explore the use of\nregression oracles, which replace the simple average used in strategies such as\nepsilon-greedy with linear regression models. Second, we examine different\nexploration patterns such as forced exploration phases. Finally, we introduce a\nnew variant of the UCB1 strategy called UCBT that has interesting properties\nand no tunable parameters. We present experimental results in a domain\nmotivated by exergames, where the goal is to maximize a player's daily steps.\nOur results show that the combination of epsilon-greedy or epsilon-decreasing\nwith regression oracles outperforms all other tested strategies in the short\nhorizon setting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 04:58:44 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gray", "Robert C.", ""], ["Zhu", "Jichen", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2102.05264", "submitter": "Santiago Ontanon", "authors": "Robert C. Gray, Jichen Zhu, Dannielle Arigo, Evan Forman and Santiago\n  Onta\\~n\\'on", "title": "Player Modeling via Multi-Armed Bandits", "comments": null, "journal-ref": "In Proceedings of the International Conference on the Foundations\n  of Digital Games (FDG 2020)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on building personalized player models solely from player\nbehavior in the context of adaptive games. We present two main contributions:\nThe first is a novel approach to player modeling based on multi-armed bandits\n(MABs). This approach addresses, at the same time and in a principled way, both\nthe problem of collecting data to model the characteristics of interest for the\ncurrent player and the problem of adapting the interactive experience based on\nthis model. Second, we present an approach to evaluating and fine-tuning these\nalgorithms prior to generating data in a user study. This is an important\nproblem, because conducting user studies is an expensive and labor-intensive\nprocess; therefore, an ability to evaluate the algorithms beforehand can save a\nsignificant amount of resources. We evaluate our approach in the context of\nmodeling players' social comparison orientation (SCO) and present empirical\nresults from both simulations and real players.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 05:04:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gray", "Robert C.", ""], ["Zhu", "Jichen", ""], ["Arigo", "Dannielle", ""], ["Forman", "Evan", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2102.05271", "submitter": "Vinay Joshi", "authors": "Vinay Joshi, Wangxin He, Jae-sun Seo and Bipin Rajendran", "title": "Hybrid In-memory Computing Architecture for the Training of Deep Neural\n  Networks", "comments": "Accepted at ISCAS 2021 for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost involved in training deep neural networks (DNNs) on von-Neumann\narchitectures has motivated the development of novel solutions for efficient\nDNN training accelerators. We propose a hybrid in-memory computing (HIC)\narchitecture for the training of DNNs on hardware accelerators that results in\nmemory-efficient inference and outperforms baseline software accuracy in\nbenchmark tasks. We introduce a weight representation technique that exploits\nboth binary and multi-level phase-change memory (PCM) devices, and this leads\nto a memory-efficient inference accelerator. Unlike previous in-memory\ncomputing-based implementations, we use a low precision weight update\naccumulator that results in more memory savings. We trained the ResNet-32\nnetwork to classify CIFAR-10 images using HIC. For a comparable model size,\nHIC-based training outperforms baseline network, trained in floating-point\n32-bit (FP32) precision, by leveraging appropriate network width multiplier.\nFurthermore, we observe that HIC-based training results in about 50% less\ninference model size to achieve baseline comparable accuracy. We also show that\nthe temporal drift in PCM devices has a negligible effect on post-training\ninference accuracy for extended periods (year). Finally, our simulations\nindicate HIC-based training naturally ensures that the number of write-erase\ncycles seen by the devices is a small fraction of the endurance limit of PCM,\ndemonstrating the feasibility of this architecture for achieving hardware\nplatforms that can learn in the field.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 05:26:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Joshi", "Vinay", ""], ["He", "Wangxin", ""], ["Seo", "Jae-sun", ""], ["Rajendran", "Bipin", ""]]}, {"id": "2102.05284", "submitter": "Liyu Chen", "authors": "Liyu Chen and Haipeng Luo", "title": "Finding the Stochastic Shortest Path with Low Regret: The Adversarial\n  Cost and Unknown Transition Case", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make significant progress toward the stochastic shortest path problem with\nadversarial costs and unknown transition. Specifically, we develop algorithms\nthat achieve $\\widetilde{O}(\\sqrt{S^2ADT_\\star K})$ regret for the\nfull-information setting and $\\widetilde{O}(\\sqrt{S^3A^2DT_\\star K})$ regret\nfor the bandit feedback setting, where $D$ is the diameter, $T_\\star$ is the\nexpected hitting time of the optimal policy, $S$ is the number of states, $A$\nis the number of actions, and $K$ is the number of episodes. Our work strictly\nimproves (Rosenberg and Mansour, 2020) in the full information setting, extends\n(Chen et al., 2020) from known transition to unknown transition, and is also\nthe first to consider the most challenging combination: bandit feedback with\nadversarial costs and unknown transition. To remedy the gap between our upper\nbounds and the current best lower bounds constructed via a stochastically\noblivious adversary, we also propose algorithms with near-optimal regret for\nthis special case.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 06:33:04 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 07:13:54 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chen", "Liyu", ""], ["Luo", "Haipeng", ""]]}, {"id": "2102.05291", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Yiwen Song, Yang Liu", "title": "Clusterability as an Alternative to Anchor Points When Learning with\n  Noisy Labels", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The label noise transition matrix, characterizing the probabilities of a\ntraining instance being wrongly annotated, is crucial to designing popular\nsolutions to learning with noisy labels. Existing works heavily rely on finding\n\"anchor points\" or their approximates, defined as instances belonging to a\nparticular class almost surely. Nonetheless, finding anchor points remains a\nnon-trivial task, and the estimation accuracy is also often throttled by the\nnumber of available anchor points. In this paper, we propose an alternative\noption to the above task. Our main contribution is the discovery of an\nefficient estimation procedure based on a clusterability condition. We prove\nthat with clusterable representations of features, using up to third-order\nconsensuses of noisy labels among neighbor representations is sufficient to\nestimate a unique transition matrix. Compared with methods using anchor points,\nour approach uses substantially more instances and benefits from a much better\nsample complexity. We demonstrate the estimation accuracy and advantages of our\nestimates using both synthetic noisy labels (on CIFAR-10/100) and real\nhuman-level noisy labels (on Clothing1M and our self-collected human-annotated\nCIFAR-10). Our code and human-level noisy CIFAR-10 labels are available at\nhttps://github.com/UCSC-REAL/HOC.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:22:56 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 21:33:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Song", "Yiwen", ""], ["Liu", "Yang", ""]]}, {"id": "2102.05299", "submitter": "Ji\\v{r}\\'i Filipovi\\v{c}", "authors": "Ji\\v{r}\\'i Filipovi\\v{c} and Jana Hozzov\\'a and Amin Nezarat and\n  Jaroslav O\\v{l}ha and Filip Petrovi\\v{c}", "title": "Searching CUDA code autotuning spaces with hardware performance\n  counters: data from benchmarks running on various GPU architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed several autotuning benchmarks in CUDA that take into\naccount performance-relevant source-code parameters and reach near\npeak-performance on various GPU architectures. We have used them during the\ndevelopment and evaluation of a novel search method for tuning space proposed\nin [1]. With our framework Kernel Tuning Toolkit, freely available at Github,\nwe measured computation times and hardware performance counters on several GPUs\nfor the complete tuning spaces of five benchmarks. These data, which we provide\nhere, might benefit research of search algorithms for the tuning spaces of GPU\ncodes or research of relation between applied code optimization, hardware\nperformance counters, and GPU kernels' performance.\n  Moreover, we describe the scripts we used for robust evaluation of our\nsearcher and comparison to others in detail. In particular, the script that\nsimulates the tuning, i.e., replaces time-demanding compiling and executing the\ntuned kernels with a quick reading of the computation time from our measured\ndata, makes it possible to inspect the convergence of tuning search over a\nlarge number of experiments. These scripts, freely available with our other\ncodes, make it easier to experiment with search algorithms and compare them in\na robust way.\n  During our research, we generated models for predicting values of performance\ncounters from values of tuning parameters of our benchmarks. Here, we provide\nthe models themselves and describe the scripts we implemented for their\ntraining. These data might benefit researchers who want to reproduce or build\non our research.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:51:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Filipovi\u010d", "Ji\u0159\u00ed", ""], ["Hozzov\u00e1", "Jana", ""], ["Nezarat", "Amin", ""], ["O\u013eha", "Jaroslav", ""], ["Petrovi\u010d", "Filip", ""]]}, {"id": "2102.05311", "submitter": "Hanshu Yan", "authors": "Hanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan,\n  Masashi Sugiyama", "title": "CIFS: Improving Adversarial Robustness of CNNs via Channel-wise\n  Importance-based Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the adversarial robustness of CNNs from the perspective of\nchannel-wise activations. By comparing \\textit{non-robust} (normally trained)\nand \\textit{robustified} (adversarially trained) models, we observe that\nadversarial training (AT) robustifies CNNs by aligning the channel-wise\nactivations of adversarial data with those of their natural counterparts.\nHowever, the channels that are \\textit{negatively-relevant} (NR) to predictions\nare still over-activated when processing adversarial data. Besides, we also\nobserve that AT does not result in similar robustness for all classes. For the\nrobust classes, channels with larger activation magnitudes are usually more\n\\textit{positively-relevant} (PR) to predictions, but this alignment does not\nhold for the non-robust classes. Given these observations, we hypothesize that\nsuppressing NR channels and aligning PR ones with their relevances further\nenhances the robustness of CNNs under AT. To examine this hypothesis, we\nintroduce a novel mechanism, i.e., \\underline{C}hannel-wise\n\\underline{I}mportance-based \\underline{F}eature \\underline{S}election (CIFS).\nThe CIFS manipulates channels' activations of certain layers by generating\nnon-negative multipliers to these channels based on their relevances to\npredictions. Extensive experiments on benchmark datasets including CIFAR10 and\nSVHN clearly verify the hypothesis and CIFS's effectiveness of robustifying\nCNNs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 08:16:43 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 02:34:34 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Yan", "Hanshu", ""], ["Zhang", "Jingfeng", ""], ["Niu", "Gang", ""], ["Feng", "Jiashi", ""], ["Tan", "Vincent Y. F.", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2102.05331", "submitter": "Martin Schmitt", "authors": "Martin Schmitt and Hinrich Sch\\\"utze", "title": "Language Models for Lexical Inference in Context", "comments": "Final version of EACL 2021 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lexical inference in context (LIiC) is the task of recognizing textual\nentailment between two very similar sentences, i.e., sentences that only differ\nin one expression. It can therefore be seen as a variant of the natural\nlanguage inference task that is focused on lexical semantics. We formulate and\nevaluate the first approaches based on pretrained language models (LMs) for\nthis task: (i) a few-shot NLI classifier, (ii) a relation induction approach\nbased on handcrafted patterns expressing the semantics of lexical inference,\nand (iii) a variant of (ii) with patterns that were automatically extracted\nfrom a corpus. All our approaches outperform the previous state of the art,\nshowing the potential of pretrained LMs for LIiC. In an extensive analysis, we\ninvestigate factors of success and failure of our three approaches.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 09:08:22 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 08:33:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2102.05334", "submitter": "Yael Mathov", "authors": "Yael Mathov, Lior Rokach, Yuval Elovici", "title": "Enhancing Real-World Adversarial Patches with 3D Modeling Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although many studies have examined adversarial examples in the real world,\nmost of them relied on 2D photos of the attack scene; thus, the attacks\nproposed cannot address realistic environments with 3D objects or varied\nconditions. Studies that use 3D objects are limited, and in many cases, the\nreal-world evaluation process is not replicable by other researchers,\npreventing others from reproducing the results. In this study, we present a\nframework that crafts an adversarial patch for an existing real-world scene.\nOur approach uses a 3D digital approximation of the scene as a simulation of\nthe real world. With the ability to add and manipulate any element in the\ndigital scene, our framework enables the attacker to improve the patch's\nrobustness in real-world settings. We use the framework to create a patch for\nan everyday scene and evaluate its performance using a novel evaluation process\nthat ensures that our results are reproducible in both the digital space and\nthe real world. Our evaluation results show that the framework can generate\nadversarial patches that are robust to different settings in the real world.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 09:16:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mathov", "Yael", ""], ["Rokach", "Lior", ""], ["Elovici", "Yuval", ""]]}, {"id": "2102.05363", "submitter": "Liwei Wang", "authors": "Bohang Zhang, Tianle Cai, Zhou Lu, Di He, Liwei Wang", "title": "Towards Certifying L-infinity Robustness using Neural Networks with\n  L-inf-dist Neurons", "comments": "Appearing at International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that standard neural networks, even with a high\nclassification accuracy, are vulnerable to small $\\ell_\\infty$-norm bounded\nadversarial perturbations. Although many attempts have been made, most previous\nworks either can only provide empirical verification of the defense to a\nparticular attack method, or can only develop a certified guarantee of the\nmodel robustness in limited scenarios. In this paper, we seek for a new\napproach to develop a theoretically principled neural network that inherently\nresists $\\ell_\\infty$ perturbations. In particular, we design a novel neuron\nthat uses $\\ell_\\infty$-distance as its basic operation (which we call\n$\\ell_\\infty$-dist neuron), and show that any neural network constructed with\n$\\ell_\\infty$-dist neurons (called $\\ell_{\\infty}$-dist net) is naturally a\n1-Lipschitz function with respect to $\\ell_\\infty$-norm. This directly provides\na rigorous guarantee of the certified robustness based on the margin of\nprediction outputs. We then prove that such networks have enough expressive\npower to approximate any 1-Lipschitz function with robust generalization\nguarantee. We further provide a holistic training strategy that can greatly\nalleviate optimization difficulties. Experimental results show that using\n$\\ell_{\\infty}$-dist nets as basic building blocks, we consistently achieve\nstate-of-the-art performance on commonly used datasets: 93.09% certified\naccuracy on MNIST ($\\epsilon=0.3$), 35.42% on CIFAR-10 ($\\epsilon=8/255$) and\n16.31% on TinyImageNet ($\\epsilon=1/255$).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:03:58 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 04:57:54 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 08:01:16 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 10:40:48 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Bohang", ""], ["Cai", "Tianle", ""], ["Lu", "Zhou", ""], ["He", "Di", ""], ["Wang", "Liwei", ""]]}, {"id": "2102.05406", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei, Haipeng Luo", "title": "Non-stationary Reinforcement Learning without Prior Knowledge: An\n  Optimal Black-box Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a black-box reduction that turns a certain reinforcement learning\nalgorithm with optimal regret in a (near-)stationary environment into another\nalgorithm with optimal dynamic regret in a non-stationary environment,\nimportantly without any prior knowledge on the degree of non-stationarity. By\nplugging different algorithms into our black-box, we provide a list of examples\nshowing that our approach not only recovers recent results for (contextual)\nmulti-armed bandits achieved by very specialized algorithms, but also\nsignificantly improves the state of the art for (generalized) linear bandits,\nepisodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most\ncases our algorithm achieves the optimal dynamic regret\n$\\widetilde{\\mathcal{O}}(\\min\\{\\sqrt{LT}, \\Delta^{1/3}T^{2/3}\\})$ where $T$ is\nthe number of rounds and $L$ and $\\Delta$ are the number and amount of changes\nof the world respectively, while previous works only obtain suboptimal bounds\nand/or require the knowledge of $L$ and $\\Delta$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 12:43:31 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:57:04 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Luo", "Haipeng", ""]]}, {"id": "2102.05424", "submitter": "Jintai Chen", "authors": "Jintai Chen, Bohan Yu, Biwen Lei, Ruiwei Feng, Danny Z. Chen, Jian Wu", "title": "Doctor Imitator: A Graph-based Bone Age Assessment Framework Using Hand\n  Radiographs", "comments": null, "journal-ref": "International Conference on Medical Image Computing and\n  Computer-Assisted Intervention (2020)", "doi": "10.1007/978-3-030-59725-2_74", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bone age assessment is challenging in clinical practice due to the\ncomplicated bone age assessment process. Current automatic bone age assessment\nmethods were designed with rare consideration of the diagnostic logistics and\nthus may yield certain uninterpretable hidden states and outputs. Consequently,\ndoctors can find it hard to cooperate with such models harmoniously because it\nis difficult to check the correctness of the model predictions. In this work,\nwe propose a new graph-based deep learning framework for bone age assessment\nwith hand radiographs, called Doctor Imitator (DI). The architecture of DI is\ndesigned to learn the diagnostic logistics of doctors using the scoring methods\n(e.g., the Tanner-Whitehouse method) for bone age assessment. Specifically, the\nconvolutions of DI capture the local features of the anatomical regions of\ninterest (ROIs) on hand radiographs and predict the ROI scores by our proposed\nAnatomy-based Group Convolution, summing up for bone age prediction. Besides,\nwe develop a novel Dual Graph-based Attention module to compute\npatient-specific attention for ROI features and context attention for ROI\nscores. As far as we know, DI is the first automatic bone age assessment\nframework following the scoring methods without fully supervised hand\nradiographs. Experiments on hand radiographs with only bone age supervision\nverify that DI can achieve excellent performance with sparse parameters and\nprovide more interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 13:45:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Chen", "Jintai", ""], ["Yu", "Bohan", ""], ["Lei", "Biwen", ""], ["Feng", "Ruiwei", ""], ["Chen", "Danny Z.", ""], ["Wu", "Jian", ""]]}, {"id": "2102.05439", "submitter": "Latika Tamrakar", "authors": "Latika Tamrakar, Dr.Padmavati Shrivastava, Dr. S. M. Ghosh", "title": "Student sentiment Analysis Using Classification With Feature Extraction\n  Techniques", "comments": "need to rework in this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technical growths have empowered, numerous revolutions in the educational\nsystem by acquainting with technology into the classroom and by elevating the\nlearning experience. Nowadays Web-based learning is getting much popularity.\nThis paper describes the web-based learning and their effectiveness towards\nstudents. One of the prime factors in education or learning system is feedback;\nit is beneficial to learning if it must be used effectively. In this paper, we\nworked on how machine learning techniques like Logistic Regression (LR),\nSupport Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT) can be\napplied over Web-based learning, emphasis given on sentiment present in the\nfeedback students. We also work on two types of Feature Extraction Technique\n(FETs) namely Count Vector (CVr) or Bag of Words) (BoW) and Term Frequency and\nInverse Document Frequency (TF-IDF) Vector. In the research study, it is our\ngoal for our proposed LR, SVM, NB, and DT models to classify the presence of\nStudent Feedback Dataset (SFB) with improved accuracy with cleaned dataset and\nfeature extraction techniques. The SFB is one of the significant concerns among\nthe student sentimental analysis.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 18:48:06 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 07:35:32 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Tamrakar", "Latika", ""], ["Shrivastava", "Dr. Padmavati", ""], ["Ghosh", "Dr. S. M.", ""]]}, {"id": "2102.05447", "submitter": "Jianzhu Guo", "authors": "Xiaqing Xu, Qiang Meng, Yunxiao Qin, Jianzhu Guo, Chenxu Zhao, Feng\n  Zhou, and Zhen Lei", "title": "Searching for Alignment in Face Recognition", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard pipeline of current face recognition frameworks consists of four\nindividual steps: locating a face with a rough bounding box and several\nfiducial landmarks, aligning the face image using a pre-defined template,\nextracting representations and comparing. Among them, face detection, landmark\ndetection and representation learning have long been studied and a lot of works\nhave been proposed. As an essential step with a significant impact on\nrecognition performance, the alignment step has attracted little attention. In\nthis paper, we first explore and highlight the effects of different alignment\ntemplates on face recognition. Then, for the first time, we try to search for\nthe optimal template automatically. We construct a well-defined searching space\nby decomposing the template searching into the crop size and vertical shift,\nand propose an efficient method Face Alignment Policy Search (FAPS). Besides, a\nwell-designed benchmark is proposed to evaluate the searched policy.\nExperiments on our proposed benchmark validate the effectiveness of our method\nto improve face recognition performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:09:16 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 15:03:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Xu", "Xiaqing", ""], ["Meng", "Qiang", ""], ["Qin", "Yunxiao", ""], ["Guo", "Jianzhu", ""], ["Zhao", "Chenxu", ""], ["Zhou", "Feng", ""], ["Lei", "Zhen", ""]]}, {"id": "2102.05449", "submitter": "Tiansheng Huang", "authors": "Tiansheng Huang, Weiwei Lin, Ying Li, Xiumin Wang, Qingbo Wu, Rui Li,\n  Ching-Hsien Hsu, and Albert Y. Zomaya", "title": "Adaptive Processor Frequency Adjustment for Mobile Edge Computing with\n  Intermittent Energy Supply", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With astonishing speed, bandwidth, and scale, Mobile Edge Computing (MEC) has\nplayed an increasingly important role in the next generation of connectivity\nand service delivery. Yet, along with the massive deployment of MEC servers,\nthe ensuing energy issue is now on an increasingly urgent agenda. In the\ncurrent context, the large scale deployment of renewable-energy-supplied MEC\nservers is perhaps the most promising solution for the incoming energy issue.\nNonetheless, as a result of the intermittent nature of their power sources,\nthese special design MEC server must be more cautious about their energy usage,\nin a bid to maintain their service sustainability as well as service standard.\nTargeting optimization on a single-server MEC scenario, we in this paper\npropose NAFA, an adaptive processor frequency adjustment solution, to enable an\neffective plan of the server's energy usage. By learning from the historical\ndata revealing request arrival and energy harvest pattern, the deep\nreinforcement learning-based solution is capable of making intelligent\nschedules on the server's processor frequency, so as to strike a good balance\nbetween service sustainability and service quality. The superior performance of\nNAFA is substantiated by real-data-based experiments, wherein NAFA demonstrates\nup to 20% increase in average request acceptance ratio and up to 50% reduction\nin average request processing time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:12:10 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 14:15:37 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Huang", "Tiansheng", ""], ["Lin", "Weiwei", ""], ["Li", "Ying", ""], ["Wang", "Xiumin", ""], ["Wu", "Qingbo", ""], ["Li", "Rui", ""], ["Hsu", "Ching-Hsien", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2102.05451", "submitter": "Yaron Strauch", "authors": "Yaron Strauch (University of Southampton), Jo Grundy (University of\n  Southampton)", "title": "Two Novel Performance Improvements for Evolving CNN Topologies", "comments": "Accepted to AAAI-21 Workshop W17: Learning Network Architecture\n  during Training. 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for\nthe processing of images. However the configuration and training of these\nnetworks is a complex task requiring deep domain knowledge, experience and much\ntrial and error. Using genetic algorithms, competitive CNN topologies for image\nrecognition can be produced for any specific purpose, however in previous work\nthis has come at high computational cost. In this work two novel approaches are\npresented to the utilisation of these algorithms, effective in reducing\ncomplexity and training time by nearly 20%. This is accomplished via\nregularisation directly on training time, and the use of partial training to\nenable early ranking of individual architectures. Both approaches are validated\non the benchmark CIFAR10 data set, and maintain accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:17:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Strauch", "Yaron", "", "University of Southampton"], ["Grundy", "Jo", "", "University of\n  Southampton"]]}, {"id": "2102.05456", "submitter": "Leo Laugier", "authors": "Leo Laugier, John Pavlopoulos, Jeffrey Sorensen, Lucas Dixon", "title": "Civil Rephrases Of Toxic Texts With Self-Supervised Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Platforms that support online commentary, from social networks to news sites,\nare increasingly leveraging machine learning to assist their moderation\nefforts. But this process does not typically provide feedback to the author\nthat would help them contribute according to the community guidelines. This is\nprohibitively time-consuming for human moderators to do, and computational\napproaches are still nascent. This work focuses on models that can help suggest\nrephrasings of toxic comments in a more civil manner. Inspired by recent\nprogress in unpaired sequence-to-sequence tasks, a self-supervised learning\nmodel is introduced, called CAE-T5. CAE-T5 employs a pre-trained text-to-text\ntransformer, which is fine tuned with a denoising and cyclic auto-encoder loss.\nExperimenting with the largest toxicity detection dataset to date (Civil\nComments) our model generates sentences that are more fluent and better at\npreserving the initial content compared to earlier text style transfer systems\nwhich we compare with using several scoring systems and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:27:52 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:11:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Laugier", "Leo", ""], ["Pavlopoulos", "John", ""], ["Sorensen", "Jeffrey", ""], ["Dixon", "Lucas", ""]]}, {"id": "2102.05460", "submitter": "Juliana Ferreira J", "authors": "Juliana Jansen Ferreira and Mateus Monteiro", "title": "The human-AI relationship in decision-making: AI explanation to support\n  people on justifying their decisions", "comments": "Pre-print of paper accepted in Workshop on Transparency And\n  Explanations In Smart Systems (TEXSS) held in conjunction with ACM\n  Intelligent User Interfaces (IUI) (April 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The explanation dimension of Artificial Intelligence (AI) based system has\nbeen a hot topic for the past years. Different communities have raised concerns\nabout the increasing presence of AI in people's everyday tasks and how it can\naffect people's lives. There is a lot of research addressing the\ninterpretability and transparency concepts of explainable AI (XAI), which are\nusually related to algorithms and Machine Learning (ML) models. But in\ndecision-making scenarios, people need more awareness of how AI works and its\noutcomes to build a relationship with that system. Decision-makers usually need\nto justify their decision to others in different domains. If that decision is\nsomehow based on or influenced by an AI-system outcome, the explanation about\nhow the AI reached that result is key to building trust between AI and humans\nin decision-making scenarios. In this position paper, we discuss the role of\nXAI in decision-making scenarios, our vision of Decision-Making with AI-system\nin the loop, and explore one case from the literature about how XAI can impact\npeople justifying their decisions, considering the importance of building the\nhuman-AI relationship for those scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:28:34 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 14:27:15 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ferreira", "Juliana Jansen", ""], ["Monteiro", "Mateus", ""]]}, {"id": "2102.05474", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Junlong Li, Hai Zhao", "title": "Multi-turn Dialogue Reading Comprehension with Pivot Turns and Knowledge", "comments": "The early version accepted by IEEE/ACM Transactions on Audio, Speech,\n  and Language Processing (TASLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-turn dialogue reading comprehension aims to teach machines to read\ndialogue contexts and solve tasks such as response selection and answering\nquestions. The major challenges involve noisy history contexts and especial\nprerequisites of commonsense knowledge that is unseen in the given material.\nExisting works mainly focus on context and response matching approaches. This\nwork thus makes the first attempt to tackle the above two challenges by\nextracting substantially important turns as pivot utterances and utilizing\nexternal knowledge to enhance the representation of context. We propose a\npivot-oriented deep selection model (PoDS) on top of the Transformer-based\nlanguage models for dialogue comprehension. In detail, our model first picks\nout the pivot utterances from the conversation history according to the\nsemantic matching with the candidate response or question, if any. Besides,\nknowledge items related to the dialogue context are extracted from a knowledge\ngraph as external knowledge. Then, the pivot utterances and the external\nknowledge are combined with a well-designed mechanism for refining predictions.\nExperimental results on four dialogue comprehension benchmark tasks show that\nour proposed model achieves great improvements on baselines. A series of\nempirical comparisons are conducted to show how our selection strategies and\nthe extra knowledge injection influence the results.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:00:12 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Junlong", ""], ["Zhao", "Hai", ""]]}, {"id": "2102.05485", "submitter": "Yufeng Zhang", "authors": "Yufeng Zhang, Wanwei Liu, Zhenbang Chen, Kenli Li, Ji Wang", "title": "On the Properties of Kullback-Leibler Divergence Between Gaussians", "comments": "arXiv admin note: text overlap with arXiv:2002.03328", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kullback-Leibler (KL) divergence is one of the most important divergence\nmeasures between probability distributions. In this paper, we investigate the\nproperties of KL divergence between Gaussians. Firstly, for any two\n$n$-dimensional Gaussians $\\mathcal{N}_1$ and $\\mathcal{N}_2$, we find the\nsupremum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when\n$KL(\\mathcal{N}_2||\\mathcal{N}_1)\\leq \\epsilon$ for $\\epsilon>0$. This reveals\nthe approximate symmetry of small KL divergence between Gaussians. We also find\nthe infimum of $KL(\\mathcal{N}_1||\\mathcal{N}_2)$ when\n$KL(\\mathcal{N}_2||\\mathcal{N}_1)\\geq M$ for $M>0$. Secondly, for any three\n$n$-dimensional Gaussians $\\mathcal{N}_1, \\mathcal{N}_2$ and $\\mathcal{N}_3$,\nwe find a bound of $KL(\\mathcal{N}_1||\\mathcal{N}_3)$ if\n$KL(\\mathcal{N}_1||\\mathcal{N}_2)$ and $KL(\\mathcal{N}_2||\\mathcal{N}_3)$ are\nbounded. This reveals that the KL divergence between Gaussians follows a\nrelaxed triangle inequality. Importantly, all the bounds in the theorems\npresented in this paper are independent of the dimension $n$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:21:53 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 04:12:30 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 10:39:20 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhang", "Yufeng", ""], ["Liu", "Wanwei", ""], ["Chen", "Zhenbang", ""], ["Li", "Kenli", ""], ["Wang", "Ji", ""]]}, {"id": "2102.05501", "submitter": "Yanis Bahroun", "authors": "Yanis Bahroun and Dmitri B. Chklovskii", "title": "A Neural Network with Local Learning Rules for Minor Subspace Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of neuromorphic hardware and modeling of biological neural\nnetworks requires algorithms with local learning rules. Artificial neural\nnetworks using local learning rules to perform principal subspace analysis\n(PSA) and clustering have recently been derived from principled objective\nfunctions. However, no biologically plausible networks exist for minor subspace\nanalysis (MSA), a fundamental signal processing task. MSA extracts the\nlowest-variance subspace of the input signal covariance matrix. Here, we\nintroduce a novel similarity matching objective for extracting the minor\nsubspace, Minor Subspace Similarity Matching (MSSM). Moreover, we derive an\nadaptive MSSM algorithm that naturally maps onto a novel neural network with\nlocal learning rules and gives numerical results showing that our method\nconverges at a competitive rate.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:44:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahroun", "Yanis", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2102.05503", "submitter": "Yanis Bahroun", "authors": "Yanis Bahroun and Anirvan M. Sengupta and Dmitri B. Chklovskii", "title": "A Similarity-preserving Neural Network Trained on Transformed Images\n  Recapitulates Salient Features of the Fly Motion Detection Circuit", "comments": "Body and supplementary materials of NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to detect content-independent transformations from data is one of\nthe central problems in biological and artificial intelligence. An example of\nsuch problem is unsupervised learning of a visual motion detector from pairs of\nconsecutive video frames. Rao and Ruderman formulated this problem in terms of\nlearning infinitesimal transformation operators (Lie group generators) via\nminimizing image reconstruction error. Unfortunately, it is difficult to map\ntheir model onto a biologically plausible neural network (NN) with local\nlearning rules. Here we propose a biologically plausible model of motion\ndetection. We also adopt the transformation-operator approach but, instead of\nreconstruction-error minimization, start with a similarity-preserving objective\nfunction. An online algorithm that optimizes such an objective function\nnaturally maps onto an NN with biologically plausible learning rules. The\ntrained NN recapitulates major features of the well-studied motion detector in\nthe fly. In particular, it is consistent with the experimental observation that\nlocal motion detectors combine information from at least three adjacent pixels,\nsomething that contradicts the celebrated Hassenstein-Reichardt model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:45:40 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahroun", "Yanis", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2102.05536", "submitter": "Amir Yehudayoff", "authors": "Gal Yehuda and Amir Yehudayoff", "title": "Slicing the hypercube is not easy", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We prove that at least $\\Omega(n^{0.51})$ hyperplanes are needed to slice all\nedges of the $n$-dimensional hypercube. We provide a couple of applications:\nlower bounds on the computational complexity of parity, and a lower bound on\nthe cover number of the hypercube by skew hyperplanes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:24:37 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 11:17:04 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Yehuda", "Gal", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "2102.05547", "submitter": "Jelle Piepenbrock", "authors": "Jelle Piepenbrock, Tom Heskes, Mikol\\'a\\v{s} Janota, Josef Urban", "title": "Learning Equational Theorem Proving", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Stratified Shortest Solution Imitation Learning (3SIL) to learn\nequational theorem proving in a deep reinforcement learning (RL) setting. The\nself-trained models achieve state-of-the-art performance in proving problems\ngenerated by one of the top open conjectures in quasigroup theory, the Abelian\nInner Mapping (AIM) Conjecture. To develop the methods, we first use two\nsimpler arithmetic rewriting tasks that share tree-structured proof states and\nsparse rewards with the AIM problems. On these tasks, 3SIL is shown to\nsignificantly outperform several established RL and imitation learning methods.\nThe final system is then evaluated in a standalone and cooperative mode on the\nAIM problems. The standalone 3SIL-trained system proves in 60 seconds more\ntheorems (70.2%) than the complex, hand-engineered Waldmeister system (65.5%).\nIn the cooperative mode, the final system is combined with the Prover9 system,\nproving in 2 seconds what standalone Prover9 proves in 60 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:33:07 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Piepenbrock", "Jelle", ""], ["Heskes", "Tom", ""], ["Janota", "Mikol\u00e1\u0161", ""], ["Urban", "Josef", ""]]}, {"id": "2102.05571", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Sharmishtha Dutta, Ryan Christian, Jared Gridley,\n  Mohammad Zaki, Alex Gittens, Charu Aggarwal", "title": "Predicting malware threat intelligence using KGs", "comments": "14 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.12526.54083", "report-no": null, "categories": "cs.CR cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large amounts of threat intelligence information about malware attacks are\navailable in disparate, typically unstructured, formats. Knowledge graphs can\ncapture this information and its context using RDF triples represented by\nentities and relations. Sparse or inaccurate threat information, however, leads\nto challenges such as incomplete or erroneous triples. Generic information\nextraction (IE) models used to populate the knowledge graph cannot fully\nguarantee domain-specific context. This paper proposes a system to generate a\nMalware Knowledge Graph called MalKG, the first open-source automated knowledge\ngraph for malware threat intelligence. MalKG dataset (MT40K\\footnote{ Anonymous\nGitHub link: https://github.com/malkg-researcher/MalKG}) contains approximately\n40,000 triples generated from 27,354 unique entities and 34 relations. For\nground truth, we manually curate a knowledge graph called MT3K, with 3,027\ntriples generated from 5,741 unique entities and 22 relations. We demonstrate\nthe intelligence prediction of MalKG using two use cases. Predicting malware\nthreat information using the benchmark model achieves 80.4 for the hits@10\nmetric (predicts the top 10 options for an information class), and 0.75 for the\nMRR (mean reciprocal rank). We also propose an automated, contextual framework\nfor information extraction, both manually and automatically, at the sentence\nlevel from 1,100 malware threat reports and from the common vulnerabilities and\nexposures (CVE) database.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:08:09 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:03:10 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 19:36:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Dutta", "Sharmishtha", ""], ["Christian", "Ryan", ""], ["Gridley", "Jared", ""], ["Zaki", "Mohammad", ""], ["Gittens", "Alex", ""], ["Aggarwal", "Charu", ""]]}, {"id": "2102.05582", "submitter": "Brian McClannahan", "authors": "Brian McClannahan, Cucong Zhong, Guanghui Wang", "title": "Classification of Long Noncoding RNA Elements Using Deep Convolutional\n  Neural Networks and Siamese Networks", "comments": "arXiv admin note: text overlap with arXiv:2008.10580", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the last decade, the discovery of noncoding RNA(ncRNA) has exploded.\nClassifying these ncRNA is critical todetermining their function. This thesis\nproposes a new methodemploying deep convolutional neural networks (CNNs) to\nclassifyncRNA sequences. To this end, this paper first proposes anefficient\napproach to convert the RNA sequences into imagescharacterizing their\nbase-pairing probability. As a result, clas-sifying RNA sequences is converted\nto an image classificationproblem that can be efficiently solved by available\nCNN-basedclassification models. This research also considers the\nfoldingpotential of the ncRNAs in addition to their primary sequence.Based on\nthe proposed approach, a benchmark image classifi-cation dataset is generated\nfrom the RFAM database of ncRNAsequences. In addition, three classical CNN\nmodels and threeSiamese network models have been implemented and comparedto\ndemonstrate the superior performance and efficiency of theproposed approach.\nExtensive experimental results show thegreat potential of using deep learning\napproaches for RNAclassification.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:26:38 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["McClannahan", "Brian", ""], ["Zhong", "Cucong", ""], ["Wang", "Guanghui", ""]]}, {"id": "2102.05600", "submitter": "Nidhi Rastogi", "authors": "Nidhi Rastogi, Qicheng Ma", "title": "DANTE: Predicting Insider Threat using LSTM on system logs", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Insider threat is one of the most pernicious threat vectors to information\nand communication technologies (ICT)across the world due to the elevated level\nof trust and access that an insider is afforded. This type of threat can stem\nfrom both malicious users with a motive as well as negligent users who\ninadvertently reveal details about trade secrets, company information, or even\naccess information to malignant players. In this paper, we propose a novel\napproach that uses system logs to detect insider behavior using a special\nrecurrent neural network (RNN) model. Ground truth is established using DANTE\nand used as the baseline for identifying anomalous behavior. For this, system\nlogs are modeled as a natural language sequence and patterns are extracted from\nthese sequences. We create workflows of sequences of actions that follow a\nnatural language logic and control flow. These flows are assigned various\ncategories of behaviors - malignant or benign. Any deviation from these\nsequences indicates the presence of a threat. We further classify threats into\none of the five categories provided in the CERT insider threat dataset. Through\nexperimental evaluation, we show that the proposed model can achieve 99%\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:56:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Rastogi", "Nidhi", ""], ["Ma", "Qicheng", ""]]}, {"id": "2102.05602", "submitter": "Hritik Bansal", "authors": "Hritik Bansal, Gantavya Bhatt, Pankaj Malhotra, Prathosh A.P", "title": "Systematic Generalization in Neural Networks-based Multivariate Time\n  Series Forecasting Models", "comments": "9 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic generalization aims to evaluate reasoning about novel combinations\nfrom known components, an intrinsic property of human cognition. In this work,\nwe study systematic generalization of NNs in forecasting future time series of\ndependent variables in a dynamical system, conditioned on past time series of\ndependent variables, and past and future control variables. We focus on\nsystematic generalization wherein the NN-based forecasting model should perform\nwell on previously unseen combinations or regimes of control variables after\nbeing trained on a limited set of the possible regimes. For NNs to depict such\nout-of-distribution generalization, they should be able to disentangle the\nvarious dependencies between control variables and dependent variables. We\nhypothesize that a modular NN architecture guided by the readily-available\nknowledge of independence of control variables as a potentially useful\ninductive bias to this end. Through extensive empirical evaluation on a toy\ndataset and a simulated electric motor dataset, we show that our proposed\nmodular NN architecture serves as a simple yet highly effective inductive bias\nthat enabling better forecasting of the dependent variables up to large\nhorizons in contrast to standard NNs, and indeed capture the true dependency\nrelations between the dependent and the control variables.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:00:45 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 16:11:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bansal", "Hritik", ""], ["Bhatt", "Gantavya", ""], ["Malhotra", "Pankaj", ""], ["P", "Prathosh A.", ""]]}, {"id": "2102.05623", "submitter": "Mark Ibrahim", "authors": "Diane Bouchacourt, Mark Ibrahim, St\\'ephane Deny", "title": "Addressing the Topological Defects of Disentanglement via Distributed\n  Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge in Machine Learning is to learn to disentangle natural\nfactors of variation in data (e.g. object shape vs. pose). A popular approach\nto disentanglement consists in learning to map each of these factors to\ndistinct subspaces of a model's latent representation. However, this approach\nhas shown limited empirical success to date. Here, we show that, for a broad\nfamily of transformations acting on images--encompassing simple affine\ntransformations such as rotations and translations--this approach to\ndisentanglement introduces topological defects (i.e. discontinuities in the\nencoder). Motivated by classical results from group representation theory, we\nstudy an alternative, more flexible approach to disentanglement which relies on\ndistributed latent operators, potentially acting on the entire latent space. We\ntheoretically and empirically demonstrate the effectiveness of this approach to\ndisentangle affine transformations. Our work lays a theoretical foundation for\nthe recent success of a new generation of models using distributed operators\nfor disentanglement.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:34:55 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Ibrahim", "Mark", ""], ["Deny", "St\u00e9phane", ""]]}, {"id": "2102.05646", "submitter": "Bharat Singh", "authors": "Bharat Singh, Mahyar Najibi, Abhishek Sharma and Larry S. Davis", "title": "Scale Normalized Image Pyramids with AutoFocus for Object Detection", "comments": "Accepted in T-PAMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient foveal framework to perform object detection. A scale\nnormalized image pyramid (SNIP) is generated that, like human vision, only\nattends to objects within a fixed size range at different scales. Such a\nrestriction of objects' size during training affords better learning of\nobject-sensitive filters, and therefore, results in better accuracy. However,\nthe use of an image pyramid increases the computational cost. Hence, we propose\nan efficient spatial sub-sampling scheme which only operates on fixed-size\nsub-regions likely to contain objects (as object locations are known during\ntraining). The resulting approach, referred to as Scale Normalized Image\nPyramid with Efficient Resampling or SNIPER, yields up to 3 times speed-up\nduring training. Unfortunately, as object locations are unknown during\ninference, the entire image pyramid still needs processing. To this end, we\nadopt a coarse-to-fine approach, and predict the locations and extent of\nobject-like regions which will be processed in successive scales of the image\npyramid. Intuitively, it's akin to our active human-vision that first skims\nover the field-of-view to spot interesting regions for further processing and\nonly recognizes objects at the right resolution. The resulting algorithm is\nreferred to as AutoFocus and results in a 2.5-5 times speed-up during inference\nwhen used with SNIP.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 18:57:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Singh", "Bharat", ""], ["Najibi", "Mahyar", ""], ["Sharma", "Abhishek", ""], ["Davis", "Larry S.", ""]]}, {"id": "2102.05710", "submitter": "Hong Qian", "authors": "Hong Qian and Yang Yu", "title": "Derivative-Free Reinforcement Learning: A Review", "comments": "This article has been accepted by Frontiers of Computer Science in\n  2020", "journal-ref": null, "doi": "10.1007/s11704-020-0241-4", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is about learning agent models that make the best\nsequential decisions in unknown environments. In an unknown environment, the\nagent needs to explore the environment while exploiting the collected\ninformation, which usually forms a sophisticated problem to solve.\nDerivative-free optimization, meanwhile, is capable of solving sophisticated\nproblems. It commonly uses a sampling-and-updating framework to iteratively\nimprove the solution, where exploration and exploitation are also needed to be\nwell balanced. Therefore, derivative-free optimization deals with a similar\ncore issue as reinforcement learning, and has been introduced in reinforcement\nlearning approaches, under the names of learning classifier systems and\nneuroevolution/evolutionary reinforcement learning. Although such methods have\nbeen developed for decades, recently, derivative-free reinforcement learning\nexhibits attracting increasing attention. However, recent survey on this topic\nis still lacking. In this article, we summarize methods of derivative-free\nreinforcement learning to date, and organize the methods in aspects including\nparameter updating, model selection, exploration, and parallel/distributed\nmethods. Moreover, we discuss some current limitations and possible future\ndirections, hoping that this article could bring more attentions to this topic\nand serve as a catalyst for developing novel and efficient approaches.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:29:22 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Qian", "Hong", ""], ["Yu", "Yang", ""]]}, {"id": "2102.05714", "submitter": "Jinwei Xing", "authors": "Jinwei Xing, Takashi Nagata, Kexin Chen, Xinyun Zou, Emre Neftci,\n  Jeffrey L. Krichmar", "title": "Domain Adaptation In Reinforcement Learning Via Latent Unified State\n  Representation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of deep reinforcement learning (RL), domain\nadaptation remains an open problem. Although the generalization ability of RL\nagents is critical for the real-world applicability of Deep RL, zero-shot\npolicy transfer is still a challenging problem since even minor visual changes\ncould make the trained agent completely fail in the new task. To address this\nissue, we propose a two-stage RL agent that first learns a latent unified state\nrepresentation (LUSR) which is consistent across multiple domains in the first\nstage, and then do RL training in one source domain based on LUSR in the second\nstage. The cross-domain consistency of LUSR allows the policy acquired from the\nsource domain to generalize to other target domains without extra training. We\nfirst demonstrate our approach in variants of CarRacing games with customized\nmanipulations, and then verify it in CARLA, an autonomous driving simulator\nwith more complex and realistic visual observations. Our results show that this\napproach can achieve state-of-the-art domain adaptation performance in related\nRL tasks and outperforms prior approaches based on latent-representation based\nRL and image-to-image translation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:38:14 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Xing", "Jinwei", ""], ["Nagata", "Takashi", ""], ["Chen", "Kexin", ""], ["Zou", "Xinyun", ""], ["Neftci", "Emre", ""], ["Krichmar", "Jeffrey L.", ""]]}, {"id": "2102.05715", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi, Amandeep Singh, Jan Rabaey", "title": "Sparse-Push: Communication- & Energy-Efficient Decentralized Distributed\n  Learning over Directed & Time-Varying Graphs with non-IID Datasets", "comments": "12 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning (DL) systems rely on a centralized computing paradigm\nwhich limits the amount of available training data, increases system latency,\nand adds privacy and security constraints. On-device learning, enabled by\ndecentralized and distributed training of DL models over peer-to-peer\nwirelessly connected edge devices, not only alleviate the above limitations but\nalso enable next-gen applications that need DL models to continuously interact\nand learn from their environment. However, this necessitates the development of\nnovel training algorithms that train DL models over time-varying and directed\npeer-to-peer graph structures while minimizing the amount of communication\nbetween the devices and also being resilient to non-IID data distributions. In\nthis work we propose, Sparse-Push, a communication efficient decentralized\ndistributed training algorithm that supports training over peer-to-peer,\ndirected, and time-varying graph topologies. The proposed algorithm enables\n466x reduction in communication with only 1% degradation in performance when\ntraining various DL models such as ResNet-20 and VGG11 over the CIFAR-10\ndataset. Further, we demonstrate how communication compression can lead to\nsignificant performance degradation in-case of non-IID datasets, and propose\nSkew-Compensated Sparse Push algorithm that recovers this performance drop\nwhile maintaining similar levels of communication compression.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:41:11 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 02:05:24 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Singh", "Amandeep", ""], ["Rabaey", "Jan", ""]]}, {"id": "2102.05756", "submitter": "Jess Hohenstein", "authors": "Jess Hohenstein and Dominic DiFranzo and Rene F. Kizilcec and Zhila\n  Aghajari and Hannah Mieczkowski and Karen Levy and Mor Naaman and Jeff\n  Hancock and Malte Jung", "title": "Artificial intelligence in communication impacts language and social\n  relationships", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) is now widely used to facilitate social\ninteraction, but its impact on social relationships and communication is not\nwell understood. We study the social consequences of one of the most pervasive\nAI applications: algorithmic response suggestions (\"smart replies\"). Two\nrandomized experiments (n = 1036) provide evidence that a commercially-deployed\nAI changes how people interact with and perceive one another in pro-social and\nanti-social ways. We find that using algorithmic responses increases\ncommunication efficiency, use of positive emotional language, and positive\nevaluations by communication partners. However, consistent with common\nassumptions about the negative implications of AI, people are evaluated more\nnegatively if they are suspected to be using algorithmic responses. Thus, even\nthough AI can increase communication efficiency and improve interpersonal\nperceptions, it risks changing users' language production and continues to be\nviewed negatively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 22:05:11 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hohenstein", "Jess", ""], ["DiFranzo", "Dominic", ""], ["Kizilcec", "Rene F.", ""], ["Aghajari", "Zhila", ""], ["Mieczkowski", "Hannah", ""], ["Levy", "Karen", ""], ["Naaman", "Mor", ""], ["Hancock", "Jeff", ""], ["Jung", "Malte", ""]]}, {"id": "2102.05757", "submitter": "Shohreh Shaghaghian Ms", "authors": "Shohreh Shaghaghian, Luna (Yue) Feng, Borna Jafarpour, Nicolai\n  Pogrebnyakov", "title": "Customizing Contextualized Language Models forLegal Document Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Inspired by the inductive transfer learning on computer vision, many efforts\nhave been made to train contextualized language models that boost the\nperformance of natural language processing tasks. These models are mostly\ntrained on large general-domain corpora such as news, books, or\nWikipedia.Although these pre-trained generic language models well perceive the\nsemantic and syntactic essence of a language structure, exploiting them in a\nreal-world domain-specific scenario still needs some practical considerations\nto be taken into account such as token distribution shifts, inference time,\nmemory, and their simultaneous proficiency in multiple tasks. In this paper, we\nfocus on the legal domain and present how different language model strained on\ngeneral-domain corpora can be best customized for multiple legal document\nreviewing tasks. We compare their efficiencies with respect to task\nperformances and present practical considerations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 22:14:15 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Shaghaghian", "Shohreh", "", "Yue"], ["Luna", "", "", "Yue"], ["Feng", "", ""], ["Jafarpour", "Borna", ""], ["Pogrebnyakov", "Nicolai", ""]]}, {"id": "2102.05762", "submitter": "Marc Rigter", "authors": "Marc Rigter, Bruno Lacerda, Nick Hawes", "title": "Risk-Averse Bayes-Adaptive Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address risk-averse Bayesadaptive reinforcement learning. We\npose the problem of optimising the conditional value at risk (CVaR) of the\ntotal return in Bayes-adaptive Markov decision processes (MDPs). We show that a\npolicy optimising CVaR in this setting is risk-averse to both the parametric\nuncertainty due to the prior distribution over MDPs, and the internal\nuncertainty due to the inherent stochasticity of MDPs. We reformulate the\nproblem as a two-player stochastic game and propose an approximate algorithm\nbased on Monte Carlo tree search and Bayesian optimisation. Our experiments\ndemonstrate that our approach significantly outperforms baseline approaches for\nthis problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 22:34:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Rigter", "Marc", ""], ["Lacerda", "Bruno", ""], ["Hawes", "Nick", ""]]}, {"id": "2102.05776", "submitter": "Goran Radanovic", "authors": "Kiarash Banihashem, Adish Singla, Goran Radanovic", "title": "Defense Against Reward Poisoning Attacks in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study defense strategies against reward poisoning attacks in reinforcement\nlearning. As a threat model, we consider attacks that minimally alter rewards\nto make the attacker's target policy uniquely optimal under the poisoned\nrewards, with the optimality gap specified by an attack parameter. Our goal is\nto design agents that are robust against such attacks in terms of the\nworst-case utility w.r.t. the true, unpoisoned, rewards while computing their\npolicies under the poisoned rewards. We propose an optimization framework for\nderiving optimal defense policies, both when the attack parameter is known and\nunknown. Moreover, we show that defense policies that are solutions to the\nproposed optimization problems have provable performance guarantees. In\nparticular, we provide the following bounds with respect to the true,\nunpoisoned, rewards: a) lower bounds on the expected return of the defense\npolicies, and b) upper bounds on how suboptimal these defense policies are\ncompared to the attacker's target policy. We conclude the paper by illustrating\nthe intuitions behind our formal results, and showing that the derived bounds\nare non-trivial.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 23:31:53 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 22:23:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Banihashem", "Kiarash", ""], ["Singla", "Adish", ""], ["Radanovic", "Goran", ""]]}, {"id": "2102.05815", "submitter": "Mengjiao Yang", "authors": "Mengjiao Yang, Ofir Nachum", "title": "Representation Matters: Offline Pretraining for Sequential Decision\n  Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of supervised learning methods on ever larger offline\ndatasets has spurred interest in the reinforcement learning (RL) field to\ninvestigate whether the same paradigms can be translated to RL algorithms. This\nresearch area, known as offline RL, has largely focused on offline policy\noptimization, aiming to find a return-maximizing policy exclusively from\noffline data. In this paper, we consider a slightly different approach to\nincorporating offline data into sequential decision-making. We aim to answer\nthe question, what unsupervised objectives applied to offline datasets are able\nto learn state representations which elevate performance on downstream tasks,\nwhether those downstream tasks be online RL, imitation learning from expert\ndemonstrations, or even offline policy optimization based on the same offline\ndataset? Through a variety of experiments utilizing standard offline RL\ndatasets, we find that the use of pretraining with unsupervised learning\nobjectives can dramatically improve the performance of policy learning\nalgorithms that otherwise yield mediocre performance on their own. Extensive\nablations further provide insights into what components of these unsupervised\nobjectives -- e.g., reward prediction, continuous or discrete representations,\npretraining or finetuning -- are most important and in which settings.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 02:38:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Yang", "Mengjiao", ""], ["Nachum", "Ofir", ""]]}, {"id": "2102.05824", "submitter": "Joel Joseph", "authors": "Joel Joseph and Alex Gu", "title": "Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Continual Learning (CL) problem involves performing well on a sequence of\ntasks under limited compute. Current algorithms in the domain are either slow,\noffline or sensitive to hyper-parameters. La-MAML, an optimization-based\nmeta-learning algorithm claims to be better than other replay-based,\nprior-based and meta-learning based approaches. According to the MER paper [1],\nmetrics to measure performance in the continual learning arena are Retained\nAccuracy (RA) and Backward Transfer-Interference (BTI). La-MAML claims to\nperform better in these values when compared to the SOTA in the domain. This is\nthe main claim of the paper, which we shall be verifying in this report.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 03:05:57 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 06:09:28 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Joseph", "Joel", ""], ["Gu", "Alex", ""]]}, {"id": "2102.05875", "submitter": "Kaiwen Li", "authors": "Kaiwen Li, Tao Zhang, Rui Wang Yuheng Wang, and Yi Han", "title": "Deep Reinforcement Learning for Combinatorial Optimization: Covering\n  Salesman Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new deep learning approach to approximately solve the\nCovering Salesman Problem (CSP). In this approach, given the city locations of\na CSP as input, a deep neural network model is designed to directly output the\nsolution. It is trained using the deep reinforcement learning without\nsupervision. Specifically, in the model, we apply the Multi-head Attention to\ncapture the structural patterns, and design a dynamic embedding to handle the\ndynamic patterns of the problem. Once the model is trained, it can generalize\nto various types of CSP tasks (different sizes and topologies) with no need of\nre-training. Through controlled experiments, the proposed approach shows\ndesirable time complexity: it runs more than 20 times faster than the\ntraditional heuristic solvers with a tiny gap of optimality. Moreover, it\nsignificantly outperforms the current state-of-the-art deep learning approaches\nfor combinatorial optimization in the aspect of both training and inference. In\ncomparison with traditional solvers, this approach is highly desirable for most\nof the challenging tasks in practice that are usually large-scale and require\nquick decisions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 07:25:04 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Li", "Kaiwen", ""], ["Zhang", "Tao", ""], ["Wang", "Rui Wang Yuheng", ""], ["Han", "Yi", ""]]}, {"id": "2102.05884", "submitter": "Glenn Dawson", "authors": "Glenn Dawson and Robi Polikar", "title": "OpinionRank: Extracting Ground Truth Labels from Unreliable Expert\n  Opinions with Graph-Based Spectral Ranking", "comments": "8 pages, 5 figures, accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As larger and more comprehensive datasets become standard in contemporary\nmachine learning, it becomes increasingly more difficult to obtain reliable,\ntrustworthy label information with which to train sophisticated models. To\naddress this problem, crowdsourcing has emerged as a popular, inexpensive, and\nefficient data mining solution for performing distributed label collection.\nHowever, crowdsourced annotations are inherently untrustworthy, as the labels\nare provided by anonymous volunteers who may have varying, unreliable\nexpertise. Worse yet, some participants on commonly used platforms such as\nAmazon Mechanical Turk may be adversarial, and provide intentionally incorrect\nlabel information without the end user's knowledge. We discuss three\nconventional models of the label generation process, describing their\nparameterizations and the model-based approaches used to solve them. We then\npropose OpinionRank, a model-free, interpretable, graph-based spectral\nalgorithm for integrating crowdsourced annotations into reliable labels for\nperforming supervised or semi-supervised learning. Our experiments show that\nOpinionRank performs favorably when compared against more highly parameterized\nalgorithms. We also show that OpinionRank is scalable to very large datasets\nand numbers of label sources, and requires considerably fewer computational\nresources than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:12:44 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 03:59:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2102.05894", "submitter": "Ali Nassif", "authors": "Ali Bou Nassif, Ismail Shahin, Shibani Hamsa, Nawel Nemmour, Keikichi\n  Hirose", "title": "CASA-Based Speaker Identification Using Cascaded GMM-CNN Classifier in\n  Noisy and Emotional Talking Conditions", "comments": "Published in Applied Soft Computing journal", "journal-ref": "Applied Soft Computing, Elsevier, 2021", "doi": "10.1016/j.asoc.2021.107141", "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work aims at intensifying text-independent speaker identification\nperformance in real application situations such as noisy and emotional talking\nconditions. This is achieved by incorporating two different modules: a\nComputational Auditory Scene Analysis CASA based pre-processing module for\nnoise reduction and cascaded Gaussian Mixture Model Convolutional Neural\nNetwork GMM-CNN classifier for speaker identification followed by emotion\nrecognition. This research proposes and evaluates a novel algorithm to improve\nthe accuracy of speaker identification in emotional and highly-noise\nsusceptible conditions. Experiments demonstrate that the proposed model yields\npromising results in comparison with other classifiers when Speech Under\nSimulated and Actual Stress SUSAS database, Emirati Speech Database ESD, the\nRyerson Audio-Visual Database of Emotional Speech and Song RAVDESS database and\nthe Fluent Speech Commands database are used in a noisy environment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:56:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Nassif", "Ali Bou", ""], ["Shahin", "Ismail", ""], ["Hamsa", "Shibani", ""], ["Nemmour", "Nawel", ""], ["Hirose", "Keikichi", ""]]}, {"id": "2102.05916", "submitter": "Ricardo Britto", "authors": "Nishrith Saini and Ricardo Britto", "title": "Using Machine Intelligence to Prioritise Code Review Requests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Code Review (MCR) is the process of reviewing new code changes that\nneed to be merged with an existing codebase. As a developer, one may receive\nmany code review requests every day, i.e., the review requests need to be\nprioritised. Manually prioritising review requests is a challenging and\ntime-consuming process. To address the above problem, we conducted an\nindustrial case study at Ericsson aiming at developing a tool called Pineapple,\nwhich uses a Bayesian Network to prioritise code review requests. To validate\nour approach/tool, we deployed it in a live software development project at\nEricsson, wherein more than 150 developers develop a telecommunication product.\nWe focused on evaluating the predictive performance, feasibility, and\nusefulness of our approach. The results indicate that Pineapple has competent\npredictive performance (RMSE = 0.21 and MAE = 0.15). Furthermore, around 82.6%\nof Pineapple's users believe the tool can support code review request\nprioritisation by providing reliable results, and around 56.5% of the users\nbelieve it helps reducing code review lead time. As future work, we plan to\nevaluate Pineapple's predictive performance, usefulness, and feasibility\nthrough a longitudinal investigation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 10:04:34 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Saini", "Nishrith", ""], ["Britto", "Ricardo", ""]]}, {"id": "2102.05919", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Esther Villar-Rodriguez, Izaskun Oregi and Aitor\n  Moreno-Fernandez-de-Leceta", "title": "Focusing on the Hybrid Quantum Computing -- Tabu Search Algorithm: new\n  results on the Asymmetric Salesman Problem", "comments": "7 pages, 2 figures, paper accepted for being presented in the Genetic\n  and Evolutionary Computation Conference 2021 (GECCO 2021)", "journal-ref": null, "doi": "10.1145/3449726.3463123", "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Computing is an emerging paradigm which is gathering a lot of\npopularity in the current scientific and technological community. Widely\nconceived as the next frontier of computation, Quantum Computing is still at\nthe dawn of its development. Thus, current solving systems suffer from\nsignificant limitations in terms of performance and capabilities. Some\ninteresting approaches have been devised by researchers and practitioners in\norder to overcome these barriers, being quantum-classical hybrid algorithms one\nof the most often used solving schemes. The main goal of this paper is to\nextend the results and findings of the recently proposed hybrid Quantum\nComputing - Tabu Search Algorithm for partitioning problems. To do that, we\nfocus our research on the adaptation of this method to the Asymmetric Traveling\nSalesman Problem. In overall, we have employed six well-known instances\nbelonging to TSPLIB to assess the performance of Quantum Computing - Tabu\nSearch Algorithm in comparison to QBSolv, a state-of-the-art decomposing\nsolver. Furthermore, as an additional contribution, this work also supposes the\nfirst solving of the Asymmetric Traveling Salesman Problem using a Quantum\nComputing based method. Aiming to boost whole community's research in QC, we\nhave released the project's repository as open source code for further\napplication and improvements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 10:08:44 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:51:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Osaba", "Eneko", ""], ["Villar-Rodriguez", "Esther", ""], ["Oregi", "Izaskun", ""], ["Moreno-Fernandez-de-Leceta", "Aitor", ""]]}, {"id": "2102.05949", "submitter": "Alex F", "authors": "Viet-Man Le and Alexander Felfernig and Mathias Uta and David\n  Benavides and Jos\\'e Galindo and Thi Ngoc Trang Tran", "title": "DirectDebug: Automated Testing and Debugging of Feature Models", "comments": "to appear in the ICSE'21 Proceedings, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variability models (e.g., feature models) are a common way for the\nrepresentation of variabilities and commonalities of software artifacts. Such\nmodels can be translated to a logical representation and thus allow different\noperations for quality assurance and other types of model property analysis.\nSpecifically, complex and often large-scale feature models can become faulty,\ni.e., do not represent the expected variability properties of the underlying\nsoftware artifact. In this paper, we introduce DirectDebug which is a direct\ndiagnosis approach to the automated testing and debugging of variability\nmodels. The algorithm helps software engineers by supporting an automated\nidentification of faulty constraints responsible for an unintended behavior of\na variability model. This approach can significantly decrease development and\nmaintenance efforts for such models.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:22:20 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Le", "Viet-Man", ""], ["Felfernig", "Alexander", ""], ["Uta", "Mathias", ""], ["Benavides", "David", ""], ["Galindo", "Jos\u00e9", ""], ["Tran", "Thi Ngoc Trang", ""]]}, {"id": "2102.05954", "submitter": "Paramita Koley", "authors": "Paramita Koley, Avirup Saha, Sourangshu Bhattacharya, Niloy Ganguly,\n  and Abir De", "title": "Demarcating Endogenous and Exogenous Opinion Dynamics: An Experimental\n  Design Approach", "comments": "25 Pages, Accepted in ACM TKDD, 2021", "journal-ref": "ACM Trans. Knowl. Discov. Data. 1, 1, Article 1 (January 2021), 25\n  pages", "doi": "10.1145/3449361", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The networked opinion diffusion in online social networks (OSN) is often\ngoverned by the two genres of opinions - endogenous opinions that are driven by\nthe influence of social contacts among users, and exogenous opinions which are\nformed by external effects like news, feeds etc. Accurate demarcation of\nendogenous and exogenous messages offers an important cue to opinion modeling,\nthereby enhancing its predictive performance. In this paper, we design a suite\nof unsupervised classification methods based on experimental design approaches,\nin which, we aim to select the subsets of events which minimize different\nmeasures of mean estimation error. In more detail, we first show that these\nsubset selection tasks are NP-Hard. Then we show that the associated objective\nfunctions are weakly submodular, which allows us to cast efficient\napproximation algorithms with guarantees. Finally, we validate the efficacy of\nour proposal on various real-world datasets crawled from Twitter as well as\ndiverse synthetic datasets. Our experiments range from validating prediction\nperformance on unsanitized and sanitized events to checking the effect of\nselecting optimal subsets of various sizes. Through various experiments, we\nhave found that our method offers a significant improvement in accuracy in\nterms of opinion forecasting, against several competitors.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:38:15 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Koley", "Paramita", ""], ["Saha", "Avirup", ""], ["Bhattacharya", "Sourangshu", ""], ["Ganguly", "Niloy", ""], ["De", "Abir", ""]]}, {"id": "2102.05956", "submitter": "Lorena Qendro", "authors": "Lorena Qendro, Jagmohan Chauhan, Alberto Gil C. P. Ramos, Cecilia\n  Mascolo", "title": "The Benefit of the Doubt: Uncertainty Aware Sensing for Edge Computing\n  Platforms", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) lack measures of \"reliability\" estimation that would\nenable reasoning over their predictions. Despite the vital importance,\nespecially in areas of human well-being and health, state-of-the-art\nuncertainty estimation techniques are computationally expensive when applied to\nresource-constrained devices. We propose an efficient framework for predictive\nuncertainty estimation in NNs deployed on embedded edge systems with no need\nfor fine-tuning or re-training strategies. To meet the energy and latency\nrequirements of these embedded platforms the framework is built from the ground\nup to provide predictive uncertainty based only on one forward pass and a\nnegligible amount of additional matrix multiplications with theoretically\nproven correctness. Our aim is to enable already trained deep learning models\nto generate uncertainty estimates on resource-limited devices at inference time\nfocusing on classification tasks. This framework is founded on theoretical\ndevelopments casting dropout training as approximate inference in Bayesian NNs.\nOur layerwise distribution approximation to the convolution layer cascades\nthrough the network, providing uncertainty estimates in one single run which\nensures minimal overhead, especially compared with uncertainty techniques that\nrequire multiple forwards passes and an equal linear rise in energy and latency\nrequirements making them unsuitable in practice. We demonstrate that it yields\nbetter performance and flexibility over previous work based on multilayer\nperceptrons to obtain uncertainty estimates. Our evaluation with mobile\napplications datasets shows that our approach not only obtains robust and\naccurate uncertainty estimations but also outperforms state-of-the-art methods\nin terms of systems performance, reducing energy consumption (up to 28x),\nkeeping the memory overhead at a minimum while still improving accuracy (up to\n16%).\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:44:32 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Qendro", "Lorena", ""], ["Chauhan", "Jagmohan", ""], ["Ramos", "Alberto Gil C. P.", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2102.05960", "submitter": "Muhammad Aamir", "authors": "Muhammad Naeem, Jian Yu, Muhammad Aamir, Sajjad Ahmad Khan, Olayinka\n  Adeleye, Zardad Khan", "title": "Comparative Analysis of Machine Learning Approaches to Analyze and\n  Predict the Covid-19 Outbreak", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background. Forecasting the time of forthcoming pandemic reduces the impact\nof diseases by taking precautionary steps such as public health messaging and\nraising the consciousness of doctors. With the continuous and rapid increase in\nthe cumulative incidence of COVID-19, statistical and outbreak prediction\nmodels including various machine learning (ML) models are being used by the\nresearch community to track and predict the trend of the epidemic, and also in\ndeveloping appropriate strategies to combat and manage its spread. Methods. In\nthis paper, we present a comparative analysis of various ML approaches\nincluding Support Vector Machine, Random Forest, K-Nearest Neighbor and\nArtificial Neural Network in predicting the COVID-19 outbreak in the\nepidemiological domain. We first apply the autoregressive distributed lag\n(ARDL) method to identify and model the short and long-run relationships of the\ntime-series COVID-19 datasets. That is, we determine the lags between a\nresponse variable and its respective explanatory time series variables as\nindependent variables. Then, the resulting significant variables concerning\ntheir lags are used in the regression model selected by the ARDL for predicting\nand forecasting the trend of the epidemic. Results. Statistical measures i.e.,\nRoot Mean Square Error (RMSE), Mean Absolute Error (MAE) and Mean Absolute\nPercentage Error (MAPE) are used for model accuracy. The values of MAPE for the\nbest selected models for confirmed, recovered and deaths cases are 0.407, 0.094\nand 0.124 respectively, which falls under the category of highly accurate\nforecasts. In addition, we computed fifteen days ahead forecast for the daily\ndeaths, recover, and confirm patients and the cases fluctuated across time in\nall aspects. Besides, the results reveal the advantages of ML algorithms for\nsupporting decision making of evolving short term policies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:57:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Naeem", "Muhammad", ""], ["Yu", "Jian", ""], ["Aamir", "Muhammad", ""], ["Khan", "Sajjad Ahmad", ""], ["Adeleye", "Olayinka", ""], ["Khan", "Zardad", ""]]}, {"id": "2102.05975", "submitter": "Giacomo Spigler", "authors": "Marlotte Pannekoek, Giacomo Spigler", "title": "Investigating Trade-offs in Utility, Fairness and Differential Privacy\n  in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To enable an ethical and legal use of machine learning algorithms, they must\nboth be fair and protect the privacy of those whose data are being used.\nHowever, implementing privacy and fairness constraints might come at the cost\nof utility (Jayaraman & Evans, 2019; Gong et al., 2020). This paper\ninvestigates the privacy-utility-fairness trade-off in neural networks by\ncomparing a Simple (S-NN), a Fair (F-NN), a Differentially Private (DP-NN), and\na Differentially Private and Fair Neural Network (DPF-NN) to evaluate\ndifferences in performance on metrics for privacy (epsilon, delta), fairness\n(risk difference), and utility (accuracy). In the scenario with the highest\nconsidered privacy guarantees (epsilon = 0.1, delta = 0.00001), the DPF-NN was\nfound to achieve better risk difference than all the other neural networks with\nonly a marginally lower accuracy than the S-NN and DP-NN. This model is\nconsidered fair as it achieved a risk difference below the strict (0.05) and\nlenient (0.1) thresholds. However, while the accuracy of the proposed model\nimproved on previous work from Xu, Yuan and Wu (2019), the risk difference was\nfound to be worse.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 12:33:19 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pannekoek", "Marlotte", ""], ["Spigler", "Giacomo", ""]]}, {"id": "2102.05983", "submitter": "Gustavo Miranda", "authors": "Gustavo Oliveira, Leandro Minku and Adriano Oliveira", "title": "Tackling Virtual and Real Concept Drifts: An Adaptive Gaussian Mixture\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world applications have been dealing with large amounts of data that\narrive over time and generally present changes in their underlying joint\nprobability distribution, i.e., concept drift. Concept drift can be subdivided\ninto two types: virtual drift, which affects the unconditional probability\ndistribution p(x), and real drift, which affects the conditional probability\ndistribution p(y|x). Existing works focuses on real drift. However, strategies\nto cope with real drift may not be the best suited for dealing with virtual\ndrift, since the real class boundaries remain unchanged. We provide the first\nin depth analysis of the differences between the impact of virtual and real\ndrifts on classifiers' suitability. We propose an approach to handle both\ndrifts called On-line Gaussian Mixture Model With Noise Filter For Handling\nVirtual and Real Concept Drifts (OGMMF-VRD). Experiments with 7 synthetic and 3\nreal-world datasets show that OGMMF-VRD obtained the best results in terms of\naverage accuracy, G-mean and runtime compared to existing approaches. Moreover,\nits accuracy over time suffered less performance degradation in the presence of\ndrifts.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 13:03:16 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Oliveira", "Gustavo", ""], ["Minku", "Leandro", ""], ["Oliveira", "Adriano", ""]]}, {"id": "2102.06018", "submitter": "Simon Pfenning", "authors": "Simon Pfenning, Philipp Holzinger, Marc Reichenbach", "title": "Transparent FPGA Acceleration with TensorFlow", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/09", "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, artificial neural networks are one of the major innovators pushing the\nprogress of machine learning. This has particularly affected the development of\nneural network accelerating hardware. However, since most of these\narchitectures require specialized toolchains, there is a certain amount of\nadditional effort for developers each time they want to make use of a new deep\nlearning accelerator. Furthermore the flexibility of the device is bound to the\narchitecture itself, as well as to the functionality of the runtime\nenvironment.\n  In this paper we propose a toolflow using TensorFlow as frontend, thus\noffering developers the opportunity of using a familiar environment. On the\nbackend we use an FPGA, which is addressable via an HSA runtime environment. In\nthis way we are able to hide the complexity of controlling new hardware from\nthe user, while at the same time maintaining a high amount of flexibility. This\ncan be achieved by our HSA toolflow, since the hardware is not statically\nconfigured with the structure of the network. Instead, it can be dynamically\nreconfigured during runtime with the respective kernels executed by the network\nand simultaneously from other sources e.g. OpenCL/OpenMP.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:49:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pfenning", "Simon", ""], ["Holzinger", "Philipp", ""], ["Reichenbach", "Marc", ""]]}, {"id": "2102.06019", "submitter": "Anav Mehta", "authors": "Anav Mehta", "title": "Reinforcement Learning For Constraint Satisfaction Game Agents\n  (15-Puzzle, Minesweeper, 2048, and Sudoku)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, reinforcement learning has seen interest because of deep\nQ-Learning, where the model is a convolutional neural network. Deep Q-Learning\nhas shown promising results in games such as Atari and AlphaGo. Instead of\nlearning the entire Q-table, it learns an estimate of the Q function that\ndetermines a state's policy action. We use Q-Learning and deep Q-learning, to\nlearn control policies of four constraint satisfaction games (15-Puzzle,\nMinesweeper, 2048, and Sudoku). 15-Puzzle is a sliding permutation puzzle and\nprovides a challenge in addressing its large state space. Minesweeper and\nSudoku involve partially observable states and guessing. 2048 is also a sliding\npuzzle but allows for easier state representation (compared to 15-Puzzle) and\nuses interesting reward shaping to solve the game. These games offer unique\ninsights into the potential and limits of reinforcement learning. The Q agent\nis trained with no rules of the game, with only the reward corresponding to\neach state's action. Our unique contribution is in choosing the reward\nstructure, state representation, and formulation of the deep neural network.\nFor low shuffle, 15-Puzzle, achieves a 100% win rate, the medium and high\nshuffle achieve about 43% and 22% win rates respectively. On a standard 16x16\nMinesweeper board, both low and high-density boards achieve close to 45% win\nrate, whereas medium density boards have a low win rate of 15%. For 2048, the\n1024 win rate was achieved with significant ease (100%) with high win rates for\n2048, 4096, 8192 and 16384 as 40%, 0.05%, 0.01% and 0.004% , respectively. The\neasy Sudoku games had a win rate of 7%, while medium and hard games had 2.1%\nand 1.2% win rates, respectively. This paper explores the environment\ncomplexity and behavior of a subset of constraint games using reward structures\nwhich can get us closer to understanding how humans learn.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 22:29:29 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Mehta", "Anav", ""]]}, {"id": "2102.06024", "submitter": "Kang Gu", "authors": "Kang Gu, Soroush Vosoughi, Temiloluwa Prioleau", "title": "Feature Selection for Multivariate Time Series via Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, there has been an ever increasing amount of multivariate\ntime series (MTS) data in various domains, typically generated by a large\nfamily of sensors such as wearable devices. This has led to the development of\nnovel learning methods on MTS data, with deep learning models dominating the\nmost recent advancements. Prior literature has primarily focused on designing\nnew network architectures for modeling temporal dependencies within MTS.\nHowever, a less studied challenge is associated with high dimensionality of MTS\ndata. In this paper, we propose a novel neural component, namely Neural Feature\nSe-lector (NFS), as an end-2-end solution for feature selection in MTS data.\nSpecifically, NFS is based on decomposed convolution design and includes two\nmodules: firstly each feature stream within MTS is processed by a temporal CNN\nindependently; then an aggregating CNN combines the processed streams to\nproduce input for other downstream networks. We evaluated the proposed NFS\nmodel on four real-world MTS datasets and found that it achieves comparable\nresults with state-of-the-art methods while providing the benefit of feature\nselection. Our paper also highlights the robustness and effectiveness of\nfeature selection with NFS compared to using recent autoencoder-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 14:33:39 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Gu", "Kang", ""], ["Vosoughi", "Soroush", ""], ["Prioleau", "Temiloluwa", ""]]}, {"id": "2102.06042", "submitter": "Yiqin Yang", "authors": "Xiaoteng Ma, Yiqin Yang, Chenghao Li, Yiwen Lu, Qianchuan Zhao, Yang\n  Jun", "title": "Modeling the Interaction between Agents in Cooperative Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based methods of multi-agent reinforcement learning (MARL), especially\nthe value decomposition methods, have been demonstrated on a range of\nchallenging cooperative tasks. However, current methods pay little attention to\nthe interaction between agents, which is essential to teamwork in games or real\nlife. This limits the efficiency of value-based MARL algorithms in the two\naspects: collaborative exploration and value function estimation. In this\npaper, we propose a novel cooperative MARL algorithm named as interactive\nactor-critic~(IAC), which models the interaction of agents from the\nperspectives of policy and value function. On the policy side, a multi-agent\njoint stochastic policy is introduced by adopting a collaborative exploration\nmodule, which is trained by maximizing the entropy-regularized expected return.\nOn the value side, we use the shared attention mechanism to estimate the value\nfunction of each agent, which takes the impact of the teammates into\nconsideration. At the implementation level, we extend the value decomposition\nmethods to continuous control tasks and evaluate IAC on benchmark tasks\nincluding classic control and multi-agent particle environments. Experimental\nresults indicate that our method outperforms the state-of-the-art approaches\nand achieves better performance in terms of cooperation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 01:58:28 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ma", "Xiaoteng", ""], ["Yang", "Yiqin", ""], ["Li", "Chenghao", ""], ["Lu", "Yiwen", ""], ["Zhao", "Qianchuan", ""], ["Jun", "Yang", ""]]}, {"id": "2102.06045", "submitter": "Rajendra Joshi Mr.", "authors": "Rajendra P. Joshi and Neeraj Kumar", "title": "Artificial Intelligence based Autonomous Molecular Design for Medical\n  Therapeutic: A Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-aware machine learning (ML) models have been increasingly adopted for\naccelerating small molecule therapeutic design in the recent years. These\nmodels have been enabled by significant advancement in state-of-the-art\nartificial intelligence (AI) and computing infrastructures. Several ML\narchitectures are pre-dominantly and independently used either for predicting\nthe properties of small molecules, or for generating lead therapeutic\ncandidates. Synergetically using these individual components along with robust\nrepresentation and data generation techniques autonomously in closed loops\nholds enormous promise for accelerated drug design which is a time consuming\nand expensive task otherwise. In this perspective, we present the most recent\nbreakthrough achieved by each of the components, and how such autonomous AI and\nML workflow can be realized to radically accelerate the hit identification and\nlead optimization. Taken together, this could significantly shorten the\ntimeline for end-to-end antiviral discovery and optimization times to weeks\nupon the arrival of a novel zoonotic transmission event. Our perspective serves\nas a guide for researchers to practice autonomous molecular design in\ntherapeutic discovery.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 00:43:46 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Joshi", "Rajendra P.", ""], ["Kumar", "Neeraj", ""]]}, {"id": "2102.06099", "submitter": "Clark Zhang", "authors": "Clark Zhang, Santiago Paternain, Alejandro Ribeiro", "title": "Sufficiently Accurate Model Learning for Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven models of dynamical systems help planners and controllers to\nprovide more precise and accurate motions. Most model learning algorithms will\ntry to minimize a loss function between the observed data and the model's\npredictions. This can be improved using prior knowledge about the task at hand,\nwhich can be encoded in the form of constraints. This turns the unconstrained\nmodel learning problem into a constrained one. These constraints allow models\nwith finite capacity to focus their expressive power on important aspects of\nthe system. This can lead to models that are better suited for certain tasks.\nThis paper introduces the constrained Sufficiently Accurate model learning\napproach, provides examples of such problems, and presents a theorem on how\nclose some approximate solutions can be. The approximate solution quality will\ndepend on the function parameterization, loss and constraint function\nsmoothness, and the number of samples in model learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 16:27:31 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhang", "Clark", ""], ["Paternain", "Santiago", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2102.06112", "submitter": "Hugo Latapie", "authors": "Hugo Latapie, Ozkan Kilic, Gaowen Liu, Yan Yan, Ramana Kompella, Pei\n  Wang, Kristinn R. Thorisson, Adam Lawrence, Yuhong Sun, Jayanth Srinivasa", "title": "A Metamodel and Framework for Artificial General Intelligence From\n  Theory to Practice", "comments": "arXiv admin note: text overlap with arXiv:2008.12879", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new metamodel-based knowledge representation that\nsignificantly improves autonomous learning and adaptation. While interest in\nhybrid machine learning / symbolic AI systems leveraging, for example,\nreasoning and knowledge graphs, is gaining popularity, we find there remains a\nneed for both a clear definition of knowledge and a metamodel to guide the\ncreation and manipulation of knowledge. Some of the benefits of the metamodel\nwe introduce in this paper include a solution to the symbol grounding problem,\ncumulative learning, and federated learning. We have applied the metamodel to\nproblems ranging from time series analysis, computer vision, and natural\nlanguage understanding and have found that the metamodel enables a wide variety\nof learning mechanisms ranging from machine learning, to graph network analysis\nand learning by reasoning engines to interoperate in a highly synergistic way.\nOur metamodel-based projects have consistently exhibited unprecedented\naccuracy, performance, and ability to generalize. This paper is inspired by the\nstate-of-the-art approaches to AGI, recent AGI-aspiring work, the granular\ncomputing community, as well as Alfred Korzybski's general semantics. One\nsurprising consequence of the metamodel is that it not only enables a new level\nof autonomous learning and optimal functioning for machine intelligences, but\nmay also shed light on a path to better understanding how to improve human\ncognition.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 16:45:58 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Latapie", "Hugo", ""], ["Kilic", "Ozkan", ""], ["Liu", "Gaowen", ""], ["Yan", "Yan", ""], ["Kompella", "Ramana", ""], ["Wang", "Pei", ""], ["Thorisson", "Kristinn R.", ""], ["Lawrence", "Adam", ""], ["Sun", "Yuhong", ""], ["Srinivasa", "Jayanth", ""]]}, {"id": "2102.06125", "submitter": "Dong Si", "authors": "Dong Si, Andrew Nakamura, Runbang Tang, Haowen Guan, Jie Hou, Ammaar\n  Firozi, Renzhi Cao, Kyle Hippe, Minglei Zhao", "title": "Artificial Intelligence Advances for De Novo Molecular Structure\n  Modeling in Cryo-EM", "comments": null, "journal-ref": "Wiley Interdisciplinary Reviews: Computational Molecular Science,\n  e1542 (2021)", "doi": "10.1002/wcms.1542", "report-no": null, "categories": "q-bio.BM cs.AI physics.bio-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Cryo-electron microscopy (cryo-EM) has become a major experimental technique\nto determine the structures of large protein complexes and molecular\nassemblies, as evidenced by the 2017 Nobel Prize. Although cryo-EM has been\ndrastically improved to generate high-resolution three-dimensional (3D) maps\nthat contain detailed structural information about macromolecules, the\ncomputational methods for using the data to automatically build structure\nmodels are lagging far behind. The traditional cryo-EM model building approach\nis template-based homology modeling. Manual de novo modeling is very\ntime-consuming when no template model is found in the database. In recent\nyears, de novo cryo-EM modeling using machine learning (ML) and deep learning\n(DL) has ranked among the top-performing methods in macromolecular structure\nmodeling. Deep-learning-based de novo cryo-EM modeling is an important\napplication of artificial intelligence, with impressive results and great\npotential for the next generation of molecular biomedicine. Accordingly, we\nsystematically review the representative ML/DL-based de novo cryo-EM modeling\nmethods. And their significances are discussed from both practical and\nmethodological viewpoints. We also briefly describe the background of cryo-EM\ndata processing workflow. Overall, this review provides an introductory guide\nto modern research on artificial intelligence (AI) for de novo molecular\nstructure modeling and future directions in this emerging field.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:06:20 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 02:03:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Si", "Dong", ""], ["Nakamura", "Andrew", ""], ["Tang", "Runbang", ""], ["Guan", "Haowen", ""], ["Hou", "Jie", ""], ["Firozi", "Ammaar", ""], ["Cao", "Renzhi", ""], ["Hippe", "Kyle", ""], ["Zhao", "Minglei", ""]]}, {"id": "2102.06137", "submitter": "Antonio Vergari", "authors": "Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, Guy Van den\n  Broeck", "title": "A Compositional Atlas of Tractable Circuit Operations: From Simple\n  Transformations to Complex Information-Theoretic Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Circuit representations are becoming the lingua franca to express and reason\nabout tractable generative and discriminative models. In this paper, we show\nhow complex inference scenarios for these models that commonly arise in machine\nlearning -- from computing the expectations of decision tree ensembles to\ninformation-theoretic divergences of deep mixture models -- can be represented\nin terms of tractable modular operations over circuits. Specifically, we\ncharacterize the tractability of a vocabulary of simple transformations --\nsums, products, quotients, powers, logarithms, and exponentials -- in terms of\nsufficient structural constraints of the circuits they operate on, and present\nnovel hardness results for the cases in which these properties are not\nsatisfied. Building on these operations, we derive a unified framework for\nreasoning about tractable models that generalizes several results in the\nliterature and opens up novel tractable inference scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:26:32 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Vergari", "Antonio", ""], ["Choi", "YooJung", ""], ["Liu", "Anji", ""], ["Teso", "Stefano", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2102.06145", "submitter": "Marina Speranskaya", "authors": "Marina Speranskaya, Martin Schmitt, Benjamin Roth", "title": "Ranking vs. Classifying: Measuring Knowledge Base Completion Quality", "comments": "AKBC 2020 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base completion (KBC) methods aim at inferring missing facts from\nthe information present in a knowledge base (KB) by estimating the likelihood\nof candidate facts. In the prevailing evaluation paradigm, models do not\nactually decide whether a new fact should be accepted or not but are solely\njudged on the position of true facts in a likelihood ranking with other\ncandidates. We argue that consideration of binary predictions is essential to\nreflect the actual KBC quality, and propose a novel evaluation paradigm,\ndesigned to provide more transparent model selection criteria for a realistic\nscenario. We construct the data set FB14k-QAQ where instead of single facts, we\nuse KB queries, i.e., facts where one entity is replaced with a variable, and\nconstruct corresponding sets of entities that are correct answers. We randomly\nremove some of these correct answers from the data set, simulating the\nrealistic scenario of real-world entities missing from a KB. This way, we can\nexplicitly measure a model's ability to handle queries that have more correct\nanswers in the real world than in the KB, including the special case of queries\nwithout any valid answer. The latter especially contrasts the ranking setting.\nWe evaluate a number of state-of-the-art KB embeddings models on our new\nbenchmark. The differences in relative performance between ranking-based and\nclassification-based evaluation that we observe in our experiments confirm our\nhypothesis that good performance on the ranking task does not necessarily\ntranslate to good performance on the actual completion task. Our results\nmotivate future work on KB embedding models with better prediction separability\nand, as a first step in that direction, we propose a simple variant of TransE\nthat encourages thresholding and achieves a significant improvement in\nclassification F1 score relative to the original TransE.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 17:53:48 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Speranskaya", "Marina", ""], ["Schmitt", "Martin", ""], ["Roth", "Benjamin", ""]]}, {"id": "2102.06148", "submitter": "Valentin Goranko", "authors": "Valentin Goranko and Fengkui Ju", "title": "A Logic for Conditional Local Strategic Reasoning", "comments": "21 pages, to appear in the LORI'2019 special issue of the Journal of\n  Logic, Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LO math.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider systems of rational agents who act and interact in pursuit of\ntheir individual and collective objectives. We study and formalise the\nreasoning of an agent, or of an external observer, about the expected choices\nof action of the other agents based on their objectives, in order to assess the\nreasoner's ability, or expectation, to achieve their own objective.\n  To formalize such reasoning we extend Pauly's Coalition Logic with three new\nmodal operators of conditional strategic reasoning, thus introducing the Logic\nfor Local Conditional Strategic Reasoning ConStR. We provide formal semantics\nfor the new conditional strategic operators in concurrent game models,\nintroduce the matching notion of bisimulation for each of them, prove\nbisimulation invariance and Hennessy-Milner property for each of them, and\ndiscuss and compare briefly their expressiveness. Finally, we also propose\nsystems of axioms for each of the basic operators of ConStR and for the full\nlogic.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 17:45:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Goranko", "Valentin", ""], ["Ju", "Fengkui", ""]]}, {"id": "2102.06166", "submitter": "Aniya Aggarwal", "authors": "Aniya Aggarwal, Samiulla Shaikh, Sandeep Hans, Swastik Haldar, Rema\n  Ananthanarayanan, Diptikalyan Saha", "title": "Testing Framework for Black-box AI Models", "comments": "4 pages Demonstrations track paper accepted at ICSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With widespread adoption of AI models for important decision making, ensuring\nreliability of such models remains an important challenge. In this paper, we\npresent an end-to-end generic framework for testing AI Models which performs\nautomated test generation for different modalities such as text, tabular, and\ntime-series data and across various properties such as accuracy, fairness, and\nrobustness. Our tool has been used for testing industrial AI models and was\nvery effective to uncover issues present in those models. Demo video link:\nhttps://youtu.be/984UCU17YZI\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:15:23 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Aggarwal", "Aniya", ""], ["Shaikh", "Samiulla", ""], ["Hans", "Sandeep", ""], ["Haldar", "Swastik", ""], ["Ananthanarayanan", "Rema", ""], ["Saha", "Diptikalyan", ""]]}, {"id": "2102.06177", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Amy Zhang, Joelle Pineau", "title": "Multi-Task Reinforcement Learning with Context-based Representations", "comments": "Accepted at the 38th International Conference on Machine Learning\n  (ICML 2021). 17 pages, 4 figures, 20 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefit of multi-task learning over single-task learning relies on the\nability to use relations across tasks to improve performance on any single\ntask. While sharing representations is an important mechanism to share\ninformation across tasks, its success depends on how well the structure\nunderlying the tasks is captured. In some real-world situations, we have access\nto metadata, or additional information about a task, that may not provide any\nnew insight in the context of a single task setup alone but inform relations\nacross multiple tasks. While this metadata can be useful for improving\nmulti-task learning performance, effectively incorporating it can be an\nadditional challenge. We posit that an efficient approach to knowledge transfer\nis through the use of multiple context-dependent, composable representations\nshared across a family of tasks. In this framework, metadata can help to learn\ninterpretable representations and provide the context to inform which\nrepresentations to compose and how to compose them. We use the proposed\napproach to obtain state-of-the-art results in Meta-World, a challenging\nmulti-task benchmark consisting of 50 distinct robotic manipulation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:41:27 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 18:10:47 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Sodhani", "Shagun", ""], ["Zhang", "Amy", ""], ["Pineau", "Joelle", ""]]}, {"id": "2102.06202", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos and Stephen Bates and Tijana Zrnic and\n  Michael I. Jordan", "title": "Private Prediction Sets", "comments": "Code available at\n  https://github.com/aangelopoulos/private_prediction_sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world settings involving consequential decision-making, the\ndeployment of machine learning systems generally requires both reliable\nuncertainty quantification and protection of individuals' privacy. We present a\nframework that treats these two desiderata jointly. Our framework is based on\nconformal prediction, a methodology that augments predictive models to return\nprediction sets that provide uncertainty quantification -- they provably cover\nthe true response with a user-specified probability, such as 90%. One might\nhope that when used with privately-trained models, conformal prediction would\nyield privacy guarantees for the resulting prediction sets; unfortunately this\nis not the case. To remedy this key problem, we develop a method that takes any\npre-trained predictive model and outputs differentially private prediction\nsets. Our method follows the general approach of split conformal prediction; we\nuse holdout data to calibrate the size of the prediction sets but preserve\nprivacy by using a privatized quantile subroutine. This subroutine compensates\nfor the noise introduced to preserve privacy in order to guarantee correct\ncoverage. We evaluate the method with experiments on the CIFAR-10, ImageNet,\nand CoronaHack datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:59:11 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""], ["Zrnic", "Tijana", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2102.06203", "submitter": "Jesse Han", "authors": "Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W. Ayers, Stanislas\n  Polu", "title": "Proof Artifact Co-training for Theorem Proving with Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Labeled data for imitation learning of theorem proving in large libraries of\nformalized mathematics is scarce as such libraries require years of\nconcentrated effort by human specialists to be built. This is particularly\nchallenging when applying large Transformer language models to tactic\nprediction, because the scaling of performance with respect to model size is\nquickly disrupted in the data-scarce, easily-overfitted regime. We propose PACT\n({\\bf P}roof {\\bf A}rtifact {\\bf C}o-{\\bf T}raining), a general methodology for\nextracting abundant self-supervised data from kernel-level proof terms for\nco-training alongside the usual tactic prediction objective. We apply this\nmethodology to Lean, an interactive proof assistant which hosts some of the\nmost sophisticated formalized mathematics to date. We instrument Lean with a\nneural theorem prover driven by a Transformer language model and show that PACT\nimproves theorem proving success rate on a held-out suite of test theorems from\n32\\% to 48\\%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:59:24 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Han", "Jesse Michael", ""], ["Rute", "Jason", ""], ["Wu", "Yuhuai", ""], ["Ayers", "Edward W.", ""], ["Polu", "Stanislas", ""]]}, {"id": "2102.06243", "submitter": "Yuping Fan", "authors": "Yuping Fan, Zhiling Lan, Taylor Childers, Paul Rich, William Allcock\n  and Michael E. Papka", "title": "Deep Reinforcement Agent for Scheduling in HPC", "comments": "Accepted by IPDPS 2021", "journal-ref": "35th IEEE International Parallel & Distributed Processing\n  Symposium (2021)", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster scheduler is crucial in high-performance computing (HPC). It\ndetermines when and which user jobs should be allocated to available system\nresources. Existing cluster scheduling heuristics are developed by human\nexperts based on their experience with specific HPC systems and workloads.\nHowever, the increasing complexity of computing systems and the highly dynamic\nnature of application workloads have placed tremendous burden on manually\ndesigned and tuned scheduling heuristics. More aggressive optimization and\nautomation are needed for cluster scheduling in HPC. In this work, we present\nan automated HPC scheduling agent named DRAS (Deep Reinforcement Agent for\nScheduling) by leveraging deep reinforcement learning. DRAS is built on a\nnovel, hierarchical neural network incorporating special HPC scheduling\nfeatures such as resource reservation and backfilling. A unique training\nstrategy is presented to enable DRAS to rapidly learn the target environment.\nOnce being provided a specific scheduling objective given by system manager,\nDRAS automatically learns to improve its policy through interaction with the\nscheduling environment and dynamically adjusts its policy as workload changes.\nThe experiments with different production workloads demonstrate that DRAS\noutperforms the existing heuristic and optimization approaches by up to 45%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:08:38 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 22:31:44 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fan", "Yuping", ""], ["Lan", "Zhiling", ""], ["Childers", "Taylor", ""], ["Rich", "Paul", ""], ["Allcock", "William", ""], ["Papka", "Michael E.", ""]]}, {"id": "2102.06245", "submitter": "Kaushik Roy", "authors": "Kaushik Roy, Qi Zhang, Manas Gaur, and Amit Sheth", "title": "Knowledge Infused Policy Gradients for Adaptive Pandemic Control", "comments": "Accepted at AAAI-MAKE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 has impacted nations differently based on their policy\nimplementations. The effective policy requires taking into account public\ninformation and adaptability to new knowledge. Epidemiological models built to\nunderstand COVID-19 seldom provide the policymaker with the capability for\nadaptive pandemic control (APC). Among the core challenges to be overcome\ninclude (a) inability to handle a high degree of non-homogeneity in different\ncontributing features across the pandemic timeline, (b) lack of an approach\nthat enables adaptive incorporation of public health expert knowledge, and (c)\ntransparent models that enable understanding of the decision-making process in\nsuggesting policy. In this work, we take the early steps to address these\nchallenges using Knowledge Infused Policy Gradient (KIPG) methods. Prior work\non knowledge infusion does not handle soft and hard imposition of varying forms\nof knowledge in disease information and guidelines to necessarily comply with.\nFurthermore, the models do not attend to non-homogeneity in feature counts,\nmanifesting as partial observability in informing the policy. Additionally,\ninterpretable structures are extracted post-learning instead of learning an\ninterpretable model required for APC. To this end, we introduce a mathematical\nframework for KIPG methods that can (a) induce relevant feature counts over\nmulti-relational features of the world, (b) handle latent non-homogeneous\ncounts as hidden variables that are linear combinations of kernelized\naggregates over the features, and (b) infuse knowledge as functional\nconstraints in a principled manner. The study establishes a theory for imposing\nhard and soft constraints and simulates it through experiments. In comparison\nwith knowledge-intensive baselines, we show quick sample efficient adaptation\nto new knowledge and interpretability in the learned policy, especially in a\npandemic context.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:13:00 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Roy", "Kaushik", ""], ["Zhang", "Qi", ""], ["Gaur", "Manas", ""], ["Sheth", "Amit", ""]]}, {"id": "2102.06258", "submitter": "Allen Hart", "authors": "Allen G. Hart, Kevin R. Olding, A. M. G. Cox, Olga Isupova, J. H. P.\n  Dawes", "title": "Using Echo State Networks to Approximate Value Functions for Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An Echo State Network (ESN) is a type of single-layer recurrent neural\nnetwork with randomly-chosen internal weights and a trainable output layer. We\nprove under mild conditions that a sufficiently large Echo State Network can\napproximate the value function of a broad class of stochastic and deterministic\ncontrol problems. Such control problems are generally non-Markovian.\n  We describe how the ESN can form the basis for novel and computationally\nefficient reinforcement learning algorithms in a non-Markovian framework. We\ndemonstrate this theory with two examples. In the first, we use an ESN to solve\na deterministic, partially observed, control problem which is a simple game we\ncall `Bee World'. In the second example, we consider a stochastic control\nproblem inspired by a market making problem in mathematical finance. In both\ncases we can compare the dynamics of the algorithms with analytic solutions to\nshow that even after only a single reinforcement policy iteration the\nalgorithms arrive at a good policy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:33:20 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 12:09:10 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Hart", "Allen G.", ""], ["Olding", "Kevin R.", ""], ["Cox", "A. M. G.", ""], ["Isupova", "Olga", ""], ["Dawes", "J. H. P.", ""]]}, {"id": "2102.06274", "submitter": "Oleg Szehr", "authors": "Oleg Szehr", "title": "Hedging of Financial Derivative Contracts via Monte Carlo Tree Search", "comments": "Corrected typos. Shorter Presentation. 15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG q-fin.PR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The construction of approximate replication strategies for pricing and\nhedging of derivative contracts in incomplete markets is a key problem of\nfinancial engineering. Recently Reinforcement Learning algorithms for hedging\nunder realistic market conditions have attracted significant interest. While\nresearch in the derivatives area mostly focused on variations of $Q$-learning,\nin artificial intelligence Monte Carlo Tree Search is the recognized\nstate-of-the-art method for various planning problems, such as the games of\nHex, Chess, Go,... This article introduces Monte Carlo Tree Search as a method\nto solve the stochastic optimal control problem behind the pricing and hedging\ntasks. As compared to $Q$-learning it combines Reinforcement Learning with tree\nsearch techniques. As a consequence Monte Carlo Tree Search has higher sample\nefficiency, is less prone to over-fitting to specific market models and\ngenerally learns stronger policies faster. In our experiments we find that\nMonte Carlo Tree Search, being the world-champion in games like Chess and Go,\nis easily capable of maximizing the utility of investor's terminal wealth\nwithout setting up an auxiliary mathematical framework.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:17:01 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 21:22:41 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 21:26:31 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Szehr", "Oleg", ""]]}, {"id": "2102.06306", "submitter": "Satwinder Singh", "authors": "Satwinder Singh, Ruili Wang, Yuanhang Qiu", "title": "DEEPF0: End-To-End Fundamental Frequency Estimation for Music and Speech\n  Signals", "comments": "Accepted in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel pitch estimation technique called DeepF0, which leverages\nthe available annotated data to directly learns from the raw audio in a\ndata-driven manner. F0 estimation is important in various speech processing and\nmusic information retrieval applications. Existing deep learning models for\npitch estimations have relatively limited learning capabilities due to their\nshallow receptive field. The proposed model addresses this issue by extending\nthe receptive field of a network by introducing the dilated convolutional\nblocks into the network. The dilation factor increases the network receptive\nfield exponentially without increasing the parameters of the model\nexponentially. To make the training process more efficient and faster, DeepF0\nis augmented with residual blocks with residual connections. Our empirical\nevaluation demonstrates that the proposed model outperforms the baselines in\nterms of raw pitch accuracy and raw chroma accuracy even using 77.4% fewer\nnetwork parameters. We also show that our model can capture reasonably well\npitch estimation even under the various levels of accompaniment noise.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 23:11:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Singh", "Satwinder", ""], ["Wang", "Ruili", ""], ["Qiu", "Yuanhang", ""]]}, {"id": "2102.06358", "submitter": "Ye Luo", "authors": "Ye Luo and Shiqing Fan", "title": "Min-Max-Plus Neural Networks", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new model of neural networks called Min-Max-Plus Neural Networks\n(MMP-NNs) based on operations in tropical arithmetic. In general, an MMP-NN is\ncomposed of three types of alternately stacked layers, namely linear layers,\nmin-plus layers and max-plus layers. Specifically, the latter two types of\nlayers constitute the nonlinear part of the network which is trainable and more\nsophisticated compared to the nonlinear part of conventional neural networks.\nIn addition, we show that with higher capability of nonlinearity expression,\nMMP-NNs are universal approximators of continuous functions, even when the\nnumber of multiplication operations is tremendously reduced (possibly to none\nin certain extreme cases). Furthermore, we formulate the backpropagation\nalgorithm in the training process of MMP-NNs and introduce an algorithm of\nnormalization to improve the rate of convergence in training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:09:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Luo", "Ye", ""], ["Fan", "Shiqing", ""]]}, {"id": "2102.06361", "submitter": "Sandra Carrasco Limeros", "authors": "Sandra Carrasco, David Fern\\'andez Llorca, Miguel \\'Angel Sotelo", "title": "SCOUT: Socially-COnsistent and UndersTandable Graph Attention Network\n  for Trajectory Prediction of Vehicles and VRUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles navigate in dynamically changing environments under a\nwide variety of conditions, being continuously influenced by surrounding\nobjects. Modelling interactions among agents is essential for accurately\nforecasting other agents' behaviour and achieving safe and comfortable motion\nplanning. In this work, we propose SCOUT, a novel Attention-based Graph Neural\nNetwork that uses a flexible and generic representation of the scene as a graph\nfor modelling interactions, and predicts socially-consistent trajectories of\nvehicles and Vulnerable Road Users (VRUs) under mixed traffic conditions. We\nexplore three different attention mechanisms and test our scheme with both\nbird-eye-view and on-vehicle urban data, achieving superior performance than\nexisting state-of-the-art approaches on InD and ApolloScape Trajectory\nbenchmarks. Additionally, we evaluate our model's flexibility and\ntransferability by testing it under completely new scenarios on RounD dataset.\nThe importance and influence of each interaction in the final prediction is\nexplored by means of Integrated Gradients technique and the visualization of\nthe attention learned.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:29:28 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 14:00:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Carrasco", "Sandra", ""], ["Llorca", "David Fern\u00e1ndez", ""], ["Sotelo", "Miguel \u00c1ngel", ""]]}, {"id": "2102.06362", "submitter": "Wenjing Chu", "authors": "Wenjing Chu", "title": "A Decentralized Approach Towards Responsible AI in Social Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For AI technology to fulfill its full promises, we must design effective\nmechanisms into the AI systems to support responsible AI behavior and curtail\npotential irresponsible use, e.g. in areas of privacy protection, human\nautonomy, robustness, and prevention of biases and discrimination in automated\ndecision making. In this paper, we present a framework that provides\ncomputational facilities for parties in a social ecosystem to produce the\ndesired responsible AI behaviors. To achieve this goal, we analyze AI systems\nat the architecture level and propose two decentralized cryptographic\nmechanisms for an AI system architecture: (1) using Autonomous Identity to\nempower human users, and (2) automating rules and adopting conventions within\nsocial institutions. We then propose a decentralized approach and outline the\nkey concepts and mechanisms based on Decentralized Identifier (DID) and\nVerifiable Credentials (VC) for a general-purpose computational infrastructure\nto realize these mechanisms. We argue the case that a decentralized approach is\nthe most promising path towards Responsible AI from both the computer science\nand social science perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:33:42 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Chu", "Wenjing", ""]]}, {"id": "2102.06474", "submitter": "Guangzhi Sun", "authors": "G. Sun, C. Zhang, P. C. Woodland", "title": "Transformer Language Models with LSTM-based Cross-utterance Information\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective incorporation of cross-utterance information has the potential\nto improve language models (LMs) for automatic speech recognition (ASR). To\nextract more powerful and robust cross-utterance representations for the\nTransformer LM (TLM), this paper proposes the R-TLM which uses hidden states in\na long short-term memory (LSTM) LM. To encode the cross-utterance information,\nthe R-TLM incorporates an LSTM module together with a segment-wise recurrence\nin some of the Transformer blocks. In addition to the LSTM module output, a\nshortcut connection using a fusion layer that bypasses the LSTM module is also\ninvestigated. The proposed system was evaluated on the AMI meeting corpus, the\nEval2000 and the RT03 telephone conversation evaluation sets. The best R-TLM\nachieved 0.9%, 0.6%, and 0.8% absolute WER reductions over the single-utterance\nTLM baseline, and 0.5%, 0.3%, 0.2% absolute WER reductions over a strong\ncross-utterance TLM baseline on the AMI evaluation set, Eval2000 and RT03\nrespectively. Improvements on Eval2000 and RT03 were further supported by\nsignificance tests. R-TLMs were found to have better LM scores on words where\nrecognition errors are more likely to occur. The R-TLM WER can be further\nreduced by interpolation with an LSTM-LM.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:12:29 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Sun", "G.", ""], ["Zhang", "C.", ""], ["Woodland", "P. C.", ""]]}, {"id": "2102.06486", "submitter": "Vanja Dosko\\v{c}", "authors": "Francesco Quinzan and Vanja Dosko\\v{c} and Andreas G\\\"obel and Tobias\n  Friedrich", "title": "Adaptive Sampling for Fast Constrained Maximization of Submodular\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several large-scale machine learning tasks, such as data summarization, can\nbe approached by maximizing functions that satisfy submodularity. These\noptimization problems often involve complex side constraints, imposed by the\nunderlying application. In this paper, we develop an algorithm with\npoly-logarithmic adaptivity for non-monotone submodular maximization under\ngeneral side constraints. The adaptive complexity of a problem is the minimal\nnumber of sequential rounds required to achieve the objective.\n  Our algorithm is suitable to maximize a non-monotone submodular function\nunder a $p$-system side constraint, and it achieves a $(p +\nO(\\sqrt{p}))$-approximation for this problem, after only poly-logarithmic\nadaptive rounds and polynomial queries to the valuation oracle function.\nFurthermore, our algorithm achieves a $(p + O(1))$-approximation when the given\nside constraint is a $p$-extendible system.\n  This algorithm yields an exponential speed-up, with respect to the\nadaptivity, over any other known constant-factor approximation algorithm for\nthis problem. It also competes with previous known results in terms of the\nquery complexity. We perform various experiments on various real-world\napplications. We find that, in comparison with commonly used heuristics, our\nalgorithm performs better on these instances.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:38:03 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Quinzan", "Francesco", ""], ["Dosko\u010d", "Vanja", ""], ["G\u00f6bel", "Andreas", ""], ["Friedrich", "Tobias", ""]]}, {"id": "2102.06518", "submitter": "Marc Hanussek", "authors": "Marc Hanussek, Falko K\\\"otter, Maximilien Kintz, Jens Drawehn", "title": "VitrAI -- Applying Explainable AI in the Real World", "comments": "Accepted for IntelliSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent progress in the field of Explainable Artificial Intelligence\n(XAI) and increasing use in practice, the need for an evaluation of different\nXAI methods and their explanation quality in practical usage scenarios arises.\nFor this purpose, we present VitrAI, which is a web-based service with the goal\nof uniformly demonstrating four different XAI algorithms in the context of\nthree real life scenarios and evaluating their performance and\ncomprehensibility for humans. This work reveals practical obstacles when\nadopting XAI methods and gives qualitative estimates on how well different\napproaches perform in said scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:44:39 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hanussek", "Marc", ""], ["K\u00f6tter", "Falko", ""], ["Kintz", "Maximilien", ""], ["Drawehn", "Jens", ""]]}, {"id": "2102.06525", "submitter": "Pramod Vadiraja", "authors": "Pramod Vadiraja, Christoph Peter Balada", "title": "Leveraging Reinforcement Learning for evaluating Robustness of KNN\n  Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The problem of finding K-nearest neighbors in the given dataset for a given\nquery point has been worked upon since several years. In very high dimensional\nspaces the K-nearest neighbor search (KNNS) suffers in terms of complexity in\ncomputation of high dimensional distances. With the issue of curse of\ndimensionality, it gets quite tedious to reliably bank on the results of\nvariety approximate nearest neighbor search approaches. In this paper, we\nsurvey some novel K-Nearest Neighbor Search approaches that tackles the problem\nof Search from the perspectives of computations, the accuracy of approximated\nresults and leveraging parallelism to speed-up computations. We attempt to\nderive a relationship between the true positive and false points for a given\nKNNS approach. Finally, in order to evaluate the robustness of a KNNS approach\nagainst adversarial points, we propose a generic Reinforcement Learning based\nframework for the same.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:10:58 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Vadiraja", "Pramod", ""], ["Balada", "Christoph Peter", ""]]}, {"id": "2102.06529", "submitter": "David Kadish", "authors": "David Kadish, Sebastian Risi, Anders Sundnes L{\\o}vlie", "title": "Improving Object Detection in Art Images Using Only Style Transfer", "comments": "8 pages, 7 figures, 3 tables, accepted at IJCNN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in object detection using deep learning neural\nnetworks, these neural networks still struggle to identify objects in art\nimages such as paintings and drawings. This challenge is known as the cross\ndepiction problem and it stems in part from the tendency of neural networks to\nprioritize identification of an object's texture over its shape. In this paper\nwe propose and evaluate a process for training neural networks to localize\nobjects - specifically people - in art images. We generate a large dataset for\ntraining and validation by modifying the images in the COCO dataset using AdaIn\nstyle transfer. This dataset is used to fine-tune a Faster R-CNN object\ndetection network, which is then tested on the existing People-Art testing\ndataset. The result is a significant improvement on the state of the art and a\nnew way forward for creating datasets to train neural networks to process art\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:48:46 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 21:58:09 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Kadish", "David", ""], ["Risi", "Sebastian", ""], ["L\u00f8vlie", "Anders Sundnes", ""]]}, {"id": "2102.06539", "submitter": "Huadong Liao", "authors": "Huadong Liao and Jiawei He", "title": "Jacobian Determinant of Normalizing Flows", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows learn a diffeomorphic mapping between the target and base\ndistribution, while the Jacobian determinant of that mapping forms another\nreal-valued function. In this paper, we show that the Jacobian determinant\nmapping is unique for the given distributions, hence the likelihood objective\nof flows has a unique global optimum. In particular, the likelihood for a class\nof flows is explicitly expressed by the eigenvalues of the auto-correlation\nmatrix of individual data point, and independent of the parameterization of\nneural network, which provides a theoretical optimal value of likelihood\nobjective and relates to probabilistic PCA. Additionally, Jacobian determinant\nis a measure of local volume change and is maximized when MLE is used for\noptimization. To stabilize normalizing flows training, it is required to\nmaintain a balance between the expansiveness and contraction of volume, meaning\nLipschitz constraint on the diffeomorphic mapping and its inverse. With these\ntheoretical results, several principles of designing normalizing flow were\nproposed. And numerical experiments on highdimensional datasets (such as\nCelebA-HQ 1024x1024) were conducted to show the improved stability of training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 14:09:28 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 06:56:35 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Liao", "Huadong", ""], ["He", "Jiawei", ""]]}, {"id": "2102.06554", "submitter": "Shen Zheng", "authors": "Kanya Mo (1), Shen Zheng (1), Xiwei Wang (1), Jinghua Wang (2),\n  Klaus-Dieter Schewe (1) ((1) Zhejiang University, UIUC Institute, (2)\n  University of Illinois at Urbana-Champaign)", "title": "Exploiting Spline Models for the Training of Fully Connected Layers in\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fully connected (FC) layer, one of the most fundamental modules in\nartificial neural networks (ANN), is often considered difficult and inefficient\nto train due to issues including the risk of overfitting caused by its large\namount of parameters. Based on previous work studying ANN from linear spline\nperspectives, we propose a spline-based approach that eases the difficulty of\ntraining FC layers. Given some dataset, we first obtain a continuous piece-wise\nlinear (CPWL) fit through spline methods such as multivariate adaptive\nregression spline (MARS). Next, we construct an ANN model from the linear\nspline model and continue to train the ANN model on the dataset using gradient\ndescent optimization algorithms. Our experimental results and theoretical\nanalysis show that our approach reduces the computational cost, accelerates the\nconvergence of FC layers, and significantly increases the interpretability of\nthe resulting model (FC layers) compared with standard ANN training with random\nparameter initialization followed by gradient descent optimizations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 14:36:55 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mo", "Kanya", ""], ["Zheng", "Shen", ""], ["Wang", "Xiwei", ""], ["Wang", "Jinghua", ""], ["Schewe", "Klaus-Dieter", ""]]}, {"id": "2102.06587", "submitter": "Rub\\'en Majadas", "authors": "Rub\\'en Majadas, Javier Garc\\'ia and Fernando Fern\\'andez", "title": "Disturbing Reinforcement Learning Agents with Corrupted Rewards", "comments": "This paper has been accepted in RAISA3 workshop celebrated in ECAI\n  2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms have led to recent successes in\nsolving complex games, such as Atari or Starcraft, and to a huge impact in\nreal-world applications, such as cybersecurity or autonomous driving. In the\nside of the drawbacks, recent works have shown how the performance of RL\nalgorithms decreases under the influence of soft changes in the reward\nfunction. However, little work has been done about how sensitive these\ndisturbances are depending on the aggressiveness of the attack and the learning\nexploration strategy. In this paper, we propose to fill this gap in the\nliterature analyzing the effects of different attack strategies based on reward\nperturbations, and studying the effect in the learner depending on its\nexploration strategy. In order to explain all the behaviors, we choose a\nsub-class of MDPs: episodic, stochastic goal-only-rewards MDPs, and in\nparticular, an intelligible grid domain as a benchmark. In this domain, we\ndemonstrate that smoothly crafting adversarial rewards are able to mislead the\nlearner, and that using low exploration probability values, the policy learned\nis more robust to corrupt rewards. Finally, in the proposed learning scenario,\na counterintuitive result arises: attacking at each learning episode is the\nlowest cost attack strategy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:53:48 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Majadas", "Rub\u00e9n", ""], ["Garc\u00eda", "Javier", ""], ["Fern\u00e1ndez", "Fernando", ""]]}, {"id": "2102.06589", "submitter": "Alec Farid", "authors": "Alec Farid and Anirudha Majumdar", "title": "PAC-BUS: Meta-Learning Bounds via PAC-Bayes and Uniform Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are motivated by the problem of providing strong generalization guarantees\nin the context of meta-learning. Existing generalization bounds are either\nchallenging to evaluate or provide vacuous guarantees in even relatively simple\nsettings. We derive a probably approximately correct (PAC) bound for\ngradient-based meta-learning using two different generalization frameworks in\norder to deal with the qualitatively different challenges of generalization at\nthe \"base\" and \"meta\" levels. We employ bounds for uniformly stable algorithms\nat the base level and bounds from the PAC-Bayes framework at the meta level.\nThe result is a novel PAC-bound that is tighter when the base learner adapts\nquickly, which is precisely the goal of meta-learning. We show that our bound\nprovides a tighter guarantee than other bounds on a toy non-convex problem on\nthe unit sphere and a text-based classification example. We also present a\npractical regularization scheme motivated by the bound in settings where the\nbound is loose and demonstrate improved performance over baseline techniques.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:57:45 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 15:14:17 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Farid", "Alec", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2102.06602", "submitter": "Paramveer Dhillon", "authors": "Paramveer Dhillon and Sinan Aral", "title": "Modeling Dynamic User Interests: A Neural Matrix Factorization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been significant interest in understanding users'\nonline content consumption patterns. But, the unstructured, high-dimensional,\nand dynamic nature of such data makes extracting valuable insights challenging.\nHere we propose a model that combines the simplicity of matrix factorization\nwith the flexibility of neural networks to efficiently extract nonlinear\npatterns from massive text data collections relevant to consumers' online\nconsumption patterns. Our model decomposes a user's content consumption journey\ninto nonlinear user and content factors that are used to model their dynamic\ninterests. This natural decomposition allows us to summarize each user's\ncontent consumption journey with a dynamic probabilistic weighting over a set\nof underlying content attributes. The model is fast to estimate, easy to\ninterpret and can harness external data sources as an empirical prior. These\nadvantages make our method well suited to the challenges posed by modern\ndatasets. We use our model to understand the dynamic news consumption interests\nof Boston Globe readers over five years. Thorough qualitative studies,\nincluding a crowdsourced evaluation, highlight our model's ability to\naccurately identify nuanced and coherent consumption patterns. These results\nare supported by our model's superior and robust predictive performance over\nseveral competitive baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:24:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Dhillon", "Paramveer", ""], ["Aral", "Sinan", ""]]}, {"id": "2102.06607", "submitter": "Sabrina Kirrane", "authors": "Sabrina Kirrane", "title": "Intelligent Software Web Agents: A Gap Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic web technologies have shown their effectiveness, especially when it\ncomes to knowledge representation, reasoning, and data integration. However,\nthe original semantic web vision, whereby machine readable web data could be\nautomatically actioned upon by intelligent software web agents, has yet to be\nrealised. In order to better understand the existing technological\nopportunities and challenges, in this paper we examine the status quo in terms\nof intelligent software web agents, guided by research with respect to\nrequirements and architectural components, coming from the agents community. We\nuse the identified requirements to both further elaborate on the semantic web\nagent motivating use case scenario, and to summarise different perspectives on\nthe requirements from the semantic web agent literature. We subsequently\npropose a hybrid semantic web agent architecture, and use the various\ncomponents and subcomponents in order to provide a focused discussion on the\nrole played by existing semantic web standards and community activities.\nFinally, we highlight open research opportunities and challenges and take a\nbroader perspective of the research by discussing the potential for intelligent\nsoftware web agents as an enabling technology for emerging domains, such as\ndigital assistants, cloud computing, and the internet of things.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:32:02 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 11:23:15 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 11:35:30 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kirrane", "Sabrina", ""]]}, {"id": "2102.06621", "submitter": "Alex Kogan", "authors": "Dave Dice and Alex Kogan", "title": "Optimizing Inference Performance of Transformers on CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Transformer architecture revolutionized the field of natural language\nprocessing (NLP). Transformers-based models (e.g., BERT) power many important\nWeb services, such as search, translation, question-answering, etc. While\nenormous research attention is paid to the training of those models, relatively\nlittle efforts are made to improve their inference performance. This paper\ncomes to address this gap by presenting an empirical analysis of scalability\nand performance of inferencing a Transformer-based model on CPUs. Focusing on\nthe highly popular BERT model, we identify key components of the Transformer\narchitecture where the bulk of the computation happens, and propose three\noptimizations to speed them up. The optimizations are evaluated using the\ninference benchmark from HuggingFace, and are shown to achieve the speedup of\nup to x2.37. The considered optimizations do not require any changes to the\nimplementation of the models nor affect their accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:01:35 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 22:30:35 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 16:54:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dice", "Dave", ""], ["Kogan", "Alex", ""]]}, {"id": "2102.06634", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Viet-Man Le and Andrei Popescu and Mathias Uta\n  and Thi Ngoc Trang Tran and M\\\"usl\\\"uum Atas", "title": "An Overview of Recommender Systems and Machine Learning in Feature\n  Modeling and Configuration", "comments": "Proceedings of ACM Vamos 2021", "journal-ref": null, "doi": "10.1145/3442391.3442408", "report-no": null, "categories": "cs.IR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems support decisions in various domains ranging from simple\nitems such as books and movies to more complex items such as financial\nservices, telecommunication equipment, and software systems. In this context,\nrecommendations are determined, for example, on the basis of analyzing the\npreferences of similar users. In contrast to simple items which can be\nenumerated in an item catalog, complex items have to be represented on the\nbasis of variability models (e.g., feature models) since a complete enumeration\nof all possible configurations is infeasible and would trigger significant\nperformance issues. In this paper, we give an overview of a potential new line\nof research which is related to the application of recommender systems and\nmachine learning techniques in feature modeling and configuration. In this\ncontext, we give examples of the application of recommender systems and machine\nlearning and discuss future research issues.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:21:36 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Felfernig", "Alexander", ""], ["Le", "Viet-Man", ""], ["Popescu", "Andrei", ""], ["Uta", "Mathias", ""], ["Tran", "Thi Ngoc Trang", ""], ["Atas", "M\u00fcsl\u00fcum", ""]]}, {"id": "2102.06690", "submitter": "Youngjun Cho", "authors": "Youngjun Cho", "title": "Rethinking Eye-blink: Assessing Task Difficulty through Physiological\n  Representation of Spontaneous Blinking", "comments": "[Accepted version] In Proceedings of CHI Conference on Human Factors\n  in Computing Systems (CHI '21), May 8-13, 2021, Yokohama, Japan. ACM, New\n  York, NY, USA. 19 Pages. https://doi.org/10.1145/3411764.3445577", "journal-ref": null, "doi": "10.1145/3411764.3445577", "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous assessment of task difficulty and mental workload is essential in\nimproving the usability and accessibility of interactive systems. Eye tracking\ndata has often been investigated to achieve this ability, with reports on the\nlimited role of standard blink metrics. Here, we propose a new approach to the\nanalysis of eye-blink responses for automated estimation of task difficulty.\nThe core module is a time-frequency representation of eye-blink, which aims to\ncapture the richness of information reflected on blinking. In our first study,\nwe show that this method significantly improves the sensitivity to task\ndifficulty. We then demonstrate how to form a framework where the represented\npatterns are analyzed with multi-dimensional Long Short-Term Memory recurrent\nneural networks for their non-linear mapping onto difficulty-related\nparameters. This framework outperformed other methods that used hand-engineered\nfeatures. This approach works with any built-in camera, without requiring\nspecialized devices. We conclude by discussing how Rethinking Eye-blink can\nbenefit real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:47:13 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Cho", "Youngjun", ""]]}, {"id": "2102.06700", "submitter": "Nikola Jovanovi\\'c", "authors": "Nikola Jovanovi\\'c, Mislav Balunovi\\'c, Maximilian Baader, Martin\n  Vechev", "title": "Certified Defenses: Why Tighter Relaxations May Hurt Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Certified defenses based on convex relaxations are an established technique\nfor training provably robust models. The key component is the choice of\nrelaxation, varying from simple intervals to tight polyhedra. Paradoxically,\nhowever, training with tighter relaxations can often lead to worse certified\nrobustness. The poor understanding of this paradox has forced recent\nstate-of-the-art certified defenses to focus on designing various heuristics in\norder to mitigate its effects. In contrast, in this paper we study the\nunderlying causes and show that tightness alone may not be the determining\nfactor. Concretely, we identify two key properties of relaxations that impact\ntraining dynamics: continuity and sensitivity. Our extensive experimental\nevaluation demonstrates that these two factors, observed alongside tightness,\nexplain the drop in certified robustness for popular relaxations. Further, we\ninvestigate the possibility of designing and training with relaxations that are\ntight, continuous and not sensitive. We believe the insights of this work can\nhelp drive the principled discovery of new and effective certified defense\nmechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:57:24 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 17:58:02 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Jovanovi\u0107", "Nikola", ""], ["Balunovi\u0107", "Mislav", ""], ["Baader", "Maximilian", ""], ["Vechev", "Martin", ""]]}, {"id": "2102.06729", "submitter": "Joris Gu\\'erin", "authors": "Igor Garcia Ballhausen Sampaio and Luigy Machaca and Jos\\'e Viterbo\n  and Joris Gu\\'erin", "title": "A novel method for object detection using deep learning and CAD models", "comments": "8 pages, 4 figures, 2 tables, To appear in the proceedings of the\n  23rd International Conference on Enterprise Information Systems (ICEIS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object Detection (OD) is an important computer vision problem for industry,\nwhich can be used for quality control in the production lines, among other\napplications. Recently, Deep Learning (DL) methods have enabled practitioners\nto train OD models performing well on complex real world images. However, the\nadoption of these models in industry is still limited by the difficulty and the\nsignificant cost of collecting high quality training datasets. On the other\nhand, when applying OD to the context of production lines, CAD models of the\nobjects to be detected are often available. In this paper, we introduce a fully\nautomated method that uses a CAD model of an object and returns a fully trained\nOD model for detecting this object. To do this, we created a Blender script\nthat generates realistic labeled datasets of images containing the object,\nwhich are then used for training the OD model. The method is validated\nexperimentally on two practical examples, showing that this approach can\ngenerate OD models performing well on real images, while being trained only on\nsynthetic images. The proposed method has potential to facilitate the adoption\nof object detection models in industry as it is easy to adapt for new objects\nand highly flexible. Hence, it can result in significant costs reduction, gains\nin productivity and improved products quality.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:19:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sampaio", "Igor Garcia Ballhausen", ""], ["Machaca", "Luigy", ""], ["Viterbo", "Jos\u00e9", ""], ["Gu\u00e9rin", "Joris", ""]]}, {"id": "2102.06732", "submitter": "Jiapeng Wang", "authors": "Jiapeng Wang, Chongyu Liu, Lianwen Jin, Guozhi Tang, Jiaxin Zhang,\n  Shuaitao Zhang, Qianying Wang, Yaqiang Wu, Mingxiang Cai", "title": "Towards Robust Visual Information Extraction in Real World: New Dataset\n  and Novel Solution", "comments": "8 pages, 5 figures, to be published in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual information extraction (VIE) has attracted considerable attention\nrecently owing to its various advanced applications such as document\nunderstanding, automatic marking and intelligent education. Most existing works\ndecoupled this problem into several independent sub-tasks of text spotting\n(text detection and recognition) and information extraction, which completely\nignored the high correlation among them during optimization. In this paper, we\npropose a robust visual information extraction system (VIES) towards real-world\nscenarios, which is a unified end-to-end trainable framework for simultaneous\ntext detection, recognition and information extraction by taking a single\ndocument image as input and outputting the structured information.\nSpecifically, the information extraction branch collects abundant visual and\nsemantic representations from text spotting for multimodal feature fusion and\nconversely, provides higher-level semantic clues to contribute to the\noptimization of text spotting. Moreover, regarding the shortage of public\nbenchmarks, we construct a fully-annotated dataset called EPHOIE\n(https://github.com/HCIILAB/EPHOIE), which is the first Chinese benchmark for\nboth text spotting and visual information extraction. EPHOIE consists of 1,494\nimages of examination paper head with complex layouts and background, including\na total of 15,771 Chinese handwritten or printed text instances. Compared with\nthe state-of-the-art methods, our VIES shows significant superior performance\non the EPHOIE dataset and achieves a 9.01% F-score gain on the widely used\nSROIE dataset under the end-to-end scenario.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 11:05:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Jiapeng", ""], ["Liu", "Chongyu", ""], ["Jin", "Lianwen", ""], ["Tang", "Guozhi", ""], ["Zhang", "Jiaxin", ""], ["Zhang", "Shuaitao", ""], ["Wang", "Qianying", ""], ["Wu", "Yaqiang", ""], ["Cai", "Mingxiang", ""]]}, {"id": "2102.06741", "submitter": "Vivek Veeriah", "authors": "Vivek Veeriah, Tom Zahavy, Matteo Hessel, Zhongwen Xu, Junhyuk Oh,\n  Iurii Kemaev, Hado van Hasselt, David Silver, Satinder Singh", "title": "Discovery of Options via Meta-Learned Subgoals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstractions in the form of options have been shown to help\nreinforcement learning (RL) agents learn faster. However, despite prior work on\nthis topic, the problem of discovering options through interaction with an\nenvironment remains a challenge. In this paper, we introduce a novel\nmeta-gradient approach for discovering useful options in multi-task RL\nenvironments. Our approach is based on a manager-worker decomposition of the RL\nagent, in which a manager maximises rewards from the environment by learning a\ntask-dependent policy over both a set of task-independent discovered-options\nand primitive actions. The option-reward and termination functions that define\na subgoal for each option are parameterised as neural networks and trained via\nmeta-gradients to maximise their usefulness. Empirical analysis on gridworld\nand DeepMind Lab tasks show that: (1) our approach can discover meaningful and\ndiverse temporally-extended options in multi-task RL domains, (2) the\ndiscovered options are frequently used by the agent while learning to solve the\ntraining tasks, and (3) that the discovered options help a randomly initialised\nmanager learn faster in completely new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:50:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Veeriah", "Vivek", ""], ["Zahavy", "Tom", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Oh", "Junhyuk", ""], ["Kemaev", "Iurii", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}, {"id": "2102.06743", "submitter": "Joshua Friedman", "authors": "Joshua S. Friedman", "title": "Edge Minimizing the Student Conflict Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many schools, courses are given in sections. Prior to timetabling students\nneed to be assigned to individual sections. We give a hybrid approximation\nsectioning algorithm that minimizes the number of edges (potential conflicts)\nin the student conflict graph (SCG). We start with a greedy algorithm to obtain\na starting solution and then continue with a constraint programming based\nalgorithm (CP-SAT) that reduces the number of edges. We apply the sectioning\nalgorithm to a highly constrained timetabling model which we specify.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 19:54:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Friedman", "Joshua S.", ""]]}, {"id": "2102.06747", "submitter": "Raphael Labaca-Castro", "authors": "Raphael Labaca-Castro, Luis Mu\\~noz-Gonz\\'alez, Feargus Pendlebury,\n  Gabi Dreo Rodosek, Fabio Pierazzi, Lorenzo Cavallaro", "title": "Universal Adversarial Perturbations for Malware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning classification models are vulnerable to adversarial examples\n-- effective input-specific perturbations that can manipulate the model's\noutput. Universal Adversarial Perturbations (UAPs), which identify noisy\npatterns that generalize across the input space, allow the attacker to greatly\nscale up the generation of these adversarial examples. Although UAPs have been\nexplored in application domains beyond computer vision, little is known about\ntheir properties and implications in the specific context of realizable\nattacks, such as malware, where attackers must reason about satisfying\nchallenging problem-space constraints.\n  In this paper, we explore the challenges and strengths of UAPs in the context\nof malware classification. We generate sequences of problem-space\ntransformations that induce UAPs in the corresponding feature-space embedding\nand evaluate their effectiveness across threat models that consider a varying\ndegree of realistic attacker knowledge. Additionally, we propose adversarial\ntraining-based mitigations using knowledge derived from the problem-space\ntransformations, and compare against alternative feature-space defenses. Our\nexperiments limit the effectiveness of a white box Android evasion attack to\n~20 % at the cost of 3 % TPR at 1 % FPR. We additionally show how our method\ncan be adapted to more restrictive application domains such as Windows malware.\n  We observe that while adversarial training in the feature space must deal\nwith large and often unconstrained regions, UAPs in the problem space identify\nspecific vulnerabilities that allow us to harden a classifier more effectively,\nshifting the challenges and associated cost of identifying new universal\nadversarial transformations back to the attacker.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:06:10 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Labaca-Castro", "Raphael", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Pendlebury", "Feargus", ""], ["Rodosek", "Gabi Dreo", ""], ["Pierazzi", "Fabio", ""], ["Cavallaro", "Lorenzo", ""]]}, {"id": "2102.06761", "submitter": "Chuizheng Meng", "authors": "Chuizheng Meng, Loc Trinh, Nan Xu, Yan Liu", "title": "MIMIC-IF: Interpretability and Fairness Evaluation of Deep Learning\n  Models on MIMIC-IV Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent release of large-scale healthcare datasets has greatly propelled\nthe research of data-driven deep learning models for healthcare applications.\nHowever, due to the nature of such deep black-boxed models, concerns about\ninterpretability, fairness, and biases in healthcare scenarios where human\nlives are at stake call for a careful and thorough examinations of both\ndatasets and models. In this work, we focus on MIMIC-IV (Medical Information\nMart for Intensive Care, version IV), the largest publicly available healthcare\ndataset, and conduct comprehensive analyses of dataset representation bias as\nwell as interpretability and prediction fairness of deep learning models for\nin-hospital mortality prediction. In terms of interpretabilty, we observe that\n(1) the best performing interpretability method successfully identifies\ncritical features for mortality prediction on various prediction models; (2)\ndemographic features are important for prediction. In terms of fairness, we\nobserve that (1) there exists disparate treatment in prescribing mechanical\nventilation among patient groups across ethnicity, gender and age; (2) all of\nthe studied mortality predictors are generally fair while the IMV-LSTM\n(Interpretable Multi-Variable Long Short-Term Memory) model provides the most\naccurate and unbiased predictions across all protected groups. We further draw\nconcrete connections between interpretability methods and fairness metrics by\nshowing how feature importance from interpretability methods can be beneficial\nin quantifying potential disparities in mortality predictors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:28:06 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Meng", "Chuizheng", ""], ["Trinh", "Loc", ""], ["Xu", "Nan", ""], ["Liu", "Yan", ""]]}, {"id": "2102.06764", "submitter": "Vedant Nanda", "authors": "Valeriia Cherepanova and Vedant Nanda and Micah Goldblum and John P.\n  Dickerson and Tom Goldstein", "title": "Technical Challenges for Training Fair Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms have been widely deployed across applications,\nmany concerns have been raised over the fairness of their predictions,\nespecially in high stakes settings (such as facial recognition and medical\nimaging). To respond to these concerns, the community has proposed and\nformalized various notions of fairness as well as methods for rectifying unfair\nbehavior. While fairness constraints have been studied extensively for\nclassical models, the effectiveness of methods for imposing fairness on deep\nneural networks is unclear. In this paper, we observe that these large models\noverfit to fairness objectives, and produce a range of unintended and\nundesirable consequences. We conduct our experiments on both facial recognition\nand automated medical diagnosis datasets using state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:36:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cherepanova", "Valeriia", ""], ["Nanda", "Vedant", ""], ["Goldblum", "Micah", ""], ["Dickerson", "John P.", ""], ["Goldstein", "Tom", ""]]}, {"id": "2102.06790", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Yongduo Sui, Xuxi Chen, Aston Zhang, Zhangyang Wang", "title": "A Unified Lottery Ticket Hypothesis for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With graphs rapidly growing in size and deeper graph neural networks (GNNs)\nemerging, the training and inference of GNNs become increasingly expensive.\nExisting network weight pruning algorithms cannot address the main space and\ncomputational bottleneck in GNNs, caused by the size and connectivity of the\ngraph. To this end, this paper first presents a unified GNN sparsification\n(UGS) framework that simultaneously prunes the graph adjacency matrix and the\nmodel weights, for effectively accelerating GNN inference on large-scale\ngraphs. Leveraging this new tool, we further generalize the recently popular\nlottery ticket hypothesis to GNNs for the first time, by defining a graph\nlottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,\nwhich can be jointly identified from the original GNN and the full dense graph\nby iteratively applying UGS. Like its counterpart in convolutional neural\nnetworks, GLT can be trained in isolation to match the performance of training\nwith the full model and graph, and can be drawn from both randomly initialized\nand self-supervised pre-trained GNNs. Our proposal has been experimentally\nverified across various GNN architectures and diverse tasks, on both\nsmall-scale graph datasets (Cora, Citeseer and PubMed), and large-scale\ndatasets from the challenging Open Graph Benchmark (OGB). Specifically, for\nnode classification, our found GLTs achieve the same accuracies with 20%~98%\nMACs saving on small graphs and 25%~85% MACs saving on large ones. For link\nprediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph\ndatasets, respectively, without compromising predictive performance. Codes\navailable at https://github.com/VITA-Group/Unified-LTH-GNN.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 21:52:43 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:45:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chen", "Tianlong", ""], ["Sui", "Yongduo", ""], ["Chen", "Xuxi", ""], ["Zhang", "Aston", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2102.06793", "submitter": "Ernest Davis", "authors": "Ernest Davis", "title": "Unanswerable Questions about Images and Texts", "comments": "15 pages, 4 figures", "journal-ref": "Frontiers in Artificial Intelligence: Language and Computation.\n  July 2020", "doi": "10.3389/frai.2020.00051", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Questions about a text or an image that cannot be answered raise distinctive\nissues for an AI. This note discusses the problem of unanswerable questions in\nVQA (visual question answering), in QA (visual question answering), and in AI\ngenerally.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 17:56:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Davis", "Ernest", ""]]}, {"id": "2102.06794", "submitter": "Yaofeng Desmond Zhong", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Extending Lagrangian and Hamiltonian Neural Networks with Differentiable\n  Contact Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incorporation of appropriate inductive bias plays a critical role in\nlearning dynamics from data. A growing body of work has been exploring ways to\nenforce energy conservation in the learned dynamics by encoding Lagrangian or\nHamiltonian dynamics into the neural network architecture. These existing\napproaches are based on differential equations, which do not allow\ndiscontinuity in the states and thereby limit the class of systems one can\nlearn. However, in reality, most physical systems, such as legged robots and\nrobotic manipulators, involve contacts and collisions, which introduce\ndiscontinuities in the states. In this paper, we introduce a differentiable\ncontact model, which can capture contact mechanics: frictionless/frictional, as\nwell as elastic/inelastic. This model can also accommodate inequality\nconstraints, such as limits on the joint angles. The proposed contact model\nextends the scope of Lagrangian and Hamiltonian neural networks by allowing\nsimultaneous learning of contact and system properties. We demonstrate this\nframework on a series of challenging 2D and 3D physical systems with different\ncoefficients of restitution and friction. The learned dynamics can be used as a\ndifferentiable physics simulator for downstream gradient-based optimization\ntasks, such as planning and control.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:02:41 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:57:44 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2102.06800", "submitter": "Jacob Dineen", "authors": "Jacob Dineen, A S M Ahsan-Ul Haque, Matthew Bielskas", "title": "Reinforcement Learning For Data Poisoning on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-80387-2_14", "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial Machine Learning has emerged as a substantial subfield of\nComputer Science due to a lack of robustness in the models we train along with\ncrowdsourcing practices that enable attackers to tamper with data. In the last\ntwo years, interest has surged in adversarial attacks on graphs yet the Graph\nClassification setting remains nearly untouched. Since a Graph Classification\ndataset consists of discrete graphs with class labels, related work has forgone\ndirect gradient optimization in favor of an indirect Reinforcement Learning\napproach. We will study the novel problem of Data Poisoning (training time)\nattack on Neural Networks for Graph Classification using Reinforcement Learning\nAgents.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:34:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dineen", "Jacob", ""], ["Haque", "A S M Ahsan-Ul", ""], ["Bielskas", "Matthew", ""]]}, {"id": "2102.06808", "submitter": "Piotr Kozakowski", "authors": "Piotr Kozakowski, Miko{\\l}aj Pacek, Piotr Mi{\\l}o\\'s", "title": "Robust and Efficient Planning using Adaptive Entropy Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the Adaptive EntropyTree Search (ANTS) algorithm.\nANTS builds on recent successes of maximum entropy planning while mitigating\nits arguably major drawback - sensitivity to the temperature setting. We endow\nANTS with a mechanism, which adapts the temperature to match a given range of\naction selection entropy in the nodes of the planning tree. With this\nmechanism, the ANTS planner enjoys remarkable hyper-parameter robustness,\nachieves high scores on the Atari benchmark, and is a capable component of a\nplanning-learning loop akin to AlphaZero. We believe that all these features\nmake ANTS a compelling choice for a general planner for complex tasks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:54:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kozakowski", "Piotr", ""], ["Pacek", "Miko\u0142aj", ""], ["Mi\u0142o\u015b", "Piotr", ""]]}, {"id": "2102.06810", "submitter": "Yuandong Tian", "authors": "Yuandong Tian and Xinlei Chen and Surya Ganguli", "title": "Understanding self-supervised Learning Dynamics without Contrastive\n  Pairs", "comments": "ICML 2021 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While contrastive approaches of self-supervised learning (SSL) learn\nrepresentations by minimizing the distance between two augmented views of the\nsame data point (positive pairs) and maximizing views from different data\npoints (negative pairs), recent \\emph{non-contrastive} SSL (e.g., BYOL and\nSimSiam) show remarkable performance {\\it without} negative pairs, with an\nextra learnable predictor and a stop-gradient operation. A fundamental question\narises: why do these methods not collapse into trivial representations? We\nanswer this question via a simple theoretical study and propose a novel\napproach, DirectPred, that \\emph{directly} sets the linear predictor based on\nthe statistics of its inputs, without gradient training. On ImageNet, it\nperforms comparably with more complex two-layer non-linear predictors that\nemploy BatchNorm and outperforms a linear predictor by $2.5\\%$ in 300-epoch\ntraining (and $5\\%$ in 60-epoch). DirectPred is motivated by our theoretical\nstudy of the nonlinear learning dynamics of non-contrastive SSL in simple\nlinear networks. Our study yields conceptual insights into how non-contrastive\nSSL methods learn, how they avoid representational collapse, and how multiple\nfactors, like predictor networks, stop-gradients, exponential moving averages,\nand weight decay all come into play. Our simple theory recapitulates the\nresults of real-world ablation studies in both STL-10 and ImageNet. Code is\nreleased\\footnote{\\url{https://github.com/facebookresearch/luckmatters/tree/master/ssl}}.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:57:28 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 16:51:55 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tian", "Yuandong", ""], ["Chen", "Xinlei", ""], ["Ganguli", "Surya", ""]]}, {"id": "2102.06822", "submitter": "Dominik Zietlow", "authors": "Dominik Zietlow, Michal Rolinek, Georg Martius", "title": "Demystifying Inductive Biases for $\\beta$-VAE Based Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of $\\beta$-Variational-Autoencoders ($\\beta$-VAEs) and their\nvariants on learning semantically meaningful, disentangled representations is\nunparalleled. On the other hand, there are theoretical arguments suggesting the\nimpossibility of unsupervised disentanglement. In this work, we shed light on\nthe inductive bias responsible for the success of VAE-based architectures. We\nshow that in classical datasets the structure of variance, induced by the\ngenerating factors, is conveniently aligned with the latent directions fostered\nby the VAE objective. This builds the pivotal bias on which the disentangling\nabilities of VAEs rely. By small, elaborate perturbations of existing datasets,\nwe hide the convenient correlation structure that is easily exploited by a\nvariety of architectures. To demonstrate this, we construct modified versions\nof standard datasets in which (i) the generative factors are perfectly\npreserved; (ii) each image undergoes a mild transformation causing a small\nchange of variance; (iii) the leading \\textbf{VAE-based disentanglement\narchitectures fail to produce disentangled representations whilst the\nperformance of a non-variational method remains unchanged}. The construction of\nour modifications is nontrivial and relies on recent progress on mechanistic\nunderstanding of $\\beta$-VAEs and their connection to PCA. We strengthen that\nconnection by providing additional insights that are of stand-alone interest.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 23:57:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zietlow", "Dominik", ""], ["Rolinek", "Michal", ""], ["Martius", "Georg", ""]]}, {"id": "2102.06849", "submitter": "Harikrishna Narasimhan", "authors": "Andrew Cotter, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit\n  Singh Rawat, Sashank J. Reddi, Yichen Zhou", "title": "Distilling Double Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation is the technique of training a \"student\" model based on examples\nthat are labeled by a separate \"teacher\" model, which itself is trained on a\nlabeled dataset. The most common explanations for why distillation \"works\" are\npredicated on the assumption that student is provided with \\emph{soft} labels,\n\\eg probabilities or confidences, from the teacher model. In this work, we\nshow, that, even when the teacher model is highly overparameterized, and\nprovides \\emph{hard} labels, using a very large held-out unlabeled dataset to\ntrain the student model can result in a model that outperforms more\n\"traditional\" approaches.\n  Our explanation for this phenomenon is based on recent work on \"double\ndescent\". It has been observed that, once a model's complexity roughly exceeds\nthe amount required to memorize the training data, increasing the complexity\n\\emph{further} can, counterintuitively, result in \\emph{better} generalization.\nResearchers have identified several settings in which it takes place, while\nothers have made various attempts to explain it (thus far, with only partial\nsuccess). In contrast, we avoid these questions, and instead seek to\n\\emph{exploit} this phenomenon by demonstrating that a highly-overparameterized\nteacher can avoid overfitting via double descent, while a student trained on a\nlarger independent dataset labeled by this teacher will avoid overfitting due\nto the size of its training set.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 02:26:48 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cotter", "Andrew", ""], ["Menon", "Aditya Krishna", ""], ["Narasimhan", "Harikrishna", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Zhou", "Yichen", ""]]}, {"id": "2102.06854", "submitter": "Takuma Oda", "authors": "Takuma Oda", "title": "Equilibrium Inverse Reinforcement Learning for Ride-hailing Vehicle\n  Network", "comments": "Accepted at WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous mobile computing have enabled ride-hailing services to collect\nvast amounts of behavioral data of riders and drivers and optimize supply and\ndemand matching in real time. While these mobility service providers have some\ndegree of control over the market by assigning vehicles to requests, they need\nto deal with the uncertainty arising from self-interested driver behavior since\nworkers are usually free to drive when they are not assigned tasks. In this\nwork, we formulate the problem of passenger-vehicle matching in a sparsely\nconnected graph and proposed an algorithm to derive an equilibrium policy in a\nmulti-agent environment. Our framework combines value iteration methods to\nestimate the optimal policy given expected state visitation and policy\npropagation to compute multi-agent state visitation frequencies. Furthermore,\nwe developed a method to learn the driver's reward function transferable to an\nenvironment with significantly different dynamics from training data. We\nevaluated the robustness to changes in spatio-temporal supply-demand\ndistributions and deterioration in data quality using a real-world taxi\ntrajectory dataset; our approach significantly outperforms several baselines in\nterms of imitation accuracy. The computational time required to obtain an\nequilibrium policy shared by all vehicles does not depend on the number of\nagents, and even on the scale of real-world services, it takes only a few\nseconds on a single CPU.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 03:18:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Oda", "Takuma", ""]]}, {"id": "2102.06858", "submitter": "Andrew Li", "authors": "Pashootan Vaezipoor, Andrew Li, Rodrigo Toro Icarte, Sheila McIlraith", "title": "LTL2Action: Generalizing LTL Instructions for Multi-Task RL", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of teaching a deep reinforcement learning (RL) agent\nto follow instructions in multi-task environments. Instructions are expressed\nin a well-known formal language -- linear temporal logic (LTL) -- and can\nspecify a diversity of complex, temporally extended behaviours, including\nconditionals and alternative realizations. Our proposed learning approach\nexploits the compositional syntax and the semantics of LTL, enabling our RL\nagent to learn task-conditioned policies that generalize to new instructions,\nnot observed during training. To reduce the overhead of learning LTL semantics,\nwe introduce an environment-agnostic LTL pretraining scheme which improves\nsample-efficiency in downstream environments. Experiments on discrete and\ncontinuous domains target combinatorial task sets of up to $\\sim10^{39}$ unique\ntasks and demonstrate the strength of our approach in learning to solve\n(unseen) tasks, given LTL instructions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 04:05:46 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 23:08:21 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 08:14:39 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Vaezipoor", "Pashootan", ""], ["Li", "Andrew", ""], ["Icarte", "Rodrigo Toro", ""], ["McIlraith", "Sheila", ""]]}, {"id": "2102.06862", "submitter": "Alex Tong Lin", "authors": "Alex Tong Lin, Wuchen Li, Stanley Osher, Guido Montufar", "title": "Wasserstein Proximal of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for training generative adversarial networks by\napplying the Wasserstein-2 metric proximal on the generators. The approach is\nbased on Wasserstein information geometry. It defines a parametrization\ninvariant natural gradient by pulling back optimal transport structures from\nprobability space to parameter space. We obtain easy-to-implement iterative\nregularizers for the parameter updates of implicit deep generative models. Our\nexperiments demonstrate that this method improves the speed and stability of\ntraining in terms of wall-clock time and Fr\\'echet Inception Distance.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 05:29:37 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lin", "Alex Tong", ""], ["Li", "Wuchen", ""], ["Osher", "Stanley", ""], ["Montufar", "Guido", ""]]}, {"id": "2102.06875", "submitter": "Yifang Chen", "authors": "Yifang Chen, Simon S. Du, Kevin Jamieson", "title": "Improved Corruption Robust Algorithms for Episodic Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study episodic reinforcement learning under unknown adversarial\ncorruptions in both the rewards and the transition probabilities of the\nunderlying system. We propose new algorithms which, compared to the existing\nresults in (Lykouris et al., 2020), achieve strictly better regret bounds in\nterms of total corruptions for the tabular setting. To be specific, firstly,\nour regret bounds depend on more precise numerical values of total rewards\ncorruptions and transition corruptions, instead of only on the total number of\ncorrupted episodes. Secondly, our regret bounds are the first of their kind in\nthe reinforcement learning setting to have the number of corruptions show up\nadditively with respect to $\\min\\{\\sqrt{T}, \\text{PolicyGapComplexity}\\}$\nrather than multiplicatively. Our results follow from a general algorithmic\nframework that combines corruption-robust policy elimination meta-algorithms,\nand plug-in reward-free exploration sub-algorithms. Replacing the\nmeta-algorithm or sub-algorithm may extend the framework to address other\ncorrupted settings with potentially more structure.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 07:04:23 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 17:34:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Chen", "Yifang", ""], ["Du", "Simon S.", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2102.06884", "submitter": "Ali Raza", "authors": "Ali Raza, Lachlan Hardy, Erin Roehrer, Soonja Yeom, Byeong ho Kang", "title": "GPSPiChain-Blockchain based Self-Contained Family Security System in\n  Smart Home", "comments": "15 pages, 6 figures, accepted in The 4th International Workshop on\n  Smart Simulation and Modelling for Complex Systems, IJCAI2019", "journal-ref": null, "doi": null, "report-no": "SSMCS2019-13", "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With advancements in technology, personal computing devices are better\nadapted for and further integrated into people's lives and homes. The\nintegration of technology into society also results in an increasing desire to\ncontrol who and what has access to sensitive information, especially for\nvulnerable people including children and the elderly. With blockchain coming in\nto the picture as a technology that can revolutionise the world, it is now\npossible to have an immutable audit trail of locational data over time. By\ncontrolling the process through inexpensive equipment in the home, it is\npossible to control whom has access to such personal data. This paper presents\na blockchain based family security system for tracking the location of\nconsenting family members' smart phones. The locations of the family members'\nsmart phones are logged and stored in a private blockchain which can be\naccessed through a node installed in the family home on a computer. The data\nfor the whereabouts of family members stays within the family unit and does not\ngo to any third party. The system is implemented in a small scale (one miner\nand two other nodes) and the technical feasibility is discussed along with the\nlimitations of the system. Further research will cover the integration of the\nsystem into a smart home environment, and ethical implementations of tracking,\nespecially of vulnerable people, using the immutability of blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 09:06:19 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Raza", "Ali", ""], ["Hardy", "Lachlan", ""], ["Roehrer", "Erin", ""], ["Yeom", "Soonja", ""], ["Kang", "Byeong ho", ""]]}, {"id": "2102.06911", "submitter": "Michiel Bakker", "authors": "Michiel A. Bakker, Richard Everett, Laura Weidinger, Iason Gabriel,\n  William S. Isaac, Joel Z. Leibo, Edward Hughes", "title": "Modelling Cooperation in Network Games with Spatio-Temporal Complexity", "comments": "AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real world is awash with multi-agent problems that require collective\naction by self-interested agents, from the routing of packets across a computer\nnetwork to the management of irrigation systems. Such systems have local\nincentives for individuals, whose behavior has an impact on the global outcome\nfor the group. Given appropriate mechanisms describing agent interaction,\ngroups may achieve socially beneficial outcomes, even in the face of short-term\nselfish incentives. In many cases, collective action problems possess an\nunderlying graph structure, whose topology crucially determines the\nrelationship between local decisions and emergent global effects. Such\nscenarios have received great attention through the lens of network games.\nHowever, this abstraction typically collapses important dimensions, such as\ngeometry and time, relevant to the design of mechanisms promoting cooperation.\nIn parallel work, multi-agent deep reinforcement learning has shown great\npromise in modelling the emergence of self-organized cooperation in complex\ngridworld domains. Here we apply this paradigm in graph-structured collective\naction problems. Using multi-agent deep reinforcement learning, we simulate an\nagent society for a variety of plausible mechanisms, finding clear transitions\nbetween different equilibria over time. We define analytic tools inspired by\nrelated literatures to measure the social outcomes, and use these to draw\nconclusions about the efficacy of different environmental interventions. Our\nmethods have implications for mechanism design in both human and artificial\nagent systems.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 12:04:52 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Bakker", "Michiel A.", ""], ["Everett", "Richard", ""], ["Weidinger", "Laura", ""], ["Gabriel", "Iason", ""], ["Isaac", "William S.", ""], ["Leibo", "Joel Z.", ""], ["Hughes", "Edward", ""]]}, {"id": "2102.06943", "submitter": "Aymen Ben Said", "authors": "Mikhail Shchukin, Aymen Ben Said, Andre Lobo Teixeira", "title": "Goods Transportation Problem Solving via Routing Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper outlines the ideas behind developing a graph-based\nheuristic-driven routing algorithm designed for a particular instance of a\ngoods transportation problem with a single good type. The proposed algorithm\nsolves the optimization problem of satisfying the demand of goods on a given\nundirected transportation graph with minimizing the estimated cost for each\ntraversed segment of the delivery path. The operation of the routing algorithm\nis discussed and overall evaluation of the proposed problem solving technique\nis given.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 15:23:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Shchukin", "Mikhail", ""], ["Said", "Aymen Ben", ""], ["Teixeira", "Andre Lobo", ""]]}, {"id": "2102.06944", "submitter": "Saman Motamed", "authors": "Saman Motamed and Farzad Khalvati", "title": "Multi-class Generative Adversarial Nets for Semi-supervised Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From generating never-before-seen images to domain adaptation, applications\nof Generative Adversarial Networks (GANs) spread wide in the domain of vision\nand graphics problems. With the remarkable ability of GANs in learning the\ndistribution and generating images of a particular class, they can be used for\nsemi-supervised classification tasks. However, the problem is that if two\nclasses of images share similar characteristics, the GAN might learn to\ngeneralize and hinder the classification of the two classes. In this paper, we\nuse various images from MNIST and Fashion-MNIST datasets to illustrate how\nsimilar images cause the GAN to generalize, leading to the poor classification\nof images. We propose a modification to the traditional training of GANs that\nallows for improved multi-class classification in similar classes of images in\na semi-supervised learning framework.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 15:26:17 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 16:25:31 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Motamed", "Saman", ""], ["Khalvati", "Farzad", ""]]}, {"id": "2102.06950", "submitter": "Hui Li", "authors": "Si Chen, Yuqiu Qian, Hui Li, Chen Lin", "title": "Sequential Recommendation in Online Games with Multiple Sequences, Tasks\n  and User Levels", "comments": "Accepted in SSTD'21", "journal-ref": null, "doi": "10.1145/3469830.3470906", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online gaming is growing faster than ever before, with increasing challenges\nof providing better user experience. Recommender systems (RS) for online games\nface unique challenges since they must fulfill players' distinct desires, at\ndifferent user levels, based on their action sequences of various action types.\nAlthough many sequential RS already exist, they are mainly single-sequence,\nsingle-task, and single-user-level. In this paper, we introduce a new\nsequential recommendation model for multiple sequences, multiple tasks, and\nmultiple user levels (abbreviated as M$^3$Rec) in Tencent Games platform, which\ncan fully utilize complex data in online games. We leverage Graph Neural\nNetwork and multi-task learning to design M$^3$Rec in order to model the\ncomplex information in the heterogeneous sequential recommendation scenario of\nTencent Games. We verify the effectiveness of M$^3$Rec on three online games of\nTencent Games platform, in both offline and online evaluations. The results\nshow that M$^3$Rec successfully addresses the challenges of recommendation in\nonline games, and it generates superior recommendations compared with\nstate-of-the-art sequential recommendation approaches.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 16:02:14 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 13:16:16 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Si", ""], ["Qian", "Yuqiu", ""], ["Li", "Hui", ""], ["Lin", "Chen", ""]]}, {"id": "2102.06955", "submitter": "Frederik Beuth", "authors": "Frederik Beuth, Tobias Schlosser, Michael Friedrich, Danny Kowerko", "title": "Improving Automated Visual Fault Detection by Combining a Biologically\n  Plausible Model of Visual Attention with Deep Learning", "comments": "This work is an extended arXiv version of the original conference\n  article published in \"IECON 2020\":\n  https://ieeexplore.ieee.org/abstract/document/9255234 . The work has been\n  extended regarding visual attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long-term goal to transfer biological processing principles as well\nas the power of human recognition into machine vision and engineering systems.\nOne of such principles is visual attention, a smart human concept which focuses\nprocessing on a part of a scene. In this contribution, we utilize attention to\nimprove the automatic detection of defect patterns for wafers within the domain\nof semiconductor manufacturing. Previous works in the domain have often\nutilized classical machine learning approaches such as KNNs, SVMs, or MLPs,\nwhile a few have already used modern approaches like deep neural networks\n(DNNs). However, one problem in the domain is that the faults are often very\nsmall and have to be detected within a larger size of the chip or even the\nwafer. Therefore, small structures in the size of pixels have to be detected in\na vast amount of image data. One interesting principle of the human brain for\nsolving this problem is visual attention. Hence, we employ here a biologically\nplausible model of visual attention for automatic visual inspection. We propose\na hybrid system of visual attention and a deep neural network. As demonstrated,\nour system achieves among other decisive advantages an improvement in accuracy\nfrom 81% to 92%, and an increase in accuracy for detecting faults from 67% to\n88%. Hence, the error rates are reduced from 19% to 8%, and notably from 33% to\n12% for detecting a fault in a chip. These results show that attention can\ngreatly improve the performance of visual inspection systems. Furthermore, we\nconduct a broad evaluation, identifying specific advantages of the biological\nattention model in this application, and benchmarks standard deep learning\napproaches as an alternative with and without attention.\n  This work is an extended arXiv version of the original conference article\npublished in \"IECON 2020\", which has been extended regarding visual attention.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 16:50:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Beuth", "Frederik", ""], ["Schlosser", "Tobias", ""], ["Friedrich", "Michael", ""], ["Kowerko", "Danny", ""]]}, {"id": "2102.06973", "submitter": "Dustin Morrill", "authors": "Dustin Morrill, Ryan D'Orazio, Marc Lanctot, James R. Wright, Michael\n  Bowling, Amy Greenwald", "title": "Efficient Deviation Types and Learning for Hindsight Rationality in\n  Extensive-Form Games", "comments": "Technical report for a paper in the proceedings of the thirty-eighth\n  International Conference on Machine Learning (ICML 2021), virtual. 39 pages\n  and 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hindsight rationality is an approach to playing general-sum games that\nprescribes no-regret learning dynamics for individual agents with respect to a\nset of deviations, and further describes jointly rational behavior among\nmultiple agents with mediated equilibria. To develop hindsight rational\nlearning in sequential decision-making settings, we formalize behavioral\ndeviations as a general class of deviations that respect the structure of\nextensive-form games. Integrating the idea of time selection into\ncounterfactual regret minimization (CFR), we introduce the extensive-form\nregret minimization (EFR) algorithm that achieves hindsight rationality for any\ngiven set of behavioral deviations with computation that scales closely with\nthe complexity of the set. We identify behavioral deviation subsets, the\npartial sequence deviation types, that subsume previously studied types and\nlead to efficient EFR instances in games with moderate lengths. In addition, we\npresent a thorough empirical analysis of EFR instantiated with different\ndeviation types in benchmark games, where we find that stronger types typically\ninduce better performance.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 18:12:53 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 03:42:10 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Morrill", "Dustin", ""], ["D'Orazio", "Ryan", ""], ["Lanctot", "Marc", ""], ["Wright", "James R.", ""], ["Bowling", "Michael", ""], ["Greenwald", "Amy", ""]]}, {"id": "2102.06982", "submitter": "Neelambuj Chaturvedi", "authors": "Neelambuj Chaturvedi", "title": "DeepRA: Predicting Joint Damage From Radiographs Using CNN with\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joint damage in Rheumatoid Arthritis (RA) is assessed by manually inspecting\nand grading radiographs of hands and feet. This is a tedious task which\nrequires trained experts whose subjective assessment leads to low inter-rater\nagreement. An algorithm which can automatically predict the joint level damage\nin hands and feet can help optimize this process, which will eventually aid the\ndoctors in better patient care and research. In this paper, we propose a\ntwo-staged approach which amalgamates object detection and convolution neural\nnetworks with attention which can efficiently and accurately predict the\noverall and joint level narrowing and erosion from patients radiographs. This\napproach has been evaluated on hands and feet radiographs of patients suffering\nfrom RA and has achieved a weighted root mean squared error (RMSE) of 1.358 and\n1.404 in predicting joint level narrowing and erosion Sharp van der Heijde\n(SvH) scores which is 31% and 19% improvement with respect to the baseline SvH\nscores, respectively. The proposed approach achieved a weighted absolute error\nof 1.456 in predicting the overall damage in hands and feet radiographs for the\npatients which is a 79% improvement as compared to the baseline. Our method\nalso provides an inherent capability to provide explanations for model\npredictions using attention weights, which is essential given the black box\nnature of deep learning models. The proposed approach was developed during the\nRA2 Dream Challenge hosted by Dream Challenges and secured 4th and 8th position\nin predicting overall and joint level narrowing and erosion SvH scores from\nradiographs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 18:48:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chaturvedi", "Neelambuj", ""]]}, {"id": "2102.06986", "submitter": "Xuebin Zheng", "authors": "Xuebin Zheng, Bingxin Zhou, Junbin Gao, Yu Guang Wang, Pietro Lio,\n  Ming Li, Guido Montufar", "title": "How Framelets Enhance Graph Neural Networks", "comments": "24 pages, 17 figures, 8 tables, ICML2021 (fix typos)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new approach for assembling graph neural networks based\non framelet transforms. The latter provides a multi-scale representation for\ngraph-structured data. We decompose an input graph into low-pass and high-pass\nfrequencies coefficients for network training, which then defines a\nframelet-based graph convolution. The framelet decomposition naturally induces\na graph pooling strategy by aggregating the graph feature into low-pass and\nhigh-pass spectra, which considers both the feature values and geometry of the\ngraph data and conserves the total information. The graph neural networks with\nthe proposed framelet convolution and pooling achieve state-of-the-art\nperformance in many node and graph prediction tasks. Moreover, we propose\nshrinkage as a new activation for the framelet convolution, which thresholds\nhigh-frequency information at different scales. Compared to ReLU, shrinkage\nactivation improves model performance on denoising and signal compression:\nnoises in both node and structure can be significantly reduced by accurately\ncutting off the high-pass coefficients from framelet decomposition, and the\nsignal can be compressed to less than half its original size with\nwell-preserved prediction performance.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 19:19:19 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 15:39:40 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 05:24:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zheng", "Xuebin", ""], ["Zhou", "Bingxin", ""], ["Gao", "Junbin", ""], ["Wang", "Yu Guang", ""], ["Lio", "Pietro", ""], ["Li", "Ming", ""], ["Montufar", "Guido", ""]]}, {"id": "2102.07004", "submitter": "Wadii Boulila Prof.", "authors": "Wadii Boulila, Maha Driss, Mohamed Al-Sarem, Faisal Saeed, Moez\n  Krichen", "title": "Weight Initialization Techniques for Deep Learning Algorithms in Remote\n  Sensing: Recent Trends and Future Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the last decade, several research works have focused on providing\nnovel deep learning methods in many application fields. However, few of them\nhave investigated the weight initialization process for deep learning, although\nits importance is revealed in improving deep learning performance. This can be\njustified by the technical difficulties in proposing new techniques for this\npromising research field. In this paper, a survey related to weight\ninitialization techniques for deep algorithms in remote sensing is conducted.\nThis survey will help practitioners to drive further research in this promising\nfield. To the best of our knowledge, this paper constitutes the first survey\nfocusing on weight initialization for deep learning models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 21:21:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Boulila", "Wadii", ""], ["Driss", "Maha", ""], ["Al-Sarem", "Mohamed", ""], ["Saeed", "Faisal", ""], ["Krichen", "Moez", ""]]}, {"id": "2102.07017", "submitter": "Sandhya Saisubramanian", "authors": "Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Mitigating Negative Side Effects via Environment Shaping", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents operating in unstructured environments often produce negative side\neffects (NSE), which are difficult to identify at design time. While the agent\ncan learn to mitigate the side effects from human feedback, such feedback is\noften expensive and the rate of learning is sensitive to the agent's state\nrepresentation. We examine how humans can assist an agent, beyond providing\nfeedback, and exploit their broader scope of knowledge to mitigate the impacts\nof NSE. We formulate this problem as a human-agent team with decoupled\nobjectives. The agent optimizes its assigned task, during which its actions may\nproduce NSE. The human shapes the environment through minor reconfiguration\nactions so as to mitigate the impacts of the agent's side effects, without\naffecting the agent's ability to complete its assigned task. We present an\nalgorithm to solve this problem and analyze its theoretical properties. Through\nexperiments with human subjects, we assess the willingness of users to perform\nminor environment modifications to mitigate the impacts of NSE. Empirical\nevaluation of our approach shows that the proposed framework can successfully\nmitigate NSE, without affecting the agent's ability to complete its assigned\ntask.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:15:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2102.07024", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen, Dipendra Misra, Robert Schapire, Miro Dud\\'ik, Patrick\n  Shafto", "title": "Interactive Learning from Activity Description", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a novel interactive learning protocol that enables training\nrequest-fulfilling agents by verbally describing their activities. Unlike\nimitation learning (IL), our protocol allows the teaching agent to provide\nfeedback in a language that is most appropriate for them. Compared with reward\nin reinforcement learning (RL), the description feedback is richer and allows\nfor improved sample complexity. We develop a probabilistic framework and an\nalgorithm that practically implements our protocol. Empirical results in two\nchallenging request-fulfilling problems demonstrate the strengths of our\napproach: compared with RL baselines, it is more sample-efficient; compared\nwith IL baselines, it achieves competitive success rates without requiring the\nteaching agent to be able to demonstrate the desired behavior using the\nlearning agent's actions. Apart from empirical evaluation, we also provide\ntheoretical guarantees for our algorithm under certain assumptions about the\nteacher and the environment.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:51:11 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 23:40:40 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Nguyen", "Khanh", ""], ["Misra", "Dipendra", ""], ["Schapire", "Robert", ""], ["Dud\u00edk", "Miro", ""], ["Shafto", "Patrick", ""]]}, {"id": "2102.07028", "submitter": "Shreyas Fadnavis", "authors": "Eleftherios Garyfallidis, Shreyas Fadnavis, Jong Sung Park, Bramsh\n  Qamar Chandio, Javier Guaje, Serge Koudoro, Nasim Anousheh", "title": "ThetA -- fast and robust clustering via a distance parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clustering is a fundamental problem in machine learning where distance-based\napproaches have dominated the field for many decades. This set of problems is\noften tackled by partitioning the data into K clusters where the number of\nclusters is chosen apriori. While significant progress has been made on these\nlines over the years, it is well established that as the number of clusters or\ndimensions increase, current approaches dwell in local minima resulting in\nsuboptimal solutions. In this work, we propose a new set of distance threshold\nmethods called Theta-based Algorithms (ThetA). Via experimental comparisons and\ncomplexity analyses we show that our proposed approach outperforms existing\napproaches in: a) clustering accuracy and b) time complexity. Additionally, we\nshow that for a large class of problems, learning the optimal threshold is\nstraightforward in comparison to learning K. Moreover, we show how ThetA can\ninfer the sparsity of datasets in higher dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 23:16:33 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 19:46:07 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Garyfallidis", "Eleftherios", ""], ["Fadnavis", "Shreyas", ""], ["Park", "Jong Sung", ""], ["Chandio", "Bramsh Qamar", ""], ["Guaje", "Javier", ""], ["Koudoro", "Serge", ""], ["Anousheh", "Nasim", ""]]}, {"id": "2102.07033", "submitter": "Patrick Lewis", "authors": "Patrick Lewis and Yuxiang Wu and Linqing Liu and Pasquale Minervini\n  and Heinrich K\\\"uttler and Aleksandra Piktus and Pontus Stenetorp and\n  Sebastian Riedel", "title": "PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain Question Answering models which directly leverage question-answer\n(QA) pairs, such as closed-book QA (CBQA) models and QA-pair retrievers, show\npromise in terms of speed and memory compared to conventional models which\nretrieve and read from text corpora. QA-pair retrievers also offer\ninterpretable answers, a high degree of control, and are trivial to update at\ntest time with new knowledge. However, these models lack the accuracy of\nretrieve-and-read systems, as substantially less knowledge is covered by the\navailable QA-pairs relative to text corpora like Wikipedia. To facilitate\nimproved QA-pair models, we introduce Probably Asked Questions (PAQ), a very\nlarge resource of 65M automatically-generated QA-pairs. We introduce a new\nQA-pair retriever, RePAQ, to complement PAQ. We find that PAQ preempts and\ncaches test questions, enabling RePAQ to match the accuracy of recent\nretrieve-and-read models, whilst being significantly faster. Using PAQ, we\ntrain CBQA models which outperform comparable baselines by 5%, but trail RePAQ\nby over 15%, indicating the effectiveness of explicit retrieval. RePAQ can be\nconfigured for size (under 500MB) or speed (over 1K questions per second)\nwhilst retaining high accuracy. Lastly, we demonstrate RePAQ's strength at\nselective QA, abstaining from answering when it is likely to be incorrect. This\nenables RePAQ to ``back-off\" to a more expensive state-of-the-art model,\nleading to a combined system which is both more accurate and 2x faster than the\nstate-of-the-art model alone.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 23:43:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lewis", "Patrick", ""], ["Wu", "Yuxiang", ""], ["Liu", "Linqing", ""], ["Minervini", "Pasquale", ""], ["K\u00fcttler", "Heinrich", ""], ["Piktus", "Aleksandra", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2102.07043", "submitter": "Haitian Sun", "authors": "Haitian Sun, Pat Verga, Bhuwan Dhingra, Ruslan Salakhutdinov, William\n  W. Cohen", "title": "Reasoning Over Virtual Knowledge Bases With Open Predicate Relations", "comments": "Accepted at the 38th International Conference on Machine Learning,\n  PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Open Predicate Query Language (OPQL); a method for\nconstructing a virtual KB (VKB) trained entirely from text. Large Knowledge\nBases (KBs) are indispensable for a wide-range of industry applications such as\nquestion answering and recommendation. Typically, KBs encode world knowledge in\na structured, readily accessible form derived from laborious human annotation\nefforts. Unfortunately, while they are extremely high precision, KBs are\ninevitably highly incomplete and automated methods for enriching them are far\ntoo inaccurate. Instead, OPQL constructs a VKB by encoding and indexing a set\nof relation mentions in a way that naturally enables reasoning and can be\ntrained without any structured supervision. We demonstrate that OPQL\noutperforms prior VKB methods on two different KB reasoning tasks and,\nadditionally, can be used as an external memory integrated into a language\nmodel (OPQL-LM) leading to improvements on two open-domain question answering\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 01:29:54 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 19:34:42 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sun", "Haitian", ""], ["Verga", "Pat", ""], ["Dhingra", "Bhuwan", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "2102.07047", "submitter": "Xu Li", "authors": "Haibin Wu, Xu Li, Andy T. Liu, Zhiyong Wu, Helen Meng, Hung-yi Lee", "title": "Adversarial defense for automatic speaker verification by cascaded\n  self-supervised learning models", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification (ASV) is one of the core technologies in\nbiometric identification. With the ubiquitous usage of ASV systems in\nsafety-critical applications, more and more malicious attackers attempt to\nlaunch adversarial attacks at ASV systems. In the midst of the arms race\nbetween attack and defense in ASV, how to effectively improve the robustness of\nASV against adversarial attacks remains an open question. We note that the\nself-supervised learning models possess the ability to mitigate superficial\nperturbations in the input after pretraining. Hence, with the goal of effective\ndefense in ASV against adversarial attacks, we propose a standard and\nattack-agnostic method based on cascaded self-supervised learning models to\npurify the adversarial perturbations. Experimental results demonstrate that the\nproposed method achieves effective defense performance and can successfully\ncounter adversarial attacks in scenarios where attackers may either be aware or\nunaware of the self-supervised learning models.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 01:56:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wu", "Haibin", ""], ["Li", "Xu", ""], ["Liu", "Andy T.", ""], ["Wu", "Zhiyong", ""], ["Meng", "Helen", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2102.07057", "submitter": "Xiang Wang", "authors": "Xiang Wang, Tinglin Huang, Dingxian Wang, Yancheng Yuan, Zhenguang\n  Liu, Xiangnan He, Tat-Seng Chua", "title": "Learning Intents behind Interactions with Knowledge Graph for\n  Recommendation", "comments": "WWW 2021 oral presentation", "journal-ref": null, "doi": "10.1145/3442381.3450133", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) plays an increasingly important role in recommender\nsystems. A recent technical trend is to develop end-to-end models founded on\ngraph neural networks (GNNs). However, existing GNN-based models are\ncoarse-grained in relational modeling, failing to (1) identify user-item\nrelation at a fine-grained level of intents, and (2) exploit relation\ndependencies to preserve the semantics of long-range connectivity.\n  In this study, we explore intents behind a user-item interaction by using\nauxiliary item knowledge, and propose a new model, Knowledge Graph-based Intent\nNetwork (KGIN). Technically, we model each intent as an attentive combination\nof KG relations, encouraging the independence of different intents for better\nmodel capability and interpretability. Furthermore, we devise a new information\naggregation scheme for GNN, which recursively integrates the relation sequences\nof long-range connectivity (i.e., relational paths). This scheme allows us to\ndistill useful information about user intents and encode them into the\nrepresentations of users and items. Experimental results on three benchmark\ndatasets show that, KGIN achieves significant improvements over the\nstate-of-the-art methods like KGAT, KGNN-LS, and CKAN. Further analyses show\nthat KGIN offers interpretable explanations for predictions by identifying\ninfluential intents and relational paths. The implementations are available at\nhttps://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 03:21:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Xiang", ""], ["Huang", "Tinglin", ""], ["Wang", "Dingxian", ""], ["Yuan", "Yancheng", ""], ["Liu", "Zhenguang", ""], ["He", "Xiangnan", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2102.07090", "submitter": "Rico Picone", "authors": "Rico A.R. Picone, Dane Webb, Finbarr Obierefu, Jotham Lentz", "title": "New methods for metastimuli: architecture, embeddings, and neural\n  network optimization", "comments": "To appear in the Springer Lecture Notes in Artificial Intelligence\n  for the Human-Computer Interaction Conference 2021, Augmented Cognition\n  thematic area", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Six significant new methodological developments of the previously-presented\n\"metastimuli architecture\" for human learning through machine learning of\nspatially correlated structural position within a user's personal information\nmanagement system (PIMS), providing the basis for haptic metastimuli, are\npresented. These include architectural innovation, recurrent (RNN) artificial\nneural network (ANN) application, a variety of atom embedding techniques\n(including a novel technique we call \"nabla\" embedding inspired by\nlinguistics), ANN hyper-parameter (one that affects the network but is not\ntrained, e.g. the learning rate) optimization, and meta-parameter (one that\ndetermines the system performance but is not trained and not a hyper-parameter,\ne.g. the atom embedding technique) optimization for exploring the large design\nspace. A technique for using the system for automatic atom categorization in a\nuser's PIMS is outlined. ANN training and hyper- and meta-parameter\noptimization results are presented and discussed in service of methodological\nrecommendations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 07:28:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Picone", "Rico A. R.", ""], ["Webb", "Dane", ""], ["Obierefu", "Finbarr", ""], ["Lentz", "Jotham", ""]]}, {"id": "2102.07097", "submitter": "Bonnie Li", "authors": "Bonnie Li, Vincent Fran\\c{c}ois-Lavet, Thang Doan, Joelle Pineau", "title": "Domain Adversarial Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of generalization in reinforcement learning where\nvisual aspects of the observations might differ, e.g. when there are different\nbackgrounds or change in contrast, brightness, etc. We assume that our agent\nhas access to only a few of the MDPs from the MDP distribution during training.\nThe performance of the agent is then reported on new unknown test domains drawn\nfrom the distribution (e.g. unseen backgrounds). For this \"zero-shot RL\" task,\nwe enforce invariance of the learned representations to visual domains via a\ndomain adversarial optimization process. We empirically show that this approach\nallows achieving a significant generalization improvement to new unseen\ndomains.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 07:58:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Li", "Bonnie", ""], ["Fran\u00e7ois-Lavet", "Vincent", ""], ["Doan", "Thang", ""], ["Pineau", "Joelle", ""]]}, {"id": "2102.07113", "submitter": "Jasmin Bogatinovski Mr.", "authors": "Jasmin Bogatinovski, Ljup\\v{c}o Todorovski, Sa\\v{s}o D\\v{z}eroski,\n  Dragi Kocev", "title": "Comprehensive Comparative Study of Multi-Label Classification Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multi-label classification (MLC) has recently received increasing interest\nfrom the machine learning community. Several studies provide reviews of methods\nand datasets for MLC and a few provide empirical comparisons of MLC methods.\nHowever, they are limited in the number of methods and datasets considered.\nThis work provides a comprehensive empirical study of a wide range of MLC\nmethods on a plethora of datasets from various domains. More specifically, our\nstudy evaluates 26 methods on 42 benchmark datasets using 20 evaluation\nmeasures. The adopted evaluation methodology adheres to the highest literature\nstandards for designing and executing large scale, time-budgeted experimental\nstudies. First, the methods are selected based on their usage by the community,\nassuring representation of methods across the MLC taxonomy of methods and\ndifferent base learners. Second, the datasets cover a wide range of complexity\nand domains of application. The selected evaluation measures assess the\npredictive performance and the efficiency of the methods. The results of the\nanalysis identify RFPCT, RFDTBR, ECCJ48, EBRJ48 and AdaBoostMH as best\nperforming methods across the spectrum of performance measures. Whenever a new\nmethod is introduced, it should be compared to different subsets of MLC\nmethods, determined on the basis of the different evaluation criteria.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 09:38:15 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 05:29:43 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Bogatinovski", "Jasmin", ""], ["Todorovski", "Ljup\u010do", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Kocev", "Dragi", ""]]}, {"id": "2102.07120", "submitter": "Vineet Nair", "authors": "Ganesh Ghalme, Vineet Nair, Vishakha Patil, Yilun Zhou", "title": "State-Visitation Fairness in Average-Reward MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fairness has emerged as an important concern in automated decision-making in\nrecent years, especially when these decisions affect human welfare. In this\nwork, we study fairness in temporally extended decision-making settings,\nspecifically those formulated as Markov Decision Processes (MDPs). Our proposed\nnotion of fairness ensures that each state's long-term visitation frequency is\nmore than a specified fraction. In an average-reward MDP (AMDP) setting, we\nformulate the problem as a bilinear saddle point program and, for a generative\nmodel, solve it using a Stochastic Mirror Descent (SMD) based algorithm. The\nproposed solution guarantees a simultaneous approximation on the expected\naverage-reward and the long-term state-visitation frequency. We validate our\ntheoretical results with experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 10:20:53 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 12:45:15 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Ghalme", "Ganesh", ""], ["Nair", "Vineet", ""], ["Patil", "Vishakha", ""], ["Zhou", "Yilun", ""]]}, {"id": "2102.07121", "submitter": "Yu Zhang", "authors": "Feiyang Ye, Baijiong Lin, Zhixiong Yue, Pengxin Guo, Qiao Xiao, Yu\n  Zhang", "title": "Multi-Objective Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning with multiple objectives can be formulated as a Multi-Objective\nBi-Level optimization Problem (MOBLP) where the upper-level subproblem is to\nsolve several possible conflicting targets for the meta learner. However,\nexisting studies either apply an inefficient evolutionary algorithm or linearly\ncombine multiple objectives as a single-objective problem with the need to tune\ncombination weights. In this paper, we propose a unified gradient-based\nMulti-Objective Meta Learning (MOML) framework and devise the first\ngradient-based optimization algorithm to solve the MOBLP by alternatively\nsolving the lower-level and upper-level subproblems via the gradient descent\nmethod and the gradient-based multi-objective optimization method,\nrespectively. Theoretically, we prove the convergence properties of the\nproposed gradient-based optimization algorithm. Empirically, we show the\neffectiveness of the proposed MOML framework in several meta learning problems,\nincluding few-shot learning, neural architecture search, domain adaptation, and\nmulti-task learning.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 10:23:09 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ye", "Feiyang", ""], ["Lin", "Baijiong", ""], ["Yue", "Zhixiong", ""], ["Guo", "Pengxin", ""], ["Xiao", "Qiao", ""], ["Zhang", "Yu", ""]]}, {"id": "2102.07125", "submitter": "Sourav Mishra", "authors": "Sourav Mishra and Suresh Sundaram", "title": "Self Regulated Learning Mechanism for Data Efficient Knowledge\n  Distillation", "comments": "8 pages, 5 figures, 6 tables, 27 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing methods for distillation do not efficiently utilize the training\ndata. This work presents a novel approach to perform distillation using only a\nsubset of the training data, making it more data-efficient. For this purpose,\nthe training of the teacher model is modified to include self-regulation\nwherein a sample in the training set is used for updating model parameters in\nthe backward pass either if it is misclassified or the model is not confident\nenough in its prediction. This modification restricts the participation of\nsamples, unlike the conventional training method. The number of times a sample\nparticipates in the self-regulated training process is a measure of its\nsignificance towards the model's knowledge. The significance values are used to\nweigh the losses incurred on the corresponding samples in the distillation\nprocess. This method is named significance-based distillation. Two other\nmethods are proposed for comparison where the student model learns by\ndistillation and incorporating self-regulation as the teacher model, either\nutilizing the significance information computed during the teacher's training\nor not. These methods are named hybrid and regulated distillations,\nrespectively. Experiments on benchmark datasets show that the proposed methods\nachieve similar performance as other state-of-the-art methods for knowledge\ndistillation while utilizing a significantly less number of samples.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 10:43:13 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 08:14:17 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Mishra", "Sourav", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2102.07152", "submitter": "Tao Zhang", "authors": "Tao Zhang, Quanyan Zhu", "title": "On the Equilibrium Elicitation of Markov Games Through Information\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers a novel information design problem and studies how the\ncraft of payoff-relevant environmental signals solely can influence the\nbehaviors of intelligent agents. The agents' strategic interactions are\ncaptured by an incomplete-information Markov game, in which each agent first\nselects one environmental signal from multiple signal sources as additional\npayoff-relevant information and then takes an action. There is a rational\ninformation designer (designer) who possesses one signal source and aims to\ncontrol the equilibrium behaviors of the agents by designing the information\nstructure of her signals sent to the agents. An obedient principle is\nestablished which states that it is without loss of generality to focus on the\ndirect information design when the information design incentivizes each agent\nto select the signal sent by the designer, such that the design process avoids\nthe predictions of the agents' strategic selection behaviors. We then introduce\nthe design protocol given a goal of the designer referred to as obedient\nimplementability (OIL) and characterize the OIL in a class of obedient perfect\nBayesian Markov Nash equilibria (O-PBME). A new framework for information\ndesign is proposed based on an approach of maximizing the optimal slack\nvariables. Finally, we formulate the designer's goal selection problem and\ncharacterize it in terms of information design by establishing a relationship\nbetween the O-PBME and the Bayesian Markov correlated equilibria, in which we\nbuild upon the revelation principle in classic information design in economics.\nThe proposed approach can be applied to elicit desired behaviors of multi-agent\nsystems in competing as well as cooperating settings and be extended to\nheterogeneous stochastic games in the complete- and the incomplete-information\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 13:30:06 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2102.07185", "submitter": "Rotem Lev Lehman", "authors": "Rotem Lev Lehman (1), Guy Shani (1), Roni Stern (1 and 2) ((1)\n  Software and Information Systems Engineering, Ben Gurion University of the\n  Negev, Be'er Sheva, Israel, (2) Palo Alto Research Center, Palo Alto, CA,\n  USA)", "title": "Partial Disclosure of Private Dependencies in Privacy Preserving\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In collaborative privacy preserving planning (CPPP), a group of agents\njointly creates a plan to achieve a set of goals while preserving each others'\nprivacy. During planning, agents often reveal the private dependencies between\ntheir public actions to other agents, that is, which public action facilitates\nthe preconditions of another public action. Previous work in CPPP does not\nlimit the disclosure of such dependencies. In this paper, we explicitly limit\nthe amount of disclosed dependencies, allowing agents to publish only a part of\ntheir private dependencies. We investigate different strategies for deciding\nwhich dependencies to publish, and how they affect the ability to find\nsolutions. We evaluate the ability of two solvers -- distribute forward search\nand centralized planning based on a single-agent projection -- to produce plans\nunder this constraint. Experiments over standard CPPP domains show that the\nproposed dependency-sharing strategies enable generating plans while sharing\nonly a small fraction of all private dependencies.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 16:10:08 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lehman", "Rotem Lev", "", "1 and 2"], ["Shani", "Guy", "", "1 and 2"], ["Stern", "Roni", "", "1 and 2"]]}, {"id": "2102.07186", "submitter": "Nasrullah Sheikh", "authors": "Xiao Qin, Nasrullah Sheikh, Berthold Reinwald, Lingfei Wu", "title": "Relation-aware Graph Attention Model With Adaptive Self-adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper describes an end-to-end solution for the relationship prediction\ntask in heterogeneous, multi-relational graphs. We particularly address two\nbuilding blocks in the pipeline, namely heterogeneous graph representation\nlearning and negative sampling. Existing message passing-based graph neural\nnetworks use edges either for graph traversal and/or selection of message\nencoding functions. Ignoring the edge semantics could have severe repercussions\non the quality of embeddings, especially when dealing with two nodes having\nmultiple relations. Furthermore, the expressivity of the learned representation\ndepends on the quality of negative samples used during training. Although\nexisting hard negative sampling techniques can identify challenging negative\nrelationships for optimization, new techniques are required to control false\nnegatives during training as false negatives could corrupt the learning\nprocess. To address these issues, first, we propose RelGNN -- a message\npassing-based heterogeneous graph attention model. In particular, RelGNN\ngenerates the states of different relations and leverages them along with the\nnode states to weigh the messages. RelGNN also adopts a self-attention\nmechanism to balance the importance of attribute features and topological\nfeatures for generating the final entity embeddings. Second, we introduce a\nparameter-free negative sampling technique -- adaptive self-adversarial (ASA)\nnegative sampling. ASA reduces the false-negative rate by leveraging positive\nrelationships to effectively guide the identification of true negative samples.\nOur experimental evaluation demonstrates that RelGNN optimized by ASA for\nrelationship prediction improves state-of-the-art performance across\nestablished benchmarks as well as on a real industrial dataset.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 16:11:56 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Qin", "Xiao", ""], ["Sheikh", "Nasrullah", ""], ["Reinwald", "Berthold", ""], ["Wu", "Lingfei", ""]]}, {"id": "2102.07200", "submitter": "Nasrullah Sheikh", "authors": "Nasrullah Sheikh, Xiao Qin, Berthold Reinwald, Christoph Miksovic,\n  Thomas Gschwind, Paolo Scotton", "title": "Knowledge Graph Embedding using Graph Convolutional Networks with\n  Relation-Aware Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Knowledge graph embedding methods learn embeddings of entities and relations\nin a low dimensional space which can be used for various downstream machine\nlearning tasks such as link prediction and entity matching. Various graph\nconvolutional network methods have been proposed which use different types of\ninformation to learn the features of entities and relations. However, these\nmethods assign the same weight (importance) to the neighbors when aggregating\nthe information, ignoring the role of different relations with the neighboring\nentities. To this end, we propose a relation-aware graph attention model that\nleverages relation information to compute different weights to the neighboring\nnodes for learning embeddings of entities and relations. We evaluate our\nproposed approach on link prediction and entity matching tasks. Our\nexperimental results on link prediction on three datasets (one proprietary and\ntwo public) and results on unsupervised entity matching on one proprietary\ndataset demonstrate the effectiveness of the relation-aware attention.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 17:19:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sheikh", "Nasrullah", ""], ["Qin", "Xiao", ""], ["Reinwald", "Berthold", ""], ["Miksovic", "Christoph", ""], ["Gschwind", "Thomas", ""], ["Scotton", "Paolo", ""]]}, {"id": "2102.07213", "submitter": "Evandro Ruiz Dr.", "authors": "Cristina Godoy Bernardo de Oliveira and Evandro Eduardo Seron Ruiz", "title": "Why Talking about ethics is not enough: a proposal for Fintech's AI\n  ethics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the potential applications of Artificial Intelligence (AI) in the\nfinancial sector increases, ethical issues become gradually latent. The\ndistrust of individuals, social groups, and governments about the risks arising\nfrom Fintech's activities is growing. Due to this scenario, the preparation of\nrecommendations and Ethics Guidelines is increasing and the risks of being\nchosen the principles and ethical values most appropriate to companies are\nhigh. Thus, this exploratory research aims to analyze the benefits of the\napplication of the stakeholder theory and the idea of Social License to build\nan environment of trust and for the realization of ethical principles by\nFintech. The formation of a Fintech association for the creation of a Social\nLicense will allow early-stage Fintech to participate from the beginning of its\nactivities in the elaboration of a dynamic ethical code and with the\nparticipation of stakeholders.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 18:23:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["de Oliveira", "Cristina Godoy Bernardo", ""], ["Ruiz", "Evandro Eduardo Seron", ""]]}, {"id": "2102.07244", "submitter": "Danda Rawat", "authors": "Felix Olowononi and Danda B. Rawat and Chunmei Liu", "title": "Resilient Machine Learning for Networked Cyber Physical Systems: A\n  Survey for Machine Learning Security to Securing Machine Learning for CPS", "comments": null, "journal-ref": null, "doi": "10.1109/COMST.2020.3036778", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber Physical Systems (CPS) are characterized by their ability to integrate\nthe physical and information or cyber worlds. Their deployment in critical\ninfrastructure have demonstrated a potential to transform the world. However,\nharnessing this potential is limited by their critical nature and the far\nreaching effects of cyber attacks on human, infrastructure and the environment.\nAn attraction for cyber concerns in CPS rises from the process of sending\ninformation from sensors to actuators over the wireless communication medium,\nthereby widening the attack surface. Traditionally, CPS security has been\ninvestigated from the perspective of preventing intruders from gaining access\nto the system using cryptography and other access control techniques. Most\nresearch work have therefore focused on the detection of attacks in CPS.\nHowever, in a world of increasing adversaries, it is becoming more difficult to\ntotally prevent CPS from adversarial attacks, hence the need to focus on making\nCPS resilient. Resilient CPS are designed to withstand disruptions and remain\nfunctional despite the operation of adversaries. One of the dominant\nmethodologies explored for building resilient CPS is dependent on machine\nlearning (ML) algorithms. However, rising from recent research in adversarial\nML, we posit that ML algorithms for securing CPS must themselves be resilient.\nThis paper is therefore aimed at comprehensively surveying the interactions\nbetween resilient CPS using ML and resilient ML when applied in CPS. The paper\nconcludes with a number of research trends and promising future research\ndirections. Furthermore, with this paper, readers can have a thorough\nunderstanding of recent advances on ML-based security and securing ML for CPS\nand countermeasures, as well as research trends in this active research area.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 20:50:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Olowononi", "Felix", ""], ["Rawat", "Danda B.", ""], ["Liu", "Chunmei", ""]]}, {"id": "2102.07246", "submitter": "Xuejiao Tang", "authors": "Ruijun Chen, Jiong Qiu and Xuejiao Tang", "title": "Responsibility Management through Responsibility Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The safety management is critically important in the workplace.\nUnfortunately, responsibility issues therein such as inefficient supervision,\npoor evaluation and inadequate perception have not been properly addressed. To\nthis end, in this paper, we deploy the Internet of Responsibilities (IoR) for\nresponsibility management. Through the building of IoR framework, hierarchical\nresponsibility management, automated responsibility evaluation at all level and\nefficient responsibility perception are achieved. The practical deployment of\nIoR system showed its effective responsibility management capability in various\nworkplaces.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 21:06:33 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 01:21:18 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chen", "Ruijun", ""], ["Qiu", "Jiong", ""], ["Tang", "Xuejiao", ""]]}, {"id": "2102.07247", "submitter": "Danda Rawat", "authors": "Aashma Uprety and Danda B. Rawat", "title": "Reinforcement Learning for IoT Security: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.3040957", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of connected smart devices has been increasing exponentially for\ndifferent Internet-of-Things (IoT) applications. Security has been a long run\nchallenge in the IoT systems which has many attack vectors, security flaws and\nvulnerabilities. Securing billions of B connected devices in IoT is a must task\nto realize the full potential of IoT applications. Recently, researchers have\nproposed many security solutions for IoT. Machine learning has been proposed as\none of the emerging solutions for IoT security and Reinforcement learning is\ngaining more popularity for securing IoT systems. Reinforcement learning,\nunlike other machine learning techniques, can learn the environment by having\nminimum information about the parameters to be learned. It solves the\noptimization problem by interacting with the environment adapting the\nparameters on the fly. In this paper, we present an comprehensive survey of\ndifferent types of cyber-attacks against different IoT systems and then we\npresent reinforcement learning and deep reinforcement learning based security\nsolutions to combat those different types of attacks in different IoT systems.\nFurthermore, we present the Reinforcement learning for securing CPS systems\n(i.e., IoT with feedback and control) such as smart grid and smart\ntransportation system. The recent important attacks and countermeasures using\nreinforcement learning B in IoT are also summarized in the form of tables. With\nthis paper, readers can have a more thorough understanding of IoT security\nattacks and countermeasures using Reinforcement Learning, as well as research\ntrends in this area.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 21:09:49 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Uprety", "Aashma", ""], ["Rawat", "Danda B.", ""]]}, {"id": "2102.07265", "submitter": "Zi Wang", "authors": "Thomas Kobber Panum, Zi Wang, Pengyu Kan, Earlence Fernandes, Somesh\n  Jha", "title": "Exploring Adversarial Robustness of Deep Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Metric Learning (DML), a widely-used technique, involves learning a\ndistance metric between pairs of samples. DML uses deep neural architectures to\nlearn semantic embeddings of the input, where the distance between similar\nexamples is small while dissimilar ones are far apart. Although the underlying\nneural networks produce good accuracy on naturally occurring samples, they are\nvulnerable to adversarially-perturbed samples that reduce performance. We take\na first step towards training robust DML models and tackle the primary\nchallenge of the metric losses being dependent on the samples in a mini-batch,\nunlike standard losses that only depend on the specific input-output pair. We\nanalyze this dependence effect and contribute a robust optimization\nformulation. Using experiments on three commonly-used DML datasets, we\ndemonstrate 5-76 fold increases in adversarial accuracy, and outperform an\nexisting DML model that sought out to be robust.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 23:18:12 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Panum", "Thomas Kobber", ""], ["Wang", "Zi", ""], ["Kan", "Pengyu", ""], ["Fernandes", "Earlence", ""], ["Jha", "Somesh", ""]]}, {"id": "2102.07266", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh, Liang Zheng", "title": "Sparse Attention Guided Dynamic Value Estimation for Single-Task\n  Multi-Scene Reinforcement Learning", "comments": "This work is a merger of arXiv:2005.12254 and arXiv:2011.12574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training deep reinforcement learning agents on environments with multiple\nlevels / scenes from the same task, has become essential for many applications\naiming to achieve generalization and domain transfer from simulation to the\nreal world. While such a strategy is helpful with generalization, the use of\nmultiple scenes significantly increases the variance of samples collected for\npolicy gradient computations. Current methods, effectively continue to view\nthis collection of scenes as a single Markov decision process (MDP), and thus\nlearn a scene-generic value function V(s). However, we argue that the sample\nvariance for a multi-scene environment is best minimized by treating each scene\nas a distinct MDP, and then learning a joint value function V(s,M) dependent on\nboth state s and MDP M. We further demonstrate that the true joint value\nfunction for a multi-scene environment, follows a multi-modal distribution\nwhich is not captured by traditional CNN / LSTM based critic networks. To this\nend, we propose a dynamic value estimation (DVE) technique, which approximates\nthe true joint value function through a sparse attention mechanism over\nmultiple value function hypothesis / modes. The resulting agent not only shows\nsignificant improvements in the final reward score across a range of OpenAI\nProcGen environments, but also exhibits enhanced navigation efficiency and\nprovides an implicit mechanism for unsupervised state-space skill\ndecomposition.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 23:30:13 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2102.07277", "submitter": "Radhabai Gopinathan Nair Gayathri", "authors": "R G Gayathri, Atul Sajjanhar, Yong Xiang and Xingjun Ma", "title": "Anomaly Detection for Scenario-based Insider Activities using CGAN\n  Augmented Data", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Insider threats are the cyber attacks from within the trusted entities of an\norganization. Lack of real-world data and issue of data imbalance leave insider\nthreat analysis an understudied research area. To mitigate the effect of skewed\nclass distribution and prove the potential of multinomial classification\nalgorithms for insider threat detection, we propose an approach that combines\ngenerative model with supervised learning to perform multi-class classification\nusing deep learning. The generative adversarial network (GAN) based insider\ndetection model introduces Conditional Generative Adversarial Network (CGAN) to\nenrich minority class samples to provide data for multi-class anomaly\ndetection. The comprehensive experiments performed on the benchmark dataset\ndemonstrates the effectiveness of introducing GAN derived synthetic data and\nthe capability of multi-class anomaly detection in insider activity analysis.\nMoreover, the method is compared with other existing methods against different\nparameters and performance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 00:08:39 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 05:06:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gayathri", "R G", ""], ["Sajjanhar", "Atul", ""], ["Xiang", "Yong", ""], ["Ma", "Xingjun", ""]]}, {"id": "2102.07298", "submitter": "Farbod Taymouri", "authors": "Farbod Taymouri, Marcello La Rosa, Sarah M. Erfani", "title": "A Deep Adversarial Model for Suffix and Remaining Time Prediction of\n  Event Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Event suffix and remaining time prediction are sequence to sequence learning\ntasks. They have wide applications in different areas such as economics,\ndigital health, business process management and IT infrastructure monitoring.\nTimestamped event sequences contain ordered events which carry at least two\nattributes: the event's label and its timestamp. Suffix and remaining time\nprediction are about obtaining the most likely continuation of event labels and\nthe remaining time until the sequence finishes, respectively. Recent deep\nlearning-based works for such predictions are prone to potentially large\nprediction errors because of closed-loop training (i.e., the next event is\nconditioned on the ground truth of previous events) and open-loop inference\n(i.e., the next event is conditioned on previously predicted events). In this\nwork, we propose an encoder-decoder architecture for open-loop training to\nadvance the suffix and remaining time prediction of event sequences. To capture\nthe joint temporal dynamics of events, we harness the power of adversarial\nlearning techniques to boost prediction performance. We consider four real-life\ndatasets and three baselines in our experiments. The results show improvements\nup to four times compared to the state of the art in suffix and remaining time\nprediction of event sequences, specifically in the realm of business process\nexecutions. We also show that the obtained improvements of adversarial training\nare superior compared to standard training under the same experimental setup.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 02:01:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Taymouri", "Farbod", ""], ["La Rosa", "Marcello", ""], ["Erfani", "Sarah M.", ""]]}, {"id": "2102.07325", "submitter": "Paarth Neekhara", "authors": "Paarth Neekhara, Shehzeen Hussain, Jinglong Du, Shlomo Dubnov, Farinaz\n  Koushanfar, Julian McAuley", "title": "Cross-modal Adversarial Reprogramming", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of large-scale deep learning models, it has become\npossible to repurpose pre-trained networks for new tasks. Recent works on\nadversarial reprogramming have shown that it is possible to repurpose neural\nnetworks for alternate tasks without modifying the network architecture or\nparameters. However these works only consider original and target tasks within\nthe same data domain. In this work, we broaden the scope of adversarial\nreprogramming beyond the data modality of the original task. We analyze the\nfeasibility of adversarially repurposing image classification neural networks\nfor Natural Language Processing (NLP) and other sequence classification tasks.\nWe design an efficient adversarial program that maps a sequence of discrete\ntokens into an image which can be classified to the desired class by an image\nclassification model. We demonstrate that by using highly efficient adversarial\nprograms, we can reprogram image classifiers to achieve competitive performance\non a variety of text and sequence classification benchmarks without retraining\nthe network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 03:46:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Neekhara", "Paarth", ""], ["Hussain", "Shehzeen", ""], ["Du", "Jinglong", ""], ["Dubnov", "Shlomo", ""], ["Koushanfar", "Farinaz", ""], ["McAuley", "Julian", ""]]}, {"id": "2102.07332", "submitter": "Jae-Hong Lee", "authors": "Jae-Hong Lee, Joon-Hyuk Chang", "title": "Attribution Mask: Filtering Out Irrelevant Features By Recursively\n  Focusing Attention on Inputs of DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods calculate attributions that visually explain the\npredictions of deep neural networks (DNNs) by highlighting important parts of\nthe input features. In particular, gradient-based attribution (GBA) methods are\nwidely used because they can be easily implemented through automatic\ndifferentiation. In this study, we use the attributions that filter out\nirrelevant parts of the input features and then verify the effectiveness of\nthis approach by measuring the classification accuracy of a pre-trained DNN.\nThis is achieved by calculating and applying an \\textit{attribution mask} to\nthe input features and subsequently introducing the masked features to the DNN,\nfor which the mask is designed to recursively focus attention on the parts of\nthe input related to the target label. The accuracy is enhanced under a certain\ncondition, i.e., \\textit{no implicit bias}, which can be derived based on our\ntheoretical insight into compressing the DNN into a single-layer neural\nnetwork. We also provide Gradient\\,*\\,Sign-of-Input (GxSI) to obtain the\nattribution mask that further improves the accuracy. As an example, on CIFAR-10\nthat is modified using the attribution mask obtained from GxSI, we achieve the\naccuracy ranging from 99.8\\% to 99.9\\% without additional training.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 04:12:04 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lee", "Jae-Hong", ""], ["Chang", "Joon-Hyuk", ""]]}, {"id": "2102.07333", "submitter": "Susannah Kate Devitt", "authors": "Angela Daly, S Kate Devitt, Monique Mann", "title": "AI Ethics Needs Good Data", "comments": "20 pages, under peer review in Pieter Verdegem (ed), AI for Everyone?\n  Critical Perspectives. University of Westminster Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this chapter we argue that discourses on AI must transcend the language of\n'ethics' and engage with power and political economy in order to constitute\n'Good Data'. In particular, we must move beyond the depoliticised language of\n'ethics' currently deployed (Wagner 2018) in determining whether AI is 'good'\ngiven the limitations of ethics as a frame through which AI issues can be\nviewed. In order to circumvent these limits, we use instead the language and\nconceptualisation of 'Good Data', as a more expansive term to elucidate the\nvalues, rights and interests at stake when it comes to AI's development and\ndeployment, as well as that of other digital technologies. Good Data\nconsiderations move beyond recurring themes of data protection/privacy and the\nFAT (fairness, transparency and accountability) movement to include explicit\npolitical economy critiques of power. Instead of yet more ethics principles\n(that tend to say the same or similar things anyway), we offer four 'pillars'\non which Good Data AI can be built: community, rights, usability and politics.\nOverall we view AI's 'goodness' as an explicly political (economy) question of\npower and one which is always related to the degree which AI is created and\nused to increase the wellbeing of society and especially to increase the power\nof the most marginalized and disenfranchised. We offer recommendations and\nremedies towards implementing 'better' approaches towards AI. Our strategies\nenable a different (but complementary) kind of evaluation of AI as part of the\nbroader socio-technical systems in which AI is built and deployed.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 04:16:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Daly", "Angela", ""], ["Devitt", "S Kate", ""], ["Mann", "Monique", ""]]}, {"id": "2102.07339", "submitter": "Yuxia Geng", "authors": "Yuxia Geng, Jiaoyan Chen, Zhuo Chen, Jeff Z. Pan, Zhiquan Ye, Zonggang\n  Yuan, Yantao Jia, Huajun Chen", "title": "OntoZSL: Ontology-enhanced Zero-shot Learning", "comments": "Accepted to The Web Conference (WWW) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot Learning (ZSL), which aims to predict for those classes that have\nnever appeared in the training data, has arisen hot research interests. The key\nof implementing ZSL is to leverage the prior knowledge of classes which builds\nthe semantic relationship between classes and enables the transfer of the\nlearned models (e.g., features) from training classes (i.e., seen classes) to\nunseen classes. However, the priors adopted by the existing methods are\nrelatively limited with incomplete semantics. In this paper, we explore richer\nand more competitive prior knowledge to model the inter-class relationship for\nZSL via ontology-based knowledge representation and semantic embedding.\nMeanwhile, to address the data imbalance between seen classes and unseen\nclasses, we developed a generative ZSL framework with Generative Adversarial\nNetworks (GANs). Our main findings include: (i) an ontology-enhanced ZSL\nframework that can be applied to different domains, such as image\nclassification (IMGC) and knowledge graph completion (KGC); (ii) a\ncomprehensive evaluation with multiple zero-shot datasets from different\ndomains, where our method often achieves better performance than the\nstate-of-the-art models. In particular, on four representative ZSL baselines of\nIMGC, the ontology-based class semantics outperform the previous priors e.g.,\nthe word embeddings of classes by an average of 12.4 accuracy points in the\nstandard ZSL across two example datasets (see Figure 4).\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 04:39:58 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Geng", "Yuxia", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Zhuo", ""], ["Pan", "Jeff Z.", ""], ["Ye", "Zhiquan", ""], ["Yuan", "Zonggang", ""], ["Jia", "Yantao", ""], ["Chen", "Huajun", ""]]}, {"id": "2102.07346", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi", "title": "On the Theory of Implicit Deep Learning: Global Convergence with\n  Implicit Layers", "comments": "ICLR 2021. Selected for ICLR Spotlight (top 6% submissions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep equilibrium model uses implicit layers, which are implicitly defined\nthrough an equilibrium point of an infinite sequence of computation. It avoids\nany explicit computation of the infinite sequence by finding an equilibrium\npoint directly via root-finding and by computing gradients via implicit\ndifferentiation. In this paper, we analyze the gradient dynamics of deep\nequilibrium models with nonlinearity only on weight matrices and non-convex\nobjective functions of weights for regression and classification. Despite\nnon-convexity, convergence to global optimum at a linear rate is guaranteed\nwithout any assumption on the width of the models, allowing the width to be\nsmaller than the output dimension and the number of data points. Moreover, we\nprove a relation between the gradient dynamics of the deep implicit layer and\nthe dynamics of trust region Newton method of a shallow explicit layer. This\nmathematically proven relation along with our numerical observation suggests\nthe importance of understanding implicit bias of implicit layers and an open\nproblem on the topic. Our proofs deal with implicit layers, weight tying and\nnonlinearity on weights, and differ from those in the related literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 05:08:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 18:39:14 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kawaguchi", "Kenji", ""]]}, {"id": "2102.07350", "submitter": "Laria Reynolds", "authors": "Laria Reynolds and Kyle McDonell", "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot\n  Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prevailing methods for mapping large generative language models to supervised\ntasks may fail to sufficiently probe models' novel capabilities. Using GPT-3 as\na case study, we show that 0-shot prompts can significantly outperform few-shot\nprompts. We suggest that the function of few-shot examples in these cases is\nbetter described as locating an already learned task rather than meta-learning.\nThis analysis motivates rethinking the role of prompts in controlling and\nevaluating powerful language models. In this work, we discuss methods of prompt\nprogramming, emphasizing the usefulness of considering prompts through the lens\nof natural language. We explore techniques for exploiting the capacity of\nnarratives and cultural anchors to encode nuanced intentions and techniques for\nencouraging deconstruction of a problem into components before producing a\nverdict. Informed by this more encompassing theory of prompt programming, we\nalso introduce the idea of a metaprompt that seeds the model to generate its\nown natural language prompts for a range of tasks. Finally, we discuss how\nthese more general methods of interacting with language models can be\nincorporated into existing and future benchmarks and practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 05:27:55 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Reynolds", "Laria", ""], ["McDonell", "Kyle", ""]]}, {"id": "2102.07358", "submitter": "Shichao Xu", "authors": "Shichao Xu, Lixu Wang, Yixuan Wang, Qi Zhu", "title": "Weak Adaptation Learning -- Addressing Cross-domain Data Insufficiency\n  with Weak Annotator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quantity and quality are crucial factors for data-driven learning\nmethods. In some target problem domains, there are not many data samples\navailable, which could significantly hinder the learning process. While data\nfrom similar domains may be leveraged to help through domain adaptation,\nobtaining high-quality labeled data for those source domains themselves could\nbe difficult or costly. To address such challenges on data insufficiency for\nclassification problem in a target domain, we propose a weak adaptation\nlearning (WAL) approach that leverages unlabeled data from a similar source\ndomain, a low-cost weak annotator that produces labels based on task-specific\nheuristics, labeling rules, or other methods (albeit with inaccuracy), and a\nsmall amount of labeled data in the target domain. Our approach first conducts\na theoretical analysis on the error bound of the trained classifier with\nrespect to the data quantity and the performance of the weak annotator, and\nthen introduces a multi-stage weak adaptation learning method to learn an\naccurate classifier by lowering the error bound. Our experiments demonstrate\nthe effectiveness of our approach in learning an accurate classifier with\nlimited labeled data in the target domain and unlabeled data in the source\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 06:19:25 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Xu", "Shichao", ""], ["Wang", "Lixu", ""], ["Wang", "Yixuan", ""], ["Zhu", "Qi", ""]]}, {"id": "2102.07360", "submitter": "Ehsan Kazemi Dr", "authors": "Ehsan Kazemi, Thomas Kerdreux and Liquang Wang", "title": "Generating Structured Adversarial Attacks Using Frank-Wolfe Method", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.01855", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  White box adversarial perturbations are generated via iterative optimization\nalgorithms most often by minimizing an adversarial loss on a $\\ell_p$\nneighborhood of the original image, the so-called distortion set. Constraining\nthe adversarial search with different norms results in disparately structured\nadversarial examples. Here we explore several distortion sets with\nstructure-enhancing algorithms. These new structures for adversarial examples\nmight provide challenges for provable and empirical robust mechanisms. Because\nadversarial robustness is still an empirical field, defense mechanisms should\nalso reasonably be evaluated against differently structured attacks. Besides,\nthese structured adversarial perturbations may allow for larger distortions\nsize than their $\\ell_p$ counter-part while remaining imperceptible or\nperceptible as natural distortions of the image. We will demonstrate in this\nwork that the proposed structured adversarial examples can significantly bring\ndown the classification accuracy of adversarialy trained classifiers while\nshowing low $\\ell_2$ distortion rate. For instance, on ImagNet dataset the\nstructured attacks drop the accuracy of adversarial model to near zero with\nonly 50\\% of $\\ell_2$ distortion generated using white-box attacks like PGD. As\na byproduct, our finding on structured adversarial examples can be used for\nadversarial regularization of models to make models more robust or improve\ntheir generalization performance on datasets which are structurally different.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 06:36:50 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Kerdreux", "Thomas", ""], ["Wang", "Liquang", ""]]}, {"id": "2102.07389", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "And/or trade-off in artificial neurons: impact on adversarial robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its discovery in 2013, the phenomenon of adversarial examples has\nattracted a growing amount of attention from the machine learning community. A\ndeeper understanding of the problem could lead to a better comprehension of how\ninformation is processed and encoded in neural networks and, more in general,\ncould help to solve the issue of interpretability in machine learning. Our idea\nto increase adversarial resilience starts with the observation that artificial\nneurons can be divided in two broad categories: AND-like neurons and OR-like\nneurons. Intuitively, the former are characterised by a relatively low number\nof combinations of input values which trigger neuron activation, while for the\nlatter the opposite is true. Our hypothesis is that the presence in a network\nof a sufficiently high number of OR-like neurons could lead to classification\n\"brittleness\" and increase the network's susceptibility to adversarial attacks.\nAfter constructing an operational definition of a neuron AND-like behaviour, we\nproceed to introduce several measures to increase the proportion of AND-like\nneurons in the network: L1 norm weight normalisation; application of an input\nfilter; comparison between the neuron output's distribution obtained when the\nnetwork is fed with the actual data set and the distribution obtained when the\nnetwork is fed with a randomised version of the former called \"scrambled data\nset\". Tests performed on the MNIST data set hint that the proposed measures\ncould represent an interesting direction to explore.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 08:19:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "2102.07412", "submitter": "Mohammad Mohammadamini", "authors": "Hadi Veisi, Hawre Hosseini, Mohammad Mohammadamini (LIA), Wirya Fathy,\n  Aso Mahmudi", "title": "Jira: a Kurdish Speech Recognition System Designing and Building Speech\n  Corpus and Pronunciation Lexicon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the first large vocabulary speech recognition\nsystem (LVSR) for the Central Kurdish language, named Jira. The Kurdish\nlanguage is an Indo-European language spoken by more than 30 million people in\nseveral countries, but due to the lack of speech and text resources, there is\nno speech recognition system for this language. To fill this gap, we introduce\nthe first speech corpus and pronunciation lexicon for the Kurdish language.\nRegarding speech corpus, we designed a sentence collection in which the ratio\nof di-phones in the collection resembles the real data of the Central Kurdish\nlanguage. The designed sentences are uttered by 576 speakers in a controlled\nenvironment with noise-free microphones (called AsoSoft Speech-Office) and in\nTelegram social network environment using mobile phones (denoted as AsoSoft\nSpeech-Crowdsourcing), resulted in 43.68 hours of speech. Besides, a test set\nincluding 11 different document topics is designed and recorded in two\ncorresponding speech conditions (i.e., Office and Crowdsourcing). Furthermore,\na 60K pronunciation lexicon is prepared in this research in which we faced\nseveral challenges and proposed solutions for them. The Kurdish language has\nseveral dialects and sub-dialects that results in many lexical variations. Our\nmethods for script standardization of lexical variations and automatic\npronunciation of the lexicon tokens are presented in detail. To setup the\nrecognition engine, we used the Kaldi toolkit. A statistical tri-gram language\nmodel that is extracted from the AsoSoft text corpus is used in the system.\nSeveral standard recipes including HMM-based models (i.e., mono, tri1, tr2,\ntri2, tri3), SGMM, and DNN methods are used to generate the acoustic model.\nThese methods are trained with AsoSoft Speech-Office and AsoSoft\nSpeech-Crowdsourcing and a combination of them. The best performance achieved\nby the SGMM acoustic model which results in 13.9% of the average word error\nrate (on different document topics) and 4.9% for the general topic.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 09:27:54 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Veisi", "Hadi", "", "LIA"], ["Hosseini", "Hawre", "", "LIA"], ["Mohammadamini", "Mohammad", "", "LIA"], ["Fathy", "Wirya", ""], ["Mahmudi", "Aso", ""]]}, {"id": "2102.07456", "submitter": "Marin Vlastelica Pogan\\v{c}i\\'c", "authors": "Marin Vlastelica, Michal Rol\\'inek and Georg Martius", "title": "Neuro-algorithmic Policies enable Fast Combinatorial Generalization", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although model-based and model-free approaches to learning the control of\nsystems have achieved impressive results on standard benchmarks, generalization\nto task variations is still lacking. Recent results suggest that generalization\nfor standard architectures improves only after obtaining exhaustive amounts of\ndata. We give evidence that generalization capabilities are in many cases\nbottlenecked by the inability to generalize on the combinatorial aspects of the\nproblem. Furthermore, we show that for a certain subclass of the MDP framework,\nthis can be alleviated by neuro-algorithmic architectures.\n  Many control problems require long-term planning that is hard to solve\ngenerically with neural networks alone. We introduce a neuro-algorithmic policy\narchitecture consisting of a neural network and an embedded time-dependent\nshortest path solver. These policies can be trained end-to-end by blackbox\ndifferentiation. We show that this type of architecture generalizes well to\nunseen variations in the environment already after seeing a few examples.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 11:07:59 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Vlastelica", "Marin", ""], ["Rol\u00ednek", "Michal", ""], ["Martius", "Georg", ""]]}, {"id": "2102.07472", "submitter": "Si Lu", "authors": "Si Lu and Ruisi Li", "title": "DAC: Deep Autoencoder-based Clustering, a General Deep Learning\n  Framework of Representation Learning", "comments": "12 pages, 8 figures, 5 tables, Intelligent Systems Conference\n  (IntelliSys) 2021 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering performs an essential role in many real world applications, such\nas market research, pattern recognition, data analysis, and image processing.\nHowever, due to the high dimensionality of the input feature values, the data\nbeing fed to clustering algorithms usually contains noise and thus could lead\nto in-accurate clustering results. While traditional dimension reduction and\nfeature selection algorithms could be used to address this problem, the simple\nheuristic rules used in those algorithms are based on some particular\nassumptions. When those assumptions does not hold, these algorithms then might\nnot work. In this paper, we propose DAC, Deep Autoencoder-based Clustering, a\ngeneralized data-driven framework to learn clustering representations using\ndeep neuron networks. Experiment results show that our approach could\neffectively boost performance of the K-Means clustering algorithm on a variety\ntypes of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 11:31:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lu", "Si", ""], ["Li", "Ruisi", ""]]}, {"id": "2102.07495", "submitter": "Youran Sun", "authors": "Naichen Shi and Ruichen Li and Sun Youran", "title": "ScrofaZero: Mastering Trick-taking Poker Game Gongzhu by Deep\n  Reinforcement Learning", "comments": "The very first versoin. Will be improved in the future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People have made remarkable progress in game AIs, especially in domain of\nperfect information game. However, trick-taking poker game, as a popular form\nof imperfect information game, has been regarded as a challenge for a long\ntime. Since trick-taking game requires high level of not only reasoning, but\nalso inference to excel, it can be a new milestone for imperfect information\ngame AI. We study Gongzhu, a trick-taking game analogous to, but slightly\nsimpler than contract bridge. Nonetheless, the strategies of Gongzhu are\ncomplex enough for both human and computer players. We train a strong Gongzhu\nAI ScrofaZero from \\textit{tabula rasa} by deep reinforcement learning, while\nfew previous efforts on solving trick-taking poker game utilize the\nrepresentation power of neural networks. Also, we introduce new techniques for\nimperfect information game including stratified sampling, importance weighting,\nintegral over equivalent class, Bayesian inference, etc. Our AI can achieve\nhuman expert level performance. The methodologies in building our program can\nbe easily transferred into a wide range of trick-taking games.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:01:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Shi", "Naichen", ""], ["Li", "Ruichen", ""], ["Youran", "Sun", ""]]}, {"id": "2102.07503", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, David Rawlinson", "title": "One-shot learning for the long term: consolidation with an artificial\n  hippocampal algorithm", "comments": "Accepted to 'The International Joint Conference on Neural Networks\n  (IJCNN) 2021' https://www.ijcnn.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard few-shot experiments involve learning to efficiently match\npreviously unseen samples by class. We claim that few-shot learning should be\nlong term, assimilating knowledge for the future, without forgetting previous\nconcepts. In the mammalian brain, the hippocampus is understood to play a\nsignificant role in this process, by learning rapidly and consolidating\nknowledge to the neocortex incrementally over a short period. In this research\nwe tested whether an artificial hippocampal algorithm (AHA), could be used with\na conventional Machine Learning (ML) model that learns incrementally analogous\nto the neocortex, to achieve one-shot learning both short and long term. The\nresults demonstrated that with the addition of AHA, the system could learn in\none-shot and consolidate the knowledge for the long term without catastrophic\nforgetting. This study is one of the first examples of using a CLS model of\nhippocampus to consolidate memories, and it constitutes a step toward few-shot\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:07:26 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 08:37:13 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "2102.07507", "submitter": "Sijie Ji", "authors": "Sijie Ji, Mo Li", "title": "CLNet: Complex Input Lightweight Neural Network designed for Massive\n  MIMO CSI Feedback", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Massive Multiple Input Multiple Output (MIMO) system is a core technology\nof the next generation communication. With the growing complexity of CSI, CSI\nfeedback in massive MIMO system has become a bottleneck problem, the\ntraditional compressive sensing based CSI feedback approaches have limited\nperformance. Recently, numerous deep learning based CSI feedback approaches\ndemonstrate their efficiency and potential. However, most existing methods\nimprove accuracy at the cost of computational complexity and the accuracy\ndecreases significantly as the CSI compression rate increases. This paper\npresents a novel neural network CLNet tailored for CSI feedback problem based\non the intrinsic properties of CSI. The experiment result shows that CLNet\noutperforms the state-of-the-art method by average accuracy improvement of\n5.41% in both outdoor and indoor scenarios with average 24.1% less\ncomputational overhead. Codes are available at GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:16:11 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 14:20:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ji", "Sijie", ""], ["Li", "Mo", ""]]}, {"id": "2102.07523", "submitter": "Nicolas Anastassacos", "authors": "Nicolas Anastassacos, Julian Garc\\'ia, Stephen Hailes, Mirco Musolesi", "title": "Cooperation and Reputation Dynamics with Reinforcement Learning", "comments": "Published in AAMAS'21, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating incentives for cooperation is a challenge in natural and artificial\nsystems. One potential answer is reputation, whereby agents trade the immediate\ncost of cooperation for the future benefits of having a good reputation. Game\ntheoretical models have shown that specific social norms can make cooperation\nstable, but how agents can independently learn to establish effective\nreputation mechanisms on their own is less understood. We use a simple model of\nreinforcement learning to show that reputation mechanisms generate two\ncoordination problems: agents need to learn how to coordinate on the meaning of\nexisting reputations and collectively agree on a social norm to assign\nreputations to others based on their behavior. These coordination problems\nexhibit multiple equilibria, some of which effectively establish cooperation.\nWhen we train agents with a standard Q-learning algorithm in an environment\nwith the presence of reputation mechanisms, convergence to undesirable\nequilibria is widespread. We propose two mechanisms to alleviate this: (i)\nseeding a proportion of the system with fixed agents that steer others towards\ngood equilibria; and (ii), intrinsic rewards based on the idea of\nintrospection, i.e., augmenting agents' rewards by an amount proportionate to\nthe performance of their own strategy against themselves. A combination of\nthese simple mechanisms is successful in stabilizing cooperation, even in a\nfully decentralized version of the problem where agents learn to use and assign\nreputations simultaneously. We show how our results relate to the literature in\nEvolutionary Game Theory, and discuss implications for artificial, human and\nhybrid systems, where reputations can be used as a way to establish trust and\ncooperation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:48:56 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Anastassacos", "Nicolas", ""], ["Garc\u00eda", "Julian", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2102.07536", "submitter": "Nils K\\\"obis C", "authors": "Margarita Leib, Nils C. K\\\"obis, Rainer Michael Rilke, Marloes Hagens,\n  Bernd Irlenbusch", "title": "The corruptive force of AI-generated advice", "comments": "Leib & K\\\"obis share first authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) is increasingly becoming a trusted advisor in\npeople's lives. A new concern arises if AI persuades people to break ethical\nrules for profit. Employing a large-scale behavioural experiment (N = 1,572),\nwe test whether AI-generated advice can corrupt people. We further test whether\ntransparency about AI presence, a commonly proposed policy, mitigates potential\nharm of AI-generated advice. Using the Natural Language Processing algorithm,\nGPT-2, we generated honesty-promoting and dishonesty-promoting advice.\nParticipants read one type of advice before engaging in a task in which they\ncould lie for profit. Testing human behaviour in interaction with actual AI\noutputs, we provide first behavioural insights into the role of AI as an\nadvisor. Results reveal that AI-generated advice corrupts people, even when\nthey know the source of the advice. In fact, AI's corrupting force is as strong\nas humans'.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:15:12 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Leib", "Margarita", ""], ["K\u00f6bis", "Nils C.", ""], ["Rilke", "Rainer Michael", ""], ["Hagens", "Marloes", ""], ["Irlenbusch", "Bernd", ""]]}, {"id": "2102.07537", "submitter": "Diogo Carvalho", "authors": "Diogo S. Carvalho, Joana Campos, Manuel Guimar\\~aes, Ana Antunes,\n  Jo\\~ao Dias, Pedro A. Santos", "title": "CHARET: Character-centered Approach to Emotion Tracking in Stories", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous agents that can engage in social interactions witha human is the\nultimate goal of a myriad of applications. A keychallenge in the design of\nthese applications is to define the socialbehavior of the agent, which requires\nextensive content creation.In this research, we explore how we can leverage\ncurrent state-of-the-art tools to make inferences about the emotional state ofa\ncharacter in a story as events unfold, in a coherent way. Wepropose a character\nrole-labelling approach to emotion tracking thataccounts for the semantics of\nemotions. We show that by identifyingactors and objects of events and\nconsidering the emotional stateof the characters, we can achieve better\nperformance in this task,when compared to end-to-end approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:17:21 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 09:01:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Carvalho", "Diogo S.", ""], ["Campos", "Joana", ""], ["Guimar\u00e3es", "Manuel", ""], ["Antunes", "Ana", ""], ["Dias", "Jo\u00e3o", ""], ["Santos", "Pedro A.", ""]]}, {"id": "2102.07539", "submitter": "Sisay Chala", "authors": "Sisay Chala, Bekele Debisa, Amante Diriba, Silas Getachew, Chala Getu,\n  Solomon Shiferaw", "title": "Crowdsourcing Parallel Corpus for English-Oromo Neural Machine\n  Translation using Community Engagement Platform", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Even though Afaan Oromo is the most widely spoken language in the Cushitic\nfamily by more than fifty million people in the Horn and East Africa, it is\nsurprisingly resource-scarce from a technological point of view. The increasing\namount of various useful documents written in English language brings to\ninvestigate the machine that can translate those documents and make it easily\naccessible for local language. The paper deals with implementing a translation\nof English to Afaan Oromo and vice versa using Neural Machine Translation. But\nthe implementation is not very well explored due to the limited amount and\ndiversity of the corpus. However, using a bilingual corpus of just over 40k\nsentence pairs we have collected, this study showed a promising result. About a\nquarter of this corpus is collected via Community Engagement Platform (CEP)\nthat was implemented to enrich the parallel corpus through crowdsourcing\ntranslations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:22:30 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chala", "Sisay", ""], ["Debisa", "Bekele", ""], ["Diriba", "Amante", ""], ["Getachew", "Silas", ""], ["Getu", "Chala", ""], ["Shiferaw", "Solomon", ""]]}, {"id": "2102.07545", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii", "title": "Data-driven Analysis for Understanding Team Sports Behaviors", "comments": "9 pages, 2 figures. This is the first draft and the final version\n  will be published in the Journal of Robotics and Mechatronics", "journal-ref": "J. Robot. Mechatron., Vol.33, No.3, pp. 505-514, 2021", "doi": "10.20965/jrm.2021.p0505", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding the principles of real-world biological multi-agent behaviors\nis a current challenge in various scientific and engineering fields. The rules\nregarding the real-world biological multi-agent behaviors such as team sports\nare often largely unknown due to their inherently higher-order interactions,\ncognition, and body dynamics. Estimation of the rules from data, i.e.,\ndata-driven approaches such as machine learning, provides an effective way for\nthe analysis of such behaviors. Although most data-driven models have\nnon-linear structures and high prediction performances, it is sometimes hard to\ninterpret them. This survey focuses on data-driven analysis for quantitative\nunderstanding of invasion team sports behaviors such as basketball and\nfootball, and introduces two main approaches for understanding such multi-agent\nbehaviors: (1) extracting easily interpretable features or rules from data and\n(2) generating and controlling behaviors in visually-understandable ways. The\nfirst approach involves the visualization of learned representations and the\nextraction of mathematical structures behind the behaviors. The second approach\ncan be used to test hypotheses by simulating and controlling future and\ncounterfactual behaviors. Lastly, the potential practical applications of\nextracted rules, features, and generated behaviors are discussed. These\napproaches can contribute to a better understanding of multi-agent behaviors in\nthe real world.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:31:45 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 07:27:48 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Fujii", "Keisuke", ""]]}, {"id": "2102.07548", "submitter": "Jichen Zhu", "authors": "Jichen Zhu, Santiago Onta\\~n\\'on", "title": "Player-Centered AI for Automatic Game Personalization: Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer games represent an ideal research domain for the next generation of\npersonalized digital applications. This paper presents a player-centered\nframework of AI for game personalization, complementary to the commonly used\nsystem-centered approaches. Built on the Structure of Actions theory, the paper\nmaps out the current landscape of game personalization research and identifies\neight open problems that need further investigation. These problems require\ndeep collaboration between technological advancement and player experience\ndesign.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:34:38 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhu", "Jichen", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2102.07574", "submitter": "Nathalia Nascimento", "authors": "Giuliano Lorenzoni and Paulo Alencar and Nathalia Nascimento and\n  Donald Cowan", "title": "Machine Learning Model Development from a Software Engineering\n  Perspective: A Systematic Literature Review", "comments": "9 pages, 2 columns. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data scientists often develop machine learning models to solve a variety of\nproblems in the industry and academy but not without facing several challenges\nin terms of Model Development. The problems regarding Machine Learning\nDevelopment involves the fact that such professionals do not realize that they\nusually perform ad-hoc practices that could be improved by the adoption of\nactivities presented in the Software Engineering Development Lifecycle. Of\ncourse, since machine learning systems are different from traditional Software\nsystems, some differences in their respective development processes are to be\nexpected. In this context, this paper is an effort to investigate the\nchallenges and practices that emerge during the development of ML models from\nthe software engineering perspective by focusing on understanding how software\ndevelopers could benefit from applying or adapting the traditional software\nengineering process to the Machine Learning workflow.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 14:25:13 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lorenzoni", "Giuliano", ""], ["Alencar", "Paulo", ""], ["Nascimento", "Nathalia", ""], ["Cowan", "Donald", ""]]}, {"id": "2102.07589", "submitter": "Nathalia Nascimento", "authors": "Nathalia Nascimento and Paulo Alencar and Donald Cowan and Carlos\n  Lucena", "title": "A Reference Model for IoT Embodied Agents Controlled by Neural Networks", "comments": "6 pages, Accepted to be published in IEEE Big Data Conference\n  Proceedings (IEEE Computer Society Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied agents is a term used to denote intelligent agents, which are a\ncomponent of devices belonging to the Internet of Things (IoT) domain. Each\nagent is provided with sensors and actuators to interact with the environment,\nand with a 'controller' that usually contains an artificial neural network\n(ANN). In previous publications, we introduced three software approaches to\ndesign, implement and test IoT embodied agents. In this paper, we propose a\nreference model based on statecharts that offers abstractions tailored to the\ndevelopment of IoT applications. The model represents embodied agents that are\ncontrolled by neural networks. Our model includes the ANN training process,\nrepresented as a reconfiguration step such as changing agent features or neural\nnet connections. Our contributions include the identification of the main\ncharacteristics of IoT embodied agents, a reference model specification based\non statecharts, and an illustrative application of the model to support\nautonomous street lights. The proposal aims to support the design and\nimplementation of IoT applications by providing high-level design abstractions\nand models, thus enabling the designer to have a uniform approach to\nconceiving, designing and explaining such applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:02:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""], ["Lucena", "Carlos", ""]]}, {"id": "2102.07594", "submitter": "Ye Bai", "authors": "Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian, Zhengqi Wen, Shuai\n  Zhang", "title": "Fast End-to-End Speech Recognition via Non-Autoregressive Models and\n  Cross-Modal Knowledge Transferring from BERT", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder (AED) models have achieved promising\nperformance in speech recognition. However, because the decoder predicts text\ntokens (such as characters or words) in an autoregressive manner, it is\ndifficult for an AED model to predict all tokens in parallel. This makes the\ninference speed relatively slow. We believe that because the encoder already\ncaptures the whole speech utterance, which has the token-level relationship\nimplicitly, we can predict a token without explicitly autoregressive language\nmodeling. When the prediction of a token does not rely on other tokens, the\nparallel prediction of all tokens in the sequence is realizable. Based on this\nidea, we propose a non-autoregressive speech recognition model called LASO\n(Listen Attentively, and Spell Once). The model consists of an encoder, a\ndecoder, and a position dependent summarizer (PDS). The three modules are based\non basic attention blocks. The encoder extracts high-level representations from\nthe speech. The PDS uses positional encodings corresponding to tokens to\nconvert the acoustic representations into token-level representations. The\ndecoder further captures token-level relationships with the self-attention\nmechanism. At last, the probability distribution on the vocabulary is computed\nfor each token position. Therefore, speech recognition is re-formulated as a\nposition-wise classification problem. Further, we propose a cross-modal\ntransfer learning method to refine semantics from a large-scale pre-trained\nlanguage model BERT for improving the performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:18:59 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 01:58:56 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 09:06:42 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 06:27:22 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 06:29:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bai", "Ye", ""], ["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Tian", "Zhengkun", ""], ["Wen", "Zhengqi", ""], ["Zhang", "Shuai", ""]]}, {"id": "2102.07599", "submitter": "Suiyi Ling", "authors": "Kevin Riou, Suiyi Ling, Guillaume Gallot, Patrick Le Callet", "title": "Seeing by haptic glance: reinforcement learning-based 3D object\n  Recognition", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Human is able to conduct 3D recognition by a limited number of haptic\ncontacts between the target object and his/her fingers without seeing the\nobject. This capability is defined as `haptic glance' in cognitive\nneuroscience. Most of the existing 3D recognition models were developed based\non dense 3D data. Nonetheless, in many real-life use cases, where robots are\nused to collect 3D data by haptic exploration, only a limited number of 3D\npoints could be collected. In this study, we thus focus on solving the\nintractable problem of how to obtain cognitively representative 3D key-points\nof a target object with limited interactions between the robot and the object.\nA novel reinforcement learning based framework is proposed, where the haptic\nexploration procedure (the agent iteratively predicts the next position for the\nrobot to explore) is optimized simultaneously with the objective 3D recognition\nwith actively collected 3D points. As the model is rewarded only when the 3D\nobject is accurately recognized, it is driven to find the sparse yet efficient\nhaptic-perceptual 3D representation of the object. Experimental results show\nthat our proposed model outperforms the state of the art models.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:38:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Riou", "Kevin", ""], ["Ling", "Suiyi", ""], ["Gallot", "Guillaume", ""], ["Callet", "Patrick Le", ""]]}, {"id": "2102.07617", "submitter": "Yingxu Wang Prof. PhD FIEEE", "authors": "Yingxu Wang, Fakhri Karray, Sam Kwong, Konstantinos N. Plataniotis,\n  Henry Leung, Ming Hou, Edward Tunstel, Imre J. Rudas, Ljiljana Trajkovic,\n  Okyay Kaynak, Janusz Kacprzyk, Mengchu Zhou, Michael H. Smith, Philip Chen\n  and Shushma Patel", "title": "On the Philosophical, Cognitive and Mathematical Foundations of\n  Symbiotic Autonomous Systems (SAS)", "comments": "Accepted by Phil. Trans. Royal Society (A): Math, Phys & Engg Sci.,\n  379(219x), 2021, Oxford, UK", "journal-ref": "Phil. Trans. Royal Society (A): Math, Phys & Engg Sci., 379(219x),\n  2021, Oxford, UK", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Symbiotic Autonomous Systems (SAS) are advanced intelligent and cognitive\nsystems exhibiting autonomous collective intelligence enabled by coherent\nsymbiosis of human-machine interactions in hybrid societies. Basic research in\nthe emerging field of SAS has triggered advanced general AI technologies\nfunctioning without human intervention or hybrid symbiotic systems synergizing\nhumans and intelligent machines into coherent cognitive systems. This work\npresents a theoretical framework of SAS underpinned by the latest advances in\nintelligence, cognition, computer, and system sciences. SAS are characterized\nby the composition of autonomous and symbiotic systems that adopt\nbio-brain-social-inspired and heterogeneously synergized structures and\nautonomous behaviors. This paper explores their cognitive and mathematical\nfoundations. The challenge to seamless human-machine interactions in a hybrid\nenvironment is addressed. SAS-based collective intelligence is explored in\norder to augment human capability by autonomous machine intelligence towards\nthe next generation of general AI, autonomous computers, and trustworthy\nmission-critical intelligent systems. Emerging paradigms and engineering\napplications of SAS are elaborated via an autonomous knowledge learning system\nthat symbiotically works between humans and cognitive robots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 05:44:25 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wang", "Yingxu", ""], ["Karray", "Fakhri", ""], ["Kwong", "Sam", ""], ["Plataniotis", "Konstantinos N.", ""], ["Leung", "Henry", ""], ["Hou", "Ming", ""], ["Tunstel", "Edward", ""], ["Rudas", "Imre J.", ""], ["Trajkovic", "Ljiljana", ""], ["Kaynak", "Okyay", ""], ["Kacprzyk", "Janusz", ""], ["Zhou", "Mengchu", ""], ["Smith", "Michael H.", ""], ["Chen", "Philip", ""], ["Patel", "Shushma", ""]]}, {"id": "2102.07638", "submitter": "Mingyong Zhou", "authors": "Mingyong Zhou", "title": "AI Uncertainty Based on Rademacher Complexity and Shannon Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper from communication channel coding perspective we are able to\npresent both a theoretical and practical discussion of AI's uncertainty,\ncapacity and evolution for pattern classification based on the classical\nRademacher complexity and Shannon entropy. First AI capacity is defined as in\ncommunication channels. It is shown qualitatively that the classical Rademacher\ncomplexity and Shannon entropy used in communication theory is closely related\nby their definitions, given a pattern classification problem with a complexity\nmeasured by Rademacher complexity. Secondly based on the Shannon mathematical\ntheory on communication coding, we derive several sufficient and necessary\nconditions for an AI's error rate approaching zero in classifications problems.\nA 1/2 criteria on Shannon entropy is derived in this paper so that error rate\ncan approach zero or is zero for AI pattern classification problems. Last but\nnot least, we show our analysis and theory by providing examples of AI pattern\nclassifications with error rate approaching zero or being zero.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 04:09:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhou", "Mingyong", ""]]}, {"id": "2102.07643", "submitter": "Alexander Felfernig", "authors": "Mathias Uta and Alexander Felfernig and Gottfried Schenner and\n  Johannes Spoecklberger", "title": "Consistency-based Merging of Variability Models", "comments": "M. Uta, A. Felfernig, G. Schenner, and J. Spoecklberger.\n  Consistency-based Merging of Variability Models, Workshop on Configuration,\n  pp. 9-12, Graz, Austria, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Globally operating enterprises selling large and complex products and\nservices often have to deal with situations where variability models are\nlocally developed to take into account the requirements of local markets. For\nexample, cars sold on the U.S. market are represented by variability models in\nsome or many aspects different from European ones. In order to support global\nvariability management processes, variability models and the underlying\nknowledge bases often need to be integrated. This is a challenging task since\nan integrated knowledge base should not produce results which are different\nfrom those produced by the individual knowledge bases. In this paper, we\nintroduce an approach to variability model integration that is based on the\nconcepts of contextual modeling and conflict detection. We present the\nunderlying concepts and the results of a corresponding performance analysis.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:28:42 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Uta", "Mathias", ""], ["Felfernig", "Alexander", ""], ["Schenner", "Gottfried", ""], ["Spoecklberger", "Johannes", ""]]}, {"id": "2102.07645", "submitter": "Hoyeop Lee", "authors": "Hoyeop Lee, Jinbae Im, Chang Ouk Kim, Sehee Chung", "title": "Freudian and Newtonian Recurrent Cell for Sequential Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A sequential recommender system aims to recommend attractive items to users\nbased on behaviour patterns. The predominant sequential recommendation models\nare based on natural language processing models, such as the gated recurrent\nunit, that embed items in some defined space and grasp the user's long-term and\nshort-term preferences based on the item embeddings. However, these approaches\nlack fundamental insight into how such models are related to the user's\ninherent decision-making process. To provide this insight, we propose a novel\nrecurrent cell, namely FaNC, from Freudian and Newtonian perspectives. FaNC\ndivides the user's state into conscious and unconscious states, and the user's\ndecision process is modelled by Freud's two principles: the pleasure principle\nand reality principle. To model the pleasure principle, i.e., free-floating\nuser's instinct, we place the user's unconscious state and item embeddings in\nthe same latent space and subject them to Newton's law of gravitation.\nMoreover, to recommend items to users, we model the reality principle, i.e.,\nbalancing the conscious and unconscious states, via a gating function. Based on\nextensive experiments on various benchmark datasets, this paper provides\ninsight into the characteristics of the proposed model. FaNC initiates a new\ndirection of sequential recommendations at the convergence of psychoanalysis\nand recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 12:46:23 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lee", "Hoyeop", ""], ["Im", "Jinbae", ""], ["Kim", "Chang Ouk", ""], ["Chung", "Sehee", ""]]}, {"id": "2102.07647", "submitter": "Antonio Candelieri", "authors": "Antonio Candelieri, Andrea Ponti, Francesco Archetti", "title": "Uncertainty quantification and exploration-exploitation trade-off in\n  humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this paper is to outline a theoretical framework to\nanalyse how humans' decision-making strategies under uncertainty manage the\ntrade-off between information gathering (exploration) and reward seeking\n(exploitation). A key observation, motivating this line of research, is the\nawareness that human learners are amazingly fast and effective at adapting to\nunfamiliar environments and incorporating upcoming knowledge: this is an\nintriguing behaviour for cognitive sciences as well as an important challenge\nfor Machine Learning. The target problem considered is active learning in a\nblack-box optimization task and more specifically how the\nexploration/exploitation dilemma can be modelled within Gaussian Process based\nBayesian Optimization framework, which is in turn based on uncertainty\nquantification. The main contribution is to analyse humans' decisions with\nrespect to Pareto rationality where the two objectives are improvement expected\nand uncertainty quantification. According to this Pareto rationality model, if\na decision set contains a Pareto efficient (dominant) strategy, a rational\ndecision maker should always select the dominant strategy over its dominated\nalternatives. The distance from the Pareto frontier determines whether a choice\nis (Pareto) rational (i.e., lays on the frontier) or is associated to\n\"exasperate\" exploration. However, since the uncertainty is one of the two\nobjectives defining the Pareto frontier, we have investigated three different\nuncertainty quantification measures and selected the one resulting more\ncompliant with the Pareto rationality model proposed. The key result is an\nanalytical framework to characterize how deviations from \"rationality\" depend\non uncertainty quantifications and the evolution of the reward seeking process.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 16:03:04 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Candelieri", "Antonio", ""], ["Ponti", "Andrea", ""], ["Archetti", "Francesco", ""]]}, {"id": "2102.07652", "submitter": "Yuanpeng He", "authors": "Yuanpeng He", "title": "TDQMF: Two-dimensional quantum mass function", "comments": "22 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum mass function has been applied in lots of fields because of its\nefficiency and validity of managing uncertainties in the form of quantum which\ncan be regarded as an extension of classical Dempster-Shafer (D-S) evidence\ntheory. However, how to handle uncertainties in the form of quantum is still an\nopen issue. In this paper, a new method is proposed to dispose uncertain\nquantum information, which is called two-dimensional quantum mass function\n(TDQMF). A TDQMF is consist of two elements, TQ = (Qoriginal, Qindicative),\nboth of the Qs are quantum mass functions, in which the Qindicative is an\nindicator of the reliability on Qoriginal. More flexibility and effectiveness\nare offered in handling uncertainty in the field of quantum by the proposed\nmethod compared with primary quantum mass function. Besides, some numerical\nexamples are provided and some practical applications are given to verify its\ncorrectness and validity\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 14:15:41 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["He", "Yuanpeng", ""]]}, {"id": "2102.07657", "submitter": "MohammadMahdi Behzadi", "authors": "MohammadMahdi Behzadi, Horea T. Ilies", "title": "Real-Time Topology Optimization in 3D via Deep Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The published literature on topology optimization has exploded over the last\ntwo decades to include methods that use shape and topological derivatives or\nevolutionary algorithms formulated on various geometric representations and\nparametrizations. One of the key challenges of all these methods is the massive\ncomputational cost associated with 3D topology optimization problems. We\nintroduce a transfer learning method based on a convolutional neural network\nthat (1) can handle high-resolution 3D design domains of various shapes and\ntopologies; (2) supports real-time design space explorations as the domain and\nboundary conditions change; (3) requires a much smaller set of high-resolution\nexamples for the improvement of learning in a new task compared to traditional\ndeep learning networks; (4) is multiple orders of magnitude more efficient than\nthe established gradient-based methods, such as SIMP. We provide numerous 2D\nand 3D examples to showcase the effectiveness and accuracy of our proposed\napproach, including for design domains that are unseen to our source network,\nas well as the generalization capabilities of the transfer learning-based\napproach. Our experiments achieved an average binary accuracy of around 95% at\nreal-time prediction rates. These properties, in turn, suggest that the\nproposed transfer-learning method may serve as the first practical underlying\nframework for real-time 3D design exploration based on topology optimization\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:09:58 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Behzadi", "MohammadMahdi", ""], ["Ilies", "Horea T.", ""]]}, {"id": "2102.07659", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Jun Luo, Ying Wen, Oliver Slumbers, Daniel Graves,\n  Haitham Bou Ammar, Jun Wang, Matthew E. Taylor", "title": "Diverse Auto-Curriculum is Critical for Successful Real-World Multiagent\n  Learning Systems", "comments": "AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent reinforcement learning (MARL) has achieved a remarkable amount of\nsuccess in solving various types of video games. A cornerstone of this success\nis the auto-curriculum framework, which shapes the learning process by\ncontinually creating new challenging tasks for agents to adapt to, thereby\nfacilitating the acquisition of new skills. In order to extend MARL methods to\nreal-world domains outside of video games, we envision in this blue sky paper\nthat maintaining a diversity-aware auto-curriculum is critical for successful\nMARL applications. Specifically, we argue that \\emph{behavioural diversity} is\na pivotal, yet under-explored, component for real-world multiagent learning\nsystems, and that significant work remains in understanding how to design a\ndiversity-aware auto-curriculum. We list four open challenges for\nauto-curriculum techniques, which we believe deserve more attention from this\ncommunity. Towards validating our vision, we recommend modelling realistic\ninteractive behaviours in autonomous driving as an important test bed, and\nrecommend the SMARTS/ULTRA benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:40:02 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 11:31:07 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Yang", "Yaodong", ""], ["Luo", "Jun", ""], ["Wen", "Ying", ""], ["Slumbers", "Oliver", ""], ["Graves", "Daniel", ""], ["Ammar", "Haitham Bou", ""], ["Wang", "Jun", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2102.07662", "submitter": "Bhaskar Mitra", "authors": "Nick Craswell, Bhaskar Mitra, Emine Yilmaz and Daniel Campos", "title": "Overview of the TREC 2020 deep learning track", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.07820", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the second year of the TREC Deep Learning Track, with the goal of\nstudying ad hoc ranking in the large training data regime. We again have a\ndocument retrieval task and a passage retrieval task, each with hundreds of\nthousands of human-labeled training queries. We evaluate using single-shot\nTREC-style evaluation, to give us a picture of which ranking methods work best\nwhen large data is available, with much more comprehensive relevance labeling\non the small number of test queries. This year we have further evidence that\nrankers with BERT-style pretraining outperform other rankers in the large data\nregime.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:47:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Yilmaz", "Emine", ""], ["Campos", "Daniel", ""]]}, {"id": "2102.07686", "submitter": "Dylan Ashley", "authors": "Dylan R. Ashley, Sina Ghiassian, Richard S. Sutton", "title": "Does the Adam Optimizer Exacerbate Catastrophic Forgetting?", "comments": "9 pages in main text + 3 pages of references + 16 pages of\n  appendices, 6 figures in main text + 21 figures in appendices, 6 tables in\n  appendices; source code available at\n  https://github.com/dylanashley/catastrophic-forgetting/tree/arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning and supervised learning\nliterature to (1) provide evidence that the choice of which modern\ngradient-based optimization algorithm is used to train an ANN has a significant\nimpact on the amount of catastrophic forgetting and show that-surprisingly-in\nmany instances classical algorithms such as vanilla SGD experience less\ncatastrophic forgetting than the more modern algorithms such as Adam. We\nempirically compare four different existing metrics for quantifying\ncatastrophic forgetting and (2) show that the degree to which the learning\nsystems experience catastrophic forgetting is sufficiently sensitive to the\nmetric used that a change from one principled metric to another is enough to\nchange the conclusions of a study dramatically. Our results suggest that a much\nmore rigorous experimental methodology is required when looking at catastrophic\nforgetting. Based on our results, we recommend inter-task forgetting in\nsupervised learning must be measured with both retention and relearning metrics\nconcurrently, and intra-task forgetting in reinforcement learning must-at the\nvery least-be measured with pairwise interference.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:32:39 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 19:56:24 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 15:52:01 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 17:00:09 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ashley", "Dylan R.", ""], ["Ghiassian", "Sina", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2102.07711", "submitter": "Anshuka Rangi", "authors": "Anshuka Rangi, Long Tran-Thanh, Haifeng Xu, Massimo Franceschetti", "title": "Secure-UCB: Saving Stochastic Bandits from Poisoning Attacks via Limited\n  Data Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies bandit algorithms under data poisoning attacks in a\nbounded reward setting. We consider a strong attacker model in which the\nattacker can observe both the selected actions and their corresponding rewards,\nand can contaminate the rewards with additive noise. We show that \\emph{any}\nbandit algorithm with regret $O(\\log T)$ can be forced to suffer a regret\n$\\Omega(T)$ with an expected amount of contamination $O(\\log T)$. This amount\nof contamination is also necessary, as we prove that there exists an $O(\\log\nT)$ regret bandit algorithm, specifically the classical UCB, that requires\n$\\Omega(\\log T)$ amount of contamination to suffer regret $\\Omega(T)$. To\ncombat such poising attacks, our second main contribution is to propose a novel\nalgorithm, Secure-UCB, which uses limited \\emph{verification} to access a\nlimited number of uncontaminated rewards. We show that with $O(\\log T)$\nexpected number of verifications, Secure-UCB can restore the order optimal\n$O(\\log T)$ regret \\emph{irrespective of the amount of contamination} used by\nthe attacker. Finally, we prove that for any bandit algorithm, this number of\nverifications $O(\\log T)$ is necessary to recover the order-optimal regret. We\ncan then conclude that Secure-UCB is order-optimal in terms of both the\nexpected regret and the expected number of verifications, and can save\nstochastic bandits from any data poisoning attack.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:02:46 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Rangi", "Anshuka", ""], ["Tran-Thanh", "Long", ""], ["Xu", "Haifeng", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2102.07716", "submitter": "Eric Langlois", "authors": "Eric D. Langlois and Tom Everitt", "title": "How RL Agents Behave When Their Actions Are Modified", "comments": "10 pages (+6 appendix); 7 figures. Published in the AAAI 2021\n  Conference on AI. Code is available at https://github.com/edlanglois/mamdp", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  35(13), 11586-11594 (2021)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in complex environments may require supervision to\nprevent the agent from attempting dangerous actions. As a result of supervisor\nintervention, the executed action may differ from the action specified by the\npolicy. How does this affect learning? We present the Modified-Action Markov\nDecision Process, an extension of the MDP model that allows actions to differ\nfrom the policy. We analyze the asymptotic behaviours of common reinforcement\nlearning algorithms in this setting and show that they adapt in different ways:\nsome completely ignore modifications while others go to various lengths in\ntrying to avoid action modifications that decrease reward. By choosing the\nright algorithm, developers can prevent their agents from learning to\ncircumvent interruptions or constraints, and better control agent responses to\nother kinds of action modification, like self-damage.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:10:03 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 05:06:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Langlois", "Eric D.", ""], ["Everitt", "Tom", ""]]}, {"id": "2102.07718", "submitter": "Ramin Mousa", "authors": "Ramin Mousa, Sara Nazari, Ali Karhe Abadi, Reza Shoukhcheshm, Mohammad\n  Niknam Pirzadeh, Leila Safari", "title": "TI-Capsule: Capsule Network for Stock Exchange Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, the use of social networking data has attracted a lot of academic and\ncommercial attention in predicting the stock market. In most studies in this\narea, the sentiment analysis of the content of user posts on social networks is\nused to predict market fluctuations. Predicting stock marketing is challenging\nbecause of the variables involved. In the short run, the market behaves like a\nvoting machine, but in the long run, it acts like a weighing machine. The\npurpose of this study is to predict EUR/USD stock behavior using Capsule\nNetwork on finance texts and Candlestick images. One of the most important\nfeatures of Capsule Network is the maintenance of features in a vector, which\nalso takes into account the space between features. The proposed model,\nTI-Capsule (Text and Image information based Capsule Neural Network), is\ntrained with both the text and image information simultaneously. Extensive\nexperiments carried on the collected dataset have demonstrated the\neffectiveness of TI-Capsule in solving the stock exchange prediction problem\nwith 91% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:13:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Mousa", "Ramin", ""], ["Nazari", "Sara", ""], ["Abadi", "Ali Karhe", ""], ["Shoukhcheshm", "Reza", ""], ["Pirzadeh", "Mohammad Niknam", ""], ["Safari", "Leila", ""]]}, {"id": "2102.07730", "submitter": "Aniruddh Gopinath Puranic", "authors": "Aniruddh G. Puranic, Jyotirmoy V. Deshmukh and Stefanos Nikolaidis", "title": "Learning from Demonstrations using Signal Temporal Logic", "comments": "Published at Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-from-demonstrations is an emerging paradigm to obtain effective\nrobot control policies for complex tasks via reinforcement learning without the\nneed to explicitly design reward functions. However, it is susceptible to\nimperfections in demonstrations and also raises concerns of safety and\ninterpretability in the learned control policies. To address these issues, we\nuse Signal Temporal Logic to evaluate and rank the quality of demonstrations.\nTemporal logic-based specifications allow us to create non-Markovian rewards,\nand also define interesting causal dependencies between tasks such as\nsequential task specifications. We validate our approach through experiments on\ndiscrete-world and OpenAI Gym environments, and show that our approach\noutperforms the state-of-the-art Maximum Causal Entropy Inverse Reinforcement\nLearning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:28:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Puranic", "Aniruddh G.", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "2102.07736", "submitter": "Baoyu Jing", "authors": "Baoyu Jing, Hanghang Tong, Yada Zhu", "title": "Network of Tensor Time Series", "comments": "Accepted by WWW'2021", "journal-ref": null, "doi": "10.1145/3442381.3449969", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Co-evolving time series appears in a multitude of applications such as\nenvironmental monitoring, financial analysis, and smart transportation. This\npaper aims to address the following challenges, including (C1) how to\nincorporate explicit relationship networks of the time series; (C2) how to\nmodel the implicit relationship of the temporal dynamics. We propose a novel\nmodel called Network of Tensor Time Series, which is comprised of two modules,\nincluding Tensor Graph Convolutional Network (TGCN) and Tensor Recurrent Neural\nNetwork (TRNN). TGCN tackles the first challenge by generalizing Graph\nConvolutional Network (GCN) for flat graphs to tensor graphs, which captures\nthe synergy between multiple graphs associated with the tensors. TRNN leverages\ntensor decomposition to model the implicit relationships among co-evolving time\nseries. The experimental results on five real-world datasets demonstrate the\nefficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:34:18 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 16:42:17 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 04:13:41 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jing", "Baoyu", ""], ["Tong", "Hanghang", ""], ["Zhu", "Yada", ""]]}, {"id": "2102.07764", "submitter": "Daniel Lenton", "authors": "Daniel Lenton, Stephen James, Ronald Clark, Andrew J. Davison", "title": "End-to-End Egospheric Spatial Memory", "comments": "Conference paper at ICLR 2021. Implementation:\n  https://github.com/ivy-dl/memory Project page: https://djl11.github.io/ESM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial memory, or the ability to remember and recall specific locations and\nobjects, is central to autonomous agents' ability to carry out tasks in real\nenvironments. However, most existing artificial memory modules are not very\nadept at storing spatial information. We propose a parameter-free module,\nEgospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere\naround the agent, enabling expressive 3D representations. ESM can be trained\nend-to-end via either imitation or reinforcement learning, and improves both\ntraining efficiency and final performance against other memory baselines on\nboth drone and manipulator visuomotor control tasks. The explicit egocentric\ngeometry also enables us to seamlessly combine the learned controller with\nother non-learned modalities, such as local obstacle avoidance. We further show\napplications to semantic segmentation on the ScanNet dataset, where ESM\nnaturally combines image-level and map-level inference modalities. Through our\nbroad set of experiments, we show that ESM provides a general computation graph\nfor embodied spatial reasoning, and the module forms a bridge between real-time\nmapping systems and differentiable memory architectures. Implementation at:\nhttps://github.com/ivy-dl/memory.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:59:07 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 18:56:39 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lenton", "Daniel", ""], ["James", "Stephen", ""], ["Clark", "Ronald", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2102.07770", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Kyungwoo Song, Seungjae Shin, Wanmo Kang, Il-Chul Moon", "title": "Posterior-Aided Regularization for Likelihood-Free Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of likelihood-free inference aims training a flexible\ndensity estimator for the target posterior with a set of input-output pairs\nfrom simulation. Given the diversity of simulation structures, it is difficult\nto find a single unified inference method for each simulation model. This paper\nproposes a universally applicable regularization technique, called\nPosterior-Aided Regularization (PAR), which is applicable to learning the\ndensity estimator, regardless of the model structure. Particularly, PAR solves\nthe mode collapse problem that arises as the output dimension of the simulation\nincreases. PAR resolves this posterior mode degeneracy through a mixture of 1)\nthe reverse KL divergence with the mode seeking property; and 2) the mutual\ninformation for the high quality representation on likelihood. Because of the\nestimation intractability of PAR, we provide a unified estimation method of PAR\nto estimate both reverse KL term and mutual information term with a single\nneural network. Afterwards, we theoretically prove the asymptotic convergence\nof the regularized optimal solution to the unregularized optimal solution as\nthe regularization magnitude converges to zero. Additionally, we empirically\nshow that past sequential neural likelihood inferences in conjunction with PAR\npresent the statistically significant gains on diverse simulation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:59:30 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kim", "Dongjun", ""], ["Song", "Kyungwoo", ""], ["Shin", "Seungjae", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2102.07800", "submitter": "Rajat Sen", "authors": "Rajat Sen, Alexander Rakhlin, Lexing Ying, Rahul Kidambi, Dean Foster,\n  Daniel Hill, Inderjit Dhillon", "title": "Top-$k$ eXtreme Contextual Bandits with Arm Hierarchy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by modern applications, such as online advertisement and\nrecommender systems, we study the top-$k$ extreme contextual bandits problem,\nwhere the total number of arms can be enormous, and the learner is allowed to\nselect $k$ arms and observe all or some of the rewards for the chosen arms. We\nfirst propose an algorithm for the non-extreme realizable setting, utilizing\nthe Inverse Gap Weighting strategy for selecting multiple arms. We show that\nour algorithm has a regret guarantee of $O(k\\sqrt{(A-k+1)T \\log\n(|\\mathcal{F}|T)})$, where $A$ is the total number of arms and $\\mathcal{F}$ is\nthe class containing the regression function, while only requiring\n$\\tilde{O}(A)$ computation per time step. In the extreme setting, where the\ntotal number of arms can be in the millions, we propose a practically-motivated\narm hierarchy model that induces a certain structure in mean rewards to ensure\nstatistical and computational efficiency. The hierarchical structure allows for\nan exponential reduction in the number of relevant arms for each context, thus\nresulting in a regret guarantee of $O(k\\sqrt{(\\log A-k+1)T \\log\n(|\\mathcal{F}|T)})$. Finally, we implement our algorithm using a hierarchical\nlinear function class and show superior performance with respect to well-known\nbenchmarks on simulated bandit feedback experiments using extreme multi-label\nclassification datasets. On a dataset with three million arms, our reduction\nscheme has an average inference time of only 7.9 milliseconds, which is a 100x\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 19:10:52 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sen", "Rajat", ""], ["Rakhlin", "Alexander", ""], ["Ying", "Lexing", ""], ["Kidambi", "Rahul", ""], ["Foster", "Dean", ""], ["Hill", "Daniel", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2102.07817", "submitter": "Markus Langer Dr.", "authors": "Markus Langer, Daniel Oster, Timo Speith, Holger Hermanns, Lena\n  K\\\"astner, Eva Schmidt, Andreas Sesing, Kevin Baum", "title": "What Do We Want From Explainable Artificial Intelligence (XAI)? -- A\n  Stakeholder Perspective on XAI and a Conceptual Model Guiding\n  Interdisciplinary XAI Research", "comments": "57 pages, 2 figures, 1 table, to be published in Artificial\n  Intelligence, Markus Langer, Daniel Oster and Timo Speith share\n  first-authorship of this paper", "journal-ref": null, "doi": "10.1016/j.artint.2021.103473", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Previous research in Explainable Artificial Intelligence (XAI) suggests that\na main aim of explainability approaches is to satisfy specific interests,\ngoals, expectations, needs, and demands regarding artificial systems (we call\nthese stakeholders' desiderata) in a variety of contexts. However, the\nliterature on XAI is vast, spreads out across multiple largely disconnected\ndisciplines, and it often remains unclear how explainability approaches are\nsupposed to achieve the goal of satisfying stakeholders' desiderata. This paper\ndiscusses the main classes of stakeholders calling for explainability of\nartificial systems and reviews their desiderata. We provide a model that\nexplicitly spells out the main concepts and relations necessary to consider and\ninvestigate when evaluating, adjusting, choosing, and developing explainability\napproaches that aim to satisfy stakeholders' desiderata. This model can serve\nresearchers from the variety of different disciplines involved in XAI as a\ncommon ground. It emphasizes where there is interdisciplinary potential in the\nevaluation and the development of explainability approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 19:54:33 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Langer", "Markus", ""], ["Oster", "Daniel", ""], ["Speith", "Timo", ""], ["Hermanns", "Holger", ""], ["K\u00e4stner", "Lena", ""], ["Schmidt", "Eva", ""], ["Sesing", "Andreas", ""], ["Baum", "Kevin", ""]]}, {"id": "2102.07820", "submitter": "Eduardo Carvalho Nunes", "authors": "Eduardo C. Nunes", "title": "Anomalous Sound Detection with Machine Learning: A Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomalous sound detection (ASD) is the task of identifying whether the sound\nemitted from an object is normal or anomalous. In some cases, early detection\nof this anomaly can prevent several problems. This article presents a\nSystematic Review (SR) about studies related to Anamolous Sound Detection using\nMachine Learning (ML) techniques. This SR was conducted through a selection of\n31 (accepted studies) studies published in journals and conferences between\n2010 and 2020. The state of the art was addressed, collecting data sets,\nmethods for extracting features in audio, ML models, and evaluation methods\nused for ASD. The results showed that the ToyADMOS, MIMII, and Mivia datasets,\nthe Mel-frequency cepstral coefficients (MFCC) method for extracting features,\nthe Autoencoder (AE) and Convolutional Neural Network (CNN) models of ML, the\nAUC and F1-score evaluation methods were most cited.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 19:57:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Nunes", "Eduardo C.", ""]]}, {"id": "2102.07825", "submitter": "Alexander Felfernig", "authors": "Martin Stettinger and Trang Tran and Ingo Pribik and Gerhard Leitner\n  and Alexander Felfernig and Ralph Samer and Muesluem Atas and Manfred Wundara", "title": "KnowledgeCheckR: Intelligent Techniques for Counteracting Forgetting", "comments": "M. Stettinger, T. N. T. Tran, I. Pribik, G. Leitner, A. Felfernig, R.\n  Samer, M. Atas, and M. Wundara. KNOWLEDGECHECKR: Intelligent Techniques for\n  Counteracting Forgetting, The 24th European Conference on Artificial\n  Intelligence (ECAI 2020), pp. 3034-3039, Santiago de Compostela, Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing e-learning environments primarily focus on the aspect of providing\nintuitive learning contents and to recommend learning units in a personalized\nfashion. The major focus of the KnowledgeCheckR environment is to take into\naccount forgetting processes which immediately start after a learning unit has\nbeen completed. In this context, techniques are needed that are able to predict\nwhich learning units are the most relevant ones to be repeated in future\nlearning sessions. In this paper, we provide an overview of the recommendation\napproaches integrated in KnowledgeCheckR. Examples thereof are utility-based\nrecommendation that helps to identify learning contents to be repeated in the\nfuture, collaborative filtering approaches that help to implement session-based\nrecommendation, and content-based recommendation that supports intelligent\nquestion answering. In order to show the applicability of the presented\ntechniques, we provide an overview of the results of empirical studies that\nhave been conducted in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:06:28 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Stettinger", "Martin", ""], ["Tran", "Trang", ""], ["Pribik", "Ingo", ""], ["Leitner", "Gerhard", ""], ["Felfernig", "Alexander", ""], ["Samer", "Ralph", ""], ["Atas", "Muesluem", ""], ["Wundara", "Manfred", ""]]}, {"id": "2102.07826", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama, Masaya Abe, Kei Nakagawa, Kenichiro McAlinn", "title": "Controlling False Discovery Rates under Cross-Sectional Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider controlling the false discovery rate for testing many time series\nwith an unknown cross-sectional correlation structure. Given a large number of\nhypotheses, false and missing discoveries can plague an analysis. While many\nprocedures have been proposed to control false discovery, most of them either\nassume independent hypotheses or lack statistical power. A problem of\nparticular interest is in financial asset pricing, where the goal is to\ndetermine which ``factors\" lead to excess returns out of a large number of\npotential factors. Our contribution is two-fold. First, we show the consistency\nof Fama and French's prominent method under multiple testing. Second, we\npropose a novel method for false discovery control using double bootstrapping.\nWe achieve superior statistical power to existing methods and prove that the\nfalse discovery rate is controlled. Simulations and a real data application\nillustrate the efficacy of our method over existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:07:17 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 04:53:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Komiyama", "Junpei", ""], ["Abe", "Masaya", ""], ["Nakagawa", "Kei", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "2102.07838", "submitter": "Ishwar Venugopal", "authors": "Ishwar Venugopal, Jessica T\\\"ollich, Michael Fairbank, Ansgar Scherp", "title": "A Comparison of Deep-Learning Methods for Analysing and Predicting\n  Business Processes", "comments": "How to cite: I. Venugopal, J. T\\\"ollich, M. Fairbank, A. Scherp, \"A\n  Comparison of Deep-Learning Methods for Analysing and Predicting Business\n  Processes\" in Proceedings of International Joint Conference on Neural\n  Networks, IJCNN, IEEE Press, July 18-22, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep-learning models such as Convolutional Neural Networks (CNN) and Long\nShort-Term Memory (LSTM) have been successfully used for process-mining tasks.\nThey have achieved better performance for different predictive tasks than\ntraditional approaches. We extend the existing body of research by testing four\ndifferent variants of Graph Neural Networks (GNN) and a fully connected\nMulti-layer Perceptron (MLP) with dropout for the tasks of predicting the\nnature and timestamp of the next process activity. In contrast to existing\nstudies, we evaluate our models' performance at different stages of a process,\ndetermined by quartiles of the number of events and normalized quarters of the\ncase duration. This provides new insights into the performance of a prediction\nmodel, as they behave differently at different stages of a business-process.\nInterestingly, our experiments show that the simple MLP often outperforms more\nsophisticated deep-learning models in both prediction tasks. We argue that care\nneeds to be taken when applying automated process-prediction techniques at\ndifferent stages of a process. We further argue that researchers should reflect\ntheir results with strong baselines methods like simple MLPs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:10:30 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 08:58:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Venugopal", "Ishwar", ""], ["T\u00f6llich", "Jessica", ""], ["Fairbank", "Michael", ""], ["Scherp", "Ansgar", ""]]}, {"id": "2102.07846", "submitter": "Friso Heslinga", "authors": "Friso G. Heslinga, Ruben T. Lucassen, Myrthe A. van den Berg, Luuk van\n  der Hoek, Josien P.W. Pluim, Javier Cabrerizo, Mark Alberti, Mitko Veta", "title": "Corneal Pachymetry by AS-OCT after Descemet's Membrane Endothelial\n  Keratoplasty", "comments": "Fixed typo in abstract: The development set consists of 960 B-scans\n  from 50 patients (instead of 68). The B-scans from the other 18 patients were\n  used for testing only", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corneal thickness (pachymetry) maps can be used to monitor restoration of\ncorneal endothelial function, for example after Descemet's membrane endothelial\nkeratoplasty (DMEK). Automated delineation of the corneal interfaces in\nanterior segment optical coherence tomography (AS-OCT) can be challenging for\ncorneas that are irregularly shaped due to pathology, or as a consequence of\nsurgery, leading to incorrect thickness measurements. In this research, deep\nlearning is used to automatically delineate the corneal interfaces and measure\ncorneal thickness with high accuracy in post-DMEK AS-OCT B-scans. Three\ndifferent deep learning strategies were developed based on 960 B-scans from 50\npatients. On an independent test set of 320 B-scans, corneal thickness could be\nmeasured with an error of 13.98 to 15.50 micrometer for the central 9 mm range,\nwhich is less than 3% of the average corneal thickness. The accurate thickness\nmeasurements were used to construct detailed pachymetry maps. Moreover,\nfollow-up scans could be registered based on anatomical landmarks to obtain\ndifferential pachymetry maps. These maps may enable a more comprehensive\nunderstanding of the restoration of the endothelial function after DMEK, where\nthickness often varies throughout different regions of the cornea, and\nsubsequently contribute to a standardized postoperative regime.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 20:56:54 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 09:48:35 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Heslinga", "Friso G.", ""], ["Lucassen", "Ruben T.", ""], ["Berg", "Myrthe A. van den", ""], ["van der Hoek", "Luuk", ""], ["Pluim", "Josien P. W.", ""], ["Cabrerizo", "Javier", ""], ["Alberti", "Mark", ""], ["Veta", "Mitko", ""]]}, {"id": "2102.07849", "submitter": "Sara Abdali", "authors": "Sara Abdali, Rutuja Gurav, Siddharth Menon, Daniel Fonseca, Negin\n  Entezari, Neil Shah, Evangelos E. Papalexakis", "title": "Identifying Misinformation from Website Screenshots", "comments": null, "journal-ref": "The International AAAI Conference on Web and Social Media (ICWSM)\n  2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:05:11 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 22:32:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abdali", "Sara", ""], ["Gurav", "Rutuja", ""], ["Menon", "Siddharth", ""], ["Fonseca", "Daniel", ""], ["Entezari", "Negin", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2102.07857", "submitter": "Sara Abdali", "authors": "Sara Abdali, Neil Shah, Evangelos E. Papalexakis", "title": "KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection", "comments": null, "journal-ref": "Second International TrueFact Workshop 2020: Making a Credible Web\n  for Tomorrow", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:41:12 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2102.07870", "submitter": "Michael E. Sander", "authors": "Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyr\\'e", "title": "Momentum Residual Neural Networks", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The training of deep residual neural networks (ResNets) with backpropagation\nhas a memory cost that increases linearly with respect to the depth of the\nnetwork. A way to circumvent this issue is to use reversible architectures. In\nthis paper, we propose to change the forward rule of a ResNet by adding a\nmomentum term. The resulting networks, momentum residual neural networks\n(Momentum ResNets), are invertible. Unlike previous invertible architectures,\nthey can be used as a drop-in replacement for any existing ResNet block. We\nshow that Momentum ResNets can be interpreted in the infinitesimal step size\nregime as second-order ordinary differential equations (ODEs) and exactly\ncharacterize how adding momentum progressively increases the representation\ncapabilities of Momentum ResNets. Our analysis reveals that Momentum ResNets\ncan learn any linear mapping up to a multiplicative factor, while ResNets\ncannot. In a learning to optimize setting, where convergence to a fixed point\nis required, we show theoretically and empirically that our method succeeds\nwhile existing invertible architectures fail. We show on CIFAR and ImageNet\nthat Momentum ResNets have the same accuracy as ResNets, while having a much\nsmaller memory footprint, and show that pre-trained Momentum ResNets are\npromising for fine-tuning models.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 22:24:52 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 12:29:54 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 08:18:05 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sander", "Michael E.", ""], ["Ablin", "Pierre", ""], ["Blondel", "Mathieu", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "2102.07900", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Jean-Luc Gaudiot, Hironori Kasahara", "title": "Engineering Education in the Age of Autonomous Machines", "comments": "to appear in IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, we have observed a huge supply-demand gap for\nautonomous driving engineers. The core problem is that autonomous driving is\nnot one single technology but rather a complex system integrating many\ntechnologies, and no one single academic department can provide comprehensive\neducation in this field. We advocate to create a cross-disciplinary program to\nexpose students with technical background in computer science, computer\nengineering, electrical engineering, as well as mechanical engineering. On top\nof the cross-disciplinary technical foundation, a capstone project that\nprovides students with hands-on experiences of working with a real autonomous\nvehicle is required to consolidate the technical foundation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 00:44:14 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Liu", "Shaoshan", ""], ["Gaudiot", "Jean-Luc", ""], ["Kasahara", "Hironori", ""]]}, {"id": "2102.07917", "submitter": "Luis Claudio Sugi Afonso", "authors": "Nathalia Q. Ascen\\c{c}\\~ao, Luis C. S. Afonso, Danilo Colombo, Luciano\n  Oliveira, Jo\\~ao P. Papa", "title": "Information Ranking Using Optimum-Path Forest", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207689", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of learning to rank has been widely studied by the machine learning\ncommunity, mainly due to its use and great importance in information retrieval,\ndata mining, and natural language processing. Therefore, ranking accurately and\nlearning to rank are crucial tasks. Context-Based Information Retrieval systems\nhave been of great importance to reduce the effort of finding relevant data.\nSuch systems have evolved by using machine learning techniques to improve their\nresults, but they are mainly dependent on user feedback. Although information\nretrieval has been addressed in different works along with classifiers based on\nOptimum-Path Forest (OPF), these have so far not been applied to the learning\nto rank task. Therefore, the main contribution of this work is to evaluate\nclassifiers based on Optimum-Path Forest, in such a context. Experiments were\nperformed considering the image retrieval and ranking scenarios, and the\nperformance of OPF-based approaches was compared to the well-known SVM-Rank\npairwise technique and a baseline based on distance calculation. The\nexperiments showed competitive results concerning precision and outperformed\ntraditional techniques in terms of computational load.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 02:01:29 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ascen\u00e7\u00e3o", "Nathalia Q.", ""], ["Afonso", "Luis C. S.", ""], ["Colombo", "Danilo", ""], ["Oliveira", "Luciano", ""], ["Papa", "Jo\u00e3o P.", ""]]}, {"id": "2102.07920", "submitter": "Kei Ota", "authors": "Kei Ota, Devesh K. Jha, Asako Kanezaki", "title": "Training Larger Networks for Deep Reinforcement Learning", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in the computer vision and natural language\nprocessing communities can be attributed to training of very deep neural\nnetworks with millions or billions of parameters which can then be trained with\nmassive amounts of data. However, similar trend has largely eluded training of\ndeep reinforcement learning (RL) algorithms where larger networks do not lead\nto performance improvement. Previous work has shown that this is mostly due to\ninstability during training of deep RL agents when using larger networks. In\nthis paper, we make an attempt to understand and address training of larger\nnetworks for deep RL. We first show that naively increasing network capacity\ndoes not improve performance. Then, we propose a novel method that consists of\n1) wider networks with DenseNet connection, 2) decoupling representation\nlearning from training of RL, 3) a distributed training method to mitigate\noverfitting problems. Using this three-fold technique, we show that we can\ntrain very large networks that result in significant performance gains. We\npresent several ablation studies to demonstrate the efficacy of the proposed\nmethod and some intuitive understanding of the reasons for performance gain. We\nshow that our proposed method outperforms other baseline algorithms on several\nchallenging locomotion tasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 02:16:54 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ota", "Kei", ""], ["Jha", "Devesh K.", ""], ["Kanezaki", "Asako", ""]]}, {"id": "2102.07933", "submitter": "Jintang Li", "authors": "Jintang Li, Kun Xu, Liang Chen, Zibin Zheng and Xiao Liu", "title": "GraphGallery: A Platform for Fast Benchmarking and Easy Development of\n  Graph Neural Networks Based Intelligent Software", "comments": "4 pages Demonstrations track paper accepted at ICSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have recently shown to be powerful tools for\nrepresenting and analyzing graph data. So far GNNs is becoming an increasingly\ncritical role in software engineering including program analysis, type\ninference, and code representation. In this paper, we introduce GraphGallery, a\nplatform for fast benchmarking and easy development of GNNs based software.\nGraphGallery is an easy-to-use platform that allows developers to automatically\ndeploy GNNs even with less domain-specific knowledge. It offers a set of\nimplementations of common GNN models based on mainstream deep learning\nframeworks. In addition, existing GNNs toolboxes such as PyG and DGL can be\neasily incorporated into the platform. Experiments demonstrate the reliability\nof implementations and superiority in fast coding. The official source code of\nGraphGallery is available at https://github.com/EdisonLeeeee/GraphGallery and a\ndemo video can be found at https://youtu.be/mv7Zs1YeaYo.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:07:24 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Li", "Jintang", ""], ["Xu", "Kun", ""], ["Chen", "Liang", ""], ["Zheng", "Zibin", ""], ["Liu", "Xiao", ""]]}, {"id": "2102.07943", "submitter": "Zhao Kang", "authors": "Zhao Kang, Zhiping Lin, Xiaofeng Zhu, Wenbo Xu", "title": "Structured Graph Learning for Scalable Subspace Clustering: From\n  Single-view to Multi-view", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph-based subspace clustering methods have exhibited promising performance.\nHowever, they still suffer some of these drawbacks: encounter the expensive\ntime overhead, fail in exploring the explicit clusters, and cannot generalize\nto unseen data points. In this work, we propose a scalable graph learning\nframework, seeking to address the above three challenges simultaneously.\nSpecifically, it is based on the ideas of anchor points and bipartite graph.\nRather than building a $n\\times n$ graph, where $n$ is the number of samples,\nwe construct a bipartite graph to depict the relationship between samples and\nanchor points. Meanwhile, a connectivity constraint is employed to ensure that\nthe connected components indicate clusters directly. We further establish the\nconnection between our method and the K-means clustering. Moreover, a model to\nprocess multi-view data is also proposed, which is linear scaled with respect\nto $n$. Extensive experiments demonstrate the efficiency and effectiveness of\nour approach with respect to many state-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:46:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kang", "Zhao", ""], ["Lin", "Zhiping", ""], ["Zhu", "Xiaofeng", ""], ["Xu", "Wenbo", ""]]}, {"id": "2102.07951", "submitter": "Boulbaba Ben Amor Prof.", "authors": "Boulbaba Ben Amor, Sylvain Arguill\\`ere and Ling Shao", "title": "ResNet-LDDMM: Advancing the LDDMM Framework Using Deep Residual Networks", "comments": "Submitted to T-PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In deformable registration, the geometric framework - large deformation\ndiffeomorphic metric mapping or LDDMM, in short - has inspired numerous\ntechniques for comparing, deforming, averaging and analyzing shapes or images.\nGrounded in flows, which are akin to the equations of motion used in fluid\ndynamics, LDDMM algorithms solve the flow equation in the space of plausible\ndeformations, i.e. diffeomorphisms. In this work, we make use of deep residual\nneural networks to solve the non-stationary ODE (flow equation) based on a\nEuler's discretization scheme. The central idea is to represent time-dependent\nvelocity fields as fully connected ReLU neural networks (building blocks) and\nderive optimal weights by minimizing a regularized loss function. Computing\nminimizing paths between deformations, thus between shapes, turns to find\noptimal network parameters by back-propagating over the intermediate building\nblocks. Geometrically, at each time step, ResNet-LDDMM searches for an optimal\npartition of the space into multiple polytopes, and then computes optimal\nvelocity vectors as affine transformations on each of these polytopes. As a\nresult, different parts of the shape, even if they are close (such as two\nfingers of a hand), can be made to belong to different polytopes, and therefore\nbe moved in different directions without costing too much energy. Importantly,\nwe show how diffeomorphic transformations, or more precisely bilipshitz\ntransformations, are predicted by our algorithm. We illustrate these ideas on\ndiverse registration problems of 3D shapes under complex topology-preserving\ntransformations. We thus provide essential foundations for more advanced shape\nvariability analysis under a novel joint geometric-neural networks\nRiemannian-like framework, i.e. ResNet-LDDMM.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 04:07:13 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Amor", "Boulbaba Ben", ""], ["Arguill\u00e8re", "Sylvain", ""], ["Shao", "Ling", ""]]}, {"id": "2102.07954", "submitter": "Dilin Wang", "authors": "Dilin Wang, Chengyue Gong, Meng Li, Qiang Liu, Vikas Chandra", "title": "AlphaNet: Improved Training of Supernets with Alpha-Divergence", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weight-sharing neural architecture search (NAS) is an effective technique for\nautomating efficient neural architecture design. Weight-sharing NAS builds a\nsupernet that assembles all the architectures as its sub-networks and jointly\ntrains the supernet with the sub-networks. The success of weight-sharing NAS\nheavily relies on distilling the knowledge of the supernet to the sub-networks.\nHowever, we find that the widely used distillation divergence, i.e., KL\ndivergence, may lead to student sub-networks that over-estimate or\nunder-estimate the uncertainty of the teacher supernet, leading to inferior\nperformance of the sub-networks. In this work, we propose to improve the\nsupernet training with a more generalized alpha-divergence. By adaptively\nselecting the alpha-divergence, we simultaneously prevent the over-estimation\nor under-estimation of the uncertainty of the teacher model. We apply the\nproposed alpha-divergence based supernets training to both slimmable neural\nnetworks and weight-sharing NAS, and demonstrate significant improvements.\nSpecifically, our discovered model family, AlphaNet, outperforms prior-art\nmodels on a wide range of FLOPs regimes, including BigNAS, Once-for-All\nnetworks, and AttentiveNAS. We achieve ImageNet top-1 accuracy of 80.0% with\nonly 444M FLOPs. Our code and pretrained models are available at\nhttps://github.com/facebookresearch/AlphaNet.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 04:23:55 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 17:19:59 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Wang", "Dilin", ""], ["Gong", "Chengyue", ""], ["Li", "Meng", ""], ["Liu", "Qiang", ""], ["Chandra", "Vikas", ""]]}, {"id": "2102.07960", "submitter": "Maryam Majidi", "authors": "Maryam Majidi and Rahil Mahdian Toroghi", "title": "A Combination of Multi-Objective Genetic Algorithm and Deep Learning for\n  Music Harmony Generation", "comments": "14 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic Music Generation (AMG) has become an interesting research topic for\nmany scientists in artificial intelligence, who are also interested in the\nmusic industry. One of the main challenges in AMG is that there is no clear\nobjective evaluation criterion that can measure the music grammar, structural\nrules, and audience satisfaction. Also, original music contains different\nelements that should work together, such as melody, harmony, and rhythm; but in\nthe most of previous works, AMG works only for one element (e.g., melody).\nTherefore, in this paper, we propose a Multi-Objective Genetic Algorithm\n(MO-GA) to generate polyphonic music pieces, considering grammar and listener\nsatisfaction. In this method, we use three objective functions. The first\nobjective function is the accuracy of the generated music piece, based on music\ntheory; and the other two objective functions are modeled scores provided by\nmusic experts and ordinary listeners. The scoring of experts and listeners\nseparately are modeled using Bi-directional Long Short-Term Memory (Bi-LSTM)\nneural networks. The proposed music generation system tries to maximize\nmentioned objective functions to generate a new piece of music, including\nmelody and harmony. The results show that the proposed method can generate\npleasant pieces with desired styles and lengths, along with harmonic sounds\nthat follow the grammar.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 05:05:54 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 06:16:38 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Majidi", "Maryam", ""], ["Toroghi", "Rahil Mahdian", ""]]}, {"id": "2102.07978", "submitter": "Ning Li", "authors": "Ning Li, Tao Li, Chunyu Hu, Kai Wang, Hong Kang", "title": "A Benchmark of Ocular Disease Intelligent Recognition: One Shot for\n  Multi-disease Detection", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ophthalmology, early fundus screening is an economic and effective way to\nprevent blindness caused by ophthalmic diseases. Clinically, due to the lack of\nmedical resources, manual diagnosis is time-consuming and may delay the\ncondition. With the development of deep learning, some researches on ophthalmic\ndiseases have achieved good results, however, most of them are just based on\none disease. During fundus screening, ophthalmologists usually give diagnoses\nof multi-disease on binocular fundus image, so we release a dataset with 8\ndiseases to meet the real medical scene, which contains 10,000 fundus images\nfrom both eyes of 5,000 patients. We did some benchmark experiments on it\nthrough some state-of-the-art deep neural networks. We found simply increasing\nthe scale of network cannot bring good results for multi-disease\nclassification, and a well-structured feature fusion method combines\ncharacteristics of multi-disease is needed. Through this work, we hope to\nadvance the research of related fields.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:00:49 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Li", "Ning", ""], ["Li", "Tao", ""], ["Hu", "Chunyu", ""], ["Wang", "Kai", ""], ["Kang", "Hong", ""]]}, {"id": "2102.07981", "submitter": "Mingbao Lin", "authors": "Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Fei Chao,\n  Mingliang Xu, Chia-Wen Lin, Ling Shao", "title": "SiMaN: Sign-to-Magnitude Network Binarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Binary neural networks (BNNs) have attracted broad research interest due to\ntheir efficient storage and computational ability. Nevertheless, a significant\nchallenge of BNNs lies in handling discrete constraints while ensuring bit\nentropy maximization, which typically makes their weight optimization very\ndifficult. Existing methods relax the learning using the sign function, which\nsimply encodes positive weights into +1s, and -1s otherwise. Alternatively, we\nformulate an angle alignment objective to constrain the weight binarization to\n{0,+1} to solve the challenge. In this paper, we show that our weight\nbinarization provides an analytical solution by encoding high-magnitude weights\ninto +1s, and 0s otherwise. Therefore, a high-quality discrete solution is\nestablished in a computationally efficient manner without the sign function. We\nprove that the learned weights of binarized networks roughly follow a Laplacian\ndistribution that does not allow entropy maximization, and further demonstrate\nthat it can be effectively solved by simply removing the $\\ell_2$\nregularization during network training. Our method, dubbed sign-to-magnitude\nnetwork binarization (SiMaN), is evaluated on CIFAR-10 and ImageNet,\ndemonstrating its superiority over the sign-based state-of-the-arts. Our source\ncode, experimental settings, training logs and binary models are available at\nhttps://github.com/lmbxmu/SiMaN.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:03:51 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 12:51:21 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Lin", "Mingbao", ""], ["Ji", "Rongrong", ""], ["Xu", "Zihan", ""], ["Zhang", "Baochang", ""], ["Chao", "Fei", ""], ["Xu", "Mingliang", ""], ["Lin", "Chia-Wen", ""], ["Shao", "Ling", ""]]}, {"id": "2102.07995", "submitter": "Yunhui Zheng", "authors": "Yunhui Zheng, Saurabh Pujar, Burn Lewis, Luca Buratti, Edward Epstein,\n  Bo Yang, Jim Laredo, Alessandro Morari, Zhong Su", "title": "D2A: A Dataset Built for AI-Based Vulnerability Detection Methods Using\n  Differential Analysis", "comments": "Accepted to the 43rd International Conference on Software\n  Engineering: Software Engineering in Practice (ICSE-SEIP '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static analysis tools are widely used for vulnerability detection as they\nunderstand programs with complex behavior and millions of lines of code.\nDespite their popularity, static analysis tools are known to generate an excess\nof false positives. The recent ability of Machine Learning models to understand\nprogramming languages opens new possibilities when applied to static analysis.\nHowever, existing datasets to train models for vulnerability identification\nsuffer from multiple limitations such as limited bug context, limited size, and\nsynthetic and unrealistic source code. We propose D2A, a differential analysis\nbased approach to label issues reported by static analysis tools. The D2A\ndataset is built by analyzing version pairs from multiple open source projects.\nFrom each project, we select bug fixing commits and we run static analysis on\nthe versions before and after such commits. If some issues detected in a\nbefore-commit version disappear in the corresponding after-commit version, they\nare very likely to be real bugs that got fixed by the commit. We use D2A to\ngenerate a large labeled dataset to train models for vulnerability\nidentification. We show that the dataset can be used to build a classifier to\nidentify possible false alarms among the issues reported by static analysis,\nhence helping developers prioritize and investigate potential true positives\nfirst.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:46:53 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zheng", "Yunhui", ""], ["Pujar", "Saurabh", ""], ["Lewis", "Burn", ""], ["Buratti", "Luca", ""], ["Epstein", "Edward", ""], ["Yang", "Bo", ""], ["Laredo", "Jim", ""], ["Morari", "Alessandro", ""], ["Su", "Zhong", ""]]}, {"id": "2102.08004", "submitter": "Kurtis Haut", "authors": "Taylan Sen, Kurtis Haut, Denis Lomakin and Ehsan Hoque", "title": "A Mental Trespass? Unveiling Truth, Exposing Thoughts and Threatening\n  Civil Liberties with Non-Invasive AI Lie Detection", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Imagine an app on your phone or computer that can tell if you are being\ndishonest, just by processing affective features of your facial expressions,\nbody movements, and voice. People could ask about your political preferences,\nyour sexual orientation, and immediately determine which of your responses are\nhonest and which are not. In this paper we argue why artificial\nintelligence-based, non-invasive lie detection technologies are likely to\nexperience a rapid advancement in the coming years, and that it would be\nirresponsible to wait any longer before discussing its implications. Legal and\npopular perspectives are reviewed to evaluate the potential for these\ntechnologies to cause societal harm. To understand the perspective of a\nreasonable person, we conducted a survey of 129 individuals, and identified\nconsent and accuracy as the major factors in their decision-making process\nregarding the use of these technologies. In our analysis, we distinguish two\ntypes of lie detection technology, accurate truth metering and accurate thought\nexposing. We generally find that truth metering is already largely within the\nscope of existing US federal and state laws, albeit with some notable\nexceptions. In contrast, we find that current regulation of thought exposing\ntechnologies is ambiguous and inadequate to safeguard civil liberties. In order\nto rectify these shortcomings, we introduce the legal concept of mental\ntrespass and use this concept as the basis for proposed regulation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:09:38 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sen", "Taylan", ""], ["Haut", "Kurtis", ""], ["Lomakin", "Denis", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2102.08005", "submitter": "Yundong Zhang", "authors": "Yundong Zhang, Huiye Liu, and Qiang Hu", "title": "TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation", "comments": "Accepted by MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Medical image segmentation - the prerequisite of numerous clinical needs -\nhas been significantly prospered by recent advances in convolutional neural\nnetworks (CNNs). However, it exhibits general limitations on modeling explicit\nlong-range relation, and existing cures, resorting to building deep encoders\nalong with aggressive downsampling operations, leads to redundant deepened\nnetworks and loss of localized details. Hence, the segmentation task awaits a\nbetter solution to improve the efficiency of modeling global contexts while\nmaintaining a strong grasp of low-level details. In this paper, we propose a\nnovel parallel-in-branch architecture, TransFuse, to address this challenge.\nTransFuse combines Transformers and CNNs in a parallel style, where both global\ndependency and low-level spatial details can be efficiently captured in a much\nshallower manner. Besides, a novel fusion technique - BiFusion module is\ncreated to efficiently fuse the multi-level features from both branches.\nExtensive experiments demonstrate that TransFuse achieves the newest\nstate-of-the-art results on both 2D and 3D medical image sets including polyp,\nskin lesion, hip, and prostate segmentation, with significant parameter\ndecrease and inference speed improvement.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:09:45 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 03:55:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhang", "Yundong", ""], ["Liu", "Huiye", ""], ["Hu", "Qiang", ""]]}, {"id": "2102.08012", "submitter": "Jason Liang", "authors": "Jason Liang, Keith Kelly", "title": "Training Stacked Denoising Autoencoders for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement stacked denoising autoencoders, a class of neural networks that\nare capable of learning powerful representations of high dimensional data. We\ndescribe stochastic gradient descent for unsupervised training of autoencoders,\nas well as a novel genetic algorithm based approach that makes use of gradient\ninformation. We analyze the performance of both optimization algorithms and\nalso the representation learning ability of the autoencoder when it is trained\non standard image classification datasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:18:22 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Liang", "Jason", ""], ["Kelly", "Keith", ""]]}, {"id": "2102.08014", "submitter": "Kei Kobayashi", "authors": "Daisuke Takehara, Kei Kobayashi", "title": "Enhancing Hierarchical Information by Using Metric Cones for Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is becoming an important method with applications in various\nareas, including social networks and knowledge graph completion. In particular,\nPoincar\\'e embedding has been proposed to capture the hierarchical structure of\ngraphs, and its effectiveness has been reported. However, most of the existing\nmethods have isometric mappings in the embedding space, and the choice of the\norigin point can be arbitrary. This fact is not desirable when the distance\nfrom the origin is used as an indicator of hierarchy, as in the case of\nPoincar\\'e embedding. In this paper, we propose graph embedding in a metric\ncone to solve such a problem, and we gain further benefits: 1) we provide an\nindicator of hierarchical information that is both geometrically and\nintuitively natural to interpret, 2) we can extract the hierarchical structure\nfrom a graph embedding output of other methods by learning additional\none-dimensional parameters, and 3) we can change the curvature of the embedding\nspace via a hyperparameter.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:23:59 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Takehara", "Daisuke", ""], ["Kobayashi", "Kei", ""]]}, {"id": "2102.08019", "submitter": "Kevin Bello", "authors": "Kevin Bello, Chuyang Ke and Jean Honorio", "title": "A Thorough View of Exact Inference in Graphs from the Degree-4\n  Sum-of-Squares Hierarchy", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing inference in graphs is a common task within several machine\nlearning problems, e.g., image segmentation, community detection, among others.\nFor a given undirected connected graph, we tackle the statistical problem of\nexactly recovering an unknown ground-truth binary labeling of the nodes from a\nsingle corrupted observation of each edge. Such problem can be formulated as a\nquadratic combinatorial optimization problem over the boolean hypercube, where\nit has been shown before that one can (with high probability and in polynomial\ntime) exactly recover the ground-truth labeling of graphs that have an\nisoperimetric number that grows with respect to the number of nodes (e.g.,\ncomplete graphs, regular expanders). In this work, we apply a powerful\nhierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the\ncombinatorial problem. Motivated by empirical evidence on the improvement in\nexact recoverability, we center our attention on the degree-4 SoS relaxation\nand set out to understand the origin of such improvement from a graph\ntheoretical perspective. We show that the solution of the dual of the relaxed\nproblem is related to finding edge weights of the Johnson and Kneser graphs,\nwhere the weights fulfill the SoS constraints and intuitively allow the input\ngraph to increase its algebraic connectivity. Finally, as byproduct of our\nanalysis, we derive a novel Cheeger-type lower bound for the algebraic\nconnectivity of graphs with signed edge weights.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:36:19 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:38:36 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bello", "Kevin", ""], ["Ke", "Chuyang", ""], ["Honorio", "Jean", ""]]}, {"id": "2102.08021", "submitter": "Alexey Chernyavskiy", "authors": "Ekaterina Redekop, Alexey Chernyavskiy", "title": "Uncertainty-based method for improving poorly labeled segmentation\n  datasets", "comments": "Accepted to ISBI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of modern deep learning algorithms for image segmentation heavily\ndepends on the availability of large datasets with clean pixel-level\nannotations (masks), where the objects of interest are accurately delineated.\nLack of time and expertise during data annotation leads to incorrect boundaries\nand label noise. It is known that deep convolutional neural networks (DCNNs)\ncan memorize even completely random labels, resulting in poor accuracy. We\npropose a framework to train binary segmentation DCNNs using sets of unreliable\npixel-level annotations. Erroneously labeled pixels are identified based on the\nestimated aleatoric uncertainty of the segmentation and are relabeled to the\ntrue value.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:37:19 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Redekop", "Ekaterina", ""], ["Chernyavskiy", "Alexey", ""]]}, {"id": "2102.08026", "submitter": "Nabil Ibtehaz", "authors": "Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan\n  Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, and Tawsifur Rahman", "title": "EDITH :ECG biometrics aided by Deep learning for reliable Individual\n  auTHentication", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, physiological signal based authentication has shown great\npromises,for its inherent robustness against forgery. Electrocardiogram (ECG)\nsignal, being the most widely studied biosignal, has also received the highest\nlevel of attention in this regard. It has been proven with numerous studies\nthat by analyzing ECG signals from different persons, it is possible to\nidentify them, with acceptable accuracy. In this work, we present, EDITH, a\ndeep learning-based framework for ECG biometrics authentication system.\nMoreover, we hypothesize and demonstrate that Siamese architectures can be used\nover typical distance metrics for improved performance. We have evaluated EDITH\nusing 4 commonly used datasets and outperformed the prior works using less\nnumber of beats. EDITH performs competitively using just a single heartbeat\n(96-99.75% accuracy) and can be further enhanced by fusing multiple beats (100%\naccuracy from 3 to 6 beats). Furthermore, the proposed Siamese architecture\nmanages to reduce the identity verification Equal Error Rate (EER) to 1.29%. A\nlimited case study of EDITH with real-world experimental data also suggests its\npotential as a practical authentication system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:45:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ibtehaz", "Nabil", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khandakar", "Amith", ""], ["Kiranyaz", "Serkan", ""], ["Rahman", "M. Sohel", ""], ["Tahir", "Anas", ""], ["Qiblawey", "Yazan", ""], ["Rahman", "Tawsifur", ""]]}, {"id": "2102.08029", "submitter": "Rukshan Wijesinghe", "authors": "Rukshan Wijesinghe, Kasun Vithanage, Dumindu Tissera, Alex Xavier,\n  Subha Fernando and Jayathu Samarawickrama", "title": "Transferring Domain Knowledge with an Adviser in Continuous Tasks", "comments": "Accepted by the 25th Pacific-Asia Conference on Knowledge Discovery\n  and Data Mining (PAKDD-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Reinforcement Learning (RL) have surpassed human-level\nperformance in many simulated environments. However, existing reinforcement\nlearning techniques are incapable of explicitly incorporating already known\ndomain-specific knowledge into the learning process. Therefore, the agents have\nto explore and learn the domain knowledge independently through a trial and\nerror approach, which consumes both time and resources to make valid responses.\nHence, we adapt the Deep Deterministic Policy Gradient (DDPG) algorithm to\nincorporate an adviser, which allows integrating domain knowledge in the form\nof pre-learned policies or pre-defined relationships to enhance the agent's\nlearning process. Our experiments on OpenAi Gym benchmark tasks show that\nintegrating domain knowledge through advisers expedites the learning and\nimproves the policy towards better optima.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 09:03:33 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Wijesinghe", "Rukshan", ""], ["Vithanage", "Kasun", ""], ["Tissera", "Dumindu", ""], ["Xavier", "Alex", ""], ["Fernando", "Subha", ""], ["Samarawickrama", "Jayathu", ""]]}, {"id": "2102.08035", "submitter": "Raid Al-Nima", "authors": "Raid R. Al-Nima, Fawaz S. Abdullah, Ali N. Hamoodi", "title": "Design a Technology Based on the Fusion of Genetic Algorithm, Neural\n  network and Fuzzy logic", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and development of a prototype technique for\nartificial intelligence based on the fusion of genetic algorithm, neural\nnetwork and fuzzy logic. It starts by establishing a relationship between the\nneural network and fuzzy logic. Then, it combines the genetic algorithm with\nthem. Information fusions are at the confidence level, where matching scores\ncan be reported and discussed. The technique is called the Genetic Neuro-Fuzzy\n(GNF). It can be used for high accuracy real-time environments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 09:17:58 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Al-Nima", "Raid R.", ""], ["Abdullah", "Fawaz S.", ""], ["Hamoodi", "Ali N.", ""]]}, {"id": "2102.08061", "submitter": "Ozan Ozdenizci", "authors": "Ozan Ozdenizci, Deniz Erdogmus", "title": "On the use of generative deep neural networks to synthesize artificial\n  multichannel EEG signals", "comments": "10th International IEEE EMBS Conference on Neural Engineering\n  (NER'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent promises of generative deep learning lately brought interest to its\npotential uses in neural engineering. In this paper we firstly review recently\nemerging studies on generating artificial electroencephalography (EEG) signals\nwith deep neural networks. Subsequently, we present our feasibility experiments\non generating condition-specific multichannel EEG signals using conditional\nvariational autoencoders. By manipulating real resting-state EEG epochs, we\npresent an approach to synthetically generate time-series multichannel signals\nthat show spectro-temporal EEG patterns which are expected to be observed\nduring distinct motor imagery conditions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:18:08 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2102.08068", "submitter": "Jinsheng Wei", "authors": "Jinsheng Wei, Guanming Lu, Jingjie Yan", "title": "A comparative study on movement feature in different directions for\n  micro-expression recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-expression can reflect people's real emotions. Recognizing\nmicro-expressions is difficult because they are small motions and have a short\nduration. As the research is deepening into micro-expression recognition, many\neffective features and methods have been proposed. To determine which direction\nof movement feature is easier for distinguishing micro-expressions, this paper\nselects 18 directions (including three types of horizontal, vertical and\noblique movements) and proposes a new low-dimensional feature called the\nHistogram of Single Direction Gradient (HSDG) to study this topic. In this\npaper, HSDG in every direction is concatenated with LBP-TOP to obtain the LBP\nwith Single Direction Gradient (LBP-SDG) and analyze which direction of\nmovement feature is more discriminative for micro-expression recognition. As\nwith some existing work, Euler Video Magnification (EVM) is employed as a\npreprocessing step. The experiments on the CASME II and SMIC-HS databases\nsummarize the effective and optimal directions and demonstrate that HSDG in an\noptimal direction is discriminative, and the corresponding LBP-SDG achieves\nstate-of-the-art performance using EVM.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:38:16 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Wei", "Jinsheng", ""], ["Lu", "Guanming", ""], ["Yan", "Jingjie", ""]]}, {"id": "2102.08072", "submitter": "Yao Mu", "authors": "Yuhang Zhang, Yao Mu, Yujie Yang, Yang Guan, Shengbo Eben Li, Qi Sun\n  and Jianyu Chen", "title": "Steadily Learn to Drive with Virtual Memory", "comments": "Submitted to the 32nd IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning has shown great potential in developing high-level\nautonomous driving. However, for high-dimensional tasks, current RL methods\nsuffer from low data efficiency and oscillation in the training process. This\npaper proposes an algorithm called Learn to drive with Virtual Memory (LVM) to\novercome these problems. LVM compresses the high-dimensional information into\ncompact latent states and learns a latent dynamic model to summarize the\nagent's experience. Various imagined latent trajectories are generated as\nvirtual memory by the latent dynamic model. The policy is learned by\npropagating gradient through the learned latent model with the imagined latent\ntrajectories and thus leads to high data efficiency. Furthermore, a double\ncritic structure is designed to reduce the oscillation during the training\nprocess. The effectiveness of LVM is demonstrated by an image-input autonomous\ndriving task, in which LVM outperforms the existing method in terms of data\nefficiency, learning stability, and control performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:46:52 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhang", "Yuhang", ""], ["Mu", "Yao", ""], ["Yang", "Yujie", ""], ["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Sun", "Qi", ""], ["Chen", "Jianyu", ""]]}, {"id": "2102.08085", "submitter": "Fouzia Altaf Ms", "authors": "Fouzia Altaf, Syed M.S. Islam, Naeem K. Janjua, Naveed Akhtar", "title": "Boosting Deep Transfer Learning for COVID-19 Classification", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  COVID-19 classification using chest Computed Tomography (CT) has been found\npragmatically useful by several studies. Due to the lack of annotated samples,\nthese studies recommend transfer learning and explore the choices of\npre-trained models and data augmentation. However, it is still unknown if there\nare better strategies than vanilla transfer learning for more accurate COVID-19\nclassification with limited CT data. This paper provides an affirmative answer,\ndevising a novel `model' augmentation technique that allows a considerable\nperformance boost to transfer learning for the task. Our method systematically\nreduces the distributional shift between the source and target domains and\nconsiders augmenting deep learning with complementary representation learning\ntechniques. We establish the efficacy of our method with publicly available\ndatasets and models, along with identifying contrasting observations in the\nprevious studies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:15:23 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Altaf", "Fouzia", ""], ["Islam", "Syed M. S.", ""], ["Janjua", "Naeem K.", ""], ["Akhtar", "Naveed", ""]]}, {"id": "2102.08092", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes, Ant\\'onio Gaspar, Lu\\'is A. Alexandre, Jo\\~ao Cordeiro", "title": "An AutoML-based Approach to Multimodal Image Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis is a research topic focused on analysing data to extract\ninformation related to the sentiment that it causes. Applications of sentiment\nanalysis are wide, ranging from recommendation systems, and marketing to\ncustomer satisfaction. Recent approaches evaluate textual content using Machine\nLearning techniques that are trained over large corpora. However, as social\nmedia grown, other data types emerged in large quantities, such as images.\nSentiment analysis in images has shown to be a valuable complement to textual\ndata since it enables the inference of the underlying message polarity by\ncreating context and connections. Multimodal sentiment analysis approaches\nintend to leverage information of both textual and image content to perform an\nevaluation. Despite recent advances, current solutions still flounder in\ncombining both image and textual information to classify social media data,\nmainly due to subjectivity, inter-class homogeneity and fusion data\ndifferences. In this paper, we propose a method that combines both textual and\nimage individual sentiment analysis into a final fused classification based on\nAutoML, that performs a random search to find the best model. Our method\nachieved state-of-the-art performance in the B-T4SA dataset, with 95.19%\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:28:50 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Lopes", "Vasco", ""], ["Gaspar", "Ant\u00f3nio", ""], ["Alexandre", "Lu\u00eds A.", ""], ["Cordeiro", "Jo\u00e3o", ""]]}, {"id": "2102.08094", "submitter": "Oier Mees", "authors": "Oier Mees, Wolfram Burgard", "title": "Composing Pick-and-Place Tasks By Grounding Language", "comments": "Accepted at the International Symposium on Experimental Robotics\n  (ISER) 2020. Videos at http://speechrobot.cs.uni-freiburg.de", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling robots to perform tasks via natural language is one of the most\nchallenging topics in human-robot interaction. In this work, we present a robot\nsystem that follows unconstrained language instructions to pick and place\narbitrary objects and effectively resolves ambiguities through dialogues. Our\napproach infers objects and their relationships from input images and language\nexpressions and can place objects in accordance with the spatial relations\nexpressed by the user. Unlike previous approaches, we consider grounding not\nonly for the picking but also for the placement of everyday objects from\nlanguage. Specifically, by grounding objects and their spatial relations, we\nallow specification of complex placement instructions, e.g. \"place it behind\nthe middle red bowl\". Our results obtained using a real-world PR2 robot\ndemonstrate the effectiveness of our method in understanding pick-and-place\nlanguage instructions and sequentially composing them to solve tabletop\nmanipulation tasks. Videos are available at\nhttp://speechrobot.cs.uni-freiburg.de\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:29:09 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Mees", "Oier", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2102.08100", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Paul Scherer and Oliver Kiss and Rik Sarkar\n  and Tamas Ferenci", "title": "Chickenpox Cases in Hungary: a Benchmark Dataset for Spatiotemporal\n  Signal Processing with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent graph convolutional neural networks are highly effective machine\nlearning techniques for spatiotemporal signal processing. Newly proposed graph\nneural network architectures are repetitively evaluated on standard tasks such\nas traffic or weather forecasting. In this paper, we propose the Chickenpox\nCases in Hungary dataset as a new dataset for comparing graph neural network\narchitectures. Our time series analysis and forecasting experiments demonstrate\nthat the Chickenpox Cases in Hungary dataset is adequate for comparing the\npredictive performance and forecasting capabilities of novel recurrent graph\nneural network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:48:57 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Scherer", "Paul", ""], ["Kiss", "Oliver", ""], ["Sarkar", "Rik", ""], ["Ferenci", "Tamas", ""]]}, {"id": "2102.08113", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Stefan Reiterer and Martin Stettinger and\n  Florian Reinfrank and Michael Jeran and Gerald Ninaus", "title": "Recommender Systems for Configuration Knowledge Engineering", "comments": "A. Felfernig S, Reiterer, M. Stettinger, F. Reinfrank, M. Jeran, and\n  G. Ninaus. Recommender Systems for Configuration Knowledge Engineering,\n  Workshop on Configuration, Vienna, Austria, pp. 51-54, ISBN:\n  979-10-91526-02-9, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge engineering bottleneck is still a major challenge in\nconfigurator projects. In this paper we show how recommender systems can\nsupport knowledge base development and maintenance processes. We discuss a\ncouple of scenarios for the application of recommender systems in knowledge\nengineering and report the results of empirical studies which show the\nimportance of user-centered configuration knowledge organization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:29:54 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Felfernig", "Alexander", ""], ["Reiterer", "Stefan", ""], ["Stettinger", "Martin", ""], ["Reinfrank", "Florian", ""], ["Jeran", "Michael", ""], ["Ninaus", "Gerald", ""]]}, {"id": "2102.08120", "submitter": "Hongyan Wu", "authors": "Jie Zhang, Jinru Ding, Suyuan Liu, Hongyan Wu", "title": "Meta-Path-Free Representation Learning on Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world networks and knowledge graphs are usually heterogeneous networks.\nRepresentation learning on heterogeneous networks is not only a popular but a\npragmatic research field. The main challenge comes from the heterogeneity --\nthe diverse types of nodes and edges. Besides, for a given node in a HIN, the\nsignificance of a neighborhood node depends not only on the structural distance\nbut semantics. How to effectively capture both structural and semantic\nrelations is another challenge. The current state-of-the-art methods are based\non the algorithm of meta-path and therefore have a serious disadvantage -- the\nperformance depends on the arbitrary choosing of meta-path(s). However, the\nselection of meta-path(s) is experience-based and time-consuming. In this work,\nwe propose a novel meta-path-free representation learning on heterogeneous\nnetworks, namely Heterogeneous graph Convolutional Networks (HCN). The proposed\nmethod fuses the heterogeneity and develops a $k$-strata algorithm ($k$ is an\ninteger) to capture the $k$-hop structural and semantic information in\nheterogeneous networks. To the best of our knowledge, this is the first attempt\nto break out of the confinement of meta-paths for representation learning on\nheterogeneous networks. We carry out extensive experiments on three real-world\nheterogeneous networks. The experimental results demonstrate that the proposed\nmethod significantly outperforms the current state-of-the-art methods in a\nvariety of analytic tasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:37:38 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhang", "Jie", ""], ["Ding", "Jinru", ""], ["Liu", "Suyuan", ""], ["Wu", "Hongyan", ""]]}, {"id": "2102.08122", "submitter": "Hongyan Wu", "authors": "Jie Zhang, Pengfei Zhou, Hongyan Wu", "title": "Dynamic Virtual Graph Significance Networks for Predicting Influenza", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-structured data and their related algorithms have attracted significant\nattention in many fields, such as influenza prediction in public health.\nHowever, the variable influenza seasonality, occasional pandemics, and domain\nknowledge pose great challenges to construct an appropriate graph, which could\nimpair the strength of the current popular graph-based algorithms to perform\ndata analysis. In this study, we develop a novel method, Dynamic Virtual Graph\nSignificance Networks (DVGSN), which can supervisedly and dynamically learn\nfrom similar \"infection situations\" in historical timepoints. Representation\nlearning on the dynamic virtual graph can tackle the varied seasonality and\npandemics, and therefore improve the performance. The extensive experiments on\nreal-world influenza data demonstrate that DVGSN significantly outperforms the\ncurrent state-of-the-art methods. To the best of our knowledge, this is the\nfirst attempt to supervisedly learn a dynamic virtual graph for time-series\nprediction tasks. Moreover, the proposed method needs less domain knowledge to\nbuild a graph in advance and has rich interpretability, which makes the method\nmore acceptable in the fields of public health, life sciences, and so on.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:38:23 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhang", "Jie", ""], ["Zhou", "Pengfei", ""], ["Wu", "Hongyan", ""]]}, {"id": "2102.08124", "submitter": "Brian Chmiel", "authors": "Itay Hubara, Brian Chmiel, Moshe Island, Ron Banner, Seffi Naor,\n  Daniel Soudry", "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to\n  Find N:M Transposable Masks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, researchers proposed pruning deep neural network weights (DNNs)\nusing an $N:M$ fine-grained block sparsity mask. In this mask, for each block\nof $M$ weights, we have at least $N$ zeros. In contrast to unstructured\nsparsity, $N:M$ fine-grained block sparsity allows acceleration in actual\nmodern hardware. So far, this was used for DNN acceleration at the inference\nphase. First, we suggest a method to convert a pretrained model with\nunstructured sparsity to a $N:M$ fine-grained block sparsity model, with little\nto no training. Then, to also allow such acceleration in the training phase, we\nsuggest a novel transposable-fine-grained sparsity mask where the same mask can\nbe used for both forward and backward passes. Our transposable mask ensures\nthat both the weight matrix and its transpose follow the same sparsity pattern;\nthus the matrix multiplication required for passing the error backward can also\nbe accelerated. We discuss the transposable constraint and devise a new measure\nfor mask constraints, called mask-diversity (MD), which correlates with their\nexpected accuracy. Then, we formulate the problem of finding the optimal\ntransposable mask as a minimum-cost-flow problem and suggest a fast linear\napproximation that can be used when the masks dynamically change while\ntraining. Our experiments suggest 2x speed-up with no accuracy degradation over\nvision and language models. A reference implementation can be found at\nhttps://github.com/papers-submission/structured_transposable_masks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 12:44:16 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Hubara", "Itay", ""], ["Chmiel", "Brian", ""], ["Island", "Moshe", ""], ["Banner", "Ron", ""], ["Naor", "Seffi", ""], ["Soudry", "Daniel", ""]]}, {"id": "2102.08137", "submitter": "Hongyan Wu", "authors": "Jie Zhang, Kazumitsu Nawata, Hongyan Wu", "title": "Spatio-Temporal Multi-step Prediction of Influenza Outbreaks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flu circulates all over the world. The worldwide infection places a\nsubstantial burden on people's health every year. Regardless of the\ncharacteristic of the worldwide circulation of flu, most previous studies\nfocused on regional prediction of flu outbreaks. The methodology of considering\nthe spatio-temporal correlation could help forecast flu outbreaks more\nprecisely. Furthermore, forecasting a long-term flu outbreak, and understanding\nflu infection trends more accurately could help hospitals, clinics, and\npharmaceutical companies to better prepare for annual flu outbreaks. Predicting\na sequence of values in the future, namely, the multi-step prediction of flu\noutbreaks should cause concern. Therefore, we highlight the importance of\ndeveloping spatio-temporal methodologies to perform multi-step prediction of\nworldwide flu outbreaks. We compared the MAPEs of SVM, RF, LSTM models of\npredicting flu data of the 1-4 weeks ahead with and without other countries'\nflu data. We found the LSTM models achieved the lowest MAPEs in most cases. As\nfor countries in the Southern hemisphere, the MAPEs of predicting flu data with\nother countries are higher than those of predicting without other countries.\nFor countries in the Northern hemisphere, the MAPEs of predicting flu data of\nthe 2-4 weeks ahead with other countries are lower than those of predicting\nwithout other countries; and the MAPEs of predicting flu data of the 1-weeks\nahead with other countries are higher than those of predicting without other\ncountries, except for the UK. In this study, we performed the spatio-temporal\nmulti-step prediction of influenza outbreaks. The methodology considering the\nspatio-temporal features improves the multi-step prediction of flu outbreaks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 13:17:11 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhang", "Jie", ""], ["Nawata", "Kazumitsu", ""], ["Wu", "Hongyan", ""]]}, {"id": "2102.08146", "submitter": "Manfred Schmidt-Schauss", "authors": "Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi Levy and Mateu\n  Villaret and Yunus Kutz", "title": "Nominal Unification and Matching of Higher Order Expressions with\n  Recursive Let", "comments": "35 pages, 9 figures, This paper is an extended version of the\n  conference publication: Manfred Schmidt-Schau{\\ss} and Temur Kutsia and Jordi\n  Levy and Mateu Villaret and Yunus Kutz, Nominal Unification of Higher Order\n  Expressions with Recursive Let, LOPSTR-16, Lecture Notes in Computer Science\n  10184, Springer, p 328 -344, 2016. arXiv admin note: text overlap with\n  arXiv:1608.03771", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A sound and complete algorithm for nominal unification of higher-order\nexpressions with a recursive let is described, and shown to run in\nnondeterministic polynomial time. We also explore specializations like nominal\nletrec-matching for expressions, for DAGs, and for garbage-free expressions and\ndetermine their complexity. Finally, we also provide a nominal unification\nalgorithm for higher-order expressions with recursive let and atom-variables,\nwhere we show that it also runs in nondeterministic polynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 13:36:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Schmidt-Schau\u00df", "Manfred", ""], ["Kutsia", "Temur", ""], ["Levy", "Jordi", ""], ["Villaret", "Mateu", ""], ["Kutz", "Yunus", ""]]}, {"id": "2102.08180", "submitter": "Todd Robinson", "authors": "Todd Robinson", "title": "Value of Information for Argumentation based Intelligence Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation provides a representation of arguments and attacks between\nthese arguments. Argumentation can be used to represent a reasoning process\nover evidence to reach conclusions. Within such a reasoning process,\nunderstanding the value of information can improve the quality of decision\nmaking based on the output of the reasoning process. The value of an item of\ninformation is inherently dependent on the available evidence and the question\nbeing answered by the reasoning. In this paper we introduce a value of\ninformation on argument frameworks to identify the most valuable arguments\nwithin the finite set of arguments in the framework, and the arguments and\nattacks which could be added to change the output of an evaluation. We\ndemonstrate the value of information within an argument framework representing\nan intelligence analysis in the maritime domain. Understanding the value of\ninformation in an intelligence analysis will allow analysts to balance the\nvalue against the costs and risks of collection, to effectively request further\ncollection of intelligence to increase the confidence in the analysis of\nhypotheses.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:28:33 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Robinson", "Todd", ""]]}, {"id": "2102.08190", "submitter": "Tai Yang", "authors": "Tai Cheng Yang", "title": "Four Generations of Control Theory Development ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This short article presents an opinion that control system study up to date\ncan be divided into four generations; namely, 1 transfer function based; 2\nstate-space based; 3 networked control systems; and 4 control in the new AI\nera.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:38:19 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Yang", "Tai Cheng", ""]]}, {"id": "2102.08199", "submitter": "Volker Steinhage", "authors": "Jakob Greis, Artem Yushchenko, Daniel Vogel, Michael Meier and Volker\n  Steinhage", "title": "Automated Identification of Vulnerable Devices in Networks using Traffic\n  Data and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT devices are vulnerable to attacks due to flawed security designs and\nlacking mechanisms for firmware updates or patches to eliminate the security\nvulnerabilities. Device-type identification combined with data from\nvulnerability databases can pinpoint vulnerable IoT devices in a network and\ncan be used to constrain the communications of vulnerable devices for\npreventing damage. In this contribution, we present and evaluate two deep\nlearning approaches to the reliable IoT device-type identification, namely a\nrecurrent and a convolutional network architecture. Both deep learning\napproaches show accuracies of 97% and 98%, respectively, and thereby outperform\nan up-to-date IoT device-type identification approach using hand-crafted\nfingerprint features obtaining an accuracy of 82%. The runtime performance for\nthe IoT identification of both deep learning approaches outperforms the\nhand-crafted approach by three magnitudes. Finally, importance metrics explain\nthe results of both deep learning approaches in terms of the utilization of the\nanalyzed traffic data flow.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:49:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Greis", "Jakob", ""], ["Yushchenko", "Artem", ""], ["Vogel", "Daniel", ""], ["Meier", "Michael", ""], ["Steinhage", "Volker", ""]]}, {"id": "2102.08211", "submitter": "Laura Kriener", "authors": "Laura Kriener, Julian G\\\"oltz, Mihai A. Petrovici", "title": "The Yin-Yang dataset", "comments": "3 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Yin-Yang dataset was developed for research on biologically plausible\nerror backpropagation and deep learning in spiking neural networks. It serves\nas an alternative to classic deep learning datasets, especially in algorithm-\nand model-prototyping scenarios, by providing several advantages. First, it is\nsmaller and therefore faster to learn, thereby being better suited for the\ndeployment on neuromorphic chips with limited network sizes. Second, it\nexhibits a very clear gap between the accuracies achievable using shallow as\ncompared to deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 15:18:05 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kriener", "Laura", ""], ["G\u00f6ltz", "Julian", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "2102.08248", "submitter": "Jakob Drachmann Havtorn Mr", "authors": "Jakob D. Havtorn, Jes Frellsen, S{\\o}ren Hauberg, Lars Maal{\\o}e", "title": "Hierarchical VAEs Know What They Don't Know", "comments": "Appeared in Proceedings of the 38th International Conference on\n  Machine Learning (ICML 2021). 18 pages, source code available at\n  https://github.com/JakobHavtorn/hvae-oodd,\n  https://github.com/vlievin/biva-pytorch and\n  https://github.com/larsmaaloee/BIVA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been demonstrated as state-of-the-art density\nestimators. Yet, recent work has found that they often assign a higher\nlikelihood to data from outside the training distribution. This seemingly\nparadoxical behavior has caused concerns over the quality of the attained\ndensity estimates. In the context of hierarchical variational autoencoders, we\nprovide evidence to explain this behavior by out-of-distribution data having\nin-distribution low-level features. We argue that this is both expected and\ndesirable behavior. With this insight in hand, we develop a fast, scalable and\nfully unsupervised likelihood-ratio score for OOD detection that requires data\nto be in-distribution across all feature-levels. We benchmark the method on a\nvast set of data and model combinations and achieve state-of-the-art results on\nout-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:08:04 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 09:35:30 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 09:54:43 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 07:44:50 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 11:55:39 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Havtorn", "Jakob D.", ""], ["Frellsen", "Jes", ""], ["Hauberg", "S\u00f8ren", ""], ["Maal\u00f8e", "Lars", ""]]}, {"id": "2102.08251", "submitter": "Tao Feng", "authors": "Tao Feng, Sirui Song, Tong Xia, Yong Li", "title": "Reinforced Contact Tracing and Epidemic Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent outbreak of COVID-19 poses a serious threat to people's lives.\nEpidemic control strategies have also caused damage to the economy by cutting\noff humans' daily commute. In this paper, we develop an Individual-based\nReinforcement Learning Epidemic Control Agent (IDRLECA) to search for smart\nepidemic control strategies that can simultaneously minimize infections and the\ncost of mobility intervention. IDRLECA first hires an infection probability\nmodel to calculate the current infection probability of each individual. Then,\nthe infection probabilities together with individuals' health status and\nmovement information are fed to a novel GNN to estimate the spread of the virus\nthrough human contacts. The estimated risks are used to further support an RL\nagent to select individual-level epidemic-control actions. The training of\nIDRLECA is guided by a specially designed reward function considering both the\ncost of mobility intervention and the effectiveness of epidemic control.\nMoreover, we design a constraint for control-action selection that eases its\ndifficulty and further improve exploring efficiency. Extensive experimental\nresults demonstrate that IDRLECA can suppress infections at a very low level\nand retain more than 95% of human mobility.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 08:31:48 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Feng", "Tao", ""], ["Song", "Sirui", ""], ["Xia", "Tong", ""], ["Li", "Yong", ""]]}, {"id": "2102.08307", "submitter": "Niall Creech", "authors": "Niall Creech, Natalia Criado Pacheco, Simon Miles", "title": "Dynamic neighbourhood optimisation for task allocation using multi-agent", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale systems there are fundamental challenges when centralised\ntechniques are used for task allocation. The number of interactions is limited\nby resource constraints such as on computation, storage, and network\ncommunication. We can increase scalability by implementing the system as a\ndistributed task-allocation system, sharing tasks across many agents. However,\nthis also increases the resource cost of communications and synchronisation,\nand is difficult to scale.\n  In this paper we present four algorithms to solve these problems. The\ncombination of these algorithms enable each agent to improve their task\nallocation strategy through reinforcement learning, while changing how much\nthey explore the system in response to how optimal they believe their current\nstrategy is, given their past experience. We focus on distributed agent systems\nwhere the agents' behaviours are constrained by resource usage limits, limiting\nagents to local rather than system-wide knowledge. We evaluate these algorithms\nin a simulated environment where agents are given a task composed of multiple\nsubtasks that must be allocated to other agents with differing capabilities, to\nthen carry out those tasks. We also simulate real-life system effects such as\nnetworking instability. Our solution is shown to solve the task allocation\nproblem to 6.7% of the theoretical optimal within the system configurations\nconsidered. It provides 5x better performance recovery over no-knowledge\nretention approaches when system connectivity is impacted, and is tested\nagainst systems up to 100 agents with less than a 9% impact on the algorithms'\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:49:14 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Creech", "Niall", ""], ["Pacheco", "Natalia Criado", ""], ["Miles", "Simon", ""]]}, {"id": "2102.08317", "submitter": "Niall Creech", "authors": "Niall Creech, Natalia Criado Pacheco, Simon Miles", "title": "Resource allocation in dynamic multiagent systems", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation and task prioritisation are key problem domains in the\nfields of autonomous vehicles, networking, and cloud computing. The challenge\nin developing efficient and robust algorithms comes from the dynamic nature of\nthese systems, with many components communicating and interacting in complex\nways. The multi-group resource allocation optimisation (MG-RAO) algorithm we\npresent uses multiple function approximations of resource demand over time,\nalongside reinforcement learning techniques, to develop a novel method of\noptimising resource allocation in these multi-agent systems. This method is\napplicable where there are competing demands for shared resources, or in task\nprioritisation problems. Evaluation is carried out in a simulated environment\ncontaining multiple competing agents. We compare the new algorithm to an\napproach where child agents distribute their resources uniformly across all the\ntasks they can be allocated. We also contrast the performance of the algorithm\nwhere resource allocation is modelled separately for groups of agents, as to\nbeing modelled jointly over all agents. The MG-RAO algorithm shows a 23 - 28%\nimprovement over fixed resource allocation in the simulated environments.\nResults also show that, in a volatile system, using the MG-RAO algorithm\nconfigured so that child agents model resource allocation for all agents as a\nwhole has 46.5% of the performance of when it is set to model multiple groups\nof agents. These results demonstrate the ability of the algorithm to solve\nresource allocation problems in multi-agent systems and to perform well in\ndynamic environments.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:56:23 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Creech", "Niall", ""], ["Pacheco", "Natalia Criado", ""], ["Miles", "Simon", ""]]}, {"id": "2102.08322", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Pengjie Ren, Maarten de Rijke", "title": "A Cooperative Memory Network for Personalized Task-oriented Dialogue\n  Systems with Incomplete User Profiles", "comments": "In Proceedings of the Web Conference 2021 (WWW '21), April 19-23,\n  2021, Ljubljana, Slovenia. ACM, New York, NY, USA, 10 pages", "journal-ref": null, "doi": "10.1145/3442381.3449843", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is increasing interest in developing personalized Task-oriented\nDialogue Systems (TDSs). Previous work on personalized TDSs often assumes that\ncomplete user profiles are available for most or even all users. This is\nunrealistic because (1) not everyone is willing to expose their profiles due to\nprivacy concerns; and (2) rich user profiles may involve a large number of\nattributes (e.g., gender, age, tastes, . . .). In this paper, we study\npersonalized TDSs without assuming that user profiles are complete. We propose\na Cooperative Memory Network (CoMemNN) that has a novel mechanism to gradually\nenrich user profiles as dialogues progress and to simultaneously improve\nresponse selection based on the enriched profiles. CoMemNN consists of two core\nmodules: User Profile Enrichment (UPE) and Dialogue Response Selection (DRS).\nThe former enriches incomplete user profiles by utilizing collaborative\ninformation from neighbor users as well as current dialogues. The latter uses\nthe enriched profiles to update the current user query so as to encode more\nuseful information, based on which a personalized response to a user request is\nselected.\n  We conduct extensive experiments on the personalized bAbI dialogue benchmark\ndatasets. We find that CoMemNN is able to enrich user profiles effectively,\nwhich results in an improvement of 3.06% in terms of response selection\naccuracy compared to state-of-the-art methods. We also test the robustness of\nCoMemNN against incompleteness of user profiles by randomly discarding\nattribute values from user profiles. Even when discarding 50% of the attribute\nvalues, CoMemNN is able to match the performance of the best performing\nbaseline without discarding user profiles, showing the robustness of CoMemNN.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:05:54 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Pei", "Jiahuan", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2102.08343", "submitter": "Aditya Kumar Akash", "authors": "Aditya Kumar Akash, Vishnu Suresh Lokhande, Sathya N. Ravi, Vikas\n  Singh", "title": "Learning Invariant Representations using Inverse Contrastive Loss", "comments": "Accepted to AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning invariant representations is a critical first step in a number of\nmachine learning tasks. A common approach corresponds to the so-called\ninformation bottleneck principle in which an application dependent function of\nmutual information is carefully chosen and optimized. Unfortunately, in\npractice, these functions are not suitable for optimization purposes since\nthese losses are agnostic of the metric structure of the parameters of the\nmodel. We introduce a class of losses for learning representations that are\ninvariant to some extraneous variable of interest by inverting the class of\ncontrastive losses, i.e., inverse contrastive loss (ICL). We show that if the\nextraneous variable is binary, then optimizing ICL is equivalent to optimizing\na regularized MMD divergence. More generally, we also show that if we are\nprovided a metric on the sample space, our formulation of ICL can be decomposed\ninto a sum of convex functions of the given distance metric. Our experimental\nresults indicate that models obtained by optimizing ICL achieve significantly\nbetter invariance to the extraneous variable for a fixed desired level of\naccuracy. In a variety of experimental settings, we show applicability of ICL\nfor learning invariant representations for both continuous and discrete\nextraneous variables.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:29:28 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Akash", "Aditya Kumar", ""], ["Lokhande", "Vishnu Suresh", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "2102.08363", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey\n  Levine, Chelsea Finn", "title": "COMBO: Conservative Offline Model-Based Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based algorithms, which learn a dynamics model from logged experience\nand perform some sort of pessimistic planning under the learned model, have\nemerged as a promising paradigm for offline reinforcement learning (offline\nRL). However, practical variants of such model-based algorithms rely on\nexplicit uncertainty quantification for incorporating pessimism. Uncertainty\nestimation with complex models, such as deep neural networks, can be difficult\nand unreliable. We overcome this limitation by developing a new model-based\noffline RL algorithm, COMBO, that regularizes the value function on\nout-of-support state-action tuples generated via rollouts under the learned\nmodel. This results in a conservative estimate of the value function for\nout-of-support state-action tuples, without requiring explicit uncertainty\nestimation. We theoretically show that our method optimizes a lower bound on\nthe true policy value, that this bound is tighter than that of prior methods,\nand our approach satisfies a policy improvement guarantee in the offline\nsetting. Through experiments, we find that COMBO consistently performs as well\nor better as compared to prior offline model-free and model-based methods on\nwidely studied offline RL benchmarks, including image-based tasks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:50:32 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Yu", "Tianhe", ""], ["Kumar", "Aviral", ""], ["Rafailov", "Rafael", ""], ["Rajeswaran", "Aravind", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "2102.08370", "submitter": "Kevin McKee", "authors": "Kevin R. McKee and Joel Z. Leibo and Charlie Beattie and Richard\n  Everett", "title": "Quantifying environment and population diversity in multi-agent\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a major challenge for multi-agent reinforcement learning.\nHow well does an agent perform when placed in novel environments and in\ninteractions with new co-players? In this paper, we investigate and quantify\nthe relationship between generalization and diversity in the multi-agent\ndomain. Across the range of multi-agent environments considered here,\nprocedurally generating training levels significantly improves agent\nperformance on held-out levels. However, agent performance on the specific\nlevels used in training sometimes declines as a result. To better understand\nthe effects of co-player variation, our experiments introduce a new\nenvironment-agnostic measure of behavioral diversity. Results demonstrate that\npopulation size and intrinsic motivation are both effective methods of\ngenerating greater population diversity. In turn, training with a diverse set\nof co-players strengthens agent performance in some (but not all) cases.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:54:39 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["McKee", "Kevin R.", ""], ["Leibo", "Joel Z.", ""], ["Beattie", "Charlie", ""], ["Everett", "Richard", ""]]}, {"id": "2102.08445", "submitter": "Nancy Xin Ru Wang", "authors": "Nancy Xin Ru Wang, Douglas Burdick, Yunyao Li", "title": "TableLab: An Interactive Table Extraction System with Adaptive Deep\n  Learning", "comments": "Accepted at IUI'21", "journal-ref": "26th International Conference on Intelligent User Interfaces 2021", "doi": "10.1145/3397482.3450718", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Table extraction from PDF and image documents is a ubiquitous task in the\nreal-world. Perfect extraction quality is difficult to achieve with one single\nout-of-box model due to (1) the wide variety of table styles, (2) the lack of\ntraining data representing this variety and (3) the inherent ambiguity and\nsubjectivity of table definitions between end-users. Meanwhile, building\ncustomized models from scratch can be difficult due to the expensive nature of\nannotating table data. We attempt to solve these challenges with TableLab by\nproviding a system where users and models seamlessly work together to quickly\ncustomize high-quality extraction models with a few labelled examples for the\nuser's document collection, which contains pages with tables. Given an input\ndocument collection, TableLab first detects tables with similar structures\n(templates) by clustering embeddings from the extraction model. Document\ncollections often contain tables created with a limited set of templates or\nsimilar structures. It then selects a few representative table examples already\nextracted with a pre-trained base deep learning model. Via an easy-to-use user\ninterface, users provide feedback to these selections without necessarily\nhaving to identify every single error. TableLab then applies such feedback to\nfinetune the pre-trained model and returns the results of the finetuned model\nback to the user. The user can choose to repeat this process iteratively until\nobtaining a customized model with satisfactory performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 20:52:44 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Wang", "Nancy Xin Ru", ""], ["Burdick", "Douglas", ""], ["Li", "Yunyao", ""]]}, {"id": "2102.08453", "submitter": "Boris Ruf", "authors": "Boris Ruf and Marcin Detyniecki", "title": "Towards the Right Kind of Fairness in AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is a concept of justice. Various definitions exist, some of them\nconflicting with each other. In the absence of an uniformly accepted notion of\nfairness, choosing the right kind for a specific situation has always been a\ncentral issue in human history. When it comes to implementing sustainable\nfairness in artificial intelligence systems, this old question plays a key role\nonce again: How to identify the most appropriate fairness metric for a\nparticular application? The answer is often a matter of context, and the best\nchoice depends on ethical standards and legal requirements. Since ethics\nguidelines on this topic are kept rather general for now, we aim to provide\nmore hands-on guidance with this document. Therefore, we first structure the\ncomplex landscape of existing fairness metrics and explain the different\noptions by example. Furthermore, we propose the \"Fairness Compass\", a tool\nwhich formalises the selection process and makes identifying the most\nappropriate fairness definition for a given system a simple, straightforward\nprocedure. Because this process also allows to document the reasoning behind\nthe respective decisions, we argue that this approach can help to build trust\nfrom the user through explaining and justifying the implemented fairness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:12:30 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 10:21:55 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 14:09:44 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 10:06:32 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 20:15:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ruf", "Boris", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2102.08462", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Vaneet Aggarwal, Kamyar Azizzadenesheli", "title": "Multi-Agent Multi-Armed Bandits with Limited Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem where $N$ agents collaboratively interact with an\ninstance of a stochastic $K$ arm bandit problem for $K \\gg N$. The agents aim\nto simultaneously minimize the cumulative regret over all the agents for a\ntotal of $T$ time steps, the number of communication rounds, and the number of\nbits in each communication round. We present Limited Communication\nCollaboration - Upper Confidence Bound (LCC-UCB), a doubling-epoch based\nalgorithm where each agent communicates only after the end of the epoch and\nshares the index of the best arm it knows. With our algorithm, LCC-UCB, each\nagent enjoys a regret of $\\tilde{O}\\left(\\sqrt{({K/N}+ N)T}\\right)$,\ncommunicates for $O(\\log T)$ steps and broadcasts $O(\\log K)$ bits in each\ncommunication step. We extend the work to sparse graphs with maximum degree\n$K_G$, and diameter $D$ and propose LCC-UCB-GRAPH which enjoys a regret bound\nof $\\tilde{O}\\left(D\\sqrt{(K/N+ K_G)DT}\\right)$. Finally, we empirically show\nthat the LCC-UCB and the LCC-UCB-GRAPH algorithm perform well and outperform\nstrategies that communicate through a central node\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 06:28:37 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""], ["Azizzadenesheli", "Kamyar", ""]]}, {"id": "2102.08482", "submitter": "Bashar Awwad Shiekh Hasan", "authors": "Robert McCluskey, Amir Enshaei, Bashar Awwad Shiekh Hasan", "title": "Finding the Ground-Truth from Multiple Labellers: Why Parameters of the\n  Task Matter", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Employing multiple workers to label data for machine learning models has\nbecome increasingly important in recent years with greater demand to collect\nhuge volumes of labelled data to train complex models while mitigating the risk\nof incorrect and noisy labelling. Whether it is large scale data gathering on\npopular crowd-sourcing platforms or smaller sets of workers in high-expertise\nlabelling exercises, there are various methods recommended to gather a\nconsensus from employed workers and establish ground-truth labels. However,\nthere is very little research on how the various parameters of a labelling task\ncan impact said methods. These parameters include the number of workers, worker\nexpertise, number of labels in a taxonomy and sample size. In this paper,\nMajority Vote, CrowdTruth and Binomial Expectation Maximisation are\ninvestigated against the permutations of these parameters in order to provide\nbetter understanding of the parameter settings to give an advantage in\nground-truth inference. Findings show that both Expectation Maximisation and\nCrowdTruth are only likely to give an advantage over majority vote under\ncertain parameter conditions, while there are many cases where the methods can\nbe shown to have no major impact. Guidance is given as to what parameters\nmethods work best under, while the experimental framework provides a way of\ntesting other established methods and also testing new methods that can attempt\nto provide advantageous performance where the methods in this paper did not. A\ngreater level of understanding regarding optimal crowd-sourcing parameters is\nalso achieved.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 22:51:11 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["McCluskey", "Robert", ""], ["Enshaei", "Amir", ""], ["Hasan", "Bashar Awwad Shiekh", ""]]}, {"id": "2102.08492", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Xuezhou Zhang, Xiaojin Zhu, Adish Singla", "title": "Reward Poisoning in Reinforcement Learning: Attacks Against Unknown\n  Learners in Unknown Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study black-box reward poisoning attacks against reinforcement learning\n(RL), in which an adversary aims to manipulate the rewards to mislead a\nsequence of RL agents with unknown algorithms to learn a nefarious policy in an\nenvironment unknown to the adversary a priori. That is, our attack makes\nminimum assumptions on the prior knowledge of the adversary: it has no initial\nknowledge of the environment or the learner, and neither does it observe the\nlearner's internal mechanism except for its performed actions. We design a\nnovel black-box attack, U2, that can provably achieve a near-matching\nperformance to the state-of-the-art white-box attack, demonstrating the\nfeasibility of reward poisoning even in the most challenging black-box setting.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 23:20:15 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rakhsha", "Amin", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2102.08507", "submitter": "Vaibhav Vasant Unhelkar", "authors": "Sangwon Seo, Lauren R. Kennedy-Metz, Marco A. Zenati, Julie A. Shah,\n  Roger D. Dias, Vaibhav V. Unhelkar", "title": "Towards an AI Coach to Infer Team Mental Model Alignment in Healthcare", "comments": "Submitted to the 2021 IEEE Conference on Cognitive and Computational\n  Aspects of Situation Management (CogSIMA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared mental models are critical to team success; however, in practice, team\nmembers may have misaligned models due to a variety of factors. In\nsafety-critical domains (e.g., aviation, healthcare), lack of shared mental\nmodels can lead to preventable errors and harm. Towards the goal of mitigating\nsuch preventable errors, here, we present a Bayesian approach to infer\nmisalignment in team members' mental models during complex healthcare task\nexecution. As an exemplary application, we demonstrate our approach using two\nsimulated team-based scenarios, derived from actual teamwork in cardiac\nsurgery. In these simulated experiments, our approach inferred model\nmisalignment with over 75% recall, thereby providing a building block for\nenabling computer-assisted interventions to augment human cognition in the\noperating room and improve teamwork.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:14:08 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Seo", "Sangwon", ""], ["Kennedy-Metz", "Lauren R.", ""], ["Zenati", "Marco A.", ""], ["Shah", "Julie A.", ""], ["Dias", "Roger D.", ""], ["Unhelkar", "Vaibhav V.", ""]]}, {"id": "2102.08539", "submitter": "Baiyu Peng", "authors": "Baiyu Peng, Yao Mu, Jingliang Duan, Yang Guan, Shengbo Eben Li, Jianyu\n  Chen", "title": "Separated Proportional-Integral Lagrangian for Chance Constrained\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is essential for reinforcement learning (RL) applied in real-world\ntasks like autonomous driving. Chance constraints which guarantee the\nsatisfaction of state constraints at a high probability are suitable to\nrepresent the requirements in real-world environment with uncertainty. Existing\nchance constrained RL methods like the penalty method and the Lagrangian method\neither exhibit periodic oscillations or cannot satisfy the constraints. In this\npaper, we address these shortcomings by proposing a separated\nproportional-integral Lagrangian (SPIL) algorithm. Taking a control\nperspective, we first interpret the penalty method and the Lagrangian method as\nproportional feedback and integral feedback control, respectively. Then, a\nproportional-integral Lagrangian method is proposed to steady learning process\nwhile improving safety. To prevent integral overshooting and reduce\nconservatism, we introduce the integral separation technique inspired by PID\ncontrol. Finally, an analytical gradient of the chance constraint is utilized\nfor model-based policy optimization. The effectiveness of SPIL is demonstrated\nby a narrow car-following task. Experiments indicate that compared with\nprevious methods, SPIL improves the performance while guaranteeing safety, with\na steady learning process.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:40:01 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Peng", "Baiyu", ""], ["Mu", "Yao", ""], ["Duan", "Jingliang", ""], ["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Chen", "Jianyu", ""]]}, {"id": "2102.08540", "submitter": "Harini Suresh", "authors": "Harini Suresh, Kathleen M. Lewis, John V. Guttag, Arvind Satyanarayan", "title": "Intuitively Assessing ML Model Reliability through Example-Based\n  Explanations and Editing Model Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability methods aim to help users build trust in and understand the\ncapabilities of machine learning models. However, existing approaches often\nrely on abstract, complex visualizations that poorly map to the task at hand or\nrequire non-trivial ML expertise to interpret. Here, we present two visual\nanalytics modules that facilitate an intuitive assessment of model reliability.\nTo help users better characterize and reason about a model's uncertainty, we\nvisualize raw and aggregate information about a given input's nearest\nneighbors. Using an interactive editor, users can manipulate this input in\nsemantically-meaningful ways, determine the effect on the output, and compare\nagainst their prior expectations. We evaluate our interface using an\nelectrocardiogram beat classification case study. Compared to a baseline\nfeature importance interface, we find that 14 physicians are better able to\nalign the model's uncertainty with domain-relevant factors and build intuition\nabout its capabilities and limitations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:41:32 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 16:07:14 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Suresh", "Harini", ""], ["Lewis", "Kathleen M.", ""], ["Guttag", "John V.", ""], ["Satyanarayan", "Arvind", ""]]}, {"id": "2102.08553", "submitter": "Jun Quan", "authors": "Jun Quan, Meng Yang, Qiang Gan, Deyi Xiong, Yiming Liu, Yuchen Dong,\n  Fangxin Ouyang, Jun Tian, Ruiling Deng, Yongzhi Li, Yang Yang and Daxin Jiang", "title": "Integrating Pre-trained Model into Rule-based Dialogue Management", "comments": "AAAI 2021 Demo Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based dialogue management is still the most popular solution for\nindustrial task-oriented dialogue systems for their interpretablility. However,\nit is hard for developers to maintain the dialogue logic when the scenarios get\nmore and more complex. On the other hand, data-driven dialogue systems, usually\nwith end-to-end structures, are popular in academic research and easier to deal\nwith complex conversations, but such methods require plenty of training data\nand the behaviors are less interpretable. In this paper, we propose a method to\nleverages the strength of both rule-based and data-driven dialogue managers\n(DM). We firstly introduce the DM of Carina Dialog System (CDS, an advanced\nindustrial dialogue system built by Microsoft). Then we propose the\n\"model-trigger\" design to make the DM trainable thus scalable to scenario\nchanges. Furthermore, we integrate pre-trained models and empower the DM with\nfew-shot capability. The experimental results demonstrate the effectiveness and\nstrong few-shot capability of our method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:44:22 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Quan", "Jun", ""], ["Yang", "Meng", ""], ["Gan", "Qiang", ""], ["Xiong", "Deyi", ""], ["Liu", "Yiming", ""], ["Dong", "Yuchen", ""], ["Ouyang", "Fangxin", ""], ["Tian", "Jun", ""], ["Deng", "Ruiling", ""], ["Li", "Yongzhi", ""], ["Yang", "Yang", ""], ["Jiang", "Daxin", ""]]}, {"id": "2102.08562", "submitter": "Haik Manukian", "authors": "Haik Manukian and Massimiliano Di Ventra", "title": "Mode-Assisted Joint Training of Deep Boltzmann Machines", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deep extension of the restricted Boltzmann machine (RBM), known as the\ndeep Boltzmann machine (DBM), is an expressive family of machine learning\nmodels which can serve as compact representations of complex probability\ndistributions. However, jointly training DBMs in the unsupervised setting has\nproven to be a formidable task. A recent technique we have proposed, called\nmode-assisted training, has shown great success in improving the unsupervised\ntraining of RBMs. Here, we show that the performance gains of the mode-assisted\ntraining are even more dramatic for DBMs. In fact, DBMs jointly trained with\nthe mode-assisted algorithm can represent the same data set with orders of\nmagnitude lower number of total parameters compared to state-of-the-art\ntraining procedures and even with respect to RBMs, provided a fan-in network\ntopology is also introduced. This substantial saving in number of parameters\nmakes this training method very appealing also for hardware implementations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 04:03:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Manukian", "Haik", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "2102.08567", "submitter": "Chulhong Kim", "authors": "Sampa Misra, Seungwan Jeon, Ravi Managuli, Seiyon Lee, Gyuwon Kim,\n  Seungchul Lee, Richard G Barr, and Chulhong Kim", "title": "Ensemble Transfer Learning of Elastography and B-mode Breast Ultrasound\n  Images", "comments": "17 pages, 10 figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided detection (CAD) of benign and malignant breast lesions becomes\nincreasingly essential in breast ultrasound (US) imaging. The CAD systems rely\non imaging features identified by the medical experts for their performance,\nwhereas deep learning (DL) methods automatically extract features from the\ndata. The challenge of the DL is the insufficiency of breast US images\navailable to train the DL models. Here, we present an ensemble transfer\nlearning model to classify benign and malignant breast tumors using B-mode\nbreast US (B-US) and strain elastography breast US (SE-US) images. This model\ncombines semantic features from AlexNet & ResNet models to classify benign from\nmalignant tumors. We use both B-US and SE-US images to train the model and\nclassify the tumors. We retrospectively gathered 85 patients' data, with 42\nbenign and 43 malignant cases confirmed with the biopsy. Each patient had\nmultiple B-US and their corresponding SE-US images, and the total dataset\ncontained 261 B-US images and 261 SE-US images. Experimental results show that\nour ensemble model achieves a sensitivity of 88.89% and specificity of 91.10%.\nThese diagnostic performances of the proposed method are equivalent to or\nbetter than manual identification. Thus, our proposed ensemble learning method\nwould facilitate detecting early breast cancer, reliably improving patient\ncare.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 04:23:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Misra", "Sampa", ""], ["Jeon", "Seungwan", ""], ["Managuli", "Ravi", ""], ["Lee", "Seiyon", ""], ["Kim", "Gyuwon", ""], ["Lee", "Seungchul", ""], ["Barr", "Richard G", ""], ["Kim", "Chulhong", ""]]}, {"id": "2102.08571", "submitter": "Yunhan Huang", "authors": "Yunhan Huang and Quanyan Zhu", "title": "Self-Triggered Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study Markov Decision Processes (MDPs) with self-triggered\nstrategies, where the idea of self-triggered control is extended to more\ngeneric MDP models. This extension broadens the application of self-triggering\npolicies to a broader range of systems. We study the co-design problems of the\ncontrol policy and the triggering policy to optimize two pre-specified cost\ncriteria. The first cost criterion is introduced by incorporating a\npre-specified update penalty into the traditional MDP cost criteria to reduce\nthe use of communication resources. Under this criteria, a novel dynamic\nprogramming (DP) equation called DP equation with optimized lookahead to\nproposed to solve for the self-triggering policy under this criteria. The\nsecond self-triggering policy is to maximize the triggering time while still\nguaranteeing a pre-specified level of sub-optimality. Theoretical underpinnings\nare established for the computation and implementation of both policies.\nThrough a gridworld numerical example, we illustrate the two policies'\neffectiveness in reducing sources consumption and demonstrate the trade-offs\nbetween resource consumption and system performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 04:41:44 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Huang", "Yunhan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2102.08581", "submitter": "Jungseul Ok", "authors": "Byungchan Ko and Jungseul Ok", "title": "Time Matters in Using Data Augmentation for Vision-based Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data augmentation technique from computer vision has been widely considered\nas a regularization method to improve data efficiency and generalization\nperformance in vision-based reinforcement learning. We variate the timing of\nusing augmentation, which is, in turn, critical depending on tasks to be solved\nin training and testing. According to our experiments on Open AI Procgen\nBenchmark, if the regularization imposed by augmentation is helpful only in\ntesting, it is better to procrastinate the augmentation after training than to\nuse it during training in terms of sample and computation complexity. We note\nthat some of such augmentations can disturb the training process. Conversely,\nan augmentation providing regularization useful in training needs to be used\nduring the whole training period to fully utilize its benefit in terms of not\nonly generalization but also data efficiency. These phenomena suggest a useful\ntiming control of data augmentation in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 05:22:34 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ko", "Byungchan", ""], ["Ok", "Jungseul", ""]]}, {"id": "2102.08583", "submitter": "Donghwan Lee", "authors": "Donghwan Lee, Jianghai Hu, Niao He", "title": "A Discrete-Time Switching System Analysis of Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel control-theoretic framework to analyze the\nnon-asymptotic convergence of Q-learning. We show that the dynamics of\nasynchronous Q-learning with a constant step-size can be naturally formulated\nas a discrete-time stochastic affine switching system. Moreover, the evolution\nof the Q-learning estimation error is over- and underestimated by trajectories\nof two simpler dynamical systems. Based on these two systems, we derive a new\nfinite-time error bound of asynchronous Q-learning when a constant stepsize is\nused. Our analysis also sheds light on the overestimation phenomenon of\nQ-learning. We further illustrate and validate the analysis through numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 05:32:07 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 15:52:19 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 05:11:23 GMT"}, {"version": "v4", "created": "Sat, 15 May 2021 15:49:52 GMT"}, {"version": "v5", "created": "Tue, 18 May 2021 14:26:32 GMT"}, {"version": "v6", "created": "Wed, 26 May 2021 03:35:50 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Lee", "Donghwan", ""], ["Hu", "Jianghai", ""], ["He", "Niao", ""]]}, {"id": "2102.08585", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Xin Zheng, Baobao Chang and Zhifang Sui", "title": "Towards Faithfulness in Open Domain Table-to-text Generation from an\n  Entity-centric View", "comments": "AAAI-21 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open domain table-to-text generation, we notice that the unfaithful\ngeneration usually contains hallucinated content which can not be aligned to\nany input table record. We thus try to evaluate the generation faithfulness\nwith two entity-centric metrics: table record coverage and the ratio of\nhallucinated entities in text, both of which are shown to have strong agreement\nwith human judgements. Then based on these metrics, we quantitatively analyze\nthe correlation between training data quality and generation fidelity which\nindicates the potential usage of entity information in faithful generation.\nMotivated by these findings, we propose two methods for faithful generation: 1)\naugmented training by incorporating the auxiliary entity information, including\nboth an augmented plan-based model and an unsupervised model and 2) training\ninstance selection based on faithfulness ranking. We show these approaches\nimprove generation fidelity in both full dataset setting and few shot learning\nsettings by both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 05:41:06 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Liu", "Tianyu", ""], ["Zheng", "Xin", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2102.08597", "submitter": "Aston Zhang", "authors": "Aston Zhang, Yi Tay, Shuai Zhang, Alvin Chan, Anh Tuan Luu, Siu Cheung\n  Hui, Jie Fu", "title": "Beyond Fully-Connected Layers with Quaternions: Parameterization of\n  Hypercomplex Multiplications with $1/n$ Parameters", "comments": "Published as a conference paper at the 9th International Conference\n  on Learning Representations (ICLR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have demonstrated reasonable success of representation learning\nin hypercomplex space. Specifically, \"fully-connected layers with Quaternions\"\n(4D hypercomplex numbers), which replace real-valued matrix multiplications in\nfully-connected layers with Hamilton products of Quaternions, both enjoy\nparameter savings with only 1/4 learnable parameters and achieve comparable\nperformance in various applications. However, one key caveat is that\nhypercomplex space only exists at very few predefined dimensions (4D, 8D, and\n16D). This restricts the flexibility of models that leverage hypercomplex\nmultiplications. To this end, we propose parameterizing hypercomplex\nmultiplications, allowing models to learn multiplication rules from data\nregardless of whether such rules are predefined. As a result, our method not\nonly subsumes the Hamilton product, but also learns to operate on any arbitrary\nnD hypercomplex space, providing more architectural flexibility using\narbitrarily $1/n$ learnable parameters compared with the fully-connected layer\ncounterpart. Experiments of applications to the LSTM and Transformer models on\nnatural language inference, machine translation, text style transfer, and\nsubject verb agreement demonstrate architectural flexibility and effectiveness\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 06:16:58 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zhang", "Aston", ""], ["Tay", "Yi", ""], ["Zhang", "Shuai", ""], ["Chan", "Alvin", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""], ["Fu", "Jie", ""]]}, {"id": "2102.08628", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Sachiko Kodera, Hidenobu Shirakami, Ryotetsu\n  Kawaguchi, Kazuhiro Watanabe, Akimasa Hirata", "title": "Knowledge discovery from emergency ambulance dispatch during COVID-19: A\n  case study of Nagoya City, Japan", "comments": "15 pages, 12 figures, 2 tables", "journal-ref": "Journal of Biomedical Informatics, 2021", "doi": "10.1016/j.jbi.2021.103743", "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasting of medical service requirements is an important big data\nproblem that is crucial for resource management in critical times such as\nnatural disasters and pandemics. With the global spread of coronavirus disease\n2019 (COVID-19), several concerns have been raised regarding the ability of\nmedical systems to handle sudden changes in the daily routines of healthcare\nproviders. One significant problem is the management of ambulance dispatch and\ncontrol during a pandemic. To help address this problem, we first analyze\nambulance dispatch data records from April 2014 to August 2020 for Nagoya City,\nJapan. Significant changes were observed in the data during the pandemic,\nincluding the state of emergency (SoE) declared across Japan. In this study, we\npropose a deep learning framework based on recurrent neural networks to\nestimate the number of emergency ambulance dispatches (EADs) during a SoE. The\nfusion of data includes environmental factors, the localization data of mobile\nphone users, and the past history of EADs, thereby providing a general\nframework for knowledge discovery and better resource management. The results\nindicate that the proposed blend of training data can be used efficiently in a\nreal-world estimation of EAD requirements during periods of high uncertainties\nsuch as pandemics.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:37:05 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Rashed", "Essam A.", ""], ["Kodera", "Sachiko", ""], ["Shirakami", "Hidenobu", ""], ["Kawaguchi", "Ryotetsu", ""], ["Watanabe", "Kazuhiro", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2102.08633", "submitter": "Yifan Gao", "authors": "Yifan Gao, Jingjing Li, Michael R. Lyu, Irwin King", "title": "Open-Retrieval Conversational Machine Reading", "comments": "Technical Report, Dataset:\n  https://github.com/Yifan-Gao/open_retrieval_conversational_machine_reading", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In conversational machine reading, systems need to interpret natural language\nrules, answer high-level questions such as \"May I qualify for VA health care\nbenefits?\", and ask follow-up clarification questions whose answer is necessary\nto answer the original question. However, existing works assume the rule text\nis provided for each user question, which neglects the essential retrieval step\nin real scenarios. In this work, we propose and investigate an open-retrieval\nsetting of conversational machine reading. In the open-retrieval setting, the\nrelevant rule texts are unknown so that a system needs to retrieve\nquestion-relevant evidence from a collection of rule texts, and answer users'\nhigh-level questions according to multiple retrieved rule texts in a\nconversational manner. We propose MUDERN, a Multi-passage Discourse-aware\nEntailment Reasoning Network which extracts conditions in the rule texts\nthrough discourse segmentation, conducts multi-passage entailment reasoning to\nanswer user questions directly, or asks clarification follow-up questions to\ninquiry more information. On our created OR-ShARC dataset, MUDERN achieves the\nstate-of-the-art performance, outperforming existing single-passage\nconversational machine reading models as well as a new multi-passage\nconversational machine reading baseline by a large margin. In addition, we\nconduct in-depth analyses to provide new insights into this new setting and our\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:55:01 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Gao", "Yifan", ""], ["Li", "Jingjing", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "2102.08634", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo Arrieta, Sergio Gil-Lopez, Ibai La\\~na, Miren Nekane\n  Bilbao, Javier Del Ser", "title": "On the Post-hoc Explainability of Deep Echo State Networks for Time\n  Series Forecasting, Image and Video Classification", "comments": "22 pages, 9 figures, 3 tables. Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their inception, learning techniques under the Reservoir Computing\nparadigm have shown a great modeling capability for recurrent systems without\nthe computing overheads required for other approaches. Among them, different\nflavors of echo state networks have attracted many stares through time, mainly\ndue to the simplicity and computational efficiency of their learning algorithm.\nHowever, these advantages do not compensate for the fact that echo state\nnetworks remain as black-box models whose decisions cannot be easily explained\nto the general audience. This work addresses this issue by conducting an\nexplainability study of Echo State Networks when applied to learning tasks with\ntime series, image and video data. Specifically, the study proposes three\ndifferent techniques capable of eliciting understandable information about the\nknowledge grasped by these recurrent models, namely, potential memory, temporal\npatterns and pixel absence effect. Potential memory addresses questions related\nto the effect of the reservoir size in the capability of the model to store\ntemporal information, whereas temporal patterns unveils the recurrent\nrelationships captured by the model over time. Finally, pixel absence effect\nattempts at evaluating the effect of the absence of a given pixel when the echo\nstate network model is used for image and video classification. We showcase the\nbenefits of our proposed suite of techniques over three different domains of\napplicability: time series modeling, image and, for the first time in the\nrelated literature, video classification. Our results reveal that the proposed\ntechniques not only allow for a informed understanding of the way these models\nwork, but also serve as diagnostic tools capable of detecting issues inherited\nfrom data (e.g. presence of hidden bias).\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:56:33 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Arrieta", "Alejandro Barredo", ""], ["Gil-Lopez", "Sergio", ""], ["La\u00f1a", "Ibai", ""], ["Bilbao", "Miren Nekane", ""], ["Del Ser", "Javier", ""]]}, {"id": "2102.08638", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Martin Stettinger and M\\\"usl\\\"um Atas and\n  Ralph Samer and Jennifer Nerlich and Simon Scholz and Juha Tiihonen and Mikko\n  Raatikainen", "title": "Towards Utility-based Prioritization of Requirements in Open Source\n  Environments", "comments": "A. Felfernig, M. Stettinger, M. Atas, R. Samer, J. Nerlich, S.\n  Scholz, J. Tiihonen, and M. Raatikainen. Towards Utility-based Prioritization\n  of Requirements in Open Source Environments, 26th IEEE Conference on\n  Requirements Engineering, pp. 406-411, Banff, Canada, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements Engineering in open source projects such as Eclipse faces the\nchallenge of having to prioritize requirements for individual contributors in a\nmore or less unobtrusive fashion. In contrast to conventional industrial\nsoftware development projects, contributors in open source platforms can decide\non their own which requirements to implement next. In this context, the main\nrole of prioritization is to support contributors in figuring out the most\nrelevant and interesting requirements to be implemented next and thus avoid\ntime-consuming and inefficient search processes. In this paper, we show how\nutility-based prioritization approaches can be used to support contributors in\nconventional as well as in open source Requirements Engineering scenarios. As\nan example of an open source environment, we use Bugzilla. In this context, we\nalso show how dependencies can be taken into account in utility-based\nprioritization processes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 09:05:54 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Felfernig", "Alexander", ""], ["Stettinger", "Martin", ""], ["Atas", "M\u00fcsl\u00fcm", ""], ["Samer", "Ralph", ""], ["Nerlich", "Jennifer", ""], ["Scholz", "Simon", ""], ["Tiihonen", "Juha", ""], ["Raatikainen", "Mikko", ""]]}, {"id": "2102.08643", "submitter": "Hao Wang", "authors": "Hao Wang, Weining Wang, Jing Liu", "title": "Temporal Memory Attention for Video Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video semantic segmentation requires to utilize the complex temporal\nrelations between frames of the video sequence. Previous works usually exploit\naccurate optical flow to leverage the temporal relations, which suffer much\nfrom heavy computational cost. In this paper, we propose a Temporal Memory\nAttention Network (TMANet) to adaptively integrate the long-range temporal\nrelations over the video sequence based on the self-attention mechanism without\nexhaustive optical flow prediction. Specially, we construct a memory using\nseveral past frames to store the temporal information of the current frame. We\nthen propose a temporal memory attention module to capture the relation between\nthe current frame and the memory to enhance the representation of the current\nframe. Our method achieves new state-of-the-art performances on two challenging\nvideo semantic segmentation datasets, particularly 80.3% mIoU on Cityscapes and\n76.5% mIoU on CamVid with ResNet-50.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 09:18:57 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Wang", "Hao", ""], ["Wang", "Weining", ""], ["Liu", "Jing", ""]]}, {"id": "2102.08686", "submitter": "Michael Cohen", "authors": "Michael K. Cohen, Marcus Hutter, Neel Nanda", "title": "Fully General Online Imitation Learning", "comments": "13 pages with 8-page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In imitation learning, imitators and demonstrators are policies for picking\nactions given past interactions with the environment. If we run an imitator, we\nprobably want events to unfold similarly to the way they would have if the\ndemonstrator had been acting the whole time. No existing work provides formal\nguidance in how this might be accomplished, instead restricting focus to\nenvironments that restart, making learning unusually easy, and conveniently\nlimiting the significance of any mistake. We address a fully general setting,\nin which the (stochastic) environment and demonstrator never reset, not even\nfor training purposes. Our new conservative Bayesian imitation learner\nunderestimates the probabilities of each available action, and queries for more\ndata with the remaining probability. Our main result: if an event would have\nbeen unlikely had the demonstrator acted the whole time, that event's\nlikelihood can be bounded above when running the (initially totally ignorant)\nimitator instead. Meanwhile, queries to the demonstrator rapidly diminish in\nfrequency.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 10:57:37 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Cohen", "Michael K.", ""], ["Hutter", "Marcus", ""], ["Nanda", "Neel", ""]]}, {"id": "2102.08689", "submitter": "Zhe Chen", "authors": "Zhe Chen, Daniel Harabor, Jiaoyang Li, Peter J. Stuckey", "title": "Symmetry Breaking for k-Robust Multi-Agent Path Finding", "comments": "8 pages. Accepted by Thirty-Fifth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  During Multi-Agent Path Finding (MAPF) problems, agents can be delayed by\nunexpected events. To address such situations recent work describes k-Robust\nConflict-BasedSearch (k-CBS): an algorithm that produces coordinated and\ncollision-free plan that is robust for up to k delays. In this work we\nintroducing a variety of pairwise symmetry breaking constraints, specific to\nk-robust planning, that can efficiently find compatible and optimal paths for\npairs of conflicting agents. We give a thorough description of the new\nconstraints and report large improvements to success rate ina range of domains\nincluding: (i) classic MAPF benchmarks;(ii) automated warehouse domains and;\n(iii) on maps from the 2019 Flatland Challenge, a recently introduced railway\ndomain where k-robust planning can be fruitfully applied to schedule trains.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:09:33 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Chen", "Zhe", ""], ["Harabor", "Daniel", ""], ["Li", "Jiaoyang", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2102.08692", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Andrea Trentini, Italo Zoppis, Alessio Zanga, Sara\n  Manzoni, Giada Pietrabissa, Anna Guerrini Usubini, and Gianluca Castelnuovo", "title": "ACTA: A Mobile-Health Solution for Integrated Nudge-Neurofeedback\n  Training for Senior Citizens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SY eess.SP eess.SY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the worldwide population gets increasingly aged, in-home telemedicine and\nmobile-health solutions represent promising services to promote active and\nindependent aging and to contribute to a paradigm shift towards patient-centric\nhealthcare. In this work, we present ACTA (Advanced Cognitive Training for\nAging), a prototype mobile-health solution to provide advanced cognitive\ntraining for senior citizens with mild cognitive impairments. We disclose here\nthe conceptualization of ACTA as the integration of two promising\nrehabilitation strategies: the \"Nudge theory\", from the cognitive domain, and\nthe neurofeedback, from the neuroscience domain. Moreover, in ACTA we exploit\nthe most advanced machine learning techniques to deliver customized and fully\nadaptive support to the elderly, while training in an ecological environment.\nACTA represents the next-step beyond SENIOR, an earlier mobile-health project\nfor cognitive training based on Nudge theory, currently ongoing in Lombardy\nRegion. Beyond SENIOR, ACTA represents a highly-usable, accessible, low-cost,\nnew-generation mobile-health solution to promote independent aging and\neffective motor-cognitive training support, while empowering the elderly in\ntheir own aging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:12:23 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Cisotto", "Giulia", ""], ["Trentini", "Andrea", ""], ["Zoppis", "Italo", ""], ["Zanga", "Alessio", ""], ["Manzoni", "Sara", ""], ["Pietrabissa", "Giada", ""], ["Usubini", "Anna Guerrini", ""], ["Castelnuovo", "Gianluca", ""]]}, {"id": "2102.08747", "submitter": "Sebastian Monka", "authors": "Sebastian Monka, Lavdim Halilaj, Stefan Schmid, Achim Rettinger", "title": "Learning Visual Models using a Knowledge Graph as a Trainer", "comments": "ISWC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional computer vision approaches, based on neural networks (NN), are\ntypically trained on a large amount of image data. By minimizing the\ncross-entropy loss between a prediction and a given class label, the NN and its\nvisual embedding space are learned to fulfill a given task. However, due to the\nsole dependence on the image data distribution of the training domain, these\nmodels tend to fail when applied to a target domain that differs from their\nsource domain. To learn a more robust NN to domain shifts, we propose the\nknowledge graph neural network (KG-NN), a neuro-symbolic approach that\nsupervises the training using image-data-invariant auxiliary knowledge. The\nauxiliary knowledge is first encoded in a knowledge graph with respective\nconcepts and their relationships, which is then transformed into a dense vector\nrepresentation via an embedding method. Using a contrastive loss function,\nKG-NN learns to adapt its visual embedding space and thus its weights according\nto the image-data invariant knowledge graph embedding space. We evaluate KG-NN\non visual transfer learning tasks for classification using the mini-ImageNet\ndataset and its derivatives, as well as road sign recognition datasets from\nGermany and China. The results show that a visual model trained with a\nknowledge graph as a trainer outperforms a model trained with cross-entropy in\nall experiments, in particular when the domain gap increases. Besides better\nperformance and stronger robustness to domain shifts, these KG-NN adapts to\nmultiple datasets and classes without suffering heavily from catastrophic\nforgetting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 13:24:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 13:21:17 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Monka", "Sebastian", ""], ["Halilaj", "Lavdim", ""], ["Schmid", "Stefan", ""], ["Rettinger", "Achim", ""]]}, {"id": "2102.08755", "submitter": "Kristina Gligoric", "authors": "Kristina Gligori\\'c, Ryen W. White, Emre K{\\i}c{\\i}man, Eric Horvitz,\n  Arnaud Chiolero, Robert West", "title": "Formation of Social Ties Influences Food Choice: A Campus-Wide\n  Longitudinal Study", "comments": null, "journal-ref": "Proc. ACM Hum.-Comput. Interact.5, CSCW1, Article 184 (April 2021)", "doi": "10.1145/34492971", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nutrition is a key determinant of long-term health, and social influence has\nlong been theorized to be a key determinant of nutrition. It has been difficult\nto quantify the postulated role of social influence on nutrition using\ntraditional methods such as surveys, due to the typically small scale and short\nduration of studies. To overcome these limitations, we leverage a novel source\nof data: logs of 38 million food purchases made over an 8-year period on the\nEcole Polytechnique Federale de Lausanne (EPFL) university campus, linked to\nanonymized individuals via the smartcards used to make on-campus purchases. In\na longitudinal observational study, we ask: How is a person's food choice\naffected by eating with someone else whose own food choice is healthy vs.\nunhealthy? To estimate causal effects from the passively observed log data, we\ncontrol confounds in a matched quasi-experimental design: we identify focal\nusers who at first do not have any regular eating partners but then start\neating with a fixed partner regularly, and we match focal users into comparison\npairs such that paired users are nearly identical with respect to covariates\nmeasured before acquiring the partner, where the two focal users' new eating\npartners diverge in the healthiness of their respective food choice. A\ndifference-in-differences analysis of the paired data yields clear evidence of\nsocial influence: focal users acquiring a healthy-eating partner change their\nhabits significantly more toward healthy foods than focal users acquiring an\nunhealthy-eating partner. We further identify foods whose purchase frequency is\nimpacted significantly by the eating partner's healthiness of food choice.\nBeyond the main results, the work demonstrates the utility of passively sensed\nfood purchase logs for deriving insights, with the potential of informing the\ndesign of public health interventions and food offerings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 13:47:28 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Gligori\u0107", "Kristina", ""], ["White", "Ryen W.", ""], ["K\u0131c\u0131man", "Emre", ""], ["Horvitz", "Eric", ""], ["Chiolero", "Arnaud", ""], ["West", "Robert", ""]]}, {"id": "2102.08758", "submitter": "Zeyad Mohsen", "authors": "Omar Mohamed, Zeyad Mohsen, Mohamed Wageeh, Mohamed Hegazy", "title": "Autonomous Navigation in Dynamic Environments: Deep Learning-Based\n  Approach", "comments": "BSc Degree, Graduation Project Thesis, Institute of Aviation\n  Engineering & Technology, Egypt, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile robotics is a research area that has witnessed incredible advances for\nthe last decades. Robot navigation is an essential task for mobile robots. Many\nmethods are proposed for allowing robots to navigate within different\nenvironments. This thesis studies different deep learning-based approaches,\nhighlighting the advantages and disadvantages of each scheme. In fact, these\napproaches are promising that some of them can navigate the robot in unknown\nand dynamic environments. In this thesis, one of the deep learning methods\nbased on convolutional neural network (CNN) is realized by software\nimplementations. There are different preparation studies to complete this\nthesis such as introduction to Linux, robot operating system (ROS), C++,\npython, and GAZEBO simulator. Within this work, we modified the drone network\n(namely, DroNet) approach to be used in an indoor environment by using a ground\nrobot in different cases. Indeed, the DroNet approach suffers from the absence\nof goal-oriented motion. Therefore, this thesis mainly focuses on tackling this\nproblem via mapping using simultaneous localization and mapping (SLAM) and path\nplanning techniques using Dijkstra. Afterward, the combination between the\nDroNet ground robot-based, mapping, and path planning leads to a goal-oriented\nmotion, following the shortest path while avoiding the dynamic obstacle.\nFinally, we propose a low-cost approach, for indoor applications such as\nrestaurants, museums, etc, on the base of using a monocular camera instead of a\nlaser scanner.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:20:20 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Mohamed", "Omar", ""], ["Mohsen", "Zeyad", ""], ["Wageeh", "Mohamed", ""], ["Hegazy", "Mohamed", ""]]}, {"id": "2102.08760", "submitter": "Serena Ivaldi", "authors": "Serena Ivaldi (LARSEN), Pauline Maurice (LORIA), Waldez Gomes (LORIA),\n  Jean Theurel (INRS (Vandoeuvre l\\`es Nancy)), Li\\^en Wioland (INRS\n  (Vandoeuvre l\\`es Nancy)), Jean-Jacques Atain-Kouadio (INRS (Vandoeuvre l\\`es\n  Nancy)), Laurent Claudon (INRS (Vandoeuvre l\\`es Nancy)), Hind Hani (CUESim),\n  Antoine Kimmoun (CHRU Nancy), Jean-Marc Sellal (CHRU Nancy), Bruno Levy (CHRU\n  Nancy), Jean Paysant (CHRU Nancy), Sergue\\\"i Malikov (CHRU Nancy), Bruno\n  Chenuel (CHRU Nancy), Nicla Settembre (CHRU Nancy)", "title": "Using exoskeletons to assist medical staff during prone positioning of\n  mechanically ventilated COVID-19 patients: a pilot study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conducted a pilot study to evaluate the potential and feasibility of\nback-support exoskeletons to help the caregivers in the Intensive Care Unit\n(ICU) of the University Hospital of Nancy (France) executing Prone Positioning\n(PP) maneuvers on patients suffering from severe COVID-19-related Acute\nRespiratory Distress Syndrome. After comparing four commercial exoskeletons,\nthe Laevo passive exoskeleton was selected and used in the ICU in April 2020.\nThe first volunteers using the Laevo reported very positive feedback and\nreduction of effort, confirmed by EMG and ECG analysis. Laevo has been since\nused to physically assist during PP in the ICU of the Hospital of Nancy,\nfollowing the recrudescence of COVID-19, with an overall positive feedback.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 09:24:33 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ivaldi", "Serena", "", "LARSEN"], ["Maurice", "Pauline", "", "LORIA"], ["Gomes", "Waldez", "", "LORIA"], ["Theurel", "Jean", "", "INRS"], ["Wioland", "Li\u00ean", "", "INRS"], ["Atain-Kouadio", "Jean-Jacques", "", "INRS"], ["Claudon", "Laurent", "", "INRS"], ["Hani", "Hind", "", "CUESim"], ["Kimmoun", "Antoine", "", "CHRU Nancy"], ["Sellal", "Jean-Marc", "", "CHRU Nancy"], ["Levy", "Bruno", "", "CHRU\n  Nancy"], ["Paysant", "Jean", "", "CHRU Nancy"], ["Malikov", "Sergue\u00ef", "", "CHRU Nancy"], ["Chenuel", "Bruno", "", "CHRU Nancy"], ["Settembre", "Nicla", "", "CHRU Nancy"]]}, {"id": "2102.08769", "submitter": "Benjamin Riu", "authors": "Karim Lounici, Katia Meziani and Benjamin Riu", "title": "Muddling Labels for Regularization, a novel approach to generalization", "comments": "arXiv admin note: text overlap with arXiv:2006.06705", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a central problem in Machine Learning. Indeed most\nprediction methods require careful calibration of hyperparameters usually\ncarried out on a hold-out \\textit{validation} dataset to achieve\ngeneralization. The main goal of this paper is to introduce a novel approach to\nachieve generalization without any data splitting, which is based on a new risk\nmeasure which directly quantifies a model's tendency to overfit. To fully\nunderstand the intuition and advantages of this new approach, we illustrate it\nin the simple linear regression model ($Y=X\\beta+\\xi$) where we develop a new\ncriterion. We highlight how this criterion is a good proxy for the true\ngeneralization risk. Next, we derive different procedures which tackle several\nstructures simultaneously (correlation, sparsity,...). Noticeably, these\nprocedures \\textbf{concomitantly} train the model and calibrate the\nhyperparameters. In addition, these procedures can be implemented via classical\ngradient descent methods when the criterion is differentiable w.r.t. the\nhyperparameters. Our numerical experiments reveal that our procedures are\ncomputationally feasible and compare favorably to the popular approach (Ridge,\nLASSO and Elastic-Net combined with grid-search cross-validation) in term of\ngeneralization. They also outperform the baseline on two additional tasks:\nestimation and support recovery of $\\beta$. Moreover, our procedures do not\nrequire any expertise for the calibration of the initial parameters which\nremain the same for all the datasets we experimented on.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:02:30 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lounici", "Karim", ""], ["Meziani", "Katia", ""], ["Riu", "Benjamin", ""]]}, {"id": "2102.08771", "submitter": "Saeid Barati", "authors": "Saeid Barati, Gordon Kindlmann, Hank Hoffmann", "title": "Comparing and Combining Approximate Computing Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximate computing frameworks configure applications so they can operate\nat a range of points in an accuracy-performance trade-off space. Prior work has\nintroduced many frameworks to create approximate programs. As approximation\nframeworks proliferate, it is natural to ask how they can be compared and\ncombined to create even larger, richer trade-off spaces. We address these\nquestions by presenting VIPER and BOA. VIPER compares trade-off spaces induced\nby different approximation frameworks by visualizing performance improvements\nacross the full range of possible accuracies. BOA is a family of exploration\ntechniques that quickly locate Pareto-efficient points in the immense trade-off\nspace produced by the combination of two or more approximation frameworks. We\nuse VIPER and BOA to compare and combine three different approximation\nframeworks from across the system stack, including: one that changes numerical\nprecision, one that skips loop iterations, and one that manipulates existing\napplication parameters. Compared to simply looking at Pareto-optimal curves, we\nfind VIPER's visualizations provide a quicker and more convenient way to\ndetermine the best approximation technique for any accuracy loss. Compared to a\nstate-of-the-art evolutionary algorithm, we find that BOA explores 14x fewer\nconfigurations yet locates 35% more Pareto-efficient points.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 04:52:43 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Barati", "Saeid", ""], ["Kindlmann", "Gordon", ""], ["Hoffmann", "Hank", ""]]}, {"id": "2102.08777", "submitter": "Felix Weitk\\\"amper", "authors": "Felix Weitk\\\"amper", "title": "An asymptotic analysis of probabilistic logic programming with\n  implications for expressing projective families of distributions", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last years, there has been increasing research on the scaling\nbehaviour of statistical relational representations with the size of the\ndomain, and on the connections between domain size dependence and lifted\ninference. In particular, the asymptotic behaviour of statistical relational\nrepresentations has come under scrutiny, and projectivity was isolated as the\nstrongest form of domain size independence. In this contribution we show that\nevery probabilistic logic program under the distribution semantics is\nasymptotically equivalent to a probabilistic logic program consisting only of\ndeterminate clauses over probabilistic facts. To facilitate the application of\nclassical results from finite model theory, we introduce the abstract\ndistribution semantics, defined as an arbitrary logical theory over\nprobabilistic facts to bridge the gap to the distribution semantics underlying\nprobabilistic logic programming. In this representation, determinate logic\nprograms correspond to quantifier-free theories, making asymptotic quantifier\nresults avilable for use. We can conclude that every probabilistic logic\nprogram inducing a projective family of distributions is in fact captured by\nthis class, and we can infer interesting consequences for the expressivity of\nprobabilistic logic programs as well as for the asymptotic behaviour of\nprobabilistic rules.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:07:16 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 12:03:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Weitk\u00e4mper", "Felix", ""]]}, {"id": "2102.08778", "submitter": "Giacomo Da Col", "authors": "Giacomo Da Col and Erich Teppan", "title": "Large-Scale Benchmarks for the Job Shop Scheduling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report contains the description of two novel job shop scheduling\nbenchmarks that resemble instances of real scheduling problem as they appear in\nindustry. In particular, the aim was to provide large-scale benchmarks (up to 1\nmillion operations) to test the state-of-the-art scheduling solutions on\nproblems that are closer to what occurs in a real industrial context. The first\nbenchmark is an extension of the well known Taillard benchmark (1992), while\nthe second is a collection of scheduling instances with a known-optimum\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:18:48 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 15:07:02 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Da Col", "Giacomo", ""], ["Teppan", "Erich", ""]]}, {"id": "2102.08811", "submitter": "Zihao Zhang", "authors": "Zihao Zhang, Bryan Lim and Stefan Zohren", "title": "Deep Learning for Market by Order Data", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market by order (MBO) data - a detailed feed of individual trade instructions\nfor a given stock on an exchange - is arguably one of the most granular sources\nof microstructure information. While limit order books (LOBs) are implicitly\nderived from it, MBO data is largely neglected by current academic literature\nwhich focuses primarily on LOB modelling. In this paper, we demonstrate the\nutility of MBO data for forecasting high-frequency price movements, providing\nan orthogonal source of information to LOB snapshots and expanding the universe\nof alpha discovery. We provide the first predictive analysis on MBO data by\ncarefully introducing the data structure and presenting a specific\nnormalisation scheme to consider level information in order books and to allow\nmodel training with multiple instruments. Through forecasting experiments using\ndeep neural networks, we show that while MBO-driven and LOB-driven models\nindividually provide similar performance, ensembles of the two can lead to\nimprovements in forecasting accuracy - indicating that MBO data is additive to\nLOB-based features.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:16:26 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 09:20:19 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Zihao", ""], ["Lim", "Bryan", ""], ["Zohren", "Stefan", ""]]}, {"id": "2102.08827", "submitter": "Inga Jatzkowski", "authors": "Inga Jatzkowski, Till Menzel, and Markus Maurer", "title": "A Knowledge-based Approach for the Automatic Construction of Skill\n  Graphs for Online Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated vehicles need to be aware of the capabilities they currently\npossess. Skill graphs are directed acylic graphs in which a vehicle's\ncapabilities and the dependencies between these capabilities are modeled. The\nskills a vehicle requires depend on the behaviors the vehicle has to perform\nand the operational design domain (ODD) of the vehicle. Skill graphs were\noriginally proposed for online monitoring of the current capabilities of an\nautomated vehicle. They have also been shown to be useful during other parts of\nthe development process, e.g. system design, system verification. Skill graph\nconstruction is an iterative, expert-based, manual process with little to no\nguidelines. This process is, thus, prone to errors and inconsistencies\nespecially regarding the propagation of changes in the vehicle's intended ODD\ninto the skill graphs. In order to circumnavigate this problem, we propose to\nformalize expert knowledge regarding skill graph construction into a knowledge\nbase and automate the construction process. Thus, all changes in the vehicle's\nODD are reflected in the skill graphs automatically leading to a reduction in\ninconsistencies and errors in the constructed skill graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:15:53 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Jatzkowski", "Inga", ""], ["Menzel", "Till", ""], ["Maurer", "Markus", ""]]}, {"id": "2102.08845", "submitter": "Gadekallu Thippa Reddy", "authors": "Shaashwat Agrawal, Sagnik Sarkar, Gautam Srivastava, Praveen Kumar\n  Reddy Maddikunta, Thippa Reddy Gadekallu", "title": "Genetically Optimized Prediction of Remaining Useful Life", "comments": "Submitted to SUSCOM, Elsevier", "journal-ref": null, "doi": "10.1016/j.suscom.2021.100565", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The application of remaining useful life (RUL) prediction has taken great\nimportance in terms of energy optimization, cost-effectiveness, and risk\nmitigation. The existing RUL prediction algorithms mostly constitute deep\nlearning frameworks. In this paper, we implement LSTM and GRU models and\ncompare the obtained results with a proposed genetically trained neural\nnetwork. The current models solely depend on Adam and SGD for optimization and\nlearning. Although the models have worked well with these optimizers, even\nlittle uncertainties in prognostics prediction can result in huge losses. We\nhope to improve the consistency of the predictions by adding another layer of\noptimization using Genetic Algorithms. The hyper-parameters - learning rate and\nbatch size are optimized beyond manual capacity. These models and the proposed\narchitecture are tested on the NASA Turbofan Jet Engine dataset. The optimized\narchitecture can predict the given hyper-parameters autonomously and provide\nsuperior results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:09:23 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Agrawal", "Shaashwat", ""], ["Sarkar", "Sagnik", ""], ["Srivastava", "Gautam", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Gadekallu", "Thippa Reddy", ""]]}, {"id": "2102.08863", "submitter": "Luis J. Manso", "authors": "Pilar Bachiller and Daniel Rodriguez-Criado and Ronit R. Jorvekar and\n  Pablo Bustos and Diego R. Faria and Luis J. Manso", "title": "A Graph Neural Network to Model Disruption in Human-Aware Robot\n  Navigation", "comments": "23 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:1909.09003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Autonomous navigation is a key skill for assistive and service robots. To be\nsuccessful, robots have to minimise the disruption caused to humans while\nmoving. This implies predicting how people will move and complying with social\nconventions. Avoiding disrupting personal spaces, people's paths and\ninteractions are examples of these social conventions. This paper leverages\nGraph Neural Networks to model robot disruption considering the movement of the\nhumans and the robot so that the model built can be used by path planning\nalgorithms. Along with the model, this paper presents an evolution of the\ndataset SocNav1 [25] which considers the movement of the robot and the humans,\nand an updated scenario-to-graph transformation which is tested using different\nGraph Neural Network blocks. The model trained achieves close-to-human\nperformance in the dataset. In addition to its accuracy, the main advantage of\nthe approach is its scalability in terms of the number of social factors that\ncan be considered in comparison with handcrafted models. The dataset and the\nmodel are available in a public repository\n(https://github.com/gnns4hri/sngnnv2).\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:44:52 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 10:57:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Bachiller", "Pilar", ""], ["Rodriguez-Criado", "Daniel", ""], ["Jorvekar", "Ronit R.", ""], ["Bustos", "Pablo", ""], ["Faria", "Diego R.", ""], ["Manso", "Luis J.", ""]]}, {"id": "2102.08866", "submitter": "Kahraman Kostas Mr", "authors": "Kahraman Kostas, Mike Just, Michael A. Lones", "title": "IoTDevID: A Behaviour-Based Fingerprinting Method for Device\n  Identification in the IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Device identification is one way to secure a network of IoT devices, whereby\ndevices identified as suspicious can subsequently be isolated from a network.\nWe introduce a novel fingerprinting method, IoTDevID, for device identification\nthat uses machine learning to model the behaviour of IoT devices based on\nnetwork packets. Our method uses an enhanced combination of features from\nprevious work and includes an approach for dealing with unbalanced device data\nvia data augmentation. We further demonstrate how to enhance device\nidentification via a group-wise data aggregation. We provide a comparative\nevaluation of our method against two recent identification methods using three\npublic IoT datasets which together contain data from over 100 devices. Through\nour evaluation we demonstrate improved performance over previous results with\nF1-scores above 99%, with considerable improvement gained from data\naggregation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:50:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Kostas", "Kahraman", ""], ["Just", "Mike", ""], ["Lones", "Michael A.", ""]]}, {"id": "2102.08871", "submitter": "Ivona Tautkute", "authors": "Ivona Tautkute and Tomasz Trzcinski", "title": "I Want This Product but Different : Multimodal Retrieval with Synthetic\n  Query Expansion", "comments": "Major edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of media retrieval using a multimodal query\n(a query which combines visual input with additional semantic information in\nnatural language feedback). We propose a SynthTriplet GAN framework which\nresolves this task by expanding the multimodal query with a synthetically\ngenerated image that captures semantic information from both image and text\ninput. We introduce a novel triplet mining method that uses a synthetic image\nas an anchor to directly optimize for embedding distances of generated and\ntarget images. We demonstrate that apart from the added value of retrieval\nillustration with synthetic image with the focus on customization and user\nfeedback, the proposed method greatly surpasses other multimodal generation\nmethods and achieves state of the art results in the multimodal retrieval task.\nWe also show that in contrast to other retrieval methods, our method provides\nexplainable embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:02:13 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 14:35:23 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tautkute", "Ivona", ""], ["Trzcinski", "Tomasz", ""]]}, {"id": "2102.08898", "submitter": "Adam Fisch", "authors": "Adam Fisch, Tal Schuster, Tommi Jaakkola, Regina Barzilay", "title": "Few-shot Conformal Prediction with Auxiliary Tasks", "comments": "ICML camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel approach to conformal prediction when the target task has\nlimited data available for training. Conformal prediction identifies a small\nset of promising output candidates in place of a single prediction, with\nguarantees that the set contains the correct answer with high probability. When\ntraining data is limited, however, the predicted set can easily become unusably\nlarge. In this work, we obtain substantially tighter prediction sets while\nmaintaining desirable marginal guarantees by casting conformal prediction as a\nmeta-learning paradigm over exchangeable collections of auxiliary tasks. Our\nconformalization algorithm is simple, fast, and agnostic to the choice of\nunderlying model, learning algorithm, or dataset. We demonstrate the\neffectiveness of this approach across a number of few-shot classification and\nregression tasks in natural language processing, computer vision, and\ncomputational chemistry for drug discovery.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:46:57 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 04:07:40 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Fisch", "Adam", ""], ["Schuster", "Tal", ""], ["Jaakkola", "Tommi", ""], ["Barzilay", "Regina", ""]]}, {"id": "2102.08933", "submitter": "David Jilk", "authors": "David J. Jilk", "title": "An Objective Laboratory Protocol for Evaluating Cognition of Non-Human\n  Systems Against Human Cognition", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I describe and reduce to practice an objective protocol for\nevaluating the cognitive capabilities of a non-human system against human\ncognition in a laboratory environment. This is important because the existence\nof a non-human system with cognitive capabilities comparable to those of humans\nmight make once-philosophical questions of safety and ethics immediate and\nurgent. Past attempts to devise evaluation methods, such as the Turing Test and\nmany others, have not met this need; most of them either emphasize a single\naspect of human cognition or a single theory of intelligence, fail to capture\nthe human capacity for generality and novelty, or require success in the\nphysical world. The protocol is broadly Bayesian, in that its primary output is\na confidence statistic in relation to a claim. Further, it provides insight\ninto the areas where and to what extent a particular system falls short of\nhuman cognition, which can help to drive further progress or precautions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:40:49 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Jilk", "David J.", ""]]}, {"id": "2102.08934", "submitter": "No\\'e Casas", "authors": "Noe Casas, Jose A. R. Fonollosa, Marta R. Costa-juss\\`a", "title": "Sparsely Factored Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to incorporate linguistic information to neural machine\ntranslation systems consists in maintaining separate vocabularies for each of\nthe annotated features to be incorporated (e.g. POS tags, dependency relation\nlabel), embed them, and then aggregate them with each subword in the word they\nbelong to. This approach, however, cannot easily accommodate annotation schemes\nthat are not dense for every word.\n  We propose a method suited for such a case, showing large improvements in\nout-of-domain data, and comparable quality for the in-domain data. Experiments\nare performed in morphologically-rich languages like Basque and German, for the\ncase of low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:42:00 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Casas", "Noe", ""], ["Fonollosa", "Jose A. R.", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2102.08945", "submitter": "Zan Gojcic", "authors": "Zan Gojcic, Or Litany, Andreas Wieser, Leonidas J. Guibas, Tolga\n  Birdal", "title": "Weakly Supervised Learning of Rigid 3D Scene Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven scene flow estimation algorithm exploiting the\nobservation that many 3D scenes can be explained by a collection of agents\nmoving as rigid bodies. At the core of our method lies a deep architecture able\nto reason at the \\textbf{object-level} by considering 3D scene flow in\nconjunction with other 3D tasks. This object level abstraction, enables us to\nrelax the requirement for dense scene flow supervision with simpler binary\nbackground segmentation mask and ego-motion annotations. Our mild supervision\nrequirements make our method well suited for recently released massive data\ncollections for autonomous driving, which do not contain dense scene flow\nannotations. As output, our model provides low-level cues like pointwise flow\nand higher-level cues such as holistic scene understanding at the level of\nrigid objects. We further propose a test-time optimization refining the\npredicted rigid scene flow. We showcase the effectiveness and generalization\ncapacity of our method on four different autonomous driving datasets. We\nrelease our source code and pre-trained models under\n\\url{github.com/zgojcic/Rigid3DSceneFlow}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:58:02 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Gojcic", "Zan", ""], ["Litany", "Or", ""], ["Wieser", "Andreas", ""], ["Guibas", "Leonidas J.", ""], ["Birdal", "Tolga", ""]]}, {"id": "2102.08946", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Zechun Liu and Jie Qin and Lei Huang and Kwang-Ting\n  Cheng and Marios Savvides", "title": "S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural\n  Networks via Guided Distribution Calibration", "comments": "CVPR 2021 camera-ready version. Self-supervised binary neural\n  networks using distillation loss (5.5~15% improvement over contrastive\n  baseline). Code is available at https://github.com/szq0214/S2-BNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies dominantly target at self-supervised learning on real-valued\nnetworks and have achieved many promising results. However, on the more\nchallenging binary neural networks (BNNs), this task has not yet been fully\nexplored in the community. In this paper, we focus on this more difficult\nscenario: learning networks where both weights and activations are binary,\nmeanwhile, without any human annotated labels. We observe that the commonly\nused contrastive objective is not satisfying on BNNs for competitive accuracy,\nsince the backbone network contains relatively limited capacity and\nrepresentation ability. Hence instead of directly applying existing\nself-supervised methods, which cause a severe decline in performance, we\npresent a novel guided learning paradigm from real-valued to distill binary\nnetworks on the final prediction distribution, to minimize the loss and obtain\ndesirable accuracy. Our proposed method can boost the simple contrastive\nlearning baseline by an absolute gain of 5.5~15% on BNNs. We further reveal\nthat it is difficult for BNNs to recover the similar predictive distributions\nas real-valued models when training without labels. Thus, how to calibrate them\nis key to address the degradation in performance. Extensive experiments are\nconducted on the large-scale ImageNet and downstream datasets. Our method\nachieves substantial improvement over the simple contrastive learning baseline,\nand is even comparable to many mainstream supervised BNN methods. Code is\navailable at https://github.com/szq0214/S2-BNN.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:59:28 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:10:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Liu", "Zechun", ""], ["Qin", "Jie", ""], ["Huang", "Lei", ""], ["Cheng", "Kwang-Ting", ""], ["Savvides", "Marios", ""]]}, {"id": "2102.08990", "submitter": "Xing Li", "authors": "Xing Li, Haichun Yang, Jiaxin He, Aadarsh Jha, Agnes B. Fogo, Lee E.\n  Wheless, Shilin Zhao, Yuankai Huo", "title": "BEDS: Bagging ensemble deep segmentation for nucleus segmentation with\n  testing stage stain augmentation", "comments": "4 pages, 5 figures, ISBI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing outcome variance is an essential task in deep learning based medical\nimage analysis. Bootstrap aggregating, also known as bagging, is a canonical\nensemble algorithm for aggregating weak learners to become a strong learner.\nRandom forest is one of the most powerful machine learning algorithms before\ndeep learning era, whose superior performance is driven by fitting bagged\ndecision trees (weak learners). Inspired by the random forest technique, we\npropose a simple bagging ensemble deep segmentation (BEDs) method to train\nmultiple U-Nets with partial training data to segment dense nuclei on\npathological images. The contributions of this study are three-fold: (1)\ndeveloping a self-ensemble learning framework for nucleus segmentation; (2)\naggregating testing stage augmentation with self-ensemble learning; and (3)\nelucidating the idea that self-ensemble and testing stage stain augmentation\nare complementary strategies for a superior segmentation performance.\nImplementation Detail: https://github.com/xingli1102/BEDs.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:34:41 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Xing", ""], ["Yang", "Haichun", ""], ["He", "Jiaxin", ""], ["Jha", "Aadarsh", ""], ["Fogo", "Agnes B.", ""], ["Wheless", "Lee E.", ""], ["Zhao", "Shilin", ""], ["Huo", "Yuankai", ""]]}, {"id": "2102.09001", "submitter": "Soeren Becker", "authors": "Soeren Becker, Florian Schmidt, Anton Gulenko, Alexander Acker, Odej\n  Kao", "title": "Towards AIOps in Edge Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge computing was introduced as a technical enabler for the demanding\nrequirements of new network technologies like 5G. It aims to overcome\nchallenges related to centralized cloud computing environments by distributing\ncomputational resources to the edge of the network towards the customers. The\ncomplexity of the emerging infrastructures increases significantly, together\nwith the ramifications of outages on critical use cases such as self-driving\ncars or health care. Artificial Intelligence for IT Operations (AIOps) aims to\nsupport human operators in managing complex infrastructures by using machine\nlearning methods. This paper describes the system design of an AIOps platform\nwhich is applicable in heterogeneous, distributed environments. The overhead of\na high-frequency monitoring solution on edge devices is evaluated and\nperformance experiments regarding the applicability of three anomaly detection\nalgorithms on edge devices are conducted. The results show, that it is feasible\nto collect metrics with a high frequency and simultaneously run specific\nanomaly detection algorithms directly on edge devices with a reasonable\noverhead on the resource utilization.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 09:33:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Becker", "Soeren", ""], ["Schmidt", "Florian", ""], ["Gulenko", "Anton", ""], ["Acker", "Alexander", ""], ["Kao", "Odej", ""]]}, {"id": "2102.09003", "submitter": "Vinod Kumar Kurmi", "authors": "Vinod K Kurmi and Venkatesh K Subramanian and Vinay P Namboodiri", "title": "Domain Impression: A Source Data Free Domain Adaptation Method", "comments": "Published- WACV-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised Domain adaptation methods solve the adaptation problem for an\nunlabeled target set, assuming that the source dataset is available with all\nlabels. However, the availability of actual source samples is not always\npossible in practical cases. It could be due to memory constraints, privacy\nconcerns, and challenges in sharing data. This practical scenario creates a\nbottleneck in the domain adaptation problem. This paper addresses this\nchallenging scenario by proposing a domain adaptation technique that does not\nneed any source data. Instead of the source data, we are only provided with a\nclassifier that is trained on the source data. Our proposed approach is based\non a generative framework, where the trained classifier is used for generating\nsamples from the source classes. We learn the joint distribution of data by\nusing the energy-based modeling of the trained classifier. At the same time, a\nnew classifier is also adapted for the target domain. We perform various\nablation analysis under different experimental setups and demonstrate that the\nproposed approach achieves better results than the baseline models in this\nextremely novel scenario.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:50:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kurmi", "Vinod K", ""], ["Subramanian", "Venkatesh K", ""], ["Namboodiri", "Vinay P", ""]]}, {"id": "2102.09005", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Monika Schubert and Christoph Zehentner", "title": "An Efficient Diagnosis Algorithm for Inconsistent Constraint Sets", "comments": "Preprint of: A. Felfernig, M. Schubert, and C. Zehentner. An\n  Efficient Diagnosis Algorithm for Inconsistent Constraint Sets. Artificial\n  Intelligence for Engineering Design, Analysis, and Manufacturing (AIEDAM),\n  Cambridge University Press, vol. 26, no.1, pp. 53-62, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint sets can become inconsistent in different contexts. For example,\nduring a configuration session the set of customer requirements can become\ninconsistent with the configuration knowledge base. Another example is the\nengineering phase of a configuration knowledge base where the underlying\nconstraints can become inconsistent with a set of test cases. In such\nsituations we are in the need of techniques that support the identification of\nminimal sets of faulty constraints that have to be deleted in order to restore\nconsistency. In this paper we introduce a divide-and-conquer based diagnosis\nalgorithm (FastDiag) which identifies minimal sets of faulty constraints in an\nover-constrained problem. This algorithm is specifically applicable in\nscenarios where the efficient identification of leading (preferred) diagnoses\nis crucial. We compare the performance of FastDiag with the conflict-directed\ncalculation of hitting sets and present an in-depth performance analysis that\nshows the advantages of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 19:55:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Felfernig", "Alexander", ""], ["Schubert", "Monika", ""], ["Zehentner", "Christoph", ""]]}, {"id": "2102.09024", "submitter": "Mohita Chaudhary", "authors": "Mohita Chaudhary, Mohamed Sadok Gastli, Lobna Nassar, Fakhri Karray", "title": "Deep Learning Approaches for Forecasting Strawberry Yields and Prices\n  Using Satellite Images and Station-Based Soil Parameters", "comments": "Paper Accepted in Association for the Advancement of Artificial\n  Intelligence (AAAI) Spring Symposium on 21st Jan, 2021", "journal-ref": "AAAI 2021 Spring Symposium on Combining Machine Learning and\n  Knowledge Engineering (AAAI-MAKE 2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational tools for forecasting yields and prices for fresh produce have\nbeen based on traditional machine learning approaches or time series modelling.\nWe propose here an alternate approach based on deep learning algorithms for\nforecasting strawberry yields and prices in Santa Barbara county, California.\nBuilding the proposed forecasting model comprises three stages: first, the\nstation-based ensemble model (ATT-CNN-LSTM-SeriesNet_Ens) with its compound\ndeep learning components, SeriesNet with Gated Recurrent Unit (GRU) and\nConvolutional Neural Network LSTM with Attention layer (Att-CNN-LSTM), are\ntrained and tested using the station-based soil temperature and moisture data\nof SantaBarbara as input and the corresponding strawberry yields or prices as\noutput. Secondly, the remote sensing ensemble model (SIM_CNN-LSTM_Ens), which\nis an ensemble model of Convolutional NeuralNetwork LSTM (CNN-LSTM) models, is\ntrained and tested using satellite images of the same county as input mapped to\nthe same yields and prices as output. These two ensembles forecast strawberry\nyields and prices with minimal forecasting errors and highest model correlation\nfor five weeks ahead forecasts.Finally, the forecasts of these two models are\nensembled to have a final forecasted value for yields and prices by introducing\na voting ensemble. Based on an aggregated performance measure (AGM), it is\nfound that this voting ensemble not only enhances the forecasting performance\nby 5% compared to its best performing component model but also outperforms the\nDeep Learning (DL) ensemble model found in literature by 33% for forecasting\nyields and 21% for forecasting prices\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 20:54:34 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Chaudhary", "Mohita", ""], ["Gastli", "Mohamed Sadok", ""], ["Nassar", "Lobna", ""], ["Karray", "Fakhri", ""]]}, {"id": "2102.09039", "submitter": "Yang Li", "authors": "Mingyuan Zhong, Gang Li, Yang Li", "title": "Spacewalker: Rapid UI Design Exploration Using Lightweight Markup\n  Enhancement and Crowd Genetic Programming", "comments": "10 pages, CHI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interface design is a complex task that involves designers examining a\nwide range of options. We present Spacewalker, a tool that allows designers to\nrapidly search a large design space for an optimal web UI with integrated\nsupport. Designers first annotate each attribute they want to explore in a\ntypical HTML page, using a simple markup extension we designed. Spacewalker\nthen parses the annotated HTML specification, and intelligently generates and\ndistributes various configurations of the web UI to crowd workers for\nevaluation. We enhanced a genetic algorithm to accommodate crowd worker\nresponses from pairwise comparison of UI designs, which is crucial for\nobtaining reliable feedback. Based on our experiments, Spacewalker allows\ndesigners to effectively search a large design space of a UI, using the\nlanguage they are familiar with, and improve their design rapidly at a minimal\ncost.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 21:54:49 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Zhong", "Mingyuan", ""], ["Li", "Gang", ""], ["Li", "Yang", ""]]}, {"id": "2102.09076", "submitter": "Niels Leadholm", "authors": "Niels Leadholm (1 and 2), Marcus Lewis (1), Subutai Ahmad (1) ((1)\n  Numenta, (2) The University of Oxford)", "title": "Grid Cell Path Integration For Movement-Based Visual Object Recognition", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grid cells enable the brain to model the physical space of the world and\nnavigate effectively via path integration, updating self-position using\ninformation from self-movement. Recent proposals suggest that the brain might\nuse similar mechanisms to understand the structure of objects in diverse\nsensory modalities, including vision. In machine vision, object recognition\ngiven a sequence of sensory samples of an image, such as saccades, is a\nchallenging problem when the sequence does not follow a consistent, fixed\npattern - yet this is something humans do naturally and effortlessly. We\nexplore how grid cell-based path integration in a cortical network can support\nreliable recognition of objects given an arbitrary sequence of inputs. Our\nnetwork (GridCellNet) uses grid cell computations to integrate visual\ninformation and make predictions based on movements. We use local Hebbian\nplasticity rules to learn rapidly from a handful of examples (few-shot\nlearning), and consider the task of recognizing MNIST digits given only a\nsequence of image feature patches. We compare GridCellNet to k-Nearest\nNeighbour (k-NN) classifiers as well as recurrent neural networks (RNNs), both\nof which lack explicit mechanisms for handling arbitrary sequences of input\nsamples. We show that GridCellNet can reliably perform classification,\ngeneralizing to both unseen examples and completely novel sequence\ntrajectories. We further show that inference is often successful after sampling\na fraction of the input space, enabling the predictive GridCellNet to\nreconstruct the rest of the image given just a few movements. We propose that\ndynamically moving agents with active sensors can use grid cell representations\nnot only for navigation, but also for efficient recognition and feature\nprediction of seen objects.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 23:52:57 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Leadholm", "Niels", "", "1 and 2"], ["Lewis", "Marcus", ""], ["Ahmad", "Subutai", ""]]}, {"id": "2102.09109", "submitter": "Eva Cetinic", "authors": "Eva Cetinic and James She", "title": "Understanding and Creating Art with AI: Review and Outlook", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technologies related to artificial intelligence (AI) have a strong impact on\nthe changes of research and creative practices in visual arts. The growing\nnumber of research initiatives and creative applications that emerge in the\nintersection of AI and art, motivates us to examine and discuss the creative\nand explorative potentials of AI technologies in the context of art. This paper\nprovides an integrated review of two facets of AI and art: 1) AI is used for\nart analysis and employed on digitized artwork collections; 2) AI is used for\ncreative purposes and generating novel artworks. In the context of AI-related\nresearch for art understanding, we present a comprehensive overview of artwork\ndatasets and recent works that address a variety of tasks such as\nclassification, object detection, similarity retrieval, multimodal\nrepresentations, computational aesthetics, etc. In relation to the role of AI\nin creating art, we address various practical and theoretical aspects of AI Art\nand consolidate related works that deal with those topics in detail. Finally,\nwe provide a concise outlook on the future progression and potential impact of\nAI technologies on our understanding and creation of art.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:38:11 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Cetinic", "Eva", ""], ["She", "James", ""]]}, {"id": "2102.09117", "submitter": "Jiachen Li", "authors": "Jiachen Li and Hengbo Ma and Zhihao Zhang and Jinning Li and Masayoshi\n  Tomizuka", "title": "Spatio-Temporal Graph Dual-Attention Network for Multi-Agent Prediction\n  and Tracking", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective understanding of the environment and accurate trajectory\nprediction of surrounding dynamic obstacles are indispensable for intelligent\nmobile systems (e.g. autonomous vehicles and social robots) to achieve safe and\nhigh-quality planning when they navigate in highly interactive and crowded\nscenarios. Due to the existence of frequent interactions and uncertainty in the\nscene evolution, it is desired for the prediction system to enable relational\nreasoning on different entities and provide a distribution of future\ntrajectories for each agent. In this paper, we propose a generic generative\nneural system (called STG-DAT) for multi-agent trajectory prediction involving\nheterogeneous agents. The system takes a step forward to explicit interaction\nmodeling by incorporating relational inductive biases with a dynamic graph\nrepresentation and leverages both trajectory and scene context information. We\nalso employ an efficient kinematic constraint layer applied to vehicle\ntrajectory prediction. The constraint not only ensures physical feasibility but\nalso enhances model performance. Moreover, the proposed prediction model can be\neasily adopted by multi-target tracking frameworks. The tracking accuracy\nproves to be improved by empirical results. The proposed system is evaluated on\nthree public benchmark datasets for trajectory prediction, where the agents\ncover pedestrians, cyclists and on-road vehicles. The experimental results\ndemonstrate that our model achieves better performance than various baseline\napproaches in terms of prediction and tracking accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 02:25:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhang", "Zhihao", ""], ["Li", "Jinning", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2102.09119", "submitter": "Yidan Qin", "authors": "Yidan Qin, Max Allan, Yisong Yue, Joel W. Burdick, Mahdi Azizian", "title": "Learning Invariant Representation of Tasks for Robust Surgical State\n  Estimation", "comments": "Accepted to IEEE Robotics & Automation Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Surgical state estimators in robot-assisted surgery (RAS) - especially those\ntrained via learning techniques - rely heavily on datasets that capture surgeon\nactions in laboratory or real-world surgical tasks. Real-world RAS datasets are\ncostly to acquire, are obtained from multiple surgeons who may use different\nsurgical strategies, and are recorded under uncontrolled conditions in highly\ncomplex environments. The combination of high diversity and limited data calls\nfor new learning methods that are robust and invariant to operating conditions\nand surgical techniques. We propose StiseNet, a Surgical Task Invariance State\nEstimation Network with an invariance induction framework that minimizes the\neffects of variations in surgical technique and operating environments inherent\nto RAS datasets. StiseNet's adversarial architecture learns to separate\nnuisance factors from information needed for surgical state estimation.\nStiseNet is shown to outperform state-of-the-art state estimation methods on\nthree datasets (including a new real-world RAS dataset: HERNIA-20).\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 02:32:50 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Qin", "Yidan", ""], ["Allan", "Max", ""], ["Yue", "Yisong", ""], ["Burdick", "Joel W.", ""], ["Azizian", "Mahdi", ""]]}, {"id": "2102.09127", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Matei Zaharia and James Zou", "title": "FrugalMCT: Efficient Online ML API Selection for Multi-Label\n  Classification Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification tasks such as OCR and multi-object recognition are\na major focus of the growing machine learning as a service industry. While many\nmulti-label prediction APIs are available, it is challenging for users to\ndecide which API to use for their own data and budget, due to the heterogeneity\nin those APIs' price and performance. Recent work shows how to select from\nsingle-label prediction APIs. However the computation complexity of the\nprevious approach is exponential in the number of labels and hence is not\nsuitable for settings like OCR. In this work, we propose FrugalMCT, a\nprincipled framework that adaptively selects the APIs to use for different data\nin an online fashion while respecting user's budget. The API selection problem\nis cast as an integer linear program, which we show has a special structure\nthat we leverage to develop an efficient online API selector with strong\nperformance guarantees. We conduct systematic experiments using ML APIs from\nGoogle, Microsoft, Amazon, IBM, Tencent and other providers for tasks including\nmulti-label image classification, scene text recognition and named entity\nrecognition. Across diverse tasks, FrugalMCT can achieve over 90% cost\nreduction while matching the accuracy of the best single API, or up to 8%\nbetter accuracy while matching the best API's cost.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 02:59:58 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Chen", "Lingjiao", ""], ["Zaharia", "Matei", ""], ["Zou", "James", ""]]}, {"id": "2102.09130", "submitter": "Feng Nan", "authors": "Feng Nan, Ramesh Nallapati, Zhiguo Wang, Cicero Nogueira dos Santos,\n  Henghui Zhu, Dejiao Zhang, Kathleen McKeown, Bing Xiang", "title": "Entity-level Factual Consistency of Abstractive Text Summarization", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A key challenge for abstractive summarization is ensuring factual consistency\nof the generated summary with respect to the original document. For example,\nstate-of-the-art models trained on existing datasets exhibit entity\nhallucination, generating names of entities that are not present in the source\ndocument. We propose a set of new metrics to quantify the entity-level factual\nconsistency of generated summaries and we show that the entity hallucination\nproblem can be alleviated by simply filtering the training data. In addition,\nwe propose a summary-worthy entity classification task to the training process\nas well as a joint entity and summary generation approach, which yield further\nimprovements in entity level metrics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 03:07:28 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Nan", "Feng", ""], ["Nallapati", "Ramesh", ""], ["Wang", "Zhiguo", ""], ["Santos", "Cicero Nogueira dos", ""], ["Zhu", "Henghui", ""], ["Zhang", "Dejiao", ""], ["McKeown", "Kathleen", ""], ["Xiang", "Bing", ""]]}, {"id": "2102.09136", "submitter": "Amir Tahmasebi", "authors": "Cansu Sen, Bingyang Ye, Javed Aslam, Amir Tahmasebi", "title": "From Extreme Multi-label to Multi-class: A Hierarchical Approach for\n  Automated ICD-10 Coding Using Phrase-level Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clinical coding is the task of assigning a set of alphanumeric codes,\nreferred to as ICD (International Classification of Diseases), to a medical\nevent based on the context captured in a clinical narrative. The latest version\nof ICD, ICD-10, includes more than 70,000 codes. As this is a labor-intensive\nand error-prone task, automatic ICD coding of medical reports using machine\nlearning has gained significant interest in the last decade. Existing\nliterature has modeled this problem as a multi-label task. Nevertheless, such\nmulti-label approach is challenging due to the extremely large label set size.\nFurthermore, the interpretability of the predictions is essential for the\nendusers (e.g., healthcare providers and insurance companies). In this paper,\nwe propose a novel approach for automatic ICD coding by reformulating the\nextreme multi-label problem into a simpler multi-class problem using a\nhierarchical solution. We made this approach viable through extensive data\ncollection to acquire phrase-level human coder annotations to supervise our\nmodels on learning the specific relations between the input text and predicted\nICD codes. Our approach employs two independently trained networks, the\nsentence tagger and the ICD classifier, stacked hierarchically to predict a\ncodeset for a medical report. The sentence tagger identifies focus sentences\ncontaining a medical event or concept relevant to an ICD coding. Using a\nsupervised attention mechanism, the ICD classifier then assigns each focus\nsentence with an ICD code. The proposed approach outperforms strong baselines\nby large margins of 23% in subset accuracy, 18% in micro-F1, and 15% in\ninstance based F-1. With our proposed approach, interpretability is achieved\nnot through implicitly learned attention scores but by attributing each\nprediction to a particular sentence and words selected by human coders.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 03:19:14 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Sen", "Cansu", ""], ["Ye", "Bingyang", ""], ["Aslam", "Javed", ""], ["Tahmasebi", "Amir", ""]]}, {"id": "2102.09139", "submitter": "Bingyan Han", "authors": "Bingyan Han", "title": "Understanding algorithmic collusion with experience replay", "comments": "References updated. Comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI cs.GT q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In an infinitely repeated pricing game, pricing algorithms based on\nartificial intelligence (Q-learning) may consistently learn to charge\nsupra-competitive prices even without communication. Although concerns on\nalgorithmic collusion have arisen, little is known on underlying factors. In\nthis work, we experimentally analyze the dynamics of algorithms with three\nvariants of experience replay. Algorithmic collusion still has roots in human\npreferences. Randomizing experience yields prices close to the static Bertrand\nequilibrium and higher prices are easily restored by favoring the latest\nexperience. Moreover, relative performance concerns also stabilize the\ncollusion. Finally, we investigate the scenarios with heterogeneous agents and\ntest robustness on various factors.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 03:28:41 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 13:57:36 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Han", "Bingyan", ""]]}, {"id": "2102.09180", "submitter": "Benjamin Patrick Evans", "authors": "Benjamin Patrick Evans, Mikhail Prokopenko", "title": "A maximum entropy model of bounded rational decision-making with prior\n  beliefs and market feedback", "comments": "39 pages, 15 figures", "journal-ref": null, "doi": "10.3390/e23060669", "report-no": null, "categories": "cs.IT cs.AI econ.TH math.IT physics.soc-ph q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded rationality is an important consideration stemming from the fact that\nagents often have limits on their processing abilities, making the assumption\nof perfect rationality inapplicable to many real tasks. We propose an\ninformation-theoretic approach to the inference of agent decisions under\nSmithian competition. The model explicitly captures the boundedness of agents\n(limited in their information-processing capacity) as the cost of information\nacquisition for expanding their prior beliefs. The expansion is measured as the\nKullblack-Leibler divergence between posterior decisions and prior beliefs.\nWhen information acquisition is free, the homo economicus agent is recovered,\nwhile in cases when information acquisition becomes costly, agents instead\nrevert to their prior beliefs. The maximum entropy principle is used to infer\nleast-biased decisions based upon the notion of Smithian competition formalised\nwithin the Quantal Response Statistical Equilibrium framework. The\nincorporation of prior beliefs into such a framework allowed us to\nsystematically explore the effects of prior beliefs on decision-making in the\npresence of market feedback, as well as importantly adding a temporal\ninterpretation to the framework. We verified the proposed model using\nAustralian housing market data, showing how the incorporation of prior\nknowledge alters the resulting agent decisions. Specifically, it allowed for\nthe separation of past beliefs and utility maximisation behaviour of the agent\nas well as the analysis into the evolution of agent beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:41:59 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 02:41:14 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 09:16:38 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "2102.09193", "submitter": "Ilan Coulon", "authors": "F\\'elix Chalumeau (1), Ilan Coulon (1), Quentin Cappart (2),\n  Louis-Martin Rousseau (2) ((1) \\'Ecole Polytechnique, Institut Polytechnique\n  de Paris, (2) \\'Ecole Polytechnique de Montr\\'eal)", "title": "SeaPearl: A Constraint Programming Solver guided by Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of efficient and generic algorithms for solving combinatorial\noptimization problems has been an active field of research for many years.\nStandard exact solving approaches are based on a clever and complete\nenumeration of the solution set. A critical and non-trivial design choice with\nsuch methods is the branching strategy, directing how the search is performed.\nThe last decade has shown an increasing interest in the design of machine\nlearning-based heuristics to solve combinatorial optimization problems. The\ngoal is to leverage knowledge from historical data to solve similar new\ninstances of a problem. Used alone, such heuristics are only able to provide\napproximate solutions efficiently, but cannot prove optimality nor bounds on\ntheir solution. Recent works have shown that reinforcement learning can be\nsuccessfully used for driving the search phase of constraint programming (CP)\nsolvers. However, it has also been shown that this hybridization is challenging\nto build, as standard CP frameworks do not natively include machine learning\nmechanisms, leading to some sources of inefficiencies. This paper presents the\nproof of concept for SeaPearl, a new CP solver implemented in Julia, that\nsupports machine learning routines in order to learn branching decisions using\nreinforcement learning. Support for modeling the learning component is also\nprovided. We illustrate the modeling and solution performance of this new\nsolver on two problems. Although not yet competitive with industrial solvers,\nSeaPearl aims to provide a flexible and open-source framework in order to\nfacilitate future research in the hybridization of constraint programming and\nmachine learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:34:38 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 15:57:02 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Chalumeau", "F\u00e9lix", ""], ["Coulon", "Ilan", ""], ["Cappart", "Quentin", ""], ["Rousseau", "Louis-Martin", ""]]}, {"id": "2102.09200", "submitter": "Harideep Nair", "authors": "Shreyas Chaudhari, Harideep Nair, Jos\\'e M.F. Moura and John Paul Shen", "title": "Unsupervised Clustering of Time Series Signals using Neuromorphic\n  Energy-Efficient Temporal Neural Networks", "comments": "Accepted for publication at ICASSP 2021", "journal-ref": null, "doi": "10.1109/ICASSP39728.2021.9414882", "report-no": null, "categories": "cs.LG cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised time series clustering is a challenging problem with diverse\nindustrial applications such as anomaly detection, bio-wearables, etc. These\napplications typically involve small, low-power devices on the edge that\ncollect and process real-time sensory signals. State-of-the-art time-series\nclustering methods perform some form of loss minimization that is extremely\ncomputationally intensive from the perspective of edge devices. In this work,\nwe propose a neuromorphic approach to unsupervised time series clustering based\non Temporal Neural Networks that is capable of ultra low-power, continuous\nonline learning. We demonstrate its clustering performance on a subset of UCR\nTime Series Archive datasets. Our results show that the proposed approach\neither outperforms or performs similarly to most of the existing algorithms\nwhile being far more amenable for efficient hardware implementation. Our\nhardware assessment analysis shows that in 7 nm CMOS the proposed architecture,\non average, consumes only about 0.005 mm^2 die area and 22 uW power and can\nprocess each signal with about 5 ns latency.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:47:43 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chaudhari", "Shreyas", ""], ["Nair", "Harideep", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Shen", "John Paul", ""]]}, {"id": "2102.09208", "submitter": "Siqing Hou", "authors": "Siqing Hou, Dongqi Han, Jun Tani", "title": "Learning Memory-Dependent Continuous Control from Demonstrations", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient exploration has presented a long-standing challenge in\nreinforcement learning, especially when rewards are sparse. A developmental\nsystem can overcome this difficulty by learning from both demonstrations and\nself-exploration. However, existing methods are not applicable to most\nreal-world robotic controlling problems because they assume that environments\nfollow Markov decision processes (MDP); thus, they do not extend to partially\nobservable environments where historical observations are necessary for\ndecision making. This paper builds on the idea of replaying demonstrations for\nmemory-dependent continuous control, by proposing a novel algorithm, Recurrent\nActor-Critic with Demonstration and Experience Replay (READER). Experiments\ninvolving several memory-crucial continuous control tasks reveal significantly\nreduce interactions with the environment using our method with a reasonably\nsmall number of demonstration samples. The algorithm also shows better sample\nefficiency and learning capabilities than a baseline reinforcement learning\nalgorithm for memory-based control from demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 08:13:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hou", "Siqing", ""], ["Han", "Dongqi", ""], ["Tani", "Jun", ""]]}, {"id": "2102.09230", "submitter": "Ginevra Carbone", "authors": "Ginevra Carbone, Guido Sanguinetti, Luca Bortolussi", "title": "Random Projections for Improved Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose two training techniques for improving the robustness of Neural\nNetworks to adversarial attacks, i.e. manipulations of the inputs that are\nmaliciously crafted to fool networks into incorrect predictions. Both methods\nare independent of the chosen attack and leverage random projections of the\noriginal inputs, with the purpose of exploiting both dimensionality reduction\nand some characteristic geometrical properties of adversarial perturbations.\nThe first technique is called RP-Ensemble and consists of an ensemble of\nnetworks trained on multiple projected versions of the original inputs. The\nsecond one, named RP-Regularizer, adds instead a regularization term to the\ntraining objective.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 09:13:14 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 07:30:13 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Carbone", "Ginevra", ""], ["Sanguinetti", "Guido", ""], ["Bortolussi", "Luca", ""]]}, {"id": "2102.09260", "submitter": "Milan Straka", "authors": "Milan Straka, Lucia Piatrikov\\'a, Peter van Bokhoven, \\v{L}ubo\\v{s}\n  Buzna", "title": "A matrix approach to detect temporal behavioral patterns at electric\n  vehicle charging stations", "comments": "8 pages, 5 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the electric vehicle (EV) arrival times and the duration of EV\nconnection to the charging station, we identify charging patterns and derive\ngroups of charging stations with similar charging patterns applying two\napproaches. The ruled based approach derives the charging patterns by\nspecifying a set of time intervals and a threshold value. In the second\napproach, we combine the modified l-p norm (as a matrix dissimilarity measure)\nwith hierarchical clustering and apply them to automatically identify charging\npatterns and groups of charging stations associated with such patterns. A\ndataset collected in a large network of public charging stations is used to\ntest both approaches. Using both methods, we derived charging patterns. The\nfirst, rule-based approach, performed well at deriving predefined patterns and\nthe latter, hierarchical clustering, showed the capability of delivering\nunexpected charging patterns.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 10:37:32 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Straka", "Milan", ""], ["Piatrikov\u00e1", "Lucia", ""], ["van Bokhoven", "Peter", ""], ["Buzna", "\u013dubo\u0161", ""]]}, {"id": "2102.09268", "submitter": "Shitao Xiao", "authors": "Shitao Xiao, Zheng Liu, Yingxia Shao, Tao Di and Xing Xie", "title": "Training Large-Scale News Recommenders with Pretrained Language Models\n  in the Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News recommendation calls for deep insights of news articles' underlying\nsemantics. Therefore, pretrained language models (PLMs), like BERT and RoBERTa,\nmay substantially contribute to the recommendation quality. However, it's\nextremely challenging to have news recommenders trained together with such big\nmodels: the learning of news recommenders requires intensive news encoding\noperations, whose cost is prohibitive if PLMs are used as the news encoder. In\nthis paper, we propose a novel framework, {SpeedyFeed}, which efficiently\ntrains PLMs-based news recommenders of superior quality. SpeedyFeed is\nhighlighted for its light-weighted encoding pipeline, which gives rise to three\nmajor advantages. Firstly, it makes the intermedia results fully reusable for\nthe training workflow, which removes most of the repetitive but redundant\nencoding operations. Secondly, it improves the data efficiency of the training\nworkflow, where non-informative data can be eliminated from encoding. Thirdly,\nit further saves the cost by leveraging simplified news encoding and compact\nnews representation. Extensive experiments show that SpeedyFeed leads to more\nthan 100$\\times$ acceleration of the training process, which enables big models\nto be trained efficiently and effectively over massive user data. The\nwell-trained PLMs-based model from SpeedyFeed demonstrates highly competitive\nperformance, where it outperforms the state-of-the-art news recommenders with\nsignificant margins. SpeedyFeed is also a model-agnostic framework, which is\npotentially applicable to a wide spectrum of content-based recommender systems;\ntherefore, the whole framework is open-sourced to facilitate the progress in\nrelated areas.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 11:08:38 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 02:15:26 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Xiao", "Shitao", ""], ["Liu", "Zheng", ""], ["Shao", "Yingxia", ""], ["Di", "Tao", ""], ["Xie", "Xing", ""]]}, {"id": "2102.09284", "submitter": "Ross Drummond", "authors": "Ross Drummond, Mathew C. Turner and Stephen R. Duncan", "title": "Reduced-Order Neural Network Synthesis with Robustness Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the wake of the explosive growth in smartphones and cyberphysical systems,\nthere has been an accelerating shift in how data is generated away from\ncentralised data towards on-device generated data. In response, machine\nlearning algorithms are being adapted to run locally on board, potentially\nhardware limited, devices to improve user privacy, reduce latency and be more\nenergy efficient. However, our understanding of how these device orientated\nalgorithms behave and should be trained is still fairly limited. To address\nthis issue, a method to automatically synthesize reduced-order neural networks\n(having fewer neurons) approximating the input/output mapping of a larger one\nis introduced. The reduced-order neural network's weights and biases are\ngenerated from a convex semi-definite programme that minimises the worst-case\napproximation error with respect to the larger network. Worst-case bounds for\nthis approximation error are obtained and the approach can be applied to a wide\nvariety of neural networks architectures. What differentiates the proposed\napproach to existing methods for generating small neural networks, e.g.\npruning, is the inclusion of the worst-case approximation error directly within\nthe training cost function, which should add robustness. Numerical examples\nhighlight the potential of the proposed approach. The overriding goal of this\npaper is to generalise recent results in the robustness analysis of neural\nnetworks to a robust synthesis problem for their weights and biases.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 12:03:57 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Drummond", "Ross", ""], ["Turner", "Mathew C.", ""], ["Duncan", "Stephen R.", ""]]}, {"id": "2102.09312", "submitter": "Luis Claudio Sugi Afonso", "authors": "Luis C. S. Afonso, Clayton R. Pereira, Silke A. T. Weber, Christian\n  Hook, Alexandre X. Falc\\~ao, Jo\\~ao P. Papa", "title": "Hierarchical Learning Using Deep Optimum-Path Forest", "comments": null, "journal-ref": null, "doi": "10.1016/j.jvcir.2020.102823", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bag-of-Visual Words (BoVW) and deep learning techniques have been widely used\nin several domains, which include computer-assisted medical diagnoses. In this\nwork, we are interested in developing tools for the automatic identification of\nParkinson's disease using machine learning and the concept of BoVW. The\nproposed approach concerns a hierarchical-based learning technique to design\nvisual dictionaries through the Deep Optimum-Path Forest classifier. The\nproposed method was evaluated in six datasets derived from data collected from\nindividuals when performing handwriting exams. Experimental results showed the\npotential of the technique, with robust achievements.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:02:40 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Afonso", "Luis C. S.", ""], ["Pereira", "Clayton R.", ""], ["Weber", "Silke A. T.", ""], ["Hook", "Christian", ""], ["Falc\u00e3o", "Alexandre X.", ""], ["Papa", "Jo\u00e3o P.", ""]]}, {"id": "2102.09336", "submitter": "Jinho Hwang", "authors": "Jinho Hwang, Larisa Shwartz, Qing Wang, Raghav Batta, Harshit Kumar,\n  Michael Nidd", "title": "FIXME: Enhance Software Reliability with Hybrid Approaches in Cloud", "comments": "ICSE SEIP, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the promise of reliability in cloud, more enterprises are migrating to\ncloud. The process of continuous integration/deployment (CICD) in cloud\nconnects developers who need to deliver value faster and more transparently\nwith site reliability engineers (SREs) who need to manage applications\nreliably. SREs feed back development issues to developers, and developers\ncommit fixes and trigger CICD to redeploy. The release cycle is more continuous\nthan ever, thus the code to production is faster and more automated. To provide\nthis higher level agility, the cloud platforms become more complex in the face\nof flexibility with deeper layers of virtualization. However, reliability does\nnot come for free with all these complexities. Software engineers and SREs need\nto deal with wider information spectrum from virtualized layers. Therefore,\nproviding correlated information with true positive evidences is critical to\nidentify the root cause of issues quickly in order to reduce mean time to\nrecover (MTTR), performance metrics for SREs. Similarity, knowledge, or\nstatistics driven approaches have been effective, but with increasing data\nvolume and types, an individual approach is limited to correlate semantic\nrelations of different data sources. In this paper, we introduce FIXME to\nenhance software reliability with hybrid diagnosis approaches for enterprises.\nOur evaluation results show using hybrid diagnosis approach is about 17% better\nin precision. The results are helpful for both practitioners and researchers to\ndevelop hybrid diagnosis in the highly dynamic cloud environment.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:34:26 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hwang", "Jinho", ""], ["Shwartz", "Larisa", ""], ["Wang", "Qing", ""], ["Batta", "Raghav", ""], ["Kumar", "Harshit", ""], ["Nidd", "Michael", ""]]}, {"id": "2102.09337", "submitter": "Chen Tessler", "authors": "Chen Tessler, Yuval Shpigelman, Gal Dalal, Amit Mandelbaum, Doron\n  Haritan Kazakov, Benjamin Fuhrer, Gal Chechik, Shie Mannor", "title": "Reinforcement Learning for Datacenter Congestion Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the task of network congestion control in datacenters using\nReinforcement Learning (RL). Successful congestion control algorithms can\ndramatically improve latency and overall network throughput. Until today, no\nsuch learning-based algorithms have shown practical potential in this domain.\nEvidently, the most popular recent deployments rely on rule-based heuristics\nthat are tested on a predetermined set of benchmarks. Consequently, these\nheuristics do not generalize well to newly-seen scenarios. Contrarily, we\ndevise an RL-based algorithm with the aim of generalizing to different\nconfigurations of real-world datacenter networks. We overcome challenges such\nas partial-observability, non-stationarity, and multi-objectiveness. We further\npropose a policy gradient algorithm that leverages the analytical structure of\nthe reward function to approximate its derivative and improve stability. We\nshow that this scheme outperforms alternative popular RL approaches, and\ngeneralizes to scenarios that were not seen during training. Our experiments,\nconducted on a realistic simulator that emulates communication networks'\nbehavior, exhibit improved performance concurrently on the multiple considered\nmetrics compared to the popular algorithms deployed today in real datacenters.\nOur algorithm is being productized to replace heuristics in some of the largest\ndatacenters in the world.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:49:28 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Tessler", "Chen", ""], ["Shpigelman", "Yuval", ""], ["Dalal", "Gal", ""], ["Mandelbaum", "Amit", ""], ["Kazakov", "Doron Haritan", ""], ["Fuhrer", "Benjamin", ""], ["Chechik", "Gal", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.09343", "submitter": "Naveen Sundar Govindarajulu", "authors": "Selmer Bringsjord and Naveen Sundar Govindarajulu and Michael Giancola", "title": "AI Can Stop Mass Shootings, and More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to build directly upon our longstanding, prior r&d in AI/machine\nethics in order to attempt to make real the blue-sky idea of AI that can thwart\nmass shootings, by bringing to bear its ethical reasoning. The r&d in question\nis overtly and avowedly logicist in form, and since we are hardly the only ones\nwho have established a firm foundation in the attempt to imbue AI's with their\nown ethical sensibility, the pursuit of our proposal by those in different\nmethodological camps should, we believe, be considered as well. We seek herein\nto make our vision at least somewhat concrete by anchoring our exposition to\ntwo simulations, one in which the AI saves the lives of innocents by locking\nout a malevolent human's gun, and a second in which this malevolent agent is\nallowed by the AI to be neutralized by law enforcement. Along the way, some\nobjections are anticipated, and rebutted.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 06:55:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bringsjord", "Selmer", ""], ["Govindarajulu", "Naveen Sundar", ""], ["Giancola", "Michael", ""]]}, {"id": "2102.09361", "submitter": "L Wynter", "authors": "Desmond Cai, Shiau Hong Lim, Laura Wynter", "title": "Efficient Reinforcement Learning in Resource Allocation Problems Through\n  Permutation Invariant Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main challenges in real-world reinforcement learning is to learn\nsuccessfully from limited training samples. We show that in certain settings,\nthe available data can be dramatically increased through a form of multi-task\nlearning, by exploiting an invariance property in the tasks. We provide a\ntheoretical performance bound for the gain in sample efficiency under this\nsetting. This motivates a new approach to multi-task learning, which involves\nthe design of an appropriate neural network architecture and a prioritized\ntask-sampling strategy. We demonstrate empirically the effectiveness of the\nproposed approach on two real-world sequential resource allocation tasks where\nthis invariance property occurs: financial portfolio optimization and meta\nfederated learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 14:13:02 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Cai", "Desmond", ""], ["Lim", "Shiau Hong", ""], ["Wynter", "Laura", ""]]}, {"id": "2102.09370", "submitter": "Lara Gauder", "authors": "Lara Gauder, Leonardo Pepino, Pablo Riera, Silvina Brussino, Jazm\\'in\n  Vidal, Agust\\'in Gravano, Luciana Ferrer", "title": "A Study on the Manifestation of Trust in Speech", "comments": "arXiv admin note: text overlap with arXiv:2007.15711,\n  arXiv:2006.05977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Research has shown that trust is an essential aspect of human-computer\ninteraction directly determining the degree to which the person is willing to\nuse a system. An automatic prediction of the level of trust that a user has on\na certain system could be used to attempt to correct potential distrust by\nhaving the system take relevant actions like, for example, apologizing or\nexplaining its decisions. In this work, we explore the feasibility of\nautomatically detecting the level of trust that a user has on a virtual\nassistant (VA) based on their speech. We developed a novel protocol for\ncollecting speech data from subjects induced to have different degrees of trust\nin the skills of a VA. The protocol consists of an interactive session where\nthe subject is asked to respond to a series of factual questions with the help\nof a virtual assistant. In order to induce subjects to either trust or distrust\nthe VA's skills, they are first informed that the VA was previously rated by\nother users as being either good or bad; subsequently, the VA answers the\nsubjects' questions consistently to its alleged abilities. All interactions are\nspeech-based, with subjects and VAs communicating verbally, which allows the\nrecording of speech produced under different trust conditions. Using this\nprotocol, we collected a speech corpus in Argentine Spanish. We show clear\nevidence that the protocol effectively succeeded in influencing subjects into\nthe desired mental state of either trusting or distrusting the agent's skills,\nand present results of a perceptual study of the degree of trust performed by\nexpert listeners. Finally, we found that the subject's speech can be used to\ndetect which type of VA they were using, which could be considered a proxy for\nthe user's trust toward the VA's abilities, with an accuracy up to 76%,\ncompared to a random baseline of 50%.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 13:08:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gauder", "Lara", ""], ["Pepino", "Leonardo", ""], ["Riera", "Pablo", ""], ["Brussino", "Silvina", ""], ["Vidal", "Jazm\u00edn", ""], ["Gravano", "Agust\u00edn", ""], ["Ferrer", "Luciana", ""]]}, {"id": "2102.09381", "submitter": "Zhe Wu", "authors": "Zhe Wu, Kai Li, Enmin Zhao, Hang Xu, Meng Zhang, Haobo Fu, Bo An,\n  Junliang Xing", "title": "L2E: Learning to Exploit Your Opponent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opponent modeling is essential to exploit sub-optimal opponents in strategic\ninteractions. Most previous works focus on building explicit models to directly\npredict the opponents' styles or strategies, which require a large amount of\ndata to train the model and lack adaptability to unknown opponents. In this\nwork, we propose a novel Learning to Exploit (L2E) framework for implicit\nopponent modeling. L2E acquires the ability to exploit opponents by a few\ninteractions with different opponents during training, thus can adapt to new\nopponents with unknown styles during testing quickly. We propose a novel\nopponent strategy generation algorithm that produces effective opponents for\ntraining automatically. We evaluate L2E on two poker games and one grid soccer\ngame, which are the commonly used benchmarks for opponent modeling.\nComprehensive experimental results indicate that L2E quickly adapts to diverse\nstyles of unknown opponents.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 14:27:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wu", "Zhe", ""], ["Li", "Kai", ""], ["Zhao", "Enmin", ""], ["Xu", "Hang", ""], ["Zhang", "Meng", ""], ["Fu", "Haobo", ""], ["An", "Bo", ""], ["Xing", "Junliang", ""]]}, {"id": "2102.09388", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Soumajit Pramanik, Rishiraj Saha Roy, Gerhard Weikum", "title": "ELIXIR: Learning from User Feedback on Explanations to Improve\n  Recommender Models", "comments": "WWW 2021, 11 pages", "journal-ref": null, "doi": "10.1145/3442381.3449848", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System-provided explanations for recommendations are an important component\ntowards transparent and trustworthy AI. In state-of-the-art research, this is a\none-way signal, though, to improve user acceptance. In this paper, we turn the\nrole of explanations around and investigate how they can contribute to\nenhancing the quality of the generated recommendations themselves. We devise a\nhuman-in-the-loop framework, called ELIXIR, where user feedback on explanations\nis leveraged for pairwise learning of user preferences. ELIXIR leverages\nfeedback on pairs of recommendations and explanations to learn user-specific\nlatent preference vectors, overcoming sparseness by label propagation with\nitem-similarity-based neighborhoods. Our framework is instantiated using\ngeneralized graph recommendation via Random Walk with Restart. Insightful\nexperiments with a real user study show significant improvements in movie and\nbook recommendations over item-level feedback.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:43:49 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 18:26:05 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 18:50:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Pramanik", "Soumajit", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2102.09390", "submitter": "Al-Akhir Nayan", "authors": "Al-Akhir Nayan, Ahamad Nokib Mozumder, Joyeta Saha, Khan Raqib Mahmud,\n  Abul Kalam Al Azad", "title": "Early Detection of Fish Diseases by Analyzing Water Quality Using\n  Machine Learning Algorithm", "comments": null, "journal-ref": "International Journal of Advanced Science and Technology, Vol. 29,\n  No. 5, (2020), pp. 14346 - 14358", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Early detection of fish diseases and identifying the underlying causes are\ncrucial for farmers to take necessary steps to mitigate the potential outbreak,\nand thus to avert financial losses with apparent negative implications to\nnational economy. Typically, fish diseases are caused by virus and bacteria;\naccording to biochemical studies, the presence of certain bacteria and virus\nmay affect the level of pH, DO, BOD, COD, TSS, TDS, EC, PO43-, NO3-N, and NH3-N\nin water, resulting in the death of fishes. Besides, natural processes, e.g.,\nphotosynthesis, respiration, and decomposition also contribute to the\nalteration of water quality that adversely affects fish health. Being motivated\nby the recent successes of machine learning techniques in complex relational\ndata analyses in accurate classification and decision-making tasks, a\nstate-of-art machine learning algorithm has been adopted in this paper to\ndetect and predict the degradation of water quality timely and accurately, thus\nit helps taking pre-emptive steps against potential fish diseases. The\nexperimental results show a high accuracy in detecting fish diseases particular\nto specific water quality based on the algorithm with real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:52:58 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Nayan", "Al-Akhir", ""], ["Mozumder", "Ahamad Nokib", ""], ["Saha", "Joyeta", ""], ["Mahmud", "Khan Raqib", ""], ["Azad", "Abul Kalam Al", ""]]}, {"id": "2102.09469", "submitter": "Ryan Beal Mr.", "authors": "Ryan Beal, Georgios Chalkiadakis, Timothy J. Norman and Sarvapali D.\n  Ramchurn", "title": "Optimising Long-Term Outcomes using Real-World Fluent Objectives: An\n  Application to Football", "comments": "Pre-Print - Accepted for publication at AAMAS-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel approach for optimising long-term tactical\nand strategic decision-making in football (soccer) by encapsulating events in a\nleague environment across a given time frame. We model the teams' objectives\nfor a season and track how these evolve as games unfold to give a fluent\nobjective that can aid in decision-making games. We develop Markov chain Monte\nCarlo and deep learning-based algorithms that make use of the fluent objectives\nin order to learn from prior games and other games in the environment and\nincrease the teams' long-term performance. Simulations of our approach using\nreal-world datasets from 760 matches shows that by using optimised tactics with\nour fluent objective and prior games, we can on average increase teams mean\nexpected finishing distribution in the league by up to 35.6%.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:42:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Beal", "Ryan", ""], ["Chalkiadakis", "Georgios", ""], ["Norman", "Timothy J.", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2102.09470", "submitter": "Lovedeep Singh", "authors": "Lovedeep Singh", "title": "Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space", "comments": "for citiation purpose, use details available on official IEEE Xplore\n  page: https://doi.org/10.1109/CICT51604.2020.9312099", "journal-ref": "2020 IEEE 4th Conference on Information & Communication Technology\n  (CICT)", "doi": "10.1109/CICT51604.2020.9312099", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:42:28 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Singh", "Lovedeep", ""]]}, {"id": "2102.09475", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen, Rupert Brooks, Sovann En, Evan Zucker, Anuj Pareek,\n  Matthew P. Lungren, Akshay Chaudhari", "title": "Gifsplanation via Latent Shift: A Simple Autoencoder Approach to\n  Counterfactual Generation for Chest X-rays", "comments": "Full paper at MIDL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Traditional image attribution methods struggle to satisfactorily\nexplain predictions of neural networks. Prediction explanation is important,\nespecially in medical imaging, for avoiding the unintended consequences of\ndeploying AI systems when false positive predictions can impact patient care.\nThus, there is a pressing need to develop improved models for model\nexplainability and introspection. Specific problem: A new approach is to\ntransform input images to increase or decrease features which cause the\nprediction. However, current approaches are difficult to implement as they are\nmonolithic or rely on GANs. These hurdles prevent wide adoption. Our approach:\nGiven an arbitrary classifier, we propose a simple autoencoder and gradient\nupdate (Latent Shift) that can transform the latent representation of a\nspecific input image to exaggerate or curtail the features used for prediction.\nWe use this method to study chest X-ray classifiers and evaluate their\nperformance. We conduct a reader study with two radiologists assessing 240\nchest X-ray predictions to identify which ones are false positives (half are)\nusing traditional attribution maps or our proposed method. Results: We found\nlow overlap with ground truth pathology masks for models with reasonably high\naccuracy. However, the results from our reader study indicate that these models\nare generally looking at the correct features. We also found that the Latent\nShift explanation allows a user to have more confidence in true positive\npredictions compared to traditional approaches (0.15$\\pm$0.95 in a 5 point\nscale with p=0.01) with only a small increase in false positive predictions\n(0.04$\\pm$1.06 with p=0.57).\n  Accompanying webpage: https://mlmed.org/gifsplanation\n  Source code: https://github.com/mlmed/gifsplanation\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:55:03 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 21:07:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Brooks", "Rupert", ""], ["En", "Sovann", ""], ["Zucker", "Evan", ""], ["Pareek", "Anuj", ""], ["Lungren", "Matthew P.", ""], ["Chaudhari", "Akshay", ""]]}, {"id": "2102.09529", "submitter": "Sara In\\'es Rizo Rodr\\'iguez", "authors": "Sara Ines Rizo Rodriguez and Francisco de Assis Tenorio de Carvalho", "title": "Fuzzy clustering algorithms with distance metric learning and entropy\n  regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The clustering methods have been used in a variety of fields such as image\nprocessing, data mining, pattern recognition, and statistical analysis.\nGenerally, the clustering algorithms consider all variables equally relevant or\nnot correlated for the clustering task. Nevertheless, in real situations, some\nvariables can be correlated or may be more or less relevant or even irrelevant\nfor this task. This paper proposes partitioning fuzzy clustering algorithms\nbased on Euclidean, City-block and Mahalanobis distances and entropy\nregularization. These methods are an iterative three steps algorithms which\nprovide a fuzzy partition, a representative for each fuzzy cluster, and the\nrelevance weight of the variables or their correlation by minimizing a suitable\nobjective function. Several experiments on synthetic and real datasets,\nincluding its application to noisy image texture segmentation, demonstrate the\nusefulness of these adaptive clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:19:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Rodriguez", "Sara Ines Rizo", ""], ["de Carvalho", "Francisco de Assis Tenorio", ""]]}, {"id": "2102.09532", "submitter": "Danijar Hafner", "authors": "Vaibhav Saxena, Jimmy Ba, Danijar Hafner", "title": "Clockwork Variational Autoencoders", "comments": "17 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has enabled algorithms to generate realistic images. However,\naccurately predicting long video sequences requires understanding long-term\ndependencies and remains an open challenge. While existing video prediction\nmodels succeed at generating sharp images, they tend to fail at accurately\npredicting far into the future. We introduce the Clockwork VAE (CW-VAE), a\nvideo prediction model that leverages a hierarchy of latent sequences, where\nhigher levels tick at slower intervals. We demonstrate the benefits of both\nhierarchical latents and temporal abstraction on 4 diverse video prediction\ndatasets with sequences of up to 1000 frames, where CW-VAE outperforms top\nvideo prediction models. Additionally, we propose a Minecraft benchmark for\nlong-term video prediction. We conduct several experiments to gain insights\ninto CW-VAE and confirm that slower levels learn to represent objects that\nchange more slowly in the video, and faster levels learn to represent faster\nobjects.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:23:04 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 21:33:21 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Saxena", "Vaibhav", ""], ["Ba", "Jimmy", ""], ["Hafner", "Danijar", ""]]}, {"id": "2102.09539", "submitter": "Elad Farhi", "authors": "Elad I. Farhi and Vadim Indelman", "title": "iX-BSP: Incremental Belief Space Planning", "comments": "60 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deciding what's next? is a fundamental problem in robotics and Artificial\nIntelligence. Under belief space planning (BSP), in a partially observable\nsetting, it involves calculating the expected accumulated belief-dependent\nreward, where the expectation is with respect to all future measurements. Since\nsolving this general un-approximated problem quickly becomes intractable, state\nof the art approaches turn to approximations while still calculating planning\nsessions from scratch. In this work we propose a novel paradigm, Incremental\nBSP (iX-BSP), based on the key insight that calculations across planning\nsessions are similar in nature and can be appropriately re-used. We calculate\nthe expectation incrementally by utilizing Multiple Importance Sampling\ntechniques for selective re-sampling and re-use of measurement from previous\nplanning sessions. The formulation of our approach considers general\ndistributions and accounts for data association aspects. We demonstrate how\niX-BSP could benefit existing approximations of the general problem,\nintroducing iML-BSP, which re-uses calculations across planning sessions under\nthe common Maximum Likelihood assumption. We evaluate both methods and\ndemonstrate a substantial reduction in computation time while statistically\npreserving accuracy. The evaluation includes both simulation and real-world\nexperiments considering autonomous vision-based navigation and SLAM. As a\nfurther contribution, we introduce to iX-BSP the non-integral wildfire\napproximation, allowing one to trade accuracy for computational performance by\naverting from updating re-used beliefs when they are \"close enough\". We\nevaluate iX-BSP under wildfire demonstrating a substantial reduction in\ncomputation time while controlling the accuracy sacrifice. We also provide\nanalytical and empirical bounds of the effect wildfire holds over the objective\nvalue.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:35:14 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 07:10:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Farhi", "Elad I.", ""], ["Indelman", "Vadim", ""]]}, {"id": "2102.09542", "submitter": "Bo Li", "authors": "Bo Liu, Li-Ming Zhan, Li Xu, Lin Ma, Yan Yang, Xiao-Ming Wu", "title": "SLAKE: A Semantically-Labeled Knowledge-Enhanced Dataset for Medical\n  Visual Question Answering", "comments": "ISBI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Medical visual question answering (Med-VQA) has tremendous potential in\nhealthcare. However, the development of this technology is hindered by the\nlacking of publicly-available and high-quality labeled datasets for training\nand evaluation. In this paper, we present a large bilingual dataset, SLAKE,\nwith comprehensive semantic labels annotated by experienced physicians and a\nnew structural medical knowledge base for Med-VQA. Besides, SLAKE includes\nricher modalities and covers more human body parts than the currently available\ndataset. We show that SLAKE can be used to facilitate the development and\nevaluation of Med-VQA systems. The dataset can be downloaded from\nhttp://www.med-vqa.com/slake.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:44:50 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Liu", "Bo", ""], ["Zhan", "Li-Ming", ""], ["Xu", "Li", ""], ["Ma", "Lin", ""], ["Yang", "Yan", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "2102.09554", "submitter": "Yuzhe Yang", "authors": "Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, Dina Katabi", "title": "Delving into Deep Imbalanced Regression", "comments": "ICML 2021 (Long Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data often exhibit imbalanced distributions, where certain target\nvalues have significantly fewer observations. Existing techniques for dealing\nwith imbalanced data focus on targets with categorical indices, i.e., different\nclasses. However, many tasks involve continuous targets, where hard boundaries\nbetween classes do not exist. We define Deep Imbalanced Regression (DIR) as\nlearning from such imbalanced data with continuous targets, dealing with\npotential missing data for certain target values, and generalizing to the\nentire target range. Motivated by the intrinsic difference between categorical\nand continuous label space, we propose distribution smoothing for both labels\nand features, which explicitly acknowledges the effects of nearby targets, and\ncalibrates both label and learned feature distributions. We curate and\nbenchmark large-scale DIR datasets from common real-world tasks in computer\nvision, natural language processing, and healthcare domains. Extensive\nexperiments verify the superior performance of our strategies. Our work fills\nthe gap in benchmarks and techniques for practical imbalanced regression\nproblems. Code and data are available at\nhttps://github.com/YyzHarry/imbalanced-regression.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:56:03 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 17:58:27 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Yang", "Yuzhe", ""], ["Zha", "Kaiwen", ""], ["Chen", "Ying-Cong", ""], ["Wang", "Hao", ""], ["Katabi", "Dina", ""]]}, {"id": "2102.09563", "submitter": "Roc\\'io del Amor del Amor", "authors": "del Amor Roc\\'io, Colomer Adri\\'an, Monteagudo Carlos, Naranjo Valery", "title": "A Deep Embedded Refined Clustering Approach for Breast Cancer\n  Distinction based on DNA Methylation", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epigenetic alterations have an important role in the development of several\ntypes of cancer. Epigenetic studies generate a large amount of data, which\nmakes it essential to develop novel models capable of dealing with large-scale\ndata. In this work, we propose a deep embedded refined clustering method for\nbreast cancer differentiation based on DNA methylation. In concrete, the deep\nlearning system presented here uses the levels of CpG island methylation\nbetween 0 and 1. The proposed approach is composed of two main stages. The\nfirst stage consists in the dimensionality reduction of the methylation data\nbased on an autoencoder. The second stage is a clustering algorithm based on\nthe soft-assignment of the latent space provided by the autoencoder. The whole\nmethod is optimized through a weighted loss function composed of two terms:\nreconstruction and classification terms. To the best of the authors' knowledge,\nno previous studies have focused on the dimensionality reduction algorithms\nlinked to classification trained end-to-end for DNA methylation analysis. The\nproposed method achieves an unsupervised clustering accuracy of 0.9927 and an\nerror rate (%) of 0.73 on 137 breast tissue samples. After a second test of the\ndeep-learning-based method using a different methylation database, an accuracy\nof 0.9343 and an error rate (%) of 6.57 on 45 breast tissue samples is\nobtained. Based on these results, the proposed algorithm outperforms other\nstate-of-the-art methods evaluated under the same conditions for breast cancer\nclassification based on DNA methylation data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 16:46:25 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Roc\u00edo", "del Amor", ""], ["Adri\u00e1n", "Colomer", ""], ["Carlos", "Monteagudo", ""], ["Valery", "Naranjo", ""]]}, {"id": "2102.09599", "submitter": "Parham Gohari", "authors": "Parham Gohari, Bo Chen, Bo Wu, Matthew Hale, and Ufuk Topcu", "title": "Privacy-Preserving Kickstarting Deep Reinforcement Learning with\n  Privacy-Aware Learners", "comments": "Under double-blind review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kickstarting deep reinforcement learning algorithms facilitate a\nteacher-student relationship among the agents and allow for a well-performing\nteacher to share demonstrations with a student to expedite the student's\ntraining. However, despite the known benefits, the demonstrations may contain\nsensitive information about the teacher's training data and existing\nkickstarting methods do not take any measures to protect it. Therefore, we use\nthe framework of differential privacy to develop a mechanism that securely\nshares the teacher's demonstrations with the student. The mechanism allows for\nthe teacher to decide upon the accuracy of its demonstrations with respect to\nthe privacy budget that it consumes, thereby granting the teacher full control\nover its data privacy. We then develop a kickstarted deep reinforcement\nlearning algorithm for the student that is privacy-aware because we calibrate\nits objective with the parameters of the teacher's privacy mechanism. The\nprivacy-aware design of the algorithm makes it possible to kickstart the\nstudent's learning despite the perturbations induced by the privacy mechanism.\nFrom numerical experiments, we highlight three empirical results: (i) the\nalgorithm succeeds in expediting the student's learning, (ii) the student\nconverges to a performance level that was not possible without the\ndemonstrations, and (iii) the student maintains its enhanced performance even\nafter the teacher stops sharing useful demonstrations due to its privacy budget\nconstraints.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 20:15:09 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 20:47:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Gohari", "Parham", ""], ["Chen", "Bo", ""], ["Wu", "Bo", ""], ["Hale", "Matthew", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2102.09600", "submitter": "Shafiuddin Rehan Ahmed", "authors": "Shafiuddin Rehan Ahmed and James H. Martin", "title": "Within-Document Event Coreference with BERT-Based Contextualized\n  Representations", "comments": "9 pages, 1 figure, 10 tables, rejected in aaai 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Event coreference continues to be a challenging problem in information\nextraction. With the absence of any external knowledge bases for events,\ncoreference becomes a clustering task that relies on effective representations\nof the context in which event mentions appear. Recent advances in\ncontextualized language representations have proven successful in many tasks,\nhowever, their use in event linking been limited. Here we present a three part\napproach that (1) uses representations derived from a pretrained BERT model to\n(2) train a neural classifier to (3) drive a simple clustering algorithm to\ncreate coreference chains. We achieve state of the art results with this model\non two standard datasets for within-document event coreference task and\nestablish a new standard on a third newer dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:12:43 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Ahmed", "Shafiuddin Rehan", ""], ["Martin", "James H.", ""]]}, {"id": "2102.09603", "submitter": "Sowmen Das", "authors": "Sowmen Das, Arup Datta, Md. Saiful Islam, Md. Ruhul Amin", "title": "Improving DeepFake Detection Using Dynamic Face Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The creation of altered and manipulated faces has become more common due to\nthe improvement of DeepFake generation methods. Simultaneously, we have seen\ndetection models' development for differentiating between a manipulated and\noriginal face from image or video content. We have observed that most publicly\navailable DeepFake detection datasets have limited variations, where a single\nface is used in many videos, resulting in an oversampled training dataset. Due\nto this, deep neural networks tend to overfit to the facial features instead of\nlearning to detect manipulation features of DeepFake content. As a result, most\ndetection architectures perform poorly when tested on unseen data. In this\npaper, we provide a quantitative analysis to investigate this problem and\npresent a solution to prevent model overfitting due to the high volume of\nsamples generated from a small number of actors. We introduce Face-Cutout, a\ndata augmentation method for training Convolutional Neural Networks (CNN), to\nimprove DeepFake detection. In this method, training images with various\nocclusions are dynamically generated using face landmark information\nirrespective of orientation. Unlike other general-purpose augmentation methods,\nit focuses on the facial information that is crucial for DeepFake detection.\nOur method achieves a reduction in LogLoss of 15.2% to 35.3% on different\ndatasets, compared to other occlusion-based augmentation techniques. We show\nthat Face-Cutout can be easily integrated with any CNN-based recognition model\nand improve detection performance.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 20:25:45 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 02:19:30 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Das", "Sowmen", ""], ["Datta", "Arup", ""], ["Islam", "Md. Saiful", ""], ["Amin", "Md. Ruhul", ""]]}, {"id": "2102.09635", "submitter": "Bibek Paudel", "authors": "Bibek Paudel, Abraham Bernstein", "title": "Random Walks with Erasure: Diversifying Personalized Recommendations on\n  Social and Information Networks", "comments": "Web Conference 2021 (WWW '21)", "journal-ref": "Proceedings of the Web Conference 2021 (WWW '21), April 19--23,\n  2021, Ljubljana, Slovenia", "doi": "10.1145/3442381.3449970", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing personalization systems promote items that match a user's\nprevious choices or those that are popular among similar users. This results in\nrecommendations that are highly similar to the ones users are already exposed\nto, resulting in their isolation inside familiar but insulated information\nsilos. In this context, we develop a novel recommendation framework with a goal\nof improving information diversity using a modified random walk exploration of\nthe user-item graph. We focus on the problem of political content\nrecommendation, while addressing a general problem applicable to\npersonalization tasks in other social and information networks.\n  For recommending political content on social networks, we first propose a new\nmodel to estimate the ideological positions for both users and the content they\nshare, which is able to recover ideological positions with high accuracy. Based\non these estimated positions, we generate diversified personalized\nrecommendations using our new random-walk based recommendation algorithm. With\nexperimental evaluations on large datasets of Twitter discussions, we show that\nour method based on \\emph{random walks with erasure} is able to generate more\nideologically diverse recommendations. Our approach does not depend on the\navailability of labels regarding the bias of users or content producers. With\nexperiments on open benchmark datasets from other social and information\nnetworks, we also demonstrate the effectiveness of our method in recommending\ndiverse long-tail items.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 21:53:32 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:23:16 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 17:20:52 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Paudel", "Bibek", ""], ["Bernstein", "Abraham", ""]]}, {"id": "2102.09665", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Marcos Zampieri", "title": "MUDES: Multilingual Detection of Offensive Spans", "comments": "Accepted to NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The interest in offensive content identification in social media has grown\nsubstantially in recent years. Previous work has dealt mostly with post level\nannotations. However, identifying offensive spans is useful in many ways. To\nhelp coping with this important challenge, we present MUDES, a multilingual\nsystem to detect offensive spans in texts. MUDES features pre-trained models, a\nPython API for developers, and a user-friendly web-based interface. A detailed\ndescription of MUDES' components is presented in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:19:00 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 15:22:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Zampieri", "Marcos", ""]]}, {"id": "2102.09666", "submitter": "Takuya Higuchi", "authors": "Takuya Higuchi, Shreyas Saxena, Mehrez Souden, Tien Dung Tran, Masood\n  Delfarah and Chandra Dhir", "title": "Dynamic curriculum learning via data parameters for noise robust keyword\n  spotting", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose dynamic curriculum learning via data parameters for noise robust\nkeyword spotting. Data parameter learning has recently been introduced for\nimage processing, where weight parameters, so-called data parameters, for\ntarget classes and instances are introduced and optimized along with model\nparameters. The data parameters scale logits and control importance over\nclasses and instances during training, which enables automatic curriculum\nlearning without additional annotations for training data. Similarly, in this\npaper, we propose using this curriculum learning approach for acoustic\nmodeling, and train an acoustic model on clean and noisy utterances with the\ndata parameters. The proposed approach automatically learns the difficulty of\nthe classes and instances, e.g. due to low speech to noise ratio (SNR), in the\ngradient descent optimization and performs curriculum learning. This curriculum\nlearning leads to overall improvement of the accuracy of the acoustic model. We\nevaluate the effectiveness of the proposed approach on a keyword spotting task.\nExperimental results show 7.7% relative reduction in false reject ratio with\nthe data parameters compared to a baseline model which is simply trained on the\nmulticonditioned dataset.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:26:07 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Higuchi", "Takuya", ""], ["Saxena", "Shreyas", ""], ["Souden", "Mehrez", ""], ["Tran", "Tien Dung", ""], ["Delfarah", "Masood", ""], ["Dhir", "Chandra", ""]]}, {"id": "2102.09672", "submitter": "Prafulla Dhariwal", "authors": "Alex Nichol, Prafulla Dhariwal", "title": "Improved Denoising Diffusion Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising diffusion probabilistic models (DDPM) are a class of generative\nmodels which have recently been shown to produce excellent samples. We show\nthat with a few simple modifications, DDPMs can also achieve competitive\nlog-likelihoods while maintaining high sample quality. Additionally, we find\nthat learning variances of the reverse diffusion process allows sampling with\nan order of magnitude fewer forward passes with a negligible difference in\nsample quality, which is important for the practical deployment of these\nmodels. We additionally use precision and recall to compare how well DDPMs and\nGANs cover the target distribution. Finally, we show that the sample quality\nand likelihood of these models scale smoothly with model capacity and training\ncompute, making them easily scalable. We release our code at\nhttps://github.com/openai/improved-diffusion\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:44:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Nichol", "Alex", ""], ["Dhariwal", "Prafulla", ""]]}, {"id": "2102.09677", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, I-Te Danny Hung, Yi Ouyang, Pin-Yu Chen", "title": "Causal Inference Q-Network: Toward Resilient Reinforcement Learning", "comments": "Preprint. Under Review. A Non-archival and preliminary venue was\n  presented in ICLR 2021 Self-supervision for Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning (DRL) has demonstrated impressive performance in\nvarious gaming simulators and real-world applications. In practice, however, a\nDRL agent may receive faulty observation by abrupt interferences such as\nblack-out, frozen-screen, and adversarial perturbation. How to design a\nresilient DRL algorithm against these rare but mission-critical and\nsafety-crucial scenarios is an important yet challenging task. In this paper,\nwe consider a generative DRL framework training with an auxiliary task of\nobservational interferences such as artificial noises. Under this framework, we\ndiscuss the importance of the causal relation and propose a causal inference\nbased DRL algorithm called causal inference Q-network (CIQ). We evaluate the\nperformance of CIQ in several benchmark DRL environments with different types\nof interferences as auxiliary labels. Our experimental results show that the\nproposed CIQ method could achieve higher performance and more resilience\nagainst observational interferences.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:50:20 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 22:22:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Hung", "I-Te Danny", ""], ["Ouyang", "Yi", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2102.09692", "submitter": "Zana Bu\\c{c}inca", "authors": "Zana Bu\\c{c}inca, Maja Barbara Malaya, Krzysztof Z. Gajos", "title": "To Trust or to Think: Cognitive Forcing Functions Can Reduce\n  Overreliance on AI in AI-assisted Decision-making", "comments": null, "journal-ref": null, "doi": "10.1145/3449287", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People supported by AI-powered decision support tools frequently overrely on\nthe AI: they accept an AI's suggestion even when that suggestion is wrong.\nAdding explanations to the AI decisions does not appear to reduce the\noverreliance and some studies suggest that it might even increase it. Informed\nby the dual-process theory of cognition, we posit that people rarely engage\nanalytically with each individual AI recommendation and explanation, and\ninstead develop general heuristics about whether and when to follow the AI\nsuggestions. Building on prior research on medical decision-making, we designed\nthree cognitive forcing interventions to compel people to engage more\nthoughtfully with the AI-generated explanations. We conducted an experiment\n(N=199), in which we compared our three cognitive forcing designs to two simple\nexplainable AI approaches and to a no-AI baseline. The results demonstrate that\ncognitive forcing significantly reduced overreliance compared to the simple\nexplainable AI approaches. However, there was a trade-off: people assigned the\nleast favorable subjective ratings to the designs that reduced the overreliance\nthe most. To audit our work for intervention-generated inequalities, we\ninvestigated whether our interventions benefited equally people with different\nlevels of Need for Cognition (i.e., motivation to engage in effortful mental\nactivities). Our results show that, on average, cognitive forcing interventions\nbenefited participants higher in Need for Cognition more. Our research suggests\nthat human cognitive motivation moderates the effectiveness of explainable AI\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 00:38:53 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bu\u00e7inca", "Zana", ""], ["Malaya", "Maja Barbara", ""], ["Gajos", "Krzysztof Z.", ""]]}, {"id": "2102.09727", "submitter": "Seohyeong Jeong", "authors": "Seohyeong Jeong, Nojun Kwak", "title": "Learning Dynamic BERT via Trainable Gate Variables and a Bi-modal\n  Regularizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The BERT model has shown significant success on various natural language\nprocessing tasks. However, due to the heavy model size and high computational\ncost, the model suffers from high latency, which is fatal to its deployments on\nresource-limited devices. To tackle this problem, we propose a dynamic\ninference method on BERT via trainable gate variables applied on input tokens\nand a regularizer that has a bi-modal property. Our method shows reduced\ncomputational cost on the GLUE dataset with a minimal performance drop.\nMoreover, the model adjusts with a trade-off between performance and\ncomputational cost with the user-specified hyperparameter.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 03:59:23 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jeong", "Seohyeong", ""], ["Kwak", "Nojun", ""]]}, {"id": "2102.09744", "submitter": "Zakria Jamali Dr.", "authors": "Zakria, Jianhua Deng, Muhammad Saddam Khokhar, Muhammad Umar Aftab,\n  Jingye Cai, Rajesh Kumar and Jay Kumar", "title": "Trends in Vehicle Re-identification Past, Present, and Future: A\n  Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle Re-identification (re-id) over surveillance camera network with\nnon-overlapping field of view is an exciting and challenging task in\nintelligent transportation systems (ITS). Due to its versatile applicability in\nmetropolitan cities, it gained significant attention. Vehicle re-id matches\ntargeted vehicle over non-overlapping views in multiple camera network.\nHowever, it becomes more difficult due to inter-class similarity, intra-class\nvariability, viewpoint changes, and spatio-temporal uncertainty. In order to\ndraw a detailed picture of vehicle re-id research, this paper gives a\ncomprehensive description of the various vehicle re-id technologies,\napplicability, datasets, and a brief comparison of different methodologies. Our\npaper specifically focuses on vision-based vehicle re-id approaches, including\nvehicle appearance, license plate, and spatio-temporal characteristics. In\naddition, we explore the main challenges as well as a variety of applications\nin different domains. Lastly, a detailed comparison of current state-of-the-art\nmethods performances over VeRi-776 and VehicleID datasets is summarized with\nfuture directions. We aim to facilitate future research by reviewing the work\nbeing done on vehicle re-id till to date.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 05:02:24 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Zakria", "", ""], ["Deng", "Jianhua", ""], ["Khokhar", "Muhammad Saddam", ""], ["Aftab", "Muhammad Umar", ""], ["Cai", "Jingye", ""], ["Kumar", "Rajesh", ""], ["Kumar", "Jay", ""]]}, {"id": "2102.09754", "submitter": "Ryan Hoque", "authors": "Ryan Hoque, Daniel Seita, Ashwin Balakrishna, Aditya Ganapathi, Ajay\n  Kumar Tanwani, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg", "title": "VisuoSpatial Foresight for Physical Sequential Fabric Manipulation", "comments": "Journal extension of prior work on VSF to appear in Autonomous Robots\n  S.I. 207. arXiv admin note: text overlap with arXiv:2003.09044", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic fabric manipulation has applications in home robotics, textiles,\nsenior care and surgery. Existing fabric manipulation techniques, however, are\ndesigned for specific tasks, making it difficult to generalize across different\nbut related tasks. We build upon the Visual Foresight framework to learn fabric\ndynamics that can be efficiently reused to accomplish different sequential\nfabric manipulation tasks with a single goal-conditioned policy. We extend our\nearlier work on VisuoSpatial Foresight (VSF), which learns visual dynamics on\ndomain randomized RGB images and depth maps simultaneously and completely in\nsimulation. In this earlier work, we evaluated VSF on multi-step fabric\nsmoothing and folding tasks against 5 baseline methods in simulation and on the\nda Vinci Research Kit (dVRK) surgical robot without any demonstrations at train\nor test time. A key finding was that depth sensing significantly improves\nperformance: RGBD data yields an 80% improvement in fabric folding success rate\nin simulation over pure RGB data. In this work, we vary 4 components of VSF,\nincluding data generation, visual dynamics model, cost function, and\noptimization procedure. Results suggest that training visual dynamics models\nusing longer, corner-based actions can improve the efficiency of fabric folding\nby 76% and enable a physical sequential fabric folding task that VSF could not\npreviously perform with 90% reliability. Code, data, videos, and supplementary\nmaterial are available at https://sites.google.com/view/fabric-vsf/.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:06:49 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 21:40:13 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hoque", "Ryan", ""], ["Seita", "Daniel", ""], ["Balakrishna", "Ashwin", ""], ["Ganapathi", "Aditya", ""], ["Tanwani", "Ajay Kumar", ""], ["Jamali", "Nawid", ""], ["Yamane", "Katsu", ""], ["Iba", "Soshi", ""], ["Goldberg", "Ken", ""]]}, {"id": "2102.09756", "submitter": "Minchao Wu", "authors": "Minchao Wu, Michael Norrish, Christian Walder, Amir Dezfouli", "title": "TacticZero: Learning to Prove Theorems from Scratch with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to interactive theorem-proving (ITP) using deep\nreinforcement learning. The proposed framework is able to learn proof search\nstrategies as well as tactic and arguments prediction in an end-to-end manner.\nWe formulate the process of ITP as a Markov decision process (MDP) in which\neach state represents a set of potential derivation paths. This structure\nallows us to introduce a novel backtracking mechanism which enables the agent\nto efficiently discard (predicted) dead-end derivations and restart from\npromising alternatives. We implement the framework in the HOL4 theorem prover.\nExperimental results show that the framework outperforms existing automated\ntheorem provers (i.e., hammers) available in HOL4 when evaluated on unseen\nproblems. We further elaborate the role of key components of the framework\nusing ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:08:39 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 07:48:40 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wu", "Minchao", ""], ["Norrish", "Michael", ""], ["Walder", "Christian", ""], ["Dezfouli", "Amir", ""]]}, {"id": "2102.09761", "submitter": "Tom Hope", "authors": "Tom Hope, Ronen Tamari, Hyeonsu Kang, Daniel Hershcovich, Joel Chan,\n  Aniket Kittur, Dafna Shahaf", "title": "Scaling Creative Inspiration with Fine-Grained Functional Facets of\n  Product Ideas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-scale repositories of products, patents and scientific papers offer an\nopportunity for creating automated systems that scour millions of ideas and\nassist users in discovering inspirations and solutions. Yet the common\nrepresentation of ideas is in the form of raw textual descriptions, lacking\nimportant structure that is required for supporting creative innovation. Prior\nwork has pointed to the importance of functional structure -- capturing the\nmechanisms and purposes of inventions -- for allowing users to discover\nstructural connections across ideas and creatively adapt existing technologies.\nHowever, the use of functional representations was either coarse and limited in\nexpressivity, or dependent on curated knowledge bases with poor coverage and\nsignificant manual effort from users.\n  To help bridge this gap and unlock the potential of large-scale idea mining,\nwe propose a novel computational representation that automatically breaks up\nproducts into fine-grained functional facets. We train a model to extract these\nfacets from a challenging real-world corpus of invention descriptions, and\nrepresent each product as a set of facet embeddings. We design similarity\nmetrics that support granular matching between functional facets across ideas,\nand use them to build a novel functional search capability that enables\nexpressive queries for mechanisms and purposes. We construct a graph capturing\nhierarchical relations between purposes and mechanisms across an entire corpus\nof products, and use the graph to help problem-solvers explore the design space\naround a focal problem and view related problem perspectives. In empirical user\nstudies, our approach leads to a significant boost in search accuracy and in\nthe quality of creative inspirations, outperforming strong baselines and\nstate-of-art representations of product texts by 50-60%.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 06:30:41 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Hope", "Tom", ""], ["Tamari", "Ronen", ""], ["Kang", "Hyeonsu", ""], ["Hershcovich", "Daniel", ""], ["Chan", "Joel", ""], ["Kittur", "Aniket", ""], ["Shahaf", "Dafna", ""]]}, {"id": "2102.09768", "submitter": "Honghua Zhang", "authors": "Honghua Zhang, Brendan Juba, Guy Van den Broeck", "title": "Probabilistic Generating Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating functions, which are widely used in combinatorics and probability\ntheory, encode function values into the coefficients of a polynomial. In this\npaper, we explore their use as a tractable probabilistic model, and propose\nprobabilistic generating circuits (PGCs) for their efficient representation.\nPGCs are strictly more expressive efficient than many existing tractable\nprobabilistic models, including determinantal point processes (DPPs),\nprobabilistic circuits (PCs) such as sum-product networks, and tractable\ngraphical models. We contend that PGCs are not just a theoretical framework\nthat unifies vastly different existing models, but also show great potential in\nmodeling realistic data. We exhibit a simple class of PGCs that are not\ntrivially subsumed by simple combinations of PCs and DPPs, and obtain\ncompetitive performance on a suite of density estimation benchmarks. We also\nhighlight PGCs' connection to the theory of strongly Rayleigh distributions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 07:06:53 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 22:50:57 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Honghua", ""], ["Juba", "Brendan", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2102.09798", "submitter": "Tillmann Miltzow", "authors": "Mikkel Abrahamsen, Linda Kleist, Tillmann Miltzow", "title": "Training Neural Networks is ER-complete", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DS cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a neural network, training data, and a threshold, it was known that it\nis NP-hard to find weights for the neural network such that the total error is\nbelow the threshold. We determine the algorithmic complexity of this\nfundamental problem precisely, by showing that it is ER-complete. This means\nthat the problem is equivalent, up to polynomial-time reductions, to deciding\nwhether a system of polynomial equations and inequalities with integer\ncoefficients and real unknowns has a solution. If, as widely expected, ER is\nstrictly larger than NP, our work implies that the problem of training neural\nnetworks is not even in NP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:28:37 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["Kleist", "Linda", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "2102.09812", "submitter": "Lucas Liebenwein", "authors": "Wilko Schwarting, Tim Seyde, Igor Gilitschenski, Lucas Liebenwein,\n  Ryan Sander, Sertac Karaman, Daniela Rus", "title": "Deep Latent Competition: Learning to Race Using Visual Control Policies\n  in Latent Space", "comments": "Wilko, Tim, and Igor contributed equally to this work; published in\n  Conference on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning competitive behaviors in multi-agent settings such as racing\nrequires long-term reasoning about potential adversarial interactions. This\npaper presents Deep Latent Competition (DLC), a novel reinforcement learning\nalgorithm that learns competitive visual control policies through self-play in\nimagination. The DLC agent imagines multi-agent interaction sequences in the\ncompact latent space of a learned world model that combines a joint transition\nfunction with opponent viewpoint prediction. Imagined self-play reduces costly\nsample generation in the real world, while the latent representation enables\nplanning to scale gracefully with observation dimensionality. We demonstrate\nthe effectiveness of our algorithm in learning competitive behaviors on a novel\nmulti-agent racing benchmark that requires planning from image observations.\nCode and videos available at\nhttps://sites.google.com/view/deep-latent-competition.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 09:00:29 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Schwarting", "Wilko", ""], ["Seyde", "Tim", ""], ["Gilitschenski", "Igor", ""], ["Liebenwein", "Lucas", ""], ["Sander", "Ryan", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "2102.09837", "submitter": "Till Hofmann", "authors": "Till Hofmann and Gerhard Lakemeyer", "title": "Controller Synthesis for Golog Programs over Finite Domains with Metric\n  Temporal Constraints", "comments": "A poster about this paper was presented at the 17th International\n  Conference on Principles of Knowledge Representation and Reasoning (KR'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Executing a Golog program on an actual robot typically requires additional\nsteps to account for hardware or software details of the robot platform, which\ncan be formulated as constraints on the program. Such constraints are often\ntemporal, refer to metric time, and require modifications to the abstract Golog\nprogram. We describe how to formulate such constraints based on a modal variant\nof the Situation Calculus. These constraints connect the abstract program with\nthe platform models, which we describe using timed automata. We show that for\nprograms over finite domains and with fully known initial state, the problem of\nsynthesizing a controller that satisfies the constraints while preserving the\neffects of the original program can be reduced to MTL synthesis. We do this by\nconstructing a timed automaton from the abstract program and synthesizing an\nMTL controller from this automaton, the platform models, and the constraints.\nWe prove that the synthesized controller results in execution traces which are\nthe same as those of the original program, possibly interleaved with\nplatform-dependent actions, that they satisfy all constraints, and that they\nhave the same effects as the traces of the original program. By doing so, we\nobtain a decidable procedure to synthesize a controller that satisfies the\nspecification while preserving the original program.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:07:29 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hofmann", "Till", ""], ["Lakemeyer", "Gerhard", ""]]}, {"id": "2102.09850", "submitter": "Manan Tomar Mr.", "authors": "Manan Tomar, Amy Zhang, Roberto Calandra, Matthew E. Taylor, Joelle\n  Pineau", "title": "Model-Invariant State Abstractions for Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accuracy and generalization of dynamics models is key to the success of\nmodel-based reinforcement learning (MBRL). As the complexity of tasks\nincreases, so does the sample inefficiency of learning accurate dynamics\nmodels. However, many complex tasks also exhibit sparsity in the dynamics,\ni.e., actions have only a local effect on the system dynamics. In this paper,\nwe exploit this property with a causal invariance perspective in the\nsingle-task setting, introducing a new type of state abstraction called\n\\textit{model-invariance}. Unlike previous forms of state abstractions, a\nmodel-invariance state abstraction leverages causal sparsity over state\nvariables. This allows for compositional generalization to unseen states,\nsomething that non-factored forms of state abstractions cannot do. We prove\nthat an optimal policy can be learned over this model-invariance state\nabstraction and show improved generalization in a simple toy domain. Next, we\npropose a practical method to approximately learn a model-invariant\nrepresentation for complex domains and validate our approach by showing\nimproved modelling performance over standard maximum likelihood approaches on\nchallenging tasks, such as the MuJoCo-based Humanoid. Finally, within the MBRL\nsetting we show strong performance gains with respect to sample efficiency\nacross a host of other continuous control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:37:54 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 14:29:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tomar", "Manan", ""], ["Zhang", "Amy", ""], ["Calandra", "Roberto", ""], ["Taylor", "Matthew E.", ""], ["Pineau", "Joelle", ""]]}, {"id": "2102.09854", "submitter": "Sao Mai Nguyen", "authors": "Nicolas Duminy (Lab-STICC), Sao Mai Nguyen (U2IS), Junshuai Zhu (IMT\n  Atlantique), Dominique Duhaut (UBS), Jerome Kerdreux (Lab-STICC)", "title": "Intrinsically Motivated Open-Ended Multi-Task Learning Using Transfer\n  Learning to Discover Task Hierarchy", "comments": null, "journal-ref": "Applied Sciences, MDPI, 2021, 11 (3), pp.975", "doi": "10.3390/app11030975", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open-ended continuous environments, robots need to learn multiple\nparameterised control tasks in hierarchical reinforcement learning. We\nhypothesise that the most complex tasks can be learned more easily by\ntransferring knowledge from simpler tasks, and faster by adapting the\ncomplexity of the actions to the task. We propose a task-oriented\nrepresentation of complex actions, called procedures, to learn online task\nrelationships and unbounded sequences of action primitives to control the\ndifferent observables of the environment. Combining both goal-babbling with\nimitation learning, and active learning with transfer of knowledge based on\nintrinsic motivation, our algorithm self-organises its learning process. It\nchooses at any given time a task to focus on; and what, how, when and from whom\nto transfer knowledge. We show with a simulation and a real industrial robot\narm, in cross-task and cross-learner transfer settings, that task composition\nis key to tackle highly complex tasks. Task decomposition is also efficiently\ntransferred across different embodied learners and by active imitation, where\nthe robot requests just a small amount of demonstrations and the adequate type\nof information. The robot learns and exploits task dependencies so as to learn\ntasks of every complexity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:44:08 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Duminy", "Nicolas", "", "Lab-STICC"], ["Nguyen", "Sao Mai", "", "U2IS"], ["Zhu", "Junshuai", "", "IMT\n  Atlantique"], ["Duhaut", "Dominique", "", "UBS"], ["Kerdreux", "Jerome", "", "Lab-STICC"]]}, {"id": "2102.09880", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Rouven Walter and Jose A. Galindo and David\n  Benavides and Seda Polat-Erdeniz and Muesluem Atas and Stefan Reiterer", "title": "Anytime Diagnosis for Reconfiguration", "comments": "Preprint, cite as: A. Felfernig. R. Walter, J. Galindo, D. Benavides,\n  M. Atas, S. Polat-Erdeniz, and S. Reiterer. Anytime Diagnosis for\n  Reconfiguration. Journal of Intelligent Information Systems, vol. 51, pp.\n  161-182, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many domains require scalable algorithms that help to determine diagnoses\nefficiently and often within predefined time limits. Anytime diagnosis is able\nto determine solutions in such a way and thus is especially useful in real-time\nscenarios such as production scheduling, robot control, and communication\nnetworks management where diagnosis and corresponding reconfiguration\ncapabilities play a major role. Anytime diagnosis in many cases comes along\nwith a trade-off between diagnosis quality and the efficiency of diagnostic\nreasoning. In this paper we introduce and analyze FlexDiag which is an anytime\ndirect diagnosis approach. We evaluate the algorithm with regard to performance\nand diagnosis quality using a configuration benchmark from the domain of\nfeature models and an industrial configuration knowledge base from the\nautomotive domain. Results show that FlexDiag helps to significantly increase\nthe performance of direct diagnosis search with corresponding quality tradeoffs\nin terms of minimality and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 11:45:52 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Felfernig", "Alexander", ""], ["Walter", "Rouven", ""], ["Galindo", "Jose A.", ""], ["Benavides", "David", ""], ["Polat-Erdeniz", "Seda", ""], ["Atas", "Muesluem", ""], ["Reiterer", "Stefan", ""]]}, {"id": "2102.09883", "submitter": "George Eskandar", "authors": "George Eskandar, Alexander Braun, Martin Meinke, Karim Armanious, Bin\n  Yang", "title": "SLPC: a VRNN-based approach for stochastic lidar prediction and\n  completion in autonomous driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future 3D LiDAR pointclouds is a challenging task that is useful\nin many applications in autonomous driving such as trajectory prediction, pose\nforecasting and decision making. In this work, we propose a new LiDAR\nprediction framework that is based on generative models namely Variational\nRecurrent Neural Networks (VRNNs), titled Stochastic LiDAR Prediction and\nCompletion (SLPC). Our algorithm is able to address the limitations of previous\nvideo prediction frameworks when dealing with sparse data by spatially\ninpainting the depth maps in the upcoming frames. Our contributions can thus be\nsummarized as follows: we introduce the new task of predicting and completing\ndepth maps from spatially sparse data, we present a sparse version of VRNNs and\nan effective self-supervised training method that does not require any labels.\nExperimental results illustrate the effectiveness of our framework in\ncomparison to the state of the art methods in video prediction.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 11:56:44 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Eskandar", "George", ""], ["Braun", "Alexander", ""], ["Meinke", "Martin", ""], ["Armanious", "Karim", ""], ["Yang", "Bin", ""]]}, {"id": "2102.09890", "submitter": "Felix Wiewel", "authors": "Felix Wiewel and Bin Yang", "title": "Condensed Composite Memory Continual Learning", "comments": "Paper accepted for publication at IJCNN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) suffer from a rapid decrease in performance when\ntrained on a sequence of tasks where only data of the most recent task is\navailable. This phenomenon, known as catastrophic forgetting, prevents DNNs\nfrom accumulating knowledge over time. Overcoming catastrophic forgetting and\nenabling continual learning is of great interest since it would enable the\napplication of DNNs in settings where unrestricted access to all the training\ndata at any time is not always possible, e.g. due to storage limitations or\nlegal issues. While many recently proposed methods for continual learning use\nsome training examples for rehearsal, their performance strongly depends on the\nnumber of stored examples. In order to improve performance of rehearsal for\ncontinual learning, especially for a small number of stored examples, we\npropose a novel way of learning a small set of synthetic examples which capture\nthe essence of a complete dataset. Instead of directly learning these synthetic\nexamples, we learn a weighted combination of shared components for each example\nthat enables a significant increase in memory efficiency. We demonstrate the\nperformance of our method on commonly used datasets and compare it to recently\nproposed related methods and baselines.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 12:18:15 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 14:39:56 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Wiewel", "Felix", ""], ["Yang", "Bin", ""]]}, {"id": "2102.09893", "submitter": "Jia Bi", "authors": "Jia Bi, Steve R.Gunn", "title": "A Variance Controlled Stochastic Method with Biased Estimation for\n  Faster Non-convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a new technique, {\\em variance controlled\nstochastic gradient} (VCSG), to improve the performance of the stochastic\nvariance reduced gradient (SVRG) algorithm. To avoid over-reducing the variance\nof gradient by SVRG, a hyper-parameter $\\lambda$ is introduced in VCSG that is\nable to control the reduced variance of SVRG. Theory shows that the\noptimization method can converge by using an unbiased gradient estimator, but\nin practice, biased gradient estimation can allow more efficient convergence to\nthe vicinity since an unbiased approach is computationally more expensive.\n$\\lambda$ also has the effect of balancing the trade-off between unbiased and\nbiased estimations. Secondly, to minimize the number of full gradient\ncalculations in SVRG, a variance-bounded batch is introduced to reduce the\nnumber of gradient calculations required in each iteration. For smooth\nnon-convex functions, the proposed algorithm converges to an approximate\nfirst-order stationary point (i.e.\n$\\mathbb{E}\\|\\nabla{f}(x)\\|^{2}\\leq\\epsilon$) within\n$\\mathcal{O}(min\\{1/\\epsilon^{3/2},n^{1/4}/\\epsilon\\})$ number of stochastic\ngradient evaluations, which improves the leading gradient complexity of\nstochastic gradient-based method SCS\n$(\\mathcal{O}(min\\{1/\\epsilon^{5/3},n^{2/3}/\\epsilon\\})$. It is shown\ntheoretically and experimentally that VCSG can be deployed to improve\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 12:22:56 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bi", "Jia", ""], ["Gunn", "Steve R.", ""]]}, {"id": "2102.09923", "submitter": "Zijian Wang", "authors": "Zijian Wang, Hao Wang, Xiangfeng Luo, Jianqi Gao", "title": "Back to Prior Knowledge: Joint Event Causality Extraction via\n  Convolutional Semantic Infusion", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Joint event and causality extraction is a challenging yet essential task in\ninformation retrieval and data mining. Recently, pre-trained language models\n(e.g., BERT) yield state-of-the-art results and dominate in a variety of NLP\ntasks. However, these models are incapable of imposing external knowledge in\ndomain-specific extraction. Considering the prior knowledge of frequent n-grams\nthat represent cause/effect events may benefit both event and causality\nextraction, in this paper, we propose convolutional knowledge infusion for\nfrequent n-grams with different windows of length within a joint extraction\nframework. Knowledge infusion during convolutional filter initialization not\nonly helps the model capture both intra-event (i.e., features in an event\ncluster) and inter-event (i.e., associations across event clusters) features\nbut also boosts training convergence. Experimental results on the benchmark\ndatasets show that our model significantly outperforms the strong BERT+CSNN\nbaseline.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 13:31:46 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Wang", "Zijian", ""], ["Wang", "Hao", ""], ["Luo", "Xiangfeng", ""], ["Gao", "Jianqi", ""]]}, {"id": "2102.09949", "submitter": "Alexander Chunikhin", "authors": "Alexander Chunikhin", "title": "Fundamentals of Semantic Numeration Systems. Can the Context be\n  Calculated?", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "PIBNASU-2020-12/2", "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is the first to propose the concept of a semantic numeration system\n(SNS) as a certain class of context-based numeration methods. The development\nof the SNS concept required the introduction of fundamentally new concepts such\nas a cardinal abstract entity, a cardinal semantic operator, a cardinal\nabstract object, a numeration space. The main attention is paid to the key\nelements of semantic numeration systems - cardinal semantic operators. A\nclassification of semantic numeration systems is given.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 21:54:59 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 15:06:49 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chunikhin", "Alexander", ""]]}, {"id": "2102.09954", "submitter": "Thanh Pham Dinh", "authors": "Huynh Thi Thanh Binh, Ta Bao Thang, Nguyen Duc Thai, Pham Dinh Thanh", "title": "A bi-level encoding scheme for the clustered shortest-path tree problem\n  in multifactorial optimization", "comments": "36 pages, 13 figures, 13 tables", "journal-ref": null, "doi": "10.1016/j.engappai.2021.104187", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Clustered Shortest-Path Tree Problem (CluSPT) plays an important role in\nvarious types of optimization problems in real-life. Recently, some\nMultifactorial Evolutionary Algorithm (MFEA) have been introduced to deal with\nthe CluSPT, however these researches still have some shortcomings such as\nevolution operators only perform on complete graphs, huge resource consumption\nfor finding the solution on large search spaces. To overcome these limitations,\nthis paper describes a MFEA-based approach to solve the CluSPT. The proposed\nalgorithm utilizes Dijkstra's algorithm to construct the spanning trees in\nclusters while using evolutionary operators for building the spanning tree\nconnecting clusters. This approach takes advantage of both exact and\napproximate algorithms so it enables the algorithm to function efficiently on\ncomplete and sparse graphs alike. Furthermore, evolutionary operators such as\nindividual encoding and decoding methods are also designed with great\nconsideration regarding performance and memory usage. We have included a proof\non the repairing method's efficacy in ensuring all solutions are valid. We have\nconducted tests on various types of Euclidean instances to assess the\neffectiveness of the proposed algorithm and methods. Experiment results point\nout the effectiveness of the proposed algorithm existing heuristic algorithms\nin most of the test cases. The impact of the proposed MFEA was analyzed and a\npossible influential factor that may be useful for further study was also\npointed out.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:36:07 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Binh", "Huynh Thi Thanh", ""], ["Thang", "Ta Bao", ""], ["Thai", "Nguyen Duc", ""], ["Thanh", "Pham Dinh", ""]]}, {"id": "2102.09972", "submitter": "Noam Razin", "authors": "Noam Razin, Asaf Maman, Nadav Cohen", "title": "Implicit Regularization in Tensor Factorization", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts to unravel the mystery of implicit regularization in deep\nlearning have led to a theoretical focus on matrix factorization -- matrix\ncompletion via linear neural network. As a step further towards practical deep\nlearning, we provide the first theoretical analysis of implicit regularization\nin tensor factorization -- tensor completion via certain type of non-linear\nneural network. We circumvent the notorious difficulty of tensor problems by\nadopting a dynamical systems perspective, and characterizing the evolution\ninduced by gradient descent. The characterization suggests a form of greedy low\ntensor rank search, which we rigorously prove under certain conditions, and\nempirically demonstrate under others. Motivated by tensor rank capturing the\nimplicit regularization of a non-linear neural network, we empirically explore\nit as a measure of complexity, and find that it captures the essence of\ndatasets on which neural networks generalize. This leads us to believe that\ntensor rank may pave way to explaining both implicit regularization in deep\nlearning, and the properties of real-world data translating this implicit\nregularization to generalization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 15:10:26 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:21:46 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 17:16:17 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Razin", "Noam", ""], ["Maman", "Asaf", ""], ["Cohen", "Nadav", ""]]}, {"id": "2102.10012", "submitter": "Paul Weng", "authors": "Ruibin Bai and Xinan Chen and Zhi-Long Chen and Tianxiang Cui and\n  Shuhui Gong and Wentao He and Xiaoping Jiang and Huan Jin and Jiahuan Jin and\n  Graham Kendall and Jiawei Li and Zheng Lu and Jianfeng Ren and Paul Weng and\n  Ning Xue and Huayan Zhang", "title": "Analytics and Machine Learning in Vehicle Routing Research", "comments": "Submitted to International Journal of Production Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vehicle Routing Problem (VRP) is one of the most intensively studied\ncombinatorial optimisation problems for which numerous models and algorithms\nhave been proposed. To tackle the complexities, uncertainties and dynamics\ninvolved in real-world VRP applications, Machine Learning (ML) methods have\nbeen used in combination with analytical approaches to enhance problem\nformulations and algorithmic performance across different problem solving\nscenarios. However, the relevant papers are scattered in several traditional\nresearch fields with very different, sometimes confusing, terminologies. This\npaper presents a first, comprehensive review of hybrid methods that combine\nanalytical techniques with ML tools in addressing VRP problems. Specifically,\nwe review the emerging research streams on ML-assisted VRP modelling and\nML-assisted VRP optimisation. We conclude that ML can be beneficial in\nenhancing VRP modelling, and improving the performance of algorithms for both\nonline and offline VRP optimisations. Finally, challenges and future\nopportunities of VRP research are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:26:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bai", "Ruibin", ""], ["Chen", "Xinan", ""], ["Chen", "Zhi-Long", ""], ["Cui", "Tianxiang", ""], ["Gong", "Shuhui", ""], ["He", "Wentao", ""], ["Jiang", "Xiaoping", ""], ["Jin", "Huan", ""], ["Jin", "Jiahuan", ""], ["Kendall", "Graham", ""], ["Li", "Jiawei", ""], ["Lu", "Zheng", ""], ["Ren", "Jianfeng", ""], ["Weng", "Paul", ""], ["Xue", "Ning", ""], ["Zhang", "Huayan", ""]]}, {"id": "2102.10015", "submitter": "Daniel Larsson", "authors": "Daniel T. Larsson, Dipankar Maity, Panagiotis Tsiotras", "title": "Information-Theoretic Abstractions for Resource-Constrained Agents via\n  Mixed-Integer Linear Programming", "comments": null, "journal-ref": "2021 Proceedings of the Workshop on Computation-Aware Algorithmic\n  Design for Cyber-Physical Systems", "doi": "10.1145/3457335.3461704", "report-no": null, "categories": "cs.RO cs.AI cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a mixed-integer linear programming formulation for the problem\nof obtaining task-relevant, multi-resolution, graph abstractions for\nresource-constrained agents is presented. The formulation leverages concepts\nfrom information-theoretic signal compression, specifically the information\nbottleneck (IB) method, to pose a graph abstraction problem as an optimal\nencoder search over the space of multi-resolution trees. The abstractions\nemerge in a task-relevant manner as a function of agent information-processing\nconstraints, and are not provided to the system a priori. We detail our\nformulation and show how the problem can be realized as an integer linear\nprogram. A non-trivial numerical example is presented to demonstrate the\nutility in employing our approach to obtain hierarchical tree abstractions for\nresource-limited agents.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:34:47 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Larsson", "Daniel T.", ""], ["Maity", "Dipankar", ""], ["Tsiotras", "Panagiotis", ""]]}, {"id": "2102.10021", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher Buckley", "title": "Neural Kalman Filtering", "comments": "17-02-21 initial upload; 29-04-21 minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kalman filter is a fundamental filtering algorithm that fuses noisy\nsensory data, a previous state estimate, and a dynamics model to produce a\nprincipled estimate of the current state. It assumes, and is optimal for,\nlinear models and white Gaussian noise. Due to its relative simplicity and\ngeneral effectiveness, the Kalman filter is widely used in engineering\napplications. Since many sensory problems the brain faces are, at their core,\nfiltering problems, it is possible that the brain possesses neural circuitry\nthat implements equivalent computations to the Kalman filter. The standard\napproach to Kalman filtering requires complex matrix computations that are\nunlikely to be directly implementable in neural circuits. In this paper, we\nshow that a gradient-descent approximation to the Kalman filter requires only\nlocal computations with variance weighted prediction errors. Moreover, we show\nthat it is possible under the same scheme to adaptively learn the dynamics\nmodel with a learning rule that corresponds directly to Hebbian plasticity. We\ndemonstrate the performance of our method on a simple Kalman filtering task,\nand propose a neural implementation of the required equations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:43:15 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 11:30:37 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher", ""]]}, {"id": "2102.10034", "submitter": "Nicolas Duczek", "authors": "Nicolas Duczek, Matthias Kerzel, Stefan Wermter", "title": "Continual Learning from Synthetic Data for a Humanoid Exercise Robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to detect and correct physical exercises, a Grow-When-Required\nNetwork (GWR) with recurrent connections, episodic memory and a novel subnode\nmechanism is developed in order to learn spatiotemporal relationships of body\nmovements and poses. Once an exercise is performed, the information of pose and\nmovement per frame is stored in the GWR. For every frame, the current pose and\nmotion pair is compared against a predicted output of the GWR, allowing for\nfeedback not only on the pose but also on the velocity of the motion. In a\npractical scenario, a physical exercise is performed by an expert like a\nphysiotherapist and then used as a reference for a humanoid robot like Pepper\nto give feedback on a patient's execution of the same exercise. This approach,\nhowever, comes with two challenges. First, the distance from the humanoid robot\nand the position of the user in the camera's view of the humanoid robot have to\nbe considered by the GWR as well, requiring a robustness against the user's\npositioning in the field of view of the humanoid robot. Second, since both the\npose and motion are dependent on the body measurements of the original\nperformer, the expert's exercise cannot be easily used as a reference. This\npaper tackles the first challenge by designing an architecture that allows for\ntolerances in translation and rotations regarding the center of the field of\nview. For the second challenge, we allow the GWR to grow online on incremental\ndata. For evaluation, we created a novel exercise dataset with virtual avatars\ncalled the Virtual-Squat dataset. Overall, we claim that our novel architecture\nbased on the GWR can use a learned exercise reference for different body\nvariations through continual online learning, while preventing catastrophic\nforgetting, enabling for an engaging long-term human-robot interaction with a\nhumanoid robot.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 17:05:25 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Duczek", "Nicolas", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "2102.10050", "submitter": "David Leslie", "authors": "David Leslie", "title": "The Arc of the Data Scientific Universe", "comments": "43 pages", "journal-ref": "Harvard Data Science Review (Winter 2021)", "doi": "10.1162/99608f92.938a18d7", "report-no": null, "categories": "physics.hist-ph cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper I explore the scaffolding of normative assumptions that\nsupports Sabina Leonelli's implicit appeal to the values of epistemic integrity\nand the global public good that conjointly animate the ethos of responsible and\nsustainable data work in the context of COVID-19. Drawing primarily on the\nwritings of sociologist Robert K. Merton, the thinkers of the Vienna Circle,\nand Charles Sanders Peirce, I make some of these assumptions explicit by\ntelling a longer story about the evolution of social thinking about the\nnormative structure of science from Merton's articulation of his well-known\nnorms (those of universalism, communism, organized skepticism, and\ndisinterestedness) to the present. I show that while Merton's norms and his\nintertwinement of these with the underlying mechanisms of democratic order\nprovide us with an especially good starting point to explore and clarify the\ncommitments and values of science, Leonelli's broader, more context-responsive,\nand more holistic vision of the epistemic integrity of data scientific\nunderstanding, and her discernment of the global and biospheric scope of its\nmoral-practical reach, move beyond Merton's schema in ways that effectively\ndraw upon important critiques. Stepping past Merton, I argue that a combination\nof situated universalism, methodological pluralism, strong objectivity, and\nunbounded communalism must guide the responsible and sustainable data work of\nthe future.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 13:29:58 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Leslie", "David", ""]]}, {"id": "2102.10052", "submitter": "Hao-Yuan Chang", "authors": "Hao-Yuan Chang (University of California, Los Angeles)", "title": "A Projection Algorithm for the Unitary Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unitary neural networks are promising alternatives for solving the exploding\nand vanishing activation/gradient problem without the need for explicit\nnormalization that reduces the inference speed. However, they often require\nlonger training time due to the additional unitary constraints on their weight\nmatrices. Here we show a novel algorithm using a backpropagation technique with\nLie algebra for computing approximated unitary weights from their pre-trained,\nnon-unitary counterparts. The unitary networks initialized with these\napproximations can reach the desired accuracies much faster, mitigating their\ntraining time penalties while maintaining inference speedups. Our approach will\nbe instrumental in the adaptation of unitary networks, especially for those\nneural architectures where pre-trained weights are freely available.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 17:33:17 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Chang", "Hao-Yuan", "", "University of California, Los Angeles"]]}, {"id": "2102.10062", "submitter": "Stephen Bonner", "authors": "Stephen Bonner and Ian P Barrett and Cheng Ye and Rowan Swiers and Ola\n  Engkvist and Andreas Bender and Charles Tapley Hoyt and William Hamilton", "title": "A Review of Biomedical Datasets Relating to Drug Discovery: A Knowledge\n  Graph Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery and development is an extremely complex process, with high\nattrition contributing to the costs of delivering new medicines to patients.\nRecently, various machine learning approaches have been proposed and\ninvestigated to help improve the effectiveness and speed of multiple stages of\nthe drug discovery pipeline. Among these techniques, it is especially those\nusing Knowledge Graphs that are proving to have considerable promise across a\nrange of tasks, including drug repurposing, drug toxicity prediction and target\ngene-disease prioritisation. In such a knowledge graph-based representation of\ndrug discovery domains, crucial elements including genes, diseases and drugs\nare represented as entities or vertices, whilst relationships or edges between\nthem indicate some level of interaction. For example, an edge between a disease\nand drug entity might represent a successful clinical trial, or an edge between\ntwo drug entities could indicate a potentially harmful interaction.\n  In order to construct high-quality and ultimately informative knowledge\ngraphs however, suitable data and information is of course required. In this\nreview, we detail publicly available primary data sources containing\ninformation suitable for use in constructing various drug discovery focused\nknowledge graphs. We aim to help guide machine learning and knowledge graph\npractitioners who are interested in applying new techniques to the drug\ndiscovery field, but who may be unfamiliar with the relevant data sources.\nOverall we hope this review will help motivate more machine learning\nresearchers to explore combining knowledge graphs and machine learning to help\nsolve key and emerging questions in the drug discovery domain.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 17:49:38 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 15:26:09 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 10:28:50 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bonner", "Stephen", ""], ["Barrett", "Ian P", ""], ["Ye", "Cheng", ""], ["Swiers", "Rowan", ""], ["Engkvist", "Ola", ""], ["Bender", "Andreas", ""], ["Hoyt", "Charles Tapley", ""], ["Hamilton", "William", ""]]}, {"id": "2102.10075", "submitter": "Tooba Tehreem", "authors": "Tooba Tehreem (Hira Tahir National University of Computer and Emerging\n  Sciences Islamabad, Pakistan)", "title": "Sentiment Analysis for YouTube Comments in Roman Urdu", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sentiment analysis is a vast area in the Machine learning domain. A lot of\nwork is done on datasets and their analysis of the English Language. In\nPakistan, a huge amount of data is in roman Urdu language, it is scattered all\nover the social sites including Twitter, YouTube, Facebook and similar\napplications. In this study the focus domain of dataset gathering is YouTube\ncomments. The Dataset contains the comments of people over different Pakistani\ndramas and TV shows. The Dataset contains multi-class classification that is\ngrouped The comments into positive, negative and neutral sentiment. In this\nStudy comparative analysis is done for five supervised learning Algorithms\nincluding linear regression, SVM, KNN, Multi layer Perceptron and Na\\\"ive Bayes\nclassifier. Accuracy, recall, precision and F-measure are used for measuring\nperformance. Results show that accuracy of SVM is 64 percent, which is better\nthan the rest of the list.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:15:52 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Tehreem", "Tooba", "", "Hira Tahir National University of Computer and Emerging\n  Sciences Islamabad, Pakistan"]]}, {"id": "2102.10084", "submitter": "Debjoy Saha", "authors": "Debjoy Saha, Naman Paharia, Debajit Chakraborty, Punyajoy Saha,\n  Animesh Mukherjee", "title": "Hate-Alert@DravidianLangTech-EACL2021: Ensembling strategies for\n  Transformer-based Offensive language Detection", "comments": "6 pages, 1 figure, 3 tables, code available at\n  https://github.com/Debjoy10/Hate-Alert-DravidianLangTech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media often acts as breeding grounds for different forms of offensive\ncontent. For low resource languages like Tamil, the situation is more complex\ndue to the poor performance of multilingual or language-specific models and\nlack of proper benchmark datasets. Based on this shared task, Offensive\nLanguage Identification in Dravidian Languages at EACL 2021, we present an\nexhaustive exploration of different transformer models, We also provide a\ngenetic algorithm technique for ensembling different models. Our ensembled\nmodels trained separately for each language secured the first position in\nTamil, the second position in Kannada, and the first position in Malayalam\nsub-tasks. The models and codes are provided.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:35:38 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Saha", "Debjoy", ""], ["Paharia", "Naman", ""], ["Chakraborty", "Debajit", ""], ["Saha", "Punyajoy", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2102.10130", "submitter": "Hamza Ali", "authors": "Abdul Azeem Sikander, Hamza Ali", "title": "Image Classification using CNN for Traffic Signs in Pakistan", "comments": "Image classification, Convolutional Neural networks, Traffic Signs,\n  Pakistan, CNN, Traffic Signs in Pakistan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The autonomous automotive industry is one of the largest and most\nconventional projects worldwide, with many technology companies effectively\ndesigning and orienting their products towards automobile safety and accuracy.\nThese products are performing very well over the roads in developed countries.\nBut can fail in the first minute in an underdeveloped country because there is\nmuch difference between a developed country environment and an underdeveloped\ncountry environment. The following study proposed to train these Artificial\nintelligence models in environment space in an underdeveloped country like\nPakistan. The proposed approach on image classification uses convolutional\nneural networks for image classification for the model. For model pre-training\nGerman traffic signs data set was selected then fine-tuned on Pakistan's\ndataset. The experimental setup showed the best results and accuracy from the\npreviously conducted experiments. In this work to increase the accuracy, more\ndataset was collected to increase the size of images in every class in the data\nset. In the future, a low number of classes are required to be further\nincreased where more images for traffic signs are required to be collected to\nget more accuracy on the training of the model over traffic signs of Pakistan's\nmost used and popular roads motorway and national highway, whose traffic signs\ncolor, size, and shapes are different from common traffic signs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 19:16:22 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sikander", "Abdul Azeem", ""], ["Ali", "Hamza", ""]]}, {"id": "2102.10242", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Bo Dai, Mengjiao Yang, Tuo Zhao, Wei Wei", "title": "Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy\n  Evaluation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable automatic evaluation of dialogue systems under an interactive\nenvironment has long been overdue. An ideal environment for evaluating dialog\nsystems, also known as the Turing test, needs to involve human interaction,\nwhich is usually not affordable for large-scale experiments. Though researchers\nhave attempted to use metrics (e.g., perplexity, BLEU) in language generation\ntasks or some model-based reinforcement learning methods (e.g., self-play\nevaluation) for automatic evaluation, these methods only show a very weak\ncorrelation with the actual human evaluation in practice. To bridge such a gap,\nwe propose a new framework named ENIGMA for estimating human evaluation scores\nbased on recent advances of off-policy evaluation in reinforcement learning.\nENIGMA only requires a handful of pre-collected experience data, and therefore\ndoes not involve human interaction with the target policy during the\nevaluation, making automatic evaluations feasible. More importantly, ENIGMA is\nmodel-free and agnostic to the behavior policies for collecting the experience\ndata (see details in Section 2), which significantly alleviates the technical\ndifficulties of modeling complex dialogue environments and human behaviors. Our\nexperiments show that ENIGMA significantly outperforms existing methods in\nterms of correlation with human evaluation scores.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:29:20 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 22:23:31 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Jiang", "Haoming", ""], ["Dai", "Bo", ""], ["Yang", "Mengjiao", ""], ["Zhao", "Tuo", ""], ["Wei", "Wei", ""]]}, {"id": "2102.10246", "submitter": "Thuy Vu", "authors": "Thuy Vu and Alessandro Moschitti", "title": "CDA: a Cost Efficient Content-based Multilingual Web Document Aligner", "comments": null, "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Content-based Document Alignment approach (CDA), an efficient\nmethod to align multilingual web documents based on content in creating\nparallel training data for machine translation (MT) systems operating at the\nindustrial level. CDA works in two steps: (i) projecting documents of a web\ndomain to a shared multilingual space; then (ii) aligning them based on the\nsimilarity of their representations in such space. We leverage lexical\ntranslation models to build vector representations using TF-IDF. CDA achieves\nperformance comparable with state-of-the-art systems in the WMT-16 Bilingual\nDocument Alignment Shared Task benchmark while operating in multilingual space.\nBesides, we created two web-scale datasets to examine the robustness of CDA in\nan industrial setting involving up to 28 languages and millions of documents.\nThe experiments show that CDA is robust, cost-effective, and is significantly\nsuperior in (i) processing large and noisy web data and (ii) scaling to new and\nlow-resourced languages.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:37:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vu", "Thuy", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2102.10247", "submitter": "Michael Green", "authors": "Michael Cerny Green, Ahmed Khalifa, Philip Bontrager, Rodrigo Canaan\n  and Julian Togelius", "title": "Game Mechanic Alignment Theory and Discovery", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new concept called Game Mechanic Alignment theory as a way to\norganize game mechanics through the lens of environmental rewards and intrinsic\nplayer motivations. By disentangling player and environmental influences,\nmechanics may be better identified for use in an automated tutorial generation\nsystem, which could tailor tutorials for a particular playstyle or player.\nWithin, we apply this theory to several well-known games to demonstrate how\ndesigners can benefit from it, we describe a methodology for how to estimate\nmechanic alignment, and we apply this methodology on multiple games in the\nGVGAI framework. We discuss how effectively this estimation captures\nintrinsic/extrinsic rewards and how our theory could be used as an alternative\nto critical mechanic discovery methods for tutorial generation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:41:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""]]}, {"id": "2102.10249", "submitter": "Benfeng Xu", "authors": "Benfeng Xu, Quan Wang, Yajuan Lyu, Yong Zhu, Zhendong Mao", "title": "Entity Structure Within and Throughout: Modeling Mention Dependencies\n  for Document-Level Relation Extraction", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entities, as the essential elements in relation extraction tasks, exhibit\ncertain structure. In this work, we formulate such structure as distinctive\ndependencies between mention pairs. We then propose SSAN, which incorporates\nthese structural dependencies within the standard self-attention mechanism and\nthroughout the overall encoding stage. Specifically, we design two alternative\ntransformation modules inside each self-attention building block to produce\nattentive biases so as to adaptively regularize its attention flow. Our\nexperiments demonstrate the usefulness of the proposed entity structure and the\neffectiveness of SSAN. It significantly outperforms competitive baselines,\nachieving new state-of-the-art results on three popular document-level relation\nextraction datasets. We further provide ablation and visualization to show how\nthe entity structure guides the model for better relation extraction. Our code\nis publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:47:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Xu", "Benfeng", ""], ["Wang", "Quan", ""], ["Lyu", "Yajuan", ""], ["Zhu", "Yong", ""], ["Mao", "Zhendong", ""]]}, {"id": "2102.10275", "submitter": "Atharva Kulkarni", "authors": "Atharva Kulkarni, Amey Hengle, Rutuja Udyawar", "title": "An Attention Ensemble Approach for Efficient Text Classification of\n  Indian Languages", "comments": "Paper accepted and presented at the 17th International Conference on\n  Natural Language Processing (ICON 2020) TechDoFication Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent surge of complex attention-based deep learning architectures has\nled to extraordinary results in various downstream NLP tasks in the English\nlanguage. However, such research for resource-constrained and morphologically\nrich Indian vernacular languages has been relatively limited. This paper\nproffers team SPPU\\_AKAH's solution for the TechDOfication 2020 subtask-1f:\nwhich focuses on the coarse-grained technical domain identification of short\ntext documents in Marathi, a Devanagari script-based Indian language. Availing\nthe large dataset at hand, a hybrid CNN-BiLSTM attention ensemble model is\nproposed that competently combines the intermediate sentence representations\ngenerated by the convolutional neural network and the bidirectional long\nshort-term memory, leading to efficient text classification. Experimental\nresults show that the proposed model outperforms various baseline machine\nlearning and deep learning models in the given task, giving the best validation\naccuracy of 89.57\\% and f1-score of 0.8875. Furthermore, the solution resulted\nin the best system submission for this subtask, giving a test accuracy of\n64.26\\% and f1-score of 0.6157, transcending the performances of other teams as\nwell as the baseline system given by the organizers of the shared task.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 07:31:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kulkarni", "Atharva", ""], ["Hengle", "Amey", ""], ["Udyawar", "Rutuja", ""]]}, {"id": "2102.10284", "submitter": "Zhenguo Nie", "authors": "Chenglin Pan, Kuan Yan, Xiao Liu, Yanjie Chen, Yanyan Luo, Xiaoming\n  Li, Zhenguo Nie, Xinjun Liu", "title": "Artificial Intelligence Enhanced Rapid and Efficient Diagnosis of\n  Mycoplasma Pneumoniae Pneumonia in Children Patients", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence methods have been increasingly turning into a\npotentially powerful tool in the diagnosis and management of diseases. In this\nstudy, we utilized logistic regression (LR), decision tree (DT), gradient\nboosted decision tree (GBDT), support vector machine (SVM), and multilayer\nperceptron (MLP) as machine learning models to rapidly diagnose the mycoplasma\npneumoniae pneumonia (MPP) in children patients. The classification task was\ncarried out after applying the preprocessing procedure to the MPP dataset. The\nmost efficient results are obtained by GBDT. It provides the best performance\nwith an accuracy of 93.7%. In contrast to standard raw feature weighting, the\nfeature importance takes the underlying correlation structure of the features\ninto account. The most crucial feature of GBDT is the \"pulmonary infiltrates\nrange\" with a score of 0.5925, followed by \"cough\" (0.0953) and \"pleural\neffusion\" (0.0492). We publicly share our full implementation with the dataset\nand trained models at https://github.com/zhenguonie/2021_AI4MPP.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 08:14:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Pan", "Chenglin", ""], ["Yan", "Kuan", ""], ["Liu", "Xiao", ""], ["Chen", "Yanjie", ""], ["Luo", "Yanyan", ""], ["Li", "Xiaoming", ""], ["Nie", "Zhenguo", ""], ["Liu", "Xinjun", ""]]}, {"id": "2102.10296", "submitter": "Seyedali Meghdadi Mr", "authors": "Seyedali Meghdadi, Guido Tack, Ariel Liebman, Nicolas Langren\\'e,\n  Christoph Bergmeir", "title": "Versatile and Robust Transient Stability Assessment via Instance\n  Transfer Learning", "comments": "Accepted at the 2021 IEEE PES General Meeting, July 25-29 2020,\n  Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To support N-1 pre-fault transient stability assessment, this paper\nintroduces a new data collection method in a data-driven algorithm\nincorporating the knowledge of power system dynamics. The domain knowledge on\nhow the disturbance effect will propagate from the fault location to the rest\nof the network is leveraged to recognise the dominant conditions that determine\nthe stability of a system. Accordingly, we introduce a new concept called\nFault-Affected Area, which provides crucial information regarding the unstable\nregion of operation. This information is embedded in an augmented dataset to\ntrain an ensemble model using an instance transfer learning framework. The test\nresults on the IEEE 39-bus system verify that this model can accurately predict\nthe stability of previously unseen operational scenarios while reducing the\nrisk of false prediction of unstable instances compared to standard approaches.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 09:10:29 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Meghdadi", "Seyedali", ""], ["Tack", "Guido", ""], ["Liebman", "Ariel", ""], ["Langren\u00e9", "Nicolas", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2102.10323", "submitter": "Phuong Nguyen", "authors": "Ludovico Iovino, Phuong T. Nguyen, Amleto Di Salle, Francesco Gallo,\n  Michele Flammini", "title": "Unavailable Transit Feed Specification: Making it Available with\n  Recurrent Neural Networks", "comments": "11 pages, 8 figures, accepted for publication by IEEE Transactions on\n  Intelligent Transportation Systems (T-ITS)", "journal-ref": null, "doi": "10.1109/TITS.2021.3053373", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Studies on public transportation in Europe suggest that European inhabitants\nuse buses in ca. 56% of all public transport travels. One of the critical\nfactors affecting such a percentage and more, in general, the demand for public\ntransport services, with an increasing reluctance to use them, is their\nquality. End-users can perceive quality from various perspectives, including\nthe availability of information, i.e., the access to details about the transit\nand the provided services. The approach proposed in this paper, using\ninnovative methodologies resorting on data mining and machine learning\ntechniques, aims to make available the unavailable data about public transport.\nIn particular, by mining GPS traces, we manage to reconstruct the complete\ntransit graph of public transport. The approach has been successfully validated\non a real dataset collected from the local bus system of the city of L'Aquila\n(Italy). The experimental results demonstrate that the proposed approach and\nimplemented framework are both effective and efficient, thus being ready for\ndeployment.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 12:17:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Iovino", "Ludovico", ""], ["Nguyen", "Phuong T.", ""], ["Di Salle", "Amleto", ""], ["Gallo", "Francesco", ""], ["Flammini", "Michele", ""]]}, {"id": "2102.10330", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu, Rob Fergus", "title": "Decoupling Value and Policy for Generalization in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard deep reinforcement learning algorithms use a shared representation\nfor the policy and value function, especially when training directly from\nimages. However, we argue that more information is needed to accurately\nestimate the value function than to learn the optimal policy. Consequently, the\nuse of a shared representation for the policy and value function can lead to\noverfitting. To alleviate this problem, we propose two approaches which are\ncombined to create IDAAC: Invariant Decoupled Advantage Actor-Critic. First,\nIDAAC decouples the optimization of the policy and value function, using\nseparate networks to model them. Second, it introduces an auxiliary loss which\nencourages the representation to be invariant to task-irrelevant properties of\nthe environment. IDAAC shows good generalization to unseen environments,\nachieving a new state-of-the-art on the Procgen benchmark and outperforming\npopular methods on DeepMind Control tasks with distractors. Our implementation\nis available at https://github.com/rraileanu/idaac.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 12:40:11 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:10:04 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Raileanu", "Roberta", ""], ["Fergus", "Rob", ""]]}, {"id": "2102.10336", "submitter": "Eltayeb Ahmed", "authors": "Eltayeb Ahmed, Anton Bakhtin, Laurens van der Maaten, Rohit Girdhar", "title": "Physical Reasoning Using Dynamics-Aware Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common approach to solving physical-reasoning tasks is to train a value\nlearner on example tasks. A limitation of such an approach is it requires\nlearning about object dynamics solely from reward values assigned to the final\nstate of a rollout of the environment. This study aims to address this\nlimitation by augmenting the reward value with additional supervisory signals\nabout object dynamics. Specifically,we define a distance measure between the\ntrajectory of two target objects, and use this distance measure to characterize\nthe similarity of two environment rollouts.We train the model to correctly rank\nrollouts according to this measure in addition to predicting the correct\nreward. Empirically, we find that this approach leads to substantial\nperformance improvements on the PHYRE benchmark for physical reasoning: our\napproach obtains a new state-of-the-art on that benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 12:56:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ahmed", "Eltayeb", ""], ["Bakhtin", "Anton", ""], ["van der Maaten", "Laurens", ""], ["Girdhar", "Rohit", ""]]}, {"id": "2102.10342", "submitter": "Jasper De Bock", "authors": "Jasper De Bock and Gert de Cooman", "title": "On a notion of independence proposed by Teddy Seidenfeld", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Teddy Seidenfeld has been arguing for quite a long time that binary\npreference models are not powerful enough to deal with a number of crucial\naspects of imprecision and indeterminacy in uncertain inference and decision\nmaking. It is at his insistence that we initiated our study of so-called sets\nof desirable option sets, which we have argued elsewhere provides an elegant\nand powerful approach to dealing with general, binary as well as non-binary,\ndecision-making under uncertainty. We use this approach here to explore an\ninteresting notion of irrelevance (and independence), first suggested by\nSeidenfeld in an example intended as a criticism of a number of specific\ndecision methodologies based on (convex) binary preferences. We show that the\nconsequences of making such an irrelevance or independence assessment are very\nstrong, and might be used to argue for the use of so-called mixing choice\nfunctions, and E-admissibility as the resulting decision scheme.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:15:28 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["De Bock", "Jasper", ""], ["de Cooman", "Gert", ""]]}, {"id": "2102.10362", "submitter": "Thomas Spooner", "authors": "Thomas Spooner, Nelson Vadori, Sumitra Ganesh", "title": "Causal Policy Gradients: Leveraging Structure for Efficient Learning in\n  (Factored) MOMDPs", "comments": "19 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods can solve complex tasks but often fail when the\ndimensionality of the action-space or objective multiplicity grow very large.\nThis occurs, in part, because the variance on score-based gradient estimators\nscales quadratically. In this paper, we address this problem through a causal\nbaseline which exploits independence structure encoded in a novel action-target\ninfluence network. Causal policy gradients (CPGs), which follow, provide a\ncommon framework for analysing key state-of-the-art algorithms, are shown to\ngeneralise traditional policy gradients, and yield a principled way of\nincorporating prior knowledge of a problem domain's generative processes. We\nprovide an analysis of the proposed estimator and identify the conditions under\nwhich variance is reduced. The algorithmic aspects of CPGs are discussed,\nincluding optimal policy factorisation, as characterised by minimum biclique\ncoverings, and the implications for the bias-variance trade-off of incorrectly\nspecifying the network. Finally, we demonstrate the performance advantages of\nour algorithm on large-scale bandit and traffic intersection problems,\nproviding a novel contribution to the latter in the form of a spatio-causal\napproximation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 14:51:12 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 09:45:16 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Spooner", "Thomas", ""], ["Vadori", "Nelson", ""], ["Ganesh", "Sumitra", ""]]}, {"id": "2102.10376", "submitter": "Gerardo Roa Dabike", "authors": "Gerardo Roa Dabike, Jon Barker", "title": "The Use of Voice Source Features for Sung Speech Recognition", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we ask whether vocal source features (pitch, shimmer, jitter,\netc) can improve the performance of automatic sung speech recognition, arguing\nthat conclusions previously drawn from spoken speech studies may not be valid\nin the sung speech domain. We first use a parallel singing/speaking corpus\n(NUS-48E) to illustrate differences in sung vs spoken voicing characteristics\nincluding pitch range, syllables duration, vibrato, jitter and shimmer. We then\nuse this analysis to inform speech recognition experiments on the sung speech\nDSing corpus, using a state of the art acoustic model and augmenting\nconventional features with various voice source parameters. Experiments are run\nwith three standard (increasingly large) training sets, DSing1 (15.1 hours),\nDSing3 (44.7 hours) and DSing30 (149.1 hours). Pitch combined with degree of\nvoicing produces a significant decrease in WER from 38.1% to 36.7% when\ntraining with DSing1 however smaller decreases in WER observed when training\nwith the larger more varied DSing3 and DSing30 sets were not seen to be\nstatistically significant. Voicing quality characteristics did not improve\nrecognition performance although analysis suggests that they do contribute to\nan improved discrimination between voiced/unvoiced phoneme pairs.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 15:54:26 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 16:18:28 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Dabike", "Gerardo Roa", ""], ["Barker", "Jon", ""]]}, {"id": "2102.10387", "submitter": "Nalin Chhibber", "authors": "Nalin Chhibber, Edith Law", "title": "Towards Teachable Conversational Agents", "comments": "9 Pages, 3 Figures, 2 Tables, Presented at NeurIPS 2020: Human in the\n  Loop Dialogue Systems Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The traditional process of building interactive machine learning systems can\nbe viewed as a teacher-learner interaction scenario where the machine-learners\nare trained by one or more human-teachers. In this work, we explore the idea of\nusing a conversational interface to investigate the interaction between\nhuman-teachers and interactive machine-learners. Specifically, we examine\nwhether teachable AI agents can reliably learn from human-teachers through\nconversational interactions, and how this learning compare with traditional\nsupervised learning algorithms. Results validate the concept of teachable\nconversational agents and highlight the factors relevant for the development of\nmachine learning systems that intend to learn from conversational interactions.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 16:56:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chhibber", "Nalin", ""], ["Law", "Edith", ""]]}, {"id": "2102.10407", "submitter": "Jun Chen", "authors": "Jun Chen, Han Guo, Kai Yi, Boyang Li, Mohamed Elhoseiny", "title": "VisualGPT: Data-efficient Adaptation of Pretrained Language Models for\n  Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to quickly learn from a small quantity oftraining data widens the\nrange of machine learning applications. In this paper, we propose a\ndata-efficient image captioning model, VisualGPT, which leverages the\nlinguistic knowledge from a large pretrained language model(LM). A crucial\nchallenge is to balance between the use of visual information in the image and\nprior linguistic knowledge acquired from pretraining. We designed a novel\nself-resurrecting encoder-decoder attention mechanism to quickly adapt the\npretrained LM as the language decoder ona small amount of in-domain training\ndata. The proposed self-resurrecting activation unit produces sparse\nactivations but has reduced susceptibility to zero gradients. We train the\nproposed model, VisualGPT, on 0.1%, 0.5% and 1% of MSCOCO and Conceptual\nCaptions training data. Under these conditions, we outperform the best baseline\nmodel by up to 10.8% CIDEr on MS COCO and upto 5.4% CIDEr on Conceptual\nCaptions. Further, Visual-GPT achieves the state-of-the-art result on IU X-ray,\na medical report generation dataset. To the best of our knowledge, this is the\nfirst work that improves data efficiency of image captioning by utilizing LM\npretrained on unimodal data. Our code is available at:\nhttps://github.com/Vision-CAIR/VisualGPT.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 18:02:42 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 18:03:11 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 07:14:40 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Jun", ""], ["Guo", "Han", ""], ["Yi", "Kai", ""], ["Li", "Boyang", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "2102.10410", "submitter": "Johar Shabbir", "authors": "Johar Shabbir, Muhammad Umair Arshad, Waseem Shahzad", "title": "NUBOT: Embedded Knowledge Graph With RASA Framework for Generating\n  Semantic Intents Responses in Roman Urdu", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of the human language is quantified by identifying intents\nand entities. Even though classification methods that rely on labeled\ninformation are often used for the comprehension of language understanding, it\nis incredibly time consuming and tedious process to generate high propensity\nsupervised datasets. In this paper, we present the generation of accurate\nintents for the corresponding Roman Urdu unstructured data and integrate this\ncorpus in RASA NLU module for intent classification. We embed knowledge graph\nwith RASA Framework to maintain the dialog history for semantic based natural\nlanguage mechanism for chatbot communication. We compare results of our work\nwith existing linguistic systems combined with semantic technologies. Minimum\naccuracy of intents generation is 64 percent of confidence and in the response\ngeneration part minimum accuracy is 82.1 percent and maximum accuracy gain is\n96.7 percent. All the scores refers to log precision, recall, and f1 measure\nfor each intents once summarized for all. Furthermore, it creates a confusion\nmatrix represents that which intents are ambiguously recognized by approach.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 18:17:21 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Shabbir", "Johar", ""], ["Arshad", "Muhammad Umair", ""], ["Shahzad", "Waseem", ""]]}, {"id": "2102.10424", "submitter": "Anastasios Kyrillidis", "authors": "Cameron R. Wolfe, Jingkang Yang, Arindam Chowdhury, Chen Dun, Artun\n  Bayer, Santiago Segarra, Anastasios Kyrillidis", "title": "GIST: Distributed Training for Large-Scale Graph Convolutional Networks", "comments": "18 pages, 4 figures, pre-print under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The graph convolutional network (GCN) is a go-to solution for machine\nlearning on graphs, but its training is notoriously difficult to scale both in\nterms of graph size and the number of model parameters. Although some work has\nexplored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we\npioneer efficient training of large-scale GCN models (i.e., ultra-wide,\noverparameterized models) with the proposal of a novel, distributed training\nframework. Our proposed training methodology, called GIST, disjointly\npartitions the parameters of a GCN model into several, smaller sub-GCNs that\nare trained independently and in parallel. In addition to being compatible with\nany GCN architecture, GIST improves model performance, scales to training on\narbitrarily large graphs, significantly decreases wall-clock training time, and\nenables the training of markedly overparameterized GCN models. Remarkably, with\nGIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which\nexceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on\nthe Amazon2M dataset.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 19:25:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 21:11:07 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 13:14:57 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wolfe", "Cameron R.", ""], ["Yang", "Jingkang", ""], ["Chowdhury", "Arindam", ""], ["Dun", "Chen", ""], ["Bayer", "Artun", ""], ["Segarra", "Santiago", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2102.10447", "submitter": "M\\'onika Farsang", "authors": "M\\'onika Farsang and Luca Szegletes", "title": "Importance of Environment Design in Reinforcement Learning: A Study of a\n  Robotic Environment", "comments": null, "journal-ref": "Proceedings of the Automation and Applied Computer Science\n  Workshop 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An in-depth understanding of the particular environment is crucial in\nreinforcement learning (RL). To address this challenge, the decision-making\nprocess of a mobile collaborative robotic assistant modeled by the Markov\ndecision process (MDP) framework is studied in this paper. The optimal\nstate-action combinations of the MDP are calculated with the non-linear Bellman\noptimality equations. This system of equations can be solved with relative ease\nby the computational power of Wolfram Mathematica, where the obtained optimal\naction-values point to the optimal policy. Unlike other RL algorithms, this\nmethodology does not approximate the optimal behavior, it gives the exact,\nexplicit solution, which provides a strong foundation for our study. With this,\nwe offer new insights into understanding the action selection mechanisms in RL\nby presenting various small modifications on the very same schema that lead to\ndifferent optimal policies.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 21:14:09 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 15:22:10 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Farsang", "M\u00f3nika", ""], ["Szegletes", "Luca", ""]]}, {"id": "2102.10454", "submitter": "Ren Wang", "authors": "Ren Wang, Kaidi Xu, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Chuang Gan,\n  Meng Wang", "title": "On Fast Adversarial Robustness Adaptation in Model-Agnostic\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-agnostic meta-learning (MAML) has emerged as one of the most successful\nmeta-learning techniques in few-shot learning. It enables us to learn a\nmeta-initialization} of model parameters (that we call meta-model) to rapidly\nadapt to new tasks using a small amount of labeled training data. Despite the\ngeneralization power of the meta-model, it remains elusive that how adversarial\nrobustness can be maintained by MAML in few-shot learning. In addition to\ngeneralization, robustness is also desired for a meta-model to defend\nadversarial examples (attacks). Toward promoting adversarial robustness in\nMAML, we first study WHEN a robustness-promoting regularization should be\nincorporated, given the fact that MAML adopts a bi-level (fine-tuning vs.\nmeta-update) learning procedure. We show that robustifying the meta-update\nstage is sufficient to make robustness adapted to the task-specific fine-tuning\nstage even if the latter uses a standard training protocol. We also make\nadditional justification on the acquired robustness adaptation by peering into\nthe interpretability of neurons' activation maps. Furthermore, we investigate\nHOW robust regularization can efficiently be designed in MAML. We propose a\ngeneral but easily-optimized robustness-regularized meta-learning framework,\nwhich allows the use of unlabeled data augmentation, fast adversarial attack\ngeneration, and computationally-light fine-tuning. In particular, we for the\nfirst time show that the auxiliary contrastive learning task can enhance the\nadversarial robustness of MAML. Finally, extensive experiments are conducted to\ndemonstrate the effectiveness of our proposed methods in robust few-shot\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 22:03:04 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Ren", ""], ["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Weng", "Tsui-Wei", ""], ["Gan", "Chuang", ""], ["Wang", "Meng", ""]]}, {"id": "2102.10456", "submitter": "M\\'onika Farsang", "authors": "M\\'onika Farsang and Luca Szegletes", "title": "Decaying Clipping Range in Proximal Policy Optimization", "comments": null, "journal-ref": "2021 IEEE 15th International Symposium on Applied Computational\n  Intelligence and Informatics (SACI), 2021, pp. 000521-000526", "doi": "10.1109/SACI51354.2021.9465602", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proximal Policy Optimization (PPO) is among the most widely used algorithms\nin reinforcement learning, which achieves state-of-the-art performance in many\nchallenging problems. The keys to its success are the reliable policy updates\nthrough the clipping mechanism and the multiple epochs of minibatch updates.\nThe aim of this research is to give new simple but effective alternatives to\nthe former. For this, we propose linearly and exponentially decaying clipping\nrange approaches throughout the training. With these, we would like to provide\nhigher exploration at the beginning and stronger restrictions at the end of the\nlearning phase. We investigate their performance in several classical control\nand locomotive robotic environments. During the analysis, we found that they\ninfluence the achieved rewards and are effective alternatives to the constant\nclipping method in many reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 22:08:05 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 15:00:37 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 07:56:35 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Farsang", "M\u00f3nika", ""], ["Szegletes", "Luca", ""]]}, {"id": "2102.10461", "submitter": "Konik Kothari", "authors": "Konik Kothari, AmirEhsan Khorashadizadeh, Maarten de Hoop, Ivan\n  Dokmani\\'c", "title": "Trumpets: Injective Flows for Inference and Inverse Problems", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose injective generative models called Trumpets that generalize\ninvertible normalizing flows. The proposed generators progressively increase\ndimension from a low-dimensional latent space. We demonstrate that Trumpets can\nbe trained orders of magnitudes faster than standard flows while yielding\nsamples of comparable or better quality. They retain many of the advantages of\nthe standard flows such as training based on maximum likelihood and a fast,\nexact inverse of the generator. Since Trumpets are injective and have fast\ninverses, they can be effectively used for downstream Bayesian inference. To\nwit, we use Trumpet priors for maximum a posteriori estimation in the context\nof image reconstruction from compressive measurements, outperforming\ncompetitive baselines in terms of reconstruction quality and speed. We then\npropose an efficient method for posterior characterization and uncertainty\nquantification with Trumpets by taking advantage of the low-dimensional latent\nspace.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 22:37:37 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kothari", "Konik", ""], ["Khorashadizadeh", "AmirEhsan", ""], ["de Hoop", "Maarten", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2102.10484", "submitter": "Pranav Rajpurkar", "authors": "Soham Gadgil, Mark Endo, Emily Wen, Andrew Y. Ng, Pranav Rajpurkar", "title": "CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps\n  for X-ray Segmentation", "comments": "Accepted to Medical Imaging with Deep Learning (MIDL) Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical image segmentation models are typically supervised by expert\nannotations at the pixel-level, which can be expensive to acquire. In this\nwork, we propose a method that combines the high quality of pixel-level expert\nannotations with the scale of coarse DNN-generated saliency maps for training\nmulti-label semantic segmentation models. We demonstrate the application of our\nsemi-supervised method, which we call CheXseg, on multi-label chest X-ray\ninterpretation. We find that CheXseg improves upon the performance (mIoU) of\nfully-supervised methods that use only pixel-level expert annotations by 9.7%\nand weakly-supervised methods that use only DNN-generated saliency maps by\n73.1%. Our best method is able to match radiologist agreement on three out of\nten pathologies and reduces the overall performance gap by 57.2% as compared to\nweakly-supervised methods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 00:47:30 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 07:02:56 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Gadgil", "Soham", ""], ["Endo", "Mark", ""], ["Wen", "Emily", ""], ["Ng", "Andrew Y.", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2102.10485", "submitter": "Massimiliano Lupo Pasini Dr.", "authors": "Massimiliano Lupo Pasini, Vittorio Gabbi, Junqi Yin, Simona Perotto,\n  Nouamane Laanait", "title": "Scalable Balanced Training of Conditional Generative Adversarial Neural\n  Networks on Image Data", "comments": null, "journal-ref": "Journal of Supercomputing, 2021", "doi": "10.1007/s11227-021-03808-2", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed approach to train deep convolutional generative\nadversarial neural network (DC-CGANs) models. Our method reduces the imbalance\nbetween generator and discriminator by partitioning the training data according\nto data labels, and enhances scalability by performing a parallel training\nwhere multiple generators are concurrently trained, each one of them focusing\non a single data label. Performance is assessed in terms of inception score and\nimage quality on MNIST, CIFAR10, CIFAR100, and ImageNet1k datasets, showing a\nsignificant improvement in comparison to state-of-the-art techniques to\ntraining DC-CGANs. Weak scaling is attained on all the four datasets using up\nto 1,000 processes and 2,000 NVIDIA V100 GPUs on the OLCF supercomputer Summit.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 00:48:19 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pasini", "Massimiliano Lupo", ""], ["Gabbi", "Vittorio", ""], ["Yin", "Junqi", ""], ["Perotto", "Simona", ""], ["Laanait", "Nouamane", ""]]}, {"id": "2102.10495", "submitter": "Rini Raju", "authors": "Shova Bhandari, Rini Raju", "title": "Social Networks Analysis to Retrieve Critical Comments on Online\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social networks are rich source of data to analyze user habits in all aspects\nof life. User's behavior is decisive component of a health system in various\ncountries. Promoting good behavior can improve the public health significantly.\nIn this work, we develop a new model for social network analysis by using text\nanalysis approach. We define each user reaction to global pandemic with\nanalyzing his online behavior. Clustering a group of online users with similar\nhabits, help to find how virus spread in different societies. Promoting the\nhealthy life style in the high risk online users of social media have\nsignificant effect on public health and reducing the effect of global pandemic.\nIn this work, we introduce a new approach to clustering habits based on user\nactivities on social media in the time of pandemic and recommend a machine\nlearning model to promote health in the online platforms.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 02:54:52 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bhandari", "Shova", ""], ["Raju", "Rini", ""]]}, {"id": "2102.10513", "submitter": "Rohan Sarkar", "authors": "Rohan Sarkar and Avinash C. Kak", "title": "CheckSoft : A Scalable Event-Driven Software Architecture for Keeping\n  Track of People and Things in People-Centric Spaces", "comments": "33 pages, 25 figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CheckSoft, a scalable event-driven software architecture for\nkeeping track of people-object interactions in people-centric applications such\nas airport checkpoint security areas, automated retail stores, smart libraries,\nand so on. The architecture works off the video data generated in real time by\na network of surveillance cameras. Although there are many different aspects to\nautomating these applications, the most difficult part of the overall problem\nis keeping track of the interactions between the people and the objects.\nCheckSoft uses finite-state-machine (FSM) based logic for keeping track of such\ninteractions which allows the system to quickly reject any false detections of\nthe interactions by the video cameras. CheckSoft is easily scalable since the\narchitecture is based on multi-processing in which a separate process is\nassigned to each human and to each \"storage container\" for the objects. A\nstorage container may be a shelf on which the objects are displayed or a bin in\nwhich the objects are stored, depending on the specific application in which\nCheckSoft is deployed.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 05:22:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sarkar", "Rohan", ""], ["Kak", "Avinash C.", ""]]}, {"id": "2102.10530", "submitter": "Kotaro Furuya", "authors": "Kotaro Furuya and Jun Ohkubo", "title": "Semi-supervised learning combining backpropagation and STDP: STDP\n  enhances learning by backpropagation with a small amount of labeled data in a\n  spiking neural network", "comments": "9 pages, 12 figures", "journal-ref": "J. Phys. Soc. Jpn. 90, 074802 (2021)", "doi": "10.7566/JPSJ.90.074802", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-supervised learning method for spiking neural networks is proposed.\nThe proposed method consists of supervised learning by backpropagation and\nsubsequent unsupervised learning by spike-timing-dependent plasticity (STDP),\nwhich is a biologically plausible learning rule. Numerical experiments show\nthat the proposed method improves the accuracy without additional labeling when\na small amount of labeled data is used. This feature has not been achieved by\nexisting semi-supervised learning methods of discriminative models. It is\npossible to implement the proposed learning method for event-driven systems.\nHence, it would be highly efficient in real-time problems if it were\nimplemented on neuromorphic hardware. The results suggest that STDP plays an\nimportant role other than self-organization when applied after supervised\nlearning, which differs from the previous method of using STDP as pre-training\ninterpreted as self-organization.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:55:02 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 09:54:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Furuya", "Kotaro", ""], ["Ohkubo", "Jun", ""]]}, {"id": "2102.10532", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Relative Expressiveness of Defeasible Logics II", "comments": "Includes extensive appendix", "journal-ref": "Theory and Practice of Logic Programming 13(4-5): 579-592, 2013", "doi": "10.1017/S1471068413000367", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  (Maher 2012) introduced an approach for relative expressiveness of defeasible\nlogics, and two notions of relative expressiveness were investigated. Using the\nfirst of these definitions of relative expressiveness, we show that all the\ndefeasible logics in the DL framework are equally expressive under this\nformulation of relative expressiveness. The second formulation of relative\nexpressiveness is stronger than the first. However, we show that logics\nincorporating individual defeat are equally expressive as the corresponding\nlogics with team defeat. Thus the only differences in expressiveness of logics\nin DL arise from differences in how ambiguity is handled. This completes the\nstudy of relative expressiveness in DL begun in \\cite{Maher12}.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 07:01:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2102.10536", "submitter": "Peter Gunnarson", "authors": "Peter Gunnarson, Ioannis Mandralis, Guido Novati, Petros Koumoutsakos,\n  John O. Dabiri", "title": "Learning Efficient Navigation in Vortical Flow Fields", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient point-to-point navigation in the presence of a background flow\nfield is important for robotic applications such as ocean surveying. In such\napplications, robots may only have knowledge of their immediate surroundings or\nbe faced with time-varying currents, which limits the use of optimal control\ntechniques for planning trajectories. Here, we apply a novel Reinforcement\nLearning algorithm to discover time-efficient navigation policies to steer a\nfixed-speed swimmer through an unsteady two-dimensional flow field. The\nalgorithm entails inputting environmental cues into a deep neural network that\ndetermines the swimmer's actions, and deploying Remember and Forget Experience\nreplay. We find that the resulting swimmers successfully exploit the background\nflow to reach the target, but that this success depends on the type of sensed\nenvironmental cue. Surprisingly, a velocity sensing approach outperformed a\nbio-mimetic vorticity sensing approach by nearly two-fold in success rate.\nEquipped with local velocity measurements, the reinforcement learning algorithm\nachieved near 100% success in reaching the target locations while approaching\nthe time-efficiency of paths found by a global optimal control planner.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 07:25:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gunnarson", "Peter", ""], ["Mandralis", "Ioannis", ""], ["Novati", "Guido", ""], ["Koumoutsakos", "Petros", ""], ["Dabiri", "John O.", ""]]}, {"id": "2102.10540", "submitter": "Luis Perez", "authors": "Luis Perez", "title": "Mastering Terra Mystica: Applying Self-Play to Multi-agent Cooperative\n  Board Games", "comments": "9 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we explore and compare multiple algorithms for solving the\ncomplex strategy game of Terra Mystica, hereafter abbreviated as TM. Previous\nwork in the area of super-human game-play using AI has proven effective, with\nrecent break-through for generic algorithms in games such as Go, Chess, and\nShogi \\cite{AlphaZero}. We directly apply these breakthroughs to a novel\nstate-representation of TM with the goal of creating an AI that will rival\nhuman players. Specifically, we present the initial results of applying\nAlphaZero to this state-representation and analyze the strategies developed. A\nbrief analysis is presented. We call this modified algorithm with our novel\nstate-representation AlphaTM. In the end, we discuss the success and\nshortcomings of this method by comparing against multiple baselines and typical\nhuman scores. All code used for this paper is available at on\n\\href{https://github.com/kandluis/terrazero}{GitHub}.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 07:53:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Perez", "Luis", ""]]}, {"id": "2102.10543", "submitter": "Xuanchi Ren", "authors": "Xuanchi Ren, Tao Yang, Yuwang Wang, Wenjun Zeng", "title": "Do Generative Models Know Disentanglement? Contrastive Learning is All\n  You Need", "comments": "Project Page: https://github.com/xrenaa/DisCo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangled generative models are typically trained with an extra\nregularization term, which encourages the traversal of each latent factor to\nmake a distinct and independent change at the cost of generation quality. When\ntraversing the latent space of generative models trained without the\ndisentanglement term, the generated samples show semantically meaningful\nchange, raising the question: do generative models know disentanglement? We\npropose an unsupervised and model-agnostic method: Disentanglement via Contrast\n(DisCo) in the Variation Space. DisCo consists of: (i) a Navigator providing\ntraversal directions in the latent space, and (ii) a $\\Delta$-Contrastor\ncomposed of two shared-weight Encoders, which encode image pairs along these\ndirections to disentangled representations respectively, and a difference\noperator to map the encoded representations to the Variation Space. We propose\ntwo more key techniques for DisCo: entropy-based domination loss to make the\nencoded representations more disentangled and the strategy of flipping hard\nnegatives to address directions with the same semantic meaning. By optimizing\nthe Navigator to discover disentangled directions in the latent space and\nEncoders to extract disentangled representations from images with Contrastive\nLearning, DisCo achieves the state-of-the-art disentanglement given pretrained\nnon-disentangled generative models, including GAN, VAE, and Flow. Project page\nat https://github.com/xrenaa/DisCo.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:01:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ren", "Xuanchi", ""], ["Yang", "Tao", ""], ["Wang", "Yuwang", ""], ["Zeng", "Wenjun", ""]]}, {"id": "2102.10544", "submitter": "Xuanchi Ren", "authors": "Xuanchi Ren, Tao Yang, Yuwang Wang, Wenjun Zeng", "title": "Rethinking Content and Style: Exploring Bias for Unsupervised\n  Disentanglement", "comments": "Project Page: https://github.com/xrenaa/CS-DisMo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content and style (C-S) disentanglement intends to decompose the underlying\nexplanatory factors of objects into two independent subspaces. From the\nunsupervised disentanglement perspective, we rethink content and style and\npropose a formulation for unsupervised C-S disentanglement based on our\nassumption that different factors are of different importance and popularity\nfor image reconstruction, which serves as a data bias. The corresponding model\ninductive bias is introduced by our proposed C-S disentanglement Module (C-S\nDisMo), which assigns different and independent roles to content and style when\napproximating the real data distributions. Specifically, each content embedding\nfrom the dataset, which encodes the most dominant factors for image\nreconstruction, is assumed to be sampled from a shared distribution across the\ndataset. The style embedding for a particular image, encoding the remaining\nfactors, is used to customize the shared distribution through an affine\ntransformation. The experiments on several popular datasets demonstrate that\nour method achieves the state-of-the-art unsupervised C-S disentanglement,\nwhich is comparable or even better than supervised methods. We verify the\neffectiveness of our method by downstream tasks: domain translation and\nsingle-view 3D reconstruction. Project page at\nhttps://github.com/xrenaa/CS-DisMo.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:04:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ren", "Xuanchi", ""], ["Yang", "Tao", ""], ["Wang", "Yuwang", ""], ["Zeng", "Wenjun", ""]]}, {"id": "2102.10545", "submitter": "Koki Ho", "authors": "Kento Tomita and Katherine A. Skinner and Koki Ho", "title": "Uncertainty-Aware Deep Learning for Autonomous Safe Landing Site\n  Selection", "comments": "18 pages, 9 figures, revised from Paper AAS 21-253 presented at the\n  AAS/AIAA Space Flight Mechanics Meeting in 2021, to be submitted to the AIAA\n  Journal of Spacecraft and Rockets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hazard detection is critical for enabling autonomous landing on planetary\nsurfaces. Current state-of-the-art methods leverage traditional computer vision\napproaches to automate identification of safe terrain from input digital\nelevation models (DEMs). However, performance for these methods can degrade for\ninput DEMs with increased sensor noise. At the same time, deep learning\ntechniques have been developed for various applications. Nevertheless, their\napplicability to safety-critical space missions has been often limited due to\nconcerns regarding their outputs' reliability. In response to this background,\nthis paper proposes an uncertainty-aware learning-based method for hazard\ndetection and landing site selection. The developed approach enables reliable\nsafe landing site selection by: (i) generating a safety prediction map and its\nuncertainty map together via Bayesian deep learning and semantic segmentation;\nand (ii) using the generated uncertainty map to filter out the uncertain pixels\nin the prediction map so that the safe landing site selection is performed only\nbased on the certain pixels (i.e., pixels for which the model is certain about\nits safety prediction). Experiments are presented with simulated data based on\na Mars HiRISE digital terrain model and varying noise levels to demonstrate the\nperformance of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:13:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Tomita", "Kento", ""], ["Skinner", "Katherine A.", ""], ["Ho", "Koki", ""]]}, {"id": "2102.10553", "submitter": "Xintong Li", "authors": "Chen Li, Xintong Li, Md Rahaman, Xiaoyan Li, Hongzan Sun, Hong Zhang,\n  Yong Zhang, Xiaoqi Li, Jian Wu, Yudong Yao, Marcin Grzegorzek", "title": "A Comprehensive Review of Computer-aided Whole-slide Image Analysis:\n  from Datasets to Feature Extraction, Segmentation, Classification, and\n  Detection Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the development of computer-aided diagnosis (CAD) and image scanning\ntechnology, Whole-slide Image (WSI) scanners are widely used in the field of\npathological diagnosis. Therefore, WSI analysis has become the key to modern\ndigital pathology. Since 2004, WSI has been used more and more in CAD. Since\nmachine vision methods are usually based on semi-automatic or fully automatic\ncomputers, they are highly efficient and labor-saving. The combination of WSI\nand CAD technologies for segmentation, classification, and detection helps\nhistopathologists obtain more stable and quantitative analysis results, save\nlabor costs and improve diagnosis objectivity. This paper reviews the methods\nof WSI analysis based on machine learning. Firstly, the development status of\nWSI and CAD methods are introduced. Secondly, we discuss publicly available WSI\ndatasets and evaluation metrics for segmentation, classification, and detection\ntasks. Then, the latest development of machine learning in WSI segmentation,\nclassification, and detection are reviewed continuously. Finally, the existing\nmethods are studied, the applicabilities of the analysis methods are analyzed,\nand the application prospects of the analysis methods in this field are\nforecasted.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:30:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Li", "Chen", ""], ["Li", "Xintong", ""], ["Rahaman", "Md", ""], ["Li", "Xiaoyan", ""], ["Sun", "Hongzan", ""], ["Zhang", "Hong", ""], ["Zhang", "Yong", ""], ["Li", "Xiaoqi", ""], ["Wu", "Jian", ""], ["Yao", "Yudong", ""], ["Grzegorzek", "Marcin", ""]]}, {"id": "2102.10556", "submitter": "Andrew Cropper", "authors": "Andrew Cropper, Sebastijan Duman\\v{c}i\\'c, Richard Evans, and Stephen\n  H. Muggleton", "title": "Inductive logic programming at 30", "comments": "Extension of IJCAI20 survey paper. arXiv admin note: substantial text\n  overlap with arXiv:2002.11002, arXiv:2008.07912", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inductive logic programming (ILP) is a form of logic-based machine learning.\nThe goal of ILP is to induce a hypothesis (a logic program) that generalises\ngiven training examples and background knowledge. As ILP turns 30, we survey\nrecent work in the field. In this survey, we focus on (i) new meta-level search\nmethods, (ii) techniques for learning recursive programs that generalise from\nfew examples, (iii) new approaches for predicate invention, and (iv) the use of\ndifferent technologies, notably answer set programming and neural networks. We\nconclude by discussing some of the current limitations of ILP and discuss\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:37:17 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Evans", "Richard", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2102.10557", "submitter": "Nam Nguyen", "authors": "Nam Nguyen and J. Morris Chang", "title": "Contrastive Self-supervised Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel cell-based neural architecture search algorithm\n(NAS), which completely alleviates the expensive costs of data labeling\ninherited from supervised learning. Our algorithm capitalizes on the\neffectiveness of self-supervised learning for image representations, which is\nan increasingly crucial topic of computer vision. First, using only a small\namount of unlabeled train data under contrastive self-supervised learning allow\nus to search on a more extensive search space, discovering better neural\narchitectures without surging the computational resources. Second, we entirely\nrelieve the cost for labeled data (by contrastive loss) in the search stage\nwithout compromising architectures' final performance in the evaluation phase.\nFinally, we tackle the inherent discrete search space of the NAS problem by\nsequential model-based optimization via the tree-parzen estimator (SMBO-TPE),\nenabling us to reduce the computational expense response surface significantly.\nAn extensive number of experiments empirically show that our search algorithm\ncan achieve state-of-the-art results with better efficiency in data labeling\ncost, searching time, and accuracy in final validation.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:38:28 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 06:09:07 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Nguyen", "Nam", ""], ["Chang", "J. Morris", ""]]}, {"id": "2102.10558", "submitter": "L\\'aszl\\'o Csat\\'o", "authors": "Kolos Csaba \\'Agoston and L\\'aszl\\'o Csat\\'o", "title": "Inconsistency thresholds for incomplete pairwise comparison matrices", "comments": "13 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI math.OC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparison matrices are increasingly used in settings where some\npairs are missing. However, there exist few inconsistency indices for similar\nincomplete data sets and no reasonable measure has an associated threshold.\nThis paper generalises the famous rule of thumb for the acceptable level of\ninconsistency, proposed by Saaty, to incomplete pairwise comparison matrices.\nThe extension is based on choosing the missing elements such that the maximal\neigenvalue of the incomplete matrix is minimised. Consequently, the\nwell-established values of the random index cannot be adopted: the\ninconsistency of random matrices is found to be the function of matrix size and\nthe number of missing elements, with a nearly linear dependence in the case of\nthe latter variable. Our results can be directly built into decision-making\nsoftware and used by practitioners as a statistical criterion for accepting or\nrejecting an incomplete pairwise comparison matrix.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:39:37 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 12:09:42 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["\u00c1goston", "Kolos Csaba", ""], ["Csat\u00f3", "L\u00e1szl\u00f3", ""]]}, {"id": "2102.10562", "submitter": "Zhe Zeng Miss", "authors": "Wenzhe Li, Zhe Zeng, Antonio Vergari, Guy Van den Broeck", "title": "Tractable Computation of Expected Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the expectation of kernel functions is a ubiquitous task in machine\nlearning, with applications from classical support vector machines to\nexploiting kernel embeddings of distributions in probabilistic modeling,\nstatistical inference, causal discovery, and deep learning. In all these\nscenarios, we tend to resort to Monte Carlo estimates as expectations of\nkernels are intractable in general. In this work, we characterize the\nconditions under which we can compute expected kernels exactly and efficiently,\nby leveraging recent advances in probabilistic circuit representations. We\nfirst construct a circuit representation for kernels and propose an approach to\nsuch tractable computation. We then demonstrate possible advancements for\nkernel embedding frameworks by exploiting tractable expected kernels to derive\nnew algorithms for two challenging scenarios: 1) reasoning under missing data\nwith kernel support vector regressors; 2) devising a collapsed black-box\nimportance sampling scheme. Finally, we empirically evaluate both algorithms\nand show that they outperform standard baselines on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:59:06 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 07:19:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Li", "Wenzhe", ""], ["Zeng", "Zhe", ""], ["Vergari", "Antonio", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2102.10581", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Patterns of Cognition: Cognitive Algorithms as Galois Connections\n  Fulfilled by Chronomorphisms On Probabilistically Typed Metagraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is argued that a broad class of AGI-relevant algorithms can be expressed\nin a common formal framework, via specifying Galois connections linking search\nand optimization processes on directed metagraphs whose edge targets are\nlabeled with probabilistic dependent types, and then showing these connections\nare fulfilled by processes involving metagraph chronomorphisms. Examples are\ndrawn from the core cognitive algorithms used in the OpenCog AGI framework:\nProbabilistic logical inference, evolutionary program learning, pattern mining,\nagglomerative clustering, pattern mining and nonlinear-dynamical attention\nallocation.\n  The analysis presented involves representing these cognitive algorithms as\nrecursive discrete decision processes involving optimizing functions defined\nover metagraphs, in which the key decisions involve sampling from probability\ndistributions over metagraphs and enacting sets of combinatory operations on\nselected sub-metagraphs. The mutual associativity of the combinatory operations\ninvolved in a cognitive process is shown to often play a key role in enabling\nthe decomposition of the process into folding and unfolding operations; a\nconclusion that has some practical implications for the particulars of\ncognitive processes, e.g. militating toward use of reversible logic and\nreversible program execution. It is also observed that where this mutual\nassociativity holds, there is an alignment between the hierarchy of subgoals\nused in recursive decision process execution and a hierarchy of subpatterns\ndefinable in terms of formal pattern theory.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 10:50:40 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2102.10585", "submitter": "Sanja Dogramadzi", "authors": "Mohammad Fattahi Sani, Raimondo Ascione, Sanja Dogramadzi", "title": "Mapping Surgeon's Hand/Finger Motion During Conventional Microsurgery to\n  Enhance Intuitive Surgical Robot Teleoperation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Recent developments in robotics and artificial intelligence (AI)\nhave led to significant advances in healthcare technologies enhancing\nrobot-assisted minimally invasive surgery (RAMIS) in some surgical specialties.\nHowever, current human-robot interfaces lack intuitive teleoperation and cannot\nmimic surgeon's hand/finger sensing and fine motion. These limitations make\ntele-operated robotic surgery not suitable for micro-surgery and difficult to\nlearn for established surgeons. We report a pilot study showing an intuitive\nway of recording and mapping surgeon's gross hand motion and the fine synergic\nmotion during cardiac micro-surgery as a way to enhance future intuitive\nteleoperation. Methods: We set to develop a prototype system able to train a\nDeep Neural Net-work (DNN) by mapping wrist, hand and surgical tool real-time\ndata acquisition(RTDA) inputs during mock-up heart micro-surgery procedures.\nThe trained network was used to estimate the tools poses from refined hand\njoint angles. Results: Based on surgeon's feedback during mock micro-surgery,\nthe developed wearable system with light-weight sensors for motion tracking did\nnot interfere with the surgery and instrument handling. The wearable motion\ntracking system used 15 finger-thumb-wrist joint angle sensors to generate\nmeaningful data-sets representing inputs of the DNN network with new hand joint\nangles added as necessary based on comparing the estimated tool poses against\nmeasured tool pose. The DNN architecture was optimized for the highest\nestimation accuracy and the ability to determine the tool pose with the least\nmean squared error. This novel approach showed that the surgical instrument's\npose, an essential requirement for teleoperation, can be accurately estimated\nfrom recorded surgeon's hand/finger movements with a mean squared error (MSE)\nless than 0.3%\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 11:21:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sani", "Mohammad Fattahi", ""], ["Ascione", "Raimondo", ""], ["Dogramadzi", "Sanja", ""]]}, {"id": "2102.10601", "submitter": "Muhammad Noor Fakhruzzaman", "authors": "Muhammad Noor Fakhruzzaman, Sie Wildan Gunawan", "title": "Web-based Application for Detecting Indonesian Clickbait Headlines using\n  IndoBERT", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With increasing usage of clickbaits in Indonesian Online News, newsworthy\narticles sometimes get buried among clickbaity news. A reliable and lightweight\ntool is needed to detect such clickbaits on-the-go. Leveraging state-of-the-art\nnatural language processing model BERT, a RESTful API based application is\ndeveloped. This study offloaded the computing resources needed to train the\nmodel on the cloud server, while the client-side application only needs to send\na request to the API and the cloud server will handle the rest. This study\nproposed the design and developed a web-based application to detect clickbait\nin Indonesian using IndoBERT as a language model. The application usage is\ndiscussed and available for public use with a performance of mean ROC-AUC of\n89%.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 13:28:52 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fakhruzzaman", "Muhammad Noor", ""], ["Gunawan", "Sie Wildan", ""]]}, {"id": "2102.10635", "submitter": "Arun Das", "authors": "Shadi Ghafghazi, Amarie Carnett, Leslie Neely, Arun Das, Paul Rad", "title": "AI-Augmented Behavior Analysis for Children with Developmental\n  Disabilities: Building Towards Precision Treatment", "comments": "Accepted to IEEE SMC Magazine. Updated IEEE copyright policy to\n  thanks section on Page 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autism spectrum disorder is a developmental disorder characterized by\nsignificant social, communication, and behavioral challenges. Individuals\ndiagnosed with autism, intellectual, and developmental disabilities (AUIDD)\ntypically require long-term care and targeted treatment and teaching. Effective\ntreatment of AUIDD relies on efficient and careful behavioral observations done\nby trained applied behavioral analysts (ABAs). However, this process\noverburdens ABAs by requiring the clinicians to collect and analyze data,\nidentify the problem behaviors, conduct pattern analysis to categorize and\npredict categorical outcomes, hypothesize responsiveness to treatments, and\ndetect the effects of treatment plans. Successful integration of digital\ntechnologies into clinical decision-making pipelines and the advancements in\nautomated decision-making using Artificial Intelligence (AI) algorithms\nhighlights the importance of augmenting teaching and treatments using novel\nalgorithms and high-fidelity sensors. In this article, we present an\nAI-Augmented Learning and Applied Behavior Analytics (AI-ABA) platform to\nprovide personalized treatment and learning plans to AUIDD individuals. By\ndefining systematic experiments along with automated data collection and\nanalysis, AI-ABA can promote self-regulative behavior using reinforcement-based\naugmented or virtual reality and other mobile platforms. Thus, AI-ABA could\nassist clinicians to focus on making precise data-driven decisions and increase\nthe quality of individualized interventions for individuals with AUIDD.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 16:15:40 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 16:23:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ghafghazi", "Shadi", ""], ["Carnett", "Amarie", ""], ["Neely", "Leslie", ""], ["Das", "Arun", ""], ["Rad", "Paul", ""]]}, {"id": "2102.10684", "submitter": "Ahmed Abdelali", "authors": "Ahmed Abdelali, Sabit Hassan, Hamdy Mubarak, Kareem Darwish and Younes\n  Samih", "title": "Pre-Training BERT on Arabic Tweets: Practical Considerations", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Pretraining Bidirectional Encoder Representations from Transformers (BERT)\nfor downstream NLP tasks is a non-trival task. We pretrained 5 BERT models that\ndiffer in the size of their training sets, mixture of formal and informal\nArabic, and linguistic preprocessing. All are intended to support Arabic\ndialects and social media. The experiments highlight the centrality of data\ndiversity and the efficacy of linguistically aware segmentation. They also\nhighlight that more data or more training step do not necessitate better\nmodels. Our new models achieve new state-of-the-art results on several\ndownstream tasks. The resulting models are released to the community under the\nname QARiB.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 20:51:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Abdelali", "Ahmed", ""], ["Hassan", "Sabit", ""], ["Mubarak", "Hamdy", ""], ["Darwish", "Kareem", ""], ["Samih", "Younes", ""]]}, {"id": "2102.10697", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Martin Docekal, Karel Ondrej, Pavel Smrz", "title": "Pruning the Index Contents for Memory Efficient Open-Domain QA", "comments": "v2 - added connection between pruner and DPR, results on TriviaQA,\n  new reranker, results with HN-DPR checkpoint and additional analyses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents a novel pipeline that demonstrates what is achievable with\na combined effort of state-of-the-art approaches. Specifically, it proposes the\nnovel R2-D2 (Rank twice, reaD twice) pipeline composed of retriever, passage\nreranker, extractive reader, generative reader and a simple way to combine\nthem. Furthermore, previous work often comes with a massive index of external\ndocuments that scales in the order of tens of GiB. This work presents a simple\napproach for pruning the contents of a massive index such that the open-domain\nQA system altogether with index, OS, and library components fits into 6GiB\ndocker image while retaining only 8% of original index contents and losing only\n3% EM accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 21:56:38 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 19:02:54 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Fajcik", "Martin", ""], ["Docekal", "Martin", ""], ["Ondrej", "Karel", ""], ["Smrz", "Pavel", ""]]}, {"id": "2102.10707", "submitter": "HanQin Cai", "authors": "HanQin Cai, Yuchen Lou, Daniel McKenzie, Wotao Yin", "title": "A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale\n  Black-Box Optimization", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the zeroth-order optimization problem in the huge-scale setting,\nwhere the dimension of the problem is so large that performing even basic\nvector operations on the decision variables is infeasible. In this paper, we\npropose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query\ncomplexity and has a much smaller per-iteration computational complexity. In\naddition, we discuss how the memory footprint of ZO-BCD can be reduced even\nfurther by the clever use of circulant measurement matrices. As an application\nof our new method, we propose the idea of crafting adversarial attacks on\nneural network based classifiers in a wavelet domain, which can result in\nproblem dimensions of over 1.7 million. In particular, we show that crafting\nadversarial examples to audio classifiers in a wavelet domain can achieve the\nstate-of-the-art attack success rate of 97.9%.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 23:06:35 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 04:30:50 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Cai", "HanQin", ""], ["Lou", "Yuchen", ""], ["McKenzie", "Daniel", ""], ["Yin", "Wotao", ""]]}, {"id": "2102.10711", "submitter": "Hanlin Niu", "authors": "Hanlin Niu, Ze Ji, Farshad Arvin, Barry Lennox, Hujun Yin, and Joaquin\n  Carrasco", "title": "Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision\n  Avoidance from Human Player", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a sensor-level mapless collision avoidance algorithm for\nuse in mobile robots that map raw sensor data to linear and angular velocities\nand navigate in an unknown environment without a map. An efficient training\nstrategy is proposed to allow a robot to learn from both human experience data\nand self-exploratory data. A game format simulation framework is designed to\nallow the human player to tele-operate the mobile robot to a goal and human\naction is also scored using the reward function. Both human player data and\nself-playing data are sampled using prioritized experience replay algorithm.\nThe proposed algorithm and training strategy have been evaluated in two\ndifferent experimental configurations: \\textit{Environment 1}, a simulated\ncluttered environment, and \\textit{Environment 2}, a simulated corridor\nenvironment, to investigate the performance. It was demonstrated that the\nproposed method achieved the same level of reward using only 16\\% of the\ntraining steps required by the standard Deep Deterministic Policy Gradient\n(DDPG) method in Environment 1 and 20\\% of that in Environment 2. In the\nevaluation of 20 random missions, the proposed method achieved no collision in\nless than 2~h and 2.5~h of training time in the two Gazebo environments\nrespectively. The method also generated smoother trajectories than DDPG. The\nproposed method has also been implemented on a real robot in the real-world\nenvironment for performance evaluation. We can confirm that the trained model\nwith the simulation software can be directly applied into the real-world\nscenario without further fine-tuning, further demonstrating its higher\nrobustness than DDPG. The video and code are available:\nhttps://youtu.be/BmwxevgsdGc\nhttps://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 23:27:34 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 02:44:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Niu", "Hanlin", ""], ["Ji", "Ze", ""], ["Arvin", "Farshad", ""], ["Lennox", "Barry", ""], ["Yin", "Hujun", ""], ["Carrasco", "Joaquin", ""]]}, {"id": "2102.10717", "submitter": "Melanie Mitchell", "authors": "Melanie Mitchell", "title": "Abstraction and Analogy-Making in Artificial Intelligence", "comments": "Revised version. 30 pages, 9 figures. To appear in Annals of the New\n  York Academy of Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual abstraction and analogy-making are key abilities underlying\nhumans' abilities to learn, reason, and robustly adapt their knowledge to new\ndomains. Despite of a long history of research on constructing AI systems with\nthese abilities, no current AI system is anywhere close to a capability of\nforming humanlike abstractions or analogies. This paper reviews the advantages\nand limitations of several approaches toward this goal, including symbolic\nmethods, deep learning, and probabilistic program induction. The paper\nconcludes with several proposals for designing challenge tasks and evaluation\nmeasures in order to make quantifiable and generalizable progress in this area.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 00:12:48 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 15:27:01 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Mitchell", "Melanie", ""]]}, {"id": "2102.10740", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Bhargav Ganguly, Vaneet Aggarwal", "title": "Communication Efficient Parallel Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider the problem where $M$ agents interact with $M$ identical and\nindependent environments with $S$ states and $A$ actions using reinforcement\nlearning for $T$ rounds. The agents share their data with a central server to\nminimize their regret. We aim to find an algorithm that allows the agents to\nminimize the regret with infrequent communication rounds. We provide \\NAM\\\nwhich runs at each agent and prove that the total cumulative regret of $M$\nagents is upper bounded as $\\Tilde{O}(DS\\sqrt{MAT})$ for a Markov Decision\nProcess with diameter $D$, number of states $S$, and number of actions $A$. The\nagents synchronize after their visitations to any state-action pair exceeds a\ncertain threshold. Using this, we obtain a bound of $O\\left(MSA\\log(MT)\\right)$\non the total number of communications rounds. Finally, we evaluate the\nalgorithm against multiple environments and demonstrate that the proposed\nalgorithm performs at par with an always communication version of the UCRL2\nalgorithm, while with significantly lower communication.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 02:46:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Agarwal", "Mridul", ""], ["Ganguly", "Bhargav", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2102.10744", "submitter": "Yudong Chen", "authors": "Yudong Chen, Chaoyu Guan, Zhikun Wei, Xin Wang, Wenwu Zhu", "title": "MetaDelta: A Meta-Learning System for Few-shot Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning aims at learning quickly on novel tasks with limited data by\ntransferring generic experience learned from previous tasks. Naturally,\nfew-shot learning has been one of the most popular applications for\nmeta-learning. However, existing meta-learning algorithms rarely consider the\ntime and resource efficiency or the generalization capacity for unknown\ndatasets, which limits their applicability in real-world scenarios. In this\npaper, we propose MetaDelta, a novel practical meta-learning system for the\nfew-shot image classification. MetaDelta consists of two core components: i)\nmultiple meta-learners supervised by a central controller to ensure efficiency,\nand ii) a meta-ensemble module in charge of integrated inference and better\ngeneralization. In particular, each meta-learner in MetaDelta is composed of a\nunique pretrained encoder fine-tuned by batch training and parameter-free\ndecoder used for prediction. MetaDelta ranks first in the final phase in the\nAAAI 2021 MetaDL\nChallenge\\footnote{https://competitions.codalab.org/competitions/26638},\ndemonstrating the advantages of our proposed system. The codes are publicly\navailable at https://github.com/Frozenmad/MetaDelta.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 02:57:22 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Yudong", ""], ["Guan", "Chaoyu", ""], ["Wei", "Zhikun", ""], ["Wang", "Xin", ""], ["Zhu", "Wenwu", ""]]}, {"id": "2102.10750", "submitter": "Ankit Kulshrestha", "authors": "Ankit Kulshrestha, Ilya Safro", "title": "Coping with Mistreatment in Fair Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning actively impacts our everyday life in almost all endeavors\nand domains such as healthcare, finance, and energy. As our dependence on the\nmachine learning increases, it is inevitable that these algorithms will be used\nto make decisions that will have a direct impact on the society spanning all\nresolutions from personal choices to world-wide policies. Hence, it is crucial\nto ensure that (un)intentional bias does not affect the machine learning\nalgorithms especially when they are required to take decisions that may have\nunintended consequences. Algorithmic fairness techniques have found traction in\nthe machine learning community and many methods and metrics have been proposed\nto ensure and evaluate fairness in algorithms and data collection.\n  In this paper, we study the algorithmic fairness in a supervised learning\nsetting and examine the effect of optimizing a classifier for the Equal\nOpportunity metric. We demonstrate that such a classifier has an increased\nfalse positive rate across sensitive groups and propose a conceptually simple\nmethod to mitigate this bias. We rigorously analyze the proposed method and\nevaluate it on several real world datasets demonstrating its efficacy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 03:26:06 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kulshrestha", "Ankit", ""], ["Safro", "Ilya", ""]]}, {"id": "2102.10760", "submitter": "Snehasish Mukherjee", "authors": "Snehasish Mukherjee", "title": "Unsupervised Meta Learning for One Shot Title Compression in Voice\n  Commerce", "comments": "Work carried out as part of CS330, Stanford University, Fall 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Product title compression for voice and mobile commerce is a well studied\nproblem with several supervised models proposed so far. However these models\nhave 2 major limitations; they are not designed to generate compressions\ndynamically based on cues at inference time, and they do not transfer well to\ndifferent categories at test time. To address these shortcomings we model title\ncompression as a meta learning problem where we ask can we learn a title\ncompression model given only 1 example compression? We adopt an unsupervised\napproach to meta training by proposing an automatic task generation algorithm\nthat models the observed label generation process as the outcome of 4\nunobserved processes. We create parameterized approximations to each of these 4\nlatent processes to get a principled way of generating random compression\nrules, which are treated as different tasks. For our main meta learner, we use\n2 models; M1 and M2. M1 is a task agnostic embedding generator whose output\nfeeds into M2 which is a task specific label generator. We pre-train M1 on a\nnovel unsupervised segment rank prediction task that allows us to treat M1 as a\nsegment generator that also learns to rank segments during the meta-training\nprocess. Our experiments on 16000 crowd generated meta-test examples show that\nour unsupervised meta training regime is able to acquire a learning algorithm\nfor different tasks after seeing only 1 example for each task. Further, we show\nthat our model trained end to end as a black box meta learner, outperforms non\nparametric approaches. Our best model obtains an F1 score of 0.8412, beating\nthe baseline by a large margin of 25 F1 points.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 03:53:33 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mukherjee", "Snehasish", ""]]}, {"id": "2102.10774", "submitter": "Lanqing Li", "authors": "Lanqing Li, Yuanhao Huang, Dijun Luo", "title": "Improved Context-Based Offline Meta-RL with Attention and Contrastive\n  Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning for offline reinforcement learning (OMRL) is an understudied\nproblem with tremendous potential impact by enabling RL algorithms in many\nreal-world applications. A popular solution to the problem is to infer task\nidentity as augmented state using a context-based encoder, for which efficient\nlearning of task representations remains an open challenge. In this work, we\nimprove upon one of the SOTA OMRL algorithms, FOCAL, by incorporating\nintra-task attention mechanism and inter-task contrastive learning objectives\nfor more effective task inference and learning of control. Theoretical analysis\nand experiments are presented to demonstrate the superior performance,\nefficiency and robustness of our end-to-end and model free method compared to\nprior algorithms across multiple meta-RL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 05:05:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Li", "Lanqing", ""], ["Huang", "Yuanhao", ""], ["Luo", "Dijun", ""]]}, {"id": "2102.10788", "submitter": "Xu Wang", "authors": "Xu Wang, Yi Jin, Yigang Cen, Tao Wang and Yidong Li", "title": "Attention Models for Point Clouds in Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the advancement of 3D point clouds in deep learning has attracted\nintensive research in different application domains such as computer vision and\nrobotic tasks. However, creating feature representation of robust,\ndiscriminative from unordered and irregular point clouds is challenging. In\nthis paper, our ultimate goal is to provide a comprehensive overview of the\npoint clouds feature representation which uses attention models. More than 75+\nkey contributions in the recent three years are summarized in this survey,\nincluding the 3D objective detection, 3D semantic segmentation, 3D pose\nestimation, point clouds completion etc. We provide a detailed characterization\n(1) the role of attention mechanisms, (2) the usability of attention models\ninto different tasks, (3) the development trend of key technology.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 05:50:22 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Xu", ""], ["Jin", "Yi", ""], ["Cen", "Yigang", ""], ["Wang", "Tao", ""], ["Li", "Yidong", ""]]}, {"id": "2102.10795", "submitter": "Chuchu Han", "authors": "Chuchu Han, Zhedong Zheng, Changxin Gao, Nong Sang, Yi Yang", "title": "Decoupled and Memory-Reinforced Networks: Towards Effective Feature\n  Learning for One-Step Person Search", "comments": "8 pages, 6 figures. Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of person search is to localize and match query persons from scene\nimages. For high efficiency, one-step methods have been developed to jointly\nhandle the pedestrian detection and identification sub-tasks using a single\nnetwork. There are two major challenges in the current one-step approaches. One\nis the mutual interference between the optimization objectives of multiple\nsub-tasks. The other is the sub-optimal identification feature learning caused\nby small batch size when end-to-end training. To overcome these problems, we\npropose a decoupled and memory-reinforced network (DMRNet). Specifically, to\nreconcile the conflicts of multiple objectives, we simplify the standard\ntightly coupled pipelines and establish a deeply decoupled multi-task learning\nframework. Further, we build a memory-reinforced mechanism to boost the\nidentification feature learning. By queuing the identification features of\nrecently accessed instances into a memory bank, the mechanism augments the\nsimilarity pair construction for pairwise metric learning. For better encoding\nconsistency of the stored features, a slow-moving average of the network is\napplied for extracting these features. In this way, the dual networks reinforce\neach other and converge to robust solution states. Experimentally, the proposed\nmethod obtains 93.2% and 46.9% mAP on CUHK-SYSU and PRW datasets, which exceeds\nall the existing one-step methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:19:45 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Han", "Chuchu", ""], ["Zheng", "Zhedong", ""], ["Gao", "Changxin", ""], ["Sang", "Nong", ""], ["Yang", "Yi", ""]]}, {"id": "2102.10800", "submitter": "Abdelrahman Hosny", "authors": "Abdelrahman Hosny and Sherief Reda", "title": "Characterizing and Optimizing EDA Flows for the Cloud", "comments": "Presented at DATE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud computing accelerates design space exploration in logic synthesis, and\nparameter tuning in physical design. However, deploying EDA jobs on the cloud\nrequires EDA teams to deeply understand the characteristics of their jobs in\ncloud environments. Unfortunately, there has been little to no public\ninformation on these characteristics. Thus, in this paper, we formulate the\nproblem of migrating EDA jobs to the cloud. First, we characterize the\nperformance of four main EDA applications, namely: synthesis, placement,\nrouting and static timing analysis. We show that different EDA jobs require\ndifferent machine configurations. Second, using observations from our\ncharacterization, we propose a novel model based on Graph Convolutional\nNetworks to predict the total runtime of a given application on different\nmachine configurations. Our model achieves a prediction accuracy of 87%. Third,\nwe develop a new formulation for optimizing cloud deployments in order to\nreduce deployment costs while meeting deadline constraints. We present a\npseudo-polynomial optimal solution using a multi-choice knapsack mapping that\nreduces costs by 35.29%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:51:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hosny", "Abdelrahman", ""], ["Reda", "Sherief", ""]]}, {"id": "2102.10801", "submitter": "Wei Lin", "authors": "Qunxi Zhu, Yao Guo, Wei Lin", "title": "Neural Delay Differential Equations", "comments": "Accepted as a poster in ICLR 2021 (submitted 28 Sep 2020, revised 22\n  Nov 2020, accepted 08 Jan 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Ordinary Differential Equations (NODEs), a framework of\ncontinuous-depth neural networks, have been widely applied, showing exceptional\nefficacy in coping with some representative datasets. Recently, an augmented\nframework has been successfully developed for conquering some limitations\nemergent in application of the original framework. Here we propose a new class\nof continuous-depth neural networks with delay, named as Neural Delay\nDifferential Equations (NDDEs), and, for computing the corresponding gradients,\nwe use the adjoint sensitivity method to obtain the delayed dynamics of the\nadjoint. Since the differential equations with delays are usually seen as\ndynamical systems of infinite dimension possessing more fruitful dynamics, the\nNDDEs, compared to the NODEs, own a stronger capacity of nonlinear\nrepresentations. Indeed, we analytically validate that the NDDEs are of\nuniversal approximators, and further articulate an extension of the NDDEs,\nwhere the initial function of the NDDEs is supposed to satisfy ODEs. More\nimportantly, we use several illustrative examples to demonstrate the\noutstanding capacities of the NDDEs and the NDDEs with ODEs' initial value.\nSpecifically, (1) we successfully model the delayed dynamics where the\ntrajectories in the lower-dimensional phase space could be mutually\nintersected, while the traditional NODEs without any argumentation are not\ndirectly applicable for such modeling, and (2) we achieve lower loss and higher\naccuracy not only for the data produced synthetically by complex models but\nalso for the real-world image datasets, i.e., CIFAR10, MNIST, and SVHN. Our\nresults on the NDDEs reveal that appropriately articulating the elements of\ndynamical systems into the network design is truly beneficial to promoting the\nnetwork performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:53:51 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhu", "Qunxi", ""], ["Guo", "Yao", ""], ["Lin", "Wei", ""]]}, {"id": "2102.10826", "submitter": "Zhiyuan Ning", "authors": "Zhiyuan Ning, Ziyue Qiao, Hao Dong, Yi Du, Yuanchun Zhou", "title": "LightCAKE: A Lightweight Framework for Context-Aware Knowledge Graph\n  Embedding", "comments": "Accepted by PAKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding (KGE) models learn to project symbolic entities and\nrelations into a continuous vector space based on the observed triplets.\nHowever, existing KGE models cannot make a proper trade-off between the graph\ncontext and the model complexity, which makes them still far from satisfactory.\nIn this paper, we propose a lightweight framework named LightCAKE for\ncontext-aware KGE. LightCAKE explicitly models the graph context without\nintroducing redundant trainable parameters, and uses an iterative aggregation\nstrategy to integrate the context information into the entity/relation\nembeddings. As a generic framework, it can be used with many simple KGE models\nto achieve excellent results. Finally, extensive experiments on public\nbenchmarks demonstrate the efficiency and effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 08:23:22 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:30:48 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ning", "Zhiyuan", ""], ["Qiao", "Ziyue", ""], ["Dong", "Hao", ""], ["Du", "Yi", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "2102.10837", "submitter": "Subho Sankar Banerjee", "authors": "Subho S. Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K.\n  Iyer", "title": "BayesPerf: Minimizing Performance Monitoring Errors Using Bayesian\n  Statistics", "comments": null, "journal-ref": "Proceedings of the Twenty-Sixth International Conference on\n  Architectural Support for Programming Languages and Operating Systems (ASPLOS\n  21), 2021", "doi": "10.1145/3445814.3446739", "report-no": null, "categories": "cs.DC cs.AI cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware performance counters (HPCs) that measure low-level architectural and\nmicroarchitectural events provide dynamic contextual information about the\nstate of the system. However, HPC measurements are error-prone due to non\ndeterminism (e.g., undercounting due to event multiplexing, or OS\ninterrupt-handling behaviors). In this paper, we present BayesPerf, a system\nfor quantifying uncertainty in HPC measurements by using a domain-driven\nBayesian model that captures microarchitectural relationships between HPCs to\njointly infer their values as probability distributions. We provide the design\nand implementation of an accelerator that allows for low-latency and low-power\ninference of the BayesPerf model for x86 and ppc64 CPUs. BayesPerf reduces the\naverage error in HPC measurements from 40.1% to 7.6% when events are being\nmultiplexed. The value of BayesPerf in real-time decision-making is illustrated\nwith a simple example of scheduling of PCIe transfers.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 09:00:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Banerjee", "Subho S.", ""], ["Jha", "Saurabh", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "2102.10863", "submitter": "Simone Pezzuto", "authors": "Thomas Grandits, Simone Pezzuto, Francisco Sahli Costabal, Paris\n  Perdikaris, Thomas Pock, Gernot Plank, Rolf Krause", "title": "Learning atrial fiber orientations and conductivity tensors from\n  intracardiac maps using physics-informed neural networks", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroanatomical maps are a key tool in the diagnosis and treatment of\natrial fibrillation. Current approaches focus on the activation times recorded.\nHowever, more information can be extracted from the available data. The fibers\nin cardiac tissue conduct the electrical wave faster, and their direction could\nbe inferred from activation times. In this work, we employ a recently developed\napproach, called physics informed neural networks, to learn the fiber\norientations from electroanatomical maps, taking into account the physics of\nthe electrical wave propagation. In particular, we train the neural network to\nweakly satisfy the anisotropic eikonal equation and to predict the measured\nactivation times. We use a local basis for the anisotropic conductivity tensor,\nwhich encodes the fiber orientation. The methodology is tested both in a\nsynthetic example and for patient data. Our approach shows good agreement in\nboth cases, with an RMSE of 2.2ms on the in-silico data and outperforming a\nstate of the art method on the patient data. The results show a first step\ntowards learning the fiber orientations from electroanatomical maps with\nphysics-informed neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 09:55:17 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:22:56 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Grandits", "Thomas", ""], ["Pezzuto", "Simone", ""], ["Costabal", "Francisco Sahli", ""], ["Perdikaris", "Paris", ""], ["Pock", "Thomas", ""], ["Plank", "Gernot", ""], ["Krause", "Rolf", ""]]}, {"id": "2102.10865", "submitter": "Federico Cerutti", "authors": "Federico Cerutti, Lance M. Kaplan, Angelika Kimmig, Murat Sensoy", "title": "Handling Epistemic and Aleatory Uncertainties in Probabilistic Circuits", "comments": "Under submission to MACH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When collaborating with an AI system, we need to assess when to trust its\nrecommendations. If we mistakenly trust it in regions where it is likely to\nerr, catastrophic failures may occur, hence the need for Bayesian approaches\nfor probabilistic reasoning in order to determine the confidence (or epistemic\nuncertainty) in the probabilities in light of the training data. We propose an\napproach to overcome the independence assumption behind most of the approaches\ndealing with a large class of probabilistic reasoning that includes Bayesian\nnetworks as well as several instances of probabilistic logic. We provide an\nalgorithm for Bayesian learning from sparse, albeit complete, observations, and\nfor deriving inferences and their confidences keeping track of the dependencies\nbetween variables when they are manipulated within the unifying computational\nformalism provided by probabilistic circuits. Each leaf of such circuits is\nlabelled with a beta-distributed random variable that provides us with an\nelegant framework for representing uncertain probabilities. We achieve better\nestimation of epistemic uncertainty than state-of-the-art approaches, including\nhighly engineered ones, while being able to handle general circuits and with\njust a modest increase in the computational effort compared to using point\nprobabilities.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 10:03:15 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cerutti", "Federico", ""], ["Kaplan", "Lance M.", ""], ["Kimmig", "Angelika", ""], ["Sensoy", "Murat", ""]]}, {"id": "2102.10867", "submitter": "Benjamin Aubin", "authors": "Benjamin Aubin, Agnieszka S{\\l}owik, Martin Arjovsky, Leon Bottou,\n  David Lopez-Paz", "title": "Linear unit-tests for invariance discovery", "comments": "5 pages, Causal Discovery & Causality-Inspired Machine Learning\n  Workshop at Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in algorithms to learn invariant correlations\nacross training environments. A big share of the current proposals find\ntheoretical support in the causality literature but, how useful are they in\npractice? The purpose of this note is to propose six linear low-dimensional\nproblems -- unit tests -- to evaluate different types of out-of-distribution\ngeneralization in a precise manner. Following initial experiments, none of the\nthree recently proposed alternatives passes all tests. By providing the code to\nautomatically replicate all the results in this manuscript\n(https://www.github.com/facebookresearch/InvarianceUnitTests), we hope that our\nunit tests become a standard steppingstone for researchers in\nout-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 10:07:51 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Aubin", "Benjamin", ""], ["S\u0142owik", "Agnieszka", ""], ["Arjovsky", "Martin", ""], ["Bottou", "Leon", ""], ["Lopez-Paz", "David", ""]]}, {"id": "2102.10882", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Zhi Tian and Bo Zhang and Xinlong Wang and Xiaolin\n  Wei and Huaxia Xia and Chunhua Shen", "title": "Conditional Positional Encodings for Vision Transformers", "comments": "A general purpose conditional position encoding for vision\n  transformers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a conditional positional encoding (CPE) scheme for vision\nTransformers. Unlike previous fixed or learnable positional encodings, which\nare pre-defined and independent of input tokens, CPE is dynamically generated\nand conditioned on the local neighborhood of the input tokens. As a result, CPE\ncan easily generalize to the input sequences that are longer than what the\nmodel has ever seen during training. Besides, CPE can keep the desired\ntranslation-invariance in the image classification task, resulting in improved\nclassification accuracy. CPE can be effortlessly implemented with a simple\nPosition Encoding Generator (PEG), and it can be seamlessly incorporated into\nthe current Transformer framework. Built on PEG, we present Conditional\nPosition encoding Vision Transformer (CPVT). We demonstrate that CPVT has\nvisually similar attention maps compared to those with learned positional\nencodings. Benefit from the conditional positional encoding scheme, we obtain\nstate-of-the-art results on the ImageNet classification task compared with\nvision Transformers to date. Our code will be made available at\nhttps://github.com/Meituan-AutoML/CPVT .\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 10:29:55 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 10:59:50 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Tian", "Zhi", ""], ["Zhang", "Bo", ""], ["Wang", "Xinlong", ""], ["Wei", "Xiaolin", ""], ["Xia", "Huaxia", ""], ["Shen", "Chunhua", ""]]}, {"id": "2102.10923", "submitter": "Mateus Riva", "authors": "Mateus Riva, Pietro Gori, Florian Yger, Roberto Cesar, Isabelle Bloch", "title": "Approximation of dilation-based spatial relations to add structural\n  constraints in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial relations between objects in an image have proved useful for\nstructural object recognition. Structural constraints can act as regularization\nin neural network training, improving generalization capability with small\ndatasets. Several relations can be modeled as a morphological dilation of a\nreference object with a structuring element representing the semantics of the\nrelation, from which the degree of satisfaction of the relation between another\nobject and the reference object can be derived. However, dilation is not\ndifferentiable, requiring an approximation to be used in the context of\ngradient-descent training of a network. We propose to approximate dilations\nusing convolutions based on a kernel equal to the structuring element. We show\nthat the proposed approximation, even if slightly less accurate than previous\napproximations, is definitely faster to compute and therefore more suitable for\ncomputationally intensive neural network applications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 11:44:02 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Riva", "Mateus", ""], ["Gori", "Pietro", ""], ["Yger", "Florian", ""], ["Cesar", "Roberto", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2102.10934", "submitter": "Tingyu Xia", "authors": "Tingyu Xia, Yue Wang, Yuan Tian, Yi Chang", "title": "Using Prior Knowledge to Guide BERT's Attention in Semantic Textual\n  Matching Tasks", "comments": "10 pages, WWW'21, April19-23, 2021, Ljubljana, Slovenia", "journal-ref": null, "doi": "10.1145/3442381.3449988", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of incorporating prior knowledge into a deep\nTransformer-based model,i.e.,Bidirectional Encoder Representations from\nTransformers (BERT), to enhance its performance on semantic textual matching\ntasks. By probing and analyzing what BERT has already known when solving this\ntask, we obtain better understanding of what task-specific knowledge BERT needs\nthe most and where it is most needed. The analysis further motivates us to take\na different approach than most existing works. Instead of using prior knowledge\nto create a new training task for fine-tuning BERT, we directly inject\nknowledge into BERT's multi-head attention mechanism. This leads us to a simple\nyet effective approach that enjoys fast training stage as it saves the model\nfrom training on additional data or tasks other than the main task. Extensive\nexperiments demonstrate that the proposed knowledge-enhanced BERT is able to\nconsistently improve semantic textual matching performance over the original\nBERT model, and the performance benefit is most salient when training data is\nscarce.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:07:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Xia", "Tingyu", ""], ["Wang", "Yue", ""], ["Tian", "Yuan", ""], ["Chang", "Yi", ""]]}, {"id": "2102.10936", "submitter": "Inga Str\\\"umke", "authors": "Daniel Fryer and Inga Str\\\"umke and Hien Nguyen", "title": "Shapley values for feature selection: The good, the bad, and the axioms", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Shapley value has become popular in the Explainable AI (XAI) literature,\nthanks, to a large extent, to a solid theoretical foundation, including four\n\"favourable and fair\" axioms for attribution in transferable utility games. The\nShapley value is provably the only solution concept satisfying these axioms. In\nthis paper, we introduce the Shapley value and draw attention to its recent\nuses as a feature selection tool. We call into question this use of the Shapley\nvalue, using simple, abstract \"toy\" counterexamples to illustrate that the\naxioms may work against the goals of feature selection. From this, we develop a\nnumber of insights that are then investigated in concrete simulation settings,\nwith a variety of Shapley value formulations, including SHapley Additive\nexPlanations (SHAP) and Shapley Additive Global importancE (SAGE).\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:09:08 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Fryer", "Daniel", ""], ["Str\u00fcmke", "Inga", ""], ["Nguyen", "Hien", ""]]}, {"id": "2102.10952", "submitter": "Rupsa Saha", "authors": "Rupsa Saha, Ole-Christoffer Granmo, Vladimir I. Zadorozhny, Morten\n  Goodwin", "title": "A Relational Tsetlin Machine with Applications to Natural Language\n  Understanding", "comments": "14 pages, 3 figures, 7 tables, relational approach to TM in NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TMs are a pattern recognition approach that uses finite state machines for\nlearning and propositional logic to represent patterns. In addition to being\nnatively interpretable, they have provided competitive accuracy for various\ntasks. In this paper, we increase the computing power of TMs by proposing a\nfirst-order logic-based framework with Herbrand semantics. The resulting TM is\nrelational and can take advantage of logical structures appearing in natural\nlanguage, to learn rules that represent how actions and consequences are\nrelated in the real world. The outcome is a logic program of Horn clauses,\nbringing in a structured view of unstructured data. In closed-domain\nquestion-answering, the first-order representation produces 10x more compact\nKBs, along with an increase in answering accuracy from 94.83% to 99.48%. The\napproach is further robust towards erroneous, missing, and superfluous\ninformation, distilling the aspects of a text that are important for real-world\nunderstanding.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 12:40:37 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Saha", "Rupsa", ""], ["Granmo", "Ole-Christoffer", ""], ["Zadorozhny", "Vladimir I.", ""], ["Goodwin", "Morten", ""]]}, {"id": "2102.10978", "submitter": "Rohan Yashraj Gupta", "authors": "Rohan Yashraj Gupta, Satya Sai Mudigonda, Pallav Kumar Baruah and\n  Phani Krishna Kandala", "title": "Markov model with machine learning integration for fraud detection in\n  health insurance", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud has led to a huge addition of expenses in health insurance sector in\nIndia. The work is aimed to provide methods applied to health insurance fraud\ndetection. The work presents two approaches - a markov model and an improved\nmarkov model using gradient boosting method in health insurance claims. The\ndataset 382,587 claims of which 38,082 claims are fraudulent. The markov based\nmodel gave the accuracy of 94.07% with F1-score at 0.6683. However, the\nimproved markov model performed much better in comparison with the accuracy of\n97.10% and F1-score of 0.8546. It was observed that the improved markov model\ngave much lower false positives compared to markov model.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 13:01:28 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gupta", "Rohan Yashraj", ""], ["Mudigonda", "Satya Sai", ""], ["Baruah", "Pallav Kumar", ""], ["Kandala", "Phani Krishna", ""]]}, {"id": "2102.10985", "submitter": "Ilche Georgievski", "authors": "Sebastian Graef and Ilche Georgievski", "title": "Software Architecture for Next-Generation AI Planning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) planning is a flourishing research and\ndevelopment discipline that provides powerful tools for searching a course of\naction that achieves some user goal. While these planning tools show excellent\nperformance on benchmark planning problems, they represent challenging software\nsystems when it comes to their use and integration in real-world applications.\nIn fact, even in-depth understanding of their internal mechanisms does not\nguarantee that one can successfully set up, use and manipulate existing\nplanning tools. We contribute toward alleviating this situation by proposing a\nservice-oriented planning architecture to be at the core of the ability to\ndesign, develop and use next-generation AI planning systems. We collect and\nclassify common planning capabilities to form the building blocks of the\nplanning architecture. We incorporate software design principles and patterns\ninto the architecture to allow for usability, interoperability and reusability\nof the planning capabilities. Our prototype planning system demonstrates the\npotential of our approach for rapid prototyping and flexibility of system\ncomposition. Finally, we provide insight into the qualitative advantages of our\napproach when compared to a typical planning tool.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 13:43:45 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Graef", "Sebastian", ""], ["Georgievski", "Ilche", ""]]}, {"id": "2102.10993", "submitter": "Takato Nishijima", "authors": "Takato Nishijima", "title": "Universal Approximation Theorem for Neural Networks", "comments": "118 pages, in Japanese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there any theoretical guarantee for the approximation ability of neural\nnetworks? The answer to this question is the \"Universal Approximation Theorem\nfor Neural Networks\". This theorem states that a neural network is dense in a\ncertain function space under an appropriate setting. This paper is a\ncomprehensive explanation of the universal approximation theorem for\nfeedforward neural networks, its approximation rate problem (the relation\nbetween the number of intermediate units and the approximation error), and\nBarron space in Japanese.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:25:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Nishijima", "Takato", ""]]}, {"id": "2102.11005", "submitter": "Kaichao You", "authors": "Kaichao You, Yong Liu, Jianmin Wang, Mingsheng Long", "title": "LogME: Practical Assessment of Pre-trained Models for Transfer Learning", "comments": "13 pages (ICML 2021 camera ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies task adaptive pre-trained model selection, an\nunderexplored problem of assessing pre-trained models for the target task and\nselect best ones from the model zoo \\emph{without fine-tuning}. A few pilot\nworks addressed the problem in transferring supervised pre-trained models to\nclassification tasks, but they cannot handle emerging unsupervised pre-trained\nmodels or regression tasks. In pursuit of a practical assessment method, we\npropose to estimate the maximum value of label evidence given features\nextracted by pre-trained models. Unlike the maximum likelihood, the maximum\nevidence is \\emph{immune to over-fitting}, while its expensive computation can\nbe dramatically reduced by our carefully designed algorithm. The Logarithm of\nMaximum Evidence (LogME) can be used to assess pre-trained models for transfer\nlearning: a pre-trained model with a high LogME value is likely to have good\ntransfer performance. LogME is \\emph{fast, accurate, and general},\ncharacterizing itself as the first practical method for assessing pre-trained\nmodels. Compared with brute-force fine-tuning, LogME brings at most\n$3000\\times$ speedup in wall-clock time and requires only $1\\%$ memory\nfootprint. It outperforms prior methods by a large margin in their setting and\nis applicable to new settings. It is general enough for diverse pre-trained\nmodels (supervised pre-trained and unsupervised pre-trained), downstream tasks\n(classification and regression), and modalities (vision and language). Code is\navailable at this repository:\n\\href{https://github.com/thuml/LogME}{https://github.com/thuml/LogME}.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 13:58:11 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 16:02:35 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 11:13:43 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["You", "Kaichao", ""], ["Liu", "Yong", ""], ["Wang", "Jianmin", ""], ["Long", "Mingsheng", ""]]}, {"id": "2102.11011", "submitter": "Avi Schwarzschild", "authors": "Avi Schwarzschild, Arjun Gupta, Amin Ghiasi, Micah Goldblum, Tom\n  Goldstein", "title": "The Uncanny Similarity of Recurrence and Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is widely believed that deep neural networks contain layer specialization,\nwherein networks extract hierarchical features representing edges and patterns\nin shallow layers and complete objects in deeper layers. Unlike common\nfeed-forward models that have distinct filters at each layer, recurrent\nnetworks reuse the same parameters at various depths. In this work, we observe\nthat recurrent models exhibit the same hierarchical behaviors and the same\nperformance benefits as depth despite reusing the same filters at every\nrecurrence. By training models of various feed-forward and recurrent\narchitectures on several datasets for image classification as well as maze\nsolving, we show that recurrent networks have the ability to closely emulate\nthe behavior of non-recurrent deep models, often doing so with far fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:09:20 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 13:47:07 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 17:10:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Schwarzschild", "Avi", ""], ["Gupta", "Arjun", ""], ["Ghiasi", "Amin", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2102.11012", "submitter": "Barry-John Theobald", "authors": "Andrew Silva, Barry-John Theobald, Nicholas Apostoloff", "title": "Multimodal Punctuation Prediction with Contextual Dropout", "comments": "Accepted for publication at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) is widely used in consumer electronics.\nASR greatly improves the utility and accessibility of technology, but usually\nthe output is only word sequences without punctuation. This can result in\nambiguity in inferring user-intent. We first present a transformer-based\napproach for punctuation prediction that achieves 8% improvement on the IWSLT\n2012 TED Task, beating the previous state of the art [1]. We next describe our\nmultimodal model that learns from both text and audio, which achieves 8%\nimprovement over the text-only algorithm on an internal dataset for which we\nhave both the audio and transcriptions. Finally, we present an approach to\nlearning a model using contextual dropout that allows us to handle variable\namounts of future context at test time.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:15:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Silva", "Andrew", ""], ["Theobald", "Barry-John", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "2102.11023", "submitter": "Boyu Zhang", "authors": "Boyu Zhang, Mushen Zhou, Jianzhong Wu, Fuchang Gao", "title": "Predicting Material Properties Using a 3D Graph Neural Network with\n  Invariant Local Descriptors", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately predicting material properties is critical for discovering and\ndesigning novel materials. Machine learning technologies have attracted\nsignificant attention in materials science community for their potential for\nlarge-scale screening. Among the machine learning methods, graph convolution\nneural networks (GCNNs) have been one of the most successful ones because of\ntheir flexibility and effectiveness in describing 3D structural data. Most\nexisting GCNN models focus on the topological structure but overly simplify the\nthree-dimensional geometric structure. In materials science, the 3D-spatial\ndistribution of the atoms, however, is crucial for determining the atomic\nstates and interatomic forces. In this paper, we propose an adaptive GCNN with\nnovel convolutions that model interactions among all neighboring atoms in\nthree-dimensional space simultaneously. We apply the model to two distinctly\nchallenging problems on predicting material properties. The first is Henry's\nconstant for gas adsorption in Metal-Organic Frameworks (MOFs), which is\nnotoriously difficult because of its high sensitivity to atomic configurations.\nThe second is the ion conductivity of solid-state crystal materials, which is\ndifficult because of very few labeled data available for training. The new\nmodel outperforms existing GCNN models on both data sets, suggesting that some\nimportant three-dimensional geometric information is indeed captured by the new\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:56:54 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhang", "Boyu", ""], ["Zhou", "Mushen", ""], ["Wu", "Jianzhong", ""], ["Gao", "Fuchang", ""]]}, {"id": "2102.11025", "submitter": "Emiliano Lorini", "authors": "Emiliano Lorini", "title": "A Qualitative Theory of Cognitive Attitudes and their Change", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": "10.1017/S1471068421000053", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general logical framework for reasoning about agents' cognitive\nattitudes of both epistemic type and motivational type. We show that it allows\nus to express a variety of relevant concepts for qualitative decision theory\nincluding the concepts of knowledge, belief, strong belief, conditional belief,\ndesire, conditional desire, strong desire and preference. We also present two\nextensions of the logic, one by the notion of choice and the other by dynamic\noperators for belief change and desire change, and we apply the former to the\nanalysis of single-stage games under incomplete information. We provide sound\nand complete axiomatizations for the basic logic and for its two extensions.\nThe paper is under consideration in Theory and Practice of Logic Programming\n(TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:28:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Lorini", "Emiliano", ""]]}, {"id": "2102.11047", "submitter": "Muhammad Hamzah Mushtaq", "authors": "Muhammad Hamzah Mushtaq", "title": "Semantic Parsing to Manipulate Relational Database For a Management\n  System", "comments": "5 pages. Figures, methodology and comparisons included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Chatbots and AI assistants have claimed their importance in today life. The\nmain reason behind adopting this technology is to connect with the user,\nunderstand their requirements, and fulfill them. This has been achieved but at\nthe cost of heavy training data and complex learning models. This work is\ncarried out proposes a simple algorithm, a model which can be implemented in\ndifferent fields each with its own work scope. The proposed model converts\nhuman language text to computer-understandable SQL queries. The model requires\ndata only related to the specific field, saving data space. This model performs\nlinear computation hence solving the computational complexity. This work also\ndefines the stages where a new methodology is implemented and what previous\nmethod was adopted to fulfill the requirement at that stage. Two datasets\navailable online will be used in this work, the ATIS dataset, and WikiSQL. This\nwork compares the computation time among the 2 datasets and also compares the\naccuracy of both. This paper works over basic Natural language processing tasks\nlike semantic parsing, NER, parts of speech and tends to achieve results\nthrough these simple methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 15:08:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mushtaq", "Muhammad Hamzah", ""]]}, {"id": "2102.11051", "submitter": "Nikola Vulin", "authors": "Nikola Vulin, Sammy Christen, Stefan Stevsic and Otmar Hilliges", "title": "Improved Learning of Robot Manipulation Tasks via Tactile Intrinsic\n  Motivation", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/LRA.2021.3061308", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the challenge of exploration in deep reinforcement\nlearning for robotic manipulation tasks. In sparse goal settings, an agent does\nnot receive any positive feedback until randomly achieving the goal, which\nbecomes infeasible for longer control sequences. Inspired by touch-based\nexploration observed in children, we formulate an intrinsic reward based on the\nsum of forces between a robot's force sensors and manipulation objects that\nencourages physical interaction. Furthermore, we introduce contact-prioritized\nexperience replay, a sampling scheme that prioritizes contact rich episodes and\ntransitions. We show that our solution accelerates the exploration and\noutperforms state-of-the-art methods on three fundamental robot manipulation\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:21:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vulin", "Nikola", ""], ["Christen", "Sammy", ""], ["Stevsic", "Stefan", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2102.11068", "submitter": "Ning Liu", "authors": "Ning Liu, Geng Yuan, Zhengping Che, Xuan Shen, Xiaolong Ma, Qing Jin,\n  Jian Ren, Jian Tang, Sijia Liu, Yanzhi Wang", "title": "Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep model compression, the recent finding \"Lottery Ticket Hypothesis\"\n(LTH) (Frankle & Carbin, 2018) pointed out that there could exist a winning\nticket (i.e., a properly pruned sub-network together with original weight\ninitialization) that can achieve competitive performance than the original\ndense network. However, it is not easy to observe such winning property in many\nscenarios, where for example, a relatively large learning rate is used even if\nit benefits training the original dense model. In this work, we investigate the\nunderlying condition and rationale behind the winning property, and find that\nthe underlying reason is largely attributed to the correlation between\ninitialized weights and final-trained weights when the learning rate is not\nsufficiently large. Thus, the existence of winning property is correlated with\nan insufficient DNN pretraining, and is unlikely to occur for a well-trained\nDNN. To overcome this limitation, we propose the \"pruning & fine-tuning\" method\nthat consistently outperforms lottery ticket sparse training under the same\npruning algorithm and the same total training epochs. Extensive experiments\nover multiple deep models (VGG, ResNet, MobileNet-v2) on different datasets\nhave been conducted to justify our proposals.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 14:49:46 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 08:19:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Ning", ""], ["Yuan", "Geng", ""], ["Che", "Zhengping", ""], ["Shen", "Xuan", ""], ["Ma", "Xiaolong", ""], ["Jin", "Qing", ""], ["Ren", "Jian", ""], ["Tang", "Jian", ""], ["Liu", "Sijia", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2102.11069", "submitter": "Guillaume Vidot", "authors": "Guillaume Vidot (IRIT), Paul Viallard (LHC), Amaury Habrard (LHC),\n  Emilie Morvant (LHC)", "title": "A PAC-Bayes Analysis of Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first general PAC-Bayesian generalization bounds for\nadversarial robustness, that estimate, at test time, how much a model will be\ninvariant to imperceptible perturbations in the input. Instead of deriving a\nworst-case analysis of the risk of a hypothesis over all the possible\nperturbations, we leverage the PAC-Bayesian framework to bound the averaged\nrisk on the perturbations for majority votes (over the whole class of\nhypotheses). Our theoretically founded analysis has the advantage to provide\ngeneral bounds (i) independent from the type of perturbations (i.e., the\nadversarial attacks), (ii) that are tight thanks to the PAC-Bayesian framework,\n(iii) that can be directly minimized during the learning phase to obtain a\nrobust model on different attacks at test time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 10:23:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vidot", "Guillaume", "", "IRIT"], ["Viallard", "Paul", "", "LHC"], ["Habrard", "Amaury", "", "LHC"], ["Morvant", "Emilie", "", "LHC"]]}, {"id": "2102.11085", "submitter": "Serkan Budak", "authors": "Serkan Budak and Bahadir Akbal", "title": "Comparative Fault Location Estimation by Using Image Processing in Mixed\n  Transmission Lines", "comments": "arXiv admin note: substantial text overlap with arXiv:2011.03238", "journal-ref": "Konya Journal of Engineering Sciences v. 8, Special Issue, pp.\n  62-75, (2020)", "doi": "10.36306/konjes.821726", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distance protection relays are used to determine the impedance based\nfault location according to the current and voltage magnitudes in the\ntransmission lines. However, the fault location cannot be correctly detected in\nmixed transmission lines due to different characteristic impedance per unit\nlength because the characteristic impedance of high voltage cable line is\nsignificantly different from overhead line. Thus, determinations of the fault\nsection and location with the distance protection relays are difficult in the\nmixed transmission lines. In this study, 154 kV overhead transmission line and\nunderground cable line are examined as the mixed transmission line for the\ndistance protection relays. Phase to ground faults are created in the mixed\ntransmission line. overhead line section and underground cable section are\nsimulated by using PSCAD-EMTDC.The short circuit fault images are generated in\nthe distance protection relay for the overhead transmission line and\nunderground cable transmission line faults. The images include the R-X\nimpedance diagram of the fault, and the R-X impedance diagram have been\ndetected by applying image processing steps. Artificial neural network (ANN)\nand the regression methods are used for prediction of the fault location, and\nthe results of image processing are used as the input parameters for the\ntraining process of ANN and the regression methods. The results of ANN and\nregression methods are compared to select the most suitable method at the end\nof this study for forecasting of the fault location in transmission lines.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:57:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Budak", "Serkan", ""], ["Akbal", "Bahadir", ""]]}, {"id": "2102.11086", "submitter": "Chris J. Maddison", "authors": "Yangjun Ruan, Karen Ullrich, Daniel Severo, James Townsend, Ashish\n  Khisti, Arnaud Doucet, Alireza Makhzani, Chris J. Maddison", "title": "Improving Lossless Compression Rates via Monte Carlo Bits-Back Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models have been successfully applied in lossless compression\nwith the bits-back coding algorithm. However, bits-back suffers from an\nincrease in the bitrate equal to the KL divergence between the approximate\nposterior and the true posterior. In this paper, we show how to remove this gap\nasymptotically by deriving bits-back coding algorithms from tighter variational\nbounds. The key idea is to exploit extended space representations of Monte\nCarlo estimators of the marginal likelihood. Naively applied, our schemes would\nrequire more initial bits than the standard bits-back coder, but we show how to\ndrastically reduce this additional cost with couplings in the latent space.\nWhen parallel architectures can be exploited, our coders can achieve better\nrates than bits-back with little additional cost. We demonstrate improved\nlossless compression rates in a variety of settings, especially in\nout-of-distribution or sequential data compression.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:58:01 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 01:38:37 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ruan", "Yangjun", ""], ["Ullrich", "Karen", ""], ["Severo", "Daniel", ""], ["Townsend", "James", ""], ["Khisti", "Ashish", ""], ["Doucet", "Arnaud", ""], ["Makhzani", "Alireza", ""], ["Maddison", "Chris J.", ""]]}, {"id": "2102.11090", "submitter": "Philipp Dufter", "authors": "Philipp Dufter, Martin Schmitt, Hinrich Sch\\\"utze", "title": "Position Information in Transformers: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are arguably the main workhorse in recent Natural Language\nProcessing research. By definition a Transformer is invariant with respect to\nreorderings of the input. However, language is inherently sequential and word\norder is essential to the semantics and syntax of an utterance. In this paper,\nwe provide an overview of common methods to incorporate position information\ninto Transformer models. The objectives of this survey are to i) showcase that\nposition information in Transformer is a vibrant and extensive research area;\nii) enable the reader to compare existing methods by providing a unified\nnotation and meaningful clustering; iii) indicate what characteristics of an\napplication should be taken into account when selecting a position encoding;\niv) provide stimuli for future research.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 15:03:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dufter", "Philipp", ""], ["Schmitt", "Martin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2102.11107", "submitter": "Francesco Locatello", "authors": "Bernhard Sch\\\"olkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary\n  Ke, Nal Kalchbrenner, Anirudh Goyal, Yoshua Bengio", "title": "Towards Causal Representation Learning", "comments": "Special Issue of Proceedings of the IEEE - Advances in Machine\n  Learning and Deep Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two fields of machine learning and graphical causality arose and\ndeveloped separately. However, there is now cross-pollination and increasing\ninterest in both fields to benefit from the advances of the other. In the\npresent paper, we review fundamental concepts of causal inference and relate\nthem to crucial open problems of machine learning, including transfer and\ngeneralization, thereby assaying how causality can contribute to modern machine\nlearning research. This also applies in the opposite direction: we note that\nmost work in causality starts from the premise that the causal variables are\ngiven. A central problem for AI and causality is, thus, causal representation\nlearning, the discovery of high-level causal variables from low-level\nobservations. Finally, we delineate some implications of causality for machine\nlearning and propose key research areas at the intersection of both\ncommunities.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 15:26:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sch\u00f6lkopf", "Bernhard", ""], ["Locatello", "Francesco", ""], ["Bauer", "Stefan", ""], ["Ke", "Nan Rosemary", ""], ["Kalchbrenner", "Nal", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2102.11132", "submitter": "Xuehao Liu", "authors": "Xuehao Liu, Sarah Jane Delany, Susan McKeever", "title": "Wider Vision: Enriching Convolutional Neural Networks via Alignment to\n  External Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep learning models suffer from opaqueness. For Convolutional Neural\nNetworks (CNNs), current research strategies for explaining models focus on the\ntarget classes within the associated training dataset. As a result, the\nunderstanding of hidden feature map activations is limited by the\ndiscriminative knowledge gleaned during training. The aim of our work is to\nexplain and expand CNNs models via the mirroring or alignment of CNN to an\nexternal knowledge base. This will allow us to give a semantic context or label\nfor each visual feature. We can match CNN feature activations to nodes in our\nexternal knowledge base. This supports knowledge-based interpretation of the\nfeatures associated with model decisions. To demonstrate our approach, we build\ntwo separate graphs. We use an entity alignment method to align the feature\nnodes in a CNN with the nodes in a ConceptNet based knowledge graph. We then\nmeasure the proximity of CNN graph nodes to semantically meaningful knowledge\nbase nodes. Our results show that in the aligned embedding space, nodes from\nthe knowledge graph are close to the CNN feature nodes that have similar\nmeanings, indicating that nodes from an external knowledge base can act as\nexplanatory semantic references for features in the model. We analyse a variety\nof graph building methods in order to improve the results from our embedding\nspace. We further demonstrate that by using hierarchical relationships from our\nexternal knowledge base, we can locate new unseen classes outside the CNN\ntraining set in our embeddings space, based on visual feature activations. This\nsuggests that we can adapt our approach to identify unseen classes based on CNN\nfeature activations. Our demonstrated approach of aligning a CNN with an\nexternal knowledge base paves the way to reason about and beyond the trained\nmodel, with future adaptations to explainable models and zero-shot learning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:00:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Liu", "Xuehao", ""], ["Delany", "Sarah Jane", ""], ["McKeever", "Susan", ""]]}, {"id": "2102.11137", "submitter": "Yichen Yang", "authors": "Yichen Yang, Jeevana Priya Inala, Osbert Bastani, Yewen Pu, Armando\n  Solar-Lezama, Martin Rinard", "title": "Program Synthesis Guided Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for reinforcement learning is solving long-horizon planning\nand control problems. Recent work has proposed leveraging programs to help\nguide the learning algorithm in these settings. However, these approaches\nimpose a high manual burden on the user since they must provide a guiding\nprogram for every new task they seek to achieve. We propose an approach that\nleverages program synthesis to automatically generate the guiding program. A\nkey challenge is how to handle partially observable environments. We propose\nmodel predictive program synthesis, which trains a generative model to predict\nthe unobserved portions of the world, and then synthesizes a program based on\nsamples from this model in a way that is robust to its uncertainty. We evaluate\nour approach on a set of challenging benchmarks, including a 2D\nMinecraft-inspired ``craft'' environment where the agent must perform a complex\nsequence of subtasks to achieve its goal, a box-world environment that requires\nabstract reasoning, and a variant of the craft environment where the agent is a\nMuJoCo Ant. Our approach significantly outperforms several baselines, and\nperforms essentially as well as an oracle that is given an effective program.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:05:32 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Yang", "Yichen", ""], ["Inala", "Jeevana Priya", ""], ["Bastani", "Osbert", ""], ["Pu", "Yewen", ""], ["Solar-Lezama", "Armando", ""], ["Rinard", "Martin", ""]]}, {"id": "2102.11158", "submitter": "Shuxiao Chen", "authors": "Qinqing Zheng, Shuxiao Chen, Qi Long, Weijie J. Su", "title": "Federated $f$-Differential Privacy", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a training paradigm where the clients\ncollaboratively learn models by repeatedly sharing information without\ncompromising much on the privacy of their local sensitive data. In this paper,\nwe introduce federated $f$-differential privacy, a new notion specifically\ntailored to the federated setting, based on the framework of Gaussian\ndifferential privacy. Federated $f$-differential privacy operates on record\nlevel: it provides the privacy guarantee on each individual record of one\nclient's data against adversaries. We then propose a generic private federated\nlearning framework {PriFedSync} that accommodates a large family of\nstate-of-the-art FL algorithms, which provably achieves federated\n$f$-differential privacy. Finally, we empirically demonstrate the trade-off\nbetween privacy guarantee and prediction performance for models trained by\n{PriFedSync} in computer vision tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:28:21 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zheng", "Qinqing", ""], ["Chen", "Shuxiao", ""], ["Long", "Qi", ""], ["Su", "Weijie J.", ""]]}, {"id": "2102.11176", "submitter": "David Sandberg", "authors": "Ursula Challita, David Sandberg", "title": "Deep Reinforcement Learning for Dynamic Spectrum Sharing of LTE and NR", "comments": "To appear in the IEEE International Conference on Communications\n  (ICC'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a proactive dynamic spectrum sharing scheme between 4G and 5G\nsystems is proposed. In particular, a controller decides on the resource split\nbetween NR and LTE every subframe while accounting for future network states\nsuch as high interference subframes and multimedia broadcast single frequency\nnetwork (MBSFN) subframes. To solve this problem, a deep reinforcement learning\n(RL) algorithm based on Monte Carlo Tree Search (MCTS) is proposed. The\nintroduced deep RL architecture is trained offline whereby the controller\npredicts a sequence of future states of the wireless access network by\nsimulating hypothetical bandwidth splits over time starting from the current\nnetwork state. The action sequence resulting in the best reward is then\nassigned. This is realized by predicting the quantities most directly relevant\nto planning, i.e., the reward, the action probabilities, and the value for each\nnetwork state. Simulation results show that the proposed scheme is able to take\nactions while accounting for future states instead of being greedy in each\nsubframe. The results also show that the proposed framework improves\nsystem-level performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:56:51 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Challita", "Ursula", ""], ["Sandberg", "David", ""]]}, {"id": "2102.11203", "submitter": "Tianle Cai", "authors": "Tianle Cai, Ruiqi Gao, Jason D. Lee, Qi Lei", "title": "A Theory of Label Propagation for Subpopulation Shift", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central problems in machine learning is domain adaptation. Unlike\npast theoretical work, we consider a new model for subpopulation shift in the\ninput or representation space. In this work, we propose a provably effective\nframework for domain adaptation based on label propagation. In our analysis, we\nuse a simple but realistic expansion assumption, proposed in\n\\citet{wei2021theoretical}. Using a teacher classifier trained on the source\ndomain, our algorithm not only propagates to the target domain but also\nimproves upon the teacher. By leveraging existing generalization bounds, we\nalso obtain end-to-end finite-sample guarantees on the entire algorithm. In\naddition, we extend our theoretical framework to a more general setting of\nsource-to-target transfer based on a third unlabeled dataset, which can be\neasily applied in various learning scenarios. Inspired by our theory, we adapt\nconsistency-based semi-supervised learning methods to domain adaptation\nsettings and gain significant improvements.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 17:27:47 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 09:26:46 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 01:59:03 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cai", "Tianle", ""], ["Gao", "Ruiqi", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2102.11211", "submitter": "Jip Van Stijn", "authors": "Jip van Stijn", "title": "Moral Decision-Making in Medical Hybrid Intelligent Systems: A Team\n  Design Patterns Approach to the Bias Mitigation and Data Sharing Design\n  Problems", "comments": "87 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Increasing automation in the healthcare sector calls for a Hybrid\nIntelligence (HI) approach to closely study and design the collaboration of\nhumans and autonomous machines. Ensuring that medical HI systems'\ndecision-making is ethical is key. The use of Team Design Patterns (TDPs) can\nadvance this goal by describing successful and reusable configurations of\ndesign problems in which decisions have a moral component, as well as through\nfacilitating communication in multidisciplinary teams designing HI systems. For\nthis research, TDPs were developed to describe a set of solutions for two\ndesign problems in a medical HI system: (1) mitigating harmful biases in\nmachine learning algorithms and (2) sharing health and behavioral patient data\nwith healthcare professionals and system developers. The Socio-Cognitive\nEngineering methodology was employed, integrating operational demands, human\nfactors knowledge, and a technological analysis into a set of TDPs. A survey\nwas created to assess the usability of the patterns on their understandability,\neffectiveness, and generalizability. The results showed that TDPs are a useful\nmethod to unambiguously describe solutions for diverse HI design problems with\na moral component on varying abstraction levels, that are usable by a\nheterogeneous group of multidisciplinary researchers. Additionally, results\nindicated that the SCE approach and the developed questionnaire are suitable\nmethods for creating and assessing TDPs. The study concludes with a set of\nproposed improvements to TDPs, including their integration with Interaction\nDesign Patterns, the inclusion of several additional concepts, and a number of\nmethodological improvements. Finally, the thesis recommends directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:09:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["van Stijn", "Jip", ""]]}, {"id": "2102.11232", "submitter": "Mirza Rami\\v{c}i\\'c", "authors": "Mirza Ramicic and Andrea Bonarini", "title": "Uncertainty Maximization in Partially Observable Domains: A Cognitive\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with an ever-increasing complexity of their domains of application,\nartificial learning agents are now able to scale up in their ability to process\nan overwhelming amount of information coming from their interaction with an\nenvironment. However, this process of scaling does come with a cost of encoding\nand processing an increasing amount of redundant information that is not\nnecessarily beneficial to the learning process itself. This work exploits the\nproperties of the learning systems defined over partially observable domains by\nselectively focusing on the specific type of information that is more likely to\nexpress the causal interaction among the transitioning states of the\nenvironment. Adaptive masking of the observation space based on the\n$\\textit{temporal difference displacement}$ criterion enabled a significant\nimprovement in convergence of temporal difference algorithms defined over a\npartially observable Markov process.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:05:41 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 15:02:21 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 20:16:03 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ramicic", "Mirza", ""], ["Bonarini", "Andrea", ""]]}, {"id": "2102.11237", "submitter": "Sulabh Katiyar", "authors": "Sulabh Katiyar, Samir Kumar Borgohain", "title": "Image Captioning using Deep Stacked LSTMs, Contextual Word Embeddings\n  and Data Augmentation", "comments": "Accepted for publication in Springer Book Series: Advances in\n  Intelligent Systems and Computing - ISSN 2194-5357. Upon publication, this\n  article will point to the published one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Image Captioning, or the automatic generation of descriptions for images, is\none of the core problems in Computer Vision and has seen considerable progress\nusing Deep Learning Techniques. We propose to use Inception-ResNet\nConvolutional Neural Network as encoder to extract features from images,\nHierarchical Context based Word Embeddings for word representations and a Deep\nStacked Long Short Term Memory network as decoder, in addition to using Image\nData Augmentation to avoid over-fitting. For data Augmentation, we use\nHorizontal and Vertical Flipping in addition to Perspective Transformations on\nthe images. We evaluate our proposed methods with two image captioning\nframeworks- Encoder-Decoder and Soft Attention. Evaluation on widely used\nmetrics have shown that our approach leads to considerable improvement in model\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:15:39 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Katiyar", "Sulabh", ""], ["Borgohain", "Samir Kumar", ""]]}, {"id": "2102.11258", "submitter": "Sandeep Mathias", "authors": "Sandeep Mathias, Rudra Murthy, Diptesh Kanojia, and Pushpak\n  Bhattacharyya", "title": "Cognitively Aided Zero-Shot Automatic Essay Grading", "comments": "This paper was accepted for publication at ICON 2020: The 17th\n  International Conference on Natural Language Processing, on December 20, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic essay grading (AEG) is a process in which machines assign a grade\nto an essay written in response to a topic, called the prompt. Zero-shot AEG is\nwhen we train a system to grade essays written to a new prompt which was not\npresent in our training data. In this paper, we describe a solution to the\nproblem of zero-shot automatic essay grading, using cognitive information, in\nthe form of gaze behaviour. Our experiments show that using gaze behaviour\nhelps in improving the performance of AEG systems, especially when we provide a\nnew essay written in response to a new prompt for scoring, by an average of\nalmost 5 percentage points of QWK.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:41:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mathias", "Sandeep", ""], ["Murthy", "Rudra", ""], ["Kanojia", "Diptesh", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2102.11271", "submitter": "Denis Yarats", "authors": "Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto", "title": "Reinforcement Learning with Prototypical Representations", "comments": null, "journal-ref": "ICML 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning effective representations in image-based environments is crucial for\nsample efficient Reinforcement Learning (RL). Unfortunately, in RL,\nrepresentation learning is confounded with the exploratory experience of the\nagent -- learning a useful representation requires diverse data, while\neffective exploration is only possible with coherent representations.\nFurthermore, we would like to learn representations that not only generalize\nacross tasks but also accelerate downstream exploration for efficient\ntask-specific training. To address these challenges we propose Proto-RL, a\nself-supervised framework that ties representation learning with exploration\nthrough prototypical representations. These prototypes simultaneously serve as\na summarization of the exploratory experience of an agent as well as a basis\nfor representing observations. We pre-train these task-agnostic representations\nand prototypes on environments without downstream task information. This\nenables state-of-the-art downstream policy learning on a set of difficult\ncontinuous control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:56:34 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 17:36:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yarats", "Denis", ""], ["Fergus", "Rob", ""], ["Lazaric", "Alessandro", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2102.11314", "submitter": "Yuval Shahar", "authors": "Erez Shalom, Ayelet Goldstein, Elior Ariel, Moshe Sheinberger, Valerie\n  Jones, Boris Van Schooten, and Yuval Shahar", "title": "Distributed Application of Guideline-Based Decision Support through\n  Mobile Devices: Implementation and Evaluation", "comments": "8 Tables and 16 figures in the main text; two Appendices, one\n  including 1 figure, the other including 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Traditionally Guideline(GL)based Decision Support Systems (DSSs) use a\ncentralized infrastructure to generate recommendations to care providers.\nHowever, managing patients at home is preferable, reducing costs and empowering\npatients. We aimed to design, implement, and demonstrate the feasibility of a\nnew architecture for a distributed DSS that provides patients with\npersonalized, context-sensitive, evidence based guidance through their mobile\ndevice, and increases the robustness of the distributed application of the GL,\nwhile maintaining access to the patient longitudinal record and to an up to\ndate evidence based GL repository. We have designed and implemented a novel\nprojection and callback (PCB) model, in which small portions of the evidence\nbased GL procedural knowledge, adapted to the patient preferences and to their\ncurrent context, are projected from a central DSS server, to a local DSS on the\npatient mobile device that applies that knowledge. When appropriate, as defined\nby a temporal pattern within the projected plan, the local DSS calls back the\ncentral DSS, requesting further assistance, possibly another projection. Thus,\nthe GL specification includes two levels: one for the central DSS, one for the\nlocal DSS. We successfully evaluated the PCB model within the MobiGuide EU\nproject by managing Gestational Diabetes Mellitus patients in Spain, and Atrial\nFibrillation patients in Italy. Significant differences exist between the two\nGL representations, suggesting additional ways to characterize GLs. Mean time\nbetween the central and local interactions was quite different for the two GLs:\n3.95 days for gestational diabetes, 23.80 days for atrial fibrillation. Most\ninteractions, 83%, were due to projections to the mDSS. Others were data\nnotifications, mostly to change context. Robustness was demonstrated through\nsuccessful recovery from multiple local DSS crashes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:20:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Shalom", "Erez", ""], ["Goldstein", "Ayelet", ""], ["Ariel", "Elior", ""], ["Sheinberger", "Moshe", ""], ["Jones", "Valerie", ""], ["Van Schooten", "Boris", ""], ["Shahar", "Yuval", ""]]}, {"id": "2102.11318", "submitter": "Falguni Laljibhai Patel", "authors": "Falguni Patel, NirmalKumar Patel, Santosh Kumar Bharti", "title": "Lie-Sensor: A Live Emotion Verifier or a Licensor for Chat Applications\n  using Emotional Intelligence", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Veracity is an essential key in research and development of innovative\nproducts. Live Emotion analysis and verification nullify deceit made to\ncomplainers on live chat, corroborate messages of both ends in messaging apps\nand promote an honest conversation between users. The main concept behind this\nemotion artificial intelligent verifier is to license or decline message\naccountability by comparing variegated emotions of chat app users recognized\nthrough facial expressions and text prediction. In this paper, a proposed\nemotion intelligent live detector acts as an honest arbiter who distributes\nfacial emotions into labels namely, Happiness, Sadness, Surprise, and Hate.\nFurther, it separately predicts a label of messages through text\nclassification. Finally, it compares both labels and declares the message as a\nfraud or a bonafide. For emotion detection, we deployed Convolutional Neural\nNetwork (CNN) using a miniXception model and for text prediction, we selected\nSupport Vector Machine (SVM) natural language processing probability classifier\ndue to receiving the best accuracy on training dataset after applying Support\nVector Machine (SVM), Random Forest Classifier, Naive Bayes Classifier, and\nLogistic regression.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 02:47:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Patel", "Falguni", ""], ["Patel", "NirmalKumar", ""], ["Bharti", "Santosh Kumar", ""]]}, {"id": "2102.11319", "submitter": "Brett Daley", "authors": "Brett Daley, Cameron Hickert, Christopher Amato", "title": "Stratified Experience Replay: Correcting Multiplicity Bias in Off-Policy\n  Reinforcement Learning", "comments": "AAMAS 2021 Extended Abstract, 3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) methods rely on experience replay to\napproximate the minibatched supervised learning setting; however, unlike\nsupervised learning where access to lots of training data is crucial to\ngeneralization, replay-based deep RL appears to struggle in the presence of\nextraneous data. Recent works have shown that the performance of Deep Q-Network\n(DQN) degrades when its replay memory becomes too large.\n  This suggests that outdated experiences somehow impact the performance of\ndeep RL, which should not be the case for off-policy methods like DQN.\nConsequently, we re-examine the motivation for sampling uniformly over a replay\nmemory, and find that it may be flawed when using function approximation. We\nshow that -- despite conventional wisdom -- sampling from the uniform\ndistribution does not yield uncorrelated training samples and therefore biases\ngradients during training. Our theory prescribes a special non-uniform\ndistribution to cancel this effect, and we propose a stratified sampling scheme\nto efficiently implement it.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:29:18 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Daley", "Brett", ""], ["Hickert", "Cameron", ""], ["Amato", "Christopher", ""]]}, {"id": "2102.11327", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Nir Baram, Shie Mannor", "title": "GELATO: Geometrically Enriched Latent Model for Offline Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning approaches can generally be divided to\nproximal and uncertainty-aware methods. In this work, we demonstrate the\nbenefit of combining the two in a latent variational model. We impose a latent\nrepresentation of states and actions and leverage its intrinsic Riemannian\ngeometry to measure distance of latent samples to the data. Our proposed\nmetrics measure both the quality of out of distribution samples as well as the\ndiscrepancy of examples in the data. We integrate our metrics in a model-based\noffline optimization framework, in which proximity and uncertainty can be\ncarefully controlled. We illustrate the geodesics on a simple grid-like\nenvironment, depicting its natural inherent topology. Finally, we analyze our\napproach and improve upon contemporary offline RL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:42:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Baram", "Nir", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.11329", "submitter": "Guy Tennenholtz", "authors": "Nir Baram, Guy Tennenholtz, Shie Mannor", "title": "Action Redundancy in Reinforcement Learning", "comments": "Equal Contribution. In Proceedings UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning\nparadigm which seeks to maximize return under entropy regularization. However,\naction entropy does not necessarily coincide with state entropy, e.g., when\nmultiple actions produce the same transition. Instead, we propose to maximize\nthe transition entropy, i.e., the entropy of next states. We show that\ntransition entropy can be described by two terms; namely, model-dependent\ntransition entropy and action redundancy. Particularly, we explore the latter\nin both deterministic and stochastic settings and develop tractable\napproximation methods in a near model-free setup. We construct algorithms to\nminimize action redundancy and demonstrate their effectiveness on a synthetic\nenvironment with multiple redundant actions as well as contemporary benchmarks\nin Atari and Mujoco. Our results suggest that action redundancy is a\nfundamental problem in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:47:26 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 06:19:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Baram", "Nir", ""], ["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "2102.11352", "submitter": "Julie Jiang", "authors": "Julie Jiang, Kristina Lerman, Emilio Ferrara", "title": "Individualized Context-Aware Tensor Factorization for Online Games\n  Predictions", "comments": null, "journal-ref": "2020 International Conference on Data Mining Workshops (ICDMW)", "doi": "10.1109/ICDMW51313.2020.00048", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual behavior and decisions are substantially influenced by their\ncontexts, such as location, environment, and time. Changes along these\ndimensions can be readily observed in Multiplayer Online Battle Arena games\n(MOBA), where players face different in-game settings for each match and are\nsubject to frequent game patches. Existing methods utilizing contextual\ninformation generalize the effect of a context over the entire population, but\ncontextual information tailored to each individual can be more effective. To\nachieve this, we present the Neural Individualized Context-aware Embeddings\n(NICE) model for predicting user performance and game outcomes. Our proposed\nmethod identifies individual behavioral differences in different contexts by\nlearning latent representations of users and contexts through non-negative\ntensor factorization. Using a dataset from the MOBA game League of Legends, we\ndemonstrate that our model substantially improves the prediction of winning\noutcome, individual user performance, and user engagement.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 20:46:02 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Jiang", "Julie", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2102.11361", "submitter": "Xavier Gonzalez I", "authors": "Xavier Ignacio Gonz\\'alez", "title": "The FaCells. An Exploratory Study about LSTM Layers on Face Sketches\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lines are human mental abstractions. A bunch of lines may form a drawing. A\nset of drawings can feed an LSTM network input layer, considering each draw as\na list of lines and a line a list of points. This paper proposes the pointless\nmotive to classify the gender of celebrities' portraits as an excuse for\nexploration in a broad, more artistic sense. Investigation results drove\ncompelling ideas here discussed. The experiments compared different ways to\nrepresent draws to be input in a network and showed that an absolute format of\ncoordinates (x, y) was a better performer than a relative one (Dx, Dy) with\nrespect to prior points, most frequent in the reviewed literature. Experiments\nalso showed that, due to the recurrent nature of LSTMs, the order of lines\nforming a drawing is a relevant factor for input in an LSTM classifier not\nstudied before. A minimum 'pencil' traveled length criteria for line ordering\nproved suitable, possible by reducing it to a TSP particular instance. The best\nconfiguration for gender classification appears with an LSTM layer that returns\nthe hidden state value for each input point step, followed by a global average\nlayer along the sequence, before the output dense layer. That result guided the\nidea of removing the average in the network pipeline and return a per-point\nattribute score just by adjusting tensors dimensions. With this trick, the\nmodel detects an attribute in a drawing and also recognizes the points linked\nto it. Moreover, by overlapping filtered lines of portraits, an attribute's\nvisual essence is depicted. Meet the FaCells.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 21:05:57 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gonz\u00e1lez", "Xavier Ignacio", ""]]}, {"id": "2102.11382", "submitter": "Xinyu Gong", "authors": "Xinyu Gong, Wuyang Chen, Tianlong Chen and Zhangyang Wang", "title": "Sandwich Batch Normalization", "comments": "Codes are available at\n  https://github.com/VITA-Group/Sandwich-Batch-Normalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Sandwich Batch Normalization (SaBN), an embarrassingly easy\nimprovement of Batch Normalization (BN) with only a few lines of code changes.\nSaBN is motivated by addressing the inherent feature distribution heterogeneity\nthat one can be identified in many tasks, which can arise from data\nheterogeneity (multiple input domains) or model heterogeneity (dynamic\narchitectures, model conditioning, etc.). Our SaBN factorizes the BN affine\nlayer into one shared sandwich affine layer, cascaded by several parallel\nindependent affine layers. Concrete analysis reveals that, during optimization,\nSaBN promotes balanced gradient norms while still preserving diverse gradient\ndirections: a property that many application tasks seem to favor. We\ndemonstrate the prevailing effectiveness of SaBN as a drop-in replacement in\nfour tasks: $\\textbf{conditional image generation}$, $\\textbf{neural\narchitecture search}$ (NAS), $\\textbf{adversarial training}$, and\n$\\textbf{arbitrary style transfer}$. Leveraging SaBN immediately achieves\nbetter Inception Score and FID on CIFAR-10 and ImageNet conditional image\ngeneration with three state-of-the-art GANs; boosts the performance of a\nstate-of-the-art weight-sharing NAS algorithm significantly on NAS-Bench-201;\nsubstantially improves the robust and standard accuracies for adversarial\ndefense; and produces superior arbitrary stylized results. We also provide\nvisualizations and analysis to help understand why SaBN works. Codes are\navailable at https://github.com/VITA-Group/Sandwich-Batch-Normalization.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 22:09:43 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gong", "Xinyu", ""], ["Chen", "Wuyang", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2102.11389", "submitter": "Michael Cochez", "authors": "Ruud van Bakel, Teodor Aleksiev, Daniel Daza, Dimitrios Alivanistos,\n  Michael Cochez", "title": "Approximate Knowledge Graph Query Answering: From Ranking to Binary\n  Classification", "comments": "To be published in Lecture Notes in Artificial Intelligence\n  (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, heterogeneous datasets are characterized by missing or even erroneous\ninformation. This is more evident when they are the product of community effort\nor automatic fact extraction methods from external sources, such as text. A\nspecial case of the aforementioned phenomenon can be seen in knowledge graphs,\nwhere this mostly appears in the form of missing or incorrect edges and nodes.\n  Structured querying on such incomplete graphs will result in incomplete sets\nof answers, even if the correct entities exist in the graph, since one or more\nedges needed to match the pattern are missing. To overcome this problem,\nseveral algorithms for approximate structured query answering have been\nproposed. Inspired by modern Information Retrieval metrics, these algorithms\nproduce a ranking of all entities in the graph, and their performance is\nfurther evaluated based on how high in this ranking the correct answers appear.\n  In this work we take a critical look at this way of evaluation. We argue that\nperforming a ranking-based evaluation is not sufficient to assess methods for\ncomplex query answering. To solve this, we introduce Message Passing Query\nBoxes (MPQB), which takes binary classification metrics back into use and shows\nthe effect this has on the recently proposed query embedding method MPQE.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 22:28:08 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["van Bakel", "Ruud", ""], ["Aleksiev", "Teodor", ""], ["Daza", "Daniel", ""], ["Alivanistos", "Dimitrios", ""], ["Cochez", "Michael", ""]]}, {"id": "2102.11396", "submitter": "Donghui Yan", "authors": "Donghui Yan, Jian Zou, Zhenpeng Li", "title": "Learning Low-dimensional Manifolds for Scoring of Tissue Microarray\n  Images", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tissue microarray (TMA) images have emerged as an important high-throughput\ntool for cancer study and the validation of biomarkers. Efforts have been\ndedicated to further improve the accuracy of TACOMA, a cutting-edge automatic\nscoring algorithm for TMA images. One major advance is due to deepTacoma, an\nalgorithm that incorporates suitable deep representations of a group nature.\nInspired by the recent advance in semi-supervised learning and deep learning,\nwe propose mfTacoma to learn alternative deep representations in the context of\nTMA image scoring. In particular, mfTacoma learns the low-dimensional\nmanifolds, a common latent structure in high dimensional data. Deep\nrepresentation learning and manifold learning typically requires large data. By\nencoding deep representation of the manifolds as regularizing features,\nmfTacoma effectively leverages the manifold information that is potentially\ncrude due to small data. Our experiments show that deep features by manifolds\noutperforms two alternatives -- deep features by linear manifolds with\nprincipal component analysis or by leveraging the group property.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 22:55:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Yan", "Donghui", ""], ["Zou", "Jian", ""], ["Li", "Zhenpeng", ""]]}, {"id": "2102.11417", "submitter": "Narsimha Chilkuri", "authors": "Narsimha Chilkuri, Chris Eliasmith", "title": "Parallelizing Legendre Memory Unit Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, a new recurrent neural network (RNN) named the Legendre Memory Unit\n(LMU) was proposed and shown to achieve state-of-the-art performance on several\nbenchmark datasets. Here we leverage the linear time-invariant (LTI) memory\ncomponent of the LMU to construct a simplified variant that can be parallelized\nduring training (and yet executed as an RNN during inference), thus overcoming\na well known limitation of training RNNs on GPUs. We show that this\nreformulation that aids parallelizing, which can be applied generally to any\ndeep network whose recurrent components are linear, makes training up to 200\ntimes faster. Second, to validate its utility, we compare its performance\nagainst the original LMU and a variety of published LSTM and transformer\nnetworks on seven benchmarks, ranging from psMNIST to sentiment analysis to\nmachine translation. We demonstrate that our models exhibit superior\nperformance on all datasets, often using fewer parameters. For instance, our\nLMU sets a new state-of-the-art result on psMNIST, and uses half the parameters\nwhile outperforming DistilBERT and LSTM models on IMDB sentiment analysis.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 23:43:47 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 22:34:37 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chilkuri", "Narsimha", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2102.11433", "submitter": "Brendon Lutnick", "authors": "Brendon Lutnick, Leema Krishna Murali, Brandon Ginley, Avi Z.\n  Rosenberg, and Pinaki Sarder", "title": "Histo-fetch -- On-the-fly processing of gigapixel whole slide images\n  simplifies and speeds neural network training", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We created a custom pipeline (histo-fetch) to efficiently extract random\npatches and labels from pathology whole slide images (WSIs) for input to a\nneural network on-the-fly. We prefetch these patches as needed during network\ntraining, avoiding the need for WSI preparation such as chopping/tiling. We\ndemonstrate the utility of this pipeline to perform artificial stain transfer\nand image generation using the popular networks CycleGAN and ProGAN,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 00:40:26 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 16:14:28 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Lutnick", "Brendon", ""], ["Murali", "Leema Krishna", ""], ["Ginley", "Brandon", ""], ["Rosenberg", "Avi Z.", ""], ["Sarder", "Pinaki", ""]]}, {"id": "2102.11436", "submitter": "Alexander Robey", "authors": "Alexander Robey and George J. Pappas and Hamed Hassani", "title": "Model-Based Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable success in a variety of applications, it is well-known\nthat deep learning can fail catastrophically when presented with\nout-of-distribution data. Toward addressing this challenge, we consider the\ndomain generalization problem, wherein predictors are trained using data drawn\nfrom a family of related training domains and then evaluated on a distinct and\nunseen test domain. We show that under a natural model of data generation and a\nconcomitant invariance condition, the domain generalization problem is\nequivalent to an infinite-dimensional constrained statistical learning problem;\nthis problem forms the basis of our approach, which we call Model-Based Domain\nGeneralization. Due to the inherent challenges in solving constrained\noptimization problems in deep learning, we exploit nonconvex duality theory to\ndevelop unconstrained relaxations of this statistical problem with tight bounds\non the duality gap. Based on this theoretical motivation, we propose a novel\ndomain generalization algorithm with convergence guarantees. In our\nexperiments, we report improvements of up to 30 percentage points over\nstate-of-the-art domain generalization baselines on several benchmarks\nincluding ColoredMNIST, Camelyon17-WILDS, FMoW-WILDS, and PACS.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 00:59:02 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 20:14:09 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 15:35:42 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Robey", "Alexander", ""], ["Pappas", "George J.", ""], ["Hassani", "Hamed", ""]]}, {"id": "2102.11448", "submitter": "DiJia Su", "authors": "DiJia Su, Jason D. Lee, John M. Mulvey, H. Vincent Poor", "title": "MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch\n  Optimization for Deployment Constrained Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contemporary applications such as healthcare, finance, robotics, and\nrecommendation systems, continuous deployment of new policies for data\ncollection and online learning is either cost ineffective or impractical. We\nconsider a setting that lies between pure offline reinforcement learning (RL)\nand pure online RL called deployment constrained RL in which the number of\npolicy deployments for data sampling is limited. To solve this challenging\ntask, we propose a new algorithmic learning framework called Model-based\nUncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our\nframework discovers novel and high quality samples for each deployment to\nenable efficient data collection. During each offline training session, we\nbootstrap the policy update by quantifying the amount of uncertainty within our\ncollected data. In the high support region (low uncertainty), we encourage our\npolicy by taking an aggressive update. In the low support region (high\nuncertainty) when the policy bootstraps into the out-of-distribution region, we\ndownweight it by our estimated uncertainty quantification. Experimental results\nshow that MUSBO achieves state-of-the-art performance in the deployment\nconstrained RL setting.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 01:30:55 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 23:59:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Su", "DiJia", ""], ["Lee", "Jason D.", ""], ["Mulvey", "John M.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2102.11482", "submitter": "Hongzhen Zhong", "authors": "Hongzhen Zhong, Hai Wan, Weilin Luo, Zhanhao Xiao, Jia Li, Biqing Fang", "title": "Structural Similarity of Boundary Conditions and an Efficient Local\n  Search Algorithm for Goal Conflict Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In goal-oriented requirements engineering, goal conflict identification is of\nfundamental importance for requirements analysis. The task aims to find the\nfeasible situations which make the goals diverge within the domain, called\nboundary conditions (BCs). However, the existing approaches for goal conflict\nidentification fail to find sufficient BCs and general BCs which cover more\ncombinations of circumstances. From the BCs found by these existing approaches,\nwe have observed an interesting phenomenon that there are some pairs of BCs are\nsimilar in formula structure, which occurs frequently in the experimental\ncases. In other words, once a BC is found, a new BC may be discovered quickly\nby slightly changing the former. It inspires us to develop a local search\nalgorithm named LOGION to find BCs, in which the structural similarity is\ncaptured by the neighborhood relation of formulae. Based on structural\nsimilarity, LOGION can find a lot of BCs in a short time. Moreover, due to the\nlarge number of BCs identified, it potentially selects more general BCs from\nthem. By taking experiments on a set of cases, we show that LOGION effectively\nexploits the structural similarity of BCs. We also compare our algorithm\nagainst the two state-of-the-art approaches. The experimental results show that\nLOGION produces one order of magnitude more BCs than the state-of-the-art\napproaches and confirm that LOGION finds out more general BCs thanks to a large\nnumber of BCs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:25:06 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhong", "Hongzhen", ""], ["Wan", "Hai", ""], ["Luo", "Weilin", ""], ["Xiao", "Zhanhao", ""], ["Li", "Jia", ""], ["Fang", "Biqing", ""]]}, {"id": "2102.11485", "submitter": "Zeyu Sun", "authors": "Zeyu Sun, Wenjie Zhang, Lili Mou, Qihao Zhu, Yingfei Xiong, Lu Zhang", "title": "Dynamic Labeling for Unlabeled Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing graph neural networks (GNNs) largely rely on node embeddings, which\nrepresent a node as a vector by its identity, type, or content. However, graphs\nwith unlabeled nodes widely exist in real-world applications (e.g., anonymized\nsocial networks). Previous GNNs either assign random labels to nodes (which\nintroduces artefacts to the GNN) or assign one embedding to all nodes (which\nfails to distinguish one node from another). In this paper, we analyze the\nlimitation of existing approaches in two types of classification tasks, graph\nclassification and node classification. Inspired by our analysis, we propose\ntwo techniques, Dynamic Labeling and Preferential Dynamic Labeling, that\nsatisfy desired properties statistically or asymptotically for each type of the\ntask. Experimental results show that we achieve high performance in various\ngraph-related tasks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:30:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sun", "Zeyu", ""], ["Zhang", "Wenjie", ""], ["Mou", "Lili", ""], ["Zhu", "Qihao", ""], ["Xiong", "Yingfei", ""], ["Zhang", "Lu", ""]]}, {"id": "2102.11488", "submitter": "Richeng Duan", "authors": "Richeng Duan, Nancy F. Chen", "title": "Senone-aware Adversarial Multi-task Training for Unsupervised Child to\n  Adult Speech Adaptation", "comments": "accepted for presentation at ICASSP-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic modeling for child speech is challenging due to the high acoustic\nvariability caused by physiological differences in the vocal tract. The dearth\nof publicly available datasets makes the task more challenging. In this work,\nwe propose a feature adaptation approach by exploiting adversarial multi-task\ntraining to minimize acoustic mismatch at the senone (tied triphone states)\nlevel between adult and child speech and leverage large amounts of transcribed\nadult speech. We validate the proposed method on three tasks: child speech\nrecognition, child pronunciation assessment, and child fluency score\nprediction. Empirical results indicate that our proposed approach consistently\noutperforms competitive baselines, achieving 7.7% relative error reduction on\nspeech recognition and up to 25.2% relative gains on the evaluation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:49:27 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Duan", "Richeng", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2102.11492", "submitter": "Xianyuan Zhan", "authors": "Xianyuan Zhan, Haoran Xu, Yue Zhang, Yusen Huo, Xiangyu Zhu, Honglei\n  Yin, Yu Zheng", "title": "DeepThermal: Combustion Optimization for Thermal Power Generating Units\n  Using Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal power generation plays a dominant role in the world's electricity\nsupply. It consumes large amounts of coal worldwide, and causes serious air\npollution. Optimizing the combustion efficiency of a thermal power generating\nunit (TPGU) is a highly challenging and critical task in the energy industry.\nWe develop a new data-driven AI system, namely DeepThermal, to optimize the\ncombustion control strategy for TPGUs. At its core, is a new model-based\noffline reinforcement learning (RL) framework, called MORE, which leverages\nlogged historical operational data of a TPGU to solve a highly complex\nconstrained Markov decision process problem via purely offline training. MORE\naims at simultaneously improving the long-term reward (increase combustion\nefficiency and reduce pollutant emission) and controlling operational risks\n(safety constraints satisfaction). In DeepThermal, we first learn a data-driven\ncombustion process simulator from the offline dataset. The RL agent of MORE is\nthen trained by combining real historical data as well as carefully filtered\nand processed simulation data through a novel restrictive exploration scheme.\nDeepThermal has been successfully deployed in four large coal-fired thermal\npower plants in China. Real-world experiments show that DeepThermal effectively\nimproves the combustion efficiency of a TPGU. We also report and demonstrate\nthe superior performance of MORE by comparing with the state-of-the-art\nalgorithms on the standard offline RL benchmarks. To the best knowledge of the\nauthors, DeepThermal is the first AI application that has been used to solve\nreal-world complex mission-critical control tasks using the offline RL\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:55:12 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 04:05:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Zhan", "Xianyuan", ""], ["Xu", "Haoran", ""], ["Zhang", "Yue", ""], ["Huo", "Yusen", ""], ["Zhu", "Xiangyu", ""], ["Yin", "Honglei", ""], ["Zheng", "Yu", ""]]}, {"id": "2102.11494", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin, Huan Wang, Caiming Xiong", "title": "Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world applications such as economics and policy making often involve\nsolving multi-agent games with two unique features: (1) The agents are\ninherently asymmetric and partitioned into leaders and followers; (2) The\nagents have different reward functions, thus the game is general-sum. The\nmajority of existing results in this field focuses on either symmetric solution\nconcepts (e.g. Nash equilibrium) or zero-sum games. It remains vastly open how\nto learn the Stackelberg equilibrium -- an asymmetric analog of the Nash\nequilibrium -- in general-sum games efficiently from samples.\n  This paper initiates the theoretical study of sample-efficient learning of\nthe Stackelberg equilibrium, in the bandit feedback setting where we only\nobserve noisy samples of the reward. We consider three representative\ntwo-player general-sum games: bandit games, bandit-reinforcement learning\n(bandit-RL) games, and linear bandit games. In all these games, we identify a\nfundamental gap between the exact value of the Stackelberg equilibrium and its\nestimated version using finitely many noisy samples, which can not be closed\ninformation-theoretically regardless of the algorithm. We then establish sharp\npositive results on sample-efficient learning of Stackelberg equilibrium with\nvalue optimal up to the gap identified above, with matching lower bounds in the\ndependency on the gap, error tolerance, and the size of the action spaces.\nOverall, our results unveil unique challenges in learning Stackelberg\nequilibria under noisy bandit feedback, which we hope could shed light on\nfuture research on this topic.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:11:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:48:56 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""]]}, {"id": "2102.11500", "submitter": "Victor Bourgin", "authors": "Victor D. Bourgin, Ioana Bica, Mihaela van der Schaar", "title": "Model-Attentive Ensemble Learning for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical time-series datasets have unique characteristics that make prediction\ntasks challenging. Most notably, patient trajectories often contain\nlongitudinal variations in their input-output relationships, generally referred\nto as temporal conditional shift. Designing sequence models capable of adapting\nto such time-varying distributions remains a prevailing problem. To address\nthis we present Model-Attentive Ensemble learning for Sequence modeling (MAES).\nMAES is a mixture of time-series experts which leverages an attention-based\ngating mechanism to specialize the experts on different sequence dynamics and\nadaptively weight their predictions. We demonstrate that MAES significantly\nout-performs popular sequence models on datasets subject to temporal shift.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:23:35 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Bourgin", "Victor D.", ""], ["Bica", "Ioana", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2102.11502", "submitter": "Hu Wang", "authors": "Liuqiao Chen, Hu Wang, Benjamin Zi Hao Zhao, Minhui Xue and Haifeng\n  Qian", "title": "Oriole: Thwarting Privacy against Trustworthy Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved unprecedented success in the field of face\nrecognition such that any individual can crawl the data of others from the\nInternet without their explicit permission for the purpose of training\nhigh-precision face recognition models, creating a serious violation of\nprivacy. Recently, a well-known system named Fawkes (published in USENIX\nSecurity 2020) claimed this privacy threat can be neutralized by uploading\ncloaked user images instead of their original images. In this paper, we present\nOriole, a system that combines the advantages of data poisoning attacks and\nevasion attacks, to thwart the protection offered by Fawkes, by training the\nattacker face recognition model with multi-cloaked images generated by Oriole.\nConsequently, the face recognition accuracy of the attack model is maintained\nand the weaknesses of Fawkes are revealed. Experimental results show that our\nproposed Oriole system is able to effectively interfere with the performance of\nthe Fawkes system to achieve promising attacking results. Our ablation study\nhighlights multiple principal factors that affect the performance of the Oriole\nsystem, including the DSSIM perturbation budget, the ratio of leaked clean user\nimages, and the numbers of multi-cloaks for each uncloaked image. We also\nidentify and discuss at length the vulnerabilities of Fawkes. We hope that the\nnew methodology presented in this paper will inform the security community of a\nneed to design more robust privacy-preserving deep learning models.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:33:55 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 06:37:27 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "Liuqiao", ""], ["Wang", "Hu", ""], ["Zhao", "Benjamin Zi Hao", ""], ["Xue", "Minhui", ""], ["Qian", "Haifeng", ""]]}, {"id": "2102.11506", "submitter": "Sulabh Katiyar", "authors": "Sulabh Katiyar, Samir Kumar Borgohain", "title": "Comparative evaluation of CNN architectures for Image Caption Generation", "comments": "Article Published in International Journal of Advanced Computer\n  Science and Applications(IJACSA), Volume 11 Issue 12, 2020", "journal-ref": "in International Journal of Advanced Computer Science and\n  Applications, 11(12), 2020", "doi": "10.14569/IJACSA.2020.0111291", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Aided by recent advances in Deep Learning, Image Caption Generation has seen\ntremendous progress over the last few years. Most methods use transfer learning\nto extract visual information, in the form of image features, with the help of\npre-trained Convolutional Neural Network models followed by transformation of\nthe visual information using a Caption Generator module to generate the output\nsentences. Different methods have used different Convolutional Neural Network\nArchitectures and, to the best of our knowledge, there is no systematic study\nwhich compares the relative efficacy of different Convolutional Neural Network\narchitectures for extracting the visual information. In this work, we have\nevaluated 17 different Convolutional Neural Networks on two popular Image\nCaption Generation frameworks: the first based on Neural Image Caption (NIC)\ngeneration model and the second based on Soft-Attention framework. We observe\nthat model complexity of Convolutional Neural Network, as measured by number of\nparameters, and the accuracy of the model on Object Recognition task does not\nnecessarily co-relate with its efficacy on feature extraction for Image Caption\nGeneration task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:43:54 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Katiyar", "Sulabh", ""], ["Borgohain", "Samir Kumar", ""]]}, {"id": "2102.11529", "submitter": "Matthieu Zimmer", "authors": "Matthieu Zimmer and Xuening Feng and Claire Glanois and Zhaohui Jiang\n  and Jianyi Zhang and Paul Weng and Li Dong and Hao Jianye and Liu Wulong", "title": "Differentiable Logic Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The integration of reasoning, learning, and decision-making is key to build\nmore general AI systems. As a step in this direction, we propose a novel\nneural-logic architecture that can solve both inductive logic programming (ILP)\nand deep reinforcement learning (RL) problems. Our architecture defines a\nrestricted but expressive continuous space of first-order logic programs by\nassigning weights to predicates instead of rules. Therefore, it is fully\ndifferentiable and can be efficiently trained with gradient descent. Besides,\nin the deep RL setting with actor-critic algorithms, we propose a novel\nefficient critic architecture. Compared to state-of-the-art methods on both ILP\nand RL problems, our proposition achieves excellent performance, while being\nable to provide a fully interpretable solution and scaling much better,\nespecially during the testing phase.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 07:31:52 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 06:14:03 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 02:40:33 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Zimmer", "Matthieu", ""], ["Feng", "Xuening", ""], ["Glanois", "Claire", ""], ["Jiang", "Zhaohui", ""], ["Zhang", "Jianyi", ""], ["Weng", "Paul", ""], ["Dong", "Li", ""], ["Jianye", "Hao", ""], ["Wulong", "Liu", ""]]}, {"id": "2102.11539", "submitter": "Alexander Nikitin", "authors": "Alexander Nikitin and Samuel Kaski", "title": "Decision Rule Elicitation for Domain Adaptation", "comments": null, "journal-ref": null, "doi": "10.1145/3397481.3450682", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human-in-the-loop machine learning is widely used in artificial intelligence\n(AI) to elicit labels for data points from experts or to provide feedback on\nhow close the predicted results are to the target. This simplifies away all the\ndetails of the decision-making process of the expert. In this work, we allow\nthe experts to additionally produce decision rules describing their\ndecision-making; the rules are expected to be imperfect but to give additional\ninformation. In particular, the rules can extend to new distributions, and\nhence enable significantly improving performance for cases where the training\nand testing distributions differ, such as in domain adaptation. We apply the\nproposed method to lifelong learning and domain adaptation problems and discuss\napplications in other branches of AI, such as knowledge acquisition problems in\nexpert systems. In simulated and real-user studies, we show that decision rule\nelicitation improves domain adaptation of the algorithm and helps to propagate\nexpert's knowledge to the AI model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 08:07:22 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nikitin", "Alexander", ""], ["Kaski", "Samuel", ""]]}, {"id": "2102.11545", "submitter": "Md Musfiqur Rahman", "authors": "Md. Musfiqur Rahman, Ayman Rasheed, Md. Mosaddek Khan, Mohammad Ali\n  Javidian, Pooyan Jamshidi and Md. Mamun-Or-Rashid", "title": "Accelerating Recursive Partition-Based Causal Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal structure discovery from observational data is fundamental to the\ncausal understanding of autonomous systems such as medical decision support\nsystems, advertising campaigns and self-driving cars. This is essential to\nsolve well-known causal decision making and prediction problems associated with\nthose real-world applications. Recently, recursive causal discovery algorithms\nhave gained particular attention among the research community due to their\nability to provide good results by using Conditional Independent (CI) tests in\nsmaller sub-problems. However, each of such algorithms needs a refinement\nfunction to remove undesired causal relations of the discovered graphs.\nNotably, with the increase of the problem size, the computation cost (i.e., the\nnumber of CI-tests) of the refinement function makes an algorithm expensive to\ndeploy in practice. This paper proposes a generic causal structure refinement\nstrategy that can locate the undesired relations with a small number of\nCI-tests, thus speeding up the algorithm for large and complex problems. We\ntheoretically prove the correctness of our algorithm. We then empirically\nevaluate its performance against the state-of-the-art algorithms in terms of\nsolution quality and completion time in synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 08:28:55 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rahman", "Md. Musfiqur", ""], ["Rasheed", "Ayman", ""], ["Khan", "Md. Mosaddek", ""], ["Javidian", "Mohammad Ali", ""], ["Jamshidi", "Pooyan", ""], ["Mamun-Or-Rashid", "Md.", ""]]}, {"id": "2102.11560", "submitter": "Sohini Roychowdhury", "authors": "Sohini Roychowdhury, Kwok Sun Tang, Mohith Ashok, Anoop Sanka", "title": "SISE-PC: Semi-supervised Image Subsampling for Explainable Pathology", "comments": "4 pages, 6 images, 2 tables, submitted to IEEE EMBC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although automated pathology classification using deep learning (DL) has\nproved to be predictively efficient, DL methods are found to be data and\ncompute cost intensive. In this work, we aim to reduce DL training costs by\npre-training a Resnet feature extractor using SimCLR contrastive loss for\nlatent encoding of OCT images. We propose a novel active learning framework\nthat identifies a minimal sub-sampled dataset containing the most uncertain OCT\nimage samples using label propagation on the SimCLR latent encodings. The\npre-trained Resnet model is then fine-tuned with the labelled minimal\nsub-sampled data and the underlying pathological sites are visually explained.\nOur framework identifies upto 2% of OCT images to be most uncertain that need\nprioritized specialist attention and that can fine-tune a Resnet model to\nachieve upto 97% classification accuracy. The proposed method can be extended\nto other medical images to minimize prediction costs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:00:15 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 07:45:25 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Roychowdhury", "Sohini", ""], ["Tang", "Kwok Sun", ""], ["Ashok", "Mohith", ""], ["Sanka", "Anoop", ""]]}, {"id": "2102.11566", "submitter": "Hongxin Xiang", "authors": "Hongxin Xiang, Cheng Xie, Ting Zeng, Yun Yang", "title": "Multi-Knowledge Fusion for New Feature Generation in Generalized\n  Zero-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suffering from the semantic insufficiency and domain-shift problems, most of\nexisting state-of-the-art methods fail to achieve satisfactory results for\nZero-Shot Learning (ZSL). In order to alleviate these problems, we propose a\nnovel generative ZSL method to learn more generalized features from\nmulti-knowledge with continuously generated new semantics in semantic-to-visual\nembedding. In our approach, the proposed Multi-Knowledge Fusion Network\n(MKFNet) takes different semantic features from multi-knowledge as input, which\nenables more relevant semantic features to be trained for semantic-to-visual\nembedding, and finally generates more generalized visual features by adaptively\nfusing visual features from different knowledge domain. The proposed New\nFeature Generator (NFG) with adaptive genetic strategy is used to enrich\nsemantic information on the one hand, and on the other hand it greatly improves\nthe intersection of visual feature generated by MKFNet and unseen visual\nfaetures. Empirically, we show that our approach can achieve significantly\nbetter performance compared to existing state-of-the-art methods on a large\nnumber of benchmarks for several ZSL tasks, including traditional ZSL,\ngeneralized ZSL and zero-shot retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:11:05 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Xiang", "Hongxin", ""], ["Xie", "Cheng", ""], ["Zeng", "Ting", ""], ["Yang", "Yun", ""]]}, {"id": "2102.11567", "submitter": "Nils K\\\"obis C", "authors": "Nils K\\\"obis, Christopher Starke, Iyad Rahwan", "title": "Artificial Intelligence as an Anti-Corruption Tool (AI-ACT) --\n  Potentials and Pitfalls for Top-down and Bottom-up Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Corruption continues to be one of the biggest societal challenges of our\ntime. New hope is placed in Artificial Intelligence (AI) to serve as an\nunbiased anti-corruption agent. Ever more available (open) government data\npaired with unprecedented performance of such algorithms render AI the next\nfrontier in anti-corruption. Summarizing existing efforts to use AI-based\nanti-corruption tools (AI-ACT), we introduce a conceptual framework to advance\nresearch and policy. It outlines why AI presents a unique tool for top-down and\nbottom-up anti-corruption approaches. For both approaches, we outline in detail\nhow AI-ACT present different potentials and pitfalls for (a) input data, (b)\nalgorithmic design, and (c) institutional implementation. Finally, we venture a\nlook into the future and flesh out key questions that need to be addressed to\ndevelop AI-ACT while considering citizens' views, hence putting \"society in the\nloop\".\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:14:19 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["K\u00f6bis", "Nils", ""], ["Starke", "Christopher", ""], ["Rahwan", "Iyad", ""]]}, {"id": "2102.11570", "submitter": "Jasmin Bogatinovski", "authors": "Harold Ott, Jasmin Bogatinovski, Alexander Acker, Sasho Nedelkoski,\n  Odej Kao", "title": "Robust and Transferable Anomaly Detection in Log Data using Pre-Trained\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Anomalies or failures in large computer systems, such as the cloud, have an\nimpact on a large number of users that communicate, compute, and store\ninformation. Therefore, timely and accurate anomaly detection is necessary for\nreliability, security, safe operation, and mitigation of losses in these\nincreasingly important systems. Recently, the evolution of the software\nindustry opens up several problems that need to be tackled including (1)\naddressing the software evolution due software upgrades, and (2) solving the\ncold-start problem, where data from the system of interest is not available. In\nthis paper, we propose a framework for anomaly detection in log data, as a\nmajor troubleshooting source of system information. To that end, we utilize\npre-trained general-purpose language models to preserve the semantics of log\nmessages and map them into log vector embeddings. The key idea is that these\nrepresentations for the logs are robust and less invariant to changes in the\nlogs, and therefore, result in a better generalization of the anomaly detection\nmodels. We perform several experiments on a cloud dataset evaluating different\nlanguage models for obtaining numerical log representations such as BERT,\nGPT-2, and XL. The robustness is evaluated by gradually altering log messages,\nto simulate a change in semantics. Our results show that the proposed approach\nachieves high performance and robustness, which opens up possibilities for\nfuture research in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:17:05 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ott", "Harold", ""], ["Bogatinovski", "Jasmin", ""], ["Acker", "Alexander", ""], ["Nedelkoski", "Sasho", ""], ["Kao", "Odej", ""]]}, {"id": "2102.11585", "submitter": "Gurkirt Singh", "authors": "Gurkirt Singh, Stephen Akrigg, Manuele Di Maio, Valentina Fontana,\n  Reza Javanmard Alitappeh, Suman Saha, Kossar Jeddisaravi, Farzad Yousefi,\n  Jacob Culley, Tom Nicholson, Jordan Omokeowa, Salman Khan, Stanislao\n  Grazioso, Andrew Bradley, Giuseppe Di Gironimo, Fabio Cuzzolin", "title": "ROAD: The ROad event Awareness Dataset for Autonomous Driving", "comments": "21 pages, dataset paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans approach driving in a holistic fashion which entails, in particular,\nunderstanding road events and their evolution. Injecting these capabilities in\nan autonomous vehicle has thus the potential to take situational awareness and\ndecision making closer to human-level performance. To this purpose, we\nintroduce the ROad event Awareness Dataset (ROAD) for Autonomous Driving, to\nour knowledge the first of its kind. ROAD is designed to test an autonomous\nvehicle's ability to detect road events, defined as triplets composed by a\nmoving agent, the action(s) it performs and the corresponding scene locations.\nROAD comprises 22 videos, originally from the Oxford RobotCar Dataset,\nannotated with bounding boxes showing the location in the image plane of each\nroad event. We also provide as baseline a new incremental algorithm for online\nroad event awareness, based on inflating RetinaNet along time, which achieves a\nmean average precision of 16.8% and 6.1% for frame-level and video-level event\ndetection, respectively, at 50% overlap. Though promising, these figures\nhighlight the challenges faced by situation awareness in autonomous driving.\nFinally, ROAD allows scholars to investigate exciting tasks such as complex\n(road) activity detection, future road event anticipation and the modelling of\nsentient road agents in terms of mental states. Dataset can be obtained from\nhttps://github.com/gurkirt/road-dataset and baseline code from\nhttps://github.com/gurkirt/3D-RetinaNet.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:48:56 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 10:07:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Singh", "Gurkirt", ""], ["Akrigg", "Stephen", ""], ["Di Maio", "Manuele", ""], ["Fontana", "Valentina", ""], ["Alitappeh", "Reza Javanmard", ""], ["Saha", "Suman", ""], ["Jeddisaravi", "Kossar", ""], ["Yousefi", "Farzad", ""], ["Culley", "Jacob", ""], ["Nicholson", "Tom", ""], ["Omokeowa", "Jordan", ""], ["Khan", "Salman", ""], ["Grazioso", "Stanislao", ""], ["Bradley", "Andrew", ""], ["Di Gironimo", "Giuseppe", ""], ["Cuzzolin", "Fabio", ""]]}, {"id": "2102.11588", "submitter": "Julio Wissing", "authors": "Julio Wissing, Benedikt Boenninghoff, Dorothea Kolossa, Tsubasa\n  Ochiai, Marc Delcroix, Keisuke Kinoshita, Tomohiro Nakatani, Shoko Araki,\n  Christopher Schymura", "title": "Data Fusion for Audiovisual Speaker Localization: Extending Dynamic\n  Stream Weights to the Spatial Domain", "comments": "4 pages, 6 figures, ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.CV cs.LG eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating the positions of multiple speakers can be helpful for tasks like\nautomatic speech recognition or speaker diarization. Both applications benefit\nfrom a known speaker position when, for instance, applying beamforming or\nassigning unique speaker identities. Recently, several approaches utilizing\nacoustic signals augmented with visual data have been proposed for this task.\nHowever, both the acoustic and the visual modality may be corrupted in specific\nspatial regions, for instance due to poor lighting conditions or to the\npresence of background noise. This paper proposes a novel audiovisual data\nfusion framework for speaker localization by assigning individual dynamic\nstream weights to specific regions in the localization space. This fusion is\nachieved via a neural network, which combines the predictions of individual\naudio and video trackers based on their time- and location-dependent\nreliability. A performance evaluation using audiovisual recordings yields\npromising results, with the proposed fusion approach outperforming all baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:59:31 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 07:57:47 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Wissing", "Julio", ""], ["Boenninghoff", "Benedikt", ""], ["Kolossa", "Dorothea", ""], ["Ochiai", "Tsubasa", ""], ["Delcroix", "Marc", ""], ["Kinoshita", "Keisuke", ""], ["Nakatani", "Tomohiro", ""], ["Araki", "Shoko", ""], ["Schymura", "Christopher", ""]]}, {"id": "2102.11598", "submitter": "Sander Dalm", "authors": "Sander Dalm, Nasir Ahmad, Luca Ambrogioni, Marcel van Gerven", "title": "Scaling up learning with GAIT-prop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation of error (BP) is a widely used and highly successful learning\nalgorithm. However, its reliance on non-local information in propagating error\ngradients makes it seem an unlikely candidate for learning in the brain. In the\nlast decade, a number of investigations have been carried out focused upon\ndetermining whether alternative more biologically plausible computations can be\nused to approximate BP. This work builds on such a local learning algorithm -\nGradient Adjusted Incremental Target Propagation (GAIT-prop) - which has\nrecently been shown to approximate BP in a manner which appears biologically\nplausible. This method constructs local, layer-wise weight update targets in\norder to enable plausible credit assignment. However, in deep networks, the\nlocal weight updates computed by GAIT-prop can deviate from BP for a number of\nreasons. Here, we provide and test methods to overcome such sources of error.\nIn particular, we adaptively rescale the locally-computed errors and show that\nthis significantly increases the performance and stability of the GAIT-prop\nalgorithm when applied to the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:19:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Dalm", "Sander", ""], ["Ahmad", "Nasir", ""], ["Ambrogioni", "Luca", ""], ["van Gerven", "Marcel", ""]]}, {"id": "2102.11603", "submitter": "Sourav Garg", "authors": "Sourav Garg and Michael Milford", "title": "SeqNet: Learning Descriptors for Sequence-based Hierarchical Place\n  Recognition", "comments": "Accepted for publication in IEEE RA-L 2021; includes supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Place Recognition (VPR) is the task of matching current visual imagery\nfrom a camera to images stored in a reference map of the environment. While\ninitial VPR systems used simple direct image methods or hand-crafted visual\nfeatures, recent work has focused on learning more powerful visual features and\nfurther improving performance through either some form of sequential matcher /\nfilter or a hierarchical matching process. In both cases the performance of the\ninitial single-image based system is still far from perfect, putting\nsignificant pressure on the sequence matching or (in the case of hierarchical\nsystems) pose refinement stages. In this paper we present a novel hybrid system\nthat creates a high performance initial match hypothesis generator using short\nlearnt sequential descriptors, which enable selective control sequential score\naggregation using single image learnt descriptors. Sequential descriptors are\ngenerated using a temporal convolutional network dubbed SeqNet, encoding short\nimage sequences using 1-D convolutions, which are then matched against the\ncorresponding temporal descriptors from the reference dataset to provide an\nordered list of place match hypotheses. We then perform selective sequential\nscore aggregation using shortlisted single image learnt descriptors from a\nseparate pipeline to produce an overall place match hypothesis. Comprehensive\nexperiments on challenging benchmark datasets demonstrate the proposed method\noutperforming recent state-of-the-art methods using the same amount of\nsequential information. Source code and supplementary material can be found at\nhttps://github.com/oravus/seqNet.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:32:10 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 01:52:08 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Garg", "Sourav", ""], ["Milford", "Michael", ""]]}, {"id": "2102.11615", "submitter": "Gabriel Istrate", "authors": "Gabriel Istrate", "title": "Models we Can Trust: Toward a Systematic Discipline of (Agent-Based)\n  Model Interpretation and Validation", "comments": "prevliminary version of paper to appear in AAMAS'21 Blue Sky Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate the development of a discipline of interacting with and\nextracting information from models, both mathematical (e.g. game-theoretic\nones) and computational (e.g. agent-based models). We outline some directions\nfor the development of a such a discipline:\n  - the development of logical frameworks for the systematic formal\nspecification of stylized facts and social mechanisms in (mathematical and\ncomputational) social science. Such frameworks would bring to attention new\nissues, such as phase transitions, i.e. dramatical changes in the validity of\nthe stylized facts beyond some critical values in parameter space. We argue\nthat such statements are useful for those logical frameworks describing\nproperties of ABM.\n  - the adaptation of tools from the theory of reactive systems (such as\nbisimulation) to obtain practically relevant notions of two systems \"having the\nsame behavior\".\n  - the systematic development of an adversarial theory of model perturbations,\nthat investigates the robustness of conclusions derived from models of social\nbehavior to variations in several features of the social dynamics. These may\ninclude: activation order, the underlying social network, individual agent\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:52:22 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Istrate", "Gabriel", ""]]}, {"id": "2102.11638", "submitter": "Jianzong Wang", "authors": "Xiaoyang Qu, Jianzong Wang, Jing Xiao", "title": "Enhancing Data-Free Adversarial Distillation with Activation\n  Regularization and Virtual Interpolation", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation refers to a technique of transferring the knowledge\nfrom a large learned model or an ensemble of learned models to a small model.\nThis method relies on access to the original training set, which might not\nalways be available. A possible solution is a data-free adversarial\ndistillation framework, which deploys a generative network to transfer the\nteacher model's knowledge to the student model. However, the data generation\nefficiency is low in the data-free adversarial distillation. We add an\nactivation regularizer and a virtual interpolation method to improve the data\ngeneration efficiency. The activation regularizer enables the students to match\nthe teacher's predictions close to activation boundaries and decision\nboundaries. The virtual interpolation method can generate virtual samples and\nlabels in-between decision boundaries. Our experiments show that our approach\nsurpasses state-of-the-art data-free distillation methods. The student model\ncan achieve 95.42% accuracy on CIFAR-10 and 77.05% accuracy on CIFAR-100\nwithout any original training data. Our model's accuracy is 13.8% higher than\nthe state-of-the-art data-free method on CIFAR-100.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 11:37:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Qu", "Xiaoyang", ""], ["Wang", "Jianzong", ""], ["Xiao", "Jing", ""]]}, {"id": "2102.11646", "submitter": "Niv Nayman", "authors": "Niv Nayman, Yonathan Aflalo, Asaf Noy, Lihi Zelnik-Manor", "title": "HardCoRe-NAS: Hard Constrained diffeRentiable Neural Architecture Search", "comments": "Niv Nayman and Yonathan Aflalo contributed equally. An implementation\n  of HardCoRe-NAS is available at: https://github.com/Alibaba-MIIL/HardCoReNAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic use of neural networks often requires adhering to multiple\nconstraints on latency, energy and memory among others. A popular approach to\nfind fitting networks is through constrained Neural Architecture Search (NAS),\nhowever, previous methods enforce the constraint only softly. Therefore, the\nresulting networks do not exactly adhere to the resource constraint and their\naccuracy is harmed. In this work we resolve this by introducing Hard\nConstrained diffeRentiable NAS (HardCoRe-NAS), that is based on an accurate\nformulation of the expected resource requirement and a scalable search method\nthat satisfies the hard constraint throughout the search. Our experiments show\nthat HardCoRe-NAS generates state-of-the-art architectures, surpassing other\nNAS methods, while strictly satisfying the hard resource constraints without\nany tuning required.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 11:56:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nayman", "Niv", ""], ["Aflalo", "Yonathan", ""], ["Noy", "Asaf", ""], ["Zelnik-Manor", "Lihi", ""]]}, {"id": "2102.11651", "submitter": "Hossein Sadr", "authors": "Hossein Sadr, Mozhdeh Nazari Solimandarabi, Mir Mohsen Pedram,\n  Mohammad Teshnehlab", "title": "A Novel Deep Learning Method for Textual Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis is known as one of the most crucial tasks in the field of\nnatural language processing and Convolutional Neural Network (CNN) is one of\nthose prominent models that is commonly used for this aim. Although\nconvolutional neural networks have obtained remarkable results in recent years,\nthey are still confronted with some limitations. Firstly, they consider that\nall words in a sentence have equal contributions in the sentence meaning\nrepresentation and are not able to extract informative words. Secondly, they\nrequire a large number of training data to obtain considerable results while\nthey have many parameters that must be accurately adjusted. To this end, a\nconvolutional neural network integrated with a hierarchical attention layer is\nproposed which is able to extract informative words and assign them higher\nweight. Moreover, the effect of transfer learning that transfers knowledge\nlearned in the source domain to the target domain with the aim of improving the\nperformance is also explored. Based on the empirical results, the proposed\nmodel not only has higher classification accuracy and can extract informative\nwords but also applying incremental transfer learning can significantly enhance\nthe classification performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:11:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sadr", "Hossein", ""], ["Solimandarabi", "Mozhdeh Nazari", ""], ["Pedram", "Mir Mohsen", ""], ["Teshnehlab", "Mohammad", ""]]}, {"id": "2102.11693", "submitter": "Qingxia Shang", "authors": "Liang Feng, Qingxia Shang, Yaqing Hou, Kay Chen Tan and Yew-Soon Ong", "title": "Multi-Space Evolutionary Search for Large-Scale Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, to improve the evolutionary algorithms used to solve\noptimization problems involving a large number of decision variables, many\nattempts have been made to simplify the problem solution space of a given\nproblem for the evolutionary search. In the literature, the existing approaches\ncan generally be categorized as decomposition-based methods and\ndimension-reduction-based methods. The former decomposes a large-scale problem\ninto several smaller subproblems, while the latter transforms the original\nhigh-dimensional solution space into a low-dimensional space. However, it is\nworth noting that a given large-scale optimization problem may not always be\ndecomposable, and it is also difficult to guarantee that the global optimum of\nthe original problem is preserved in the reduced low-dimensional problem space.\nThis paper thus proposes a new search paradigm, namely the multi-space\nevolutionary search, to enhance the existing evolutionary search methods for\nsolving large-scale optimization problems. In contrast to existing approaches\nthat perform an evolutionary search in a single search space, the proposed\nparadigm is designed to conduct a search in multiple solution spaces that are\nderived from the given problem, each possessing a unique landscape. The\nproposed paradigm makes no assumptions about the large-scale optimization\nproblem of interest, such as that the problem is decomposable or that a certain\nrelationship exists among the decision variables. To verify the efficacy of the\nproposed paradigm, comprehensive empirical studies in comparison to four\nstate-of-the-art algorithms were conducted using the CEC2013 large-scale\nbenchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 13:50:09 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 01:58:32 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Feng", "Liang", ""], ["Shang", "Qingxia", ""], ["Hou", "Yaqing", ""], ["Tan", "Kay Chen", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2102.11717", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Qingyuan Wu, Pengcheng He, Xiaoyang Tan", "title": "A Novel Greedy-Step Bellman Optimality Equation for Efficient Value\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently propagating credit to responsible actions is a central and\nchallenging task in reinforcement learning. To accelerate information\npropagation, this paper presents a new method that bridges a highway that\nallows unimpeded information to flow across long horizons. The key to our\nmethod is a newly proposed Bellman equation, called Greedy-Step Bellman\nOptimality Equation, through which the high-credit information can fast\npropagate across a long horizon. We theoretically show that the solution of the\nnew equation is exactly the optimal value function and the corresponding\noperator converges faster than the classical operator. Besides, it leads to a\nnew multi-step off-policy algorithm, which is capable of safely utilizing any\noff-policy data collected by the arbitrary policy. Experiments reveal that the\nproposed method is reliable, easy to implement. Moreover, without employing\nadditional components of Rainbow except Double DQN, our method achieves\ncompetitive performance with Rainbow on the benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 14:32:20 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 15:06:27 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 09:45:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Yuhui", ""], ["Wu", "Qingyuan", ""], ["He", "Pengcheng", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "2102.11724", "submitter": "Lu Cheng", "authors": "Lu Cheng, Ruocheng Guo, Huan Liu", "title": "Causal Mediation Analysis with Hidden Confounders", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in causal inference is to break down the total effect of\ntreatment into different causal pathways and quantify the causal effect in each\npathway. Causal mediation analysis (CMA) is a formal statistical approach for\nidentifying and estimating these causal effects. Central to CMA is the\nsequential ignorability assumption that implies all pre-treatment confounders\nare measured and they can capture different types of confounding, e.g.,\npost-treatment confounders and hidden confounders. Typically unverifiable in\nobservational studies, this assumption restrains both the coverage and\npracticality of conventional methods. This work, therefore, aims to circumvent\nthe stringent assumption by following a causal graph with a unified confounder\nand its proxy variables. Our core contribution is an algorithm that combines\ndeep latent-variable models and proxy strategy to jointly infer a unified\nsurrogate confounder and estimate different causal effects in CMA from observed\nvariables. Empirical evaluations using both synthetic and semi-synthetic\ndatasets validate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:46:11 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cheng", "Lu", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""]]}, {"id": "2102.11736", "submitter": "Wenxuan Wang", "authors": "Zhengyu Liu, Jingliang Duan, Wenxuan Wang, Shengbo Eben Li, Yuming\n  Yin, Ziyu Lin, Qi Sun, Bo Cheng", "title": "Recurrent Model Predictive Control", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.10289", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes an off-line algorithm, called Recurrent Model Predictive\nControl (RMPC), to solve general nonlinear finite-horizon optimal control\nproblems. Unlike traditional Model Predictive Control (MPC) algorithms, it can\nmake full use of the current computing resources and adaptively select the\nlongest model prediction horizon. Our algorithm employs a recurrent function to\napproximate the optimal policy, which maps the system states and reference\nvalues directly to the control inputs. The number of prediction steps is equal\nto the number of recurrent cycles of the learned policy function. With an\narbitrary initial policy function, the proposed RMPC algorithm can converge to\nthe optimal policy by directly minimizing the designed loss function. We\nfurther prove the convergence and optimality of the RMPC algorithm thorough\nBellman optimality principle, and demonstrate its generality and efficiency\nusing two numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:01:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Liu", "Zhengyu", ""], ["Duan", "Jingliang", ""], ["Wang", "Wenxuan", ""], ["Li", "Shengbo Eben", ""], ["Yin", "Yuming", ""], ["Lin", "Ziyu", ""], ["Sun", "Qi", ""], ["Cheng", "Bo", ""]]}, {"id": "2102.11743", "submitter": "Kyle Mills", "authors": "Kyle Mills and Isaac Tamblyn", "title": "Weakly-supervised multi-class object localization using only object\n  counts as labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the use of an extensive deep neural network to localize\ninstances of objects in images. The EDNN is naturally able to accurately\nperform multi-class counting using only ground truth count values as labels.\nWithout providing any conceptual information, object annotations, or pixel\nsegmentation information, the neural network is able to formulate its own\nconceptual representation of the items in the image. Using images labelled with\nonly the counts of the objects present,the structure of the extensive deep\nneural network can be exploited to perform localization of the objects within\nthe visual field. We demonstrate that a trained EDNN can be used to count\nobjects in images much larger than those on which it was trained. In order to\ndemonstrate our technique, we introduce seven new data sets: five progressively\nharder MNIST digit-counting data sets, and two datasets of 3d-rendered rubber\nducks in various situations. On most of these datasets, the EDNN achieves\ngreater than 99% test set accuracy in counting objects.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:14:46 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Mills", "Kyle", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2102.11749", "submitter": "Ewan Dunbar", "authors": "Louis Fournier and Ewan Dunbar", "title": "Paraphrases do not explain word analogies", "comments": "To appear in Proceedings of the 16th Conference of the European\n  Chapter of the Association for Computational Linguistics: Volume 2, Short\n  Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many types of distributional word embeddings (weakly) encode linguistic\nregularities as directions (the difference between \"jump\" and \"jumped\" will be\nin a similar direction to that of \"walk\" and \"walked,\" and so on). Several\nattempts have been made to explain this fact. We respond to Allen and\nHospedales' recent (ICML, 2019) theoretical explanation, which claims that\nword2vec and GloVe will encode linguistic regularities whenever a specific\nrelation of paraphrase holds between the four words involved in the regularity.\nWe demonstrate that the explanation does not go through: the paraphrase\nrelations needed under this explanation do not hold empirically.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:25:10 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Fournier", "Louis", ""], ["Dunbar", "Ewan", ""]]}, {"id": "2102.11761", "submitter": "Sam Witty", "authors": "Sam Witty, David Jensen, Vikash Mansinghka", "title": "A Simulation-Based Test of Identifiability for Bayesian Causal Inference", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a procedure for testing the identifiability of Bayesian\nmodels for causal inference. Although the do-calculus is sound and complete\ngiven a causal graph, many practical assumptions cannot be expressed in terms\nof graph structure alone, such as the assumptions required by instrumental\nvariable designs, regression discontinuity designs, and within-subjects\ndesigns. We present simulation-based identifiability (SBI), a fully automated\nidentification test based on a particle optimization scheme with simulated\nobservations. This approach expresses causal assumptions as priors over\nfunctions in a structural causal model, including flexible priors using\nGaussian processes. We prove that SBI is asymptotically sound and complete, and\nproduces practical finite-sample bounds. We also show empirically that SBI\nagrees with known results in graph-based identification as well as with\nwidely-held intuitions for designs in which graph-based methods are\ninconclusive.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:42:06 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Witty", "Sam", ""], ["Jensen", "David", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "2102.11762", "submitter": "Hardik Meisheri", "authors": "Omkar Shelke, Hardik Meisheri, Harshad Khadilkar", "title": "School of hard knocks: Curriculum analysis for Pommerman with a fixed\n  computational budget", "comments": "8 pages, Submitted to ALA workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pommerman is a hybrid cooperative/adversarial multi-agent environment, with\nchallenging characteristics in terms of partial observability, limited or no\ncommunication, sparse and delayed rewards, and restrictive computational time\nlimits. This makes it a challenging environment for reinforcement learning (RL)\napproaches. In this paper, we focus on developing a curriculum for learning a\nrobust and promising policy in a constrained computational budget of 100,000\ngames, starting from a fixed base policy (which is itself trained to imitate a\nnoisy expert policy). All RL algorithms starting from the base policy use\nvanilla proximal-policy optimization (PPO) with the same reward function, and\nthe only difference between their training is the mix and sequence of opponent\npolicies. One expects that beginning training with simpler opponents and then\ngradually increasing the opponent difficulty will facilitate faster learning,\nleading to more robust policies compared against a baseline where all available\nopponent policies are introduced from the start. We test this hypothesis and\nshow that within constrained computational budgets, it is in fact better to\n\"learn in the school of hard knocks\", i.e., against all available opponent\npolicies nearly from the start. We also include ablation studies where we study\nthe effect of modifying the base environment properties of ammo and bomb blast\nstrength on the agent performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:43:09 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 07:54:32 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Shelke", "Omkar", ""], ["Meisheri", "Hardik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2102.11764", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Vaneet Aggarwal, Fanglin Bao, Zubin Jacob", "title": "Quantum Entropic Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.IT math.IT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As quantum computing and networking nodes scale-up, important open questions\narise on the causal influence of various sub-systems on the total system\nperformance. These questions are related to the tomographic reconstruction of\nthe macroscopic wavefunction and optimizing connectivity of large engineered\nqubit systems, the reliable broadcasting of information across quantum networks\nas well as speed-up of classical causal inference algorithms on quantum\ncomputers. A direct generalization of the existing causal inference techniques\nto the quantum domain is not possible due to superposition and entanglement. We\nput forth a new theoretical framework for merging quantum information science\nand causal inference by exploiting entropic principles. First, we build the\nfundamental connection between the celebrated quantum marginal problem and\nentropic causal inference. Second, inspired by the definition of geometric\nquantum discord, we fill the gap between classical conditional probabilities\nand quantum conditional density matrices. These fundamental theoretical\nadvances are exploited to develop a scalable algorithmic approach for quantum\nentropic causal inference. We apply our proposed framework to an experimentally\nrelevant scenario of identifying message senders on quantum noisy links. This\nsuccessful inference on a synthetic quantum dataset can lay the foundations of\nidentifying originators of malicious activity on future multi-node quantum\nnetworks. We unify classical and quantum causal inference in a principled way\npaving the way for future applications in quantum computing and networking.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 15:51:34 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:40:47 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Aggarwal", "Vaneet", ""], ["Bao", "Fanglin", ""], ["Jacob", "Zubin", ""]]}, {"id": "2102.11782", "submitter": "Yasir Mahmood", "authors": "Yasir Mahmood, Arne Meier, Johannes Schmidt", "title": "Parameterized Complexity of Logic-Based Argumentation in Schaefer's\n  Framework", "comments": "Technical report to the final version at AAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic-based argumentation is a well-established formalism modelling\nnonmonotonic reasoning. It has been playing a major role in AI for decades,\nnow. Informally, a set of formulas is the support for a given claim if it is\nconsistent, subset-minimal, and implies the claim. In such a case, the pair of\nthe support and the claim together is called an argument. In this paper, we\nstudy the propositional variants of the following three computational tasks\nstudied in argumentation: ARG (exists a support for a given claim with respect\nto a given set of formulas), ARG-Check (is a given set a support for a given\nclaim), and ARG-Rel (similarly as ARG plus requiring an additionally given\nformula to be contained in the support). ARG-Check is complete for the\ncomplexity class DP, and the other two problems are known to be complete for\nthe second level of the polynomial hierarchy (Parson et al., J. Log. Comput.,\n2003) and, accordingly, are highly intractable. Analyzing the reason for this\nintractability, we perform a two-dimensional classification: first, we consider\nall possible propositional fragments of the problem within Schaefer's framework\n(STOC 1978), and then study different parameterizations for each of the\nfragment. We identify a list of reasonable structural parameters (size of the\nclaim, support, knowledge-base) that are connected to the aforementioned\ndecision problems. Eventually, we thoroughly draw a fine border of\nparameterized intractability for each of the problems showing where the\nproblems are fixed-parameter tractable and when this exactly stops.\nSurprisingly, several cases are of very high intractability (paraNP and\nbeyond).\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:34:42 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Mahmood", "Yasir", ""], ["Meier", "Arne", ""], ["Schmidt", "Johannes", ""]]}, {"id": "2102.11791", "submitter": "Ramon Fraga Pereira", "authors": "Kin Max Gusm\\~ao, Ramon Fraga Pereira, and Felipe Meneguzzi", "title": "Inferring Agents Preferences as Priors for Probabilistic Goal\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to goal recognition have leveraged planning landmarks to\nachieve high-accuracy with low runtime cost. These approaches, however, lack a\nprobabilistic interpretation. Furthermore, while most probabilistic models to\ngoal recognition assume that the recognizer has access to a prior probability\nrepresenting, for example, an agent's preferences, virtually no goal\nrecognition approach actually uses the prior in practice, simply assuming a\nuniform prior. In this paper, we provide a model to both extend landmark-based\ngoal recognition with a probabilistic interpretation and allow the estimation\nof such prior probability and its usage to compute posterior probabilities\nafter repeated interactions of observed agents. We empirically show that our\nmodel can not only recognize goals effectively but also successfully infer the\ncorrect prior probability distribution representing an agent's preferences.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:53:23 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gusm\u00e3o", "Kin Max", ""], ["Pereira", "Ramon Fraga", ""], ["Meneguzzi", "Felipe", ""]]}, {"id": "2102.11848", "submitter": "Lucas Costa Brito", "authors": "Lucas Costa Brito, Gian Antonio Susto, Jorge Nei Brito, Marcus Antonio\n  Viana Duarte", "title": "An Explainable Artificial Intelligence Approach for Unsupervised Fault\n  Detection and Diagnosis in Rotating Machinery", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monitoring of rotating machinery is an essential task in today's\nproduction processes. Currently, several machine learning and deep\nlearning-based modules have achieved excellent results in fault detection and\ndiagnosis. Nevertheless, to further increase user adoption and diffusion of\nsuch technologies, users and human experts must be provided with explanations\nand insights by the modules. Another issue is related, in most cases, with the\nunavailability of labeled historical data that makes the use of supervised\nmodels unfeasible. Therefore, a new approach for fault detection and diagnosis\nin rotating machinery is here proposed. The methodology consists of three\nparts: feature extraction, fault detection and fault diagnosis. In the first\npart, the vibration features in the time and frequency domains are extracted.\nSecondly, in the fault detection, the presence of fault is verified in an\nunsupervised manner based on anomaly detection algorithms. The modularity of\nthe methodology allows different algorithms to be implemented. Finally, in\nfault diagnosis, Shapley Additive Explanations (SHAP), a technique to interpret\nblack-box models, is used. Through the feature importance ranking obtained by\nthe model explainability, the fault diagnosis is performed. Two tools for\ndiagnosis are proposed, namely: unsupervised classification and root cause\nanalysis. The effectiveness of the proposed approach is shown on three datasets\ncontaining different mechanical faults in rotating machinery. The study also\npresents a comparison between models used in machine learning explainability:\nSHAP and Local Depth-based Feature Importance for the Isolation Forest (Local-\nDIFFI). Lastly, an analysis of several state-of-art anomaly detection\nalgorithms in rotating machinery is included.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:28:18 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Brito", "Lucas Costa", ""], ["Susto", "Gian Antonio", ""], ["Brito", "Jorge Nei", ""], ["Duarte", "Marcus Antonio Viana", ""]]}, {"id": "2102.11855", "submitter": "Hao-Yuan Chang", "authors": "Hao-Yuan Chang, Kang L. Wang (University of California, Los Angeles)", "title": "Deep Convolutional Neural Networks with Unitary Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While normalizations aim to fix the exploding and vanishing gradient problem\nin deep neural networks, they have drawbacks in speed or accuracy because of\ntheir dependency on the data set statistics. This work is a comprehensive study\nof a novel method based on unitary synaptic weights derived from Lie Group to\nconstruct intrinsically stable neural systems. Here we show that unitary\nconvolutional neural networks deliver up to 32% faster inference speeds while\nmaintaining competitive prediction accuracy. Unlike prior arts restricted to\nsquare synaptic weights, we expand the unitary networks to weights of any size\nand dimension.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:36:13 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chang", "Hao-Yuan", "", "University of California, Los Angeles"], ["Wang", "Kang L.", "", "University of California, Los Angeles"]]}, {"id": "2102.11856", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Kevin Liang, Nikhil Mehta, Lawrence Carin", "title": "Meta-Learned Attribute Self-Gating for Continual Generalized Zero-Shot\n  Learning", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot learning (ZSL) has been shown to be a promising approach to\ngeneralizing a model to categories unseen during training by leveraging class\nattributes, but challenges still remain. Recently, methods using generative\nmodels to combat bias towards classes seen during training have pushed the\nstate of the art of ZSL, but these generative models can be slow or\ncomputationally expensive to train. Additionally, while many previous ZSL\nmethods assume a one-time adaptation to unseen classes, in reality, the world\nis always changing, necessitating a constant adjustment for deployed models.\nModels unprepared to handle a sequential stream of data are likely to\nexperience catastrophic forgetting. We propose a meta-continual zero-shot\nlearning (MCZSL) approach to address both these issues. In particular, by\npairing self-gating of attributes and scaled class normalization with\nmeta-learning based training, we are able to outperform state-of-the-art\nresults while being able to train our models substantially faster\n($>100\\times$) than expensive generative-based approaches. We demonstrate this\nby performing experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2\nand SUN) in both generalized zero-shot learning and generalized continual\nzero-shot learning settings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:36:14 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Liang", "Kevin", ""], ["Mehta", "Nikhil", ""], ["Carin", "Lawrence", ""]]}, {"id": "2102.11872", "submitter": "Shivin Srivastava", "authors": "Shivin Srivastava, Siddharth Bhatia, Lingxiao Huang, Lim Jun Heng,\n  Kenji Kawaguchi, Vaibhav Rajan", "title": "Dont Just Divide; Polarize and Conquer!", "comments": "19 Pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In data containing heterogeneous subpopulations, classification performance\nbenefits from incorporating the knowledge of cluster structure in the\nclassifier. Previous methods for such combined clustering and classification\nare either 1) classifier-specific and not generic, or 2) independently perform\nclustering and classifier training, which may not form clusters that can\npotentially benefit classifier performance. The question of how to perform\nclustering to improve the performance of classifiers trained on the clusters\nhas received scant attention in previous literature, despite its importance in\nseveral real-world applications. In this paper, we design a simple and\nefficient classification algorithm called Clustering Aware Classification\n(CAC), to find clusters that are well suited for being used as training\ndatasets by classifiers for each underlying subpopulation. Our experiments on\nsynthetic and real benchmark datasets demonstrate the efficacy of CAC over\nprevious methods for combined clustering and classification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 18:59:39 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 06:26:30 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Srivastava", "Shivin", ""], ["Bhatia", "Siddharth", ""], ["Huang", "Lingxiao", ""], ["Heng", "Lim Jun", ""], ["Kawaguchi", "Kenji", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "2102.11905", "submitter": "Chen Tang", "authors": "Chen Tang, Nishan Srishankar, Sujitha Martin, Masayoshi Tomizuka", "title": "Grounded Relational Inference: Domain Knowledge Driven Explainable\n  Autonomous Driving", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Explainability is essential for autonomous vehicles and other robotics\nsystems interacting with humans and other objects during operation. Humans need\nto understand and anticipate the actions taken by the machines for trustful and\nsafe cooperation. In this work, we aim to enable the explainability of an\nautonomous driving system at the design stage by incorporating expert domain\nknowledge into the model. We propose Grounded Relational Inference (GRI). It\nmodels an interactive system's underlying dynamics by inferring an interaction\ngraph representing the agents' relations. We ensure an interpretable\ninteraction graph by grounding the relational latent space into semantic\nbehaviors defined with expert domain knowledge. We demonstrate that it can\nmodel interactive traffic scenarios under both simulation and real-world\nsettings, and generate interpretable graphs explaining the vehicle's behavior\nby their interactions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 19:34:32 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Tang", "Chen", ""], ["Srishankar", "Nishan", ""], ["Martin", "Sujitha", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2102.11917", "submitter": "Edmon Begoli", "authors": "Jeremiah Duncan, Fabian Fallas, Chris Gropp, Emily Herron, Maria\n  Mahbub, Paula Olaya, Eduardo Ponce, Tabitha K. Samuel, Daniel Schultz,\n  Sudarshan Srinivasan, Maofeng Tang, Viktor Zenkov, Quan Zhou, Edmon Begoli", "title": "The Sensitivity of Word Embeddings-based Author Detection Models to\n  Semantic-preserving Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Authorship analysis is an important subject in the field of natural language\nprocessing. It allows the detection of the most likely writer of articles,\nnews, books, or messages. This technique has multiple uses in tasks related to\nauthorship attribution, detection of plagiarism, style analysis, sources of\nmisinformation, etc. The focus of this paper is to explore the limitations and\nsensitiveness of established approaches to adversarial manipulations of inputs.\nTo this end, and using those established techniques, we first developed an\nexperimental frame-work for author detection and input perturbations. Next, we\nexperimentally evaluated the performance of the authorship detection model to a\ncollection of semantic-preserving adversarial perturbations of input\nnarratives. Finally, we compare and analyze the effects of different\nperturbation strategies, input and model configurations, and the effects of\nthese on the author detection model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 19:55:45 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Duncan", "Jeremiah", ""], ["Fallas", "Fabian", ""], ["Gropp", "Chris", ""], ["Herron", "Emily", ""], ["Mahbub", "Maria", ""], ["Olaya", "Paula", ""], ["Ponce", "Eduardo", ""], ["Samuel", "Tabitha K.", ""], ["Schultz", "Daniel", ""], ["Srinivasan", "Sudarshan", ""], ["Tang", "Maofeng", ""], ["Zenkov", "Viktor", ""], ["Zhou", "Quan", ""], ["Begoli", "Edmon", ""]]}, {"id": "2102.11922", "submitter": "Puneet Mathur", "authors": "Puneet Mathur, Trisha Mittal and Dinesh Manocha", "title": "Dynamic Graph Modeling of Simultaneous EEG and Eye-tracking Data for\n  Reading Task Identification", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new approach, that we call AdaGTCN, for identifying human reader\nintent from Electroencephalogram~(EEG) and Eye movement~(EM) data in order to\nhelp differentiate between normal reading and task-oriented reading.\nUnderstanding the physiological aspects of the reading process~(the cognitive\nload and the reading intent) can help improve the quality of crowd-sourced\nannotated data. Our method, Adaptive Graph Temporal Convolution Network\n(AdaGTCN), uses an Adaptive Graph Learning Layer and Deep Neighborhood Graph\nConvolution Layer for identifying the reading activities using time-locked EEG\nsequences recorded during word-level eye-movement fixations. Adaptive Graph\nLearning Layer dynamically learns the spatial correlations between the EEG\nelectrode signals while the Deep Neighborhood Graph Convolution Layer exploits\ntemporal features from a dense graph neighborhood to establish the state of the\nart in reading task identification over other contemporary approaches. We\ncompare our approach with several baselines to report an improvement of 6.29%\non the ZuCo 2.0 dataset, along with extensive ablation experiments\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 18:19:49 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Mathur", "Puneet", ""], ["Mittal", "Trisha", ""], ["Manocha", "Dinesh", ""]]}, {"id": "2102.11924", "submitter": "Henry Soldano", "authors": "Henry Soldano", "title": "Finite Confluences and Closed Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to propose and investigate a partial order\nstructure weaker than the lattice structure and which have nice properties\nregarding closure operators. We extend accordingly closed pattern mining and\nformal concept analysis to such structures we further call confluences. The\nprimary motivation for investigating these structures is that it allows to\nreduce a lattice to a part whose elements are connected, as in some graph,\nstill preserving a useful characterization of closure operators. Our\ninvestigation also considers how reducing one of the lattice involved in a\nGalois connection affects the structure of the closure operators ranges. When\nextending this way formal concept analysis we will focus on the intensional\nspace, i.e. in reducing the pattern language, while recent investigations\nrather explored the reduction of the extensional space to connected elements.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 09:12:46 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Soldano", "Henry", ""]]}, {"id": "2102.11932", "submitter": "Thomas Kleine Buening", "authors": "Thomas Kleine Buening and Meirav Segal and Debabrota Basu and Christos\n  Dimitrakakis and Anne-Marie George", "title": "On Meritocracy in Optimal Set Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting a set of individuals from a candidate\npopulation in order to maximise utility. When the utility function is defined\nover sets, this raises the question of how to define meritocracy. We define and\nanalyse an appropriate notion of meritocracy derived from the utility function.\nWe introduce the notion of expected marginal contributions of individuals and\nanalyse its links to the underlying optimisation problem, our notion of\nmeritocracy, and other notions of fairness such as the Shapley value. We also\nexperimentally analyse the effect of different policy structures on the utility\nand meritocracy in a simulated college admission setting including constraints\non statistical parity.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 20:36:36 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:34:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Buening", "Thomas Kleine", ""], ["Segal", "Meirav", ""], ["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""], ["George", "Anne-Marie", ""]]}, {"id": "2102.11938", "submitter": "Kanishk Gandhi", "authors": "Kanishk Gandhi, Gala Stojnic, Brenden M. Lake, Moira R. Dillon", "title": "Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and\n  actions of others", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To achieve human-like common sense about everyday life, machine learning\nsystems must understand and reason about the goals, preferences, and actions of\nothers. Human infants intuitively achieve such common sense by making\ninferences about the underlying causes of other agents' actions. Directly\ninformed by research on infant cognition, our benchmark BIB challenges machines\nto achieve generalizable, common-sense reasoning about other agents like human\ninfants do. As in studies on infant cognition, moreover, we use a violation of\nexpectation paradigm in which machines must predict the plausibility of an\nagent's behavior given a video sequence, making this benchmark appropriate for\ndirect validation with human infants in future studies. We show that recently\nproposed, deep-learning-based agency reasoning models fail to show infant-like\nreasoning, leaving BIB an open challenge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:01:06 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Gandhi", "Kanishk", ""], ["Stojnic", "Gala", ""], ["Lake", "Brenden M.", ""], ["Dillon", "Moira R.", ""]]}, {"id": "2102.11944", "submitter": "Sebastian Stabinger BSc MSc", "authors": "Sebastian Stabinger, David Peer, and Antonio Rodr\\'iguez-S\\'anchez", "title": "Arguments for the Unsuitability of Convolutional Neural Networks for\n  Non--Local Tasks", "comments": "Under review at Neural Networks Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have established themselves over the past years\nas the state of the art method for image classification, and for many datasets,\nthey even surpass humans in categorizing images. Unfortunately, the same\narchitectures perform much worse when they have to compare parts of an image to\neach other to correctly classify this image.\n  Until now, no well-formed theoretical argument has been presented to explain\nthis deficiency. In this paper, we will argue that convolutional layers are of\nlittle use for such problems, since comparison tasks are global by nature, but\nconvolutional layers are local by design. We will use this insight to\nreformulate a comparison task into a sorting task and use findings on sorting\nnetworks to propose a lower bound for the number of parameters a neural network\nneeds to solve comparison tasks in a generalizable way. We will use this lower\nbound to argue that attention, as well as iterative/recurrent processing, is\nneeded to prevent a combinatorial explosion.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:13:49 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Stabinger", "Sebastian", ""], ["Peer", "David", ""], ["Rodr\u00edguez-S\u00e1nchez", "Antonio", ""]]}, {"id": "2102.11955", "submitter": "Casey Meehan", "authors": "Casey Meehan, Kamalika Chaudhuri", "title": "Location Trace Privacy Under Conditional Priors", "comments": "To be published in the proceedings of AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing meaningful privacy to users of location based services is\nparticularly challenging when multiple locations are revealed in a short period\nof time. This is primarily due to the tremendous degree of dependence that can\nbe anticipated between points. We propose a R\\'enyi divergence based privacy\nframework for bounding expected privacy loss for conditionally dependent data.\nAdditionally, we demonstrate an algorithm for achieving this privacy under\nGaussian process conditional priors. This framework both exemplifies why\nconditionally dependent data is so challenging to protect and offers a strategy\nfor preserving privacy to within a fixed radius for sensitive locations in a\nuser's trace.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:55:34 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Meehan", "Casey", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2102.11965", "submitter": "Frank van Harmelen", "authors": "Michael van Bekkum, Maaike de Boer, Frank van Harmelen, Andr\\'e\n  Meyer-Vitali, Annette ten Teije", "title": "Modular Design Patterns for Hybrid Learning and Reasoning Systems: a\n  taxonomy, patterns and use cases", "comments": "20 pages, 22 figures, accepted for publication in the International\n  Journal of Applied Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The unification of statistical (data-driven) and symbolic (knowledge-driven)\nmethods is widely recognised as one of the key challenges of modern AI. Recent\nyears have seen large number of publications on such hybrid neuro-symbolic AI\nsystems. That rapidly growing literature is highly diverse and mostly\nempirical, and is lacking a unifying view of the large variety of these hybrid\nsystems. In this paper we analyse a large body of recent literature and we\npropose a set of modular design patterns for such hybrid, neuro-symbolic\nsystems. We are able to describe the architecture of a very large number of\nhybrid systems by composing only a small set of elementary patterns as building\nblocks.\n  The main contributions of this paper are: 1) a taxonomically organised\nvocabulary to describe both processes and data structures used in hybrid\nsystems; 2) a set of 15+ design patterns for hybrid AI systems, organised in a\nset of elementary patterns and a set of compositional patterns; 3) an\napplication of these design patterns in two realistic use-cases for hybrid AI\nsystems. Our patterns reveal similarities between systems that were not\nrecognised until now. Finally, our design patterns extend and refine Kautz'\nearlier attempt at categorising neuro-symbolic architectures.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 22:16:05 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 11:18:15 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["van Bekkum", "Michael", ""], ["de Boer", "Maaike", ""], ["van Harmelen", "Frank", ""], ["Meyer-Vitali", "Andr\u00e9", ""], ["Teije", "Annette ten", ""]]}, {"id": "2102.12002", "submitter": "Ecenaz Erdemir", "authors": "Ecenaz Erdemir, Jeffrey Bickford, Luca Melis and Sergul Aydore", "title": "Adversarial Robustness with Non-uniform Perturbations", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of machine learning models is critical for security related\napplications, where real-world adversaries are uniquely focused on evading\nneural network based detectors. Prior work mainly focus on crafting adversarial\nexamples (AEs) with small uniform norm-bounded perturbations across features to\nmaintain the requirement of imperceptibility. However, uniform perturbations do\nnot result in realistic AEs in domains such as malware, finance, and social\nnetworks. For these types of applications, features typically have some\nsemantically meaningful dependencies. The key idea of our proposed approach is\nto enable non-uniform perturbations that can adequately represent these feature\ndependencies during adversarial training. We propose using characteristics of\nthe empirical data distribution, both on correlations between the features and\nthe importance of the features themselves. Using experimental datasets for\nmalware classification, credit risk prediction, and spam detection, we show\nthat our approach is more robust to real-world attacks. Finally, we present\nrobustness certification utilizing non-uniform perturbation bounds, and show\nthat non-uniform bounds achieve better certification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:54:43 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 21:40:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Erdemir", "Ecenaz", ""], ["Bickford", "Jeffrey", ""], ["Melis", "Luca", ""], ["Aydore", "Sergul", ""]]}, {"id": "2102.12010", "submitter": "Pierre Merriaux", "authors": "Jean-Luc D\\'eziel, Pierre Merriaux, Francis Tremblay, Dave Lessard,\n  Dominique Plourde, Julien Stanguennec, Pierre Goulet and Pierre Olivier", "title": "PixSet : An Opportunity for 3D Computer Vision to Go Beyond Point Clouds\n  With a Full-Waveform LiDAR Dataset", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leddar PixSet is a new publicly available dataset (dataset.leddartech.com)\nfor autonomous driving research and development. One key novelty of this\ndataset is the presence of full-waveform data from the Leddar Pixell sensor, a\nsolid-state flash LiDAR. Full-waveform data has been shown to improve the\nperformance of perception algorithms in airborne applications but is yet to be\ndemonstrated for terrestrial applications such as autonomous driving. The\nPixSet dataset contains approximately 29k frames from 97 sequences recorded in\nhigh-density urban areas, using a set of various sensors (cameras, LiDARs,\nradar, IMU, etc.) Each frame has been manually annotated with 3D bounding\nboxes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:13:17 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 00:25:11 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["D\u00e9ziel", "Jean-Luc", ""], ["Merriaux", "Pierre", ""], ["Tremblay", "Francis", ""], ["Lessard", "Dave", ""], ["Plourde", "Dominique", ""], ["Stanguennec", "Julien", ""], ["Goulet", "Pierre", ""], ["Olivier", "Pierre", ""]]}, {"id": "2102.12017", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Darshan W. Bryner and Jose C. Principe", "title": "Annotating Motion Primitives for Simplifying Action Search in\n  Reinforcement Learning", "comments": "Submitted to IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning in large-scale environments is challenging due to the\nmany possible actions that can be taken in specific situations. We have\npreviously developed a means of constraining, and hence speeding up, the search\nprocess through the use of motion primitives; motion primitives are sequences\nof pre-specified actions taken across a state series. As a byproduct of this\nwork, we have found that if the motion primitives' motions and actions are\nlabeled, then the search can be sped up further. Since motion primitives may\ninitially lack such details, we propose a theoretically viewpoint-insensitive\nand speed-insensitive means of automatically annotating the underlying motions\nand actions. We do this through a differential-geometric, spatio-temporal\nkinematics descriptor, which analyzes how the poses of entities in two motion\nsequences change over time. We use this descriptor in conjunction with a\nweighted-nearest-neighbor classifier to label the primitives using a limited\nset of training examples. In our experiments, we achieve high motion and action\nannotation rates for human-action-derived primitives with as few as one\ntraining sample. We also demonstrate that reinforcement learning using\naccurately labeled trajectories leads to high-performing policies more quickly\nthan standard reinforcement learning techniques. This is partly because motion\nprimitives encode prior domain knowledge and preempt the need to re-discover\nthat knowledge during training. It is also because agents can leverage the\nlabels to systematically ignore action classes that do not facilitate task\nobjectives, thereby reducing the action space.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:32:06 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 22:45:44 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 05:28:42 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Bryner", "Darshan W.", ""], ["Principe", "Jose C.", ""]]}, {"id": "2102.12037", "submitter": "William Harvey", "authors": "William Harvey, Saeid Naderiparizi, Frank Wood", "title": "Image Completion via Inference in Deep Generative Models", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider image completion from the perspective of amortized inference in\nan image generative model. We leverage recent state of the art variational\nauto-encoder architectures that have been shown to produce photo-realistic\nnatural images at non-trivial resolutions. Through amortized inference in such\na model we can train neural artifacts that produce diverse, realistic image\ncompletions even when the vast majority of an image is missing. We demonstrate\nsuperior sample quality and diversity compared to prior art on the CIFAR-10 and\nFFHQ-256 datasets. We conclude by describing and demonstrating an application\nthat requires an in-painting model with the capabilities ours exhibits: the use\nof Bayesian optimal experimental design to select the most informative sequence\nof small field of view x-rays for chest pathology detection.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 02:59:43 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 22:18:32 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Harvey", "William", ""], ["Naderiparizi", "Saeid", ""], ["Wood", "Frank", ""]]}, {"id": "2102.12060", "submitter": "Ana Marasovi\\'c", "authors": "Sarah Wiegreffe and Ana Marasovi\\'c", "title": "Teach Me to Explain: A Review of Datasets for Explainable NLP", "comments": "Version 2: added missing references, changed the NLI example in Table\n  1, and corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable NLP (ExNLP) has increasingly focused on collecting\nhuman-annotated explanations. These explanations are used downstream in three\nways: as data augmentation to improve performance on a predictive task, as a\nloss signal to train models to produce explanations for their predictions, and\nas a means to evaluate the quality of model-generated explanations. In this\nreview, we identify three predominant classes of explanations (highlights,\nfree-text, and structured), organize the literature on annotating each type,\npoint to what has been learned to date, and give recommendations for collecting\nExNLP datasets in the future.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 04:25:01 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 04:42:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wiegreffe", "Sarah", ""], ["Marasovi\u0107", "Ana", ""]]}, {"id": "2102.12070", "submitter": "Nishanth Rao", "authors": "Nishanth Rao and Suresh Sundaram", "title": "Spatio-Temporal Look-Ahead Trajectory Prediction using Memory Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prognostication of vehicle trajectories in unknown environments is\nintrinsically a challenging and difficult problem to solve. The behavior of\nsuch vehicles is highly influenced by surrounding traffic, road conditions, and\nrogue participants present in the environment. Moreover, the presence of\npedestrians, traffic lights, stop signs, etc., makes it much harder to infer\nthe behavior of various traffic agents. This paper attempts to solve the\nproblem of Spatio-temporal look-ahead trajectory prediction using a novel\nrecurrent neural network called the Memory Neuron Network. The Memory Neuron\nNetwork (MNN) attempts to capture the input-output relationship between the\npast positions and the future positions of the traffic agents. The proposed\nmodel is computationally less intensive and has a simple architecture as\ncompared to other deep learning models that utilize LSTMs and GRUs. It is then\nevaluated on the publicly available NGSIM dataset and its performance is\ncompared with several state-of-art algorithms. Additionally, the performance is\nalso evaluated on a custom synthetic dataset generated from the CARLA\nsimulator. It is seen that the proposed model outperforms the existing\nstate-of-art algorithms. Finally, the model is integrated with the CARLA\nsimulator to test its robustness in real-time traffic scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 05:02:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Rao", "Nishanth", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2102.12076", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen", "title": "Perspective: Purposeful Failure in Artificial Life and Artificial\n  Intelligence", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex systems fail. I argue that failures can be a blueprint characterizing\nliving organisms and biological intelligence, a control mechanism to increase\ncomplexity in evolutionary simulations, and an alternative to classical fitness\noptimization. Imitating biological successes in Artificial Life and Artificial\nIntelligence can be misleading; imitating failures offers a path towards\nunderstanding and emulating life it in artificial systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 05:43:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sinapayen", "Lana", ""]]}, {"id": "2102.12088", "submitter": "Harshad Khadilkar", "authors": "Nazneen N Sultana, Vinita Baniwal, Ansuma Basumatary, Piyush Mittal,\n  Supratim Ghosh, Harshad Khadilkar", "title": "Fast Approximate Solutions using Reinforcement Learning for Dynamic\n  Capacitated Vehicle Routing with Time Windows", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops an inherently parallelised, fast, approximate\nlearning-based solution to the generic class of Capacitated Vehicle Routing\nProblems with Time Windows and Dynamic Routing (CVRP-TWDR). Considering\nvehicles in a fleet as decentralised agents, we postulate that using\nreinforcement learning (RL) based adaptation is a key enabler for real-time\nroute formation in a dynamic environment. The methodology allows each agent\n(vehicle) to independently evaluate the value of serving each customer, and\nuses a centralised allocation heuristic to finalise the allocations based on\nthe generated values. We show that the solutions produced by this method are\nsignificantly faster than exact formulations and state-of-the-art\nmeta-heuristics, while being reasonably close to optimal in terms of solution\nquality. We describe experiments in both the static case (when all customer\ndemands and time windows are known in advance) as well as the dynamic case\n(where customers can pop up at any time during execution). The results with a\nsingle trained model on large, out-of-distribution test data demonstrate the\nscalability and flexibility of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 06:30:16 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 05:10:45 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Sultana", "Nazneen N", ""], ["Baniwal", "Vinita", ""], ["Basumatary", "Ansuma", ""], ["Mittal", "Piyush", ""], ["Ghosh", "Supratim", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2102.12141", "submitter": "You Zhou", "authors": "You Zhou and Jianfeng Gao and Tamim Asfour", "title": "Learning to Shift Attention for Motion Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge of motion generation using robot learning from demonstration\ntechniques is that human demonstrations follow a distribution with multiple\nmodes for one task query. Previous approaches fail to capture all modes or tend\nto average modes of the demonstrations and thus generate invalid trajectories.\nThe other difficulty is the small number of demonstrations that cannot cover\nthe entire working space. To overcome this problem, a motion generation model\nwith extrapolation ability is needed. Previous works restrict task queries as\nlocal frames and learn representations in local frames. We propose a model to\nsolve both problems. For multiple modes, we suggest to learn local latent\nrepresentations of motion trajectories with a density estimation method based\non real-valued non-volume preserving (RealNVP) transformations that provides a\nset of powerful, stably invertible, and learnable transformations. To improve\nthe extrapolation ability, we propose to shift the attention of the robot from\none local frame to another during the task execution. In experiments, we\nconsider the docking problem used also in previous works where a trajectory has\nto be generated to connect two dockers without collision. We increase\ncomplexity of the task and show that the proposed method outperforms other\napproaches. In addition, we evaluate the approach in real robot experiments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 09:07:52 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Zhou", "You", ""], ["Gao", "Jianfeng", ""], ["Asfour", "Tamim", ""]]}, {"id": "2102.12151", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Christoph Zehentner and Paul Blazek", "title": "CoreDiag: Eliminating Redundancy in Constraint Sets", "comments": "A. Felfernig, C. Zehentner, and P. Blazek. COREDIAG: Eliminating\n  Redundancy in Constraint Sets. In the 22nd International Workshop on\n  Principles of Diagnosis, Murnau, Germany, pp. 219-224, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based environments such as configuration systems, recommender\nsystems, and scheduling systems support users in different decision making\nscenarios. These environments exploit a knowledge base for determining\nsolutions of interest for the user. The development and maintenance of such\nknowledge bases is an extremely time-consuming and error-prone task. Users\noften specify constraints which do not reflect the real-world. For example,\nredundant constraints are specified which often increase both, the effort for\ncalculating a solution and efforts related to knowledge base development and\nmaintenance. In this paper we present a new algorithm (CoreDiag) which can be\nexploited for the determination of minimal cores (minimal non-redundant\nconstraint sets). The algorithm is especially useful for distributed knowledge\nengineering scenarios where the degree of redundancy can become high. In order\nto show the applicability of our approach, we present an empirical study\nconducted with commercial configuration knowledge bases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 09:16:10 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Felfernig", "Alexander", ""], ["Zehentner", "Christoph", ""], ["Blazek", "Paul", ""]]}, {"id": "2102.12182", "submitter": "Christian Tomani", "authors": "Christian Tomani, Daniel Cremers, Florian Buettner", "title": "Parameterized Temperature Scaling for Boosting the Expressive Power in\n  Post-Hoc Uncertainty Calibration", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of uncertainty calibration and introduce a novel\ncalibration method, Parametrized Temperature Scaling (PTS). Standard deep\nneural networks typically yield uncalibrated predictions, which can be\ntransformed into calibrated confidence scores using post-hoc calibration\nmethods. In this contribution, we demonstrate that the performance of\naccuracy-preserving state-of-the-art post-hoc calibrators is limited by their\nintrinsic expressive power. We generalize temperature scaling by computing\nprediction-specific temperatures, parameterized by a neural network. We show\nwith extensive experiments that our novel accuracy-preserving approach\nconsistently outperforms existing algorithms across a large number of model\narchitectures, datasets and metrics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:18:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Tomani", "Christian", ""], ["Cremers", "Daniel", ""], ["Buettner", "Florian", ""]]}, {"id": "2102.12194", "submitter": "Alexandre Borges", "authors": "Alexandre Borges and Arlindo Oliveira", "title": "Combining Off and On-Policy Training in Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The combination of deep learning and Monte Carlo Tree Search (MCTS) has shown\nto be effective in various domains, such as board and video games. AlphaGo\nrepresented a significant step forward in our ability to learn complex board\ngames, and it was rapidly followed by significant advances, such as AlphaGo\nZero and AlphaZero. Recently, MuZero demonstrated that it is possible to master\nboth Atari games and board games by directly learning a model of the\nenvironment, which is then used with MCTS to decide what move to play in each\nposition. During tree search, the algorithm simulates games by exploring\nseveral possible moves and then picks the action that corresponds to the most\npromising trajectory. When training, limited use is made of these simulated\ngames since none of their trajectories are directly used as training examples.\nEven if we consider that not all trajectories from simulated games are useful,\nthere are thousands of potentially useful trajectories that are discarded.\nUsing information from these trajectories would provide more training data,\nmore quickly, leading to faster convergence and higher sample efficiency.\nRecent work introduced an off-policy value target for AlphaZero that uses data\nfrom simulated games. In this work, we propose a way to obtain off-policy\ntargets using data from simulated games in MuZero. We combine these off-policy\ntargets with the on-policy targets already used in MuZero in several ways, and\nstudy the impact of these targets and their combinations in three environments\nwith distinct characteristics. When used in the right combinations, our results\nshow that these targets can speed up the training process and lead to faster\nconvergence and higher rewards than the ones obtained by MuZero.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 10:47:26 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 15:14:56 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Borges", "Alexandre", ""], ["Oliveira", "Arlindo", ""]]}, {"id": "2102.12206", "submitter": "Eyal Ben-David", "authors": "Eyal Ben-David, Nadav Oved, Roi Reichart", "title": "PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen\n  Domains", "comments": "First two authors contributed equally to this work. Our code and data\n  are available at: https://github.com/eyalbd2/PADA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Processing algorithms have made incredible progress, but\nthey still struggle when applied to out-of-distribution examples. We address a\nchallenging and underexplored version of this domain adaptation problem, where\nan algorithm is trained on several source domains, and then applied to examples\nfrom an unseen domain that is unknown at training time. Particularly, no\nexamples, labeled or unlabeled, or any other knowledge about the target domain\nare available to the algorithm at training time. We present PADA: A\nPrompt-based Autoregressive Domain Adaptation algorithm, based on the T5 model.\nGiven a test example, PADA first generates a unique prompt and then,\nconditioned on this prompt, labels the example with respect to the NLP task.\nThe prompt is a sequence of unrestricted length, consisting of pre-defined\nDomain Related Features (DRFs) that characterize each of the source domains.\nIntuitively, the prompt is a unique signature that maps the test example to the\nsemantic space spanned by the source domains. In experiments with 3 tasks (text\nclassification and sequence tagging), for a total of 14 multi-source adaptation\nscenarios, PADA substantially outperforms strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:02:29 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 06:01:21 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Ben-David", "Eyal", ""], ["Oved", "Nadav", ""], ["Reichart", "Roi", ""]]}, {"id": "2102.12221", "submitter": "Sheik Mohammad Mostakim Fattah", "authors": "Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, and Sajib Mistry", "title": "A CP-Net based Qualitative Composition Approach for an IaaS Provider", "comments": "published in The 19th International Conference on Web Information\n  Systems Engineering (WISE) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel CP-Net based composition approach to qualitatively select\nan optimal set of consumers for an IaaS provider. The IaaS provider's and\nconsumers' qualitative preferences are captured using CP-Nets. We propose a\nCP-Net composability model using the semantic congruence property of a\nqualitative composition. A greedy-based and a heuristic-based consumer\nselection approaches are proposed that effectively reduce the search space of\ncandidate consumers in the composition. Experimental results prove the\nfeasibility of the proposed composition approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:21:20 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Fattah", "Sheik Mohammad Mostakim", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""]]}, {"id": "2102.12227", "submitter": "Andrea Galassi", "authors": "Andrea Galassi, Marco Lippi, Paolo Torroni", "title": "Multi-Task Attentive Residual Networks for Argument Mining", "comments": "12 pages, 2 figures, submitted to IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the use of residual networks and neural attention for argument\nmining and in particular link prediction. The method we propose makes no\nassumptions on document or argument structure. We propose a residual\narchitecture that exploits attention, multi-task learning, and makes use of\nensemble. We evaluate it on a challenging data set consisting of user-generated\ncomments, as well as on two other datasets consisting of scientific\npublications. On the user-generated content dataset, our model outperforms\nstate-of-the-art methods that rely on domain knowledge. On the scientific\nliterature datasets it achieves results comparable to those yielded by\nBERT-based approaches but with a much smaller model size.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:35:28 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Galassi", "Andrea", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "2102.12295", "submitter": "Sergey Nesteruk", "authors": "Sergey Nesteruk, Dmitrii Shadrin, Mariia Pukalchik", "title": "Image Augmentation for Multitask Few-Shot Learning: Agricultural Domain\n  Use-Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large datasets' availability is catalyzing a rapid expansion of deep learning\nin general and computer vision in particular. At the same time, in many\ndomains, a sufficient amount of training data is lacking, which may become an\nobstacle to the practical application of computer vision techniques. This paper\nchallenges small and imbalanced datasets based on the example of a plant\nphenomics domain. We introduce an image augmentation framework, which enables\nus to extremely enlarge the number of training samples while providing the data\nfor such tasks as object detection, semantic segmentation, instance\nsegmentation, object counting, image denoising, and classification. We prove\nthat our augmentation method increases model performance when only a few\ntraining samples are available. In our experiment, we use the DeepLabV3 model\non semantic segmentation tasks with Arabidopsis and Nicotiana tabacum image\ndataset. The obtained result shows a 9% relative increase in model performance\ncompared to the basic image augmentation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:08:34 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Nesteruk", "Sergey", ""], ["Shadrin", "Dmitrii", ""], ["Pukalchik", "Mariia", ""]]}, {"id": "2102.12307", "submitter": "Dmitry Ivanov", "authors": "Dmitry Ivanov, Vladimir Egorov, Aleksei Shpilman", "title": "Balancing Rational and Other-Regarding Preferences in\n  Cooperative-Competitive Environments", "comments": "Short version of this paper is accepted to AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent reinforcement learning studies extensively explore the interplay\nbetween cooperative and competitive behaviour in mixed environments. Unlike\ncooperative environments where agents strive towards a common goal, mixed\nenvironments are notorious for the conflicts of selfish and social interests.\nAs a consequence, purely rational agents often struggle to achieve and maintain\ncooperation. A prevalent approach to induce cooperative behaviour is to assign\nadditional rewards based on other agents' well-being. However, this approach\nsuffers from the issue of multi-agent credit assignment, which can hinder\nperformance. This issue is efficiently alleviated in cooperative setting with\nsuch state-of-the-art algorithms as QMIX and COMA. Still, when applied to mixed\nenvironments, these algorithms may result in unfair allocation of rewards. We\npropose BAROCCO, an extension of these algorithms capable to balance individual\nand social incentives. The mechanism behind BAROCCO is to train two distinct\nbut interwoven components that jointly affect each agent's decisions. Our\nmeta-algorithm is compatible with both Q-learning and Actor-Critic frameworks.\nWe experimentally confirm the advantages over the existing methods and explore\nthe behavioural aspects of BAROCCO in two mixed multi-agent setups.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:35:32 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Ivanov", "Dmitry", ""], ["Egorov", "Vladimir", ""], ["Shpilman", "Aleksei", ""]]}, {"id": "2102.12308", "submitter": "Omri Bar", "authors": "Daniel Neimark, Omri Bar, Maya Zohar, Gregory D. Hager, Dotan\n  Asselmann", "title": "\"Train one, Classify one, Teach one\" -- Cross-surgery transfer learning\n  for surgical step recognition", "comments": "MIDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work demonstrated the ability of machine learning to automatically\nrecognize surgical workflow steps from videos. However, these studies focused\non only a single type of procedure. In this work, we analyze, for the first\ntime, surgical step recognition on four different laparoscopic surgeries:\nCholecystectomy, Right Hemicolectomy, Sleeve Gastrectomy, and Appendectomy.\nInspired by the traditional apprenticeship model, in which surgical training is\nbased on the Halstedian method, we paraphrase the \"see one, do one, teach one\"\napproach for the surgical intelligence domain as \"train one, classify one,\nteach one\". In machine learning, this approach is often referred to as transfer\nlearning. To analyze the impact of transfer learning across different\nlaparoscopic procedures, we explore various time-series architectures and\nexamine their performance on each target domain. We introduce a new\narchitecture, the Time-Series Adaptation Network (TSAN), an architecture\noptimized for transfer learning of surgical step recognition, and we show how\nTSAN can be pre-trained using self-supervised learning on a Sequence Sorting\ntask. Such pre-training enables TSAN to learn workflow steps of a new\nlaparoscopic procedure type from only a small number of labeled samples from\nthe target procedure. Our proposed architecture leads to better performance\ncompared to other possible architectures, reaching over 90% accuracy when\ntransferring from laparoscopic Cholecystectomy to the other three procedure\ntypes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:36:18 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 06:55:23 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Neimark", "Daniel", ""], ["Bar", "Omri", ""], ["Zohar", "Maya", ""], ["Hager", "Gregory D.", ""], ["Asselmann", "Dotan", ""]]}, {"id": "2102.12321", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Abhishek Bhandwaldar, Chuang Gan, Kevin A. Smith, Shari\n  Liu, Dan Gutfreund, Elizabeth Spelke, Joshua B. Tenenbaum, Tomer D. Ullman", "title": "AGENT: A Benchmark for Core Psychological Reasoning", "comments": "ICML 2021, 12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine agents to successfully interact with humans in real-world\nsettings, they will need to develop an understanding of human mental life.\nIntuitive psychology, the ability to reason about hidden mental variables that\ndrive observable actions, comes naturally to people: even pre-verbal infants\ncan tell agents from objects, expecting agents to act efficiently to achieve\ngoals given constraints. Despite recent interest in machine agents that reason\nabout other agents, it is not clear if such agents learn or hold the core\npsychology principles that drive human reasoning. Inspired by cognitive\ndevelopment studies on intuitive psychology, we present a benchmark consisting\nof a large dataset of procedurally generated 3D animations, AGENT (Action,\nGoal, Efficiency, coNstraint, uTility), structured around four scenarios (goal\npreferences, action efficiency, unobserved constraints, and cost-reward\ntrade-offs) that probe key concepts of core intuitive psychology. We validate\nAGENT with human-ratings, propose an evaluation protocol emphasizing\ngeneralization, and compare two strong baselines built on Bayesian inverse\nplanning and a Theory of Mind neural network. Our results suggest that to pass\nthe designed tests of core intuitive psychology at human levels, a model must\nacquire or have built-in representations of how agents plan, combining utility\ncomputations and core knowledge of objects and physics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:58:23 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 18:11:01 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 03:41:55 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 03:13:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shu", "Tianmin", ""], ["Bhandwaldar", "Abhishek", ""], ["Gan", "Chuang", ""], ["Smith", "Kevin A.", ""], ["Liu", "Shari", ""], ["Gutfreund", "Dan", ""], ["Spelke", "Elizabeth", ""], ["Tenenbaum", "Joshua B.", ""], ["Ullman", "Tomer D.", ""]]}, {"id": "2102.12327", "submitter": "Alexander Felfernig", "authors": "Alexander Felfernig and Stefan Reiterer and Martin Stettinger and\n  Michael Jeran", "title": "An Overview of Direct Diagnosis and Repair Techniques in the WeeVis\n  Recommendation Environment", "comments": "A. Felfernig, S. Reiterer, M. Stettinger, and M. Jeran. An Overview\n  of Direct Diagnosis and Repair Techniques in the WeeVis Recommendation\n  Environment. In the 25th International Workshop on Principles of Diagnosis,\n  Graz, Austria, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based recommenders support users in the identification of items\n(products) fitting their wishes and needs. Example domains are financial\nservices and electronic equipment. In this paper we show how divide-and-conquer\nbased (direct) diagnosis algorithms (no conflict detection is needed) can be\nexploited in constraint-based recommendation scenarios. In this context, we\nprovide an overview of the MediaWiki-based recommendation environment WeeVis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:02:50 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Felfernig", "Alexander", ""], ["Reiterer", "Stefan", ""], ["Stettinger", "Martin", ""], ["Jeran", "Michael", ""]]}, {"id": "2102.12344", "submitter": "Lingheng Meng", "authors": "Lingheng Meng, Rob Gorbet, Dana Kuli\\'c", "title": "Memory-based Deep Reinforcement Learning for POMDP", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A promising characteristic of Deep Reinforcement Learning (DRL) is its\ncapability to learn optimal policy in an end-to-end manner without relying on\nfeature engineering. However, most approaches assume a fully observable state\nspace, i.e. fully observable Markov Decision Process (MDP). In real-world\nrobotics, this assumption is unpractical, because of the sensor issues such as\nsensors' capacity limitation and sensor noise, and the lack of knowledge about\nif the observation design is complete or not. These scenarios lead to Partially\nObservable MDP (POMDP) and need special treatment. In this paper, we propose\nLong-Short-Term-Memory-based Twin Delayed Deep Deterministic Policy Gradient\n(LSTM-TD3) by introducing a memory component to TD3, and compare its\nperformance with other DRL algorithms in both MDPs and POMDPs. Our results\ndemonstrate the significant advantages of the memory component in addressing\nPOMDPs, including the ability to handle missing and noisy observation data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:25:13 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:15:10 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 15:24:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Meng", "Lingheng", ""], ["Gorbet", "Rob", ""], ["Kuli\u0107", "Dana", ""]]}, {"id": "2102.12347", "submitter": "Syed Yousaf Shah", "authors": "Syed Yousaf Shah, Dhaval Patel, Long Vu, Xuan-Hong Dang, Bei Chen,\n  Peter Kirchner, Horst Samulowitz, David Wood, Gregory Bramble, Wesley M.\n  Gifford, Giridhar Ganapavarapu, Roman Vaculin and Petros Zerfos", "title": "AutoAI-TS: AutoAI for Time Series Forecasting", "comments": "Accepted for publication at ACM SIGMOD 2021 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of time series forecasting models including traditional\nstatistical models, machine learning models and more recently deep learning\nhave been proposed in the literature. However, choosing the right model along\nwith good parameter values that performs well on a given data is still\nchallenging. Automatically providing a good set of models to users for a given\ndataset saves both time and effort from using trial-and-error approaches with a\nwide variety of available models along with parameter optimization. We present\nAutoAI for Time Series Forecasting (AutoAI-TS) that provides users with a zero\nconfiguration (zero-conf ) system to efficiently train, optimize and choose\nbest forecasting model among various classes of models for the given dataset.\nWith its flexible zero-conf design, AutoAI-TS automatically performs all the\ndata preparation, model creation, parameter optimization, training and model\nselection for users and provides a trained model that is ready to use. For\ngiven data, AutoAI-TS utilizes a wide variety of models including classical\nstatistical models, Machine Learning (ML) models, statistical-ML hybrid models\nand deep learning models along with various transformations to create\nforecasting pipelines. It then evaluates and ranks pipelines using the proposed\nT-Daub mechanism to choose the best pipeline. The paper describe in detail all\nthe technical aspects of AutoAI-TS along with extensive benchmarking on a\nvariety of real world data sets for various use-cases. Benchmark results show\nthat AutoAI-TS, with no manual configuration from the user, automatically\ntrains and selects pipelines that on average outperform existing\nstate-of-the-art time series forecasting toolkits.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:30:54 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 18:10:12 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Shah", "Syed Yousaf", ""], ["Patel", "Dhaval", ""], ["Vu", "Long", ""], ["Dang", "Xuan-Hong", ""], ["Chen", "Bei", ""], ["Kirchner", "Peter", ""], ["Samulowitz", "Horst", ""], ["Wood", "David", ""], ["Bramble", "Gregory", ""], ["Gifford", "Wesley M.", ""], ["Ganapavarapu", "Giridhar", ""], ["Vaculin", "Roman", ""], ["Zerfos", "Petros", ""]]}, {"id": "2102.12413", "submitter": "Alexander Felfernig", "authors": "A. Felfernig and N. Tintarev and T.N.T. Trang and M. Stettinger", "title": "Designing Explanations for Group Recommender Systems", "comments": "Cite as: A. Felfernig, N. Tintarev, T.N.T. Trang, and M. Stettinger.\n  Explanations for Groups. In A. Felfernig, L. Boratto, M. Stettinger, and M.\n  Tkalcic (Eds.), Group Recommender Systems: An Introduction (pp. 105-126).\n  SpringerBriefs in Electrical and Computer Engineering. Springer, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations are used in recommender systems for various reasons. Users have\nto be supported in making (high-quality) decisions more quickly. Developers of\nrecommender systems want to convince users to purchase specific items. Users\nshould better understand how the recommender system works and why a specific\nitem has been recommended. Users should also develop a more in-depth\nunderstanding of the item domain. Consequently, explanations are designed in\norder to achieve specific \\emph{goals} such as increasing the transparency of a\nrecommendation or increasing a user's trust in the recommender system. In this\npaper, we provide an overview of existing research related to explanations in\nrecommender systems, and specifically discuss aspects relevant to group\nrecommendation scenarios. In this context, we present different ways of\nexplaining and visualizing recommendations determined on the basis of\npreference aggregation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:05:39 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Felfernig", "A.", ""], ["Tintarev", "N.", ""], ["Trang", "T. N. T.", ""], ["Stettinger", "M.", ""]]}, {"id": "2102.12415", "submitter": "Stephanie Allen", "authors": "Stephanie Allen and John P. Dickerson and Steven A. Gabriel", "title": "Using Inverse Optimization to Learn Cost Functions in Generalized Nash\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demonstrated by Ratliff et al. (2014), inverse optimization can be used to\nrecover the objective function parameters of players in multi-player Nash\ngames. These games involve the optimization problems of multiple players in\nwhich the players can affect each other in their objective functions. In\ngeneralized Nash equilibrium problems (GNEPs), a player's set of feasible\nactions is also impacted by the actions taken by other players in the game; see\nFacchinei and Kanzow (2010) for more background on this problem. One example of\nsuch impact comes in the form of joint/\"coupled\" constraints as referenced by\nRosen (1965), Harker (1991), and Facchinei et al. (2007) which involve other\nplayers' variables in the constraints of the feasible region. We extend the\nframework of Ratliff et al. (2014) to find inverse optimization solutions for\nthe class of GNEPs with joint constraints. The resulting formulation is then\napplied to a simulated multi-player transportation problem on a road network.\nAlso, we provide some theoretical results related to this transportation\nproblem regarding runtime of the extended framework as well as uniqueness and\nnon-uniqueness of solutions to our simulation experiments. We see that our\nmodel recovers parameterizations that produce the same flow patterns as the\noriginal parameterizations and that this holds true across multiple networks,\ndifferent assumptions regarding players' perceived costs, and the majority of\nrestrictive capacity settings and the associated numbers of players. Code for\nthe project can be found at: https://github.com/sallen7/IO_GNEP.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:13:27 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Allen", "Stephanie", ""], ["Dickerson", "John P.", ""], ["Gabriel", "Steven A.", ""]]}, {"id": "2102.12432", "submitter": "Keidai Iiyama", "authors": "Keidai Iiyama, Kento Tomita, Bhavi A. Jagatia, Tatsuwaki Nakagawa and\n  Koki Ho", "title": "Deep Reinforcement Learning for Safe Landing Site Selection with\n  Concurrent Consideration of Divert Maneuvers", "comments": "25 pages, 14 figures, This paper is an updated version of Paper AAS\n  20-583 presented at the AAS/AIAA Astrodynamics Specialist Conference, Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This research proposes a new integrated framework for identifying safe\nlanding locations and planning in-flight divert maneuvers. The state-of-the-art\nalgorithms for landing zone selection utilize local terrain features such as\nslopes and roughness to judge the safety and priority of the landing point.\nHowever, when there are additional chances of observation and diverting in the\nfuture, these algorithms are not able to evaluate the safety of the decision\nitself to target the selected landing point considering the overall descent\ntrajectory. In response to this challenge, we propose a reinforcement learning\nframework that optimizes a landing site selection strategy concurrently with a\nguidance and control strategy to the target landing site. The trained agent\ncould evaluate and select landing sites with explicit consideration of the\nterrain features, quality of future observations, and control to achieve a safe\nand efficient landing trajectory at a system-level. The proposed framework was\nable to achieve 94.8 $\\%$ of successful landing in highly challenging landing\nsites where over 80$\\%$ of the area around the initial target lading point is\nhazardous, by effectively updating the target landing site and feedback control\ngain during descent.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:53:10 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Iiyama", "Keidai", ""], ["Tomita", "Kento", ""], ["Jagatia", "Bhavi A.", ""], ["Nakagawa", "Tatsuwaki", ""], ["Ho", "Koki", ""]]}, {"id": "2102.12463", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Seth Cooper", "title": "Generating and Blending Game Levels via Quality-Diversity in the Latent\n  Space of a Variational Autoencoder", "comments": "Accepted to FDG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have demonstrated the use of variational autoencoders (VAEs)\nfor generating levels in the style of existing games and blending levels across\ndifferent games. Further, quality-diversity (QD) algorithms have also become\npopular for generating varied game content by using evolution to explore a\nsearch space while focusing on both variety and quality. To reap the benefits\nof both these approaches, we present a level generation and game blending\napproach that combines the use of VAEs and QD algorithms. Specifically, we\ntrain VAEs on game levels and run the MAP-Elites QD algorithm using the learned\nlatent space of the VAE as the search space. The latent space captures the\nproperties of the games whose levels we want to generate and blend, while\nMAP-Elites searches this latent space to find a diverse set of levels\noptimizing a given objective such as playability. We test our method using\nmodels for 5 different platformer games as well as a blended domain spanning 3\nof these games. We refer to using MAP-Elites for blending as Blend-Elites. Our\nresults show that MAP-Elites in conjunction with VAEs enables the generation of\na diverse set of playable levels not just for each individual game but also for\nthe blended domain while illuminating game-specific regions of the blended\nlatent space.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 18:44:23 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:44:36 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2102.12550", "submitter": "Sheng Li", "authors": "Sheng Li, Yutai Zhou, Ross Allen, Mykel J. Kochenderfer", "title": "Learning Emergent Discrete Message Communication for Cooperative\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a important factor that enables agents work cooperatively in\nmulti-agent reinforcement learning (MARL). Most previous work uses continuous\nmessage communication whose high representational capacity comes at the expense\nof interpretability. Allowing agents to learn their own discrete message\ncommunication protocol emerged from a variety of domains can increase the\ninterpretability for human designers and other agents.This paper proposes a\nmethod to generate discrete messages analogous to human languages, and achieve\ncommunication by a broadcast-and-listen mechanism based on self-attention. We\nshow that discrete message communication has performance comparable to\ncontinuous message communication but with much a much smaller vocabulary\nsize.Furthermore, we propose an approach that allows humans to interactively\nsend discrete messages to agents.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 20:44:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Sheng", ""], ["Zhou", "Yutai", ""], ["Allen", "Ross", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2102.12551", "submitter": "Rolf Morel", "authors": "Rolf Morel, Andrew Cropper", "title": "Learning Logic Programs by Explaining Failures", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists form hypotheses and experimentally test them. If a hypothesis\nfails (is refuted), scientists try to explain the failure to eliminate other\nhypotheses. We introduce similar explanation techniques for inductive logic\nprogramming (ILP). We build on the ILP approach learning from failures. Given a\nhypothesis represented as a logic program, we test it on examples. If a\nhypothesis fails, we identify clauses and literals responsible for the failure.\nBy explaining failures, we can eliminate other hypotheses that will provably\nfail. We introduce a technique for failure explanation based on analysing\nSLD-trees. We experimentally evaluate failure explanation in the Popper ILP\nsystem. Our results show that explaining failures can drastically reduce\nlearning times.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 14:32:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Morel", "Rolf", ""], ["Cropper", "Andrew", ""]]}, {"id": "2102.12553", "submitter": "Rolf Morel", "authors": "Rolf Morel", "title": "Refinement Type Directed Search for Meta-Interpretive-Learning of\n  Higher-Order Logic Programs", "comments": "Oxford 2018 MSc thesis; 82 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The program synthesis problem within the Inductive Logic Programming (ILP)\ncommunity has typically been seen as untyped. We consider the benefits of user\nprovided types on background knowledge. Building on the Meta-Interpretive\nLearning (MIL) framework, we show that type checking is able to prune large\nparts of the hypothesis space of programs. The introduction of polymorphic type\nchecking to the MIL approach to logic program synthesis is validated by strong\ntheoretical and experimental results, showing a cubic reduction in the size of\nthe search space and synthesis time, in terms of the number of typed background\npredicates. Additionally we are able to infer polymorphic types of synthesized\nclauses and of entire programs. The other advancement is in developing an\napproach to leveraging refinement types in ILP. Here we show that further\npruning of the search space can be achieved, though the SMT solving used for\nrefinement type checking comes\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:40:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Morel", "Rolf", ""]]}, {"id": "2102.12560", "submitter": "Angelos Filos", "authors": "Angelos Filos, Clare Lyle, Yarin Gal, Sergey Levine, Natasha Jaques,\n  Gregory Farquhar", "title": "PsiPhi-Learning: Reinforcement Learning with Demonstrations using\n  Successor Features and Inverse Temporal Difference Learning", "comments": "The last two authors contributed equally. Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study reinforcement learning (RL) with no-reward demonstrations, a setting\nin which an RL agent has access to additional data from the interaction of\nother agents with the same environment. However, it has no access to the\nrewards or goals of these agents, and their objectives and levels of expertise\nmay vary widely. These assumptions are common in multi-agent settings, such as\nautonomous driving. To effectively use this data, we turn to the framework of\nsuccessor features. This allows us to disentangle shared features and dynamics\nof the environment from agent-specific rewards and policies. We propose a\nmulti-task inverse reinforcement learning (IRL) algorithm, called \\emph{inverse\ntemporal difference learning} (ITD), that learns shared state features,\nalongside per-agent successor features and preference vectors, purely from\ndemonstrations without reward labels. We further show how to seamlessly\nintegrate ITD with learning from online environment interactions, arriving at a\nnovel algorithm for reinforcement learning with demonstrations, called $\\Psi\n\\Phi$-learning (pronounced `Sci-Fi'). We provide empirical evidence for the\neffectiveness of $\\Psi \\Phi$-learning as a method for improving RL, IRL,\nimitation, and few-shot transfer, and derive worst-case bounds for its\nperformance in zero-shot transfer to new tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:12:09 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 16:13:14 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Filos", "Angelos", ""], ["Lyle", "Clare", ""], ["Gal", "Yarin", ""], ["Levine", "Sergey", ""], ["Jaques", "Natasha", ""], ["Farquhar", "Gregory", ""]]}, {"id": "2102.12564", "submitter": "Javier Alvarez-Jimenez", "authors": "Emmanuel Maqueda, Javier Alvarez-Jimenez, Carlos Mena, Ivan Meza", "title": "Triplet loss based embeddings for forensic speaker identification in\n  Spanish", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of digital technology, it is more common that committed\ncrimes or legal disputes involve some form of speech recording where the\nidentity of a speaker is questioned [1]. In face of this situation, the field\nof forensic speaker identification has been looking to shed light on the\nproblem by quantifying how much a speech recording belongs to a particular\nperson in relation to a population. In this work, we explore the use of speech\nembeddings obtained by training a CNN using the triplet loss. In particular, we\nfocus on the Spanish language which has not been extensively studies. We\npropose extracting the embeddings from speech spectrograms samples, then\nexplore several configurations of such spectrograms, and finally, quantify the\nembeddings quality. We also show some limitations of our data setting which is\npredominantly composed by male speakers. At the end, we propose two approaches\nto calculate the Likelihood Radio given out speech embeddings and we show that\ntriplet loss is a good alternative to create speech embeddings for forensic\nspeaker identification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:24:25 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Maqueda", "Emmanuel", ""], ["Alvarez-Jimenez", "Javier", ""], ["Mena", "Carlos", ""], ["Meza", "Ivan", ""]]}, {"id": "2102.12571", "submitter": "Brandon Araki", "authors": "Brandon Araki, Xiao Li, Kiran Vodrahalli, Jonathan DeCastro, Micah J.\n  Fry, Daniela Rus", "title": "The Logical Options Framework", "comments": "23 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning composable policies for environments with complex rules and tasks is\na challenging problem. We introduce a hierarchical reinforcement learning\nframework called the Logical Options Framework (LOF) that learns policies that\nare satisfying, optimal, and composable. LOF efficiently learns policies that\nsatisfy tasks by representing the task as an automaton and integrating it into\nlearning and planning. We provide and prove conditions under which LOF will\nlearn satisfying, optimal policies. And lastly, we show how LOF's learned\npolicies can be composed to satisfy unseen tasks with only 10-50 retraining\nsteps. We evaluate LOF on four tasks in discrete and continuous domains,\nincluding a 3D pick-and-place environment.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 21:43:16 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Araki", "Brandon", ""], ["Li", "Xiao", ""], ["Vodrahalli", "Kiran", ""], ["DeCastro", "Jonathan", ""], ["Fry", "Micah J.", ""], ["Rus", "Daniela", ""]]}, {"id": "2102.12574", "submitter": "Vicky Mak-Hau", "authors": "Vicky Mak-Hau and John Yearwood and William Moran", "title": "Knowledge engineering mixed-integer linear programming: constraint\n  typology", "comments": "6 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2011.06300", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the constraint typology of mixed-integer linear\nprogramming MILP formulations. MILP is a commonly used mathematical programming\ntechnique for modelling and solving real-life scheduling, routing, planning,\nresource allocation, timetabling optimization problems, providing optimized\nbusiness solutions for industry sectors such as: manufacturing, agriculture,\ndefence, healthcare, medicine, energy, finance, and transportation. Despite the\nnumerous real-life Combinatorial Optimization Problems found and solved, and\nmillions yet to be discovered and formulated, the number of types of\nconstraints, the building blocks of a MILP, is relatively much smaller. In the\nsearch of a suitable machine readable knowledge representation for MILPs, we\npropose an optimization modelling tree built based upon an MILP ontology that\ncan be used as a guidance for automated systems to elicit an MILP model from\nend-users on their combinatorial business optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:07:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mak-Hau", "Vicky", ""], ["Yearwood", "John", ""], ["Moran", "William", ""]]}, {"id": "2102.12575", "submitter": "Yuanpeng He", "authors": "Yuanpeng He", "title": "Ordinal relative belief entropy", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specially customised Entropies are widely applied in measuring the degree of\nuncertainties existing in the frame of discernment. However, all of these\nentropies regard the frame as a whole that has already been determined which\ndose not conform to actual situations. In real life, everything comes in an\norder, so how to measure uncertainties of the dynamic process of determining\nsequence of propositions contained in a frame of discernment is still an open\nissue and no related research has been proceeded. Therefore, a novel ordinal\nentropy to measure uncertainties of the frame of discernment considering the\norder of confirmation of propositions is proposed in this paper. Compared with\ntraditional entropies, it manifests effects on degree of uncertainty brought by\norders of propositions existing in a frame of discernment. Besides, some\nnumerical examples are provided to verify the correctness and validity of the\nproposed entropy in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 04:17:04 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["He", "Yuanpeng", ""]]}, {"id": "2102.12579", "submitter": "Alexander Kulikov", "authors": "Alexander S. Kulikov and Nikita Slezkin", "title": "SAT-based Circuit Local Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Finding exact circuit size is a notorious optimization problem in practice.\nWhereas modern computers and algorithmic techniques allow to find a circuit of\nsize seven in blink of an eye, it may take more than a week to search for a\ncircuit of size thirteen. One of the reasons of this behavior is that the\nsearch space is enormous: the number of circuits of size $s$ is\n$s^{\\Theta(s)}$, the number of Boolean functions on $n$ variables is $2^{2^n}$.\n  In this paper, we explore the following natural heuristic idea for decreasing\nthe size of a given circuit: go through all its subcircuits of moderate size\nand check whether any of them can be improved by reducing to SAT. This may be\nviewed as a local search approach: we search for a smaller circuit in a ball\naround a given circuit. We report the results of experiments with various\nsymmetric functions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:01:50 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kulikov", "Alexander S.", ""], ["Slezkin", "Nikita", ""]]}, {"id": "2102.12593", "submitter": "Bing Li", "authors": "Bing Li, Yuanlue Zhu, Yitong Wang, Chia-Wen Lin, Bernard Ghanem,\n  Linlin Shen", "title": "AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised\n  Anime Face Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework to translate a portrait\nphoto-face into an anime appearance. Our aim is to synthesize anime-faces which\nare style-consistent with a given reference anime-face. However, unlike typical\ntranslation tasks, such anime-face translation is challenging due to complex\nvariations of appearances among anime-faces. Existing methods often fail to\ntransfer the styles of reference anime-faces, or introduce noticeable\nartifacts/distortions in the local shapes of their generated faces. We propose\nAniGAN, a novel GAN-based translator that synthesizes high-quality anime-faces.\nSpecifically, a new generator architecture is proposed to simultaneously\ntransfer color/texture styles and transform local facial shapes into anime-like\ncounterparts based on the style of a reference anime-face, while preserving the\nglobal structure of the source photo-face. We propose a double-branch\ndiscriminator to learn both domain-specific distributions and domain-shared\ndistributions, helping generate visually pleasing anime-faces and effectively\nmitigate artifacts. Extensive experiments on selfie2anime and a new face2anime\ndataset qualitatively and quantitatively demonstrate the superiority of our\nmethod over state-of-the-art methods. The new dataset is available at\nhttps://github.com/bing-li-ai/AniGAN .\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 22:47:38 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 11:30:50 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Li", "Bing", ""], ["Zhu", "Yuanlue", ""], ["Wang", "Yitong", ""], ["Lin", "Chia-Wen", ""], ["Ghanem", "Bernard", ""], ["Shen", "Linlin", ""]]}, {"id": "2102.12594", "submitter": "Angelina Wang", "authors": "Angelina Wang and Olga Russakovsky", "title": "Directional Bias Amplification", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mitigating bias in machine learning systems requires refining our\nunderstanding of bias propagation pathways: from societal structures to\nlarge-scale data to trained models to impact on society. In this work, we focus\non one aspect of the problem, namely bias amplification: the tendency of models\nto amplify the biases present in the data they are trained on. A metric for\nmeasuring bias amplification was introduced in the seminal work by Zhao et al.\n(2017); however, as we demonstrate, this metric suffers from a number of\nshortcomings including conflating different types of bias amplification and\nfailing to account for varying base rates of protected attributes. We introduce\nand analyze a new, decoupled metric for measuring bias amplification,\n$\\text{BiasAmp}_{\\rightarrow}$ (Directional Bias Amplification). We thoroughly\nanalyze and discuss both the technical assumptions and normative implications\nof this metric. We provide suggestions about its measurement by cautioning\nagainst predicting sensitive attributes, encouraging the use of confidence\nintervals due to fluctuations in the fairness of models across runs, and\ndiscussing the limitations of what this metric captures. Throughout this paper,\nwe work to provide an interrogative look at the technical measurement of bias\namplification, guided by our normative ideas of what we want it to encompass.\nCode is located at https://github.com/princetonvisualai/directional-bias-amp\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 22:54:21 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 23:50:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Angelina", ""], ["Russakovsky", "Olga", ""]]}, {"id": "2102.12616", "submitter": "Nicholas Watters", "authors": "Nicholas Watters and Joshua Tenenbaum and Mehrdad Jazayeri", "title": "Modular Object-Oriented Games: A Task Framework for Reinforcement\n  Learning, Psychology, and Neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, trends towards studying simulated games have gained momentum\nin the fields of artificial intelligence, cognitive science, psychology, and\nneuroscience. The intersections of these fields have also grown recently, as\nresearchers increasing study such games using both artificial agents and human\nor animal subjects. However, implementing games can be a time-consuming\nendeavor and may require a researcher to grapple with complex codebases that\nare not easily customized. Furthermore, interdisciplinary researchers studying\nsome combination of artificial intelligence, human psychology, and animal\nneurophysiology face additional challenges, because existing platforms are\ndesigned for only one of these domains. Here we introduce Modular\nObject-Oriented Games, a Python task framework that is lightweight, flexible,\ncustomizable, and designed for use by machine learning, psychology, and\nneurophysiology researchers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 01:17:03 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Watters", "Nicholas", ""], ["Tenenbaum", "Joshua", ""], ["Jazayeri", "Mehrdad", ""]]}, {"id": "2102.12648", "submitter": "Yuanqing Wang", "authors": "Yuanqing Wang, Theofanis Karaletsos", "title": "Stochastic Aggregation in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) manifest pathologies including over-smoothing\nand limited discriminating power as a result of suboptimally expressive\naggregating mechanisms. We herein present a unifying framework for stochastic\naggregation (STAG) in GNNs, where noise is (adaptively) injected into the\naggregation process from the neighborhood to form node embeddings. We provide\ntheoretical arguments that STAG models, with little overhead, remedy both of\nthe aforementioned problems. In addition to fixed-noise models, we also propose\nprobabilistic versions of STAG models and a variational inference framework to\nlearn the noise posterior. We conduct illustrative experiments clearly\ntargeting oversmoothing and multiset aggregation limitations. Furthermore, STAG\nenhances general performance of GNNs demonstrated by competitive performance in\ncommon citation and molecule graph benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 02:52:03 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:46:00 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Yuanqing", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "2102.12668", "submitter": "Hiroyasu Tsukamoto", "authors": "Hiroyasu Tsukamoto and Soon-Jo Chung", "title": "Learning-based Robust Motion Planning with Guaranteed Stability: A\n  Contraction Theory Approach", "comments": "IEEE Robotics and Automation Letters (RA-L), Accepted June 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Learning-based Autonomous Guidance with RObustness and\nStability guarantees (LAG-ROS), which provides machine learning-based nonlinear\nmotion planners with formal robustness and stability guarantees, by designing a\ndifferential Lyapunov function using contraction theory. LAG-ROS utilizes a\nneural network to model a robust tracking controller independently of a target\ntrajectory, for which we show that the Euclidean distance between the target\nand controlled trajectories is exponentially bounded linearly in the learning\nerror, even under the existence of bounded external disturbances. We also\npresent a convex optimization approach that minimizes the steady-state bound of\nthe tracking error to construct the robust control law for neural network\ntraining. In numerical simulations, it is demonstrated that the proposed method\nindeed possesses superior properties of robustness and nonlinear stability\nresulting from contraction theory, whilst retaining the computational\nefficiency of existing learning-based motion planners.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 03:47:15 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 22:56:18 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 19:26:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Tsukamoto", "Hiroyasu", ""], ["Chung", "Soon-Jo", ""]]}, {"id": "2102.12671", "submitter": "Boer Lyu", "authors": "Boer Lyu, Lu Chen, Su Zhu, Kai Yu", "title": "LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short\n  Text Matching", "comments": "Accepted by AAAI 2021; 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese short text matching is a fundamental task in natural language\nprocessing. Existing approaches usually take Chinese characters or words as\ninput tokens. They have two limitations: 1) Some Chinese words are polysemous,\nand semantic information is not fully utilized. 2) Some models suffer potential\nissues caused by word segmentation. Here we introduce HowNet as an external\nknowledge base and propose a Linguistic knowledge Enhanced graph Transformer\n(LET) to deal with word ambiguity. Additionally, we adopt the word lattice\ngraph as input to maintain multi-granularity information. Our model is also\ncomplementary to pre-trained language models. Experimental results on two\nChinese datasets show that our models outperform various typical text matching\napproaches. Ablation study also indicates that both semantic information and\nmulti-granularity information are important for text matching modeling.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 04:01:51 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Lyu", "Boer", ""], ["Chen", "Lu", ""], ["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "2102.12702", "submitter": "Guolin Ke", "authors": "Chengxuan Ying, Guolin Ke, Di He, Tie-Yan Liu", "title": "LazyFormer: Self Attention with Lazy Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Improving the efficiency of Transformer-based language pre-training is an\nimportant task in NLP, especially for the self-attention module, which is\ncomputationally expensive. In this paper, we propose a simple but effective\nsolution, called \\emph{LazyFormer}, which computes the self-attention\ndistribution infrequently. LazyFormer composes of multiple lazy blocks, each of\nwhich contains multiple Transformer layers. In each lazy block, the\nself-attention distribution is only computed once in the first layer and then\nis reused in all upper layers. In this way, the cost of computation could be\nlargely saved. We also provide several training tricks for LazyFormer.\nExtensive experiments demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 06:18:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ying", "Chengxuan", ""], ["Ke", "Guolin", ""], ["He", "Di", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2102.12722", "submitter": "Jing Dong", "authors": "Jing Dong, Ke Li, Shuai Li, Baoxiang Wang", "title": "Combinatorial Bandits under Strategic Manipulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of combinatorial multi-armed bandits (CMAB) under\nstrategic manipulations of rewards, where each arm can modify the emitted\nreward signals for its own interest. Our setting elaborates a more realistic\nmodel of adaptive arms that imposes relaxed assumptions compared to adversarial\ncorruptions and adversarial attacks. Algorithms designed under strategic arms\ngain robustness in real applications while avoiding being overcautious and\nhampering the performance. We bridge the gap between strategic manipulations\nand adversarial attacks by investigating the optimal colluding strategy among\narms under the MAB problem. We then propose a strategic variant of the\ncombinatorial UCB algorithm, which has a regret of at most $O(m\\log T + m\nB_{max})$ under strategic manipulations, where $T$ is the time horizon, $m$ is\nthe number of arms, and $B_{max}$ is the maximum budget. We further provide\nlower bounds on the strategic budgets for attackers to incur certain regret of\nthe bandit algorithm. Extensive experiments corroborate our theoretical\nfindings on robustness and regret bounds, in a variety of regimes of\nmanipulation budgets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 07:57:27 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Dong", "Jing", ""], ["Li", "Ke", ""], ["Li", "Shuai", ""], ["Wang", "Baoxiang", ""]]}, {"id": "2102.12723", "submitter": "Dmitry Ignatov", "authors": "L\\'eonard Kwuida and Dmitry I. Ignatov", "title": "On Interpretability and Similarity in Concept-Based Machine Learning", "comments": "Invited Talk at AIST 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM math.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) provides important techniques for classification and\npredictions. Most of these are black-box models for users and do not provide\ndecision-makers with an explanation. For the sake of transparency or more\nvalidity of decisions, the need to develop explainable/interpretable ML-methods\nis gaining more and more importance. Certain questions need to be addressed:\n  How does an ML procedure derive the class for a particular entity? Why does a\nparticular clustering emerge from a particular unsupervised ML procedure? What\ncan we do if the number of attributes is very large? What are the possible\nreasons for the mistakes for concrete cases and models?\n  For binary attributes, Formal Concept Analysis (FCA) offers techniques in\nterms of intents of formal concepts, and thus provides plausible reasons for\nmodel prediction. However, from the interpretable machine learning viewpoint,\nwe still need to provide decision-makers with the importance of individual\nattributes to the classification of a particular object, which may facilitate\nexplanations by experts in various domains with high-cost errors like medicine\nor finance.\n  We discuss how notions from cooperative game theory can be used to assess the\ncontribution of individual attributes in classification and clustering\nprocesses in concept-based machine learning. To address the 3rd question, we\npresent some ideas on how to reduce the number of attributes using similarities\nin large contexts.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 07:57:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kwuida", "L\u00e9onard", ""], ["Ignatov", "Dmitry I.", ""]]}, {"id": "2102.12746", "submitter": "Konstantinos Demertzis", "authors": "Konstantinos Demertzis", "title": "Blockchained Federated Learning for Threat Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing complexity of threats in smart cities, the changing\nenvironment, and the weakness of traditional security systems, which in most\ncases fail to detect serious threats such as zero-day attacks, the need for\nalternative more active and more effective security methods keeps increasing.\nSuch approaches are the adoption of intelligent solutions to prevent, detect\nand deal with threats or anomalies under the conditions and the operating\nparameters of the infrastructure in question. This research paper introduces\nthe development of an intelligent Threat Defense system, employing Blockchain\nFederated Learning, which seeks to fully upgrade the way passive intelligent\nsystems operate, aiming at implementing an Advanced Adaptive Cooperative\nLearning (AACL) mechanism for smart cities networks. The AACL is based on the\nmost advanced methods of computational intelligence while ensuring privacy and\nanonymity for participants and stakeholders. The proposed framework combines\nFederated Learning for the distributed and continuously validated learning of\nthe tracing algorithms. Learning is achieved through encrypted smart contracts\nwithin the blockchain technology, for unambiguous validation and control of the\nprocess. The aim of the proposed Framework is to intelligently classify smart\ncities networks traffic derived from Industrial IoT (IIoT) by Deep Content\nInspection (DCI) methods, in order to identify anomalies that are usually due\nto Advanced Persistent Threat (APT) attacks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:16:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Demertzis", "Konstantinos", ""]]}, {"id": "2102.12756", "submitter": "Edgar Beck M.Sc.", "authors": "Edgar Beck, Carsten Bockelmann and Armin Dekorsy", "title": "Learning a Probabilistic Relaxation of Discrete Variables for Soft\n  Detection with Low Complexity: CMDNet", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the great success of Machine Learning (ML), especially Deep Neural\nNetworks (DNNs), in many research domains in 2010s, several ML-based approaches\nwere proposed for detection in large inverse linear problems, e.g., massive\nMIMO systems. The main motivation behind is that the complexity of Maximum\nA-Posteriori (MAP) detection grows exponentially with system dimensions.\nInstead of using DNNs, essentially being a black-box, we take a slightly\ndifferent approach and introduce a probabilistic Continuous relaxation of\ndisCrete variables to MAP detection. Enabling close approximation and\ncontinuous optimization, we derive an iterative detection algorithm: Concrete\nMAP Detection (CMD). Furthermore, extending CMD by the idea of deep unfolding\ninto CMDNet, we allow for (online) optimization of a small number of parameters\nto different working points while limiting complexity. In contrast to recent\nDNN-based approaches, we select the optimization criterion and output of CMDNet\nbased on information theory and are thus able to learn approximate\nprobabilities of the individual optimal detector. This is crucial for soft\ndecoding in today's communication systems. Numerical simulation results in MIMO\nsystems reveal CMDNet to feature a promising accuracy complexity trade-off\ncompared to State of the Art. Notably, we demonstrate CMDNet's soft outputs to\nbe reliable for decoders.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:54:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 13:01:07 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Beck", "Edgar", ""], ["Bockelmann", "Carsten", ""], ["Dekorsy", "Armin", ""]]}, {"id": "2102.12773", "submitter": "Fengshi Tian Clarence", "authors": "Fengshi Tian, Jie Yang, Shiqi Zhao, Mohamad Sawan", "title": "A New Neuromorphic Computing Approach for Epileptic Seizure Prediction", "comments": "Accepted to 2021 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": "2021 IEEE International Symposium on Circuits and Systems (ISCAS)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several high specificity and sensitivity seizure prediction methods with\nconvolutional neural networks (CNNs) are reported. However, CNNs are\ncomputationally expensive and power hungry. These inconveniences make CNN-based\nmethods hard to be implemented on wearable devices. Motivated by the\nenergy-efficient spiking neural networks (SNNs), a neuromorphic computing\napproach for seizure prediction is proposed in this work. This approach uses a\ndesigned gaussian random discrete encoder to generate spike sequences from the\nEEG samples and make predictions in a spiking convolutional neural network\n(Spiking-CNN) which combines the advantages of CNNs and SNNs. The experimental\nresults show that the sensitivity, specificity and AUC can remain 95.1%, 99.2%\nand 0.912 respectively while the computation complexity is reduced by 98.58%\ncompared to CNN, indicating that the proposed Spiking-CNN is hardware friendly\nand of high precision.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:39:18 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Tian", "Fengshi", ""], ["Yang", "Jie", ""], ["Zhao", "Shiqi", ""], ["Sawan", "Mohamad", ""]]}, {"id": "2102.12781", "submitter": "Harshay Shah", "authors": "Harshay Shah, Prateek Jain, Praneeth Netrapalli", "title": "Do Input Gradients Highlight Discriminative Features?", "comments": "Code: https://github.com/harshays/inputgradients", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Post-hoc gradient-based interpretability methods [Simonyan et al., 2013,\nSmilkov et al., 2017] that provide instance-specific explanations of model\npredictions are often based on assumption (A): magnitude of input gradients --\ngradients of logits with respect to input -- noisily highlight discriminative\ntask-relevant features. In this work, we test the validity of assumption (A)\nusing a three-pronged approach. First, we develop an evaluation framework,\nDiffROAR, to test assumption (A) on four image classification benchmarks. Our\nresults suggest that (i) input gradients of standard models (i.e., trained on\noriginal data) may grossly violate (A), whereas (ii) input gradients of\nadversarially robust models satisfy (A). Second, we then introduce BlockMNIST,\nan MNIST-based semi-real dataset, that by design encodes a priori knowledge of\ndiscriminative features. Our analysis on BlockMNIST leverages this information\nto validate as well as characterize differences between input gradient\nattributions of standard and robust models. Finally, we theoretically prove\nthat our empirical findings hold on a simplified version of the BlockMNIST\ndataset. Specifically, we prove that input gradients of standard\none-hidden-layer MLPs trained on this dataset do not highlight\ninstance-specific signal coordinates, thus grossly violating assumption (A).\nOur findings motivate the need to formalize and test common assumptions in\ninterpretability in a falsifiable manner [Leavitt and Morcos, 2020].\nAdditionally, we believe that the DiffROAR evaluation framework and\nBlockMNIST-based datasets can serve as sanity checks to audit instance-specific\ninterpretability methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:04:38 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 15:30:11 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shah", "Harshay", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "2102.12828", "submitter": "Ningyu Zhang", "authors": "Xin Xie, Xiangnan Chen, Xiang Chen, Yong Wang, Ningyu Zhang, Shumin\n  Deng, Huajun Chen", "title": "ZJUKLAB at SemEval-2021 Task 4: Negative Augmentation with Language\n  Model for Reading Comprehension of Abstract Meaning", "comments": "Accepted by SemEval-2021 Workshop, ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our systems for the three Subtasks of SemEval Task4:\nReading Comprehension of Abstract Meaning (ReCAM). We explain the algorithms\nused to learn our models and the process of tuning the algorithms and selecting\nthe best model. Inspired by the similarity of the ReCAM task and the language\npre-training, we propose a simple yet effective technology, namely, negative\naugmentation with language model. Evaluation results demonstrate the\neffectiveness of our proposed approach. Our models achieve the 4th rank on both\nofficial test sets of Subtask 1 and Subtask 2 with an accuracy of 87.9% and an\naccuracy of 92.8%, respectively. We further conduct comprehensive model\nanalysis and observe interesting error cases, which may promote future\nresearches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:03:05 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 07:31:42 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 10:12:26 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Xie", "Xin", ""], ["Chen", "Xiangnan", ""], ["Chen", "Xiang", ""], ["Wang", "Yong", ""], ["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Chen", "Huajun", ""]]}, {"id": "2102.12843", "submitter": "Asier Guti\\'errez-Fandi\\~no", "authors": "Asier Guti\\'errez-Fandi\\~no, Jordi Armengol-Estap\\'e, Casimiro Pio\n  Carrino, Ona De Gibert, Aitor Gonzalez-Agirre, Marta Villegas", "title": "Spanish Biomedical and Clinical Language Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We computed both Word and Sub-word Embeddings using FastText. For Sub-word\nembeddings we selected Byte Pair Encoding (BPE) algorithm to represent the\nsub-words. We evaluated the Biomedical Word Embeddings obtaining better results\nthan previous versions showing the implication that with more data, we obtain\nbetter representations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:30:04 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Guti\u00e9rrez-Fandi\u00f1o", "Asier", ""], ["Armengol-Estap\u00e9", "Jordi", ""], ["Carrino", "Casimiro Pio", ""], ["De Gibert", "Ona", ""], ["Gonzalez-Agirre", "Aitor", ""], ["Villegas", "Marta", ""]]}, {"id": "2102.12846", "submitter": "Dimitri Kartsaklis", "authors": "Robin Lorenz, Anna Pearson, Konstantinos Meichanetzidis, Dimitri\n  Kartsaklis, Bob Coecke", "title": "QNLP in Practice: Running Compositional Models of Meaning on a Quantum\n  Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Natural Language Processing (QNLP) deals with the design and\nimplementation of NLP models intended to be run on quantum hardware. In this\npaper, we present results on the first NLP experiments conducted on Noisy\nIntermediate-Scale Quantum (NISQ) computers for datasets of size >= 100\nsentences. Exploiting the formal similarity of the compositional model of\nmeaning by Coecke et al. (2010) with quantum theory, we create representations\nfor sentences that have a natural mapping to quantum circuits. We use these\nrepresentations to implement and successfully train two NLP models that solve\nsimple sentence classification tasks on quantum hardware. We describe in detail\nthe main principles, the process and challenges of these experiments, in a way\naccessible to NLP researchers, thus paving the way for practical Quantum\nNatural Language Processing.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:37:33 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Lorenz", "Robin", ""], ["Pearson", "Anna", ""], ["Meichanetzidis", "Konstantinos", ""], ["Kartsaklis", "Dimitri", ""], ["Coecke", "Bob", ""]]}, {"id": "2102.12853", "submitter": "M. Alex O. Vasilescu", "authors": "M. Alex O. Vasilescu, Eric Kim, and Xiao S. Zeng", "title": "CausalX: Causal Explanations and Block Multilinear Factor Analysis", "comments": "arXiv admin note: text overlap with arXiv:1911.04180", "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR),\n  Milan, Italy, pp. 10736-10743", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By adhering to the dictum, \"No causation without manipulation (treatment,\nintervention)\", cause and effect data analysis represents changes in observed\ndata in terms of changes in the causal factors. When causal factors are not\namenable for active manipulation in the real world due to current technological\nlimitations or ethical considerations, a counterfactual approach performs an\nintervention on the model of data formation. In the case of object\nrepresentation or activity (temporal object) representation, varying object\nparts is generally unfeasible whether they be spatial and/or temporal.\nMultilinear algebra, the algebra of higher-order tensors, is a suitable and\ntransparent framework for disentangling the causal factors of data formation.\nLearning a part-based intrinsic causal factor representations in a multilinear\nframework requires applying a set of interventions on a part-based multilinear\nmodel. We propose a unified multilinear model of wholes and parts. We derive a\nhierarchical block multilinear factorization, the M-mode Block SVD, that\ncomputes a disentangled representation of the causal factors by optimizing\nsimultaneously across the entire object hierarchy. Given computational\nefficiency considerations, we introduce an incremental bottom-up computational\nalternative, the Incremental M-mode Block SVD, that employs the lower-level\nabstractions, the part representations, to represent the higher level of\nabstractions, the parent wholes. This incremental computational approach may\nalso be employed to update the causal model parameters when data becomes\navailable incrementally. The resulting object representation is an\ninterpretable combinatorial choice of intrinsic causal factor representations\nrelated to an object's recursive hierarchy of wholes and parts that renders\nobject recognition robust to occlusion and reduces training data requirements.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:49:01 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 12:03:44 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vasilescu", "M. Alex O.", ""], ["Kim", "Eric", ""], ["Zeng", "Xiao S.", ""]]}, {"id": "2102.12855", "submitter": "Mingyu Cai", "authors": "Mingyu Cai, Mohammadhosein Hasanbeig, Shaoping Xiao, Alessandro Abate\n  and Zhen Kan", "title": "Modular Deep Reinforcement Learning for Continuous Motion Planning with\n  Temporal Logic", "comments": "arXiv admin note: text overlap with arXiv:2010.06797", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the motion planning of autonomous dynamical systems\nmodeled by Markov decision processes (MDP) with unknown transition\nprobabilities over continuous state and action spaces. Linear temporal logic\n(LTL) is used to specify high-level tasks over infinite horizon, which can be\nconverted into a limit deterministic generalized B\\\"uchi automaton (LDGBA) with\nseveral accepting sets. The novelty is to design an embedded product MDP\n(EP-MDP) between the LDGBA and the MDP by incorporating a synchronous\ntracking-frontier function to record unvisited accepting sets of the automaton,\nand to facilitate the satisfaction of the accepting conditions. The proposed\nLDGBA-based reward shaping and discounting schemes for the model-free\nreinforcement learning (RL) only depend on the EP-MDP states and can overcome\nthe issues of sparse rewards. Rigorous analysis shows that any RL method that\noptimizes the expected discounted return is guaranteed to find an optimal\npolicy whose traces maximize the satisfaction probability. A modular deep\ndeterministic policy gradient (DDPG) is then developed to generate such\npolicies over continuous state and action spaces. The performance of our\nframework is evaluated via an array of OpenAI gym environments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:11:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 18:52:06 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 16:26:14 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cai", "Mingyu", ""], ["Hasanbeig", "Mohammadhosein", ""], ["Xiao", "Shaoping", ""], ["Abate", "Alessandro", ""], ["Kan", "Zhen", ""]]}, {"id": "2102.12894", "submitter": "Sara Sangalli", "authors": "Sara Sangalli, Ertunc Erdil, Andreas Hoetker, Olivio Donati, Ender\n  Konukoglu", "title": "Constrained Optimization to Train Neural Networks on Critical and\n  Under-Represented Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are notorious for making more mistakes for the\nclasses that have substantially fewer samples than the others during training.\nSuch class imbalance is ubiquitous in clinical applications and very crucial to\nhandle because the classes with fewer samples most often correspond to critical\ncases (e.g., cancer) where misclassifications can have severe consequences. Not\nto miss such cases, binary classifiers need to be operated at high True\nPositive Rates (TPR) by setting a higher threshold but this comes at the cost\nof very high False Positive Rates (FPR) for problems with class imbalance.\nExisting methods for learning under class imbalance most often do not take this\ninto account. We argue that prediction accuracy should be improved by\nemphasizing reducing FPRs at high TPRs for problems where misclassification of\nthe positive, i.e., critical, class samples are associated with higher cost. To\nthis end, we pose the training of a DNN for binary classification as a\nconstrained optimization problem and introduce a novel constraint that can be\nused with existing loss functions to enforce maximal area under the ROC curve\n(AUC) through prioritizing FPR reduction at high TPR. We solve the resulting\nconstrained optimization problem using an Augmented Lagrangian method (ALM).\nGoing beyond binary, we also propose two possible extensions of the proposed\nconstraint for multi-class classification problems. We present experimental\nresults for image-based binary and multi-class classification applications\nusing an in-house medical imaging dataset, CIFAR10, and CIFAR100. Our results\ndemonstrate that the proposed method improves the baselines in majority of the\ncases by attaining higher accuracy on critical classes while reducing the\nmisclassification rate for the non-critical class samples.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:49:36 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 15:58:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sangalli", "Sara", ""], ["Erdil", "Ertunc", ""], ["Hoetker", "Andreas", ""], ["Donati", "Olivio", ""], ["Konukoglu", "Ender", ""]]}, {"id": "2102.12924", "submitter": "Joery De Vries", "authors": "Joery A. de Vries, Ken S. Voskuil, Thomas M. Moerland and Aske Plaat", "title": "Visualizing MuZero Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MuZero, a model-based reinforcement learning algorithm that uses a value\nequivalent dynamics model, achieved state-of-the-art performance in Chess,\nShogi and the game of Go. In contrast to standard forward dynamics models that\npredict a full next state, value equivalent models are trained to predict a\nfuture value, thereby emphasizing value relevant information in the\nrepresentations. While value equivalent models have shown strong empirical\nsuccess, there is no research yet that visualizes and investigates what types\nof representations these models actually learn. Therefore, in this paper we\nvisualize the latent representation of MuZero agents. We find that action\ntrajectories may diverge between observation embeddings and internal state\ntransition dynamics, which could lead to instability during planning. Based on\nthis insight, we propose two regularization techniques to stabilize MuZero's\nperformance. Additionally, we provide an open-source implementation of MuZero\nalong with an interactive visualizer of learned representations, which may aid\nfurther investigation of value equivalent algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:25:17 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 12:25:28 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["de Vries", "Joery A.", ""], ["Voskuil", "Ken S.", ""], ["Moerland", "Thomas M.", ""], ["Plaat", "Aske", ""]]}, {"id": "2102.12957", "submitter": "Jianzhun Shao", "authors": "Jianzhun Shao, Hongchang Zhang, Yuhang Jiang, Shuncheng He, Xiangyang\n  Ji", "title": "Credit Assignment with Meta-Policy Gradient for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward decomposition is a critical problem in centralized training with\ndecentralized execution~(CTDE) paradigm for multi-agent reinforcement learning.\nTo take full advantage of global information, which exploits the states from\nall agents and the related environment for decomposing Q values into individual\ncredits, we propose a general meta-learning-based Mixing Network with Meta\nPolicy Gradient~(MNMPG) framework to distill the global hierarchy for delicate\nreward decomposition. The excitation signal for learning global hierarchy is\ndeduced from the episode reward difference between before and after \"exercise\nupdates\" through the utility network. Our method is generally applicable to the\nCTDE method using a monotonic mixing network. Experiments on the StarCraft II\nmicromanagement benchmark demonstrate that our method just with a simple\nutility network is able to outperform the current state-of-the-art MARL\nalgorithms on 4 of 5 super hard scenarios. Better performance can be further\nachieved when combined with a role-based utility network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:03:37 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Shao", "Jianzhun", ""], ["Zhang", "Hongchang", ""], ["Jiang", "Yuhang", ""], ["He", "Shuncheng", ""], ["Ji", "Xiangyang", ""]]}, {"id": "2102.12962", "submitter": "Rui Yang", "authors": "Rui Yang, Jiafei Lyu, Yu Yang, Jiangpeng Ya, Feng Luo, Dijun Luo,\n  Lanqing Li, Xiu Li", "title": "Bias-reduced Multi-step Hindsight Experience Replay for Efficient\n  Multi-goal Reinforcement Learning", "comments": "20pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-goal reinforcement learning is widely applied in planning and robot\nmanipulation. Two main challenges in multi-goal reinforcement learning are\nsparse rewards and sample inefficiency. Hindsight Experience Replay (HER) aims\nto tackle the two challenges via goal relabeling. However, HER-related works\nstill need millions of samples and a huge computation. In this paper, we\npropose Multi-step Hindsight Experience Replay (MHER), incorporating multi-step\nrelabeled returns based on $n$-step relabeling to improve sample efficiency.\nDespite the advantages of $n$-step relabeling, we theoretically and\nexperimentally prove the off-policy $n$-step bias introduced by $n$-step\nrelabeling may lead to poor performance in many environments. To address the\nabove issue, two bias-reduced MHER algorithms, MHER($\\lambda$) and Model-based\nMHER (MMHER) are presented. MHER($\\lambda$) exploits the $\\lambda$ return while\nMMHER benefits from model-based value expansions. Experimental results on\nnumerous multi-goal robotic tasks show that our solutions can successfully\nalleviate off-policy $n$-step bias and achieve significantly higher sample\nefficiency than HER and Curriculum-guided HER with little additional\ncomputation beyond HER.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:05:57 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 04:55:42 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Yang", "Rui", ""], ["Lyu", "Jiafei", ""], ["Yang", "Yu", ""], ["Ya", "Jiangpeng", ""], ["Luo", "Feng", ""], ["Luo", "Dijun", ""], ["Li", "Lanqing", ""], ["Li", "Xiu", ""]]}, {"id": "2102.12980", "submitter": "Ali Shafti", "authors": "Ali Shafti and A. Aldo Faisal", "title": "Non-invasive Cognitive-level Human Interfacing for the Robotic\n  Restoration of Reaching & Grasping", "comments": "Manuscript accepted at IEEE EMBS Neural Engineering 2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive and Wearable Robotics have the potential to support humans with\ndifferent types of motor impairments to become independent and fulfil their\nactivities of daily living successfully. The success of these robot systems,\nhowever, relies on the ability to meaningfully decode human action intentions\nand carry them out appropriately. Neural interfaces have been explored for use\nin such system with several successes, however, they tend to be invasive and\nrequire training periods in the order of months. We present a robotic system\nfor human augmentation, capable of actuating the user's arm and fingers for\nthem, effectively restoring the capability of reaching, grasping and\nmanipulating objects; controlled solely through the user's eye movements. We\ncombine wearable eye tracking, the visual context of the environment and the\nstructural grammar of human actions to create a cognitive-level assistive\nrobotic setup that enables the users in fulfilling activities of daily living,\nwhile conserving interpretability, and the agency of the user. The interface is\nworn, calibrated and ready to use within 5 minutes. Users learn to control and\nmake successful use of the system with an additional 5 minutes of interaction.\nThe system is tested with 5 healthy participants, showing an average success\nrate of $96.6\\%$ on first attempt across 6 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:32:04 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "2102.12982", "submitter": "Nils Rethmeier", "authors": "Nils Rethmeier and Isabelle Augenstein", "title": "A Primer on Contrastive Pretraining in Language Processing: Methods,\n  Lessons Learned and Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern natural language processing (NLP) methods employ self-supervised\npretraining objectives such as masked language modeling to boost the\nperformance of various application tasks. These pretraining methods are\nfrequently extended with recurrence, adversarial or linguistic property\nmasking, and more recently with contrastive learning objectives. Contrastive\nself-supervised training objectives enabled recent successes in image\nrepresentation pretraining by learning to contrast input-input pairs of\naugmented images as either similar or dissimilar. However, in NLP, automated\ncreation of text input augmentations is still very challenging because a single\ntoken can invert the meaning of a sentence. For this reason, some contrastive\nNLP pretraining methods contrast over input-label pairs, rather than over\ninput-input pairs, using methods from Metric Learning and Energy Based Models.\nIn this survey, we summarize recent self-supervised and supervised contrastive\nNLP pretraining methods and describe where they are used to improve language\nmodeling, few or zero-shot learning, pretraining data-efficiency and specific\nNLP end-tasks. We introduce key contrastive learning concepts with lessons\nlearned from prior research and structure works by applications and cross-field\nrelations. Finally, we point to open challenges and future directions for\ncontrastive NLP to encourage bringing contrastive NLP pretraining closer to\nrecent successes in image representation pretraining.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:35:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Rethmeier", "Nils", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2102.13003", "submitter": "Claire Birnie PhD", "authors": "Claire Birnie, Haithem Jarraya and Fredrik Hansteen", "title": "An introduction to distributed training of deep neural networks for\n  segmentation tasks with large seismic datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning applications are drastically progressing in seismic processing\nand interpretation tasks. However, the majority of approaches subsample data\nvolumes and restrict model sizes to minimise computational requirements.\nSubsampling the data risks losing vital spatio-temporal information which could\naid training whilst restricting model sizes can impact model performance, or in\nsome extreme cases, renders more complicated tasks such as segmentation\nimpossible. This paper illustrates how to tackle the two main issues of\ntraining of large neural networks: memory limitations and impracticably large\ntraining times. Typically, training data is preloaded into memory prior to\ntraining, a particular challenge for seismic applications where data is\ntypically four times larger than that used for standard image processing tasks\n(float32 vs. uint8). Using a microseismic use case, we illustrate how over\n750GB of data can be used to train a model by using a data generator approach\nwhich only stores in memory the data required for that training batch.\nFurthermore, efficient training over large models is illustrated through the\ntraining of a 7-layer UNet with input data dimensions of 4096X4096. Through a\nbatch-splitting distributed training approach, training times are reduced by a\nfactor of four. The combination of data generators and distributed training\nremoves any necessity of data 1 subsampling or restriction of neural network\nsizes, offering the opportunity of utilisation of larger networks,\nhigher-resolution input data or moving from 2D to 3D problem spaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:06:00 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Birnie", "Claire", ""], ["Jarraya", "Haithem", ""], ["Hansteen", "Fredrik", ""]]}, {"id": "2102.13019", "submitter": "Rodrigo Nogueira", "authors": "Rodrigo Nogueira, Zhiying Jiang, Jimmy Lin", "title": "Investigating the Limitations of Transformers with Simple Arithmetic\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform arithmetic tasks is a remarkable trait of human\nintelligence and might form a critical component of more complex reasoning\ntasks. In this work, we investigate if the surface form of a number has any\ninfluence on how sequence-to-sequence language models learn simple arithmetic\ntasks such as addition and subtraction across a wide range of values. We find\nthat how a number is represented in its surface form has a strong influence on\nthe model's accuracy. In particular, the model fails to learn addition of\nfive-digit numbers when using subwords (e.g., \"32\"), and it struggles to learn\nwith character-level representations (e.g., \"3 2\"). By introducing position\ntokens (e.g., \"3 10e1 2\"), the model learns to accurately add and subtract\nnumbers up to 60 digits. We conclude that modern pretrained language models can\neasily learn arithmetic from very few examples, as long as we use the proper\nsurface representation. This result bolsters evidence that subword tokenizers\nand positional encodings are components in current transformer designs that\nmight need improvement. Moreover, we show that regardless of the number of\nparameters and training examples, models cannot learn addition rules that are\nindependent of the length of the numbers seen during training. Code to\nreproduce our experiments is available at\nhttps://github.com/castorini/transformers-arithmetic\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:22:53 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 15:54:38 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 19:58:27 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Nogueira", "Rodrigo", ""], ["Jiang", "Zhiying", ""], ["Lin", "Jimmy", ""]]}, {"id": "2102.13034", "submitter": "Yuan Shen", "authors": "Yuan Shen, Niviru Wijayaratne, Peter Du, Shanduojiao Jiang, Katherine\n  Driggs Campbell", "title": "AutoPreview: A Framework for Autopilot Behavior Understanding", "comments": "7 pages, 5 figures, CHI 2021 Late breaking Work", "journal-ref": "CHI Conference on Human Factors in Computing Systems Extended\n  Abstracts (CHI '21 Extended Abstracts), May 8 to 13, 2021, Yokohama, Japan", "doi": "10.1145/3411763.3451591", "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of self driving cars may differ from people expectations, (e.g.\nan autopilot may unexpectedly relinquish control). This expectation mismatch\ncan cause potential and existing users to distrust self driving technology and\ncan increase the likelihood of accidents. We propose a simple but effective\nframework, AutoPreview, to enable consumers to preview a target autopilot\npotential actions in the real world driving context before deployment. For a\ngiven target autopilot, we design a delegate policy that replicates the target\nautopilot behavior with explainable action representations, which can then be\nqueried online for comparison and to build an accurate mental model. To\ndemonstrate its practicality, we present a prototype of AutoPreview integrated\nwith the CARLA simulator along with two potential use cases of the framework.\nWe conduct a pilot study to investigate whether or not AutoPreview provides\ndeeper understanding about autopilot behavior when experiencing a new autopilot\npolicy for the first time. Our results suggest that the AutoPreview method\nhelps users understand autopilot behavior in terms of driving style\ncomprehension, deployment preference, and exact action timing prediction.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:40:59 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Shen", "Yuan", ""], ["Wijayaratne", "Niviru", ""], ["Du", "Peter", ""], ["Jiang", "Shanduojiao", ""], ["Campbell", "Katherine Driggs", ""]]}, {"id": "2102.13045", "submitter": "Nicholay Topin", "authors": "Nicholay Topin, Stephanie Milani, Fei Fang, Manuela Veloso", "title": "Iterative Bounding MDPs: Learning Interpretable Policies via\n  Non-Interpretable Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current work in explainable reinforcement learning generally produces\npolicies in the form of a decision tree over the state space. Such policies can\nbe used for formal safety verification, agent behavior prediction, and manual\ninspection of important features. However, existing approaches fit a decision\ntree after training or use a custom learning procedure which is not compatible\nwith new learning techniques, such as those which use neural networks. To\naddress this limitation, we propose a novel Markov Decision Process (MDP) type\nfor learning decision tree policies: Iterative Bounding MDPs (IBMDPs). An IBMDP\nis constructed around a base MDP so each IBMDP policy is guaranteed to\ncorrespond to a decision tree policy for the base MDP when using a\nmethod-agnostic masking procedure. Because of this decision tree equivalence,\nany function approximator can be used during training, including a neural\nnetwork, while yielding a decision tree policy for the base MDP. We present the\nrequired masking procedure as well as a modified value update step which allows\nIBMDPs to be solved using existing algorithms. We apply this procedure to\nproduce IBMDP variants of recent reinforcement learning methods. We empirically\nshow the benefits of our approach by solving IBMDPs to produce decision tree\npolicies for the base MDPs.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:55:15 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Topin", "Nicholay", ""], ["Milani", "Stephanie", ""], ["Fang", "Fei", ""], ["Veloso", "Manuela", ""]]}, {"id": "2102.13076", "submitter": "Francesco Bodria", "authors": "Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca\n  Naretto, Dino Pedreschi, Salvatore Rinzivillo", "title": "Benchmarking and Survey of Explanation Methods for Black Box Models", "comments": "This work is currently under review on an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of black-box models in Artificial Intelligence has\nenhanced the need for explanation methods to reveal how these obscure models\nreach specific decisions. Retrieving explanations is fundamental to unveil\npossible biases and to resolve practical or ethical issues. Nowadays, the\nliterature is full of methods with different explanations. We provide a\ncategorization of explanation methods based on the type of explanation\nreturned. We present the most recent and widely used explainers, and we show a\nvisual comparison among explanations and a quantitative benchmarking.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:50:29 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Bodria", "Francesco", ""], ["Giannotti", "Fosca", ""], ["Guidotti", "Riccardo", ""], ["Naretto", "Francesca", ""], ["Pedreschi", "Dino", ""], ["Rinzivillo", "Salvatore", ""]]}, {"id": "2102.13085", "submitter": "Nikola Jovanovi\\'c", "authors": "Nikola Jovanovi\\'c, Zhao Meng, Lukas Faber, Roger Wattenhofer", "title": "Towards Robust Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of adversarially robust self-supervised learning on\ngraphs. In the contrastive learning framework, we introduce a new method that\nincreases the adversarial robustness of the learned representations through i)\nadversarial transformations and ii) transformations that not only remove but\nalso insert edges. We evaluate the learned representations in a preliminary set\nof experiments, obtaining promising results. We believe this work takes an\nimportant step towards incorporating robustness as a viable auxiliary task in\ngraph contrastive learning.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:55:15 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Jovanovi\u0107", "Nikola", ""], ["Meng", "Zhao", ""], ["Faber", "Lukas", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2102.13100", "submitter": "Donald J. Hejna Iii", "authors": "Donald J. Hejna III, Pieter Abbeel, Lerrel Pinto", "title": "Task-Agnostic Morphology Evolution", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning primarily focuses on learning behavior, usually\noverlooking the fact that an agent's function is largely determined by form.\nSo, how should one go about finding a morphology fit for solving tasks in a\ngiven environment? Current approaches that co-adapt morphology and behavior use\na specific task's reward as a signal for morphology optimization. However, this\noften requires expensive policy optimization and results in task-dependent\nmorphologies that are not built to generalize. In this work, we propose a new\napproach, Task-Agnostic Morphology Evolution (TAME), to alleviate both of these\nissues. Without any task or reward specification, TAME evolves morphologies by\nonly applying randomly sampled action primitives on a population of agents.\nThis is accomplished using an information-theoretic objective that efficiently\nranks agents by their ability to reach diverse states in the environment and\nthe causality of their actions. Finally, we empirically demonstrate that across\n2D, 3D, and manipulation environments TAME can evolve morphologies that match\nthe multi-task performance of those learned with task supervised algorithms.\nOur code and videos can be found at\nhttps://sites.google.com/view/task-agnostic-evolution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:59:21 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hejna", "Donald J.", "III"], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2102.13128", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski", "title": "An Online Learning Approach to Interpolation and Extrapolation in Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular assumption for out-of-distribution generalization is that the\ntraining data comprises sub-datasets, each drawn from a distinct distribution;\nthe goal is then to \"interpolate\" these distributions and \"extrapolate\" beyond\nthem -- this objective is broadly known as domain generalization. A common\nbelief is that ERM can interpolate but not extrapolate and that the latter is\nconsiderably more difficult, but these claims are vague and lack formal\njustification. In this work, we recast generalization over sub-groups as an\nonline game between a player minimizing risk and an adversary presenting new\ntest distributions. Under an existing notion of inter- and extrapolation based\non reweighting of sub-group likelihoods, we rigorously demonstrate that\nextrapolation is computationally much harder than interpolation, though their\nstatistical complexity is not significantly different. Furthermore, we show\nthat ERM -- or a noisy variant -- is provably minimax-optimal for both tasks.\nOur framework presents a new avenue for the formal analysis of domain\ngeneralization algorithms which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:06:48 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Ravikumar", "Pradeep", ""], ["Risteski", "Andrej", ""]]}, {"id": "2102.13162", "submitter": "Spencer Killen", "authors": "Spencer Killen, Jia-Huai You", "title": "Unfounded Sets for Disjunctive Hybrid MKNF Knowledge Bases", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the closed-world reasoning of answer set programming (ASP) with the\nopen-world reasoning of ontologies broadens the space of applications of\nreasoners. Disjunctive hybrid MKNF knowledge bases succinctly extend ASP and in\nsome cases without increasing the complexity of reasoning tasks. However, in\nmany cases, solver development is lagging behind. As the result, the only known\nmethod of solving disjunctive hybrid MKNF knowledge bases is based on\nguess-and-verify, as formulated by Motik and Rosati in their original work. A\nmain obstacle is understanding how constraint propagation may be performed by a\nsolver, which, in the context of ASP, centers around the computation of\n\\textit{unfounded atoms}, the atoms that are false given a partial\ninterpretation. In this work, we build towards improving solvers for hybrid\nMKNF knowledge bases with disjunctive rules: We formalize a notion of unfounded\nsets for these knowledge bases, identify lower complexity bounds, and\ndemonstrate how we might integrate these developments into a solver. We discuss\nchallenges introduced by ontologies that are not present in the development of\nsolvers for disjunctive logic programs, which warrant some deviations from\ntraditional definitions of unfounded sets. We compare our work with prior\ndefinitions of unfounded sets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 20:44:42 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Killen", "Spencer", ""], ["You", "Jia-Huai", ""]]}, {"id": "2102.13170", "submitter": "Zhuolin Yang", "authors": "Zhuolin Yang, Zhaoxi Chen, Tiffany Cai, Xinyun Chen, Bo Li, Yuandong\n  Tian", "title": "Understanding Robustness in Teacher-Student Setting: A New Perspective", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have appeared as a ubiquitous property of machine\nlearning models where bounded adversarial perturbation could mislead the models\nto make arbitrarily incorrect predictions. Such examples provide a way to\nassess the robustness of machine learning models as well as a proxy for\nunderstanding the model training process. Extensive studies try to explain the\nexistence of adversarial examples and provide ways to improve model robustness\n(e.g. adversarial training). While they mostly focus on models trained on\ndatasets with predefined labels, we leverage the teacher-student framework and\nassume a teacher model, or oracle, to provide the labels for given instances.\nWe extend Tian (2019) in the case of low-rank input data and show that student\nspecialization (trained student neuron is highly correlated with certain\nteacher neuron at the same layer) still happens within the input subspace, but\nthe teacher and student nodes could differ wildly out of the data subspace,\nwhich we conjecture leads to adversarial examples. Extensive experiments show\nthat student specialization correlates strongly with model robustness in\ndifferent scenarios, including student trained via standard training,\nadversarial training, confidence-calibrated adversarial training, and training\nwith robust feature dataset. Our studies could shed light on the future\nexploration about adversarial examples, and enhancing model robustness via\nprincipled data augmentation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 20:54:24 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 03:49:19 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yang", "Zhuolin", ""], ["Chen", "Zhaoxi", ""], ["Cai", "Tiffany", ""], ["Chen", "Xinyun", ""], ["Li", "Bo", ""], ["Tian", "Yuandong", ""]]}, {"id": "2102.13185", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, Bo Dai, Jiayu Zhou", "title": "Off-Policy Imitation Learning from Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning from Observations (LfO) is a practical reinforcement learning\nscenario from which many applications can benefit through the reuse of\nincomplete resources. Compared to conventional imitation learning (IL), LfO is\nmore challenging because of the lack of expert action guidance. In both\nconventional IL and LfO, distribution matching is at the heart of their\nfoundation. Traditional distribution matching approaches are sample-costly\nwhich depend on on-policy transitions for policy learning. Towards\nsample-efficiency, some off-policy solutions have been proposed, which,\nhowever, either lack comprehensive theoretical justifications or depend on the\nguidance of expert actions. In this work, we propose a sample-efficient LfO\napproach that enables off-policy optimization in a principled manner. To\nfurther accelerate the learning procedure, we regulate the policy update with\nan inverse action model, which assists distribution matching from the\nperspective of mode-covering. Extensive empirical results on challenging\nlocomotion tasks indicate that our approach is comparable with state-of-the-art\nin terms of both sample-efficiency and asymptotic performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:33:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Dai", "Bo", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2102.13190", "submitter": "George Papakostas Prof.", "authors": "G.K. Sidiropoulos, G.A. Papakostas", "title": "Machine Biometrics -- Towards Identifying Machines in a Smart City\n  Environment", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper deals with the identification of machines in a smart city\nenvironment. The concept of machine biometrics is proposed in this work for the\nfirst time, as a way to authenticate machine identities interacting with humans\nin everyday life. This definition is imposed in modern years where autonomous\nvehicles, social robots, etc. are considered active members of contemporary\nsocieties. In this context, the case of car identification from the engine\nbehavioral biometrics is examined. For this purpose, 22 sound features were\nextracted and their discrimination capabilities were tested in combination with\n9 different machine learning classifiers, towards identifying 5 car\nmanufacturers. The experimental results revealed the ability of the proposed\nbiometrics to identify cars with high accuracy up to 98% for the case of the\nMultilayer Perceptron (MLP) neural network model.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:49:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Sidiropoulos", "G. K.", ""], ["Papakostas", "G. A.", ""]]}, {"id": "2102.13212", "submitter": "Reza Teshnizi", "authors": "Reza H. Teshnizi, Dylan A. Shell", "title": "Motion Planning for a Pair of Tethered Robots", "comments": "Accepted to appear in Autonomous Robots Special Issue 203:\n  Topological Methods in Robotics. Keywords: Motion Planning; Tethered Robots;\n  Multi-Robot Coordination; A* Search", "journal-ref": null, "doi": "10.1007/s10514-021-09972-x", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering an environment containing polygonal obstacles, we address the\nproblem of planning motions for a pair of planar robots connected to one\nanother via a cable of limited length. Much like prior problems with a single\nrobot connected via a cable to a fixed base, straight line-of-sight visibility\nplays an important role. The present paper shows how the reduced visibility\ngraph provides a natural discretization and captures the essential topological\nconsiderations very effectively for the two robot case as well. Unlike the\nsingle robot case, however, the bounded cable length introduces considerations\naround coordination (or equivalently, when viewed from the point of view of a\ncentralized planner, relative timing) that complicates the matter. Indeed, the\npaper has to introduce a rather more involved formalization than prior\nsingle-robot work in order to establish the core theoretical result -- a\ntheorem permitting the problem to be cast as one of finding paths rather than\ntrajectories. Once affirmed, the planning problem reduces to a straightforward\ngraph search with an elegant representation of the connecting cable, demanding\nonly a few extra ancillary checks that ensure sufficiency of cable to guarantee\nfeasibility of the solution. We describe our implementation of A${}^\\star$\nsearch, and report experimental results. Lastly, we prescribe an optimal\nexecution for the solutions provided by the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 22:45:46 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Teshnizi", "Reza H.", ""], ["Shell", "Dylan A.", ""]]}, {"id": "2102.13249", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Sam Wiseman, Karen Livescu, Kevin Gimpel", "title": "Learning Chess Blindfolded: Evaluating Language Models on State Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer language models have made tremendous strides in natural language\nunderstanding tasks. However, the complexity of natural language makes it\nchallenging to ascertain how accurately these models are tracking the world\nstate underlying the text. Motivated by this issue, we consider the task of\nlanguage modeling for the game of chess. Unlike natural language, chess\nnotations describe a simple, constrained, and deterministic domain. Moreover,\nwe observe that the appropriate choice of chess notation allows for directly\nprobing the world state, without requiring any additional probing-related\nmachinery. We find that: (a) With enough training data, transformer language\nmodels can learn to track pieces and predict legal moves with high accuracy\nwhen trained solely on move sequences. (b) For small training sets providing\naccess to board state information during training can yield significant\nimprovements. (c) The success of transformer language models is dependent on\naccess to the entire game history i.e. \"full attention\". Approximating this\nfull attention results in a significant performance drop. We propose this\ntestbed as a benchmark for future work on the development and analysis of\ntransformer language models.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 01:16:23 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Wiseman", "Sam", ""], ["Livescu", "Karen", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2102.13258", "submitter": "Feng Xue", "authors": "Feng Xue and Junfeng Cao and Yu Zhou and Fei Sheng and Yankai Wang and\n  Anlong Ming", "title": "Boundary-induced and scene-aggregated network for monocular depth\n  prediction", "comments": "Accepted by Pattern Recognition 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular depth prediction is an important task in scene understanding. It\naims to predict the dense depth of a single RGB image. With the development of\ndeep learning, the performance of this task has made great improvements.\nHowever, two issues remain unresolved: (1) The deep feature encodes the wrong\nfarthest region in a scene, which leads to a distorted 3D structure of the\npredicted depth; (2) The low-level features are insufficient utilized, which\nmakes it even harder to estimate the depth near the edge with sudden depth\nchange. To tackle these two issues, we propose the Boundary-induced and\nScene-aggregated network (BS-Net). In this network, the Depth Correlation\nEncoder (DCE) is first designed to obtain the contextual correlations between\nthe regions in an image, and perceive the farthest region by considering the\ncorrelations. Meanwhile, the Bottom-Up Boundary Fusion (BUBF) module is\ndesigned to extract accurate boundary that indicates depth change. Finally, the\nStripe Refinement module (SRM) is designed to refine the dense depth induced by\nthe boundary cue, which improves the boundary accuracy of the predicted depth.\nSeveral experimental results on the NYUD v2 dataset and \\xff{the iBims-1\ndataset} illustrate the state-of-the-art performance of the proposed approach.\nAnd the SUN-RGBD dataset is employed to evaluate the generalization of our\nmethod. Code is available at https://github.com/XuefengBUPT/BS-Net.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 01:43:17 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 15:09:46 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xue", "Feng", ""], ["Cao", "Junfeng", ""], ["Zhou", "Yu", ""], ["Sheng", "Fei", ""], ["Wang", "Yankai", ""], ["Ming", "Anlong", ""]]}, {"id": "2102.13268", "submitter": "Jiameng Fan", "authors": "Jiameng Fan, Wenchao Li", "title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information\n  Bottleneck", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning (DRL) agents are often sensitive to visual\nchanges that were unseen in their training environments. To address this\nproblem, we leverage the sequential nature of RL to learn robust\nrepresentations that encode only task-relevant information from observations\nbased on the unsupervised multi-view setting. Specifically, we introduce an\nauxiliary objective based on the multi-view in-formation bottleneck (MIB)\nprinciple which quantifies the amount of task-irrelevant information and\nencourages learning representations that are both predictive of the future and\nless sensitive to task-irrelevant distractions. This enables us to train\nhigh-performance policies that are robust to visual distractions and can\ngeneralize to unseen environments. We demonstrate that our approach can achieve\nSOTA performance on diverse visual control tasks on the DeepMind Control Suite,\neven when the background is replaced with natural videos. In addition, we show\nthat our approach outperforms well-established baselines for generalization to\nunseen environments on the Procgen benchmark. Our code is open-sourced and\navailable at https://github.com/JmfanBU/DRIBO.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:24:36 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 17:46:33 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 15:14:44 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Fan", "Jiameng", ""], ["Li", "Wenchao", ""]]}, {"id": "2102.13272", "submitter": "Jingbo Jiang", "authors": "Jingbo Jiang, Xizi Chen, Chi-Ying Tsui", "title": "A Reconfigurable Winograd CNN Accelerator with Nesting Decomposition\n  Algorithm for Computing Convolution with Large Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature found that convolutional neural networks (CNN) with large\nfilters perform well in some applications such as image semantic segmentation.\nWinograd transformation helps to reduce the number of multiplications in a\nconvolution but suffers from numerical instability when the convolution filter\nsize gets large. This work proposes a nested Winograd algorithm to iteratively\ndecompose a large filter into a sequence of 3x3 tiles which can then be\naccelerated with a 3x3 Winograd algorithm. Compared with the state-of-art\nOLA-Winograd algorithm, the proposed algorithm reduces the multiplications by\n1.41 to 3.29 times for computing 5x5 to 9x9 convolutions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:42:42 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Jiang", "Jingbo", ""], ["Chen", "Xizi", ""], ["Tsui", "Chi-Ying", ""]]}, {"id": "2102.13280", "submitter": "Luyan Liu", "authors": "Luyan Liu, Zhiwei Wen, Songwei Liu, Hong-Yu Zhou, Hongwei Zhu,\n  Weicheng Xie, Linlin Shen, Kai Ma and Yefeng Zheng", "title": "MixSearch: Searching for Domain Generalized Medical Image Segmentation\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Considering the scarcity of medical data, most datasets in medical image\nanalysis are an order of magnitude smaller than those of natural images.\nHowever, most Network Architecture Search (NAS) approaches in medical images\nfocused on specific datasets and did not take into account the generalization\nability of the learned architectures on unseen datasets as well as different\ndomains. In this paper, we address this point by proposing to search for\ngeneralizable U-shape architectures on a composited dataset that mixes medical\nimages from multiple segmentation tasks and domains creatively, which is named\nMixSearch. Specifically, we propose a novel approach to mix multiple\nsmall-scale datasets from multiple domains and segmentation tasks to produce a\nlarge-scale dataset. Then, a novel weaved encoder-decoder structure is designed\nto search for a generalized segmentation network in both cell-level and\nnetwork-level. The network produced by the proposed MixSearch framework\nachieves state-of-the-art results compared with advanced encoder-decoder\nnetworks across various datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:55:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Liu", "Luyan", ""], ["Wen", "Zhiwei", ""], ["Liu", "Songwei", ""], ["Zhou", "Hong-Yu", ""], ["Zhu", "Hongwei", ""], ["Xie", "Weicheng", ""], ["Shen", "Linlin", ""], ["Ma", "Kai", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2102.13283", "submitter": "Junxiao Xue", "authors": "Junxiao Xue and Xiangyan Kong and Bowei Dong and Mingliang Xu", "title": "Multi-Agent Path Planning based on MPC and DDPG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The problem of mixed static and dynamic obstacle avoidance is essential for\npath planning in highly dynamic environment. However, the paths formed by grid\nedges can be longer than the true shortest paths in the terrain since their\nheadings are artificially constrained. Existing methods can hardly deal with\ndynamic obstacles. To address this problem, we propose a new algorithm\ncombining Model Predictive Control (MPC) with Deep Deterministic Policy\nGradient (DDPG). Firstly, we apply the MPC algorithm to predict the trajectory\nof dynamic obstacles. Secondly, the DDPG with continuous action space is\ndesigned to provide learning and autonomous decision-making capability for\nrobots. Finally, we introduce the idea of the Artificial Potential Field to set\nthe reward function to improve convergence speed and accuracy. We employ Unity\n3D to perform simulation experiments in highly uncertain environment such as\naircraft carrier decks and squares. The results show that our method has made\ngreat improvement on accuracy by 7%-30% compared with the other methods, and on\nthe length of the path and turning angle by reducing 100 units and 400-450\ndegrees compared with DQN (Deep Q Network), respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 02:57:13 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Xue", "Junxiao", ""], ["Kong", "Xiangyan", ""], ["Dong", "Bowei", ""], ["Xu", "Mingliang", ""]]}, {"id": "2102.13307", "submitter": "Shashi Suman", "authors": "Shashi Suman, Ali Etemad, Francois Rivest", "title": "Potential Impacts of Smart Homes on Human Behavior: A Reinforcement\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We aim to investigate the potential impacts of smart homes on human behavior.\nTo this end, we simulate a series of human models capable of performing various\nactivities inside a reinforcement learning-based smart home. We then\ninvestigate the possibility of human behavior being altered as a result of the\nsmart home and the human model adapting to one-another. We design a semi-Markov\ndecision process human task interleaving model based on hierarchical\nreinforcement learning that learns to make decisions to either pursue or leave\nan activity. We then integrate our human model in the smart home which is based\non Q-learning. We show that a smart home trained on a generic human model is\nable to anticipate and learn the thermal preferences of human models with\nintrinsic rewards similar to the generic model. The hierarchical human model\nlearns to complete each activity and set optimal thermal settings for maximum\ncomfort. With the smart home, the number of time steps required to change the\nthermal settings are reduced for the human models. Interestingly, we observe\nthat small variations in the human model reward structures can lead to the\nopposite behavior in the form of unexpected switching between activities which\nsignals changes in human behavior due to the presence of the smart home.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 05:33:46 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 16:52:17 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 23:05:44 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Suman", "Shashi", ""], ["Etemad", "Ali", ""], ["Rivest", "Francois", ""]]}, {"id": "2102.13322", "submitter": "Hongxin Xiang", "authors": "Cheng Xie, Ting Zeng, Hongxin Xiang, Keqin Li, Yun Yang, Qing Liu", "title": "Class Knowledge Overlay to Visual Feature Learning for Zero-Shot Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New categories can be discovered by transforming semantic features into\nsynthesized visual features without corresponding training samples in zero-shot\nimage classification. Although significant progress has been made in generating\nhigh-quality synthesized visual features using generative adversarial networks,\nguaranteeing semantic consistency between the semantic features and visual\nfeatures remains very challenging. In this paper, we propose a novel zero-shot\nlearning approach, GAN-CST, based on class knowledge to visual feature learning\nto tackle the problem. The approach consists of three parts, class knowledge\noverlay, semi-supervised learning and triplet loss. It applies class knowledge\noverlay (CKO) to obtain knowledge not only from the corresponding class but\nalso from other classes that have the knowledge overlay. It ensures that the\nknowledge-to-visual learning process has adequate information to generate\nsynthesized visual features. The approach also applies a semi-supervised\nlearning process to re-train knowledge-to-visual model. It contributes to\nreinforcing synthesized visual features generation as well as new category\nprediction. We tabulate results on a number of benchmark datasets demonstrating\nthat the proposed model delivers superior performance over state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 06:34:35 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Xie", "Cheng", ""], ["Zeng", "Ting", ""], ["Xiang", "Hongxin", ""], ["Li", "Keqin", ""], ["Yang", "Yun", ""], ["Liu", "Qing", ""]]}, {"id": "2102.13326", "submitter": "Hongxin Xiang", "authors": "Zeng Ting, Xiang Hongxin, Xie Cheng, Yang Yun, Liu Qing", "title": "Zero-Shot Learning Based on Knowledge Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-Shot Learning (ZSL) is an emerging research that aims to solve the\nclassification problems with very few training data. The present works on ZSL\nmainly focus on the mapping of learning semantic space to visual space. It\nencounters many challenges that obstruct the progress of ZSL research. First,\nthe representation of the semantic feature is inadequate to represent all\nfeatures of the categories. Second, the domain drift problem still exists\nduring the transfer from semantic space to visual space. In this paper, we\nintroduce knowledge sharing (KS) to enrich the representation of semantic\nfeatures. Based on KS, we apply a generative adversarial network to generate\npseudo visual features from semantic features that are very close to the real\nvisual features. Abundant experimental results from two benchmark datasets of\nZSL show that the proposed approach has a consistent improvement.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 06:43:29 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Ting", "Zeng", ""], ["Hongxin", "Xiang", ""], ["Cheng", "Xie", ""], ["Yun", "Yang", ""], ["Qing", "Liu", ""]]}, {"id": "2102.13368", "submitter": "Arianna Casanova", "authors": "Arianna Casanova, Juerg Kohlas, Marco Zaffalon", "title": "Information algebras in the theory of imprecise probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that coherent sets of gambles and coherent lower and\nupper previsions can be embedded into the algebraic structure of information\nalgebra. This leads firstly, to a new perspective of the algebraic and logical\nstructure of desirability and imprecise probabilities and secondly, it connects\nimprecise probabilities to other formalism in computer science sharing the same\nunderlying structure. Both the domain free and the labeled view of the\nresulting information algebras are presented, considering product possibility\nspaces. Moreover, it is shown that both are atomistic and therefore they can be\nembedded in set algebras.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 09:36:39 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 10:08:28 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 07:35:33 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Casanova", "Arianna", ""], ["Kohlas", "Juerg", ""], ["Zaffalon", "Marco", ""]]}, {"id": "2102.13384", "submitter": "Kailash Budhathoki", "authors": "Kailash Budhathoki, Dominik Janzing, Patrick Bloebaum, Hoiyi Ng", "title": "Why did the distribution change?", "comments": "Proceedings of the Twenty Fourth International Conference on\n  Artificial Intelligence and Statistics (AISTATS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a formal approach based on graphical causal models to identify\nthe \"root causes\" of the change in the probability distribution of variables.\nAfter factorizing the joint distribution into conditional distributions of each\nvariable, given its parents (the \"causal mechanisms\"), we attribute the change\nto changes of these causal mechanisms. This attribution analysis accounts for\nthe fact that mechanisms often change independently and sometimes only some of\nthem change. Through simulations, we study the performance of our distribution\nchange attribution method. We then present a real-world case study identifying\nthe drivers of the difference in the income distribution between men and women.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:22:59 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 07:53:22 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Budhathoki", "Kailash", ""], ["Janzing", "Dominik", ""], ["Bloebaum", "Patrick", ""], ["Ng", "Hoiyi", ""]]}, {"id": "2102.13388", "submitter": "Aur\\'elie Boisbunon", "authors": "Aur\\'elie Boisbunon, Carlo Fanara, Ingrid Grenet, Jonathan Daeden,\n  Alexis Vighi, Marc Schoenauer", "title": "Zoetrope Genetic Programming for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Zoetrope Genetic Programming (ZGP) algorithm is based on an original\nrepresentation for mathematical expressions, targeting evolutionary symbolic\nregression.The zoetropic representation uses repeated fusion operations between\npartial expressions, starting from the terminal set. Repeated fusions within an\nindividual gradually generate more complex expressions, ending up in what can\nbe viewed as new features. These features are then linearly combined to best\nfit the training data. ZGP individuals then undergo specific crossover and\nmutation operators, and selection takes place between parents and offspring.\nZGP is validated using a large number of public domain regression datasets, and\ncompared to other symbolic regression algorithms, as well as to traditional\nmachine learning algorithms. ZGP reaches state-of-the-art performance with\nrespect to both types of algorithms, and demonstrates a low computational time\ncompared to other symbolic regression approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:47:10 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Boisbunon", "Aur\u00e9lie", ""], ["Fanara", "Carlo", ""], ["Grenet", "Ingrid", ""], ["Daeden", "Jonathan", ""], ["Vighi", "Alexis", ""], ["Schoenauer", "Marc", ""]]}, {"id": "2102.13490", "submitter": "Mahnaz Sadat Qafari", "authors": "Mahnaz Sadat Qafari, Wil van der Aalst", "title": "Case Level Counterfactual Reasoning in Process Mining", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining is widely used to diagnose processes and uncover performance\nand compliance problems. It is also possible to see relations between different\nbehavioral aspects, e.g., cases that deviate more at the beginning of the\nprocess tend to get delayed in the last part of the process. However,\ncorrelations do not necessarily reveal causalities. Moreover, standard process\nmining diagnostics do not indicate how to improve the process. This is the\nreason we advocate the use of \\emph{structural equation models} and\n\\emph{counterfactual reasoning}. We use results from causal inference and adapt\nthese to be able to reason over event logs and process interventions. We have\nimplemented the approach as a ProM plug-in and have evaluated it on several\ndata sets. Our ProM plug-in produces recommendations that indicate how specific\ncases could have been handled differently to avoid a performance or compliance\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:52:18 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Qafari", "Mahnaz Sadat", ""], ["van der Aalst", "Wil", ""]]}, {"id": "2102.13515", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Pablo Sprechmann, Steven Hansen, Andre Barreto,\n  Steven Kapturowski, Alex Vitvitskyi, Adri\\`a Puigdom\\`enech Badia, Charles\n  Blundell", "title": "Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Designing agents that acquire knowledge autonomously and use it to solve new\ntasks efficiently is an important challenge in reinforcement learning.\nKnowledge acquired during an unsupervised pre-training phase is often\ntransferred by fine-tuning neural network weights once rewards are exposed, as\nis common practice in supervised domains. Given the nature of the reinforcement\nlearning problem, we argue that standard fine-tuning strategies alone are not\nenough for efficient transfer in challenging domains. We introduce Behavior\nTransfer (BT), a technique that leverages pre-trained policies for exploration\nand that is complementary to transferring neural network weights. Our\nexperiments show that, when combined with large-scale pre-training in the\nabsence of rewards, existing intrinsic motivation objectives can lead to the\nemergence of complex behaviors. These pre-trained policies can then be\nleveraged by BT to discover better solutions than without pre-training, and\ncombining BT with standard fine-tuning strategies results in additional\nbenefits. The largest gains are generally observed in domains requiring\nstructured exploration, including settings where the behavior of the\npre-trained policies is misaligned with the downstream task.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 16:51:02 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 10:08:08 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 09:36:51 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Sprechmann", "Pablo", ""], ["Hansen", "Steven", ""], ["Barreto", "Andre", ""], ["Kapturowski", "Steven", ""], ["Vitvitskyi", "Alex", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Blundell", "Charles", ""]]}, {"id": "2102.13517", "submitter": "Kuo Yang", "authors": "Kuo Yang, Emad A. Mohammed, Behrouz H. Far", "title": "Detection of Alzheimer's Disease Using Graph-Regularized Convolutional\n  Neural Network Based on Structural Similarity Learning of Brain Magnetic\n  Resonance Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This paper presents an Alzheimer's disease (AD) detection method\nbased on learning structural similarity between Magnetic Resonance Images\n(MRIs) and representing this similarity as a graph. Methods: We construct the\nsimilarity graph using embedded features of the input image (i.e., Non-Demented\n(ND), Very Mild Demented (VMD), Mild Demented (MD), and Moderated Demented\n(MDTD)). We experiment and compare different dimension-reduction and clustering\nalgorithms to construct the best similarity graph to capture the similarity\nbetween the same class images using the cosine distance as a similarity\nmeasure. We utilize the similarity graph to present (sample) the training data\nto a convolutional neural network (CNN). We use the similarity graph as a\nregularizer in the loss function of a CNN model to minimize the distance\nbetween the input images and their k-nearest neighbours in the similarity graph\nwhile minimizing the categorical cross-entropy loss between the training image\npredictions and the actual image class labels. Results: We conduct extensive\nexperiments with several pre-trained CNN models and compare the results to\nother recent methods. Conclusion: Our method achieves superior performance on\nthe testing dataset (accuracy = 0.986, area under receiver operating\ncharacteristics curve = 0.998, F1 measure = 0.987). Significance: The\nclassification results show an improvement in the prediction accuracy compared\nto the other methods. We release all the code used in our experiments to\nencourage reproducible research in this area\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 14:49:50 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Yang", "Kuo", ""], ["Mohammed", "Emad A.", ""], ["Far", "Behrouz H.", ""]]}, {"id": "2102.13519", "submitter": "Stefan Bl\\\"ucher", "authors": "Stefan Bl\\\"ucher and Nils Strodthoff", "title": "PredDiff: Explanations and Interactions from Conditional Expectations", "comments": "8 pages, 4 Figures, clarified main text and revised Appendix D, code\n  available at https://github.com/PredDiff/PredDiffTabular", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  PredDiff is a model-agnostic, local attribution method that is firmly rooted\nin probability theory. Its simple intuition is to measure prediction changes\nwhen marginalizing out feature variables. In this work, we clarify properties\nof PredDiff and put forward several extensions of the original formalism. Most\nnotably, we introduce a new measure for interaction effects. Interactions are\nan inevitable step towards a comprehensive understanding of black-box models.\nImportantly, our framework readily allows to investigate interactions between\narbitrary feature subsets and scales linearly with their number. We demonstrate\nthe soundness of PredDiff relevances and interactions both in the\nclassification and regression setting. To this end, we use different analytic,\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:46:47 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 14:27:07 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Bl\u00fccher", "Stefan", ""], ["Strodthoff", "Nils", ""]]}, {"id": "2102.13564", "submitter": "Martin Suda", "authors": "Martin Suda", "title": "Improving ENIGMA-Style Clause Selection While Learning From History", "comments": "16 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We re-examine the topic of machine-learned clause selection guidance in\nsaturation-based theorem provers. The central idea, recently popularized by the\nENIGMA system, is to learn a classifier for recognizing clauses that appeared\nin previously discovered proofs. In subsequent runs, clauses classified\npositively are prioritized for selection. We propose several improvements to\nthis approach and experimentally confirm their viability. For the\ndemonstration, we use a recursive neural network to classify clauses based on\ntheir derivation history and the presence or absence of automatically supplied\ntheory axioms therein. The automatic theorem prover Vampire guided by the\nnetwork achieves a 41% improvement on a relevant subset of SMT-LIB in a real\ntime evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 16:13:45 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 17:46:50 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Suda", "Martin", ""]]}, {"id": "2102.13605", "submitter": "Yigit Tuncel", "authors": "Yigit Tuncel, Ganapati Bhat, Jaehyun Park, Umit Ogras", "title": "ECO: Enabling Energy-Neutral IoT Devices through Runtime Allocation of\n  Harvested Energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy harvesting offers an attractive and promising mechanism to power\nlow-energy devices. However, it alone is insufficient to enable an\nenergy-neutral operation, which can eliminate tedious battery charging and\nreplacement requirements. Achieving an energy-neutral operation is challenging\nsince the uncertainties in harvested energy undermine the quality of service\nrequirements. To address this challenge, we present a rollout-based runtime\nenergy-allocation framework that optimizes the utility of the target device\nunder energy constraints. The proposed framework uses an efficient iterative\nalgorithm to compute initial energy allocations at the beginning of a day. The\ninitial allocations are then corrected at every interval to compensate for the\ndeviations from the expected energy harvesting pattern. We evaluate this\nframework using solar and motion energy harvesting modalities and American Time\nUse Survey data from 4772 different users. Compared to state-of-the-art\ntechniques, the proposed framework achieves 34.6% higher utility even under\nenergy-limited scenarios. Moreover, measurements on a wearable device prototype\nshow that the proposed framework has less than 0.1% energy overhead compared to\niterative approaches with a negligible loss in utility.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:21:25 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Tuncel", "Yigit", ""], ["Bhat", "Ganapati", ""], ["Park", "Jaehyun", ""], ["Ogras", "Umit", ""]]}, {"id": "2102.13620", "submitter": "Himabindu Lakkaraju", "authors": "Sohini Upadhyay, Shalmali Joshi, Himabindu Lakkaraju", "title": "Towards Robust and Reliable Algorithmic Recourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As predictive models are increasingly being deployed in high-stakes decision\nmaking (e.g., loan approvals), there has been growing interest in post hoc\ntechniques which provide recourse to affected individuals. These techniques\ngenerate recourses under the assumption that the underlying predictive model\ndoes not change. However, in practice, models are often regularly updated for a\nvariety of reasons (e.g., dataset shifts), thereby rendering previously\nprescribed recourses ineffective. To address this problem, we propose a novel\nframework, RObust Algorithmic Recourse (ROAR), that leverages adversarial\ntraining for finding recourses that are robust to model shifts. To the best of\nour knowledge, this work proposes the first solution to this critical problem.\nWe also carry out detailed theoretical analysis which underscores the\nimportance of constructing recourses that are robust to model shifts: 1) we\nderive a lower bound on the probability of invalidation of recourses generated\nby existing approaches which are not robust to model shifts. 2) we prove that\nthe additional cost incurred due to the robust recourses output by our\nframework is bounded. Experimental evaluation on multiple synthetic and\nreal-world datasets demonstrates the efficacy of the proposed framework and\nsupports our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:38:52 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 14:56:24 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Upadhyay", "Sohini", ""], ["Joshi", "Shalmali", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2102.13631", "submitter": "Zhaozhuo Xu", "authors": "Zhaozhuo Xu, Aditya Desai, Menal Gupta, Anu Chandran, Antoine\n  Vial-Aussavy, Anshumali Shrivastava", "title": "Beyond Convolutions: A Novel Deep Learning Approach for Raw Seismic Data\n  Ingestion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional seismic processing workflows (SPW) are expensive, requiring over\na year of human and computational effort. Deep learning (DL) based data-driven\nseismic workflows (DSPW) hold the potential to reduce these timelines to a few\nminutes. Raw seismic data (terabytes) and required subsurface prediction\n(gigabytes) are enormous. This large-scale, spatially irregular time-series\ndata poses seismic data ingestion (SDI) as an unconventional yet fundamental\nproblem in DSPW. Current DL research is limited to small-scale simplified\nsynthetic datasets as they treat seismic data like images and process them with\nconvolution networks. Real seismic data, however, is at least 5D. Applying 5D\nconvolutions to this scale is computationally prohibitive. Moreover, raw\nseismic data is highly unstructured and hence inherently non-image like. We\npropose a fundamental shift to move away from convolutions and introduce SESDI:\nSet Embedding based SDI approach. SESDI first breaks down the mammoth task of\nlarge-scale prediction into an efficient compact auxiliary task. SESDI\ngracefully incorporates irregularities in data with its novel model\narchitecture. We believe SESDI is the first successful demonstration of\nend-to-end learning on real seismic data. SESDI achieves SSIM of over 0.8 on\nvelocity inversion task on real proprietary data from the Gulf of Mexico and\noutperforms the state-of-the-art U-Net model on synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:12:53 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Xu", "Zhaozhuo", ""], ["Desai", "Aditya", ""], ["Gupta", "Menal", ""], ["Chandran", "Anu", ""], ["Vial-Aussavy", "Antoine", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2102.13640", "submitter": "Jakob Heiss", "authors": "Jakob Heiss, Jakob Weissteiner, Hanna Wutte, Sven Seuken, Josef\n  Teichmann", "title": "NOMU: Neural Optimization-based Model Uncertainty", "comments": "9 pages + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods for estimating model uncertainty for neural networks (NNs).\nTo isolate the effect of model uncertainty, we focus on a noiseless setting\nwith scarce training data. We introduce five important desiderata regarding\nmodel uncertainty that any method should satisfy. However, we find that\nestablished benchmarks often fail to reliably capture some of these desiderata,\neven those that are required by Bayesian theory. To address this, we introduce\na new approach for capturing model uncertainty for NNs, which we call Neural\nOptimization-based Model Uncertainty (NOMU). The main idea of NOMU is to design\na network architecture consisting of two connected sub-NNs, one for model\nprediction and one for model uncertainty, and to train it using a\ncarefully-designed loss function. Importantly, our design enforces that NOMU\nsatisfies our five desiderata. Due to its modular architecture, NOMU can\nprovide model uncertainty for any given (previously trained) NN if given access\nto its training data. We first experimentally study noiseless regression with\nscarce training data to highlight the deficiencies of the established\nbenchmarks. Finally, we study the important task of Bayesian optimization (BO)\nwith costly evaluations, where good model uncertainty estimates are essential.\nOur results show that NOMU performs as well or better than state-of-the-art\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:34:43 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 16:53:19 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 22:00:03 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Heiss", "Jakob", ""], ["Weissteiner", "Jakob", ""], ["Wutte", "Hanna", ""], ["Seuken", "Sven", ""], ["Teichmann", "Josef", ""]]}, {"id": "2102.13651", "submitter": "Baohe Zhang", "authors": "Baohe Zhang, Raghu Rajan, Luis Pineda, Nathan Lambert, Andr\\'e\n  Biedenkapp, Kurtland Chua, Frank Hutter, Roberto Calandra", "title": "On the Importance of Hyperparameter Optimization for Model-based\n  Reinforcement Learning", "comments": "19 pages, accepted by AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) is a promising framework for\nlearning control in a data-efficient manner. MBRL algorithms can be fairly\ncomplex due to the separate dynamics modeling and the subsequent planning\nalgorithm, and as a result, they often possess tens of hyperparameters and\narchitectural choices. For this reason, MBRL typically requires significant\nhuman expertise before it can be applied to new problems and domains. To\nalleviate this problem, we propose to use automatic hyperparameter optimization\n(HPO). We demonstrate that this problem can be tackled effectively with\nautomated HPO, which we demonstrate to yield significantly improved performance\ncompared to human experts. In addition, we show that tuning of several MBRL\nhyperparameters dynamically, i.e. during the training itself, further improves\nthe performance compared to using static hyperparameters which are kept fixed\nfor the whole training. Finally, our experiments provide valuable insights into\nthe effects of several hyperparameters, such as plan horizon or learning rate\nand their influence on the stability of training and resulting rewards.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:57:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Zhang", "Baohe", ""], ["Rajan", "Raghu", ""], ["Pineda", "Luis", ""], ["Lambert", "Nathan", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Chua", "Kurtland", ""], ["Hutter", "Frank", ""], ["Calandra", "Roberto", ""]]}]