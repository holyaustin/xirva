[{"id": "0807.0337", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Unveiling the mystery of visual information processing in human brain", "comments": "Accepted to be published in Brain Research (BRES-38102)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally accepted that human vision is an extremely powerful\ninformation processing system that facilitates our interaction with the\nsurrounding world. However, despite extended and extensive research efforts,\nwhich encompass many exploration fields, the underlying fundamentals and\noperational principles of visual information processing in human brain remain\nunknown. We still are unable to figure out where and how along the path from\neyes to the cortex the sensory input perceived by the retina is converted into\na meaningful object representation, which can be consciously manipulated by the\nbrain. Studying the vast literature considering the various aspects of brain\ninformation processing, I was surprised to learn that the respected scholarly\ndiscussion is totally indifferent to the basic keynote question: \"What is\ninformation?\" in general or \"What is visual information?\" in particular. In the\nold days, it was assumed that any scientific research approach has first to\ndefine its basic departure points. Why was it overlooked in brain information\nprocessing research remains a conundrum. In this paper, I am trying to find a\nremedy for this bizarre situation. I propose an uncommon definition of\n\"information\", which can be derived from Kolmogorov's Complexity Theory and\nChaitin's notion of Algorithmic Information. Embracing this new definition\nleads to an inevitable revision of traditional dogmas that shape the state of\nthe art of brain information processing research. I hope this revision would\nbetter serve the challenging goal of human visual information processing\nmodeling.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2008 12:33:48 GMT"}], "update_date": "2008-07-07", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "0807.0517", "submitter": "Miklos Antal Mr", "authors": "Miklos Antal, Laszlo Balogh", "title": "Modeling belief systems with scale-free networks", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Evolution of belief systems has always been in focus of cognitive research.\nIn this paper we delineate a new model describing belief systems as a network\nof statements considered true. Testing the model a small number of parameters\nenabled us to reproduce a variety of well-known mechanisms ranging from opinion\nchanges to development of psychological problems. The self-organizing opinion\nstructure showed a scale-free degree distribution. The novelty of our work lies\nin applying a convenient set of definitions allowing us to depict opinion\nnetwork dynamics in a highly favorable way, which resulted in a scale-free\nbelief network. As an additional benefit, we listed several conjectural\nconsequences in a number of areas related to thinking and reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2008 09:38:19 GMT"}], "update_date": "2008-07-04", "authors_parsed": [["Antal", "Miklos", ""], ["Balogh", "Laszlo", ""]]}, {"id": "0807.0627", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2)", "title": "Belief decision support and reject for textured images characterization", "comments": null, "journal-ref": "International Conference on Information Fusion, Lens : France\n  (2008)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The textured images' classification assumes to consider the images in terms\nof area with the same texture. In uncertain environment, it could be better to\ntake an imprecise decision or to reject the area corresponding to an unlearning\nclass. Moreover, on the areas that are the classification units, we can have\nmore than one texture. These considerations allows us to develop a belief\ndecision model permitting to reject an area as unlearning and to decide on\nunions and intersections of learning classes. The proposed approach finds all\nits justification in an application of seabed characterization from sonar\nimages, which contributes to an illustration.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2008 19:46:21 GMT"}], "update_date": "2008-07-04", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"]]}, {"id": "0807.0908", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh", "title": "The Correspondence Analysis Platform for Uncovering Deep Structure in\n  Data and Information", "comments": "Sixth Annual Boole Lecture in Informatics, Boole Centre for Research\n  in Informatics, Cork, Ireland, 29 April 2008. 28 pp., 17 figures. To appear,\n  Computer Journal. This version: 3 typos corrected", "journal-ref": "Computer Journal, 53 (3), 304-315, 2010", "doi": "10.1093/comjnl/bxn045", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two aspects of information semantics: (i) the collection of all\nrelationships, (ii) tracking and spotting anomaly and change. The first is\nimplemented by endowing all relevant information spaces with a Euclidean metric\nin a common projected space. The second is modelled by an induced ultrametric.\nA very general way to achieve a Euclidean embedding of different information\nspaces based on cross-tabulation counts (and from other input data formats) is\nprovided by Correspondence Analysis. From there, the induced ultrametric that\nwe are particularly interested in takes a sequential - e.g. temporal - ordering\nof the data into account. We employ such a perspective to look at narrative,\n\"the flow of thought and the flow of language\" (Chafe). In application to\npolicy decision making, we show how we can focus analysis in a small number of\ndimensions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2008 15:22:54 GMT"}, {"version": "v2", "created": "Tue, 2 Sep 2008 17:07:52 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Murtagh", "Fionn", ""]]}, {"id": "0807.1494", "submitter": "Matteo Gagliolo", "authors": "Matteo Gagliolo and Juergen Schmidhuber", "title": "Algorithm Selection as a Bandit Problem with Unbounded Losses", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-642-13800-3_7", "report-no": "IDSIA-07-08", "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm selection is typically based on models of algorithm performance,\nlearned during a separate offline training sequence, which can be prohibitively\nexpensive. In recent work, we adopted an online approach, in which a\nperformance model is iteratively updated and used to guide selection on a\nsequence of problem instances. The resulting exploration-exploitation trade-off\nwas represented as a bandit problem with expert advice, using an existing\nsolver for this game, but this required the setting of an arbitrary bound on\nalgorithm runtimes, thus invalidating the optimal regret of the solver. In this\npaper, we propose a simpler framework for representing algorithm selection as a\nbandit problem, with partial information, and an unknown bound on losses. We\nadapt an existing solver to this game, proving a bound on its expected regret,\nwhich holds also for the resulting algorithm selection technique. We present\npreliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT\nbenchmark.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2008 16:47:36 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Gagliolo", "Matteo", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "0807.1906", "submitter": "Florentin Smarandache", "authors": "Florentin Smarandache", "title": "Extension of Inagaki General Weighted Operators and A New Fusion Rule\n  Class of Proportional Redistribution of Intersection Masses", "comments": "6 pages; SWIFT 2008 - Skovde Workshop on Information Fusion Topics,\n  Sweden;", "journal-ref": "International Journal of Artificial Intelligence, Vol. 3, No. A09,\n  79-85, 2009", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend Inagaki Weighted Operators fusion rule (WO) in\ninformation fusion by doing redistribution of not only the conflicting mass,\nbut also of masses of non-empty intersections, that we call Double Weighted\nOperators (DWO). Then we propose a new fusion rule Class of Proportional\nRedistribution of Intersection Masses (CPRIM), which generates many interesting\nparticular fusion rules in information fusion. Both formulas are presented for\nany number of sources of information. An application and comparison with other\nfusion rules are given in the last section.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2008 18:30:10 GMT"}, {"version": "v2", "created": "Mon, 1 Sep 2008 19:03:33 GMT"}, {"version": "v3", "created": "Sat, 4 Oct 2008 23:09:41 GMT"}], "update_date": "2009-06-17", "authors_parsed": [["Smarandache", "Florentin", ""]]}, {"id": "0807.1997", "submitter": "Zhi-Hua Zhou", "authors": "Zhi-Hua Zhou, Yu-Yin Sun, Yu-Feng Li", "title": "Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples", "comments": "ICML, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-instance learning attempts to learn from a training set consisting of\nlabeled bags each containing many unlabeled instances. Previous studies\ntypically treat the instances in the bags as independently and identically\ndistributed. However, the instances in a bag are rarely independent, and\ntherefore a better performance can be expected if the instances are treated in\nan non-i.i.d. way that exploits the relations among instances. In this paper,\nwe propose a simple yet effective multi-instance learning method, which regards\neach bag as a graph and uses a specific kernel to distinguish the graphs by\nconsidering the features of the nodes as well as the features of the edges that\nconvey some relations among instances. The effectiveness of the proposed method\nis validated by experiments.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2008 20:19:18 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2009 17:22:40 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2009 08:43:03 GMT"}, {"version": "v4", "created": "Wed, 13 May 2009 16:22:00 GMT"}], "update_date": "2009-05-13", "authors_parsed": [["Zhou", "Zhi-Hua", ""], ["Sun", "Yu-Yin", ""], ["Li", "Yu-Feng", ""]]}, {"id": "0807.2282", "submitter": "Arfan Ghani Mr.", "authors": "Arfan Ghani, Martin McGinnity, Liam Maguire, Jim Harkin", "title": "Hardware/Software Co-Design for Spike Based Recognition", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical applications based on recurrent spiking neurons are limited due\nto their non-trivial learning algorithms. The temporal nature of spiking\nneurons is more favorable for hardware implementation where signals can be\nrepresented in binary form and communication can be done through the use of\nspikes. This work investigates the potential of recurrent spiking neurons\nimplementations on reconfigurable platforms and their applicability in temporal\nbased applications. A theoretical framework of reservoir computing is\ninvestigated for hardware/software implementation. In this framework, only\nreadout neurons are trained which overcomes the burden of training at the\nnetwork level. These recurrent neural networks are termed as microcircuits\nwhich are viewed as basic computational units in cortical computation. This\npaper investigates the potential of recurrent neural reservoirs and presents a\nnovel hardware/software strategy for their implementation on FPGAs. The design\nis implemented and the functionality is tested in the context of speech\nrecognition application.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2008 23:44:47 GMT"}], "update_date": "2008-07-16", "authors_parsed": [["Ghani", "Arfan", ""], ["McGinnity", "Martin", ""], ["Maguire", "Liam", ""], ["Harkin", "Jim", ""]]}, {"id": "0807.2383", "submitter": "Michel Rueher", "authors": "H\\'el\\`ene Collavizza (I3S), Michel Rueher (I3S), Pascal Van\n  Hentenryck (Brown University)", "title": "CPBVP: A Constraint-Programming Framework for Bounded Program\n  Verification", "comments": null, "journal-ref": "The 14th International Conference on Principles and Practice of\n  Constraint Programming, Sydney : Australie (2008)", "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to verify the conformity of a program with its\nspecification and proposes a novel constraint-programming framework for bounded\nprogram verification (CPBPV). The CPBPV framework uses constraint stores to\nrepresent the specification and the program and explores execution paths\nnondeterministically. The input program is partially correct if each constraint\nstore so produced implies the post-condition. CPBPV does not explore spurious\nexecution paths as it incrementally prunes execution paths early by detecting\nthat the constraint store is not consistent. CPBPV uses the rich language of\nconstraint programming to express the constraint store. Finally, CPBPV is\nparametrized with a list of solvers which are tried in sequence, starting with\nthe least expensive and less general. Experimental results often produce orders\nof magnitude improvements over earlier approaches, running times being often\nindependent of the variable domains. Moreover, CPBPV was able to detect subtle\nerrors in some programs while other frameworks based on model checking have\nfailed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2008 14:18:43 GMT"}], "update_date": "2008-07-16", "authors_parsed": [["Collavizza", "H\u00e9l\u00e8ne", "", "I3S"], ["Rueher", "Michel", "", "I3S"], ["Van Hentenryck", "Pascal", "", "Brown University"]]}, {"id": "0807.3287", "submitter": "Johannes Wollbold", "authors": "Johannes Wollbold, Reinhard Guthke, Bernhard Ganter", "title": "Constructing a Knowledge Base for Gene Regulatory Dynamics by Formal\n  Concept Analysis Methods", "comments": "15 pages, 1 figure, LaTeX style llncsdoc.sty", "journal-ref": "K. Horimoto et al. (Eds.): AB 2008, LNCS 5147. Springer,\n  Heidelberg 2008, pp. 230-244", "doi": null, "report-no": null, "categories": "q-bio.MN cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our aim is to build a set of rules, such that reasoning over temporal\ndependencies within gene regulatory networks is possible. The underlying\ntransitions may be obtained by discretizing observed time series, or they are\ngenerated based on existing knowledge, e.g. by Boolean networks or their\nnondeterministic generalization. We use the mathematical discipline of formal\nconcept analysis (FCA), which has been applied successfully in domains as\nknowledge representation, data mining or software engineering. By the attribute\nexploration algorithm, an expert or a supporting computer program is enabled to\ndecide about the validity of a minimal set of implications and thus to\nconstruct a sound and complete knowledge base. From this all valid implications\nare derivable that relate to the selected properties of a set of genes. We\npresent results of our method for the initiation of sporulation in Bacillus\nsubtilis. However the formal structures are exhibited in a most general manner.\nTherefore the approach may be adapted to signal transduction or metabolic\nnetworks, as well as to discrete temporal transitions in many biological and\nnonbiological areas.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jul 2008 15:46:22 GMT"}], "update_date": "2008-07-22", "authors_parsed": [["Wollbold", "Johannes", ""], ["Guthke", "Reinhard", ""], ["Ganter", "Bernhard", ""]]}, {"id": "0807.3483", "submitter": "Arnaud Martin", "authors": "Arnaud Martin (E3I2)", "title": "Implementing general belief function framework with a practical\n  codification for low complexity", "comments": "Advances and Applications of DSmT for Information Fusion, Florentin\n  Smarandache & Jean Dezert (Ed.) (2008) Pnd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we propose a new practical codification of the elements of\nthe Venn diagram in order to easily manipulate the focal elements. In order to\nreduce the complexity, the eventual constraints must be integrated in the\ncodification at the beginning. Hence, we only consider a reduced hyper power\nset $D_r^\\Theta$ that can be $2^\\Theta$ or $D^\\Theta$. We describe all the\nsteps of a general belief function framework. The step of decision is\nparticularly studied, indeed, when we can decide on intersections of the\nsingletons of the discernment space no actual decision functions are easily to\nuse. Hence, two approaches are proposed, an extension of previous one and an\napproach based on the specificity of the elements on which to decide. The\nprincipal goal of this chapter is to provide practical codes of a general\nbelief function framework for the researchers and users needing the belief\nfunction theory.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2008 13:50:22 GMT"}], "update_date": "2008-07-23", "authors_parsed": [["Martin", "Arnaud", "", "E3I2"]]}, {"id": "0807.3669", "submitter": "Jean Dezert", "authors": "Jean Dezert (ONERA), Florentin Smarandache", "title": "A new probabilistic transformation of belief mass assignment", "comments": null, "journal-ref": "Fusion 2008 International Conference on Information Fusion,\n  Cologne : Allemagne (2008)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose in Dezert-Smarandache Theory (DSmT) framework, a\nnew probabilistic transformation, called DSmP, in order to build a subjective\nprobability measure from any basic belief assignment defined on any model of\nthe frame of discernment. Several examples are given to show how the DSmP\ntransformation works and we compare it to main existing transformations\nproposed in the literature so far. We show the advantages of DSmP over\nclassical transformations in term of Probabilistic Information Content (PIC).\nThe direct extension of this transformation for dealing with qualitative belief\nassignments is also presented.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2008 13:49:30 GMT"}], "update_date": "2008-07-24", "authors_parsed": [["Dezert", "Jean", "", "ONERA"], ["Smarandache", "Florentin", ""]]}, {"id": "0807.3908", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez", "title": "A Distributed Process Infrastructure for a Distributed Data Structure", "comments": "written as a column for the Semantic Web and Information Systems\n  Bulletin, AIS Special Interest Group on Semantic Web and Information Systems\n  (SIGSEMIS), ISSN: 1556-2301", "journal-ref": null, "doi": null, "report-no": "LA-UR-08-04138", "categories": "cs.AI cs.DL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The Resource Description Framework (RDF) is continuing to grow outside the\nbounds of its initial function as a metadata framework and into the domain of\ngeneral-purpose data modeling. This expansion has been facilitated by the\ncontinued increase in the capacity and speed of RDF database repositories known\nas triple-stores. High-end RDF triple-stores can hold and process on the order\nof 10 billion triples. In an effort to provide a seamless integration of the\ndata contained in RDF repositories, the Linked Data community is providing\nspecifications for linking RDF data sets into a universal distributed graph\nthat can be traversed by both man and machine. While the seamless integration\nof RDF data sets is important, at the scale of the data sets that currently\nexist and will ultimately grow to become, the \"download and index\" philosophy\nof the World Wide Web will not so easily map over to the Semantic Web. This\nessay discusses the importance of adding a distributed RDF process\ninfrastructure to the current distributed RDF data structure.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jul 2008 15:16:16 GMT"}], "update_date": "2008-07-25", "authors_parsed": [["Rodriguez", "Marko A.", ""]]}, {"id": "0807.4417", "submitter": "Daniel Sonntag", "authors": "Daniel Sonntag", "title": "On Introspection, Metacognitive Control and Augmented Data Mining Live\n  Cycles", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss metacognitive modelling as an enhancement to cognitive modelling\nand computing. Metacognitive control mechanisms should enable AI systems to\nself-reflect, reason about their actions, and to adapt to new situations. In\nthis respect, we propose implementation details of a knowledge taxonomy and an\naugmented data mining life cycle which supports a live integration of obtained\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2008 12:05:16 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2009 15:43:21 GMT"}], "update_date": "2009-01-15", "authors_parsed": [["Sonntag", "Daniel", ""]]}, {"id": "0807.4478", "submitter": "Carlos Miravet", "authors": "Carlos Miravet, Luis Pascual, Eloise Krouch, Juan Manuel del Cura", "title": "An Image-Based Sensor System for Autonomous Rendez-Vous with\n  Uncooperative Satellites", "comments": "12 pages, 13 figures. Presented in the 7th International ESA\n  Conference on Guidance, Navigation & Control Systems, Tralee, Ireland, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper are described the image processing algorithms developed by\nSENER, Ingenieria y Sistemas to cope with the problem of image-based,\nautonomous rendez-vous (RV) with an orbiting satellite. The methods developed\nhave a direct application in the OLEV (Orbital Life Extension Extension\nVehicle) mission. OLEV is a commercial mission under development by a\nconsortium formed by Swedish Space Corporation, Kayser-Threde and SENER, aimed\nto extend the operational life of geostationary telecommunication satellites by\nsupplying them control, navigation and guidance services. OLEV is planned to\nuse a set of cameras to determine the angular position and distance to the\nclient satellite during the complete phases of rendez-vous and docking, thus\nenabling the operation with satellites not equipped with any specific\nnavigational aid to provide support during the approach. The ability to operate\nwith un-equipped client satellites significantly expands the range of\napplicability of the system under development, compared to other competing\nvideo technologies already tested in previous spatial missions, such as the\nones described here below.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2008 15:46:02 GMT"}], "update_date": "2008-07-29", "authors_parsed": [["Miravet", "Carlos", ""], ["Pascual", "Luis", ""], ["Krouch", "Eloise", ""], ["del Cura", "Juan Manuel", ""]]}, {"id": "0807.4618", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn", "title": "AceWiki: A Natural and Expressive Semantic Wiki", "comments": "To be published as: Proceedings of Semantic Web User Interaction at\n  CHI 2008: Exploring HCI Challenges, CEUR Workshop Proceedings", "journal-ref": "In Proceedings of the Fifth International Workshop on Semantic Web\n  User Interaction (SWUI 2008), CEUR Workshop Proceedings, Volume 543, 2009", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AceWiki, a prototype of a new kind of semantic wiki using the\ncontrolled natural language Attempto Controlled English (ACE) for representing\nits content. ACE is a subset of English with a restricted grammar and a formal\nsemantics. The use of ACE has two important advantages over existing semantic\nwikis. First, we can improve the usability and achieve a shallow learning\ncurve. Second, ACE is more expressive than the formal languages of existing\nsemantic wikis. Our evaluation shows that people who are not familiar with the\nformal foundations of the Semantic Web are able to deal with AceWiki after a\nvery short learning phase and without the help of an expert.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2008 09:54:44 GMT"}], "update_date": "2009-12-07", "authors_parsed": [["Kuhn", "Tobias", ""]]}, {"id": "0807.4623", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn", "title": "AceWiki: Collaborative Ontology Management in Controlled Natural\n  Language", "comments": null, "journal-ref": "In Proceedings of the 3rd Semantic Wiki Workshop, CEUR Workshop\n  Proceedings, 2008", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AceWiki is a prototype that shows how a semantic wiki using controlled\nnatural language - Attempto Controlled English (ACE) in our case - can make\nontology management easy for everybody. Sentences in ACE can automatically be\ntranslated into first-order logic, OWL, or SWRL. AceWiki integrates the OWL\nreasoner Pellet and ensures that the ontology is always consistent. Previous\nresults have shown that people with no background in logic are able to add\nformal knowledge to AceWiki without being instructed or trained in advance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2008 10:15:38 GMT"}], "update_date": "2008-07-30", "authors_parsed": [["Kuhn", "Tobias", ""]]}, {"id": "0807.4680", "submitter": "Sergio Miguel Tome", "authors": "Sergio Miguel", "title": "Hacia una teoria de unificacion para los comportamientos cognitivos", "comments": "63 pages, 4 figures, Spanish, mistakes erased", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each cognitive science tries to understand a set of cognitive behaviors. The\nstructuring of knowledge of this nature's aspect is far from what it can be\nexpected about a science. Until now universal standard consistently describing\nthe set of cognitive behaviors has not been found, and there are many questions\nabout the cognitive behaviors for which only there are opinions of members of\nthe scientific community. This article has three proposals. The first proposal\nis to raise to the scientific community the necessity of unified the cognitive\nbehaviors. The second proposal is claim the application of the Newton's\nreasoning rules about nature of his book, Philosophiae Naturalis Principia\nMathematica, to the cognitive behaviors. The third is to propose a scientific\ntheory, currently developing, that follows the rules established by Newton to\nmake sense of nature, and could be the theory to explain all the cognitive\nbehaviors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2008 15:11:12 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2008 11:54:51 GMT"}, {"version": "v3", "created": "Sun, 19 Oct 2008 12:01:24 GMT"}], "update_date": "2008-10-19", "authors_parsed": [["Miguel", "Sergio", ""]]}, {"id": "0807.5091", "submitter": "Sujay Sanghavi", "authors": "Sujay Sanghavi, Devavrat Shah and Alan Willsky", "title": "Message-passing for Maximum Weight Independent Set", "comments": "Submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": "10.1109/TIT.2009.2030448", "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of message-passing algorithms for the problem of\nfinding the max-weight independent set (MWIS) in a graph. First, we study the\nperformance of the classical loopy max-product belief propagation. We show that\neach fixed point estimate of max-product can be mapped in a natural way to an\nextreme point of the LP polytope associated with the MWIS problem. However,\nthis extreme point may not be the one that maximizes the value of node weights;\nthe particular extreme point at final convergence depends on the initialization\nof max-product. We then show that if max-product is started from the natural\ninitialization of uninformative messages, it always solves the correct LP -- if\nit converges. This result is obtained via a direct analysis of the iterative\nalgorithm, and cannot be obtained by looking only at fixed points.\n  The tightness of the LP relaxation is thus necessary for max-product\noptimality, but it is not sufficient. Motivated by this observation, we show\nthat a simple modification of max-product becomes gradient descent on (a\nconvexified version of) the dual of the LP, and converges to the dual optimum.\nWe also develop a message-passing algorithm that recovers the primal MWIS\nsolution from the output of the descent algorithm. We show that the MWIS\nestimate obtained using these two algorithms in conjunction is correct when the\ngraph is bipartite and the MWIS is unique.\n  Finally, we show that any problem of MAP estimation for probability\ndistributions over finite domains can be reduced to an MWIS problem. We believe\nthis reduction will yield new insights and algorithms for MAP estimation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jul 2008 15:26:27 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Sanghavi", "Sujay", ""], ["Shah", "Devavrat", ""], ["Willsky", "Alan", ""]]}]