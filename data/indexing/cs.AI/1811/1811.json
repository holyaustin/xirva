[{"id": "1811.00002", "submitter": "Rafael Valle", "authors": "Ryan Prenger, Rafael Valle, Bryan Catanzaro", "title": "WaveGlow: A Flow-based Generative Network for Speech Synthesis", "comments": "5 pages, 1 figure, 1 table, 13 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose WaveGlow: a flow-based network capable of generating\nhigh quality speech from mel-spectrograms. WaveGlow combines insights from Glow\nand WaveNet in order to provide fast, efficient and high-quality audio\nsynthesis, without the need for auto-regression. WaveGlow is implemented using\nonly a single network, trained using only a single cost function: maximizing\nthe likelihood of the training data, which makes the training procedure simple\nand stable. Our PyTorch implementation produces audio samples at a rate of more\nthan 500 kHz on an NVIDIA V100 GPU. Mean Opinion Scores show that it delivers\naudio quality as good as the best publicly available WaveNet implementation.\nAll code will be made publicly available online.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:22:25 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Prenger", "Ryan", ""], ["Valle", "Rafael", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1811.00090", "submitter": "Fangkai Yang", "authors": "Daoming Lyu, Fangkai Yang, Bo Liu, Steven Gustafson", "title": "SDRL: Interpretable and Data-efficient Deep Reinforcement Learning\n  Leveraging Symbolic Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has gained great success by learning\ndirectly from high-dimensional sensory inputs, yet is notorious for the lack of\ninterpretability. Interpretability of the subtasks is critical in hierarchical\ndecision-making as it increases the transparency of black-box-style DRL\napproach and helps the RL practitioners to understand the high-level behavior\nof the system better. In this paper, we introduce symbolic planning into DRL\nand propose a framework of Symbolic Deep Reinforcement Learning (SDRL) that can\nhandle both high-dimensional sensory inputs and symbolic planning. The\ntask-level interpretability is enabled by relating symbolic actions to\noptions.This framework features a planner -- controller -- meta-controller\narchitecture, which takes charge of subtask scheduling, data-driven subtask\nlearning, and subtask evaluation, respectively. The three components\ncross-fertilize each other and eventually converge to an optimal symbolic plan\nalong with the learned subtasks, bringing together the advantages of long-term\nplanning capability with symbolic knowledge and end-to-end reinforcement\nlearning directly from a high-dimensional sensory input. Experimental results\nvalidate the interpretability of subtasks, along with improved data efficiency\ncompared with state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 19:56:06 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 22:24:09 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 23:01:23 GMT"}, {"version": "v4", "created": "Thu, 28 Feb 2019 18:24:19 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Lyu", "Daoming", ""], ["Yang", "Fangkai", ""], ["Liu", "Bo", ""], ["Gustafson", "Steven", ""]]}, {"id": "1811.00102", "submitter": "Mayank Baranwal", "authors": "Amber Srivastava, Mayank Baranwal and Srinivasa Salapaka", "title": "On the Persistence of Clustering Solutions and True Number of Clusters\n  in a Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically clustering algorithms provide clustering solutions with\nprespecified number of clusters. The lack of a priori knowledge on the true\nnumber of underlying clusters in the dataset makes it important to have a\nmetric to compare the clustering solutions with different number of clusters.\nThis article quantifies a notion of persistence of clustering solutions that\nenables comparing solutions with different number of clusters. The persistence\nrelates to the range of data-resolution scales over which a clustering solution\npersists; it is quantified in terms of the maximum over two-norms of all the\nassociated cluster-covariance matrices. Thus we associate a persistence value\nfor each element in a set of clustering solutions with different number of\nclusters. We show that the datasets where natural clusters are a priori known,\nthe clustering solutions that identify the natural clusters are most persistent\n- in this way, this notion can be used to identify solutions with true number\nof clusters. Detailed experiments on a variety of standard and synthetic\ndatasets demonstrate that the proposed persistence-based indicator outperforms\nthe existing approaches, such as, gap-statistic method, $X$-means, $G$-means,\n$PG$-means, dip-means algorithms and information-theoretic method, in\naccurately identifying the clustering solutions with true number of clusters.\nInterestingly, our method can be explained in terms of the phase-transition\nphenomenon in the deterministic annealing algorithm, where the number of\ndistinct cluster centers changes (bifurcates) with respect to an annealing\nparameter.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 20:27:16 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 20:45:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Srivastava", "Amber", ""], ["Baranwal", "Mayank", ""], ["Salapaka", "Srinivasa", ""]]}, {"id": "1811.00128", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Evan Cater, Dipendra Misra, Michael L. Littman", "title": "Towards a Simple Approach to Multi-step Model-based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When environmental interaction is expensive, model-based reinforcement\nlearning offers a solution by planning ahead and avoiding costly mistakes.\nModel-based agents typically learn a single-step transition model. In this\npaper, we propose a multi-step model that predicts the outcome of an action\nsequence with variable length. We show that this model is easy to learn, and\nthat the model can make policy-conditional predictions. We report preliminary\nresults that show a clear advantage for the multi-step model compared to its\none-step counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 21:31:59 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Asadi", "Kavosh", ""], ["Cater", "Evan", ""], ["Misra", "Dipendra", ""], ["Littman", "Michael L.", ""]]}, {"id": "1811.00135", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, Tiancheng Zhao, William Yang Wang", "title": "Dirichlet Variational Autoencoder for Text Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an improved variational autoencoder (VAE) for text modeling with\ntopic information explicitly modeled as a Dirichlet latent variable. By\nproviding the proposed model topic awareness, it is more superior at\nreconstructing input texts. Furthermore, due to the inherent interactions\nbetween the newly introduced Dirichlet variable and the conventional\nmultivariate Gaussian variable, the model is less prone to KL divergence\nvanishing. We derive the variational lower bound for the new model and conduct\nexperiments on four different data sets. The results show that the proposed\nmodel is superior at text reconstruction across the latent space and\nclassifications on learned representations have higher test accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:04:22 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Xiao", "Yijun", ""], ["Zhao", "Tiancheng", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00147", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Vivek Kulkarni, William Yang Wang", "title": "DOLORES: Deep Contextualized Knowledge Graph Embeddings", "comments": "10 pages, 6 figures", "journal-ref": "Automated Knowledge Base Construction (AKBC), 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method DOLORES for learning knowledge graph embeddings\nthat effectively captures contextual cues and dependencies among entities and\nrelations. First, we note that short paths on knowledge graphs comprising of\nchains of entities and relations can encode valuable information regarding\ntheir contextual usage. We operationalize this notion by representing knowledge\ngraphs not as a collection of triples but as a collection of entity-relation\nchains, and learn embeddings for entities and relations using deep neural\nmodels that capture such contextual usage. In particular, our model is based on\nBi-Directional LSTMs and learn deep representations of entities and relations\nfrom constructed entity-relation chains. We show that these representations can\nvery easily be incorporated into existing models to significantly advance the\nstate of the art on several knowledge graph prediction tasks like link\nprediction, triple classification, and missing relation type prediction (in\nsome cases by at least 9.5%).\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:59:57 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Wang", "Haoyu", ""], ["Kulkarni", "Vivek", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00155", "submitter": "Avner May", "authors": "Jian Zhang, Avner May, Tri Dao, Christopher R\\'e", "title": "Low-Precision Random Fourier Features for Memory-Constrained Kernel\n  Approximation", "comments": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to train kernel approximation methods that generalize well\nunder a memory budget. Building on recent theoretical work, we define a measure\nof kernel approximation error which we find to be more predictive of the\nempirical generalization performance of kernel approximation methods than\nconventional metrics. An important consequence of this definition is that a\nkernel approximation matrix must be high rank to attain close approximation.\nBecause storing a high-rank approximation is memory intensive, we propose using\na low-precision quantization of random Fourier features (LP-RFFs) to build a\nhigh-rank approximation under a memory budget. Theoretically, we show\nquantization has a negligible effect on generalization performance in important\nsettings. Empirically, we demonstrate across four benchmark datasets that\nLP-RFFs can match the performance of full-precision RFFs and the Nystr\\\"{o}m\nmethod, with 3x-10x and 50x-460x less memory, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:24:51 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 05:50:12 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Zhang", "Jian", ""], ["May", "Avner", ""], ["Dao", "Tri", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1811.00162", "submitter": "Shang-Yu Su", "authors": "Yu-An Wang, Yu-Kai Huang, Tzu-Chuan Lin, Shang-Yu Su, Yun-Nung Chen", "title": "Modeling Melodic Feature Dependency with Modularized Variational\n  Auto-Encoder", "comments": "The first three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic melody generation has been a long-time aspiration for both AI\nresearchers and musicians. However, learning to generate euphonious melodies\nhas turned out to be highly challenging. This paper introduces 1) a new variant\nof variational autoencoder (VAE), where the model structure is designed in a\nmodularized manner in order to model polyphonic and dynamic music with domain\nknowledge, and 2) a hierarchical encoding/decoding strategy, which explicitly\nmodels the dependency between melodic features. The proposed framework is\ncapable of generating distinct melodies that sounds natural, and the\nexperiments for evaluating generated music clips show that the proposed model\noutperforms the baselines in human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:59:04 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Wang", "Yu-An", ""], ["Huang", "Yu-Kai", ""], ["Lin", "Tzu-Chuan", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1811.00164", "submitter": "Noam Brown", "authors": "Noam Brown, Adam Lerer, Sam Gross, Tuomas Sandholm", "title": "Deep Counterfactual Regret Minimization", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML), 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR) is the leading framework for solving\nlarge imperfect-information games. It converges to an equilibrium by\niteratively traversing the game tree. In order to deal with extremely large\ngames, abstraction is typically applied before running CFR. The abstracted game\nis solved with tabular CFR, and its solution is mapped back to the full game.\nThis process can be problematic because aspects of abstraction are often manual\nand domain specific, abstraction algorithms may miss important strategic\nnuances of the game, and there is a chicken-and-egg problem because determining\na good abstraction requires knowledge of the equilibrium of the game. This\npaper introduces Deep Counterfactual Regret Minimization, a form of CFR that\nobviates the need for abstraction by instead using deep neural networks to\napproximate the behavior of CFR in the full game. We show that Deep CFR is\nprincipled and achieves strong performance in large poker games. This is the\nfirst non-tabular variant of CFR to be successful in large games.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 00:07:02 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:44:39 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 17:53:39 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Brown", "Noam", ""], ["Lerer", "Adam", ""], ["Gross", "Sam", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1811.00196", "submitter": "Qingyu Yin", "authors": "Hui Liu, Qingyu Yin, William Yang Wang", "title": "Towards Explainable NLP: A Generative Explanation Framework for Text\n  Classification", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building explainable systems is a critical problem in the field of Natural\nLanguage Processing (NLP), since most machine learning models provide no\nexplanations for the predictions. Existing approaches for explainable machine\nlearning systems tend to focus on interpreting the outputs or the connections\nbetween inputs and outputs. However, the fine-grained information is often\nignored, and the systems do not explicitly generate the human-readable\nexplanations. To better alleviate this problem, we propose a novel generative\nexplanation framework that learns to make classification decisions and generate\nfine-grained explanations at the same time. More specifically, we introduce the\nexplainable factor and the minimum risk training approach that learn to\ngenerate more reasonable explanations. We construct two new datasets that\ncontain summaries, rating scores, and fine-grained reasons. We conduct\nexperiments on both datasets, comparing with several strong neural network\nbaseline systems. Experimental results show that our method surpasses all\nbaselines on both datasets, and is able to generate concise explanations at the\nsame time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 02:45:57 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 13:12:58 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Hui", ""], ["Yin", "Qingyu", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00198", "submitter": "Yu Hao", "authors": "Hao Yu, Vivek Kulkarni, William Wang", "title": "MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via\n  Network Infused Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many knowledge graph embedding methods operate on triples and are therefore\nimplicitly limited by a very local view of the entire knowledge graph. We\npresent a new framework MOHONE to effectively model higher order network\neffects in knowledge-graphs, thus enabling one to capture varying degrees of\nnetwork connectivity (from the local to the global). Our framework is generic,\nexplicitly models the network scale, and captures two different aspects of\nsimilarity in networks: (a) shared local neighborhood and (b) structural\nrole-based similarity. First, we introduce methods that learn network\nrepresentations of entities in the knowledge graph capturing these varied\naspects of similarity. We then propose a fast, efficient method to incorporate\nthe information captured by these network representations into existing\nknowledge graph embeddings. We show that our method consistently and\nsignificantly improves the performance on link prediction of several different\nknowledge-graph embedding methods including TRANSE, TRANSD, DISTMULT, and\nCOMPLEX(by at least 4 points or 17% in some cases).\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:04:09 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Yu", "Hao", ""], ["Kulkarni", "Vivek", ""], ["Wang", "William", ""]]}, {"id": "1811.00208", "submitter": "Xu Chu", "authors": "Xu Chu, Yang Lin, Jingyue Gao, Jiangtao Wang, Yasha Wang, Leye Wang", "title": "Multi-Label Robust Factorization Autoencoder and its Application in\n  Predicting Drug-Drug Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interactions (DDIs) are a major cause of preventable\nhospitalizations and deaths. Predicting the occurrence of DDIs helps drug\nsafety professionals allocate investigative resources and take appropriate\nregulatory action promptly. Traditional DDI prediction methods predict DDIs\nbased on the similarity between drugs. Recently, researchers revealed that\npredictive performance can be improved by better modeling the interactions\nbetween drug pairs with bilinear forms. However, the shallow models leveraging\nbilinear forms suffer from limitations on capturing complicated nonlinear\ninteractions between drug pairs. To this end, we propose Multi-Label Robust\nFactorization Autoencoder (abbreviated to MuLFA) for DDI prediction, which\nlearns a representation of interactions between drug pairs and has the\ncapability of characterizing complicated nonlinear interactions more precisely.\nMoreover, a novel loss called CuXCov is designed to effectively learn the\nparameters of MuLFA. Furthermore, the decoder is able to generate high-risk\nchemical structures of drug pairs for specific DDIs, assisting pharmacists to\nbetter understand the relationship between drug chemistry and DDI. Experimental\nresults on real-world datasets demonstrate that MuLFA consistently outperforms\nstate-of-the-art methods; particularly, it increases 21:3% predictive\nperformance compared to the best baseline for top 50 frequent DDIs.We also\nillustrate various case studies to demonstrate the efficacy of the chemical\nstructures generated by MuLFA in DDI diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:50:45 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Chu", "Xu", ""], ["Lin", "Yang", ""], ["Gao", "Jingyue", ""], ["Wang", "Jiangtao", ""], ["Wang", "Yasha", ""], ["Wang", "Leye", ""]]}, {"id": "1811.00210", "submitter": "Jie Chen", "authors": "Tengfei Ma, Patrick Ferber, Siyu Huo, Jie Chen, Michael Katz", "title": "Online Planner Selection with Graph Neural Networks and Adaptive\n  Scheduling", "comments": "AAAI 2020. Code is released at\n  https://github.com/matenure/GNN_planner. Data set is released at\n  https://github.com/IBM/IPC-graph-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated planning is one of the foundational areas of AI. Since no single\nplanner can work well for all tasks and domains, portfolio-based techniques\nhave become increasingly popular in recent years. In particular, deep learning\nemerges as a promising methodology for online planner selection. Owing to the\nrecent development of structural graph representations of planning tasks, we\npropose a graph neural network (GNN) approach to selecting candidate planners.\nGNNs are advantageous over a straightforward alternative, the convolutional\nneural networks, in that they are invariant to node permutations and that they\nincorporate node labels for better inference.\n  Additionally, for cost-optimal planning, we propose a two-stage adaptive\nscheduling method to further improve the likelihood that a given task is solved\nin time. The scheduler may switch at halftime to a different planner,\nconditioned on the observed performance of the first one. Experimental results\nvalidate the effectiveness of the proposed method against strong baselines,\nboth deep learning and non-deep learning based.\n  The code is available at \\url{https://github.com/matenure/GNN_planner}.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:51:32 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 02:15:12 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 20:32:03 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 16:16:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ma", "Tengfei", ""], ["Ferber", "Patrick", ""], ["Huo", "Siyu", ""], ["Chen", "Jie", ""], ["Katz", "Michael", ""]]}, {"id": "1811.00222", "submitter": "Kaidi Cao", "authors": "Kaidi Cao, Jing Liao, Lu Yuan", "title": "CariGANs: Unpaired Photo-to-Caricature Translation", "comments": "To appear at SIGGRAPH Asia 2018", "journal-ref": "ACM Transactions on Graphics, Vol. 37, No. 6, Article 244.\n  Publication date: November 2018", "doi": "10.1145/3272127.3275046", "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial caricature is an art form of drawing faces in an exaggerated way to\nconvey humor or sarcasm. In this paper, we propose the first Generative\nAdversarial Network (GAN) for unpaired photo-to-caricature translation, which\nwe call \"CariGANs\". It explicitly models geometric exaggeration and appearance\nstylization using two components: CariGeoGAN, which only models the\ngeometry-to-geometry transformation from face photos to caricatures, and\nCariStyGAN, which transfers the style appearance from caricatures to face\nphotos without any geometry deformation. In this way, a difficult cross-domain\ntranslation problem is decoupled into two easier tasks. The perceptual study\nshows that caricatures generated by our CariGANs are closer to the hand-drawn\nones, and at the same time better persevere the identity, compared to\nstate-of-the-art methods. Moreover, our CariGANs allow users to control the\nshape exaggeration degree and change the color/texture style by tuning the\nparameters or giving an example caricature.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 04:39:20 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 03:47:13 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Cao", "Kaidi", ""], ["Liao", "Jing", ""], ["Yuan", "Lu", ""]]}, {"id": "1811.00239", "submitter": "Lili Mou", "authors": "Nabiha Asghar, Lili Mou, Kira A. Selby, Kevin D. Pantasdo, Pascal\n  Poupart, Xin Jiang", "title": "Progressive Memory Banks for Incremental Domain Adaptation", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of incremental domain adaptation (IDA) in\nnatural language processing (NLP). We assume each domain comes one after\nanother, and that we could only access data in the current domain. The goal of\nIDA is to build a unified model performing well on all the domains that we have\nencountered. We adopt the recurrent neural network (RNN) widely used in NLP,\nbut augment it with a directly parameterized memory bank, which is retrieved by\nan attention mechanism at each step of RNN transition. The memory bank provides\na natural way of IDA: when adapting our model to a new domain, we progressively\nadd new slots to the memory bank, which increases the number of parameters, and\nthus the model capacity. We learn the new memory slots and fine-tune existing\nparameters by back-propagation. Experimental results show that our approach\nachieves significantly better performance than fine-tuning alone. Compared with\nexpanding hidden states, our approach is more robust for old domains, shown by\nboth empirical and theoretical results. Our model also outperforms previous\nwork of IDA including elastic weight consolidation and progressive neural\nnetworks in the experiments.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 05:22:01 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 04:04:14 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Asghar", "Nabiha", ""], ["Mou", "Lili", ""], ["Selby", "Kira A.", ""], ["Pantasdo", "Kevin D.", ""], ["Poupart", "Pascal", ""], ["Jiang", "Xin", ""]]}, {"id": "1811.00260", "submitter": "Edoardo Conti", "authors": "Jason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen\n  He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye, Zhengxing Chen, Scott\n  Fujimoto", "title": "Horizon: Facebook's Open Source Applied Reinforcement Learning Platform", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Horizon, Facebook's open source applied\nreinforcement learning (RL) platform. Horizon is an end-to-end platform\ndesigned to solve industry applied RL problems where datasets are large\n(millions to billions of observations), the feedback loop is slow (vs. a\nsimulator), and experiments must be done with care because they don't run in a\nsimulator. Unlike other RL platforms, which are often designed for fast\nprototyping and experimentation, Horizon is designed with production use cases\nas top of mind. The platform contains workflows to train popular deep RL\nalgorithms and includes data preprocessing, feature transformation, distributed\ntraining, counterfactual policy evaluation, optimized serving, and a\nmodel-based data understanding tool. We also showcase and describe real\nexamples where reinforcement learning models trained with Horizon significantly\noutperformed and replaced supervised learning systems at Facebook.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:02:45 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 22:49:50 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 05:57:02 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 20:47:42 GMT"}, {"version": "v5", "created": "Wed, 4 Sep 2019 19:30:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gauci", "Jason", ""], ["Conti", "Edoardo", ""], ["Liang", "Yitao", ""], ["Virochsiri", "Kittipat", ""], ["He", "Yuchen", ""], ["Kaden", "Zachary", ""], ["Narayanan", "Vivek", ""], ["Ye", "Xiaohui", ""], ["Chen", "Zhengxing", ""], ["Fujimoto", "Scott", ""]]}, {"id": "1811.00265", "submitter": "Rui Wang", "authors": "Rui Wang and Deyu Zhou and Yulan He", "title": "ATM:Adversarial-neural Topic Model", "comments": "Published at the journal Information Processing & Management", "journal-ref": "Information Processing & Management, Volume 56, Issue 6, November\n  2019, 102098", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are widely used for thematic structure discovery in text. But\ntraditional topic models often require dedicated inference procedures for\nspecific tasks at hand. Also, they are not designed to generate word-level\nsemantic representations. To address these limitations, we propose a topic\nmodeling approach based on Generative Adversarial Nets (GANs), called\nAdversarial-neural Topic Model (ATM). The proposed ATM models topics with\nDirichlet prior and employs a generator network to capture the semantic\npatterns among latent topics. Meanwhile, the generator could also produce\nword-level semantic representations. To illustrate the feasibility of porting\nATM to tasks other than topic modeling, we apply ATM for open domain event\nextraction. Our experimental results on the two public corpora show that ATM\ngenerates more coherence topics, outperforming a number of competitive\nbaselines. Moreover, ATM is able to extract meaningful events from news\narticles.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 07:18:31 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 09:34:04 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wang", "Rui", ""], ["Zhou", "Deyu", ""], ["He", "Yulan", ""]]}, {"id": "1811.00323", "submitter": "Emna Krichen Tn", "authors": "Emna Krichene, Wael Ouarda, Habib Chabchoub, Adel M. Alimi", "title": "Taylor-based Optimized Recursive Extended Exponential Smoothed Neural\n  Networks Forecasting Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A newly introduced method called Taylor-based Optimized Recursive Extended\nExponential Smoothed Neural Networks Forecasting method is applied and extended\nin this study to forecast numerical values. Unlike traditional forecasting\ntechniques which forecast only future values, our proposed method provides a\nnew extension to correct the predicted values which is done by forecasting the\nestimated error. Experimental results demonstrated that the proposed method has\na high accuracy both in training and testing data and outperform the\nstate-of-the-art RNN models on Mackey-Glass, NARMA, Lorenz and Henon map\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 11:39:49 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Krichene", "Emna", ""], ["Ouarda", "Wael", ""], ["Chabchoub", "Habib", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1811.00401", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "J\\\"orn-Henrik Jacobsen, Jens Behrmann, Richard Zemel, Matthias Bethge", "title": "Excessive Invariance Causes Adversarial Vulnerability", "comments": null, "journal-ref": "Proceedings of the 7th International Conference on Learning\n  Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their impressive performance, deep neural networks exhibit striking\nfailures on out-of-distribution inputs. One core idea of adversarial example\nresearch is to reveal neural network errors under such distribution shifts. We\ndecompose these errors into two complementary sources: sensitivity and\ninvariance. We show deep networks are not only too sensitive to task-irrelevant\nchanges of their input, as is well-known from epsilon-adversarial examples, but\nare also too invariant to a wide range of task-relevant changes, thus making\nvast regions in input space vulnerable to adversarial attacks. We show such\nexcessive invariance occurs across various tasks and architecture types. On\nMNIST and ImageNet one can manipulate the class-specific content of almost any\nimage without changing the hidden activations. We identify an insufficiency of\nthe standard cross-entropy loss as a reason for these failures. Further, we\nextend this objective based on an information-theoretic analysis so it\nencourages the model to consider all task-dependent features in its decision.\nThis provides the first approach tailored explicitly to overcome excessive\ninvariance and resulting vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 14:14:03 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 03:26:21 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 04:12:20 GMT"}, {"version": "v4", "created": "Sun, 12 Jul 2020 07:26:06 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Jacobsen", "J\u00f6rn-Henrik", ""], ["Behrmann", "Jens", ""], ["Zemel", "Richard", ""], ["Bethge", "Matthias", ""]]}, {"id": "1811.00426", "submitter": "Christopher Iliffe Sprague", "authors": "Christopher Iliffe Sprague, \\\"Ozer \\\"Ozkahraman, Andrea Munafo, Rachel\n  Marlow, Alexander Phillips, Petter \\\"Ogren", "title": "Improving the Modularity of AUV Control Systems using Behaviour Trees", "comments": "Submitted to 2018 IEEE OES Autonomous Underwater Vehicle Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how behaviour trees (BTs) can be used to design\nmodular, versatile, and robust control architectures for mission-critical\nsystems. In particular, we show this in the context of autonomous underwater\nvehicles (AUVs). Robustness, in terms of system safety, is important since\nmanual recovery of AUVs is often extremely difficult. Further more, versatility\nis important to be able to execute many different kinds of missions. Finally,\nmodularity is needed to achieve a combination of robustness and versatility, as\nthe complexity of a versatile systems needs to be encapsulated in modules, in\norder to create a simple overall structure enabling robustness analysis. The\nproposed design is illustrated using a typical AUV mission.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:13:49 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Sprague", "Christopher Iliffe", ""], ["\u00d6zkahraman", "\u00d6zer", ""], ["Munafo", "Andrea", ""], ["Marlow", "Rachel", ""], ["Phillips", "Alexander", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1811.00458", "submitter": "Di Chen", "authors": "Di Chen, Carla P. Gomes", "title": "Bias Reduction via End-to-End Shift Learning: Application to Citizen\n  Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen science projects are successful at gathering rich datasets for\nvarious applications. However, the data collected by citizen scientists are\noften biased --- in particular, aligned more with the citizens' preferences\nthan with scientific objectives. We propose the Shift Compensation Network\n(SCN), an end-to-end learning scheme which learns the shift from the scientific\nobjectives to the biased data while compensating for the shift by re-weighting\nthe training data. Applied to bird observational data from the citizen science\nproject eBird, we demonstrate how SCN quantifies the data distribution shift\nand outperforms supervised learning models that do not address the data bias.\nCompared with competing models in the context of covariate shift, we further\ndemonstrate the advantage of SCN in both its effectiveness and its capability\nof handling massive high-dimensional data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 15:54:30 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 21:32:48 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 17:36:08 GMT"}, {"version": "v4", "created": "Wed, 14 Nov 2018 05:35:37 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Di", ""], ["Gomes", "Carla P.", ""]]}, {"id": "1811.00482", "submitter": "Xiaofan Xu", "authors": "Xiaofan Xu, Mi Sun Park, Cormac Brick", "title": "Hybrid Pruning: Thinner Sparse Networks for Fast Inference on Edge\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce hybrid pruning which combines both coarse-grained channel and\nfine-grained weight pruning to reduce model size, computation and power demands\nwith no to little loss in accuracy for enabling modern networks deployment on\nresource-constrained devices, such as always-on security cameras and drones.\nAdditionally, to effectively perform channel pruning, we propose a fast\nsensitivity test that helps us quickly identify the sensitivity of within and\nacross layers of a network to the output accuracy for target multiplier\naccumulators (MACs) or accuracy tolerance. Our experiment shows significantly\nbetter results on ResNet50 on ImageNet compared to existing work, even with an\nadditional constraint of channels be hardware-friendly number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 16:24:50 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Xu", "Xiaofan", ""], ["Park", "Mi Sun", ""], ["Brick", "Cormac", ""]]}, {"id": "1811.00497", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Songpeng Zu, Chengliang Gao, Yuan Zhang, and Wei Feng", "title": "Modeling Attention Flow on Graphs", "comments": "NeurIPS 2018 Relational Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world scenarios demand reasoning about process, more than final outcome\nprediction, to discover latent causal chains and better understand complex\nsystems. It requires the learning algorithms to offer both accurate predictions\nand clear interpretations. We design a set of trajectory reasoning tasks on\ngraphs with only the source and the destination observed. We present the\nattention flow mechanism to explicitly model the reasoning process, leveraging\nthe relational inductive biases by basing our models on graph networks. We\nstudy the way attention flow can effectively act on the underlying information\nflow implemented by message passing. Experiments demonstrate that the attention\nflow driven by and interacting with graph networks can provide higher accuracy\nin prediction and better interpretation for trajectory reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 16:59:54 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 08:59:30 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Xu", "Xiaoran", ""], ["Zu", "Songpeng", ""], ["Gao", "Chengliang", ""], ["Zhang", "Yuan", ""], ["Feng", "Wei", ""]]}, {"id": "1811.00512", "submitter": "Renato Negrinho", "authors": "Renato Negrinho, Matthew R. Gormley, Geoffrey J. Gordon", "title": "Learning Beam Search Policies via Imitation Learning", "comments": "Published in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is widely used for approximate decoding in structured prediction\nproblems. Models often use a beam at test time but ignore its existence at\ntrain time, and therefore do not explicitly learn how to use the beam. We\ndevelop an unifying meta-algorithm for learning beam search policies using\nimitation learning. In our setting, the beam is part of the model, and not just\nan artifact of approximate decoding. Our meta-algorithm captures existing\nlearning algorithms and suggests new ones. It also lets us show novel no-regret\nguarantees for learning beam search policies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:31:10 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 17:15:37 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Negrinho", "Renato", ""], ["Gormley", "Matthew R.", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1811.00521", "submitter": "Bryan He", "authors": "Bryan He, James Zou", "title": "Minimizing Close-k Aggregate Loss Improves Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classification, the de facto method for aggregating individual losses is\nthe average loss. When the actual metric of interest is 0-1 loss, it is common\nto minimize the average surrogate loss for some well-behaved (e.g. convex)\nsurrogate. Recently, several other aggregate losses such as the maximal loss\nand average top-$k$ loss were proposed as alternative objectives to address\nshortcomings of the average loss. However, we identify common classification\nsettings, e.g. the data is imbalanced, has too many easy or ambiguous examples,\netc., when average, maximal and average top-$k$ all suffer from suboptimal\ndecision boundaries, even on an infinitely large training set. To address this\nproblem, we propose a new classification objective called the close-$k$\naggregate loss, where we adaptively minimize the loss for points close to the\ndecision boundary. We provide theoretical guarantees for the 0-1 accuracy when\nwe optimize close-$k$ aggregate loss. We also conduct systematic experiments\nacross the PMLB and OpenML benchmark datasets. Close-$k$ achieves significant\ngains in 0-1 test accuracy, improvements of $\\geq 2$% and $p<0.05$, in over 25%\nof the datasets compared to average, maximal and average top-$k$. In contrast,\nthe previous aggregate losses outperformed close-$k$ in less than 2% of the\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:42:18 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 17:39:14 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["He", "Bryan", ""], ["Zou", "James", ""]]}, {"id": "1811.00614", "submitter": "Mehrnoosh Sadrzadeh", "authors": "Mehrnoosh Sadrzadeh, Matthew Purver, Julian Hough, Ruth Kempson", "title": "Exploring Semantic Incrementality with Dynamic Syntax and Vector Space\n  Semantics", "comments": "accepted in SemDial 2018:\n  https://semdial.hypotheses.org/program/accepted-papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental requirements for models of semantic processing in\ndialogue is incrementality: a model must reflect how people interpret and\ngenerate language at least on a word-by-word basis, and handle phenomena such\nas fragments, incomplete and jointly-produced utterances. We show that the\nincremental word-by-word parsing process of Dynamic Syntax (DS) can be assigned\na compositional distributional semantics, with the composition operator of DS\ncorresponding to the general operation of tensor contraction from multilinear\nalgebra. We provide abstract semantic decorations for the nodes of DS trees, in\nterms of vectors, tensors, and sums thereof; using the latter to model the\nunderspecified elements crucial to assigning partial representations during\nincremental processing. As a working example, we give an instantiation of this\ntheory using plausibility tensors of compositional distributional semantics,\nand show how our framework can incrementally assign a semantic plausibility\nmeasure as it parses phrases and sentences.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 19:59:06 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Sadrzadeh", "Mehrnoosh", ""], ["Purver", "Matthew", ""], ["Hough", "Julian", ""], ["Kempson", "Ruth", ""]]}, {"id": "1811.00631", "submitter": "Rados{\\l}aw Piliszek", "authors": "Rados{\\l}aw Piliszek, Krzysztof Mnich, Szymon Migacz, Pawe{\\l}\n  Tabaszewski, Andrzej Su{\\l}ecki, Aneta Polewko-Klim and Witold Rudnicki", "title": "MDFS - MultiDimensional Feature Selection", "comments": "12 pages, 3 figures, 5 tables, license: CC-BY", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identification of informative variables in an information system is often\nperformed using simple one-dimensional filtering procedures that discard\ninformation about interactions between variables. Such approach may result in\nremoving some relevant variables from consideration. Here we present an R\npackage MDFS (MultiDimensional Feature Selection) that performs identification\nof informative variables taking into account synergistic interactions between\nmultiple descriptors and the decision variable. MDFS is an implementation of an\nalgorithm based on information theory. Computational kernel of the package is\nimplemented in C++. A high-performance version implemented in CUDA C is also\navailable. The applications of MDFS are demonstrated using the well-known\nMadelon dataset that has synergistic variables by design. The dataset comes\nfrom the UCI Machine Learning Repository. It is shown that multidimensional\nanalysis is more sensitive than one-dimensional tests and returns more reliable\nrankings of importance.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 12:22:14 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Piliszek", "Rados\u0142aw", ""], ["Mnich", "Krzysztof", ""], ["Migacz", "Szymon", ""], ["Tabaszewski", "Pawe\u0142", ""], ["Su\u0142ecki", "Andrzej", ""], ["Polewko-Klim", "Aneta", ""], ["Rudnicki", "Witold", ""]]}, {"id": "1811.00671", "submitter": "Sean Welleck", "authors": "Sean Welleck, Jason Weston, Arthur Szlam, Kyunghyun Cho", "title": "Dialogue Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistency is a long standing issue faced by dialogue models. In this paper,\nwe frame the consistency of dialogue agents as natural language inference (NLI)\nand create a new natural language inference dataset called Dialogue NLI. We\npropose a method which demonstrates that a model trained on Dialogue NLI can be\nused to improve the consistency of a dialogue model, and evaluate the method\nwith human evaluation and with automatic metrics on a suite of evaluation sets\ndesigned to measure a dialogue model's consistency.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:10:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 01:08:01 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Welleck", "Sean", ""], ["Weston", "Jason", ""], ["Szlam", "Arthur", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1811.00681", "submitter": "Yaliang Li", "authors": "Sheng Shen, Yaliang Li, Nan Du, Xian Wu, Yusheng Xie, Shen Ge, Tao\n  Yang, Kai Wang, Xingzheng Liang, Wei Fan", "title": "On the Generation of Medical Question-Answer Pairs", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has achieved promising progress recently. However,\nanswering a question in real-world scenarios like the medical domain is still\nchallenging, due to the requirement of external knowledge and the insufficient\nquantity of high-quality training data. In the light of these challenges, we\nstudy the task of generating medical QA pairs in this paper. With the insight\nthat each medical question can be considered as a sample from the latent\ndistribution of questions given answers, we propose an automated medical QA\npair generation framework, consisting of an unsupervised key phrase detector\nthat explores unstructured material for validity, and a generator that involves\na multi-pass decoder to integrate structural knowledge for diversity. A series\nof experiments have been conducted on a real-world dataset collected from the\nNational Medical Licensing Examination of China. Both automatic evaluation and\nhuman annotation demonstrate the effectiveness of the proposed method. Further\ninvestigation shows that, by incorporating the generated QA pairs for training,\nsignificant improvement in terms of accuracy can be achieved for the\nexamination QA system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:50:43 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:58:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Shen", "Sheng", ""], ["Li", "Yaliang", ""], ["Du", "Nan", ""], ["Wu", "Xian", ""], ["Xie", "Yusheng", ""], ["Ge", "Shen", ""], ["Yang", "Tao", ""], ["Wang", "Kai", ""], ["Liang", "Xingzheng", ""], ["Fan", "Wei", ""]]}, {"id": "1811.00692", "submitter": "Yuanpeng Li", "authors": "Yuanpeng Li, Yi Yang, Jianyu Wang, Wei Xu", "title": "Zero-Shot Transfer VQA Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring a large vocabulary is an important aspect of human intelligence.\nOnecommon approach for human to populating vocabulary is to learn words\nduringreading or listening, and then use them in writing or speaking. This\nability totransfer from input to output is natural for human, but it is\ndifficult for machines.Human spontaneously performs this knowledge transfer in\ncomplicated multimodaltasks, such as Visual Question Answering (VQA). In order\nto approach human-levelArtificial Intelligence, we hope to equip machines with\nsuch ability. Therefore, toaccelerate this research, we propose a newzero-shot\ntransfer VQA(ZST-VQA)dataset by reorganizing the existing VQA v1.0 dataset in\nthe way that duringtraining, some words appear only in one module (i.e.\nquestions) but not in theother (i.e. answers). In this setting, an intelligent\nmodel should understand andlearn the concepts from one module (i.e. questions),\nand at test time, transfer themto the other (i.e. predict the concepts as\nanswers). We conduct evaluation on thisnew dataset using three existing\nstate-of-the-art VQA neural models. Experimentalresults show a significant drop\nin performance on this dataset, indicating existingmethods do not address the\nzero-shot transfer problem. Besides, our analysis findsthat this may be caused\nby the implicit bias learned during training.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 01:02:49 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Li", "Yuanpeng", ""], ["Yang", "Yi", ""], ["Wang", "Jianyu", ""], ["Xu", "Wei", ""]]}, {"id": "1811.00740", "submitter": "Xiaoyu Wang", "authors": "Xiaoyu Wang, Cailian Chen, Yang Min, Jianping He, Bo Yang, Yang Zhang", "title": "Efficient Metropolitan Traffic Prediction Based on Graph Recurrent\n  Neural Network", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic prediction is a fundamental and vital task in Intelligence\nTransportation System (ITS), but it is very challenging to get high accuracy\nwhile containing low computational complexity due to the spatiotemporal\ncharacteristics of traffic flow, especially under the metropolitan\ncircumstances. In this work, a new topological framework, called Linkage\nNetwork, is proposed to model the road networks and present the propagation\npatterns of traffic flow. Based on the Linkage Network model, a novel online\npredictor, named Graph Recurrent Neural Network (GRNN), is designed to learn\nthe propagation patterns in the graph. It could simultaneously predict traffic\nflow for all road segments based on the information gathered from the whole\ngraph, which thus reduces the computational complexity significantly from O(nm)\nto O(n+m), while keeping the high accuracy. Moreover, it can also predict the\nvariations of traffic trends. Experiments based on real-world data demonstrate\nthat the proposed method outperforms the existing prediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:08:40 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Wang", "Xiaoyu", ""], ["Chen", "Cailian", ""], ["Min", "Yang", ""], ["He", "Jianping", ""], ["Yang", "Bo", ""], ["Zhang", "Yang", ""]]}, {"id": "1811.00746", "submitter": "Michelle Zhou", "authors": "Jingyi Li, Michelle X. Zhou, Huahai Yang, Gloria Mark", "title": "Confiding in and Listening to Virtual Agents: The Effect of Personality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an intelligent virtual interviewer that engages with a user in a\ntext-based conversation and automatically infers the user's psychological\ntraits, such as personality. We investigate how the personality of a virtual\ninterviewer influences a user's behavior from two perspectives: the user's\nwillingness to confide in, and listen to, a virtual interviewer. We have\ndeveloped two virtual interviewers with distinct personalities and deployed\nthem in a real-world recruiting event. We present findings from completed\ninterviews with 316 actual job applicants. Notably, users are more willing to\nconfide in and listen to a virtual interviewer with a serious, assertive\npersonality. Moreover, users' personality traits, inferred from their chat\ntext, influence their perception of a virtual interviewer, and their\nwillingness to confide in and listen to a virtual interviewer. Finally, we\ndiscuss the implications of our work on building hyper-personalized,\nintelligent agents based on user traits.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:50:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Li", "Jingyi", ""], ["Zhou", "Michelle X.", ""], ["Yang", "Huahai", ""], ["Mark", "Gloria", ""]]}, {"id": "1811.00770", "submitter": "Ray Oshikawa", "authors": "Ray Oshikawa, Jing Qian, William Yang Wang", "title": "A Survey on Natural Language Processing for Fake News Detection", "comments": "11 pages, no figure, Accepted to LREC 2020", "journal-ref": "Proceedings of the 12th Language Resources and Evaluation\n  Conference (LREC 2020) pp. 6086-6093", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 08:10:21 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:40:56 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Oshikawa", "Ray", ""], ["Qian", "Jing", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00796", "submitter": "Mitsuru Kusumoto", "authors": "Mitsuru Kusumoto, Keisuke Yahata, Masahiro Sakai", "title": "Automated Theorem Proving in Intuitionistic Propositional Logic by Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem-solving in automated theorem proving (ATP) can be interpreted as\na search problem where the prover constructs a proof tree step by step. In this\npaper, we propose a deep reinforcement learning algorithm for proof search in\nintuitionistic propositional logic. The most significant challenge in the\napplication of deep learning to the ATP is the absence of large, public theorem\ndatabase. We, however, overcame this issue by applying a novel data\naugmentation procedure at each iteration of the reinforcement learning. We also\nimprove the efficiency of the algorithm by representing the syntactic structure\nof formulas by a novel compact graph representation. Using the large volume of\naugmented data, we train highly accurate graph neural networks that approximate\nthe value function for the set of the syntactic structures of formulas. Our\nmethod is also cost-efficient in terms of computational time. We will show that\nour prover outperforms Coq's $\\texttt{tauto}$ tactic, a prover based on\nhuman-engineered heuristics. Within the specified time limit, our prover solved\n84% of the theorems in a benchmark library, while $\\texttt{tauto}$ was able to\nsolve only 52%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 09:49:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Kusumoto", "Mitsuru", ""], ["Yahata", "Keisuke", ""], ["Sakai", "Masahiro", ""]]}, {"id": "1811.00797", "submitter": "Natalia Soboleva", "authors": "Anton Andreychuk (1), Natalia Soboleva (2), Konstantin Yakovlev (2, 3,\n  4) ((1) Peoples' Friendship University of Russia, (2) National Research\n  University Higher School of Economics, (3) Federal Research Center ''Computer\n  Science and Control'' of Russian Academy of Sciences, (4) Moscow Institute of\n  Physics and Technology )", "title": "eLIAN: Enhanced Algorithm for Angle-constrained Path Finding", "comments": null, "journal-ref": "Kuznetsov S., Osipov G., Stefanuk V. (eds) Artificial\n  Intelligence. RCAI 2018. Communications in Computer and Information Science,\n  vol 934. Springer, Cham", "doi": "10.1007/978-3-030-00617-4_19", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problem of finding 2D paths of special shape, e.g. paths comprised of line\nsegments having the property that the angle between any two consecutive\nsegments does not exceed the predefined threshold, is considered in the paper.\nThis problem is harder to solve than the one when shortest paths of any shape\nare sought, since the planer's search space is substantially bigger as multiple\nsearch nodes corresponding to the same location need to be considered. One way\nto reduce the search effort is to fix the length of the path's segment and to\nprune the nodes that violate the imposed constraint. This leads to\nincompleteness and to the sensitivity of the 's performance to chosen parameter\nvalue. In this work we introduce a novel technique that reduces this\nsensitivity by automatically adjusting the length of the path's segment\non-the-fly, e.g. during the search. Embedding this technique into the known\ngrid-based angle-constrained path finding algorithm - LIAN, leads to notable\nincrease of the planner's effectiveness, e.g. success rate, while keeping\nefficiency, e.g. runtime, overhead at reasonable level. Experimental evaluation\nshows that LIAN with the suggested enhancements, dubbed eLIAN, solves up to\n20\\% of tasks more compared to the predecessor. Meanwhile, the solution quality\nof eLIAN is nearly the same as the one of LIAN.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 09:54:35 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Andreychuk", "Anton", ""], ["Soboleva", "Natalia", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1811.00839", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang,\n  P. Sadayappan and Srinivasan Parthasarathy", "title": "ATP: Directed Graph Embedding with Asymmetric Transitivity Preservation", "comments": "has been accepted to the Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI 2019), acceptance rate: 1150/7095 = 16.2%", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs have been widely used in Community Question Answering\nservices (CQAs) to model asymmetric relationships among different types of\nnodes in CQA graphs, e.g., question, answer, user. Asymmetric transitivity is\nan essential property of directed graphs, since it can play an important role\nin downstream graph inference and analysis. Question difficulty and user\nexpertise follow the characteristic of asymmetric transitivity. Maintaining\nsuch properties, while reducing the graph to a lower dimensional vector\nembedding space, has been the focus of much recent research. In this paper, we\ntackle the challenge of directed graph embedding with asymmetric transitivity\npreservation and then leverage the proposed embedding method to solve a\nfundamental task in CQAs: how to appropriately route and assign newly posted\nquestions to users with the suitable expertise and interest in CQAs. The\ntechnique incorporates graph hierarchy and reachability information naturally\nby relying on a non-linear transformation that operates on the core\nreachability and implicit hierarchy within such graphs. Subsequently, the\nmethodology levers a factorization-based approach to generate two embedding\nvectors for each node within the graph, to capture the asymmetric transitivity.\nExtensive experiments show that our framework consistently and significantly\noutperforms the state-of-the-art baselines on two diverse real-world tasks:\nlink prediction, and question difficulty estimation and expert finding in\nonline forums like Stack Exchange. Particularly, our framework can support\ninductive embedding learning for newly posted questions (unseen nodes during\ntraining), and therefore can properly route and assign these kinds of questions\nto experts in CQAs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 12:45:16 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 14:25:49 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Sun", "Jiankai", ""], ["Bandyopadhyay", "Bortik", ""], ["Bashizade", "Armin", ""], ["Liang", "Jiongqian", ""], ["Sadayappan", "P.", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1811.00875", "submitter": "Sandro Sozzo", "authors": "Sandro Sozzo", "title": "Quantum Structures in Human Decision-making: Towards Quantum Expected\n  Utility", "comments": "13 pages, 1 figure, standard LateX", "journal-ref": null, "doi": "10.1007/s10773-019-04022-w", "report-no": null, "categories": "cs.AI econ.GN q-bio.NC q-fin.EC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {\\it Ellsberg thought experiments} and empirical confirmation of Ellsberg\npreferences pose serious challenges to {\\it subjective expected utility theory}\n(SEUT). We have recently elaborated a quantum-theoretic framework for human\ndecisions under uncertainty which satisfactorily copes with the Ellsberg\nparadox and other puzzles of SEUT. We apply here the quantum-theoretic\nframework to the {\\it Ellsberg two-urn example}, showing that the paradox can\nbe explained by assuming a state change of the conceptual entity that is the\nobject of the decision ({\\it decision-making}, or {\\it DM}, {\\it entity}) and\nrepresenting subjective probabilities by quantum probabilities. We also model\nthe empirical data we collected in a DM test on human participants within the\ntheoretic framework above. The obtained results are relevant, as they provide a\nline to model real life, e.g., financial and medical, decisions that show the\nsame empirical patterns as the two-urn experiment.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:29:51 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Sozzo", "Sandro", ""]]}, {"id": "1811.00937", "submitter": "Alon Talmor", "authors": "Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant", "title": "CommonsenseQA: A Question Answering Challenge Targeting Commonsense\n  Knowledge", "comments": "accepted as a long paper at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering a question, people often draw upon their rich world knowledge\nin addition to the particular context. Recent work has focused primarily on\nanswering questions given some relevant document or context, and required very\nlittle general background. To investigate question answering with prior\nknowledge, we present CommonsenseQA: a challenging new dataset for commonsense\nquestion answering. To capture common sense beyond associations, we extract\nfrom ConceptNet (Speer et al., 2017) multiple target concepts that have the\nsame semantic relation to a single source concept. Crowd-workers are asked to\nauthor multiple-choice questions that mention the source concept and\ndiscriminate in turn between each of the target concepts. This encourages\nworkers to create questions with complex semantics that often require prior\nknowledge. We create 12,247 questions through this procedure and demonstrate\nthe difficulty of our task with a large number of strong baselines. Our best\nbaseline is based on BERT-large (Devlin et al., 2018) and obtains 56% accuracy,\nwell below human performance, which is 89%.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:34:29 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 18:02:58 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Talmor", "Alon", ""], ["Herzig", "Jonathan", ""], ["Lourie", "Nicholas", ""], ["Berant", "Jonathan", ""]]}, {"id": "1811.00958", "submitter": "Bo Liu", "authors": "Bo Liu and Luwan Zhang and Ji Liu", "title": "Dantzig Selector with an Approximately Optimal Denoising Matrix and its\n  Application to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dantzig Selector (DS) is widely used in compressed sensing and sparse\nlearning for feature selection and sparse signal recovery. Since the DS\nformulation is essentially a linear programming optimization, many existing\nlinear programming solvers can be simply applied for scaling up. The DS\nformulation can be explained as a basis pursuit denoising problem, wherein the\ndata matrix (or measurement matrix) is employed as the denoising matrix to\neliminate the observation noise. However, we notice that the data matrix may\nnot be the optimal denoising matrix, as shown by a simple counter-example. This\nmotivates us to pursue a better denoising matrix for defining a general DS\nformulation. We first define the optimal denoising matrix through a minimax\noptimization, which turns out to be an NPhard problem. To make the problem\ncomputationally tractable, we propose a novel algorithm, termed as Optimal\nDenoising Dantzig Selector (ODDS), to approximately estimate the optimal\ndenoising matrix. Empirical experiments validate the proposed method. Finally,\na novel sparse reinforcement learning algorithm is formulated by extending the\nproposed ODDS algorithm to temporal difference learning, and empirical\nexperimental results demonstrate to outperform the conventional vanilla DS-TD\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:15:14 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Liu", "Bo", ""], ["Zhang", "Luwan", ""], ["Liu", "Ji", ""]]}, {"id": "1811.00995", "submitter": "J\\\"orn-Henrik Jacobsen", "authors": "Jens Behrmann, Will Grathwohl, Ricky T. Q. Chen, David Duvenaud,\n  J\\\"orn-Henrik Jacobsen", "title": "Invertible Residual Networks", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning\n  (ICML), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that standard ResNet architectures can be made invertible, allowing\nthe same model to be used for classification, density estimation, and\ngeneration. Typically, enforcing invertibility requires partitioning dimensions\nor restricting network architectures. In contrast, our approach only requires\nadding a simple normalization step during training, already available in\nstandard frameworks. Invertible ResNets define a generative model which can be\ntrained by maximum likelihood on unlabeled data. To compute likelihoods, we\nintroduce a tractable approximation to the Jacobian log-determinant of a\nresidual block. Our empirical evaluation shows that invertible ResNets perform\ncompetitively with both state-of-the-art image classifiers and flow-based\ngenerative models, something that has not been previously achieved with a\nsingle architecture.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:17:55 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 17:18:26 GMT"}, {"version": "v3", "created": "Sat, 18 May 2019 18:19:33 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Behrmann", "Jens", ""], ["Grathwohl", "Will", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "1811.01001", "submitter": "Mirac Suzgun", "authors": "Mirac Suzgun, Yonatan Belinkov, Stuart M. Shieber", "title": "On Evaluating the Generalization of LSTM Models in Formal Languages", "comments": "Proceedings of the Society for Computation in Linguistics (SCiL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are theoretically Turing-complete and\nestablished themselves as a dominant model for language processing. Yet, there\nstill remains an uncertainty regarding their language learning capabilities. In\nthis paper, we empirically evaluate the inductive learning capabilities of Long\nShort-Term Memory networks, a popular extension of simple RNNs, to learn simple\nformal languages, in particular $a^nb^n$, $a^nb^nc^n$, and $a^nb^nc^nd^n$. We\ninvestigate the influence of various aspects of learning, such as training data\nregimes and model capacity, on the generalization to unobserved samples. We\nfind striking differences in model performances under different training\nsettings and highlight the need for careful analysis and assessment when making\nclaims about the learning capabilities of neural network models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:37:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Suzgun", "Mirac", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart M.", ""]]}, {"id": "1811.01012", "submitter": "Dhiraj Madan", "authors": "Dhiraj Madan, Dinesh Raghu, Gaurav Pandey and Sachindra Joshi", "title": "Unsupervised Learning of Interpretable Dialog Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several deep learning based models have been proposed for end-to-end\nlearning of dialogs. While these models can be trained from data without the\nneed for any additional annotations, it is hard to interpret them. On the other\nhand, there exist traditional state based dialog systems, where the states of\nthe dialog are discrete and hence easy to interpret. However these states need\nto be handcrafted and annotated in the data. To achieve the best of both\nworlds, we propose Latent State Tracking Network (LSTN) using which we learn an\ninterpretable model in unsupervised manner. The model defines a discrete latent\nvariable at each turn of the conversation which can take a finite set of\nvalues. Since these discrete variables are not present in the training data, we\nuse EM algorithm to train our model in unsupervised manner. In the experiments,\nwe show that LSTN can help achieve interpretability in dialog models without\nmuch decrease in performance compared to end-to-end approaches.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:56:23 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Madan", "Dhiraj", ""], ["Raghu", "Dinesh", ""], ["Pandey", "Gaurav", ""], ["Joshi", "Sachindra", ""]]}, {"id": "1811.01085", "submitter": "Jonathan Rubin", "authors": "S. Mazdak Abulnaga and Jonathan Rubin", "title": "Ischemic Stroke Lesion Segmentation in CT Perfusion Scans using Pyramid\n  Pooling and Focal Loss", "comments": "BrainLes 2018 MICCAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fully convolutional neural network for segmenting ischemic\nstroke lesions in CT perfusion images for the ISLES 2018 challenge. Treatment\nof stroke is time sensitive and current standards for lesion identification\nrequire manual segmentation, a time consuming and challenging process.\nAutomatic segmentation methods present the possibility of accurately\nidentifying lesions and improving treatment planning. Our model is based on the\nPSPNet, a network architecture that makes use of pyramid pooling to provide\nglobal and local contextual information. To learn the varying shapes of the\nlesions, we train our network using focal loss, a loss function designed for\nthe network to focus on learning the more difficult samples. We compare our\nmodel to networks trained using the U-Net and V-Net architectures. Our approach\ndemonstrates effective performance in lesion segmentation and ranked among the\ntop performers at the challenge conclusion.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 20:55:20 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Abulnaga", "S. Mazdak", ""], ["Rubin", "Jonathan", ""]]}, {"id": "1811.01106", "submitter": "Stefan Hell", "authors": "Stefan Hell, Vasileios Argyriou", "title": "Machine learning architectures to predict motion sickness using a\n  Virtual Reality rollercoaster simulation tool", "comments": "4 pages, accepted to AIVR conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual Reality (VR) can cause an unprecedented immersion and feeling of\npresence yet a lot of users experience motion sickness when moving through a\nvirtual environment. Rollercoaster rides are popular in Virtual Reality but\nhave to be well designed to limit the amount of nausea the user may feel. This\npaper describes a novel framework to get automated ratings on motion sickness\nusing Neural Networks. An application that lets users create rollercoasters\ndirectly in VR, share them with other users and ride and rate them is used to\ngather real-time data related to the in-game behaviour of the player, the track\nitself and users' ratings based on a Simulator Sickness Questionnaire (SSQ)\nintegrated into the application. Machine learning architectures based on deep\nneural networks are trained using this data aiming to predict motion sickness\nlevels. While this paper focuses on rollercoasters this framework could help to\nrate any VR application on motion sickness and intensity that involves camera\nmovement. A new well defined dataset is provided in this paper and the\nperformance of the proposed architectures are evaluated in a comparative study.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 22:02:40 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Hell", "Stefan", ""], ["Argyriou", "Vasileios", ""]]}, {"id": "1811.01118", "submitter": "Priyansh Trivedi", "authors": "Gaurav Maheshwari, Priyansh Trivedi, Denis Lukovnikov, Nilesh\n  Chakraborty, Asja Fischer, Jens Lehmann", "title": "Learning to Rank Query Graphs for Complex Question Answering over\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we conduct an empirical investigation of neural query graph\nranking approaches for the task of complex question answering over knowledge\ngraphs. We experiment with six different ranking models and propose a novel\nself-attention based slot matching model which exploits the inherent structure\nof query graphs, our logical form of choice. Our proposed model generally\noutperforms the other models on two QA datasets over the DBpedia knowledge\ngraph, evaluated in different settings. In addition, we show that transfer\nlearning from the larger of those QA datasets to the smaller dataset yields\nsubstantial improvements, effectively offsetting the general lack of training\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 22:59:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lukovnikov", "Denis", ""], ["Chakraborty", "Nilesh", ""], ["Fischer", "Asja", ""], ["Lehmann", "Jens", ""]]}, {"id": "1811.01122", "submitter": "Gunnar Carlsson", "authors": "Gunnar Carlsson and Rickard Br\\\"uel Gabrielsson", "title": "Topological Approaches to Deep Learning", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform topological data analysis on the internal states of convolutional\ndeep neural networks to develop an understanding of the computations that they\nperform. We apply this understanding to modify the computations so as to (a)\nspeed up computations and (b) improve generalization from one data set of\ndigits to another. One byproduct of the analysis is the production of a\ngeometry on new sets of features on data sets of images, and use this\nobservation to develop a methodology for constructing analogues of CNN's for\nmany other geometries, including the graph structures constructed by\ntopological data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 23:18:03 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Carlsson", "Gunnar", ""], ["Gabrielsson", "Rickard Br\u00fcel", ""]]}, {"id": "1811.01127", "submitter": "Tushar Khot", "authors": "Souvik Kundu and Tushar Khot and Ashish Sabharwal and Peter Clark", "title": "Exploiting Explicit Paths for Multi-hop Reading Comprehension", "comments": null, "journal-ref": "ACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, path-based reasoning approach for the multi-hop reading\ncomprehension task where a system needs to combine facts from multiple passages\nto answer a question. Although inspired by multi-hop reasoning over knowledge\ngraphs, our proposed approach operates directly over unstructured text. It\ngenerates potential paths through passages and scores them without any direct\npath supervision. The proposed model, named PathNet, attempts to extract\nimplicit relations from text through entity pair representations, and compose\nthem to encode each path. To capture additional context, PathNet also composes\nthe passage representations along each path to compute a passage-based\nrepresentation. Unlike previous approaches, our model is then able to explain\nits reasoning via these explicit paths through the passages. We show that our\napproach outperforms prior models on the multi-hop Wikihop dataset, and also\ncan be generalized to apply to the OpenBookQA dataset, matching\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 23:48:46 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 22:01:59 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kundu", "Souvik", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""]]}, {"id": "1811.01136", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Holger Schwenk", "title": "Margin-based Parallel Corpus Mining with Multilingual Sentence\n  Embeddings", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation is highly sensitive to the size and quality of the\ntraining data, which has led to an increasing interest in collecting and\nfiltering large parallel corpora. In this paper, we propose a new method for\nthis task based on multilingual sentence embeddings. In contrast to previous\napproaches, which rely on nearest neighbor retrieval with a hard threshold over\ncosine similarity, our proposed method accounts for the scale inconsistencies\nof this measure, considering the margin between a given sentence pair and its\nclosest candidates instead. Our experiments show large improvements over\nexisting methods. We outperform the best published results on the BUCC mining\ntask and the UN reconstruction task by more than 10 F1 and 30 precision points,\nrespectively. Filtering the English-German ParaCrawl corpus with our approach,\nwe obtain 31.2 BLEU points on newstest2014, an improvement of more than one\npoint over the best official filtered version.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 00:34:05 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 22:17:09 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Artetxe", "Mikel", ""], ["Schwenk", "Holger", ""]]}, {"id": "1811.01146", "submitter": "Amanda Sofie Rios", "authors": "Amanda Rios and Laurent Itti", "title": "Closed-Loop Memory GAN for Continual Learning", "comments": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence (IJCAI-2019). https://doi.org/10.24963/ijcai.2019/462", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential learning of tasks using gradient descent leads to an unremitting\ndecline in the accuracy of tasks for which training data is no longer\navailable, termed catastrophic forgetting. Generative models have been explored\nas a means to approximate the distribution of old tasks and bypass storage of\nreal data. Here we propose a cumulative closed-loop memory replay GAN (CloGAN)\nprovided with external regularization by a small memory unit selected for\nmaximum sample diversity. We evaluate incremental class learning using a\nnotoriously hard paradigm, single-headed learning, in which each task is a\ndisjoint subset of classes in the overall dataset, and performance is evaluated\non all previous classes. First, we show that when constructing a dynamic memory\nunit to preserve sample heterogeneity, model performance asymptotically\napproaches training on the full dataset. We then show that using a stochastic\ngenerator to continuously output fresh new images during training increases\nperformance significantly further meanwhile generating quality images. We\ncompare our approach to several baselines including fine-tuning by gradient\ndescent (FGD), Elastic Weight Consolidation (EWC), Deep Generative Replay (DGR)\nand Memory Replay GAN (MeRGAN). Our method has very low long-term memory cost,\nthe memory unit, as well as negligible intermediate memory storage.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 02:40:01 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 21:17:48 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 21:44:55 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Rios", "Amanda", ""], ["Itti", "Laurent", ""]]}, {"id": "1811.01147", "submitter": "Sharon Levy", "authors": "Sharon Levy, Wenhan Xiong, Elizabeth Belding, William Yang Wang", "title": "SafeRoute: Learning to Navigate Streets Safely in an Urban Environment", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that 85% of women have changed their traveled route to\navoid harassment and assault. Despite this, current mapping tools do not\nempower users with information to take charge of their personal safety. We\npropose SafeRoute, a novel solution to the problem of navigating cities and\navoiding street harassment and crime. Unlike other street navigation\napplications, SafeRoute introduces a new type of path generation via deep\nreinforcement learning. This enables us to successfully optimize for\nmulti-criteria path-finding and incorporate representation learning within our\nframework. Our agent learns to pick favorable streets to create a safe and\nshort path with a reward function that incorporates safety and efficiency.\nGiven access to recent crime reports in many urban cities, we train our model\nfor experiments in Boston, New York, and San Francisco. We test our model on\nareas of these cities, specifically the populated downtown regions where\ntourists and those unfamiliar with the streets walk. We evaluate SafeRoute and\nsuccessfully improve over state-of-the-art methods by up to 17% in local\naverage distance from crimes while decreasing path length by up to 7%.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 03:16:11 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Levy", "Sharon", ""], ["Xiong", "Wenhan", ""], ["Belding", "Elizabeth", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.01220", "submitter": "Philippe Toint", "authors": "Coralia Cartis and Nick I. M. Gould and Philippe L. Toint", "title": "Sharp worst-case evaluation complexity bounds for arbitrary-order\n  nonconvex optimization with inexpensive constraints", "comments": "30 pages", "journal-ref": "SIAM Journal on Optimization,, vol. 30(1), pp. 513-541, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.CC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide sharp worst-case evaluation complexity bounds for nonconvex\nminimization problems with general inexpensive constraints, i.e.\\ problems\nwhere the cost of evaluating/enforcing of the (possibly nonconvex or even\ndisconnected) constraints, if any, is negligible compared to that of evaluating\nthe objective function. These bounds unify, extend or improve all known upper\nand lower complexity bounds for unconstrained and convexly-constrained\nproblems. It is shown that, given an accuracy level $\\epsilon$, a degree of\nhighest available Lipschitz continuous derivatives $p$ and a desired optimality\norder $q$ between one and $p$, a conceptual regularization algorithm requires\nno more than $O(\\epsilon^{-\\frac{p+1}{p-q+1}})$ evaluations of the objective\nfunction and its derivatives to compute a suitably approximate $q$-th order\nminimizer. With an appropriate choice of the regularization, a similar result\nalso holds if the $p$-th derivative is merely H\\\"older rather than Lipschitz\ncontinuous. We provide an example that shows that the above complexity bound is\nsharp for unconstrained and a wide class of constrained problems, we also give\nreasons for the optimality of regularization methods from a worst-case\ncomplexity point of view, within a large class of algorithms that use the same\nderivative information.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 14:04:35 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Cartis", "Coralia", ""], ["Gould", "Nick I. M.", ""], ["Toint", "Philippe L.", ""]]}, {"id": "1811.01237", "submitter": "Jun Feng", "authors": "Jun Feng, Minlie Huang, Yijie Zhang, Yang Yang and Xiaoyan Zhu", "title": "Relation Mention Extraction from Noisy Data with Hierarchical\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address a task of relation mention extraction from noisy\ndata: extracting representative phrases for a particular relation from noisy\nsentences that are collected via distant supervision. Despite its significance\nand value in many downstream applications, this task is less studied on noisy\ndata. The major challenges exists in 1) the lack of annotation on mention\nphrases, and more severely, 2) handling noisy sentences which do not express a\nrelation at all. To address the two challenges, we formulate the task as a\nsemi-Markov decision process and propose a novel hierarchical reinforcement\nlearning model. Our model consists of a top-level sentence selector to remove\nnoisy sentences, a low-level mention extractor to extract relation mentions,\nand a reward estimator to provide signals to guide data denoising and mention\nextraction without explicit annotations. Experimental results show that our\nmodel is effective to extract relation mentions from noisy data.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 15:50:27 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Feng", "Jun", ""], ["Huang", "Minlie", ""], ["Zhang", "Yijie", ""], ["Yang", "Yang", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1811.01267", "submitter": "Gillian Hadfield", "authors": "Dylan Hadfield-Menell, McKane Andrus, and Gillian K. Hadfield", "title": "Legible Normativity for AI Alignment: The Value of Silly Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become commonplace to assert that autonomous agents will have to be\nbuilt to follow human rules of behavior--social norms and laws. But human laws\nand norms are complex and culturally varied systems, in many cases agents will\nhave to learn the rules. This requires autonomous agents to have models of how\nhuman rule systems work so that they can make reliable predictions about rules.\nIn this paper we contribute to the building of such models by analyzing an\noverlooked distinction between important rules and what we call silly\nrules--rules with no discernible direct impact on welfare. We show that silly\nrules render a normative system both more robust and more adaptable in response\nto shocks to perceived stability. They make normativity more legible for\nhumans, and can increase legibility for AI systems as well. For AI systems to\nintegrate into human normative systems, we suggest, it may be important for\nthem to have models that include representations of silly rules.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 19:09:18 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Hadfield-Menell", "Dylan", ""], ["Andrus", "McKane", ""], ["Hadfield", "Gillian K.", ""]]}, {"id": "1811.01287", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c, Nikola Jovanovi\\'c,\n  Thomas Kipf, Pietro Li\\`o", "title": "Towards Sparse Hierarchical Graph Classifiers", "comments": "To appear in the Workshop on Relational Representation Learning (R2L)\n  at NIPS 2018. 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in representation learning on graphs, mainly leveraging graph\nconvolutional networks, have brought a substantial improvement on many\ngraph-based benchmark tasks. While novel approaches to learning node embeddings\nare highly suitable for node classification and link prediction, their\napplication to graph classification (predicting a single label for the entire\ngraph) remains mostly rudimentary, typically using a single global pooling step\nto aggregate node features or a hand-designed, fixed heuristic for hierarchical\ncoarsening of the graph structure. An important step towards ameliorating this\nis differentiable graph coarsening---the ability to reduce the size of the\ngraph in an adaptive, data-dependent manner within a graph neural network\npipeline, analogous to image downsampling within CNNs. However, the previous\nprominent approach to pooling has quadratic memory requirements during training\nand is therefore not scalable to large graphs. Here we combine several recent\nadvances in graph neural network design to demonstrate that competitive\nhierarchical graph classification results are possible without sacrificing\nsparsity. Our results are verified on several established graph classification\nbenchmarks, and highlight an important direction for future research in\ngraph-based neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 21:39:43 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Jovanovi\u0107", "Nikola", ""], ["Kipf", "Thomas", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1811.01299", "submitter": "Minh Nguyen", "authors": "Minh N. B. Nguyen, Samuel Thomas, Anne E. Gattiker, Sujatha Kashyap,\n  Kush R. Varshney", "title": "SimplerVoice: A Key Message & Visual Description Generator System for\n  Illiteracy", "comments": null, "journal-ref": "Data For Good Exchange 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SimplerVoice: a key message and visual description generator\nsystem to help low-literate adults navigate the information-dense world with\nconfidence, on their own. SimplerVoice can automatically generate sensible\nsentences describing an unknown object, extract semantic meanings of the object\nusage in the form of a query string, then, represent the string as multiple\ntypes of visual guidance (pictures, pictographs, etc.). We demonstrate\nSimplerVoice system in a case study of generating grocery products' manuals\nthrough a mobile application. To evaluate, we conducted a user study on\nSimplerVoice's generated description in comparison to the information\ninterpreted by users from other methods: the original product package and\nsearch engines' top result, in which SimplerVoice achieved the highest\nperformance score: 4.82 on 5-point mean opinion score scale. Our result shows\nthat SimplerVoice is able to provide low-literate end-users with simple yet\ninformative components to help them understand how to use the grocery products,\nand that the system may potentially provide benefits in other real-world use\ncases\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 23:43:38 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Nguyen", "Minh N. B.", ""], ["Thomas", "Samuel", ""], ["Gattiker", "Anne E.", ""], ["Kashyap", "Sujatha", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1811.01304", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen and Ernesto Jimenez-Ruiz and Ian Horrocks and Charles\n  Sutton", "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically annotating column types with knowledge base (KB) concepts is a\ncritical task to gain a basic understanding of web tables. Current methods rely\non either table metadata like column name or entity correspondences of cells in\nthe KB, and may fail to deal with growing web tables with incomplete meta\ninformation. In this paper we propose a neural network based column type\nannotation framework named ColNet which is able to integrate KB reasoning and\nlookup with machine learning and can automatically train Convolutional Neural\nNetworks for prediction. The prediction model not only considers the contextual\nsemantics within a cell using word representation, but also embeds the\nsemantics of a column by learning locality features from multiple cells. The\nmethod is evaluated with DBPedia and two different web table datasets, T2Dv2\nfrom the general Web and Limaye from Wikipedia pages, and achieves higher\nperformance than the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 00:26:00 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 15:30:31 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Horrocks", "Ian", ""], ["Sutton", "Charles", ""]]}, {"id": "1811.01315", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Xiang Yan, Alan Yu, Pascal Van Hentenryck", "title": "Modeling Stated Preference for Mobility-on-Demand Transit: A Comparison\n  of Machine Learning and Logit Models", "comments": "30 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logit models are usually applied when studying individual travel behavior,\ni.e., to predict travel mode choice and to gain behavioral insights on traveler\npreferences. Recently, some studies have applied machine learning to model\ntravel mode choice and reported higher out-of-sample predictive accuracy than\ntraditional logit models (e.g., multinomial logit). However, little research\nfocuses on comparing the interpretability of machine learning with logit\nmodels. In other words, how to draw behavioral insights from the\nhigh-performance \"black-box\" machine-learning models remains largely unsolved\nin the field of travel behavior modeling.\n  This paper aims at providing a comprehensive comparison between the two\napproaches by examining the key similarities and differences in model\ndevelopment, evaluation, and behavioral interpretation between logit and\nmachine-learning models for travel mode choice modeling. To complement the\ntheoretical discussions, the paper also empirically evaluates the two\napproaches on the stated-preference survey data for a new type of transit\nsystem integrating high-frequency fixed-route services and ridesourcing. The\nresults show that machine learning can produce significantly higher predictive\naccuracy than logit models. Moreover, machine learning and logit models largely\nagree on many aspects of behavioral interpretations. In addition, machine\nlearning can automatically capture the nonlinear relationship between the input\nfeatures and choice outcomes. The paper concludes that there is great potential\nin merging ideas from machine learning and conventional statistical methods to\ndevelop refined models for travel behavior research and suggests some new\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 02:55:49 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 19:40:52 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhao", "Xilei", ""], ["Yan", "Xiang", ""], ["Yu", "Alan", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1811.01336", "submitter": "Rajesh Dachiraju", "authors": "Rajesh Dachiraju", "title": "A Function Fitting Method", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe a function fitting method that has potential\napplications in machine learning and also prove relevant theorems. The\ndescribed function fitting method is a convex minimization problem and can be\nsolved using a gradient descent algorithm. We also provide qualitative analysis\non fitness to data of this function fitting method. The function fitting\nproblem is also shown to be a solution of a linear, weak partial differential\nequation(PDE). We describe a way to fit a Sobolev function by giving a method\nto choose the optimal $\\lambda$ parameter. We describe a closed-form solution\nto the derived PDE, which enables the parametrization of the solution function.\nWe describe a simple numerical solution using a gradient descent algorithm,\nthat converges uniformly to the actual solution. As the functional of the\nminimization problem is a quadratic form, there also exists a numerical method\nusing linear algebra. Lastly, we give some numerical examples and also\nnumerically demonstrate its application to a binary classification problem.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 08:36:01 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 01:43:16 GMT"}, {"version": "v3", "created": "Sun, 13 Jan 2019 07:56:54 GMT"}, {"version": "v4", "created": "Sat, 19 Jan 2019 03:34:50 GMT"}, {"version": "v5", "created": "Sat, 14 Dec 2019 12:54:47 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Dachiraju", "Rajesh", ""]]}, {"id": "1811.01339", "submitter": "Ahmadreza Ahmadi", "authors": "Ahmadreza Ahmadi and Jun Tani", "title": "A Novel Predictive-Coding-Inspired Variational RNN Model for Online\n  Prediction and Recognition", "comments": "The paper is accepted in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces PV-RNN, a novel variational RNN inspired by the\npredictive-coding ideas. The model learns to extract the probabilistic\nstructures hidden in fluctuating temporal patterns by dynamically changing the\nstochasticity of its latent states. Its architecture attempts to address two\nmajor concerns of variational Bayes RNNs: how can latent variables learn\nmeaningful representations and how can the inference model transfer future\nobservations to the latent variables. PV-RNN does both by introducing adaptive\nvectors mirroring the training data, whose values can then be adapted\ndifferently during evaluation. Moreover, prediction errors during\nbackpropagation, rather than external inputs during the forward computation,\nare used to convey information to the network about the external data. For\ntesting, we introduce error regression for predicting unseen sequences as\ninspired by predictive coding that leverages those mechanisms. The model\nintroduces a weighting parameter, the meta-prior, to balance the optimization\npressure placed on two terms of a lower bound on the marginal likelihood of the\nsequential data. We test the model on two datasets with probabilistic\nstructures and show that with high values of the meta-prior the network\ndevelops deterministic chaos through which the data's randomness is imitated.\nFor low values, the model behaves as a random process. The network performs\nbest on intermediate values, and is able to capture the latent probabilistic\nstructure with good generalization. Analyzing the meta-prior's impact on the\nnetwork allows to precisely study the theoretical value and practical benefits\nof incorporating stochastic dynamics in our model. We demonstrate better\nprediction performance on a robot imitation task with our model using error\nregression compared to a standard variational Bayes model lacking such a\nprocedure.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 08:56:50 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 14:59:40 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 02:08:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ahmadi", "Ahmadreza", ""], ["Tani", "Jun", ""]]}, {"id": "1811.01399", "submitter": "Peifeng Wang", "authors": "Peifeng Wang, Jialong Han, Chenliang Li, Rong Pan", "title": "Logic Attention Based Neighborhood Aggregation for Inductive Knowledge\n  Graph Embedding", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding aims at modeling entities and relations with\nlow-dimensional vectors. Most previous methods require that all entities should\nbe seen during training, which is unpractical for real-world knowledge graphs\nwith new entities emerging on a daily basis. Recent efforts on this issue\nsuggest training a neighborhood aggregator in conjunction with the conventional\nentity and relation embeddings, which may help embed new entities inductively\nvia their existing neighbors. However, their neighborhood aggregators neglect\nthe unordered and unequal natures of an entity's neighbors. To this end, we\nsummarize the desired properties that may lead to effective neighborhood\naggregators. We also introduce a novel aggregator, namely, Logic Attention\nNetwork (LAN), which addresses the properties by aggregating neighbors with\nboth rules- and network-based attention weights. By comparing with conventional\naggregators on two knowledge graph completion tasks, we experimentally validate\nLAN's superiority in terms of the desired properties.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 16:39:28 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 04:06:14 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Peifeng", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""], ["Pan", "Rong", ""]]}, {"id": "1811.01409", "submitter": "Mehwish Alam Miss", "authors": "Mehwish Alam, Aldo Gangemi, Valentina Presutti, Diego Reforgiato\n  Recupero", "title": "Semantic Role Labeling for Knowledge Graph Extraction from Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces TakeFive, a new semantic role labeling method that\ntransforms a text into a frame-oriented knowledge graph. It performs dependency\nparsing, identifies the words that evoke lexical frames, locates the roles and\nfillers for each frame, runs coercion techniques, and formalises the results as\na knowledge graph. This formal representation complies with the frame semantics\nused in Framester, a factual-linguistic linked data resource. The obtained\nprecision, recall and F1 values indicate that TakeFive is competitive with\nother existing methods such as SEMAFOR, Pikes, PathLSTM and FRED. We finally\ndiscuss how to combine TakeFive and FRED, obtaining higher values of precision,\nrecall and F1.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 17:57:07 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Alam", "Mehwish", ""], ["Gangemi", "Aldo", ""], ["Presutti", "Valentina", ""], ["Recupero", "Diego Reforgiato", ""]]}, {"id": "1811.01439", "submitter": "Brent Mittelstadt", "authors": "Brent Mittelstadt, Chris Russell, Sandra Wachter", "title": "Explaining Explanations in AI", "comments": "FAT* 2019 Proceedings", "journal-ref": null, "doi": "10.1145/3287560.3287574", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on interpretability in machine learning and AI has focused on the\nbuilding of simplified models that approximate the true criteria used to make\ndecisions. These models are a useful pedagogical device for teaching trained\nprofessionals how to predict what decisions will be made by the complex system,\nand most importantly how the system might break. However, when considering any\nsuch model it's important to remember Box's maxim that \"All models are wrong\nbut some are useful.\" We focus on the distinction between these models and\nexplanations in philosophy and sociology. These models can be understood as a\n\"do it yourself kit\" for explanations, allowing a practitioner to directly\nanswer \"what if questions\" or generate contrastive explanations without\nexternal assistance. Although a valuable ability, giving these models as\nexplanations appears more difficult than necessary, and other forms of\nexplanation may not have the same trade-offs. We contrast the different schools\nof thought on what makes an explanation, and suggest that machine learning\nmight benefit from viewing the problem more broadly.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 21:35:16 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Mittelstadt", "Brent", ""], ["Russell", "Chris", ""], ["Wachter", "Sandra", ""]]}, {"id": "1811.01458", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Francis Song, Edward Hughes, Neil Burch, Iain\n  Dunning, Shimon Whiteson, Matthew Botvinick, Michael Bowling", "title": "Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing the actions of others, humans make inferences about why they\nacted as they did, and what this implies about the world; humans also use the\nfact that their actions will be interpreted in this manner, allowing them to\nact informatively and thereby communicate efficiently with others. Although\nlearning algorithms have recently achieved superhuman performance in a number\nof two-player, zero-sum games, scalable multi-agent reinforcement learning\nalgorithms that can discover effective strategies and conventions in complex,\npartially observable settings have proven elusive. We present the Bayesian\naction decoder (BAD), a new multi-agent learning method that uses an\napproximate Bayesian update to obtain a public belief that conditions on the\nactions taken by all agents in the environment. BAD introduces a new Markov\ndecision process, the public belief MDP, in which the action space consists of\nall deterministic partial policies, and exploits the fact that an agent acting\nonly on this public belief state can still learn to use its private information\nif the action space is augmented to be over all partial policies mapping\nprivate information into environment actions. The Bayesian update is closely\nrelated to the theory of mind reasoning that humans carry out when observing\nothers' actions. We first validate BAD on a proof-of-principle two-step matrix\ngame, where it outperforms policy gradient methods; we then evaluate BAD on the\nchallenging, cooperative partial-information card game Hanabi, where, in the\ntwo-player setting, it surpasses all previously published learning and\nhand-coded approaches, establishing a new state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 23:43:54 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 16:51:31 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 21:21:00 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Song", "Francis", ""], ["Hughes", "Edward", ""], ["Burch", "Neil", ""], ["Dunning", "Iain", ""], ["Whiteson", "Shimon", ""], ["Botvinick", "Matthew", ""], ["Bowling", "Michael", ""]]}, {"id": "1811.01468", "submitter": "Najmeh Sadoughi", "authors": "Najmeh Sadoughi, Greg P. Finley, James Fone, Vignesh Murali, Maxim\n  Korenevski, Slava Baryshnikov, Nico Axtmann, Mark Miller, David\n  Suendermann-Oeft", "title": "Medical code prediction with multi-view convolution and\n  description-regularized label-dependent attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A ubiquitous task in processing electronic medical data is the assignment of\nstandardized codes representing diagnoses and/or procedures to free-text\ndocuments such as medical reports. This is a difficult natural language\nprocessing task that requires parsing long, heterogeneous documents and\nselecting a set of appropriate codes from tens of thousands of\npossibilities---many of which have very few positive training samples. We\npresent a deep learning system that advances the state of the art for the\nMIMIC-III dataset, achieving a new best micro F1-measure of 55.85\\%,\nsignificantly outperforming the previous best result (Mullenbach et al. 2018).\nWe achieve this through a number of enhancements, including two major novel\ncontributions: multi-view convolutional channels, which effectively learn to\nadjust kernel sizes throughout the input; and attention regularization,\nmediated by natural-language code descriptions, which helps overcome sparsity\nfor thousands of uncommon codes. These and other modifications are selected to\naddress difficulties inherent to both automated coding specifically and deep\nlearning generally. Finally, we investigate our accuracy results in detail to\nindividually measure the impact of these contributions and point the way\ntowards future algorithmic improvements.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 00:54:03 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Sadoughi", "Najmeh", ""], ["Finley", "Greg P.", ""], ["Fone", "James", ""], ["Murali", "Vignesh", ""], ["Korenevski", "Maxim", ""], ["Baryshnikov", "Slava", ""], ["Axtmann", "Nico", ""], ["Miller", "Mark", ""], ["Suendermann-Oeft", "David", ""]]}, {"id": "1811.01480", "submitter": "Jixue Liu", "authors": "Jixue Liu, Jiuyong Li, Lin Liu, Thuc Duy Le, Feiyue Ye, Gefei Li", "title": "FairMod - Making Predictive Models Discrimination Aware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models such as decision trees and neural networks may produce\ndiscrimination in their predictions. This paper proposes a method to\npost-process the predictions of a predictive model to make the processed\npredictions non-discriminatory. The method considers multiple protected\nvariables together. Multiple protected variables make the problem more\nchallenging than a simple protected variable. The method uses a well-cited\ndiscrimination metric and adapts it to allow the specification of explanatory\nvariables, such as position, profession, education, that describe the contexts\nof the applications. It models the post-processing of predictions problem as a\nnonlinear optimization problem to find best adjustments to the predictions so\nthat the discrimination constraints of all protected variables are all met at\nthe same time. The proposed method is independent of classification methods. It\ncan handle the cases that existing methods cannot handle: satisfying multiple\nprotected attributes at the same time, allowing multiple explanatory\nattributes, and being independent of classification model types. An evaluation\nusing four real world data sets shows that the proposed method is as\neffectively as existing methods, in addition to its extra power.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 02:07:03 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Liu", "Jixue", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Le", "Thuc Duy", ""], ["Ye", "Feiyue", ""], ["Li", "Gefei", ""]]}, {"id": "1811.01483", "submitter": "Jongwook Choi", "authors": "Jongwook Choi, Yijie Guo, Marcin Moczulski, Junhyuk Oh, Neal Wu,\n  Mohammad Norouzi, Honglak Lee", "title": "Contingency-Aware Exploration in Reinforcement Learning", "comments": "In ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates whether learning contingency-awareness and\ncontrollable aspects of an environment can lead to better exploration in\nreinforcement learning. To investigate this question, we consider an\ninstantiation of this hypothesis evaluated on the Arcade Learning Element\n(ALE). In this study, we develop an attentive dynamics model (ADM) that\ndiscovers controllable elements of the observations, which are often associated\nwith the location of the character in Atari games. The ADM is trained in a\nself-supervised fashion to predict the actions taken by the agent. The learned\ncontingency information is used as a part of the state representation for\nexploration purposes. We demonstrate that combining actor-critic algorithm with\ncount-based exploration using our representation achieves impressive results on\na set of notoriously challenging Atari games due to sparse rewards. For\nexample, we report a state-of-the-art score of >11,000 points on Montezuma's\nRevenge without using expert demonstrations, explicit high-level information\n(e.g., RAM states), or supervisory data. Our experiments confirm that\ncontingency-awareness is indeed an extremely powerful concept for tackling\nexploration problems in reinforcement learning and opens up interesting\nresearch questions for further investigations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 02:12:11 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 05:12:36 GMT"}, {"version": "v3", "created": "Mon, 4 Mar 2019 18:55:24 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Choi", "Jongwook", ""], ["Guo", "Yijie", ""], ["Moczulski", "Marcin", ""], ["Oh", "Junhyuk", ""], ["Wu", "Neal", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""]]}, {"id": "1811.01501", "submitter": "Zhouchen Lin", "authors": "Jia Li, Cong Fang, Zhouchen Lin", "title": "Lifted Proximal Operator Machines", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new optimization method for training feed-forward neural\nnetworks. By rewriting the activation function as an equivalent proximal\noperator, we approximate a feed-forward neural network by adding the proximal\noperators to the objective function as penalties, hence we call the lifted\nproximal operator machine (LPOM). LPOM is block multi-convex in all layer-wise\nweights and activations. This allows us to use block coordinate descent to\nupdate the layer-wise weights and activations in parallel. Most notably, we\nonly use the mapping of the activation function itself, rather than its\nderivatives, thus avoiding the gradient vanishing or blow-up issues in gradient\nbased training methods. So our method is applicable to various non-decreasing\nLipschitz continuous activation functions, which can be saturating and\nnon-differentiable. LPOM does not require more auxiliary variables than the\nlayer-wise activations, thus using roughly the same amount of memory as\nstochastic gradient descent (SGD) does. We further prove the convergence of\nupdating the layer-wise weights and activations. Experiments on MNIST and\nCIFAR-10 datasets testify to the advantages of LPOM.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 03:33:24 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Li", "Jia", ""], ["Fang", "Cong", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1811.01533", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Transfer learning for time series classification", "comments": "Accepted at IEEE International Conference on Big Data 2018", "journal-ref": null, "doi": "10.1109/BigData.2018.8621990", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning for deep neural networks is the process of first training a\nbase network on a source dataset, and then transferring the learned features\n(the network's weights) to a second network to be trained on a target dataset.\nThis idea has been shown to improve deep neural network's generalization\ncapabilities in many computer vision tasks such as image recognition and object\nlocalization. Apart from these applications, deep Convolutional Neural Networks\n(CNNs) have also recently gained popularity in the Time Series Classification\n(TSC) community. However, unlike for image recognition problems, transfer\nlearning techniques have not yet been investigated thoroughly for the TSC task.\nThis is surprising as the accuracy of deep learning models for TSC could\npotentially be improved if the model is fine-tuned from a pre-trained neural\nnetwork instead of training it from scratch. In this paper, we fill this gap by\ninvestigating how to transfer deep CNNs for the TSC task. To evaluate the\npotential of transfer learning, we performed extensive experiments using the\nUCR archive which is the largest publicly available TSC benchmark containing 85\ndatasets. For each dataset in the archive, we pre-trained a model and then\nfine-tuned it on the other datasets resulting in 7140 different deep neural\nnetworks. These experiments revealed that transfer learning can improve or\ndegrade the model's predictions depending on the dataset used for transfer.\nTherefore, in an effort to predict the best source dataset for a given target\ndataset, we propose a new method relying on Dynamic Time Warping to measure\ninter-datasets similarities. We describe how our method can guide the transfer\nto choose the best source dataset leading to an improvement in accuracy on 71\nout of 85 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 07:06:32 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1811.01545", "submitter": "Ping Guo", "authors": "P. Guo, K. Wang, and X. L. Zhou", "title": "PILAE: A Non-gradient Descent Learning Scheme for Deep Feedforward\n  Neural Networks", "comments": "This work is our effort toward to realize AutoML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a non-gradient descent learning scheme is proposed for deep\nfeedforward neural networks (DNN). As we known, autoencoder can be used as the\nbuilding blocks of the multi-layer perceptron (MLP) deep neural network. So,\nthe MLP will be taken as an example to illustrate the proposed scheme of\npseudoinverse learning algorithm for autoencoder (PILAE) training. The PILAE\nwith low rank approximation is a non-gradient based learning algorithm, and the\nencoder weight matrix is set to be the low rank approximation of the\npseudoinverse of the input matrix, while the decoder weight matrix is\ncalculated by the pseudoinverse learning algorithm. It is worth to note that\nonly few network structure hyperparameters need to be tuned. Hence, the\nproposed algorithm can be regarded as a quasi-automated training algorithm\nwhich can be utilized in autonomous machine learning research field. The\nexperimental results show that the proposed learning scheme for DNN can achieve\nbetter performance on considering the tradeoff between training efficiency and\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 08:14:11 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:30:10 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Guo", "P.", ""], ["Wang", "K.", ""], ["Zhou", "X. L.", ""]]}, {"id": "1811.01557", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Yan Zhu, Evangelos E. Papalexakis, Abdullah\n  Mueen, Eamonn Keogh", "title": "Representation Learning by Reconstructing Neighborhoods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its introduction, unsupervised representation learning has attracted a\nlot of attention from the research community, as it is demonstrated to be\nhighly effective and easy-to-apply in tasks such as dimension reduction,\nclustering, visualization, information retrieval, and semi-supervised learning.\nIn this work, we propose a novel unsupervised representation learning framework\ncalled neighbor-encoder, in which domain knowledge can be easily incorporated\ninto the learning process without modifying the general encoder-decoder\narchitecture of the classic autoencoder.In contrast to autoencoder, which\nreconstructs the input data itself, neighbor-encoder reconstructs the input\ndata's neighbors. As the proposed representation learning problem is\nessentially a neighbor reconstruction problem, domain knowledge can be easily\nincorporated in the form of an appropriate definition of similarity between\nobjects. Based on that observation, our framework can leverage any\noff-the-shelf similarity search algorithms or side information to find the\nneighbor of an input object. Applications of other algorithms (e.g.,\nassociation rule mining) in our framework are also possible, given that the\nappropriate definition of neighbor can vary in different contexts. We have\ndemonstrated the effectiveness of our framework in many diverse domains,\nincluding images, text, and time series, and for various data mining tasks\nincluding classification, clustering, and visualization. Experimental results\nshow that neighbor-encoder not only outperforms autoencoder in most of the\nscenarios we consider, but also achieves the state-of-the-art performance on\ntext document clustering.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 08:56:21 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 06:31:16 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Zhu", "Yan", ""], ["Papalexakis", "Evangelos E.", ""], ["Mueen", "Abdullah", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1811.01662", "submitter": "Tien Huu Do", "authors": "Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Angel Lopez\n  Aguirre, Valerio Panzica La Manna, Frank Pasveer, Wilfried Philips, Nikos\n  Deligiannis", "title": "Matrix Completion With Variational Graph Autoencoders: Application in\n  Hyperlocal Air Quality Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring air quality from a limited number of observations is an essential\ntask for monitoring and controlling air pollution. Existing inference methods\ntypically use low spatial resolution data collected by fixed monitoring\nstations and infer the concentration of air pollutants using additional types\nof data, e.g., meteorological and traffic information. In this work, we focus\non street-level air quality inference by utilizing data collected by mobile\nstations. We formulate air quality inference in this setting as a graph-based\nmatrix completion problem and propose a novel variational model based on graph\nconvolutional autoencoders. Our model captures effectively the spatio-temporal\ncorrelation of the measurements and does not depend on the availability of\nadditional information apart from the street-network topology. Experiments on a\nreal air quality dataset, collected with mobile stations, shows that the\nproposed model outperforms state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:18:32 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Do", "Tien Huu", ""], ["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Aguirre", "Angel Lopez", ""], ["La Manna", "Valerio Panzica", ""], ["Pasveer", "Frank", ""], ["Philips", "Wilfried", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1811.01692", "submitter": "Carmine Dodaro", "authors": "Carmine Dodaro and Francesco Ricca", "title": "The External Interface for Extending WASP", "comments": "22 pages, 1 figure, Under consideration in Theory and Practice of\n  Logic Programming (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 225-248", "doi": "10.1017/S1471068418000558", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a successful declarative formalism for\nknowledge representation and reasoning. The evaluation of ASP programs is\nnowadays based on the Conflict-Driven Clause Learning (CDCL) backtracking\nsearch algorithm. Recent work suggested that the performance of CDCL-based\nimplementations can be considerably improved on specific benchmarks by\nextending their solving capabilities with custom heuristics and propagators.\nHowever, embedding such algorithms into existing systems requires expert\nknowledge of the internals of ASP implementations. The development of effective\nsolver extensions can be made easier by providing suitable programming\ninterfaces. In this paper, we present the interface for extending the\nCDCL-based ASP solver WASP. The interface is both general, i.e. it can be used\nfor providing either new branching heuristics and propagators, and external,\ni.e. the implementation of new algorithms requires no internal modifications of\nWASP. Moreover, we review the applications of the interface witnessing it can\nbe successfully used to extend WASP for solving effectively hard instances of\nboth real-world and synthetic problems. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:04:48 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 09:58:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dodaro", "Carmine", ""], ["Ricca", "Francesco", ""]]}, {"id": "1811.01700", "submitter": "Junjie Zeng", "authors": "Junjie Zeng, Long Qin, Yue Hu, Cong Hu and Quanjun Yin", "title": "Combining Subgoal Graphs with Reinforcement Learning to Build a Rational\n  Pathfinder", "comments": "20 pages", "journal-ref": null, "doi": "10.3390/app9020323", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a hierarchical path planning framework called SG-RL\n(subgoal graphs-reinforcement learning), to plan rational paths for agents\nmaneuvering in continuous and uncertain environments. By \"rational\", we mean\n(1) efficient path planning to eliminate first-move lags; (2) collision-free\nand smooth for agents with kinematic constraints satisfied. SG-RL works in a\ntwo-level manner. At the first level, SG-RL uses a geometric path-planning\nmethod, i.e., Simple Subgoal Graphs (SSG), to efficiently find optimal abstract\npaths, also called subgoal sequences. At the second level, SG-RL uses an RL\nmethod, i.e., Least-Squares Policy Iteration (LSPI), to learn near-optimal\nmotion-planning policies which can generate kinematically feasible and\ncollision-free trajectories between adjacent subgoals. The first advantage of\nthe proposed method is that SSG can solve the limitations of sparse reward and\nlocal minima trap for RL agents; thus, LSPI can be used to generate paths in\ncomplex environments. The second advantage is that, when the environment\nchanges slightly (i.e., unexpected obstacles appearing), SG-RL does not need to\nreconstruct subgoal graphs and replan subgoal sequences using SSG, since LSPI\ncan deal with uncertainties by exploiting its generalization ability to handle\nchanges in environments. Simulation experiments in representative scenarios\ndemonstrate that, compared with existing methods, SG-RL can work well on\nlarge-scale maps with relatively low action-switching frequencies and shorter\npath lengths, and SG-RL can deal with small changes in environments. We further\ndemonstrate that the design of reward functions and the types of training\nenvironments are important factors for learning feasible policies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:12:14 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Zeng", "Junjie", ""], ["Qin", "Long", ""], ["Hu", "Yue", ""], ["Hu", "Cong", ""], ["Yin", "Quanjun", ""]]}, {"id": "1811.01701", "submitter": "Ahsan Adeel", "authors": "Ahsan Adeel", "title": "Role of Awareness and Universal Context in a Spiking Conscious Neural\n  Network (SCNN): A New Perspective and Future Directions", "comments": "Neural Computation | MIT Press Journals (In-Process)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Awareness plays a major role in human cognition and adaptive behaviour,\nthough mechanisms involved remain unknown. Awareness is not an objectively\nestablished fact, therefore, despite extensive research, scientists have not\nbeen able to fully interpret its contribution in multisensory integration and\nprecise neural firing, hence, questions remain: (1) How the biological neuron\nintegrates the incoming multisensory signals with respect to different\nsituations? (2) How are the roles of incoming multisensory signals defined\n(selective amplification/attenuation) that help neuron(s) to originate a\nprecise neural firing complying with the anticipated behavioural-constraint of\nthe environment? (3) How are the external environment and anticipated behaviour\nintegrated? Recently, scientists have exploited deep learning to integrate\nmultimodal cues and capture context-dependent meanings. Yet, these methods\nsuffer from imprecise behavioural representation. In this research, we\nintroduce a new theory on the role of awareness and universal context that can\nhelp answering the aforementioned crucial neuroscience questions. Specifically,\nwe propose a class of spiking conscious neuron in which the output depends on\nthree functionally distinctive integrated input variables: receptive field\n(RF), local contextual field (LCF), and universal contextual field (UCF). The\nRF defines the incoming ambiguous sensory signal, LCF defines the modulatory\nsignal coming from other parts of the brain, and UCF defines the awareness. It\nis believed that the conscious neuron inherently contains enough knowledge\nabout the situation in which the problem is to be solved based on past learning\nand reasoning and it defines the precise role of incoming multisensory signals\nto originate a precise neural firing (exhibiting switch-like behaviour). It is\nshown that the conscious neuron helps modelling a more precise human behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:12:23 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Adeel", "Ahsan", ""]]}, {"id": "1811.01713", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Ian E.H. Yen, Kun Xu, Fangli Xu, Avinash Balakrishnan,\n  Pin-Yu Chen, Pradeep Ravikumar, Michael J. Witbrock", "title": "Word Mover's Embedding: From Word2Vec to Document Embedding", "comments": "EMNLP'18 Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the celebrated Word2Vec technique yields semantically rich\nrepresentations for individual words, there has been relatively less success in\nextending to generate unsupervised sentences or documents embeddings. Recent\nwork has demonstrated that a distance measure between documents called\n\\emph{Word Mover's Distance} (WMD) that aligns semantically similar words,\nyields unprecedented KNN classification accuracy. However, WMD is expensive to\ncompute, and it is hard to extend its use beyond a KNN classifier. In this\npaper, we propose the \\emph{Word Mover's Embedding } (WME), a novel approach to\nbuilding an unsupervised document (sentence) embedding from pre-trained word\nembeddings. In our experiments on 9 benchmark text classification datasets and\n22 textual similarity tasks, the proposed technique consistently matches or\noutperforms state-of-the-art techniques, with significantly higher accuracy on\nproblems of short length.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 19:43:17 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wu", "Lingfei", ""], ["Yen", "Ian E. H.", ""], ["Xu", "Kun", ""], ["Xu", "Fangli", ""], ["Balakrishnan", "Avinash", ""], ["Chen", "Pin-Yu", ""], ["Ravikumar", "Pradeep", ""], ["Witbrock", "Michael J.", ""]]}, {"id": "1811.01741", "submitter": "Minne Li", "authors": "Lisheng Wu, Minne Li, Jun Wang", "title": "Learning Shared Dynamics with Meta-World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have consciousness as the ability to perceive events and objects: a\nmental model of the world developed from the most impoverished of visual\nstimuli, enabling humans to make rapid decisions and take actions. Although\nspatial and temporal aspects of different scenes are generally diverse, the\nunderlying physics among environments still work the same way, thus learning an\nabstract description of shared physical dynamics helps human to understand the\nworld. In this paper, we explore building this mental world with neural network\nmodels through multi-task learning, namely the meta-world model. We show\nthrough extensive experiments that our proposed meta-world models successfully\ncapture the common dynamics over the compact representations of visually\ndifferent environments from Atari Games. We also demonstrate that agents\nequipped with our meta-world model possess the ability of visual\nself-recognition, i.e., recognize themselves from the reflected mirrored\nenvironment derived from the classic mirror self-recognition test (MSR).\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:38:45 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wu", "Lisheng", ""], ["Li", "Minne", ""], ["Wang", "Jun", ""]]}, {"id": "1811.01742", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin and George D. C. Cavalcanti", "title": "META-DES.H: a dynamic ensemble selection technique using meta-learning\n  and a dynamic weighting approach", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.00825,\n  arXiv:1810.01270, arXiv:1811.00217", "journal-ref": "Published on the International Joint Conference on Neural Networks\n  (IJCNN), 2015, pp. 1-8", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Dynamic Ensemble Selection (DES) techniques, only the most competent\nclassifiers are selected to classify a given query sample. Hence, the key issue\nin DES is how to estimate the competence of each classifier in a pool to select\nthe most competent ones. In order to deal with this issue, we proposed a novel\ndynamic ensemble selection framework using meta-learning, called META-DES. The\nframework is divided into three steps. In the first step, the pool of\nclassifiers is generated from the training data. In the second phase the\nmeta-features are computed using the training data and used to train a\nmeta-classifier that is able to predict whether or not a base classifier from\nthe pool is competent enough to classify an input instance. In this paper, we\npropose improvements to the training and generalization phase of the META-DES\nframework. In the training phase, we evaluate four different algorithms for the\ntraining of the meta-classifier. For the generalization phase, three\ncombination approaches are evaluated: Dynamic selection, where only the\nclassifiers that attain a certain competence level are selected; Dynamic\nweighting, where the meta-classifier estimates the competence of each\nclassifier in the pool, and the outputs of all classifiers in the pool are\nweighted based on their level of competence; and a hybrid approach, in which\nfirst an ensemble with the most competent classifiers is selected, after which\nthe weights of the selected classifiers are estimated in order to be used in a\nweighted majority voting scheme. Experiments are carried out on 30\nclassification datasets. Experimental results demonstrate that the changes\nproposed in this paper significantly improve the recognition accuracy of the\nsystem in several datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:28:01 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.01743", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Robert Sabourin, George D. C. Cavalcanti", "title": "On Meta-Learning for Dynamic Ensemble Selection", "comments": "arXiv admin note: substantial text overlap with arXiv:1810.01270;\n  text overlap with arXiv:1509.00825", "journal-ref": "Published on the International Conference on Pattern Recognition\n  (ICPR), 2014, pp. 1230-1235", "doi": "10.1109/ICPR.2014.221", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel dynamic ensemble selection framework using\nmeta-learning. The framework is divided into three steps. In the first step,\nthe pool of classifiers is generated from the training data. The second phase\nis responsible to extract the meta-features and train the meta-classifier. Five\ndistinct sets of meta-features are proposed, each one corresponding to a\ndifferent criterion to measure the level of competence of a classifier for the\nclassification of a given query sample. The meta-features are computed using\nthe training data and used to train a meta-classifier that is able to predict\nwhether or not a base classifier from the pool is competent enough to classify\nan input instance. Three different training scenarios for the training of the\nmeta-classifier are considered: problem-dependent, problem-independent and\nhybrid. Experimental results show that the problem-dependent scenario provides\nthe best result. In addition, the performance of the problem-dependent scenario\nis strongly correlated with the recognition rate of the system. A comparison\nwith state-of-the-art techniques shows that the proposed-dependent approach\noutperforms current dynamic ensemble selection techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 23:13:38 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1811.01778", "submitter": "Paul Trichelair", "authors": "Paul Trichelair and Ali Emami and Adam Trischler and Kaheer Suleman\n  and Jackie Chi Kit Cheung", "title": "How Reasonable are Common-Sense Reasoning Tasks: A Case-Study on the\n  Winograd Schema Challenge and SWAG", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have significantly improved the state-of-the-art on\ncommon-sense reasoning (CSR) benchmarks like the Winograd Schema Challenge\n(WSC) and SWAG. The question we ask in this paper is whether improved\nperformance on these benchmarks represents genuine progress towards\ncommon-sense-enabled systems. We make case studies of both benchmarks and\ndesign protocols that clarify and qualify the results of previous work by\nanalyzing threats to the validity of previous experimental designs. Our\nprotocols account for several properties prevalent in common-sense benchmarks\nincluding size limitations, structural regularities, and variable instance\ndifficulty.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:11:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 06:28:44 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Trichelair", "Paul", ""], ["Emami", "Ali", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1811.01846", "submitter": "Cong Feng", "authors": "Cong Feng and Jie Zhang", "title": "Reinforcement Learning based Dynamic Model Selection for Short-Term Load\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing prevalence of smart grid technology, short-term load\nforecasting (STLF) becomes particularly important in power system operations.\nThere is a large collection of methods developed for STLF, but selecting a\nsuitable method under varying conditions is still challenging. This paper\ndevelops a novel reinforcement learning based dynamic model selection (DMS)\nmethod for STLF. A forecasting model pool is first built, including ten\nstate-of-the-art machine learning based forecasting models. Then a Q-learning\nagent learns the optimal policy of selecting the best forecasting model for the\nnext time step, based on the model performance. The optimal DMS policy is\napplied to select the best model at each time step with a moving window.\nNumerical simulations on two-year load and weather data show that the\nQ-learning algorithm converges fast, resulting in effective and efficient DMS.\nThe developed STLF model with Q-learning based DMS improves the forecasting\naccuracy by approximately 50%, compared to the state-of-the-art machine\nlearning based STLF models.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:04:35 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Feng", "Cong", ""], ["Zhang", "Jie", ""]]}, {"id": "1811.01848", "submitter": "Aravind Rajeswaran", "authors": "Kendall Lowrey, Aravind Rajeswaran, Sham Kakade, Emanuel Todorov, Igor\n  Mordatch", "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via\n  Model-Based Control", "comments": "The first two authors contributed equally. Accepted at ICLR 2019.\n  Supplementary videos available at: https://sites.google.com/view/polo-mpc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a plan online and learn offline (POLO) framework for the setting\nwhere an agent, with an internal model, needs to continually act and learn in\nthe world. Our work builds on the synergistic relationship between local\nmodel-based control, global value function learning, and exploration. We study\nhow local trajectory optimization can cope with approximation errors in the\nvalue function, and can stabilize and accelerate value function learning.\nConversely, we also study how approximate value functions can help reduce the\nplanning horizon and allow for better policies beyond local solutions. Finally,\nwe also demonstrate how trajectory optimization can be used to perform\ntemporally coordinated exploration in conjunction with estimating uncertainty\nin value function approximation. This exploration is critical for fast and\nstable learning of the value function. Combining these components enable\nsolutions to complex simulated control tasks, like humanoid locomotion and\ndexterous in-hand manipulation, in the equivalent of a few minutes of\nexperience in the real world.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:09:18 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 20:54:47 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 16:39:23 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Lowrey", "Kendall", ""], ["Rajeswaran", "Aravind", ""], ["Kakade", "Sham", ""], ["Todorov", "Emanuel", ""], ["Mordatch", "Igor", ""]]}, {"id": "1811.01910", "submitter": "Nikolai Rozanov", "authors": "Edward Collins, Nikolai Rozanov, Bingbing Zhang", "title": "Evolutionary Data Measures: Understanding the Difficulty of Text\n  Classification Tasks", "comments": "27 pages, 6 tables, 3 figures (submitted for publication in June\n  2018), CoNLL 2018", "journal-ref": "ACL, CoNLL(K18-1037), 22, 380--391, (2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification tasks are usually analysed and improved through new model\narchitectures or hyperparameter optimisation but the underlying properties of\ndatasets are discovered on an ad-hoc basis as errors occur. However,\nunderstanding the properties of the data is crucial in perfecting models. In\nthis paper we analyse exactly which characteristics of a dataset best determine\nhow difficult that dataset is for the task of text classification. We then\npropose an intuitive measure of difficulty for text classification datasets\nwhich is simple and fast to calculate. We show that this measure generalises to\nunseen data by comparing it to state-of-the-art datasets and results. This\nmeasure can be used to analyse the precise source of errors in a dataset and\nallows fast estimation of how difficult a dataset is to learn. We searched for\nthis measure by training 12 classical and neural network based models on 78\nreal-world datasets, then use a genetic algorithm to discover the best measure\nof difficulty. Our difficulty-calculating code ( https://github.com/Wluper/edm\n) and datasets ( http://data.wluper.com ) are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:39:54 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 10:07:20 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Collins", "Edward", ""], ["Rozanov", "Nikolai", ""], ["Zhang", "Bingbing", ""]]}, {"id": "1811.02017", "submitter": "Taco Cohen", "authors": "Taco Cohen, Mario Geiger, Maurice Weiler", "title": "A General Theory of Equivariant CNNs on Homogeneous Spaces", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 32 (NeurIPS\n  2019) 9142-9153", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theory of Group equivariant Convolutional Neural\nNetworks (G-CNNs) on homogeneous spaces such as Euclidean space and the sphere.\nFeature maps in these networks represent fields on a homogeneous base space,\nand layers are equivariant maps between spaces of fields. The theory enables a\nsystematic classification of all existing G-CNNs in terms of their symmetry\ngroup, base space, and field type. We also consider a fundamental question:\nwhat is the most general kind of equivariant linear map between feature spaces\n(fields) of given types? Following Mackey, we show that such maps correspond\none-to-one with convolutions using equivariant kernels, and characterize the\nspace of such kernels.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 20:22:10 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 14:59:52 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Cohen", "Taco", ""], ["Geiger", "Mario", ""], ["Weiler", "Maurice", ""]]}, {"id": "1811.02063", "submitter": "Xuesong Yang", "authors": "Di He, Xuesong Yang, Boon Pang Lim, Yi Liang, Mark Hasegawa-Johnson,\n  Deming Chen", "title": "When CTC Training Meets Acoustic Landmarks", "comments": "To Appear in ICASSP 2019; The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist temporal classification (CTC) provides an end-to-end acoustic\nmodel (AM) training strategy. CTC learns accurate AMs without time-aligned\nphonetic transcription, but sometimes fails to converge, especially in\nresource-constrained scenarios. In this paper, the convergence properties of\nCTC are improved by incorporating acoustic landmarks. We tailored a new set of\nacoustic landmarks to help CTC training converge more rapidly and smoothly\nwhile also reducing recognition error rates. We leveraged new target label\nsequences mixed with both phone and manner changes to guide CTC training.\nExperiments on TIMIT demonstrated that CTC based acoustic models converge\nsignificantly faster and smoother when they are augmented by acoustic\nlandmarks. The models pretrained with mixed target labels can be further\nfinetuned, resulting in phone error rates 8.72% below baseline on TIMIT.\nConsistent performance gain is also observed on WSJ (a larger corpus) and\nreduced TIMIT (smaller). With WSJ, we are the first to succeed in verifying the\neffectiveness of acoustic landmark theory on a mid-sized ASR task.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:22:24 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 21:37:44 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["He", "Di", ""], ["Yang", "Xuesong", ""], ["Lim", "Boon Pang", ""], ["Liang", "Yi", ""], ["Hasegawa-Johnson", "Mark", ""], ["Chen", "Deming", ""]]}, {"id": "1811.02073", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Borislav Mavrin, Linglong Kong, Bo Liu, Hengshuai Yao", "title": "QUOTA: The Quantile Option Architecture for Reinforcement Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Quantile Option Architecture (QUOTA) for\nexploration based on recent advances in distributional reinforcement learning\n(RL). In QUOTA, decision making is based on quantiles of a value distribution,\nnot only the mean. QUOTA provides a new dimension for exploration via making\nuse of both optimism and pessimism of a value distribution. We demonstrate the\nperformance advantage of QUOTA in both challenging video games and physical\nrobot simulators.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 22:49:03 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 19:52:47 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Zhang", "Shangtong", ""], ["Mavrin", "Borislav", ""], ["Kong", "Linglong", ""], ["Liu", "Bo", ""], ["Yao", "Hengshuai", ""]]}, {"id": "1811.02130", "submitter": "Prem Seetharaman", "authors": "Prem Seetharaman, Gordon Wichern, Jonathan Le Roux, Bryan Pardo", "title": "Bootstrapping single-channel source separation via unsupervised spatial\n  clustering on stereo mixtures", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating an audio scene into isolated sources is a fundamental problem in\ncomputer audition, analogous to image segmentation in visual scene analysis.\nSource separation systems based on deep learning are currently the most\nsuccessful approaches for solving the underdetermined separation problem, where\nthere are more sources than channels. Traditionally, such systems are trained\non sound mixtures where the ground truth decomposition is already known. Since\nmost real-world recordings do not have such a decomposition available, this\nlimits the range of mixtures one can train on, and the range of mixtures the\nlearned models may successfully separate. In this work, we use a simple blind\nspatial source separation algorithm to generate estimated decompositions of\nstereo mixtures. These estimates, together with a weighting scheme in the\ntime-frequency domain, based on confidence in the separation quality, are used\nto train a deep learning model that can be used for single-channel separation,\nwhere no source direction information is available. This demonstrates how a\nsimple cue such as the direction of origin of source can be used to bootstrap a\nmodel for source separation that can be used in situations where that cue is\nnot available.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 02:20:40 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Seetharaman", "Prem", ""], ["Wichern", "Gordon", ""], ["Roux", "Jonathan Le", ""], ["Pardo", "Bryan", ""]]}, {"id": "1811.02178", "submitter": "Feifan Xu", "authors": "Feifan Xu, Fei He, Enze Xie, Liang Li", "title": "Fast OBDD Reordering using Neural Message Passing on Hypergraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordered binary decision diagrams (OBDDs) are an efficient data structure for\nrepresenting and manipulating Boolean formulas. With respect to different\nvariable orders, the OBDDs' sizes may vary from linear to exponential in the\nnumber of the Boolean variables. Finding the optimal variable order has been\nproved a NP-complete problem. Many heuristics have been proposed to find a\nnear-optimal solution of this problem. In this paper, we propose a neural\nnetwork-based method to predict near-optimal variable orders for unknown\nformulas. Viewing these formulas as hypergraphs, and lifting the message\npassing neural network into 3-hypergraph (MPNN3), we are able to learn the\npatterns of Boolean formula. Compared to the traditional methods, our method\ncan find a near-the-best solution with an extremely shorter time, even for some\nhard examples.To the best of our knowledge, this is the first work on applying\nneural network to OBDD reordering.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 06:07:09 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Xu", "Feifan", ""], ["He", "Fei", ""], ["Xie", "Enze", ""], ["Li", "Liang", ""]]}, {"id": "1811.02188", "submitter": "Ritchie Lee", "authors": "Ritchie Lee, Ole J. Mengshoel, Anshu Saksena, Ryan Gardner, Daniel\n  Genin, Joshua Silbermann, Michael Owen, Mykel J. Kochenderfer", "title": "Adaptive Stress Testing: Finding Likely Failure Events with\n  Reinforcement Learning", "comments": "36 pages, 17 figures, 5 tables", "journal-ref": "Journal of Artificial Intelligence Research (JAIR) 69 (2020)\n  1165-1201", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the most likely path to a set of failure states is important to the\nanalysis of safety-critical systems that operate over a sequence of time steps,\nsuch as aircraft collision avoidance systems and autonomous cars. In many\napplications such as autonomous driving, failures cannot be completely\neliminated due to the complex stochastic environment in which the system\noperates. As a result, safety validation is not only concerned about whether a\nfailure can occur, but also discovering which failures are most likely to\noccur. This article presents adaptive stress testing (AST), a framework for\nfinding the most likely path to a failure event in simulation. We consider a\ngeneral black box setting for partially observable and continuous-valued\nsystems operating in an environment with stochastic disturbances. We formulate\nthe problem as a Markov decision process and use reinforcement learning to\noptimize it. The approach is simulation-based and does not require internal\nknowledge of the system, making it suitable for black-box testing of large\nsystems. We present formulations for fully observable and partially observable\nsystems. In the latter case, we present a modified Monte Carlo tree search\nalgorithm that only requires access to the pseudorandom number generator of the\nsimulator to overcome partial observability. We also present an extension of\nthe framework, called differential adaptive stress testing (DAST), that can\nfind failures that occur in one system but not in another. This type of\ndifferential analysis is useful in applications such as regression testing,\nwhere we are concerned with finding areas of relative weakness compared to a\nbaseline. We demonstrate the effectiveness of the approach on an aircraft\ncollision avoidance application, where a prototype aircraft collision avoidance\nsystem is stress tested to find the most likely scenarios of near mid-air\ncollision.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 06:49:47 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 21:21:48 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 18:56:44 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Lee", "Ritchie", ""], ["Mengshoel", "Ole J.", ""], ["Saksena", "Anshu", ""], ["Gardner", "Ryan", ""], ["Genin", "Daniel", ""], ["Silbermann", "Joshua", ""], ["Owen", "Michael", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1811.02215", "submitter": "Colin Leverger", "authors": "Colin Leverger (LACODAM), Vincent Lemaire, Simon Malinowski (UR1,\n  LinkMedia), Thomas Guyet (LACODAM), Laurence Roz\\'e (LACODAM, INSA Rennes)", "title": "Day-ahead time series forecasting: application to capacity planning", "comments": null, "journal-ref": "AALTD'18 at ECML 2018, Sep 2018, Dublin, Ireland", "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of capacity planning, forecasting the evolution of informatics\nservers usage enables companies to better manage their computational resources.\nWe address this problem by collecting key indicator time series and propose to\nforecast their evolution a day-ahead. Our method assumes that data is\nstructured by a daily seasonality, but also that there is typical evolution of\nindicators within a day. Then, it uses the combination of a clustering\nalgorithm and Markov Models to produce day-ahead forecasts. Our experiments on\nreal datasets show that the data satisfies our assumption and that, in the case\nstudy, our method outperforms classical approaches (AR, Holt-Winters).\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:14:01 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Leverger", "Colin", "", "LACODAM"], ["Lemaire", "Vincent", "", "UR1,\n  LinkMedia"], ["Malinowski", "Simon", "", "UR1,\n  LinkMedia"], ["Guyet", "Thomas", "", "LACODAM"], ["Roz\u00e9", "Laurence", "", "LACODAM, INSA Rennes"]]}, {"id": "1811.02216", "submitter": "Dmitry Maximov", "authors": "Dmitry Maximov", "title": "An Optimal Itinerary Generation in a Configuration Space of Large\n  Intellectual Agent Groups with Linear Logic", "comments": "\"Management of Large-Scale Systems Development\" (MLSD-2018) a full\n  version of the conference paper", "journal-ref": "will be published in Advances in System Science and Applications\n  2019", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A group of intelligent agents which fulfill a set of tasks in parallel is\nrepresented first by the tensor multiplication of corresponding processes in a\nlinear logic game category. An optimal itinerary in the configuration space of\nthe group states is defined as a play with maximal total reward in the\ncategory. New moments also are: the reward is represented as a degree of\ncertainty (visibility) of an agent goal, and the system goals are chosen by the\ngreatest value corresponding to these processes in the system goal lattice.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 08:24:58 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Maximov", "Dmitry", ""]]}, {"id": "1811.02234", "submitter": "Maxime Bucher", "authors": "Maxime Bucher (Palaiseau), St\\'ephane Herbin (Palaiseau), Fr\\'ed\\'eric\n  Jurie", "title": "Semantic bottleneck for computer vision tasks", "comments": null, "journal-ref": "Asian Conference on Computer Vision (ACCV), Dec 2018, Perth,\n  Australia", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for the representation of images that is\nsemantic by nature, addressing the question of computation intelligibility in\ncomputer vision tasks. More specifically, our proposition is to introduce what\nwe call a semantic bottleneck in the processing pipeline, which is a crossing\npoint in which the representation of the image is entirely expressed with\nnatural language , while retaining the efficiency of numerical representations.\nWe show that our approach is able to generate semantic representations that\ngive state-of-the-art results on semantic content-based image retrieval and\nalso perform very well on image classification tasks. Intelligibility is\nevaluated through user centered experiments for failure detection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 09:01:02 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Bucher", "Maxime", "", "Palaiseau"], ["Herbin", "St\u00e9phane", "", "Palaiseau"], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1811.02304", "submitter": "Pan Hu", "authors": "Pan Hu, Boris Motik, Ian Horrocks", "title": "Modular Materialisation of Datalog Programs", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semina\\\"ive algorithm can materialise all consequences of arbitrary\ndatalog rules, and it also forms the basis for incremental algorithms that\nupdate a materialisation as the input facts change. Certain (combinations of)\nrules, however, can be handled much more efficiently using custom algorithms.\nTo integrate such algorithms into a general reasoning approach that can handle\narbitrary rules, we propose a modular framework for materialisation computation\nand its maintenance. We split a datalog program into modules that can be\nhandled using specialised algorithms, and handle the remaining rules using the\nsemina\\\"ive algorithm. We also present two algorithms for computing the\ntransitive and the symmetric-transitive closure of a relation that can be used\nwithin our framework. Finally, we show empirically that our framework can\nhandle arbitrary datalog programs while outperforming existing approaches,\noften by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 11:51:10 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 23:57:54 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Hu", "Pan", ""], ["Motik", "Boris", ""], ["Horrocks", "Ian", ""]]}, {"id": "1811.02366", "submitter": "Antonio Lieto", "authors": "Antonio Lieto and Gian Luca Pozzato", "title": "A Description Logic Framework for Commonsense Conceptual Combination\n  Integrating Typicality, Probabilities and Cognitive Heuristics", "comments": "39 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonmonotonic Description Logic of typicality able to account for\nthe phenomenon of concept combination of prototypical concepts. The proposed\nlogic relies on the logic of typicality ALC TR, whose semantics is based on the\nnotion of rational closure, as well as on the distributed semantics of\nprobabilistic Description Logics, and is equipped with a cognitive heuristic\nused by humans for concept composition. We first extend the logic of typicality\nALC TR by typicality inclusions whose intuitive meaning is that \"there is\nprobability p about the fact that typical Cs are Ds\". As in the distributed\nsemantics, we define different scenarios containing only some typicality\ninclusions, each one having a suitable probability. We then focus on those\nscenarios whose probabilities belong to a given and fixed range, and we exploit\nsuch scenarios in order to ascribe typical properties to a concept C obtained\nas the combination of two prototypical concepts. We also show that reasoning in\nthe proposed Description Logic is EXPTIME-complete as for the underlying ALC.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 14:28:43 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 14:45:20 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 22:05:36 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 08:31:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Lieto", "Antonio", ""], ["Pozzato", "Gian Luca", ""]]}, {"id": "1811.02446", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Knowledge and Blameworthiness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blameworthiness of an agent or a coalition of agents is often defined in\nterms of the principle of alternative possibilities: for the coalition to be\nresponsible for an outcome, the outcome must take place and the coalition\nshould have had a strategy to prevent it. In this article we argue that in the\nsettings with imperfect information, not only should the coalition have had a\nstrategy, but it also should have known that it had a strategy, and it should\nhave known what the strategy was. The main technical result of the article is a\nsound and complete bimodal logic that describes the interplay between knowledge\nand blameworthiness in strategic games with imperfect information.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 16:02:31 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 15:32:25 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 13:15:15 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1811.02454", "submitter": "Zhao Zhong", "authors": "Chen Lin, Zhao Zhong, Wei Wu, Junjie Yan", "title": "Synaptic Strength For Convolutional Neural Network", "comments": "Accepted by NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks(CNNs) are both computation and memory intensive\nwhich hindered their deployment in mobile devices. Inspired by the relevant\nconcept in neural science literature, we propose Synaptic Pruning: a\ndata-driven method to prune connections between input and output feature maps\nwith a newly proposed class of parameters called Synaptic Strength. Synaptic\nStrength is designed to capture the importance of a connection based on the\namount of information it transports. Experiment results show the effectiveness\nof our approach. On CIFAR-10, we prune connections for various CNN models with\nup to 96% , which results in significant size reduction and computation saving.\nFurther evaluation on ImageNet demonstrates that synaptic pruning is able to\ndiscover efficient models which is competitive to state-of-the-art compact CNNs\nsuch as MobileNet-V2 and NasNet-Mobile. Our contribution is summarized as\nfollowing: (1) We introduce Synaptic Strength, a new class of parameters for\nCNNs to indicate the importance of each connections. (2) Our approach can prune\nvarious CNNs with high compression without compromising accuracy. (3) Further\ninvestigation shows, the proposed Synaptic Strength is a better indicator for\nkernel pruning compared with the previous approach in both empirical result and\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:06:49 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Lin", "Chen", ""], ["Zhong", "Zhao", ""], ["Wu", "Wei", ""], ["Yan", "Junjie", ""]]}, {"id": "1811.02483", "submitter": "Yufei Wang", "authors": "Yufei Wang, Zheyuan Ryan Shi, Lantao Yu, Yi Wu, Rohit Singh, Lucas\n  Joppa, Fei Fang", "title": "Deep Reinforcement Learning for Green Security Games with Real-Time\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Green Security Games (GSGs) have been proposed and applied to optimize\npatrols conducted by law enforcement agencies in green security domains such as\ncombating poaching, illegal logging and overfishing. However, real-time\ninformation such as footprints and agents' subsequent actions upon receiving\nthe information, e.g., rangers following the footprints to chase the poacher,\nhave been neglected in previous work. To fill the gap, we first propose a new\ngame model GSG-I which augments GSGs with sequential movement and the vital\nelement of real-time information. Second, we design a novel deep reinforcement\nlearning-based algorithm, DeDOL, to compute a patrolling strategy that adapts\nto the real-time information against a best-responding attacker. DeDOL is built\nupon the double oracle framework and the policy-space response oracle, solving\na restricted game and iteratively adding best response strategies to it through\ntraining deep Q-networks. Exploring the game structure, DeDOL uses\ndomain-specific heuristic strategies as initial strategies and constructs\nseveral local modes for efficient and parallelized training. To our knowledge,\nthis is the first attempt to use Deep Q-Learning for security games.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:43:47 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Wang", "Yufei", ""], ["Shi", "Zheyuan Ryan", ""], ["Yu", "Lantao", ""], ["Wu", "Yi", ""], ["Singh", "Rohit", ""], ["Joppa", "Lucas", ""], ["Fang", "Fei", ""]]}, {"id": "1811.02486", "submitter": "Igor Mordatch", "authors": "Igor Mordatch", "title": "Concept Learning with Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many hallmarks of human intelligence, such as generalizing from limited\nexperience, abstract reasoning and planning, analogical reasoning, creative\nproblem solving, and capacity for language require the ability to consolidate\nexperience into concepts, which act as basic building blocks of understanding\nand reasoning. We present a framework that defines a concept by an energy\nfunction over events in the environment, as well as an attention mask over\nentities participating in the event. Given few demonstration events, our method\nuses inference-time optimization procedure to generate events involving similar\nconcepts or identify entities involved in the concept. We evaluate our\nframework on learning visual, quantitative, relational, temporal concepts from\ndemonstration events in an unsupervised manner. Our approach is able to\nsuccessfully generate and identify concepts in a few-shot setting and resulting\nlearned concepts can be reused across environments. Example videos of our\nresults are available at sites.google.com/site/energyconceptmodels\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:52:20 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Mordatch", "Igor", ""]]}, {"id": "1811.02540", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm", "title": "Regret Circuits: Composability of Regret Minimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is a powerful tool for solving large-scale problems; it\nwas recently used in breakthrough results for large-scale extensive-form game\nsolving. This was achieved by composing simplex regret minimizers into an\noverall regret-minimization framework for extensive-form game strategy spaces.\nIn this paper we study the general composability of regret minimizers. We\nderive a calculus for constructing regret minimizers for composite convex sets\nthat are obtained from convexity-preserving operations on simpler convex sets.\nWe show that local regret minimizers for the simpler sets can be combined with\nadditional regret minimizers into an aggregate regret minimizer for the\ncomposite set. As one application, we show that the CFR framework can be\nconstructed easily from our framework. We also show ways to include curtailing\n(constraining) operations into our framework. For one, they enables the\nconstruction of CFR generalization for extensive-form games with general convex\nstrategy constraints that can cut across decision points.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:30:27 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 20:30:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1811.02546", "submitter": "Paul Yaworsky", "authors": "Paul Yaworsky", "title": "A Model for General Intelligence", "comments": "7 pages; distribution statement added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overarching problem in artificial intelligence (AI) is that we do not\nunderstand the intelligence process well enough to enable the development of\nadequate computational models. Much work has been done in AI over the years at\nlower levels, but a big part of what has been missing involves the high level,\nabstract, general nature of intelligence. We address this gap by developing a\nmodel for general intelligence. To accomplish this, we focus on three basic\naspects of intelligence. First, we must realize the general order and nature of\nintelligence at a high level. Second, we must come to know what these\nrealizations mean with respect to the overall intelligence process. Third, we\nmust describe these realizations as clearly as possible. We propose a\nhierarchical model to help capture and exploit the order within intelligence.\nThe underlying order involves patterns of signals that become organized, stored\nand activated in space and time. These patterns can be described using a\nsimple, general hierarchy, with physical signals at the lowest level,\ninformation in the middle, and abstract signal representations at the top. This\nhigh level perspective provides a big picture that literally helps us see the\nintelligence process, thereby enabling fundamental realizations, a better\nunderstanding and clear descriptions of the intelligence process. The resulting\nmodel can be used to support all kinds of information processing across\nmultiple levels of abstraction. As computer technology improves, and as\ncooperation increases between humans and computers, people will become more\nefficient and more productive in performing their information processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:37:04 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 20:21:25 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Yaworsky", "Paul", ""]]}, {"id": "1811.02597", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Andrew Patterson, Martha White, Richard S. Sutton,\n  Adam White", "title": "Online Off-policy Prediction", "comments": "68 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of online prediction learning, where\nlearning proceeds continuously as the agent interacts with an environment. The\npredictions made by the agent are contingent on a particular way of behaving,\nrepresented as a value function. However, the behavior used to select actions\nand generate the behavior data might be different from the one used to define\nthe predictions, and thus the samples are generated off-policy. The ability to\nlearn behavior-contingent predictions online and off-policy has long been\nadvocated as a key capability of predictive-knowledge learning systems but\nremained an open algorithmic challenge for decades. The issue lies with the\ntemporal difference (TD) learning update at the heart of most prediction\nalgorithms: combining bootstrapping, off-policy sampling and function\napproximation may cause the value estimate to diverge. A breakthrough came with\nthe development of a new objective function that admitted stochastic gradient\ndescent variants of TD. Since then, many sound online off-policy prediction\nalgorithms have been developed, but there has been limited empirical work\ninvestigating the relative merits of all the variants. This paper aims to fill\nthese empirical gaps and provide clarity on the key ideas behind each method.\nWe summarize the large body of literature on off-policy learning, focusing on\n1- methods that use computation linear in the number of features and are\nconvergent under off-policy sampling, and 2- other methods which have proven\nuseful with non-fixed, nonlinear function approximation. We provide an\nempirical study of off-policy prediction methods in two challenging\nmicroworlds. We report each method's parameter sensitivity, empirical\nconvergence rate, and final performance, providing new insights that should\nenable practitioners to successfully extend these new methods to large-scale\napplications.[Abridged abstract]\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 19:09:04 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Ghiassian", "Sina", ""], ["Patterson", "Andrew", ""], ["White", "Martha", ""], ["Sutton", "Richard S.", ""], ["White", "Adam", ""]]}, {"id": "1811.02617", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Category Trees", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.07042", "journal-ref": "WSEAS Transactions on Computer Research, Vol. 6, pp. 49 - 54,\n  2018. E-ISSN: 2415-1521", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a batch classifier that has been improved from the\nearlier version and fixed a mistake in the earlier paper. Two important changes\nhave been made. Each category is represented by a classifier, where each\nclassifier classifies its own subset of data rows, using batch input values to\nrepresent the centroid. The first change is to use the category centroid as the\ndesired category output. When the classifier represents more than one category,\nit creates a new layer and splits, to represent each category separately in the\nnew layer. The second change therefore, is to allow the classifier to branch to\nnew levels when there is a split in the data, or when some data rows are\nincorrectly classified. Each layer can therefore branch like a tree - not for\ndistinguishing features, but for distinguishing categories. The paper then\nsuggests further innovations, by adding fixed value ranges through bands, for\neach column or feature of the input dataset. When considering features, it is\nshown that some of the data can be classified directly through fixed value\nranges, while the rest can be classified using the classifier technique. Tests\nshow that the method can successfully classify a diverse set of benchmark\ndatasets to better than the state-of-the-art. The paper also discusses a\nbiological analogy with neurons and neuron links.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 20:21:26 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 10:32:40 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 11:01:22 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 15:00:57 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2020 14:43:39 GMT"}, {"version": "v6", "created": "Tue, 19 May 2020 14:26:39 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1811.02627", "submitter": "Bin Song", "authors": "Yue Zhang, Bin Song, Xiaojiang Du, and Mohsen Guizani", "title": "Vehicle Tracking Using Surveillance with Multimodal Data Fusion", "comments": "8 pages,6 figures,33 conferences", "journal-ref": null, "doi": "10.1109/TITS.2017.2787101", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle location prediction or vehicle tracking is a significant topic within\nconnected vehicles. This task, however, is difficult if only a single modal\ndata is available, probably causing bias and impeding the accuracy. With the\ndevelopment of sensor networks in connected vehicles, multimodal data are\nbecoming accessible. Therefore, we propose a framework for vehicle tracking\nwith multimodal data fusion. Specifically, we fuse the results of two\nmodalities, images and velocity, in our vehicle-tracking task. Images, being\nprocessed in the module of vehicle detection, provide direct information about\nthe features of vehicles, whereas velocity estimation can further evaluate the\npossible location of the target vehicles, which reduces the number of features\nbeing compared, and decreases the time consumption and computational cost.\nVehicle detection is designed with a color-faster R-CNN, which takes both the\nshape and color of the vehicles into consideration. Meanwhile, velocity\nestimation is through the Kalman filter, which is a classical method for\ntracking. Finally, a multimodal data fusion method is applied to integrate\nthese outcomes so that vehicle-tracking tasks can be achieved. Experimental\nresults suggest the efficiency of our methods, which can track vehicles using a\nseries of surveillance cameras in urban areas.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:14:05 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Zhang", "Yue", ""], ["Song", "Bin", ""], ["Du", "Xiaojiang", ""], ["Guizani", "Mohsen", ""]]}, {"id": "1811.02629", "submitter": "Spyridon Bakas", "authors": "Spyridon Bakas, Mauricio Reyes, Andras Jakab, Stefan Bauer, Markus\n  Rempfler, Alessandro Crimi, Russell Takeshi Shinohara, Christoph Berger, Sung\n  Min Ha, Martin Rozycki, Marcel Prastawa, Esther Alberts, Jana Lipkova, John\n  Freymann, Justin Kirby, Michel Bilello, Hassan Fathallah-Shaykh, Roland\n  Wiest, Jan Kirschke, Benedikt Wiestler, Rivka Colen, Aikaterini Kotrotsou,\n  Pamela Lamontagne, Daniel Marcus, Mikhail Milchenko, Arash Nazeri, Marc-Andre\n  Weber, Abhishek Mahajan, Ujjwal Baid, Elizabeth Gerstner, Dongjin Kwon, Gagan\n  Acharya, Manu Agarwal, Mahbubul Alam, Alberto Albiol, Antonio Albiol,\n  Francisco J. Albiol, Varghese Alex, Nigel Allinson, Pedro H. A. Amorim,\n  Abhijit Amrutkar, Ganesh Anand, Simon Andermatt, Tal Arbel, Pablo Arbelaez,\n  Aaron Avery, Muneeza Azmat, Pranjal B., W Bai, Subhashis Banerjee, Bill\n  Barth, Thomas Batchelder, Kayhan Batmanghelich, Enzo Battistella, Andrew\n  Beers, Mikhail Belyaev, Martin Bendszus, Eze Benson, Jose Bernal, Halandur\n  Nagaraja Bharath, George Biros, Sotirios Bisdas, James Brown, Mariano\n  Cabezas, Shilei Cao, Jorge M. Cardoso, Eric N Carver, Adri\\`a Casamitjana,\n  Laura Silvana Castillo, Marcel Cat\\`a, Philippe Cattin, Albert Cerigues,\n  Vinicius S. Chagas, Siddhartha Chandra, Yi-Ju Chang, Shiyu Chang, Ken Chang,\n  Joseph Chazalon, Shengcong Chen, Wei Chen, Jefferson W Chen, Zhaolin Chen,\n  Kun Cheng, Ahana Roy Choudhury, Roger Chylla, Albert Cl\\'erigues, Steven\n  Colleman, Ramiro German Rodriguez Colmeiro, Marc Combalia, Anthony Costa,\n  Xiaomeng Cui, Zhenzhen Dai, Lutao Dai, Laura Alexandra Daza, Eric Deutsch,\n  Changxing Ding, Chao Dong, Shidu Dong, Wojciech Dudzik, Zach Eaton-Rosen,\n  Gary Egan, Guilherme Escudero, Th\\'eo Estienne, Richard Everson, Jonathan\n  Fabrizio, Yong Fan, Longwei Fang, Xue Feng, Enzo Ferrante, Lucas Fidon,\n  Martin Fischer, Andrew P. French, Naomi Fridman, Huan Fu, David Fuentes,\n  Yaozong Gao, Evan Gates, David Gering, Amir Gholami, Willi Gierke, Ben\n  Glocker, Mingming Gong, Sandra Gonz\\'alez-Vill\\'a, T. Grosges, Yuanfang Guan,\n  Sheng Guo, Sudeep Gupta, Woo-Sup Han, Il Song Han, Konstantin Harmuth,\n  Huiguang He, Aura Hern\\'andez-Sabat\\'e, Evelyn Herrmann, Naveen Himthani,\n  Winston Hsu, Cheyu Hsu, Xiaojun Hu, Xiaobin Hu, Yan Hu, Yifan Hu, Rui Hua,\n  Teng-Yi Huang, Weilin Huang, Sabine Van Huffel, Quan Huo, Vivek HV, Khan M.\n  Iftekharuddin, Fabian Isensee, Mobarakol Islam, Aaron S. Jackson, Sachin R.\n  Jambawalikar, Andrew Jesson, Weijian Jian, Peter Jin, V Jeya Maria Jose,\n  Alain Jungo, B Kainz, Konstantinos Kamnitsas, Po-Yu Kao, Ayush Karnawat,\n  Thomas Kellermeier, Adel Kermi, Kurt Keutzer, Mohamed Tarek Khadir, Mahendra\n  Khened, Philipp Kickingereder, Geena Kim, Nik King, Haley Knapp, Urspeter\n  Knecht, Lisa Kohli, Deren Kong, Xiangmao Kong, Simon Koppers, Avinash Kori,\n  Ganapathy Krishnamurthi, Egor Krivov, Piyush Kumar, Kaisar Kushibar, Dmitrii\n  Lachinov, Tryphon Lambrou, Joon Lee, Chengen Lee, Yuehchou Lee, M Lee,\n  Szidonia Lefkovits, Laszlo Lefkovits, James Levitt, Tengfei Li, Hongwei Li,\n  Wenqi Li, Hongyang Li, Xiaochuan Li, Yuexiang Li, Heng Li, Zhenye Li, Xiaoyu\n  Li, Zeju Li, XiaoGang Li, Wenqi Li, Zheng-Shen Lin, Fengming Lin, Pietro Lio,\n  Chang Liu, Boqiang Liu, Xiang Liu, Mingyuan Liu, Ju Liu, Luyan Liu, Xavier\n  Llado, Marc Moreno Lopez, Pablo Ribalta Lorenzo, Zhentai Lu, Lin Luo, Zhigang\n  Luo, Jun Ma, Kai Ma, Thomas Mackie, Anant Madabushi, Issam Mahmoudi, Klaus H.\n  Maier-Hein, Pradipta Maji, CP Mammen, Andreas Mang, B. S. Manjunath, Michal\n  Marcinkiewicz, S McDonagh, Stephen McKenna, Richard McKinley, Miriam Mehl,\n  Sachin Mehta, Raghav Mehta, Raphael Meier, Christoph Meinel, Dorit Merhof,\n  Craig Meyer, Robert Miller, Sushmita Mitra, Aliasgar Moiyadi, David\n  Molina-Garcia, Miguel A.B. Monteiro, Grzegorz Mrukwa, Andriy Myronenko, Jakub\n  Nalepa, Thuyen Ngo, Dong Nie, Holly Ning, Chen Niu, Nicholas K Nuechterlein,\n  Eric Oermann, Arlindo Oliveira, Diego D. C. Oliveira, Arnau Oliver, Alexander\n  F. I. Osman, Yu-Nian Ou, Sebastien Ourselin, Nikos Paragios, Moo Sung Park,\n  Brad Paschke, J. Gregory Pauloski, Kamlesh Pawar, Nick Pawlowski, Linmin Pei,\n  Suting Peng, Silvio M. Pereira, Julian Perez-Beteta, Victor M. Perez-Garcia,\n  Simon Pezold, Bao Pham, Ashish Phophalia, Gemma Piella, G.N. Pillai, Marie\n  Piraud, Maxim Pisov, Anmol Popli, Michael P. Pound, Reza Pourreza, Prateek\n  Prasanna, Vesna Prkovska, Tony P. Pridmore, Santi Puch, \\'Elodie Puybareau,\n  Buyue Qian, Xu Qiao, Martin Rajchl, Swapnil Rane, Michael Rebsamen, Hongliang\n  Ren, Xuhua Ren, Karthik Revanuru, Mina Rezaei, Oliver Rippel, Luis Carlos\n  Rivera, Charlotte Robert, Bruce Rosen, Daniel Rueckert, Mohammed Safwan,\n  Mostafa Salem, Joaquim Salvi, Irina Sanchez, Irina S\\'anchez, Heitor M.\n  Santos, Emmett Sartor, Dawid Schellingerhout, Klaudius Scheufele, Matthew R.\n  Scott, Artur A. Scussel, Sara Sedlar, Juan Pablo Serrano-Rubio, N. Jon Shah,\n  Nameetha Shah, Mazhar Shaikh, B. Uma Shankar, Zeina Shboul, Haipeng Shen,\n  Dinggang Shen, Linlin Shen, Haocheng Shen, Varun Shenoy, Feng Shi, Hyung Eun\n  Shin, Hai Shu, Diana Sima, M Sinclair, Orjan Smedby, James M. Snyder,\n  Mohammadreza Soltaninejad, Guidong Song, Mehul Soni, Jean Stawiaski, Shashank\n  Subramanian, Li Sun, Roger Sun, Jiawei Sun, Kay Sun, Yu Sun, Guoxia Sun,\n  Shuang Sun, Yannick R Suter, Laszlo Szilagyi, Sanjay Talbar, Dacheng Tao,\n  Dacheng Tao, Zhongzhao Teng, Siddhesh Thakur, Meenakshi H Thakur, Sameer\n  Tharakan, Pallavi Tiwari, Guillaume Tochon, Tuan Tran, Yuhsiang M. Tsai,\n  Kuan-Lun Tseng, Tran Anh Tuan, Vadim Turlapov, Nicholas Tustison, Maria\n  Vakalopoulou, Sergi Valverde, Rami Vanguri, Evgeny Vasiliev, Jonathan\n  Ventura, Luis Vera, Tom Vercauteren, C. A. Verrastro, Lasitha Vidyaratne,\n  Veronica Vilaplana, Ajeet Vivekanandan, Guotai Wang, Qian Wang, Chiatse J.\n  Wang, Weichung Wang, Duo Wang, Ruixuan Wang, Yuanyuan Wang, Chunliang Wang,\n  Guotai Wang, Ning Wen, Xin Wen, Leon Weninger, Wolfgang Wick, Shaocheng Wu,\n  Qiang Wu, Yihong Wu, Yong Xia, Yanwu Xu, Xiaowen Xu, Peiyuan Xu, Tsai-Ling\n  Yang, Xiaoping Yang, Hao-Yu Yang, Junlin Yang, Haojin Yang, Guang Yang,\n  Hongdou Yao, Xujiong Ye, Changchang Yin, Brett Young-Moxon, Jinhua Yu,\n  Xiangyu Yue, Songtao Zhang, Angela Zhang, Kun Zhang, Xuejie Zhang, Lichi\n  Zhang, Xiaoyue Zhang, Yazhuo Zhang, Lei Zhang, Jianguo Zhang, Xiang Zhang,\n  Tianhao Zhang, Sicheng Zhao, Yu Zhao, Xiaomei Zhao, Liang Zhao, Yefeng Zheng,\n  Liming Zhong, Chenhong Zhou, Xiaobing Zhou, Fan Zhou, Hongtu Zhu, Jin Zhu,\n  Ying Zhuge, Weiwei Zong, Jayashree Kalpathy-Cramer, Keyvan Farahani, Christos\n  Davatzikos, Koen van Leemput, Bjoern Menze", "title": "Identifying the Best Machine Learning Algorithms for Brain Tumor\n  Segmentation, Progression Assessment, and Overall Survival Prediction in the\n  BRATS Challenge", "comments": "The International Multimodal Brain Tumor Segmentation (BraTS)\n  Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are the most common primary brain malignancies, with different\ndegrees of aggressiveness, variable prognosis and various heterogeneous\nhistologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic\ncore, active and non-enhancing core. This intrinsic heterogeneity is also\nportrayed in their radio-phenotype, as their sub-regions are depicted by\nvarying intensity profiles disseminated across multi-parametric magnetic\nresonance imaging (mpMRI) scans, reflecting varying biological properties.\nTheir heterogeneous shape, extent, and location are some of the factors that\nmake these tumors difficult to resect, and in some cases inoperable. The amount\nof resected tumor is a factor also considered in longitudinal scans, when\nevaluating the apparent tumor for potential diagnosis of progression.\nFurthermore, there is mounting evidence that accurate segmentation of the\nvarious tumor sub-regions can offer the basis for quantitative image analysis\ntowards prediction of patient overall survival. This study assesses the\nstate-of-the-art machine learning (ML) methods used for brain tumor image\nanalysis in mpMRI scans, during the last seven instances of the International\nBrain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we\nfocus on i) evaluating segmentations of the various glioma sub-regions in\npre-operative mpMRI scans, ii) assessing potential tumor progression by virtue\nof longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO\ncriteria, and iii) predicting the overall survival from pre-operative mpMRI\nscans of patients that underwent gross total resection. Finally, we investigate\nthe challenge of identifying the best ML algorithms for each of these tasks,\nconsidering that apart from being diverse on each instance of the challenge,\nthe multi-institutional mpMRI BraTS dataset has also been a continuously\nevolving/growing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:10:18 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 23:18:19 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 13:35:04 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Bakas", "Spyridon", ""], ["Reyes", "Mauricio", ""], ["Jakab", "Andras", ""], ["Bauer", "Stefan", ""], ["Rempfler", "Markus", ""], ["Crimi", "Alessandro", ""], ["Shinohara", "Russell Takeshi", ""], ["Berger", "Christoph", ""], ["Ha", "Sung Min", ""], ["Rozycki", "Martin", ""], ["Prastawa", "Marcel", ""], ["Alberts", "Esther", ""], ["Lipkova", "Jana", ""], ["Freymann", "John", ""], ["Kirby", "Justin", ""], ["Bilello", "Michel", ""], ["Fathallah-Shaykh", "Hassan", ""], ["Wiest", "Roland", ""], ["Kirschke", "Jan", ""], ["Wiestler", "Benedikt", ""], ["Colen", "Rivka", ""], ["Kotrotsou", "Aikaterini", ""], ["Lamontagne", "Pamela", ""], ["Marcus", "Daniel", ""], ["Milchenko", "Mikhail", ""], ["Nazeri", "Arash", ""], ["Weber", "Marc-Andre", ""], ["Mahajan", "Abhishek", ""], ["Baid", "Ujjwal", ""], ["Gerstner", "Elizabeth", ""], ["Kwon", "Dongjin", ""], ["Acharya", "Gagan", ""], ["Agarwal", "Manu", ""], ["Alam", "Mahbubul", ""], ["Albiol", "Alberto", ""], ["Albiol", "Antonio", ""], ["Albiol", "Francisco J.", ""], ["Alex", "Varghese", ""], ["Allinson", "Nigel", ""], ["Amorim", "Pedro H. A.", ""], ["Amrutkar", "Abhijit", ""], ["Anand", "Ganesh", ""], ["Andermatt", "Simon", ""], ["Arbel", "Tal", ""], ["Arbelaez", "Pablo", ""], ["Avery", "Aaron", ""], ["Azmat", "Muneeza", ""], ["B.", "Pranjal", ""], ["Bai", "W", ""], ["Banerjee", "Subhashis", ""], ["Barth", "Bill", ""], ["Batchelder", "Thomas", ""], ["Batmanghelich", "Kayhan", ""], ["Battistella", "Enzo", ""], ["Beers", "Andrew", ""], ["Belyaev", "Mikhail", ""], ["Bendszus", "Martin", ""], ["Benson", "Eze", ""], ["Bernal", "Jose", ""], ["Bharath", "Halandur Nagaraja", ""], ["Biros", "George", ""], ["Bisdas", "Sotirios", ""], ["Brown", "James", ""], ["Cabezas", "Mariano", ""], ["Cao", "Shilei", ""], ["Cardoso", "Jorge M.", ""], ["Carver", "Eric N", ""], ["Casamitjana", "Adri\u00e0", ""], ["Castillo", "Laura Silvana", ""], ["Cat\u00e0", "Marcel", ""], ["Cattin", "Philippe", ""], ["Cerigues", "Albert", ""], ["Chagas", "Vinicius S.", ""], ["Chandra", "Siddhartha", ""], ["Chang", "Yi-Ju", ""], ["Chang", "Shiyu", ""], ["Chang", "Ken", ""], ["Chazalon", "Joseph", ""], ["Chen", "Shengcong", ""], ["Chen", "Wei", ""], ["Chen", "Jefferson W", ""], ["Chen", "Zhaolin", ""], ["Cheng", "Kun", ""], ["Choudhury", "Ahana Roy", ""], ["Chylla", "Roger", ""], ["Cl\u00e9rigues", "Albert", ""], ["Colleman", "Steven", ""], ["Colmeiro", "Ramiro German Rodriguez", ""], ["Combalia", "Marc", ""], ["Costa", "Anthony", ""], ["Cui", "Xiaomeng", ""], ["Dai", "Zhenzhen", ""], ["Dai", "Lutao", ""], ["Daza", "Laura Alexandra", ""], ["Deutsch", "Eric", ""], ["Ding", "Changxing", ""], ["Dong", "Chao", ""], ["Dong", "Shidu", ""], ["Dudzik", "Wojciech", ""], ["Eaton-Rosen", "Zach", ""], ["Egan", "Gary", ""], ["Escudero", "Guilherme", ""], ["Estienne", "Th\u00e9o", ""], ["Everson", "Richard", ""], ["Fabrizio", "Jonathan", ""], ["Fan", "Yong", ""], ["Fang", "Longwei", ""], ["Feng", "Xue", ""], ["Ferrante", "Enzo", ""], ["Fidon", "Lucas", ""], ["Fischer", "Martin", ""], ["French", "Andrew P.", ""], ["Fridman", "Naomi", ""], ["Fu", "Huan", ""], ["Fuentes", "David", ""], ["Gao", "Yaozong", ""], ["Gates", "Evan", ""], ["Gering", "David", ""], ["Gholami", "Amir", ""], ["Gierke", "Willi", ""], ["Glocker", "Ben", ""], ["Gong", "Mingming", ""], ["Gonz\u00e1lez-Vill\u00e1", "Sandra", ""], ["Grosges", "T.", ""], ["Guan", "Yuanfang", ""], ["Guo", "Sheng", ""], ["Gupta", "Sudeep", ""], ["Han", "Woo-Sup", ""], ["Han", "Il Song", ""], ["Harmuth", "Konstantin", ""], ["He", "Huiguang", ""], ["Hern\u00e1ndez-Sabat\u00e9", "Aura", ""], ["Herrmann", "Evelyn", ""], ["Himthani", "Naveen", ""], ["Hsu", "Winston", ""], ["Hsu", "Cheyu", ""], ["Hu", "Xiaojun", ""], ["Hu", "Xiaobin", ""], ["Hu", "Yan", ""], ["Hu", "Yifan", ""], ["Hua", "Rui", ""], ["Huang", "Teng-Yi", ""], ["Huang", "Weilin", ""], ["Van Huffel", "Sabine", ""], ["Huo", "Quan", ""], ["HV", "Vivek", ""], ["Iftekharuddin", "Khan M.", ""], ["Isensee", "Fabian", ""], ["Islam", "Mobarakol", ""], ["Jackson", "Aaron S.", ""], ["Jambawalikar", "Sachin R.", ""], ["Jesson", "Andrew", ""], ["Jian", "Weijian", ""], ["Jin", "Peter", ""], ["Jose", "V Jeya Maria", ""], ["Jungo", "Alain", ""], ["Kainz", "B", ""], ["Kamnitsas", "Konstantinos", ""], ["Kao", "Po-Yu", ""], ["Karnawat", "Ayush", ""], ["Kellermeier", "Thomas", ""], ["Kermi", "Adel", ""], ["Keutzer", "Kurt", ""], ["Khadir", "Mohamed Tarek", ""], ["Khened", "Mahendra", ""], ["Kickingereder", "Philipp", ""], ["Kim", "Geena", ""], ["King", "Nik", ""], ["Knapp", "Haley", ""], ["Knecht", "Urspeter", ""], ["Kohli", "Lisa", ""], ["Kong", "Deren", ""], ["Kong", "Xiangmao", ""], ["Koppers", "Simon", ""], ["Kori", "Avinash", ""], ["Krishnamurthi", "Ganapathy", ""], ["Krivov", "Egor", ""], ["Kumar", "Piyush", ""], ["Kushibar", "Kaisar", ""], ["Lachinov", "Dmitrii", ""], ["Lambrou", "Tryphon", ""], ["Lee", "Joon", ""], ["Lee", "Chengen", ""], ["Lee", "Yuehchou", ""], ["Lee", "M", ""], ["Lefkovits", "Szidonia", ""], ["Lefkovits", "Laszlo", ""], ["Levitt", "James", ""], ["Li", "Tengfei", ""], ["Li", "Hongwei", ""], ["Li", "Wenqi", ""], ["Li", "Hongyang", ""], ["Li", "Xiaochuan", ""], ["Li", "Yuexiang", ""], ["Li", "Heng", ""], ["Li", "Zhenye", ""], ["Li", "Xiaoyu", ""], ["Li", "Zeju", ""], ["Li", "XiaoGang", ""], ["Li", "Wenqi", ""], ["Lin", "Zheng-Shen", ""], ["Lin", "Fengming", ""], ["Lio", "Pietro", ""], ["Liu", "Chang", ""], ["Liu", "Boqiang", ""], ["Liu", "Xiang", ""], ["Liu", "Mingyuan", ""], ["Liu", "Ju", ""], ["Liu", "Luyan", ""], ["Llado", "Xavier", ""], ["Lopez", "Marc Moreno", ""], ["Lorenzo", "Pablo Ribalta", ""], ["Lu", "Zhentai", ""], ["Luo", "Lin", ""], ["Luo", "Zhigang", ""], ["Ma", "Jun", ""], ["Ma", "Kai", ""], ["Mackie", "Thomas", ""], ["Madabushi", "Anant", ""], ["Mahmoudi", "Issam", ""], ["Maier-Hein", "Klaus H.", ""], ["Maji", "Pradipta", ""], ["Mammen", "CP", ""], ["Mang", "Andreas", ""], ["Manjunath", "B. S.", ""], ["Marcinkiewicz", "Michal", ""], ["McDonagh", "S", ""], ["McKenna", "Stephen", ""], ["McKinley", "Richard", ""], ["Mehl", "Miriam", ""], ["Mehta", "Sachin", ""], ["Mehta", "Raghav", ""], ["Meier", "Raphael", ""], ["Meinel", "Christoph", ""], ["Merhof", "Dorit", ""], ["Meyer", "Craig", ""], ["Miller", "Robert", ""], ["Mitra", "Sushmita", ""], ["Moiyadi", "Aliasgar", ""], ["Molina-Garcia", "David", ""], ["Monteiro", "Miguel A. B.", ""], ["Mrukwa", "Grzegorz", ""], ["Myronenko", "Andriy", ""], ["Nalepa", "Jakub", ""], ["Ngo", "Thuyen", ""], ["Nie", "Dong", ""], ["Ning", "Holly", ""], ["Niu", "Chen", ""], ["Nuechterlein", "Nicholas K", ""], ["Oermann", "Eric", ""], ["Oliveira", "Arlindo", ""], ["Oliveira", "Diego D. C.", ""], ["Oliver", "Arnau", ""], ["Osman", "Alexander F. I.", ""], ["Ou", "Yu-Nian", ""], ["Ourselin", "Sebastien", ""], ["Paragios", "Nikos", ""], ["Park", "Moo Sung", ""], ["Paschke", "Brad", ""], ["Pauloski", "J. Gregory", ""], ["Pawar", "Kamlesh", ""], ["Pawlowski", "Nick", ""], ["Pei", "Linmin", ""], ["Peng", "Suting", ""], ["Pereira", "Silvio M.", ""], ["Perez-Beteta", "Julian", ""], ["Perez-Garcia", "Victor M.", ""], ["Pezold", "Simon", ""], ["Pham", "Bao", ""], ["Phophalia", "Ashish", ""], ["Piella", "Gemma", ""], ["Pillai", "G. N.", ""], ["Piraud", "Marie", ""], ["Pisov", "Maxim", ""], ["Popli", "Anmol", ""], ["Pound", "Michael P.", ""], ["Pourreza", "Reza", ""], ["Prasanna", "Prateek", ""], ["Prkovska", "Vesna", ""], ["Pridmore", "Tony P.", ""], ["Puch", "Santi", ""], ["Puybareau", "\u00c9lodie", ""], ["Qian", "Buyue", ""], ["Qiao", "Xu", ""], ["Rajchl", "Martin", ""], ["Rane", "Swapnil", ""], ["Rebsamen", "Michael", ""], ["Ren", "Hongliang", ""], ["Ren", "Xuhua", ""], ["Revanuru", "Karthik", ""], ["Rezaei", "Mina", ""], ["Rippel", "Oliver", ""], ["Rivera", "Luis Carlos", ""], ["Robert", "Charlotte", ""], ["Rosen", "Bruce", ""], ["Rueckert", "Daniel", ""], ["Safwan", "Mohammed", ""], ["Salem", "Mostafa", ""], ["Salvi", "Joaquim", ""], ["Sanchez", "Irina", ""], ["S\u00e1nchez", "Irina", ""], ["Santos", "Heitor M.", ""], ["Sartor", "Emmett", ""], ["Schellingerhout", "Dawid", ""], ["Scheufele", "Klaudius", ""], ["Scott", "Matthew R.", ""], ["Scussel", "Artur A.", ""], ["Sedlar", "Sara", ""], ["Serrano-Rubio", "Juan Pablo", ""], ["Shah", "N. Jon", ""], ["Shah", "Nameetha", ""], ["Shaikh", "Mazhar", ""], ["Shankar", "B. Uma", ""], ["Shboul", "Zeina", ""], ["Shen", "Haipeng", ""], ["Shen", "Dinggang", ""], ["Shen", "Linlin", ""], ["Shen", "Haocheng", ""], ["Shenoy", "Varun", ""], ["Shi", "Feng", ""], ["Shin", "Hyung Eun", ""], ["Shu", "Hai", ""], ["Sima", "Diana", ""], ["Sinclair", "M", ""], ["Smedby", "Orjan", ""], ["Snyder", "James M.", ""], ["Soltaninejad", "Mohammadreza", ""], ["Song", "Guidong", ""], ["Soni", "Mehul", ""], ["Stawiaski", "Jean", ""], ["Subramanian", "Shashank", ""], ["Sun", "Li", ""], ["Sun", "Roger", ""], ["Sun", "Jiawei", ""], ["Sun", "Kay", ""], ["Sun", "Yu", ""], ["Sun", "Guoxia", ""], ["Sun", "Shuang", ""], ["Suter", "Yannick R", ""], ["Szilagyi", "Laszlo", ""], ["Talbar", "Sanjay", ""], ["Tao", "Dacheng", ""], ["Tao", "Dacheng", ""], ["Teng", "Zhongzhao", ""], ["Thakur", "Siddhesh", ""], ["Thakur", "Meenakshi H", ""], ["Tharakan", "Sameer", ""], ["Tiwari", "Pallavi", ""], ["Tochon", "Guillaume", ""], ["Tran", "Tuan", ""], ["Tsai", "Yuhsiang M.", ""], ["Tseng", "Kuan-Lun", ""], ["Tuan", "Tran Anh", ""], ["Turlapov", "Vadim", ""], ["Tustison", "Nicholas", ""], ["Vakalopoulou", "Maria", ""], ["Valverde", "Sergi", ""], ["Vanguri", "Rami", ""], ["Vasiliev", "Evgeny", ""], ["Ventura", "Jonathan", ""], ["Vera", "Luis", ""], ["Vercauteren", "Tom", ""], ["Verrastro", "C. A.", ""], ["Vidyaratne", "Lasitha", ""], ["Vilaplana", "Veronica", ""], ["Vivekanandan", "Ajeet", ""], ["Wang", "Guotai", ""], ["Wang", "Qian", ""], ["Wang", "Chiatse J.", ""], ["Wang", "Weichung", ""], ["Wang", "Duo", ""], ["Wang", "Ruixuan", ""], ["Wang", "Yuanyuan", ""], ["Wang", "Chunliang", ""], ["Wang", "Guotai", ""], ["Wen", "Ning", ""], ["Wen", "Xin", ""], ["Weninger", "Leon", ""], ["Wick", "Wolfgang", ""], ["Wu", "Shaocheng", ""], ["Wu", "Qiang", ""], ["Wu", "Yihong", ""], ["Xia", "Yong", ""], ["Xu", "Yanwu", ""], ["Xu", "Xiaowen", ""], ["Xu", "Peiyuan", ""], ["Yang", "Tsai-Ling", ""], ["Yang", "Xiaoping", ""], ["Yang", "Hao-Yu", ""], ["Yang", "Junlin", ""], ["Yang", "Haojin", ""], ["Yang", "Guang", ""], ["Yao", "Hongdou", ""], ["Ye", "Xujiong", ""], ["Yin", "Changchang", ""], ["Young-Moxon", "Brett", ""], ["Yu", "Jinhua", ""], ["Yue", "Xiangyu", ""], ["Zhang", "Songtao", ""], ["Zhang", "Angela", ""], ["Zhang", "Kun", ""], ["Zhang", "Xuejie", ""], ["Zhang", "Lichi", ""], ["Zhang", "Xiaoyue", ""], ["Zhang", "Yazhuo", ""], ["Zhang", "Lei", ""], ["Zhang", "Jianguo", ""], ["Zhang", "Xiang", ""], ["Zhang", "Tianhao", ""], ["Zhao", "Sicheng", ""], ["Zhao", "Yu", ""], ["Zhao", "Xiaomei", ""], ["Zhao", "Liang", ""], ["Zheng", "Yefeng", ""], ["Zhong", "Liming", ""], ["Zhou", "Chenhong", ""], ["Zhou", "Xiaobing", ""], ["Zhou", "Fan", ""], ["Zhu", "Hongtu", ""], ["Zhu", "Jin", ""], ["Zhuge", "Ying", ""], ["Zong", "Weiwei", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Farahani", "Keyvan", ""], ["Davatzikos", "Christos", ""], ["van Leemput", "Koen", ""], ["Menze", "Bjoern", ""]]}, {"id": "1811.02657", "submitter": "Tan Nguyen", "authors": "Tan Nguyen, Nhat Ho, Ankit Patel, Anima Anandkumar, Michael I. Jordan,\n  Richard G. Baraniuk", "title": "A Bayesian Perspective of Convolutional Neural Networks through a\n  Deconvolutional Generative Model", "comments": "Keywords: neural nets, generative models, semi-supervised learning,\n  cross-entropy, statistical guarantees 80 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:27:37 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:21:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nguyen", "Tan", ""], ["Ho", "Nhat", ""], ["Patel", "Ankit", ""], ["Anandkumar", "Anima", ""], ["Jordan", "Michael I.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1811.02693", "submitter": "Jacob Rafati", "authors": "Jacob Rafati and Roummel F. Marcia", "title": "Deep Reinforcement Learning via L-BFGS Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms allow artificial agents to improve\ntheir action selections so as to increase rewarding experiences in their\nenvironments. Deep Reinforcement Learning algorithms require solving a\nnonconvex and nonlinear unconstrained optimization problem. Methods for solving\nthe optimization problems in deep RL are restricted to the class of first-order\nalgorithms, such as stochastic gradient descent (SGD). The major drawback of\nthe SGD methods is that they have the undesirable effect of not escaping saddle\npoints and their performance can be seriously obstructed by ill-conditioning.\nFurthermore, SGD methods require exhaustive trial and error to fine-tune many\nlearning parameters. Using second derivative information can result in improved\nconvergence properties, but computing the Hessian matrix for large-scale\nproblems is not practical. Quasi-Newton methods require only first-order\ngradient information, like SGD, but they can construct a low rank approximation\nof the Hessian matrix and result in superlinear convergence. The limited-memory\nBroyden-Fletcher-Goldfarb-Shanno (L-BFGS) approach is one of the most popular\nquasi-Newton methods that construct positive definite Hessian approximations.\nIn this paper, we introduce an efficient optimization method, based on the\nlimited memory BFGS quasi-Newton method using line search strategy -- as an\nalternative to SGD methods. Our method bridges the disparity between first\norder methods and second order methods by continuing to use gradient\ninformation to calculate a low-rank Hessian approximations. We provide formal\nconvergence analysis as well as empirical results on a subset of the classic\nATARI 2600 games. Our results show a robust convergence with preferred\ngeneralization characteristics, as well as fast training time and no need for\nthe experience replaying mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 22:18:21 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:52:38 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Rafati", "Jacob", ""], ["Marcia", "Roummel F.", ""]]}, {"id": "1811.02696", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Hao Chen, Hengshuai Yao", "title": "ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an actor ensemble algorithm, named ACE, for\ncontinuous control with a deterministic policy in reinforcement learning. In\nACE, we use actor ensemble (i.e., multiple actors) to search the global maxima\nof the critic. Besides the ensemble perspective, we also formulate ACE in the\noption framework by extending the option-critic architecture with deterministic\nintra-option policies, revealing a relationship between ensemble and options.\nFurthermore, we perform a look-ahead tree search with those actors and a\nlearned value prediction model, resulting in a refined value estimation. We\ndemonstrate a significant performance boost of ACE over DDPG and its variants\nin challenging physical robot simulators.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 22:32:55 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Zhang", "Shangtong", ""], ["Chen", "Hao", ""], ["Yao", "Hengshuai", ""]]}, {"id": "1811.02701", "submitter": "EPTCS", "authors": "Martha Lewis, Bob Coecke, Jules Hedges, Dimitri Kartsaklis, Dan\n  Marsden", "title": "Proceedings of the 2018 Workshop on Compositional Approaches in Physics,\n  NLP, and Social Sciences", "comments": null, "journal-ref": "EPTCS 283, 2018", "doi": "10.4204/EPTCS.283", "report-no": null, "categories": "cs.CL cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compose parts to form a more complex whole, and to analyze a\nwhole as a combination of elements, is desirable across disciplines. This\nworkshop bring together researchers applying compositional approaches to\nphysics, NLP, cognitive science, and game theory. Within NLP, a long-standing\naim is to represent how words can combine to form phrases and sentences. Within\nthe framework of distributional semantics, words are represented as vectors in\nvector spaces. The categorical model of Coecke et al. [2010], inspired by\nquantum protocols, has provided a convincing account of compositionality in\nvector space models of NLP. There is furthermore a history of vector space\nmodels in cognitive science. Theories of categorization such as those developed\nby Nosofsky [1986] and Smith et al. [1988] utilise notions of distance between\nfeature vectors. More recently G\\\"ardenfors [2004, 2014] has developed a model\nof concepts in which conceptual spaces provide geometric structures, and\ninformation is represented by points, vectors and regions in vector spaces. The\nsame compositional approach has been applied to this formalism, giving\nconceptual spaces theory a richer model of compositionality than previously\n[Bolt et al., 2018]. Compositional approaches have also been applied in the\nstudy of strategic games and Nash equilibria. In contrast to classical game\ntheory, where games are studied monolithically as one global object,\ncompositional game theory works bottom-up by building large and complex games\nfrom smaller components. Such an approach is inherently difficult since the\ninteraction between games has to be considered. Research into categorical\ncompositional methods for this field have recently begun [Ghani et al., 2018].\nMoreover, the interaction between the three disciplines of cognitive science,\nlinguistics and game theory is a fertile ground for research. Game theory in\ncognitive science is a well-established area [Camerer, 2011]. Similarly game\ntheoretic approaches have been applied in linguistics [J\\\"ager, 2008]. Lastly,\nthe study of linguistics and cognitive science is intimately intertwined\n[Smolensky and Legendre, 2006, Jackendoff, 2007]. Physics supplies\ncompositional approaches via vector spaces and categorical quantum theory,\nallowing the interplay between the three disciplines to be examined.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 23:25:45 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Lewis", "Martha", ""], ["Coecke", "Bob", ""], ["Hedges", "Jules", ""], ["Kartsaklis", "Dimitri", ""], ["Marsden", "Dan", ""]]}, {"id": "1811.02728", "submitter": "Rizal Fathony", "authors": "Rizal Fathony, Ashkan Rezaei, Mohammad Ali Bashiri, Xinhua Zhang,\n  Brian D. Ziebart", "title": "Distributionally Robust Graphical Models", "comments": "Appears in Neural Information Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many structured prediction problems, complex relationships between\nvariables are compactly defined using graphical structures. The most prevalent\ngraphical prediction methods---probabilistic graphical models and large margin\nmethods---have their own distinct strengths but also possess significant\ndrawbacks. Conditional random fields (CRFs) are Fisher consistent, but they do\nnot permit integration of customized loss metrics into their learning process.\nLarge-margin models, such as structured support vector machines (SSVMs), have\nthe flexibility to incorporate customized loss metrics, but lack Fisher\nconsistency guarantees. We present adversarial graphical models (AGM), a\ndistributionally robust approach for constructing a predictor that performs\nrobustly for a class of data distributions defined using a graphical structure.\nOur approach enjoys both the flexibility of incorporating customized loss\nmetrics into its design as well as the statistical guarantee of Fisher\nconsistency. We present exact learning and prediction algorithms for AGM with\ntime complexity similar to existing graphical models and show the practical\nbenefits of our approach with experiments.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:18:32 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Fathony", "Rizal", ""], ["Rezaei", "Ashkan", ""], ["Bashiri", "Mohammad Ali", ""], ["Zhang", "Xinhua", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1811.02736", "submitter": "Hyungjun Lim", "authors": "Hyungjun Lim, Younggwan Kim, Youngmoon Jung, Myunghun Jung, and Hoirin\n  Kim", "title": "Learning acoustic word embeddings with phonetically associated triplet\n  network", "comments": "5 pages, 4 figures, submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous researches on acoustic word embeddings used in query-by-example\nspoken term detection have shown remarkable performance improvements when using\na triplet network. However, the triplet network is trained using only a limited\ninformation about acoustic similarity between words. In this paper, we propose\na novel architecture, phonetically associated triplet network (PATN), which\naims at increasing discriminative power of acoustic word embeddings by\nutilizing phonetic information as well as word identity. The proposed model is\nlearned to minimize a combined loss function that was made by introducing a\ncross entropy loss to the lower layer of LSTM-based triplet network. We\nobserved that the proposed method performs significantly better than the\nbaseline triplet network on a word discrimination task with the WSJ dataset\nresulting in over 20% relative improvement in recall rate at 1.0 false alarm\nper hour. Finally, we examined the generalization ability by conducting the\nout-of-domain test on the RM dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 02:38:49 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 05:25:53 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 01:35:25 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lim", "Hyungjun", ""], ["Kim", "Younggwan", ""], ["Jung", "Youngmoon", ""], ["Jung", "Myunghun", ""], ["Kim", "Hoirin", ""]]}, {"id": "1811.02782", "submitter": "Diego Alvarez-Estevez", "authors": "Vicente Moret-Bonillo, Isaac Fern\\'andez-Varela, Diego Alvarez-Estevez", "title": "Uncertainty in Quantum Rule-Based Systems", "comments": "20 pages, 8 tables, 7 figures", "journal-ref": "Archives of Clinical and Biomedical Research, vol. 5, issue 1,\n  2021", "doi": "10.26502/acbr.50170149", "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the problem of the uncertainty in rule-based systems\n(RBS), but from the perspective of quantum computing (QC). In this work we\nfirst remember the characteristics of Quantum Rule-Based Systems (QRBS), a\nconcept defined in a previous article by one of the authors of this paper, and\nwe introduce the problem of quantum uncertainty. We assume that the subjective\nuncertainty that affects the facts of classical RBSs can be treated as a direct\nconsequence of the probabilistic nature of quantum mechanics (QM), and we also\nassume that the uncertainty associated with a given hypothesis is a consequence\nof the propagation of the imprecision through the inferential circuits of RBSs.\nThis article does not intend to contribute anything new to the QM field: it is\na work of artificial intelligence (AI) that uses QC techniques to solve the\nproblem of uncertainty in RBSs. Bearing the above arguments in mind a quantum\nmodel is proposed. This model has been applied to a problem already defined by\none of the authors of this work in a previous publication and which is briefly\ndescribed in this article. Then the model is generalized, and it is thoroughly\nevaluated. The results obtained show that QC is a valid, effective and\nefficient method to deal with the inherent uncertainty of RBSs\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 07:34:23 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Moret-Bonillo", "Vicente", ""], ["Fern\u00e1ndez-Varela", "Isaac", ""], ["Alvarez-Estevez", "Diego", ""]]}, {"id": "1811.02790", "submitter": "Ajay Mandlekar", "authors": "Ajay Mandlekar, Yuke Zhu, Animesh Garg, Jonathan Booher, Max Spero,\n  Albert Tung, Julian Gao, John Emmons, Anchit Gupta, Emre Orbay, Silvio\n  Savarese, Li Fei-Fei", "title": "RoboTurk: A Crowdsourcing Platform for Robotic Skill Learning through\n  Imitation", "comments": "Published at the Conference on Robot Learning (CoRL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning has empowered recent advances in learning robotic\nmanipulation tasks by addressing shortcomings of Reinforcement Learning such as\nexploration and reward specification. However, research in this area has been\nlimited to modest-sized datasets due to the difficulty of collecting large\nquantities of task demonstrations through existing mechanisms. This work\nintroduces RoboTurk to address this challenge. RoboTurk is a crowdsourcing\nplatform for high quality 6-DoF trajectory based teleoperation through the use\nof widely available mobile devices (e.g. iPhone). We evaluate RoboTurk on three\nmanipulation tasks of varying timescales (15-120s) and observe that our user\ninterface is statistically similar to special purpose hardware such as virtual\nreality controllers in terms of task completion times. Furthermore, we observe\nthat poor network conditions, such as low bandwidth and high delay links, do\nnot substantially affect the remote users' ability to perform task\ndemonstrations successfully on RoboTurk. Lastly, we demonstrate the efficacy of\nRoboTurk through the collection of a pilot dataset; using RoboTurk, we\ncollected 137.5 hours of manipulation data from remote workers, amounting to\nover 2200 successful task demonstrations in 22 hours of total system usage. We\nshow that the data obtained through RoboTurk enables policy learning on\nmulti-step manipulation tasks with sparse rewards and that using larger\nquantities of demonstrations during policy learning provides benefits in terms\nof both learning consistency and final performance. For additional results,\nvideos, and to download our pilot dataset, visit\n$\\href{http://roboturk.stanford.edu/}{\\texttt{roboturk.stanford.edu}}$\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 08:01:21 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mandlekar", "Ajay", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Booher", "Jonathan", ""], ["Spero", "Max", ""], ["Tung", "Albert", ""], ["Gao", "Julian", ""], ["Emmons", "John", ""], ["Gupta", "Anchit", ""], ["Orbay", "Emre", ""], ["Savarese", "Silvio", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1811.02872", "submitter": "Mikul\\'a\\v{s} Zelinka", "authors": "Mikul\\'a\\v{s} Zelinka", "title": "Baselines for Reinforcement Learning in Text Games", "comments": "8 pages, published at ICTAI 2018", "journal-ref": null, "doi": "10.1109/ICTAI2018.2018.00125", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn optimal control policies in systems where action space\nis defined by sentences in natural language would allow many interesting\nreal-world applications such as automatic optimisation of dialogue systems.\nText-based games with multiple endings and rewards are a promising platform for\nthis task, since their feedback allows us to employ reinforcement learning\ntechniques to jointly learn text representations and control policies. We argue\nthat the key property of AI agents, especially in the text-games context, is\ntheir ability to generalise to previously unseen games. We present a\nminimalistic text-game playing agent, testing its generalisation and transfer\nlearning performance and showing its ability to play multiple games at once. We\nalso present pyfiction, an open-source library for universal access to\ndifferent text games that could, together with our agent that implements its\ninterface, serve as a baseline for future research.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 13:30:40 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 19:23:15 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Zelinka", "Mikul\u00e1\u0161", ""]]}, {"id": "1811.02945", "submitter": "Marija Jegorova", "authors": "Marija Jegorova, St\\'ephane Doncieux, Timothy Hospedales", "title": "Behavioural Repertoire via Generative Adversarial Policy Networks", "comments": "In Proceedings of 2019 Joint IEEE 9th International Conference on\n  Development and Learning and Epigenetic Robotics (ICDL-EpiRob), pages 320 -\n  326", "journal-ref": "2019 Joint IEEE 9th International Conference on Development and\n  Learning and Epigenetic Robotics (ICDL-EpiRob)", "doi": "10.1109/ICDL-EpiRob44920.2019", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms are enabling robots to solve increasingly challenging\nreal-world tasks. These approaches often rely on demonstrations and reproduce\nthe behavior shown. Unexpected changes in the environment may require using\ndifferent behaviors to achieve the same effect, for instance to reach and grasp\nan object in changing clutter. An emerging paradigm addressing this robustness\nissue is to learn a diverse set of successful behaviors for a given task, from\nwhich a robot can select the most suitable policy when faced with a new\nenvironment. In this paper, we explore a novel realization of this vision by\nlearning a generative model over policies. Rather than learning a single\npolicy, or a small fixed repertoire, our generative model for policies\ncompactly encodes an unbounded number of policies and allows novel controller\nvariants to be sampled. Leveraging our generative policy network, a robot can\nsample novel behaviors until it finds one that works for a new environment. We\ndemonstrate this idea with an application of robust ball-throwing in the\npresence of obstacles. We show that this approach achieves a greater diversity\nof behaviors than an existing evolutionary approach, while maintaining good\nefficacy of sampled behaviors, allowing a Baxter robot to hit targets more\noften when ball throwing in the presence of obstacles.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 15:47:48 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 17:11:05 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:37:28 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jegorova", "Marija", ""], ["Doncieux", "St\u00e9phane", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1811.02959", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Shagun Sodhani, William L. Hamilton and Joelle Pineau", "title": "Compositional Language Understanding with Text-based Relational\n  Reasoning", "comments": "4 pages of main content, to be presented at Relational Representation\n  Learning Workshop, NIPS 2018, Montreal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks for natural language reasoning have largely focused on\nextractive, fact-based question-answering (QA) and common-sense inference.\nHowever, it is also crucial to understand the extent to which neural networks\ncan perform relational reasoning and combinatorial generalization from natural\nlanguage---abilities that are often obscured by annotation artifacts and the\ndominance of language modeling in standard QA benchmarks. In this work, we\npresent a novel benchmark dataset for language understanding that isolates\nperformance on relational reasoning. We also present a neural message-passing\nbaseline and show that this model, which incorporates a relational inductive\nbias, is superior at combinatorial generalization compared to a traditional\nrecurrent neural network approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:17:48 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:32:05 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Sinha", "Koustuv", ""], ["Sodhani", "Shagun", ""], ["Hamilton", "William L.", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.02964", "submitter": "Johannes Klinglmayr", "authors": "Bernhard Bergmair and Thomas Buchegger and Johann Hoffelner and Gerald\n  Schatz and Siegfried Silber and Johannes Klinglmayr", "title": "Instantly Deployable Expert Knowledge - Networks of Knowledge Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge and information are becoming the primary resources of the emerging\ninformation society. To exploit the potential of available expert knowledge,\ncomprehension and application skills (i.e. expert competences) are necessary.\nThe ability to acquire these skills is limited for any individual human.\nConsequently, the capacities to solve problems based on human knowledge in a\nmanual (i.e. mental) way are strongly limited. We envision a new systemic\napproach to enable scalable knowledge deployment without expert competences.\nEventually, the system is meant to instantly deploy humanity's total knowledge\nin full depth for every individual challenge. To this end, we propose a\nsocio-technical framework that transforms expert knowledge into a solution\ncreation system. Knowledge is represented by automated algorithms (knowledge\nengines). Executable compositions of knowledge engines (networks of knowledge\nengines) generate requested individual information at runtime. We outline how\nthese knowledge representations could yield legal, ethical and social\nchallenges and nurture new business and remuneration models on knowledge. We\nidentify major technological and economic concepts that are already pushing the\nboundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge\nbases, ontologies, advanced search tools, automation of knowledge work, the API\neconomy. We indicate impacts on society, economy and labour. Existing\ndevelopments are linked, including a specific use case in engineering design.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:30:08 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Bergmair", "Bernhard", ""], ["Buchegger", "Thomas", ""], ["Hoffelner", "Johann", ""], ["Schatz", "Gerald", ""], ["Silber", "Siegfried", ""], ["Klinglmayr", "Johannes", ""]]}, {"id": "1811.03009", "submitter": "Roman Yampolskiy", "authors": "Yana B. Feygin, Kelly Morris, Roman V. Yampolskiy", "title": "Uploading Brain into Computer: Whom to Upload First?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The final goal of the intelligence augmentation process is a complete merger\nof biological brains and computers allowing for integration and mutual\nenhancement between computer's speed and memory and human's intelligence. This\nprocess, known as uploading, analyzes human brain in detail sufficient to\nunderstand its working patterns and makes it possible to simulate said brain on\na computer. As it is likely that such simulations would quickly evolve or be\nmodified to achieve superintelligence it is very important to make sure that\nthe first brain chosen for such a procedure is a suitable one. In this paper,\nwe attempt to answer the question: Whom to upload first?\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 19:57:47 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Feygin", "Yana B.", ""], ["Morris", "Kelly", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1811.03016", "submitter": "Hadi Mansourifar", "authors": "Hadi Mansourifar, Weidong Shi", "title": "Toward Efficient Breast Cancer Diagnosis and Survival Prediction Using\n  L-Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most frequently reported cancer type among the women\naround the globe and beyond that it has the second highest female fatality rate\namong all cancer types. Despite all the progresses made in prevention and early\nintervention, early prognosis and survival prediction rates are still\nunsatisfactory. In this paper, we propose a novel type of perceptron called\nL-Perceptron which outperforms all the previous supervised learning methods by\nreaching 97.42 \\% and 98.73 \\% in terms of accuracy and sensitivity,\nrespectively in Wisconsin Breast Cancer dataset. Experimental results on\nHaberman's Breast Cancer Survival dataset, show the superiority of proposed\nmethod by reaching 75.18 \\% and 83.86 \\% in terms of accuracy and F1 score,\nrespectively. The results are the best reported ones obtained in 10-fold cross\nvalidation in absence of any preprocessing or feature selection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:17:08 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Mansourifar", "Hadi", ""], ["Shi", "Weidong", ""]]}, {"id": "1811.03035", "submitter": "Can Eren Sezener", "authors": "Can Eren Sezener", "title": "Computing the Value of Computation for Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent agent performs actions in order to achieve its goals. Such\nactions can either be externally directed, such as opening a door, or\ninternally directed, such as writing data to a memory location or strengthening\na synaptic connection. Some internal actions, to which we refer as\ncomputations, potentially help the agent choose better actions. Considering\nthat (external) actions and computations might draw upon the same resources,\nsuch as time and energy, deciding when to act or compute, as well as what to\ncompute, are detrimental to the performance of an agent.\n  In an environment that provides rewards depending on an agent's behavior, an\naction's value is typically defined as the sum of expected long-term rewards\nsucceeding the action (itself a complex quantity that depends on what the agent\ngoes on to do after the action in question). However, defining the value of a\ncomputation is not as straightforward, as computations are only valuable in a\nhigher order way, through the alteration of actions.\n  This thesis offers a principled way of computing the value of a computation\nin a planning setting formalized as a Markov decision process. We present two\ndifferent definitions of computation values: static and dynamic. They address\ntwo extreme cases of the computation budget: affording calculation of zero or\ninfinitely many steps in the future. We show that these values have desirable\nproperties, such as temporal consistency and asymptotic convergence.\n  Furthermore, we propose methods for efficiently computing and approximating\nthe static and dynamic computation values. We describe a sense in which the\npolicies that greedily maximize these values can be optimal. We utilize these\nprinciples to construct Monte Carlo tree search algorithms that outperform most\nof the state-of-the-art in terms of finding higher quality actions given the\nsame simulation resources.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:39:24 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Sezener", "Can Eren", ""]]}, {"id": "1811.03056", "submitter": "Christoph Dann", "authors": "Christoph Dann, Lihong Li, Wei Wei, Emma Brunskill", "title": "Policy Certificates: Towards Accountable Reinforcement Learning", "comments": "article appearing at ICML 2019; full version including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a reinforcement learning algorithm can vary drastically\nduring learning because of exploration. Existing algorithms provide little\ninformation about the quality of their current policy before executing it, and\nthus have limited use in high-stakes applications like healthcare. We address\nthis lack of accountability by proposing that algorithms output policy\ncertificates. These certificates bound the sub-optimality and return of the\npolicy in the next episode, allowing humans to intervene when the certified\nquality is not satisfactory. We further introduce two new algorithms with\ncertificates and present a new framework for theoretical analysis that\nguarantees the quality of their policies and certificates. For tabular MDPs, we\nshow that computing certificates can even improve the sample-efficiency of\noptimism-based exploration. As a result, one of our algorithms is the first to\nachieve minimax-optimal PAC bounds up to lower-order terms, and this algorithm\nalso matches (and in some settings slightly improves upon) existing minimax\nregret bounds.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:16:28 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 15:32:43 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 20:50:36 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dann", "Christoph", ""], ["Li", "Lihong", ""], ["Wei", "Wei", ""], ["Brunskill", "Emma", ""]]}, {"id": "1811.03064", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh", "title": "Towards a Near Universal Time Series Data Mining Tool: Introducing the\n  Matrix Profile", "comments": "PhD dissertation (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a flurry of research on all-pairs-similarity-search\n(or, self-join) for text, DNA, and a handful of other datatypes, and these\nsystems have been applied to many diverse data mining problems. Surprisingly,\nhowever, little progress has been made on addressing this problem for time\nseries subsequences. In this thesis, we have introduced a near universal time\nseries data mining tool called matrix profile which solves the\nall-pairs-similarity-search problem and caches the output in an easy-to-access\nfashion. The proposed algorithm is not only parameter-free, exact and scalable,\nbut also applicable for both single and multidimensional time series. By\nbuilding time series data mining methods on top of matrix profile, many time\nseries data mining tasks (e.g., motif discovery, discord discovery, shapelet\ndiscovery, semantic segmentation, and clustering) can be efficiently solved.\nBecause the same matrix profile can be shared by a diverse set of time series\ndata mining methods, matrix profile is versatile and\ncomputed-once-use-many-times data structure. We demonstrate the utility of\nmatrix profile for many time series data mining problems, including motif\ndiscovery, discord discovery, weakly labeled time series classification, and\nrepresentation learning on domains as diverse as seismology, entomology, music\nprocessing, bioinformatics, human activity monitoring, electrical power-demand\nmonitoring, and medicine. We hope the matrix profile is not the end but the\nbeginning of many more time series data mining projects.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:21:33 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 04:40:46 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""]]}, {"id": "1811.03066", "submitter": "Viraj Prabhu", "authors": "Viraj Prabhu, Anitha Kannan, Murali Ravuri, Manish Chablani, David\n  Sontag, Xavier Amatriain", "title": "Prototypical Clustering Networks for Dermatological Disease Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of image classification for the purpose of aiding\ndoctors in dermatological diagnosis. Dermatological diagnosis poses two major\nchallenges for standard off-the-shelf techniques: First, the data distribution\nis typically extremely long tailed. Second, intra-class variability is often\nlarge. To address the first issue, we formulate the problem as low-shot\nlearning, where once deployed, a base classifier must rapidly generalize to\ndiagnose novel conditions given very few labeled examples. To model diverse\nclasses effectively, we propose Prototypical Clustering Networks (PCN), an\nextension to Prototypical Networks that learns a mixture of prototypes for each\nclass. Prototypes are initialized for each class via clustering and refined via\nan online update scheme. Classification is performed by measuring similarity to\na weighted combination of prototypes within a class, where the weights are the\ninferred cluster responsibilities. We demonstrate the strengths of our approach\nin effective diagnosis on a realistic dataset of dermatological conditions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:27:41 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Prabhu", "Viraj", ""], ["Kannan", "Anitha", ""], ["Ravuri", "Murali", ""], ["Chablani", "Manish", ""], ["Sontag", "David", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1811.03119", "submitter": "Ryan Gardner", "authors": "Jared Markowitz, Ryan W. Gardner, and Ashley J. Llorens", "title": "On the Complexity of Reconnaissance Blind Chess", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a complexity analysis for the game of reconnaissance\nblind chess (RBC), a recently-introduced variant of chess where each player\ndoes not know the positions of the opponent's pieces a priori but may reveal a\nsubset of them through chosen, private sensing actions. In contrast to many\ncommonly studied imperfect information games like poker, an RBC player does not\nknow what the opponent knows or has chosen to learn, exponentially expanding\nthe size of the game's information sets (i.e., the number of possible game\nstates that are consistent with what a player has observed). Effective RBC\nsensing and moving strategies must account for the uncertainty of both players,\nan essential element of many real-world decision-making problems. Here we\nevaluate RBC from a game theoretic perspective, tracking the proliferation of\ninformation sets from the perspective of selected canonical bot players in\ntournament play. We show that, even for effective sensing strategies, the game\nsizes of RBC compare to those of Go while the average size of a player's\ninformation set throughout an RBC game is much greater than that of a player in\nHeads-up Limit Hold 'Em. We compare these measures of complexity among\ndifferent playing algorithms and provide cursory assessments of the various\nsensing and moving strategies.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 19:20:21 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 16:09:19 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Markowitz", "Jared", ""], ["Gardner", "Ryan W.", ""], ["Llorens", "Ashley J.", ""]]}, {"id": "1811.03158", "submitter": "Lin Chen", "authors": "Lin Chen, Lei Xu, Shouhuai Xu, Zhimin Gao, Weidong Shi", "title": "Election with Bribed Voter Uncertainty: Hardness and Approximation\n  Algorithm", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bribery in election (or computational social choice in general) is an\nimportant problem that has received a considerable amount of attention. In the\nclassic bribery problem, the briber (or attacker) bribes some voters in\nattempting to make the briber's designated candidate win an election. In this\npaper, we introduce a novel variant of the bribery problem, \"Election with\nBribed Voter Uncertainty\" or BVU for short, accommodating the uncertainty that\nthe vote of a bribed voter may or may not be counted. This uncertainty occurs\neither because a bribed voter may not cast its vote in fear of being caught, or\nbecause a bribed voter is indeed caught and therefore its vote is discarded. As\na first step towards ultimately understanding and addressing this important\nproblem, we show that it does not admit any multiplicative $O(1)$-approximation\nalgorithm modulo standard complexity assumptions. We further show that there is\nan approximation algorithm that returns a solution with an additive-$\\epsilon$\nerror in FPT time for any fixed $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 21:49:00 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Chen", "Lin", ""], ["Xu", "Lei", ""], ["Xu", "Shouhuai", ""], ["Gao", "Zhimin", ""], ["Shi", "Weidong", ""]]}, {"id": "1811.03163", "submitter": "Tim Miller", "authors": "Tim Miller", "title": "Contrastive Explanation: A Structural-Model Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model of contrastive explanation using structural\ncasual models. The topic of causal explanation in artificial intelligence has\ngathered interest in recent years as researchers and practitioners aim to\nincrease trust and understanding of intelligent decision-making. While\ndifferent sub-fields of artificial intelligence have looked into this problem\nwith a sub-field-specific view, there are few models that aim to capture\nexplanation more generally. One general model is based on structural causal\nmodels. It defines an explanation as a fact that, if found to be true, would\nconstitute an actual cause of a specific event. However, research in philosophy\nand social sciences shows that explanations are contrastive: that is, when\npeople ask for an explanation of an event -- the fact -- they (sometimes\nimplicitly) are asking for an explanation relative to some contrast case; that\nis, \"Why P rather than Q?\". In this paper, we extend the structural causal\nmodel approach to define two complementary notions of contrastive explanation,\nand demonstrate them on two classical problems in artificial intelligence:\nclassification and planning. We believe that this model can help researchers in\nsubfields of artificial intelligence to better understand contrastive\nexplanation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 22:05:45 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 03:06:06 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Miller", "Tim", ""]]}, {"id": "1811.03205", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Ashish Khetan, Zinan Lin, Sewoong Oh", "title": "Robustness of Conditional GANs to Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning conditional generators from noisy labeled\nsamples, where the labels are corrupted by random noise. A standard training of\nconditional GANs will not only produce samples with wrong labels, but also\ngenerate poor quality samples. We consider two scenarios, depending on whether\nthe noise model is known or not. When the distribution of the noise is known,\nwe introduce a novel architecture which we call Robust Conditional GAN (RCGAN).\nThe main idea is to corrupt the label of the generated sample before feeding to\nthe adversarial discriminator, forcing the generator to produce samples with\nclean labels. This approach of passing through a matching noisy channel is\njustified by corresponding multiplicative approximation bounds between the loss\nof the RCGAN and the distance between the clean real distribution and the\ngenerator distribution. This shows that the proposed approach is robust, when\nused with a carefully chosen discriminator architecture, known as projection\ndiscriminator. When the distribution of the noise is not known, we provide an\nextension of our architecture, which we call RCGAN-U, that learns the noise\nmodel simultaneously while training the generator. We show experimentally on\nMNIST and CIFAR-10 datasets that both the approaches consistently improve upon\nbaseline approaches, and RCGAN-U closely matches the performance of RCGAN.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:07:17 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Khetan", "Ashish", ""], ["Lin", "Zinan", ""], ["Oh", "Sewoong", ""]]}, {"id": "1811.03218", "submitter": "Michael Jacobs", "authors": "Michael A. Jacobs, Christopher Umbricht, Vishwa Parekh, Riham El\n  Khouli, Leslie Cope, Katarzyna J. Macura, Susan Harvey, Antonio C. Wolff", "title": "Advanced machine learning informatics modeling using clinical and\n  radiological imaging metrics for characterizing breast tumor characteristics\n  with the OncotypeDX gene array", "comments": "32 pages, 6 figures, Abstract number SSQ01-04:Radiological Society of\n  North America 2015 Scientific Assembly and Annual Meeting,Chicago IL", "journal-ref": null, "doi": null, "report-no": "SSQ01-04", "categories": "physics.med-ph cs.AI cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose-Optimal use of established and imaging methods, such as\nmultiparametric magnetic resonance imaging(mpMRI) can simultaneously identify\nkey functional parameters and provide unique imaging phenotypes of breast\ncancer. Therefore, we have developed and implemented a new machine-learning\ninformatic system that integrates clinical variables, derived from imaging and\nclinical health records, to compare with the 21-gene array assay, OncotypeDX.\nMaterials and methods-We tested our informatics modeling in a subset of\npatients (n=81) who had ER+ disease and underwent OncotypeDX gene expression\nand breast mpMRI testing. The machine-learning informatic method is termed\nIntegrated Radiomic Informatic System-IRIS was applied to the mpMRI, clinical\nand pathologic descriptors, as well as a gene array analysis. The IRIS method\nusing an advanced graph theoretic model and quantitative metrics. Summary\nstatistics (mean and standard deviations) for the quantitative imaging\nparameters were obtained. Sensitivity and specificity and Area Under the Curve\nwere calculated for the classification of the patients. Results-The OncotypeDX\nclassification by IRIS model had sensitivity of 95% and specificity of 89% with\nAUC of 0.92. The breast lesion size was larger for the high-risk groups and\nlower for both low risk and intermediate risk groups. There were significant\ndifferences in PK-DCE and ADC map values in each group. The ADC map values for\nhigh- and intermediate-risk groups were significantly lower than the low-risk\ngroup. Conclusion-These initial studies provide deeper understandings of\nimaging features and molecular gene array OncotypeDX score. This insight\nprovides the foundation to relate these imaging features to the assessment of\ntreatment response for improved personalized medicine.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 01:53:22 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Jacobs", "Michael A.", ""], ["Umbricht", "Christopher", ""], ["Parekh", "Vishwa", ""], ["Khouli", "Riham El", ""], ["Cope", "Leslie", ""], ["Macura", "Katarzyna J.", ""], ["Harvey", "Susan", ""], ["Wolff", "Antonio C.", ""]]}, {"id": "1811.03276", "submitter": "EPTCS", "authors": "Gijs Wijnholds (Queen Mary University of London), Mehrnoosh Sadrzadeh\n  (Queen Mary University of London)", "title": "Classical Copying versus Quantum Entanglement in Natural Language: The\n  Case of VP-ellipsis", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 103-119", "doi": "10.4204/EPTCS.283.8", "report-no": null, "categories": "cs.CL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares classical copying and quantum entanglement in natural\nlanguage by considering the case of verb phrase (VP) ellipsis. VP ellipsis is a\nnon-linear linguistic phenomenon that requires the reuse of resources, making\nit the ideal test case for a comparative study of different copying behaviours\nin compositional models of natural language. Following the line of research in\ncompositional distributional semantics set out by (Coecke et al., 2010) we\ndevelop an extension of the Lambek calculus which admits a controlled form of\ncontraction to deal with the copying of linguistic resources. We then develop\ntwo different compositional models of distributional meaning for this calculus.\nIn the first model, we follow the categorical approach of (Coecke et al., 2013)\nin which a functorial passage sends the proofs of the grammar to linear maps on\nvector spaces and we use Frobenius algebras to allow for copying. In the second\ncase, we follow the more traditional approach that one finds in categorial\ngrammars, whereby an intermediate step interprets proofs as non-linear lambda\nterms, using multiple variable occurrences that model classical copying. As a\ncase study, we apply the models to derive different readings of ambiguous\nelliptical phrases and compare the analyses that each model provides.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:12:46 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wijnholds", "Gijs", "", "Queen Mary University of London"], ["Sadrzadeh", "Mehrnoosh", "", "Queen Mary University of London"]]}, {"id": "1811.03277", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford), Giovanni de Felice (University of\n  Oxford), Dan Marsden (University of Oxford), Alexis Toumi (University of\n  Oxford)", "title": "Towards Compositional Distributional Discourse Analysis", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 1-12", "doi": "10.4204/EPTCS.283.1", "report-no": null, "categories": "cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical compositional distributional semantics provide a method to derive\nthe meaning of a sentence from the meaning of its individual words: the\ngrammatical reduction of a sentence automatically induces a linear map for\ncomposing the word vectors obtained from distributional semantics. In this\npaper, we extend this passage from word-to-sentence to sentence-to-discourse\ncomposition. To achieve this we introduce a notion of basic anaphoric\ndiscourses as a mid-level representation between natural language discourse\nformalised in terms of basic discourse representation structures (DRS); and\nknowledge base queries over the Semantic Web as described by basic graph\npatterns in the Resource Description Framework (RDF). This provides a\nhigh-level specification for compositional algorithms for question answering\nand anaphora resolution, and allows us to give a picture of natural language\nunderstanding as a process involving both statistical and logical resources.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:14:19 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"], ["de Felice", "Giovanni", "", "University of\n  Oxford"], ["Marsden", "Dan", "", "University of Oxford"], ["Toumi", "Alexis", "", "University of\n  Oxford"]]}, {"id": "1811.03325", "submitter": "Xiaoshi Zhong", "authors": "Xiaoshi Zhong and Erik Cambria and Jagath C. Rajapakse", "title": "Discovering Power Laws in Entity Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a discovery that the length of the entities in various\ndatasets follows a family of scale-free power law distributions. The concept of\nentity here broadly includes the named entity, entity mention, time expression,\naspect term, and domain-specific entity that are well investigated in natural\nlanguage processing and related areas. The entity length denotes the number of\nwords in an entity. The power law distributions in entity length possess the\nscale-free property and have well-defined means and finite variances. We\nexplain the phenomenon of power laws in entity length by the principle of least\neffort in communication and the preferential mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 09:16:19 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 14:23:31 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 15:27:40 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhong", "Xiaoshi", ""], ["Cambria", "Erik", ""], ["Rajapakse", "Jagath C.", ""]]}, {"id": "1811.03355", "submitter": "Sanjay Modgil", "authors": "Davide Grossi and Sanjay Modgil", "title": "On the Graded Acceptability of Arguments in Abstract and Instantiated\n  Argumentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a formal theory of the degree of justification of\narguments, which relies solely on the structure of an argumentation framework,\nand which can be successfully interfaced with approaches to instantiated\nargumentation. The theory is developed in three steps. First, the paper\nintroduces a graded generalization of the two key notions underpinning Dung's\nsemantics: self-defense and conflict-freeness. This leads to a natural\ngeneralization of Dung's semantics, whereby standard extensions are weakened or\nstrengthened depending on the level of self-defense and conflict-freeness they\nmeet. The paper investigates the fixpoint theory of these semantics,\nestablishing existence results for them. Second, the paper shows how graded\nsemantics readily provide an approach to argument rankings, offering a novel\ncontribution to the recently growing research programme on ranking-based\nsemantics. Third, this novel approach to argument ranking is applied and\nstudied in the context of instantiated argumentation frameworks, and in so\ndoing is shown to account for a simple form of accrual of arguments within the\nDung paradigm. Finally, the theory is compared in detail with existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 11:08:01 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Grossi", "Davide", ""], ["Modgil", "Sanjay", ""]]}, {"id": "1811.03376", "submitter": "Xi Chen", "authors": "Xi Chen, Ali Ghadirzadeh, M{\\aa}rten Bj\\\"orkman and Patric Jensfelt", "title": "Meta-Learning for Multi-objective Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective reinforcement learning (MORL) is the generalization of\nstandard reinforcement learning (RL) approaches to solve sequential decision\nmaking problems that consist of several, possibly conflicting, objectives.\nGenerally, in such formulations, there is no single optimal policy which\noptimizes all the objectives simultaneously, and instead, a number of policies\nhas to be found each optimizing a preference of the objectives. In other words,\nthe MORL is framed as a meta-learning problem, with the task distribution given\nby a distribution over the preferences. We demonstrate that such a formulation\nresults in a better approximation of the Pareto optimal solutions in terms of\nboth the optimality and the computational efficiency. We evaluated our method\non obtaining Pareto optimal policies using a number of continuous control\nproblems with high degrees of freedom.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 12:26:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 10:35:03 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Chen", "Xi", ""], ["Ghadirzadeh", "Ali", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""], ["Jensfelt", "Patric", ""]]}, {"id": "1811.03388", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie and Hisashi Kashima", "title": "Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing", "comments": "8 pages, 3 figures, 7 tables, to appear at the 33th AAAI Conference\n  on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge tracing is a sequence prediction problem where the goal is to\npredict the outcomes of students over questions as they are interacting with a\nlearning platform. By tracking the evolution of the knowledge of some student,\none can optimize instruction. Existing methods are either based on temporal\nlatent variable models, or factor analysis with temporal features. We here show\nthat factorization machines (FMs), a model for regression or classification,\nencompasses several existing models in the educational literature as special\ncases, notably additive factor model, performance factor model, and\nmultidimensional item response theory. We show, using several real datasets of\ntens of thousands of users and items, that FMs can estimate student knowledge\naccurately and fast even when student data is sparsely observed, and handle\nside information such as multiple knowledge components and number of attempts\nat item or skill level. Our approach allows to fit student models of higher\ndimension than existing models, and provides a testbed to try new combinations\nof features in order to improve existing models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:02:09 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 05:41:18 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Vie", "Jill-J\u00eann", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1811.03433", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicholas Ayache", "title": "Explainable cardiac pathology classification on cine MRI with motion\n  characterization by semi-supervised learning of apparent flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to classify cardiac pathology based on a novel approach\nto extract image derived features to characterize the shape and motion of the\nheart. An original semi-supervised learning procedure, which makes efficient\nuse of a large amount of non-segmented images and a small amount of images\nsegmented manually by experts, is developed to generate pixel-wise apparent\nflow between two time points of a 2D+t cine MRI image sequence. Combining the\napparent flow maps and cardiac segmentation masks, we obtain a local apparent\nflow corresponding to the 2D motion of myocardium and ventricular cavities.\nThis leads to the generation of time series of the radius and thickness of\nmyocardial segments to represent cardiac motion. These time series of motion\nfeatures are reliable and explainable characteristics of pathological cardiac\nmotion. Furthermore, they are combined with shape-related features to classify\ncardiac pathologies. Using only nine feature values as input, we propose an\nexplainable, simple and flexible model for pathology classification. On ACDC\ntraining set and testing set, the model achieves 95% and 94% respectively as\nclassification accuracy. Its performance is hence comparable to that of the\nstate-of-the-art. Comparison with various other models is performed to outline\nsome advantages of our model.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 14:22:05 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 20:52:47 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1811.03493", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma, Adam Safron, and Nick J. Hay", "title": "Integrative Biological Simulation, Neuropsychology, and AI Safety", "comments": "5 pages", "journal-ref": "Proceedings of the AAAI Workshop on Artificial Intelligence Safety\n  2019 co-located with the Thirty-Third AAAI Conference on Artificial\n  Intelligence 2019 (AAAI 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a biologically-inspired research agenda with parallel tracks\naimed at AI and AI safety. The bottom-up component consists of building a\nsequence of biophysically realistic simulations of simple organisms such as the\nnematode $Caenorhabditis$ $elegans$, the fruit fly $Drosophila$ $melanogaster$,\nand the zebrafish $Danio$ $rerio$ to serve as platforms for research into AI\nalgorithms and system architectures. The top-down component consists of an\napproach to value alignment that grounds AI goal structures in neuropsychology,\nbroadly considered. Our belief is that parallel pursuit of these tracks will\ninform the development of value-aligned AI systems that have been inspired by\nembodied organisms with sensorimotor integration. An important set of side\nbenefits is that the research trajectories we describe here are grounded in\nlong-standing intellectual traditions within existing research communities and\nfunding structures. In addition, these research programs overlap with\nsignificant contemporary themes in the biological and psychological sciences\nsuch as data/model integration and reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 01:38:24 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 19:04:47 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sarma", "Gopal P.", ""], ["Safron", "Adam", ""], ["Hay", "Nick J.", ""]]}, {"id": "1811.03496", "submitter": "Helge Spieker", "authors": "Helge Spieker, Arnaud Gotlieb, Morten Mossige", "title": "Multi-Cycle Assignment Problems with Rotational Diversity", "comments": "Extended journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-cycle assignment problems address scenarios where a series of general\nassignment problems has to be solved sequentially. Subsequent cycles can differ\nfrom previous ones due to changing availability or creation of tasks and\nagents, which makes an upfront static schedule infeasible and introduces\nuncertainty in the task-agent assignment process. We consider the setting\nwhere, besides profit maximization, it is also desired to maintain diverse\nassignments for tasks and agents, such that all tasks have been assigned to all\nagents over subsequent cycles. This problem of multi-cycle assignment with\nrotational diversity is approached in two sub-problems: The outer problem which\naugments the original profit maximization objective with additional information\nabout the state of rotational diversity while the inner problem solves the\nadjusted general assignment problem in a single execution of the model. We\ndiscuss strategies to augment the profit values and evaluate them\nexperimentally. The method's efficacy is shown in three case studies:\nmulti-cycle variants of the multiple knapsack and the multiple subset sum\nproblems, and a real-world case study on the test case selection and assignment\nproblem from the software engineering domain.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 15:39:35 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 16:11:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Spieker", "Helge", ""], ["Gotlieb", "Arnaud", ""], ["Mossige", "Morten", ""]]}, {"id": "1811.03532", "submitter": "Duncan McElfresh", "authors": "Duncan C McElfresh, Hoda Bidkhori, John P Dickerson", "title": "Scalable Robust Kidney Exchange", "comments": "Presented at AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In barter exchanges, participants directly trade their endowed goods in a\nconstrained economic setting without money. Transactions in barter exchanges\nare often facilitated via a central clearinghouse that must match participants\neven in the face of uncertainty---over participants, existence and quality of\npotential trades, and so on. Leveraging robust combinatorial optimization\ntechniques, we address uncertainty in kidney exchange, a real-world barter\nmarket where patients swap (in)compatible paired donors. We provide two\nscalable robust methods to handle two distinct types of uncertainty in kidney\nexchange---over the quality and the existence of a potential match. The latter\ncase directly addresses a weakness in all stochastic-optimization-based methods\nto the kidney exchange clearing problem, which all necessarily require explicit\nestimates of the probability of a transaction existing---a still-unsolved\nproblem in this nascent market. We also propose a novel, scalable kidney\nexchange formulation that eliminates the need for an exponential-time\nconstraint generation process in competing formulations, maintains provable\noptimality, and serves as a subsolver for our robust approach. For each type of\nuncertainty we demonstrate the benefits of robustness on real data from a\nlarge, fielded kidney exchange in the United States. We conclude by drawing\nparallels between robustness and notions of fairness in the kidney exchange\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:25:27 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["McElfresh", "Duncan C", ""], ["Bidkhori", "Hoda", ""], ["Dickerson", "John P", ""]]}, {"id": "1811.03539", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira, Diego Pinheiro, Mariana Macedo, Carmelo Bastos-Filho,\n  Ronaldo Menezes", "title": "Uncovering the Social Interaction in Swarm Intelligence with Network\n  Science", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm intelligence is the collective behavior emerging in systems with\nlocally interacting components. Because of their self-organization\ncapabilities, swarm-based systems show essential properties for handling\nreal-world problems such as robustness, scalability, and flexibility. Yet, we\ndo not know why swarm-based algorithms work well and neither we can compare the\ndifferent approaches in the literature. The lack of a common framework capable\nof characterizing these several swarm-based algorithms, transcending their\nparticularities, has led to a stream of publications inspired by different\naspects of nature without a systematic comparison over existing approaches.\nHere, we address this gap by introducing a network-based framework---the\ninteraction network---to examine computational swarm-based systems via the\noptics of the social dynamics of such interaction network; a clear example of\nnetwork science being applied to bring further clarity to a complicated field\nwithin artificial intelligence. We discuss the social interactions of four\nwell-known swarm-based algorithms and provide an in-depth case study of the\nParticle Swarm Optimization. The interaction network enables researchers to\nstudy swarm algorithms as systems, removing the algorithm particularities from\nthe analyses while focusing on the structure of the social interactions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:36:11 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:27:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Oliveira", "Marcos", ""], ["Pinheiro", "Diego", ""], ["Macedo", "Mariana", ""], ["Bastos-Filho", "Carmelo", ""], ["Menezes", "Ronaldo", ""]]}, {"id": "1811.03555", "submitter": "Haoran Tang", "authors": "Dennis Lee, Haoran Tang, Jeffrey O Zhang, Huazhe Xu, Trevor Darrell,\n  Pieter Abbeel", "title": "Modular Architecture for StarCraft II with Deep Reinforcement Learning", "comments": "Accepted to The 14th AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment (AIIDE'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel modular architecture for StarCraft II AI. The architecture\nsplits responsibilities between multiple modules that each control one aspect\nof the game, such as build-order selection or tactics. A centralized scheduler\nreviews macros suggested by all modules and decides their order of execution.\nAn updater keeps track of environment changes and instantiates macros into\nseries of executable actions. Modules in this framework can be optimized\nindependently or jointly via human design, planning, or reinforcement learning.\nWe apply deep reinforcement learning techniques to training two out of six\nmodules of a modular agent with self-play, achieving 94% or 87% win rates\nagainst the \"Harder\" (level 5) built-in Blizzard bot in Zerg vs. Zerg matches,\nwith or without fog-of-war.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:13:50 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Lee", "Dennis", ""], ["Tang", "Haoran", ""], ["Zhang", "Jeffrey O", ""], ["Xu", "Huazhe", ""], ["Darrell", "Trevor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1811.03567", "submitter": "Honglin Chen", "authors": "Will Xiao, Honglin Chen, Qianli Liao and Tomaso Poggio", "title": "Biologically-plausible learning algorithms can scale to large datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation (BP) algorithm is often thought to be biologically\nimplausible in the brain. One of the main reasons is that BP requires symmetric\nweight matrices in the feedforward and feedback pathways. To address this\n\"weight transport problem\" (Grossberg, 1987), two more biologically plausible\nalgorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax\nBP's weight symmetry requirements and demonstrate comparable learning\ncapabilities to that of BP on small datasets. However, a recent study by\nBartunov et al. (2018) evaluate variants of target-propagation (TP) and\nfeedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that\nalthough many of the proposed algorithms perform well on MNIST and CIFAR, they\nperform significantly worse than BP on ImageNet. Here, we additionally evaluate\nthe sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and\nFA in that the feedback and feedforward weights share signs but not magnitudes.\nWe examine the performance of sign-symmetry and feedback alignment on ImageNet\nand MS COCO datasets using different network architectures (ResNet-18 and\nAlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained\nwith sign-symmetry can attain classification performance approaching that of\nBP-trained networks. These results complement the study by Bartunov et al.\n(2018), and establish a new benchmark for future biologically plausible\nlearning algorithms on more difficult datasets and more complex architectures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:43:59 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 21:23:57 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 02:03:52 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Xiao", "Will", ""], ["Chen", "Honglin", ""], ["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1811.03653", "submitter": "Jason Pittman", "authors": "Jason M. Pittman, Jesus P. Espinoza, Courtney Soboleski Crosby", "title": "Stovepiping and Malicious Software: A Critical Review of AGI Containment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Awareness of the possible impacts associated with artificial intelligence has\nrisen in proportion to progress in the field. While there are tremendous\nbenefits to society, many argue that there are just as many, if not more,\nconcerns related to advanced forms of artificial intelligence. Accordingly,\nresearch into methods to develop artificial intelligence safely is increasingly\nimportant. In this paper, we provide an overview of one such safety paradigm:\ncontainment with a critical lens aimed toward generative adversarial networks\nand potentially malicious artificial intelligence. Additionally, we illuminate\nthe potential for a developmental blindspot in the stovepiping of containment\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 19:19:53 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Pittman", "Jason M.", ""], ["Espinoza", "Jesus P.", ""], ["Crosby", "Courtney Soboleski", ""]]}, {"id": "1811.03654", "submitter": "Yang Liu", "authors": "Nripsuta Saxena, Karen Huang, Evan DeFilippis, Goran Radanovic, David\n  Parkes, Yang Liu", "title": "How Do Fairness Definitions Fare? Examining Public Attitudes Towards\n  Algorithmic Definitions of Fairness", "comments": "To appear at AI Ethics and Society (AIES) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the best way to define algorithmic fairness? While many definitions\nof fairness have been proposed in the computer science literature, there is no\nclear agreement over a particular definition. In this work, we investigate\nordinary people's perceptions of three of these fairness definitions. Across\ntwo online experiments, we test which definitions people perceive to be the\nfairest in the context of loan decisions, and whether fairness perceptions\nchange with the addition of sensitive information (i.e., race of the loan\napplicants). Overall, one definition (calibrated fairness) tends to be more\npreferred than the others, and the results also provide support for the\nprinciple of affirmative action.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 19:21:14 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 19:56:07 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Saxena", "Nripsuta", ""], ["Huang", "Karen", ""], ["DeFilippis", "Evan", ""], ["Radanovic", "Goran", ""], ["Parkes", "David", ""], ["Liu", "Yang", ""]]}, {"id": "1811.03685", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "New CleverHans Feature: Better Adversarial Robustness Evaluations with\n  Attack Bundling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report describes a new feature of the CleverHans library\ncalled \"attack bundling\". Many papers about adversarial examples present lists\nof error rates corresponding to different attack algorithms. A common approach\nis to take the maximum across this list and compare defenses against that error\nrate. We argue that a better approach is to use attack bundling: the max should\nbe taken across many examples at the level of individual examples, then the\nerror rate should be calculated by averaging after this maximization operation.\nReporting the bundled attacker error rate provides a lower bound on the true\nworst-case error rate. The traditional approach of reporting the maximum error\nrate across attacks can underestimate the true worst-case error rate by an\namount approaching 100\\% as the number of attacks approaches infinity. Attack\nbundling can be used with different prioritization schemes to optimize\nquantities such as error rate on adversarial examples, perturbation size needed\nto cause misclassification, or failure rate when using a specific confidence\nthreshold.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 21:30:57 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1811.03700", "submitter": "Chao Weng", "authors": "Chao Weng, Dong Yu", "title": "A Comparison of Lattice-free Discriminative Training Criteria for Purely\n  Sequence-Trained Neural Network Acoustic Models", "comments": "under review ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, three lattice-free (LF) discriminative training criteria for\npurely sequence-trained neural network acoustic models are compared on LVCSR\ntasks, namely maximum mutual information (MMI), boosted maximum mutual\ninformation (bMMI) and state-level minimum Bayes risk (sMBR). We demonstrate\nthat, analogous to LF-MMI, a neural network acoustic model can also be trained\nfrom scratch using LF-bMMI or LF-sMBR criteria respectively without the need of\ncross-entropy pre-training. Furthermore, experimental results on\nSwitchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models\ntrained with LF-bMMI consistently outperform those trained with plain LF-MMI\nand achieve a relative word error rate (WER) reduction of 5% over competitive\ntemporal convolution projected LSTM (TDNN-LSTMP) LF-MMI baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 22:37:55 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 10:55:10 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Weng", "Chao", ""], ["Yu", "Dong", ""]]}, {"id": "1811.03733", "submitter": "Bhavya Kailkhura", "authors": "Thomas A. Hogan and Bhavya Kailkhura", "title": "Universal Decision-Based Black-Box Perturbations: Breaking\n  Security-Through-Obscurity Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a universal (image-agnostic) perturbation to\nfool machine learning (ML) classifiers (e.g., neural nets, decision tress) in\nthe hard-label black-box setting. Recent work in adversarial ML in the\nwhite-box setting (model parameters are known) has shown that many\nstate-of-the-art image classifiers are vulnerable to universal adversarial\nperturbations: a fixed human-imperceptible perturbation that, when added to any\nimage, causes it to be misclassified with high probability Kurakin et al.\n[2016], Szegedy et al. [2013], Chen et al. [2017a], Carlini and Wagner [2017].\nThis paper considers a more practical and challenging problem of finding such\nuniversal perturbations in an obscure (or black-box) setting. More\nspecifically, we use zeroth order optimization algorithms to find such a\nuniversal adversarial perturbation when no model information is revealed-except\nthat the attacker can make queries to probe the classifier. We further relax\nthe assumption that the output of a query is continuous valued confidence\nscores for all the classes and consider the case where the output is a\nhard-label decision. Surprisingly, we found that even in these extremely\nobscure regimes, state-of-the-art ML classifiers can be fooled with a very high\nprobability just by adding a single human-imperceptible image perturbation to\nany natural image. The surprising existence of universal perturbations in a\nhard-label black-box setting raises serious security concerns with the\nexistence of a universal noise vector that adversaries can possibly exploit to\nbreak a classifier on most natural images.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 01:43:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:56:52 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Hogan", "Thomas A.", ""], ["Kailkhura", "Bhavya", ""]]}, {"id": "1811.03742", "submitter": "Xingyu Li", "authors": "Xingyu Li, Bogdan I. Epureanu", "title": "Analysis of Fleet Modularity in an Artificial Intelligence-Based\n  Attacker-Defender Game", "comments": "30 pages, 15 figures, manuscript to be submitted to European Journal\n  of Operational Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because combat environments change over time and technology upgrades are\nwidespread for ground vehicles, a large number of vehicles and equipment become\nquickly obsolete. A possible solution for the U.S. Army is to develop fleets of\nmodular military vehicles, which are built by interchangeable substantial\ncomponents also known as modules. One of the typical characteristics of module\nis their ease of assembly and disassembly through simple means such as\nplug-in/pull-out actions, which allows for real-time fleet reconfiguration to\nmeet dynamic demands. Moreover, military demands are time-varying and highly\nstochastic because commanders keep reacting to enemy's actions. To capture\nthese characteristics, we formulated an intelligent agent-based model to\nimitate decision making process during fleet operation, which combines\nreal-time optimization with artificial intelligence. The agents are capable of\ninferring enemy's future move based on historical data and optimize\ndispatch/operation decisions accordingly. We implement our model to simulate an\nattacker-defender game between two adversarial and intelligent players,\nrepresenting the commanders from modularized fleet and conventional fleet\nrespectively. Given the same level of combat resources and intelligence, we\nhighlight the tactical advantages of fleet modularity in terms of win rate,\nunpredictability and suffered damage.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 02:24:19 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2019 20:26:35 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Li", "Xingyu", ""], ["Epureanu", "Bogdan I.", ""]]}, {"id": "1811.03751", "submitter": "Sailik Sengupta", "authors": "Niharika Jain, Lydia Manikonda, Alberto Olmo Hernandez, Sailik\n  Sengupta and Subbarao Kambhampati", "title": "Imagining an Engineer: On GAN-Based Data Augmentation Perpetuating\n  Biases", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of synthetic data generated by Generative Adversarial Networks (GANs)\nhas become quite a popular method to do data augmentation for many\napplications. While practitioners celebrate this as an economical way to get\nmore synthetic data that can be used to train downstream classifiers, it is not\nclear that they recognize the inherent pitfalls of this technique. In this\npaper, we aim to exhort practitioners against deriving any false sense of\nsecurity against data biases based on data augmentation. To drive this point\nhome, we show that starting with a dataset consisting of head-shots of\nengineering researchers, GAN-based augmentation \"imagines\" synthetic engineers,\nmost of whom have masculine features and white skin color (inferred from a\nhuman subject study conducted on Amazon Mechanical Turk). This demonstrates how\nbiases inherent in the training data are reinforced, and sometimes even\namplified, by GAN-based data augmentation; it should serve as a cautionary tale\nfor the lay practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:02:35 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Jain", "Niharika", ""], ["Manikonda", "Lydia", ""], ["Hernandez", "Alberto Olmo", ""], ["Sengupta", "Sailik", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1811.03804", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, Xiyu Zhai", "title": "Gradient Descent Finds Global Minima of Deep Neural Networks", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent finds a global minimum in training deep neural networks\ndespite the objective function being non-convex. The current paper proves\ngradient descent achieves zero training loss in polynomial time for a deep\nover-parameterized neural network with residual connections (ResNet). Our\nanalysis relies on the particular structure of the Gram matrix induced by the\nneural network architecture. This structure allows us to show the Gram matrix\nis stable throughout the training process and this stability implies the global\noptimality of the gradient descent algorithm. We further extend our analysis to\ndeep residual convolutional neural networks and obtain a similar convergence\nresult.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 07:39:59 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 05:31:53 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 03:35:26 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 19:01:22 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Li", "Haochuan", ""], ["Wang", "Liwei", ""], ["Zhai", "Xiyu", ""]]}, {"id": "1811.03819", "submitter": "Chao Yu", "authors": "Chao Yu", "title": "The Price of Governance: A Middle Ground Solution to Coordination in\n  Organizational Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving coordination is crucial in organizational control. This paper\ninvestigates a middle ground solution between decentralized interactions and\ncentralized administrations for coordinating agents beyond inefficient\nbehavior. We first propose the price of governance (PoG) to evaluate how such a\nmiddle ground solution performs in terms of effectiveness and cost. We then\npropose a hierarchical supervision framework to explicitly model the PoG, and\ndefine step by step how to realize the core principle of the framework and\ncompute the optimal PoG for a control problem. Two illustrative case studies\nare carried out to exemplify the applications of the proposed framework and its\nmethodology. Results show that by properly formulating and implementing each\nstep, the hierarchical supervision framework is capable of promoting\ncoordination among agents while bounding administrative cost to a minimum in\ndifferent kinds of organizational control problems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 08:58:16 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Yu", "Chao", ""]]}, {"id": "1811.03822", "submitter": "Bin Liu", "authors": "Bin Liu", "title": "A Very Brief and Critical Discussion on AutoML", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution presents a very brief and critical discussion on automated\nmachine learning (AutoML), which is categorized here into two classes, referred\nto as narrow AutoML and generalized AutoML, respectively. The conclusions\nyielded from this discussion can be summarized as follows: (1) most existent\nresearch on AutoML belongs to the class of narrow AutoML; (2) advances in\nnarrow AutoML are mainly motivated by commercial needs, while any possible\nbenefit obtained is definitely at a cost of increase in computing burdens;\n(3)the concept of generalized AutoML has a strong tie in spirit with artificial\ngeneral intelligence (AGI), also called \"strong AI\", for which obstacles abound\nfor obtaining pivotal progresses.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 09:07:52 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Liu", "Bin", ""]]}, {"id": "1811.03830", "submitter": "Guillaume Jaume", "authors": "Guillaume Jaume, Behzad Bozorgtabar, Hazim Kemal Ekenel, Jean-Philippe\n  Thiran, Maria Gabrani", "title": "Image-Level Attentional Context Modeling Using Nested-Graph Neural\n  Networks", "comments": "NIPS 2018, Relational Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new scene graph generation method called image-level\nattentional context modeling (ILAC). Our model includes an attentional graph\nnetwork that effectively propagates contextual information across the graph\nusing image-level features. Whereas previous works use an object-centric\ncontext, we build an image-level context agent to encode the scene properties.\nThe proposed method comprises a single-stream network that iteratively refines\nthe scene graph with a nested graph neural network. We demonstrate that our\napproach achieves competitive performance with the state-of-the-art for scene\ngraph generation on the Visual Genome dataset, while requiring fewer parameters\nthan other methods. We also show that ILAC can improve regular object detectors\nby incorporating relational image-level information.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 09:33:31 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 07:46:33 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jaume", "Guillaume", ""], ["Bozorgtabar", "Behzad", ""], ["Ekenel", "Hazim Kemal", ""], ["Thiran", "Jean-Philippe", ""], ["Gabrani", "Maria", ""]]}, {"id": "1811.03831", "submitter": "Philippe Toint", "authors": "S. Bellavia and G. Gurioli and B. Morini and Ph.L. Toint", "title": "Adaptive Regularization Algorithms with Inexact Evaluations for\n  Nonconvex Optimization", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regularization algorithm using inexact function values and inexact\nderivatives is proposed and its evaluation complexity analyzed. This algorithm\nis applicable to unconstrained problems and to problems with inexpensive\nconstraints (that is constraints whose evaluation and enforcement has\nnegligible cost) under the assumption that the derivative of highest degree is\n$\\beta$-H\\\"{o}lder continuous. It features a very flexible adaptive mechanism\nfor determining the inexactness which is allowed, at each iteration, when\ncomputing objective function values and derivatives. The complexity analysis\ncovers arbitrary optimality order and arbitrary degree of available approximate\nderivatives. It extends results of Cartis, Gould and Toint (2018) on the\nevaluation complexity to the inexact case: if a $q$th order minimizer is sought\nusing approximations to the first $p$ derivatives, it is proved that a suitable\napproximate minimizer within $\\epsilon$ is computed by the proposed algorithm\nin at most $O(\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ iterations and at most\n$O(|\\log(\\epsilon)|\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ approximate\nevaluations. An algorithmic variant, although more rigid in practice, can be\nproved to find such an approximate minimizer in\n$O(|\\log(\\epsilon)|+\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ evaluations.While\nthe proposed framework remains so far conceptual for high degrees and orders,\nit is shown to yield simple and computationally realistic inexact methods when\nspecialized to the unconstrained and bound-constrained first- and second-order\ncases. The deterministic complexity results are finally extended to the\nstochastic context, yielding adaptive sample-size rules for subsampling methods\ntypical of machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 09:39:53 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 09:01:24 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 13:17:04 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Bellavia", "S.", ""], ["Gurioli", "G.", ""], ["Morini", "B.", ""], ["Toint", "Ph. L.", ""]]}, {"id": "1811.03853", "submitter": "Qiming Zou", "authors": "Qiming Zou, Ling Wang, Ke Lu, Yu Li", "title": "Sample-Efficient Policy Learning based on Completely Behavior Cloning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct policy search is one of the most important algorithm of reinforcement\nlearning. However, learning from scratch needs a large amount of experience\ndata and can be easily prone to poor local optima. In addition to that, a\npartially trained policy tends to perform dangerous action to agent and\nenvironment. In order to overcome these challenges, this paper proposed a\npolicy initialization algorithm called Policy Learning based on Completely\nBehavior Cloning (PLCBC). PLCBC first transforms the Model Predictive Control\n(MPC) controller into a piecewise affine (PWA) function using multi-parametric\nprogramming, and uses a neural network to express this function. By this way,\nPLCBC can completely clone the MPC controller without any performance loss, and\nis totally training-free. The experiments show that this initialization\nstrategy can help agent learn at the high reward state region, and converge\nfaster and better.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 10:34:53 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Zou", "Qiming", ""], ["Wang", "Ling", ""], ["Lu", "Ke", ""], ["Li", "Yu", ""]]}, {"id": "1811.03866", "submitter": "Timo Schick", "authors": "Timo Schick, Hinrich Sch\\\"utze", "title": "Learning Semantic Representations for Novel Words: Leveraging Both Form\n  and Context", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a key component of high-performing natural language\nprocessing (NLP) systems, but it remains a challenge to learn good\nrepresentations for novel words on the fly, i.e., for words that did not occur\nin the training data. The general problem setting is that word embeddings are\ninduced on an unlabeled training corpus and then a model is trained that embeds\nnovel words into this induced embedding space. Currently, two approaches for\nlearning embeddings of novel words exist: (i) learning an embedding from the\nnovel word's surface-form (e.g., subword n-grams) and (ii) learning an\nembedding from the context in which it occurs. In this paper, we propose an\narchitecture that leverages both sources of information - surface-form and\ncontext - and show that it results in large increases in embedding quality. Our\narchitecture obtains state-of-the-art results on the Definitional Nonce and\nContextual Rare Words datasets. As input, we only require an embedding set and\nan unlabeled corpus for training our architecture to produce embeddings\nappropriate for the induced embedding space. Thus, our model can easily be\nintegrated into any existing NLP system and enhance its capability to handle\nnovel words.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 11:44:05 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1811.03868", "submitter": "Eduardo C\\'esar Garrido Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an and Alejandro Albarca-Molina", "title": "Suggesting Cooking Recipes Through Simulation and Bayesian Optimization", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-03493-1_30", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooking typically involves a plethora of decisions about ingredients and\ntools that need to be chosen in order to write a good cooking recipe. Cooking\ncan be modelled in an optimization framework, as it involves a search space of\ningredients, kitchen tools, cooking times or temperatures. If we model as an\nobjective function the quality of the recipe, several problems arise. No\nanalytical expression can model all the recipes, so no gradients are available.\nThe objective function is subjective, in other words, it contains noise.\nMoreover, evaluations are expensive both in time and human resources. Bayesian\nOptimization (BO) emerges as an ideal methodology to tackle problems with these\ncharacteristics. In this paper, we propose a methodology to suggest recipe\nrecommendations based on a Machine Learning (ML) model that fits real and\nsimulated data and BO. We provide empirical evidence with two experiments that\nsupport the adequacy of the methodology.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 11:48:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Albarca-Molina", "Alejandro", ""]]}, {"id": "1811.03906", "submitter": "Helge Spieker", "authors": "Arnaud Gotlieb, Dusica Marijan, Helge Spieker", "title": "ITE: A Lightweight Implementation of Stratified Reasoning for\n  Constructive Logical Operators", "comments": "Extended journal version", "journal-ref": "International Journal on Artificial Intelligence Tools, Vol. 29,\n  No. 03n04, 2060006 (2020)", "doi": "10.1142/S0218213020600064", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Programming (CP) is a powerful declarative programming paradigm\nwhere inference and search are interleaved to find feasible and optimal\nsolutions to various type of constraint systems. However, handling logical\nconnectors with constructive information in CP is notoriously difficult. This\npaper presents If Then Else (ITE), a lightweight implementation of stratified\nconstructive reasoning for logical connectives. Stratification is introduced to\ncope with the risk of combinatorial explosion of constructing information from\nnested and combined logical operators. ITE is an open-source library built on\ntop of SICStus Prolog clp(fd), which proposes various operators, including\nconstructive disjunction and negation, constructive implication and\nconditional. These operators can be used to express global constraints and to\nbenefit from constructive reasoning for more domain pruning during constraint\nfiltering. Even though ITE is not competitive with specialized filtering\nalgorithms available in some global constraints implementations, its\nexpressiveness allows users to easily define well-tuned constraints with\npowerful deduction capabilities. Our extended experimental results show that\nITE is more efficient than available generic approaches that handle logical\nconstraint systems over finite domains.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:07:47 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 14:26:14 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 06:23:43 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gotlieb", "Arnaud", ""], ["Marijan", "Dusica", ""], ["Spieker", "Helge", ""]]}, {"id": "1811.03909", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas, Iraklis A. Klampanos and Vangelis Karkaletsis", "title": "Evidence Transfer for Improving Clustering Tasks Using External\n  Categorical Evidence", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852384", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce evidence transfer for clustering, a deep learning\nmethod that can incrementally manipulate the latent representations of an\nautoencoder, according to external categorical evidence, in order to improve a\nclustering outcome. By evidence transfer we define the process by which the\ncategorical outcome of an external, auxiliary task is exploited to improve a\nprimary task, in this case representation learning for clustering. Our proposed\nmethod makes no assumptions regarding the categorical evidence presented, nor\nthe structure of the latent space. We compare our method, against the baseline\nsolution by performing k-means clustering before and after its deployment.\nExperiments with three different kinds of evidence show that our method\neffectively manipulates the latent representations when introduced with real\ncorresponding evidence, while remaining robust when presented with low quality\nevidence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:10:18 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2018 19:39:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""], ["Karkaletsis", "Vangelis", ""]]}, {"id": "1811.04028", "submitter": "Philipp Blandfort", "authors": "Philipp Blandfort, J\\\"orn Hees, Desmond U. Patton", "title": "An Overview of Computational Approaches for Interpretation Analysis", "comments": "Preprint submitted to Digital Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is said that beauty is in the eye of the beholder. But how exactly can we\ncharacterize such discrepancies in interpretation? For example, are there any\nspecific features of an image that makes person A regard an image as beautiful\nwhile person B finds the same image displeasing? Such questions ultimately aim\nat explaining our individual ways of interpretation, an intention that has been\nof fundamental importance to the social sciences from the beginning. More\nrecently, advances in computer science brought up two related questions: First,\ncan computational tools be adopted for analyzing ways of interpretation?\nSecond, what if the \"beholder\" is a computer model, i.e., how can we explain a\ncomputer model's point of view? Numerous efforts have been made regarding both\nof these points, while many existing approaches focus on particular aspects and\nare still rather separate. With this paper, in order to connect these\napproaches we introduce a theoretical framework for analyzing interpretation,\nwhich is applicable to interpretation of both human beings and computer models.\nWe give an overview of relevant computational approaches from various fields,\nand discuss the most common and promising application areas. The focus of this\npaper lies on interpretation of text and image data, while many of the\npresented approaches are applicable to other types of data as well.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 17:25:25 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 09:14:59 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Blandfort", "Philipp", ""], ["Hees", "J\u00f6rn", ""], ["Patton", "Desmond U.", ""]]}, {"id": "1811.04047", "submitter": "Hongyang Jia", "authors": "Hongyang Jia, Yinqi Tang, Hossein Valavi, Jintao Zhang and Naveen\n  Verma", "title": "A Microprocessor implemented in 65nm CMOS with Configurable and\n  Bit-scalable Accelerator for Programmable In-memory Computing", "comments": null, "journal-ref": "IEEE Journal of Solid-State Circuits, vol. 55, no. 9, pp.\n  2609-2621, Sept. 2020", "doi": "10.1109/JSSC.2020.2987714", "report-no": null, "categories": "cs.AR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a programmable in-memory-computing processor,\ndemonstrated in a 65nm CMOS technology. For data-centric workloads, such as\ndeep neural networks, data movement often dominates when implemented with\ntoday's computing architectures. This has motivated spatial architectures,\nwhere the arrangement of data-storage and compute hardware is distributed and\nexplicitly aligned to the computation dataflow, most notably for matrix-vector\nmultiplication. In-memory computing is a spatial architecture where processing\nelements correspond to dense bit cells, providing local storage and compute,\ntypically employing analog operation. Though this raises the potential for high\nenergy efficiency and throughput, analog operation has significantly limited\nrobustness, scale, and programmability. This paper describes a 590kb\nin-memory-computing accelerator integrated in a programmable processor\narchitecture, by exploiting recent approaches to charge-domain in-memory\ncomputing. The architecture takes the approach of tight coupling with an\nembedded CPU, through accelerator interfaces enabling integration in the\nstandard processor memory space. Additionally, a near-memory-computing datapath\nboth enables diverse computations locally, to address operations required\nacross applications, and enables bit-precision scalability for\nmatrix/input-vector elements, through a bit-parallel/bit-serial (BP/BS) scheme.\nChip measurements show an energy efficiency of 152/297 1b-TOPS/W and throughput\nof 4.7/1.9 1b-TOPS (scaling linearly with the matrix/input-vector element\nprecisions) at VDD of 1.2/0.85V. Neural network demonstrations with 1-b/4-b\nweights and activations for CIFAR-10 classification consume 5.3/105.2\n$\\mu$J/image at 176/23 fps, with accuracy at the level of digital/software\nimplementation (89.3/92.4 $\\%$ accuracy).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 18:03:14 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Jia", "Hongyang", ""], ["Tang", "Yinqi", ""], ["Valavi", "Hossein", ""], ["Zhang", "Jintao", ""], ["Verma", "Naveen", ""]]}, {"id": "1811.04122", "submitter": "Helge Spieker", "authors": "Helge Spieker, Arnaud Gotlieb, Dusica Marijan, Morten Mossige", "title": "Reinforcement Learning for Automatic Test Case Prioritization and\n  Selection in Continuous Integration", "comments": "Spieker, H., Gotlieb, A., Marijan, D., & Mossige, M. (2017).\n  Reinforcement Learning for Automatic Test Case Prioritization and Selection\n  in Continuous Integration. In Proceedings of 26th International Symposium on\n  Software Testing and Analysis (ISSTA'17) (pp. 12--22). ACM", "journal-ref": null, "doi": "10.1145/3092703.3092709", "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing in Continuous Integration (CI) involves test case prioritization,\nselection, and execution at each cycle. Selecting the most promising test cases\nto detect bugs is hard if there are uncertainties on the impact of committed\ncode changes or, if traceability links between code and tests are not\navailable. This paper introduces Retecs, a new method for automatically\nlearning test case selection and prioritization in CI with the goal to minimize\nthe round-trip time between code commits and developer feedback on failed test\ncases. The Retecs method uses reinforcement learning to select and prioritize\ntest cases according to their duration, previous last execution and failure\nhistory. In a constantly changing environment, where new test cases are created\nand obsolete test cases are deleted, the Retecs method learns to prioritize\nerror-prone test cases higher under guidance of a reward function and by\nobserving previous CI cycles. By applying Retecs on data extracted from three\nindustrial case studies, we show for the first time that reinforcement learning\nenables fruitful automatic adaptive test case selection and prioritization in\nCI and regression testing.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 20:08:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Spieker", "Helge", ""], ["Gotlieb", "Arnaud", ""], ["Marijan", "Dusica", ""], ["Mossige", "Morten", ""]]}, {"id": "1811.04132", "submitter": "Monireh Ebrahimi", "authors": "Monireh Ebrahimi, Md Kamruzzaman Sarker, Federico Bianchi, Ning Xie,\n  Derek Doran, Pascal Hitzler", "title": "Reasoning over RDF Knowledge Bases using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic Web knowledge representation standards, and in particular RDF and\nOWL, often come endowed with a formal semantics which is considered to be of\nfundamental importance for the field. Reasoning, i.e., the drawing of logical\ninferences from knowledge expressed in such standards, is traditionally based\non logical deductive methods and algorithms which can be proven to be sound and\ncomplete and terminating, i.e. correct in a very strong sense. For various\nreasons, though, in particular, the scalability issues arising from the\never-increasing amounts of Semantic Web data available and the inability of\ndeductive algorithms to deal with noise in the data, it has been argued that\nalternative means of reasoning should be investigated which bear high promise\nfor high scalability and better robustness. From this perspective, deductive\nalgorithms can be considered the gold standard regarding correctness against\nwhich alternative methods need to be tested. In this paper, we show that it is\npossible to train a Deep Learning system on RDF knowledge graphs, such that it\nis able to perform reasoning over new RDF knowledge graphs, with high precision\nand recall compared to the deductive gold standard.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 21:00:46 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Ebrahimi", "Monireh", ""], ["Sarker", "Md Kamruzzaman", ""], ["Bianchi", "Federico", ""], ["Xie", "Ning", ""], ["Doran", "Derek", ""], ["Hitzler", "Pascal", ""]]}, {"id": "1811.04172", "submitter": "Zhengwei Wang", "authors": "Zhengwei Wang, Graham Healy, Alan F. Smeaton, Tomas E. Ward", "title": "Use of Neural Signals to Evaluate the Quality of Generative Adversarial\n  Network Performance in Facial Image Generation", "comments": null, "journal-ref": "Cognitive Computation, August 2019", "doi": "10.1007/s12559-019-09670-y", "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in using generative adversarial networks (GANs)\nto produce image content that is indistinguishable from real images as judged\nby a typical person. A number of GAN variants for this purpose have been\nproposed, however, evaluating GANs performance is inherently difficult because\ncurrent methods for measuring the quality of their output are not always\nconsistent with what a human perceives. We propose a novel approach that\ncombines a brain-computer interface (BCI) with GANs to generate a measure we\ncall Neuroscore, which closely mirrors the behavioral ground truth measured\nfrom participants tasked with discerning real from synthetic images. This\ntechnique we call a neuro-AI interface, as it provides an interface between a\nhuman's neural systems and an AI process. In this paper, we first compare the\nthree most widely used metrics in the literature for evaluating GANs in terms\nof visual quality and compare their outputs with human judgments. Secondly we\npropose and demonstrate a novel approach using neural signals and rapid serial\nvisual presentation (RSVP) that directly measures a human perceptual response\nto facial production quality, independent of a behavioral response measurement.\nThe correlation between our proposed Neuroscore and human perceptual judgments\nhas Pearson correlation statistics: $\\mathrm{r}(48) = -0.767, \\mathrm{p} =\n2.089e-10$. We also present the bootstrap result for the correlation i.e.,\n$\\mathrm{p}\\leq 0.0001$. Results show that our Neuroscore is more consistent\nwith human judgment compared to the conventional metrics we evaluated. We\nconclude that neural signals have potential applications for high quality,\nrapid evaluation of GANs in the context of visual image synthesis.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 01:37:56 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 16:22:03 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 15:28:39 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Wang", "Zhengwei", ""], ["Healy", "Graham", ""], ["Smeaton", "Alan F.", ""], ["Ward", "Tomas E.", ""]]}, {"id": "1811.04173", "submitter": "Son-Il Kwak", "authors": "Chung-Jin Kwak, Son-Il Kwak, Dae-Song Kang, Song-Il Choe, Jin-Ung Kim,\n  Hyok-Gi Chea", "title": "New Movement and Transformation Principle of Fuzzy Reasoning and Its\n  Application to Fuzzy Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new fuzzy reasoning principle, so called Movement\nand Transformation Principle(MTP). This Principle is to obtain a new fuzzy\nreasoning result by Movement and Transformation the consequent fuzzy set in\nresponse to the Movement, Transformation, and Movement-Transformation\noperations between the antecedent fuzzy set and fuzzificated observation\ninformation. And then we presented fuzzy modus ponens and fuzzy modus tollens\nbased on MTP. We compare proposed method with Mamdani fuzzy system, Sugeno\nfuzzy system, Wang distance type fuzzy reasoning method and Hellendoorn\nfunctional type method. And then we applied to the learning experiments of the\nfuzzy neural network based on MTP and compared it with the Sugeno method.\nThrough prediction experiments of fuzzy neural network on the precipitation\ndata and security situation data, learning accuracy and time performance are\nclearly improved. Consequently we show that our method based on MTP is\ncomputationally simple and does not involve nonlinear operations, so it is easy\nto handle mathematically.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 01:46:28 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Kwak", "Chung-Jin", ""], ["Kwak", "Son-Il", ""], ["Kang", "Dae-Song", ""], ["Choe", "Song-Il", ""], ["Kim", "Jin-Ung", ""], ["Chea", "Hyok-Gi", ""]]}, {"id": "1811.04179", "submitter": "Valts Blukis", "authors": "Valts Blukis, Dipendra Misra, Ross A. Knepper, Yoav Artzi", "title": "Mapping Navigation Instructions to Continuous Control Actions with\n  Position-Visitation Prediction", "comments": "Appeared in Conference on Robot Learning 2018", "journal-ref": "In Conference on Robot Learning (pp. 505-518) (2018)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach for mapping natural language instructions and raw\nobservations to continuous control of a quadcopter drone. Our model predicts\ninterpretable position-visitation distributions indicating where the agent\nshould go during execution and where it should stop, and uses the predicted\ndistributions to select the actions to execute. This two-step model\ndecomposition allows for simple and efficient training using a combination of\nsupervised learning and imitation learning. We evaluate our approach with a\nrealistic drone simulator, and demonstrate absolute task-completion accuracy\nimprovements of 16.85% over two state-of-the-art instruction-following methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 02:57:38 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 18:37:30 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Blukis", "Valts", ""], ["Misra", "Dipendra", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "1811.04184", "submitter": "Farshid Farhat", "authors": "Farshid Farhat, Mohammad Mahdi Kamani, James Z. Wang", "title": "CAPTAIN: Comprehensive Composition Assistance for Photo Taking", "comments": "30 pages, 21 figures, 4 tables, submitted to IJCV (International\n  Journal of Computer Vision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people are interested in taking astonishing photos and sharing with\nothers. Emerging hightech hardware and software facilitate ubiquitousness and\nfunctionality of digital photography. Because composition matters in\nphotography, researchers have leveraged some common composition techniques to\nassess the aesthetic quality of photos computationally. However, composition\ntechniques developed by professionals are far more diverse than well-documented\ntechniques can cover. We leverage the vast underexplored innovations in\nphotography for computational composition assistance. We propose a\ncomprehensive framework, named CAPTAIN (Composition Assistance for Photo\nTaking), containing integrated deep-learned semantic detectors, sub-genre\ncategorization, artistic pose clustering, personalized aesthetics-based image\nretrieval, and style set matching. The framework is backed by a large dataset\ncrawled from a photo-sharing Website with mostly photography enthusiasts and\nprofessionals. The work proposes a sequence of steps that have not been\nexplored in the past by researchers. The work addresses personal preferences\nfor composition through presenting a ranked-list of photographs to the user\nbased on user-specified weights in the similarity measure. The matching\nalgorithm recognizes the best shot among a sequence of shots with respect to\nthe user's preferred style set. We have conducted a number of experiments on\nthe newly proposed components and reported findings. A user study demonstrates\nthat the work is useful to those taking photos.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 03:43:05 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Farhat", "Farshid", ""], ["Kamani", "Mohammad Mahdi", ""], ["Wang", "James Z.", ""]]}, {"id": "1811.04210", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Densely Connected Attention Propagation for Reading Comprehension", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DecaProp (Densely Connected Attention Propagation), a new densely\nconnected neural architecture for reading comprehension (RC). There are two\ndistinct characteristics of our model. Firstly, our model densely connects all\npairwise layers of the network, modeling relationships between passage and\nquery across all hierarchical levels. Secondly, the dense connectors in our\nnetwork are learned via attention instead of standard residual skip-connectors.\nTo this end, we propose novel Bidirectional Attention Connectors (BAC) for\nefficiently forging connections throughout the network. We conduct extensive\nexperiments on four challenging RC benchmarks. Our proposed approach achieves\nstate-of-the-art results on all four, outperforming existing baselines by up to\n$2.6\\%-14.2\\%$ in absolute F1 score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 07:54:13 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 11:19:54 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1811.04234", "submitter": "Felix Petersen", "authors": "Felix Petersen, Moritz Schubotz, Bela Gipp", "title": "Towards Formula Translation using Recursive Neural Networks", "comments": "11 pages, Work-in-Progress paper in CICM-WS 2018 Workshop Papers at\n  11th Conference on Intelligent Computer Mathematics CICM 2018", "journal-ref": "Conference on Intelligent Computer Mathematics (CICM) 2018,\n  CEUR-WS Vol-2307, WiP3", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it has become common to perform automated translations on natural\nlanguage, performing translations between different representations of\nmathematical formulae has thus far not been possible. We implemented the first\ntranslator for mathematical formulae based on recursive neural networks. We\nchose recursive neural networks because mathematical formulae inherently\ninclude a structural encoding. In our implementation, we developed new\ntechniques and topologies for recursive tree-to-tree neural networks based on\nmulti-variate multi-valued Long Short-Term Memory cells. We propose a novel\napproach for mini-batch training that utilizes clustering and tree traversal.\nWe evaluate our translator and analyze the behavior of our proposed topologies\nand techniques based on a translation from generic LaTeX to the semantic LaTeX\nnotation. We use the semantic LaTeX notation from the Digital Library for\nMathematical Formulae and the Digital Repository for Mathematical Formulae at\nthe National Institute for Standards and Technology. We find that a simple\nheuristics-based clustering algorithm outperforms the conventional clustering\nalgorithms on the task of clustering binary trees of mathematical formulae with\nrespect to their topology. Furthermore, we find a mask for the loss function,\nwhich can prevent the neural network from finding a local minimum of the loss\nfunction. Given our preliminary results, a complete translation from formula to\nformula is not yet possible. However, we achieved a prediction accuracy of\n47.05% for predicting symbols at the correct position and an accuracy of 92.3%\nwhen ignoring the predicted position. Concluding, our work advances the field\nof recursive neural networks by improving the training speed and quality of\ntraining. In the future, we will work towards a complete translation allowing a\nmachine-interpretation of LaTeX formulae.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 11:20:18 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Petersen", "Felix", ""], ["Schubotz", "Moritz", ""], ["Gipp", "Bela", ""]]}, {"id": "1811.04272", "submitter": "Chao Yu", "authors": "Chao Yu, Tianpei Yang, Wenxuan Zhu, Dongxu wang, Guangliang Li", "title": "Learning Shaping Strategies in Human-in-the-loop Interactive\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing reinforcement learning agents with informationally rich human\nknowledge can dramatically improve various aspects of learning. Prior work has\ndeveloped different kinds of shaping methods that enable agents to learn\nefficiently in complex environments. All these methods, however, tailor human\nguidance to agents in specialized shaping procedures, thus embodying various\ncharacteristics and advantages in different domains. In this paper, we\ninvestigate the interplay between different shaping methods for more robust\nlearning performance. We propose an adaptive shaping algorithm which is capable\nof learning the most suitable shaping method in an on-line manner. Results in\ntwo classic domains verify its effectiveness from both simulated and real human\nstudies, shedding some light on the role and impact of human factors in\nhuman-robot collaborative learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 15:26:31 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Yu", "Chao", ""], ["Yang", "Tianpei", ""], ["Zhu", "Wenxuan", ""], ["wang", "Dongxu", ""], ["Li", "Guangliang", ""]]}, {"id": "1811.04303", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "PolyNeuron: Automatic Neuron Discovery via Learned Polyharmonic Spline\n  Activations", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated deep neural network architecture design has received a significant\namount of recent attention. However, this attention has not been equally shared\nby one of the fundamental building blocks of a deep neural network, the\nneurons. In this study, we propose PolyNeuron, a novel automatic neuron\ndiscovery approach based on learned polyharmonic spline activations. More\nspecifically, PolyNeuron revolves around learning polyharmonic splines,\ncharacterized by a set of control points, that represent the activation\nfunctions of the neurons in a deep neural network. A relaxed variant of\nPolyNeuron, which we term PolyNeuron-R, loosens the constraints imposed by\nPolyNeuron to reduce the computational complexity for discovering the neuron\nactivation functions in an automated manner. Experiments show both PolyNeuron\nand PolyNeuron-R lead to networks that have improved or comparable performance\non multiple network architectures (LeNet-5 and ResNet-20) using different\ndatasets (MNIST and CIFAR10). As such, automatic neuron discovery approaches\nsuch as PolyNeuron is a worthy direction to explore.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 20:14:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.04323", "submitter": "Ryosuke Furuta", "authors": "Ryosuke Furuta, Naoto Inoue, Toshihiko Yamasaki", "title": "Fully Convolutional Network with Multi-Step Reinforcement Learning for\n  Image Processing", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles a new problem setting: reinforcement learning with\npixel-wise rewards (pixelRL) for image processing. After the introduction of\nthe deep Q-network, deep RL has been achieving great success. However, the\napplications of deep RL for image processing are still limited. Therefore, we\nextend deep RL to pixelRL for various image processing applications. In\npixelRL, each pixel has an agent, and the agent changes the pixel value by\ntaking an action. We also propose an effective learning method for pixelRL that\nsignificantly improves the performance by considering not only the future\nstates of the own pixel but also those of the neighbor pixels. The proposed\nmethod can be applied to some image processing tasks that require pixel-wise\nmanipulations, where deep RL has never been applied. We apply the proposed\nmethod to three image processing tasks: image denoising, image restoration, and\nlocal color enhancement. Our experimental results demonstrate that the proposed\nmethod achieves comparable or better performance, compared with the\nstate-of-the-art methods based on supervised learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 22:59:44 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:58:01 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Furuta", "Ryosuke", ""], ["Inoue", "Naoto", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "1811.04343", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Konark Jain, Ratneel V. Deo, Sally Cripps", "title": "Langevin-gradient parallel tempering for Bayesian neural learning", "comments": "In review. Software:\n  https://github.com/sydney-machine-learning/parallel-tempering-neural-net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural learning feature a rigorous approach to estimation and\nuncertainty quantification via the posterior distribution of weights that\nrepresent knowledge of the neural network. This not only provides point\nestimates of optimal set of weights but also the ability to quantify\nuncertainty in decision making using the posterior distribution. Markov chain\nMonte Carlo (MCMC) techniques are typically used to obtain sample-based\nestimates of the posterior distribution. However, these techniques face\nchallenges in convergence and scalability, particularly in settings with large\ndatasets and network architectures. This paper address these challenges in two\nways. First, parallel tempering is used used to explore multiple modes of the\nposterior distribution and implemented in multi-core computing architecture.\nSecond, we make within-chain sampling schemes more efficient by using Langevin\ngradient information in forming Metropolis-Hastings proposal distributions. We\ndemonstrate the techniques using time series prediction and pattern\nclassification applications. The results show that the method not only improves\nthe computational time, but provides better prediction or decision making\ncapabilities when compared to related methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 03:53:54 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Konark", ""], ["Deo", "Ratneel V.", ""], ["Cripps", "Sally", ""]]}, {"id": "1811.04345", "submitter": "Ishan Jindal", "authors": "Ishan Jindal, Zhiwei Qin, Xuewen Chen, Matthew Nokleby and Jieping Ye", "title": "Optimizing Taxi Carpool Policies via Reinforcement Learning and\n  Spatio-Temporal Mining", "comments": "Accepted at IEEE International Conference on Big Data 2018. arXiv\n  admin note: text overlap with arXiv:1710.04350", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a reinforcement learning (RL) based system to learn\nan effective policy for carpooling that maximizes transportation efficiency so\nthat fewer cars are required to fulfill the given amount of trip demand. For\nthis purpose, first, we develop a deep neural network model, called ST-NN\n(Spatio-Temporal Neural Network), to predict taxi trip time from the raw GPS\ntrip data. Secondly, we develop a carpooling simulation environment for RL\ntraining, with the output of ST-NN and using the NYC taxi trip dataset. In\norder to maximize transportation efficiency and minimize traffic congestion, we\nchoose the effective distance covered by the driver on a carpool trip as the\nreward. Therefore, the more effective distance a driver achieves over a trip\n(i.e. to satisfy more trip demand) the higher the efficiency and the less will\nbe the traffic congestion. We compared the performance of RL learned policy to\na fixed policy (which always accepts carpool) as a baseline and obtained\npromising results that are interpretable and demonstrate the advantage of our\nRL approach. We also compare the performance of ST-NN to that of\nstate-of-the-art travel time estimation methods and observe that ST-NN\nsignificantly improves the prediction performance and is more robust to\noutliers.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:13:31 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Jindal", "Ishan", ""], ["Qin", "Zhiwei", ""], ["Chen", "Xuewen", ""], ["Nokleby", "Matthew", ""], ["Ye", "Jieping", ""]]}, {"id": "1811.04350", "submitter": "John Yang", "authors": "John Yang, Gyujeong Lee, Minsung Hyun, Simyung Chang, Nojun Kwak", "title": "Towards Governing Agent's Efficacy: Action-Conditional $\\beta$-VAE for\n  Deep Transparent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the blackbox issue of deep neural networks in the settings of\nreinforcement learning (RL) where neural agents learn towards maximizing reward\ngains in an uncontrollable way. Such learning approach is risky when the\ninteracting environment includes an expanse of state space because it is then\nalmost impossible to foresee all unwanted outcomes and penalize them with\nnegative rewards beforehand. Unlike reverse analysis of learned neural features\nfrom previous works, our proposed method \\nj{tackles the blackbox issue by\nencouraging} an RL policy network to learn interpretable latent features\nthrough an implementation of a disentangled representation learning method.\nToward this end, our method allows an RL agent to understand self-efficacy by\ndistinguishing its influences from uncontrollable environmental factors, which\nclosely resembles the way humans understand their scenes. Our experimental\nresults show that the learned latent factors not only are interpretable, but\nalso enable modeling the distribution of entire visited state space with a\nspecific action condition. We have experimented that this characteristic of the\nproposed structure can lead to ex post facto governance for desired behaviors\nof RL agents.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 04:48:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Yang", "John", ""], ["Lee", "Gyujeong", ""], ["Hyun", "Minsung", ""], ["Chang", "Simyung", ""], ["Kwak", "Nojun", ""]]}, {"id": "1811.04352", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang and Yafang Huang and Hai Zhao", "title": "Open Vocabulary Learning for Neural Chinese Pinyin IME", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pinyin-to-character (P2C) conversion is the core component of pinyin-based\nChinese input method engine (IME). However, the conversion is seriously\ncompromised by the ambiguities of Chinese characters corresponding to pinyin as\nwell as the predefined fixed vocabularies. To alleviate such inconveniences, we\npropose a neural P2C conversion model augmented by an online updated vocabulary\nwith a sampling mechanism to support open vocabulary learning during IME\nworking. Our experiments show that the proposed method outperforms commercial\nIMEs and state-of-the-art traditional models on standard corpus and true\ninputting history dataset in terms of multiple metrics and thus the online\nupdated vocabulary indeed helps our IME effectively follows user inputting\nbehavior.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 05:07:25 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:02:18 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 07:11:16 GMT"}, {"version": "v4", "created": "Thu, 6 Jun 2019 12:54:31 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Huang", "Yafang", ""], ["Zhao", "Hai", ""]]}, {"id": "1811.04364", "submitter": "Shehroz Khan", "authors": "Amir Ahmad, Shehroz S. Khan", "title": "Survey of state-of-the-art mixed data clustering algorithms", "comments": "20 Pages, 2 columns, 6 Tables, 209 References", "journal-ref": "IEEE Access, 2019", "doi": "10.1109/ACCESS.2019.2903568", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed data comprises both numeric and categorical features, and mixed\ndatasets occur frequently in many domains, such as health, finance, and\nmarketing. Clustering is often applied to mixed datasets to find structures and\nto group similar objects for further analysis. However, clustering mixed data\nis challenging because it is difficult to directly apply mathematical\noperations, such as summation or averaging, to the feature values of these\ndatasets. In this paper, we present a taxonomy for the study of mixed data\nclustering algorithms by identifying five major research themes. We then\npresent a state-of-the-art review of the research works within each research\ntheme. We analyze the strengths and weaknesses of these methods with pointers\nfor future research directions. Lastly, we present an in-depth analysis of the\noverall challenges in this field, highlight open research questions and discuss\nguidelines to make progress in the field.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 07:27:51 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 23:11:42 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 22:30:04 GMT"}, {"version": "v4", "created": "Tue, 29 Jan 2019 05:54:20 GMT"}, {"version": "v5", "created": "Sat, 9 Mar 2019 21:25:46 GMT"}, {"version": "v6", "created": "Mon, 18 Mar 2019 18:30:33 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Ahmad", "Amir", ""], ["Khan", "Shehroz S.", ""]]}, {"id": "1811.04369", "submitter": "Izzeddin Gur", "authors": "Izzeddin Gur, Dilek Hakkani-Tur, Gokhan Tur, Pararth Shah", "title": "User Modeling for Task Oriented Dialogues", "comments": "Accepted at SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce end-to-end neural network based models for simulating users of\ntask-oriented dialogue systems. User simulation in dialogue systems is crucial\nfrom two different perspectives: (i) automatic evaluation of different dialogue\nmodels, and (ii) training task-oriented dialogue systems. We design a\nhierarchical sequence-to-sequence model that first encodes the initial user\ngoal and system turns into fixed length representations using Recurrent Neural\nNetworks (RNN). It then encodes the dialogue history using another RNN layer.\nAt each turn, user responses are decoded from the hidden representations of the\ndialogue level RNN. This hierarchical user simulator (HUS) approach allows the\nmodel to capture undiscovered parts of the user goal without the need of an\nexplicit dialogue state tracking. We further develop several variants by\nutilizing a latent variable model to inject random variations into user\nresponses to promote diversity in simulated user responses and a novel goal\nregularization mechanism to penalize divergence of user responses from the\ninitial user goal. We evaluate the proposed models on movie ticket booking\ndomain by systematically interacting each user simulator with various dialogue\nsystem policies trained with different objectives and users.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 08:21:55 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gur", "Izzeddin", ""], ["Hakkani-Tur", "Dilek", ""], ["Tur", "Gokhan", ""], ["Shah", "Pararth", ""]]}, {"id": "1811.04376", "submitter": "Tanmayee Narendra Ms", "authors": "Tanmayee Narendra, Anush Sankaran, Deepak Vijaykeerthy and Senthil\n  Mani", "title": "Explaining Deep Learning Models using Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning models have been successfully applied to a variety of\ntasks, due to the millions of parameters, they are becoming increasingly opaque\nand complex. In order to establish trust for their widespread commercial use,\nit is important to formalize a principled framework to reason over these\nmodels. In this work, we use ideas from causal inference to describe a general\nframework to reason over CNN models. Specifically, we build a Structural Causal\nModel (SCM) as an abstraction over a specific aspect of the CNN. We also\nformulate a method to quantitatively rank the filters of a convolution layer\naccording to their counterfactual importance. We illustrate our approach with\npopular CNN architectures such as LeNet5, VGG19, and ResNet32.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 09:26:55 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Narendra", "Tanmayee", ""], ["Sankaran", "Anush", ""], ["Vijaykeerthy", "Deepak", ""], ["Mani", "Senthil", ""]]}, {"id": "1811.04407", "submitter": "Liu Yuezhang", "authors": "Liu Yuezhang, Ruohan Zhang, Dana H. Ballard", "title": "An initial attempt of combining visual selective attention with deep\n  reinforcement learning", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention serves as a means of feature selection mechanism in the\nperceptual system. Motivated by Broadbent's leaky filter model of selective\nattention, we evaluate how such mechanism could be implemented and affect the\nlearning process of deep reinforcement learning. We visualize and analyze the\nfeature maps of DQN on a toy problem Catch, and propose an approach to combine\nvisual selective attention with deep reinforcement learning. We experiment with\noptical flow-based attention and A2C on Atari games. Experiment results show\nthat visual selective attention could lead to improvements in terms of sample\nefficiency on tested games. An intriguing relation between attention and batch\nnormalization is also discovered.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 12:22:44 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 07:14:00 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 17:48:44 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yuezhang", "Liu", ""], ["Zhang", "Ruohan", ""], ["Ballard", "Dana H.", ""]]}, {"id": "1811.04441", "submitter": "Chao Shang", "authors": "Chao Shang, Yun Tang, Jing Huang, Jinbo Bi, Xiaodong He, Bowen Zhou", "title": "End-to-end Structure-Aware Convolutional Networks for Knowledge Base\n  Completion", "comments": "The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding has been an active research topic for knowledge\nbase completion, with progressive improvement from the initial TransE, TransH,\nDistMult et al to the current state-of-the-art ConvE. ConvE uses 2D convolution\nover embeddings and multiple layers of nonlinear features to model knowledge\ngraphs. The model can be efficiently trained and scalable to large knowledge\ngraphs. However, there is no structure enforcement in the embedding space of\nConvE. The recent graph convolutional network (GCN) provides another way of\nlearning graph node embedding by successfully utilizing graph connectivity\nstructure. In this work, we propose a novel end-to-end Structure-Aware\nConvolutional Network (SACN) that takes the benefit of GCN and ConvE together.\nSACN consists of an encoder of a weighted graph convolutional network (WGCN),\nand a decoder of a convolutional network called Conv-TransE. WGCN utilizes\nknowledge graph node structure, node attributes and edge relation types. It has\nlearnable weights that adapt the amount of information from neighbors used in\nlocal aggregation, leading to more accurate embeddings of graph nodes. Node\nattributes in the graph are represented as additional nodes in the WGCN. The\ndecoder Conv-TransE enables the state-of-the-art ConvE to be translational\nbetween entities and relations while keeps the same link prediction performance\nas ConvE. We demonstrate the effectiveness of the proposed SACN on standard\nFB15k-237 and WN18RR datasets, and it gives about 10% relative improvement over\nthe state-of-the-art ConvE in terms of HITS@1, HITS@3 and HITS@10.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 18:07:44 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 01:14:53 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Shang", "Chao", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["Bi", "Jinbo", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1811.04454", "submitter": "Milan Aggarwal", "authors": "Milan Aggarwal, Nupur Kumari, Ayush Bansal, Balaji Krishnamurthy", "title": "ReDecode Framework for Iterative Improvement in Paraphrase Generation", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases, that is, different variations of a sentence conveying\nthe same meaning, is an important yet challenging task in NLP. Automatically\ngenerating paraphrases has its utility in many NLP tasks like question\nanswering, information retrieval, conversational systems to name a few. In this\npaper, we introduce iterative refinement of generated paraphrases within VAE\nbased generation framework. Current sequence generation models lack the\ncapability to (1) make improvements once the sentence is generated; (2) rectify\nerrors made while decoding. We propose a technique to iteratively refine the\noutput using multiple decoders, each one attending on the output sentence\ngenerated by the previous decoder. We improve current state of the art results\nsignificantly - with over 9% and 28% absolute increase in METEOR scores on\nQuora question pairs and MSCOCO datasets respectively. We also show\nqualitatively through examples that our re-decoding approach generates better\nparaphrases compared to a single decoder by rectifying errors and making\nimprovements in paraphrase structure, inducing variations and introducing new\nbut semantically coherent information.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 19:02:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Aggarwal", "Milan", ""], ["Kumari", "Nupur", ""], ["Bansal", "Ayush", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1811.04458", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Time-interval balancing in multi-processor scheduling of composite\n  modular jobs (preliminary description)", "comments": "37 pages, 16 figures, 56 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes a special time-interval balancing in multi-processor\nscheduling of composite modular jobs. This scheduling problem is close to\njust-in-time planning approach. First, brief literature surveys are presented\non just-in-time scheduling and due-data/due-window scheduling problems.\nFurther, the problem and its formulation are proposed for the time-interval\nbalanced scheduling of composite modular jobs. The illustrative real world\nplanning example for modular home-building is described. Here, the main\nobjective function consists in a balance between production of the typical\nbuilding modules (details) and the assembly processes of the building(s) (by\nseveral teams). The assembly plan has to be modified to satisfy the balance\nrequirements. The solving framework is based on the following: (i) clustering\nof initial set of modular detail types to obtain about ten basic detail types\nthat correspond to main manufacturing conveyors; (ii) designing a preliminary\nplan of assembly for buildings; (iii) detection of unbalanced time periods,\n(iv) modification of the planning solution to improve the schedule balance. The\nframework implements a metaheuristic based on local optimization approach. Two\nother applications (supply chain management, information transmission systems)\nare briefly described.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 19:13:20 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1811.04504", "submitter": "Aaron Mishkin", "authors": "Aaron Mishkin, Frederik Kunstner, Didrik Nielsen, Mark Schmidt and\n  Mohammad Emtiyaz Khan", "title": "SLANG: Fast Structured Covariance Approximations for Bayesian Deep\n  Learning with Natural Gradient", "comments": "NeurIPS 2018 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation in large deep-learning models is a computationally\nchallenging task, where it is difficult to form even a Gaussian approximation\nto the posterior distribution. In such situations, existing methods usually\nresort to a diagonal approximation of the covariance matrix despite, the fact\nthat these matrices are known to result in poor uncertainty estimates. To\naddress this issue, we propose a new stochastic, low-rank, approximate\nnatural-gradient (SLANG) method for variational inference in large, deep\nmodels. Our method estimates a \"diagonal plus low-rank\" structure based solely\non back-propagated gradients of the network log-likelihood. This requires\nstrictly less gradient computations than methods that compute the gradient of\nthe whole variational objective. Empirical evaluations on standard benchmarks\nconfirm that SLANG enables faster and more accurate estimation of uncertainty\nthan mean-field methods, and performs comparably to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 23:18:27 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 01:01:06 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Mishkin", "Aaron", ""], ["Kunstner", "Frederik", ""], ["Nielsen", "Didrik", ""], ["Schmidt", "Mark", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "1811.04516", "submitter": "Oscar Chang", "authors": "Oscar Chang, Robert Kwiatkowski, Siyuan Chen, Hod Lipson", "title": "Agent Embeddings: A Latent Representation for Pole-Balancing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is possible to reduce a high-dimensional object like a neural\nnetwork agent into a low-dimensional vector representation with semantic\nmeaning that we call agent embeddings, akin to word or face embeddings. This\ncan be done by collecting examples of existing networks, vectorizing their\nweights, and then learning a generative model over the weight space in a\nsupervised fashion. We investigate a pole-balancing task, Cart-Pole, as a case\nstudy and show that multiple new pole-balancing networks can be generated from\ntheir agent embeddings without direct access to training data from the\nCart-Pole simulator. In general, the learned embedding space is helpful for\nmapping out the space of solutions for a given task. We observe in the case of\nCart-Pole the surprising finding that good agents make different decisions\ndespite learning similar representations, whereas bad agents make similar (bad)\ndecisions while learning dissimilar representations. Linearly interpolating\nbetween the latent embeddings for a good agent and a bad agent yields an agent\nembedding that generates a network with intermediate performance, where the\nperformance can be tuned according to the coefficient of interpolation. Linear\nextrapolation in the latent space also results in performance boosts, up to a\npoint.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 00:31:59 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 20:35:01 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 22:31:49 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 03:12:53 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Chang", "Oscar", ""], ["Kwiatkowski", "Robert", ""], ["Chen", "Siyuan", ""], ["Lipson", "Hod", ""]]}, {"id": "1811.04551", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David\n  Ha, Honglak Lee, James Davidson", "title": "Learning Latent Dynamics for Planning from Pixels", "comments": "20 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning has been very successful for control tasks with known environment\ndynamics. To leverage planning in unknown environments, the agent needs to\nlearn the dynamics from interactions with the world. However, learning dynamics\nmodels that are accurate enough for planning has been a long-standing\nchallenge, especially in image-based domains. We propose the Deep Planning\nNetwork (PlaNet), a purely model-based agent that learns the environment\ndynamics from images and chooses actions through fast online planning in latent\nspace. To achieve high performance, the dynamics model must accurately predict\nthe rewards ahead for multiple time steps. We approach this using a latent\ndynamics model with both deterministic and stochastic transition components.\nMoreover, we propose a multi-step variational inference objective that we name\nlatent overshooting. Using only pixel observations, our agent solves continuous\ncontrol tasks with contact dynamics, partial observability, and sparse rewards,\nwhich exceed the difficulty of tasks that were previously solved by planning\nwith learned models. PlaNet uses substantially fewer episodes and reaches final\nperformance close to and sometimes higher than strong model-free algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 04:30:10 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:21:00 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 19:12:41 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 18:28:53 GMT"}, {"version": "v5", "created": "Tue, 4 Jun 2019 18:13:09 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Fischer", "Ian", ""], ["Villegas", "Ruben", ""], ["Ha", "David", ""], ["Lee", "Honglak", ""], ["Davidson", "James", ""]]}, {"id": "1811.04584", "submitter": "Tung-Cheng Wu", "authors": "Tung-Cheng Wu, Shau-Yin Tseng, Chin-Feng Lai, Chia-Yu Ho, Ying-Hsun\n  Lai", "title": "Navigating Assistance System for Quadcopter with Deep Reinforcement\n  Learning", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep reinforcement learning method for quadcopter\nbypassing the obstacle on the flying path. In the past study, the algorithm\nonly controls the forward direction about quadcopter. In this letter, we use\ntwo functions to control quadcopter. One is quadcopter navigating function. It\nis based on calculating coordination point and find the straight path to the\ngoal. The other function is collision avoidance function. It is implemented by\ndeep Q-network model. Both two function will output rotating degree, the agent\nwill combine both output and turn direct. Besides, deep Q-network can also make\nquadcopter fly up and down to bypass the obstacle and arrive at the goal. Our\nexperimental result shows that the collision rate is 14% after 500 flights.\nBased on this work, we will train more complex sense and transfer model to the\nreal quadcopter.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:47:38 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wu", "Tung-Cheng", ""], ["Tseng", "Shau-Yin", ""], ["Lai", "Chin-Feng", ""], ["Ho", "Chia-Yu", ""], ["Lai", "Ying-Hsun", ""]]}, {"id": "1811.04588", "submitter": "Xin Lv", "authors": "Xin Lv, Lei Hou, Juanzi Li, Zhiyuan Liu", "title": "Differentiating Concepts and Instances for Knowledge Graph Embedding", "comments": null, "journal-ref": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing. 2018: 1971-1979", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts, which represent a group of different instances sharing common\nproperties, are essential information in knowledge representation. Most\nconventional knowledge embedding methods encode both entities (concepts and\ninstances) and relations as vectors in a low dimensional semantic space\nequally, ignoring the difference between concepts and instances. In this paper,\nwe propose a novel knowledge graph embedding model named TransC by\ndifferentiating concepts and instances. Specifically, TransC encodes each\nconcept in knowledge graph as a sphere and each instance as a vector in the\nsame semantic space. We use the relative positions to model the relations\nbetween concepts and instances (i.e., instanceOf), and the relations between\nconcepts and sub-concepts (i.e., subClassOf). We evaluate our model on both\nlink prediction and triple classification tasks on the dataset based on YAGO.\nExperimental results show that TransC outperforms state-of-the-art methods, and\ncaptures the semantic transitivity for instanceOf and subClassOf relation. Our\ncodes and datasets can be obtained from https:// github.com/davidlvxin/TransC.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 07:09:36 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Lv", "Xin", ""], ["Hou", "Lei", ""], ["Li", "Juanzi", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1811.04651", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro, Maria Attarian", "title": "Combining Learned Lyrical Structures and Vocabulary for Improved Lyric\n  Generation", "comments": "Extended abstract (2 pages) for the NIPS 2018 Second Workshop on\n  Machine Learning for Creativity and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of language models for generating lyrics and poetry has received an\nincreased interest in the last few years. They pose a unique challenge relative\nto standard natural language problems, as their ultimate purpose is reative,\nnotions of accuracy and reproducibility are secondary to notions of lyricism,\nstructure, and diversity. In this creative setting, traditional quantitative\nmeasures for natural language problems, such as BLEU scores, prove inadequate:\na high-scoring model may either fail to produce output respecting the desired\nstructure (e.g. song verses), be a terribly boring creative companion, or both.\nIn this work we propose a mechanism for combining two separately trained\nlanguage models into a framework that is able to produce output respecting the\ndesired song structure, while providing a richness and diversity of vocabulary\nthat renders it more creatively appealing.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 10:48:43 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Castro", "Pablo Samuel", ""], ["Attarian", "Maria", ""]]}, {"id": "1811.04727", "submitter": "Robert Walecki Mr", "authors": "Robert Walecki, Albert Buchard, Kostis Gourgoulias, Chris Hart, Maria\n  Lomeli, A. K. W. Navarro, Max Zwiessele, Yura Perov, Saurabh Johri", "title": "Universal Marginalizer for Amortised Inference and Embedding of\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are powerful tools which allow us to formalise\nour knowledge about the world and reason about its inherent uncertainty. There\nexist a considerable number of methods for performing inference in\nprobabilistic graphical models; however, they can be computationally costly due\nto significant time burden and/or storage requirements; or they lack\ntheoretical guarantees of convergence and accuracy when applied to large scale\ngraphical models. To this end, we propose the Universal Marginaliser Importance\nSampler (UM-IS) -- a hybrid inference scheme that combines the flexibility of a\ndeep neural network trained on samples from the model and inherits the\nasymptotic guarantees of importance sampling. We show how combining samples\ndrawn from the graphical model with an appropriate masking function allows us\nto train a single neural network to approximate any of the corresponding\nconditional marginal distributions, and thus amortise the cost of inference. We\nalso show that the graph embeddings can be applied for tasks such as:\nclustering, classification and interpretation of relationships between the\nnodes. Finally, we benchmark the method on a large graph (>1000 nodes), showing\nthat UM-IS outperforms sampling-based methods by a large margin while being\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 13:55:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Walecki", "Robert", ""], ["Buchard", "Albert", ""], ["Gourgoulias", "Kostis", ""], ["Hart", "Chris", ""], ["Lomeli", "Maria", ""], ["Navarro", "A. K. W.", ""], ["Zwiessele", "Max", ""], ["Perov", "Yura", ""], ["Johri", "Saurabh", ""]]}, {"id": "1811.04747", "submitter": "Hongyi Huang", "authors": "Hongyi Huang", "title": "Reimplementation and Reinterpretation of the Copycat Project", "comments": "14 pages, 4 figures, 2 tables. Work in progress preprint. Research\n  project spans 2 years both within my time in Northeastern University\n  internships and class time in Viewpoint School, thus dual affiliation is\n  accepted by both parties. More experimental comparison results will be added\n  when conclusive experiments are completed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the reinterpreted and reimplemented Copycat project, an\narchitecture solving letter analogy domain problems. To support a flexible\nimplementation change and rigor testing process, we propose a implementation\nmethod in DrRacket by using functional abstraction, naming system,\ninitialization, and structural reference. Finally, benefits and limitations are\nanalyzed for cognitive architectures along the lines of Copycat.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 00:55:45 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Huang", "Hongyi", ""]]}, {"id": "1811.04760", "submitter": "Steven Gratton", "authors": "Steven Gratton", "title": "Quantum Reasoning using Lie Algebra for Everyday Life (and AI\n  perhaps...)", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the applicability of the formalism of quantum mechanics to\neveryday life. It seems to be directly relevant for situations in which the\nvery act of coming to a conclusion or decision on one issue affects one's\nconfidence about conclusions or decisions on another issue. Lie algebra theory\nis argued to be a very useful tool in guiding the construction of quantum\ndescriptions of such situations. Tests, extensions and speculative applications\nand implications, including for the encoding of thoughts in neural networks,\nare discussed. It is suggested that the recognition and incorporation of such\nmathematical structure into machine learning and artificial intelligence might\nlead to significant efficiency and generality gains in addition to ensuring\nprobabilistic reasoning at a fundamental level.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 15:08:08 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gratton", "Steven", ""]]}, {"id": "1811.04786", "submitter": "Brandon Fain", "authors": "Brandon Fain, Ashish Goel, Kamesh Munagala, Nina Prabhu", "title": "Random Dictators with a Random Referee: Constant Sample Complexity\n  Mechanisms for Social Choice", "comments": "Conference version Published in AAAI 2019\n  (https://aaai.org/Conferences/AAAI-19/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study social choice mechanisms in an implicit utilitarian framework with a\nmetric constraint, where the goal is to minimize \\textit{Distortion}, the worst\ncase social cost of an ordinal mechanism relative to underlying cardinal\nutilities. We consider two additional desiderata: Constant sample complexity\nand Squared Distortion. Constant sample complexity means that the mechanism\n(potentially randomized) only uses a constant number of ordinal queries\nregardless of the number of voters and alternatives. Squared Distortion is a\nmeasure of variance of the Distortion of a randomized mechanism.\n  Our primary contribution is the first social choice mechanism with constant\nsample complexity \\textit{and} constant Squared Distortion (which also implies\nconstant Distortion). We call the mechanism Random Referee, because it uses a\nrandom agent to compare two alternatives that are the favorites of two other\nrandom agents. We prove that the use of a comparison query is necessary: no\nmechanism that only elicits the top-k preferred alternatives of voters (for\nconstant k) can have Squared Distortion that is sublinear in the number of\nalternatives. We also prove that unlike any top-k only mechanism, the\nDistortion of Random Referee meaningfully improves on benign metric spaces,\nusing the Euclidean plane as a canonical example. Finally, among top-1 only\nmechanisms, we introduce Random Oligarchy. The mechanism asks just 3 queries\nand is essentially optimal among the class of such mechanisms with respect to\nDistortion.\n  In summary, we demonstrate the surprising power of constant sample complexity\nmechanisms generally, and just three random voters in particular, to provide\nsome of the best known results in the implicit utilitarian framework.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:26:22 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 15:20:44 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 21:10:11 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fain", "Brandon", ""], ["Goel", "Ashish", ""], ["Munagala", "Kamesh", ""], ["Prabhu", "Nina", ""]]}, {"id": "1811.04787", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw K{\\l}opotek", "title": "Mathematical Theory of Evidence Versus Evidence", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.04000,\n  arXiv:1707.03881", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the apparent greatest weakness of the\nMathematical Theory of Evidence (MTE) of Shafer \\cite{Shafer:76}, which has\nbeen strongly criticized by Wasserman \\cite{Wasserman:92ijar}.\n  Weaknesses of Shafer's proposal \\cite{Shafer:90b} of probabilistic\ninterpretation of MTE belief functions is demonstrated. Thereafter a new\nprobabilistic interpretation of MTE conforming both to definition of belief\nfunction and to Dempster's rule of combination of independent evidence. It is\nshown that shaferian conditioning of belief functions on observations\n\\cite{Shafer:90b} may be treated as selection combined with modification of\ndata, that is data is not viewed as it is but it is casted into one's beliefs\nin what it should be like.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 12:01:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw", ""]]}, {"id": "1811.04790", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw K{\\l}opotek", "title": "Reasoning From Data in the Mathematical Theory of Evidence", "comments": "presented as poster M.A. K{\\l}opotek: Reasoning from Data in the\n  Mathematical Theory of Evidence. [in:] Proc. Eighth International Symposium\n  On Methodologies For Intelligent Systems (ISMIS'94), Charlotte, North\n  Carolina, USA, October 16-19, 1994. arXiv admin note: text overlap with\n  arXiv:1707.03881", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical Theory of Evidence (MTE) is known as a foundation for reasoning\nwhen knowledge is expressed at various levels of detail. Though much research\neffort has been committed to this theory since its foundation, many questions\nremain open. One of the most important open questions seems to be the\nrelationship between frequencies and the Mathematical Theory of Evidence. The\ntheory is blamed to leave frequencies outside (or aside of) its framework. The\nseriousness of this accusation is obvious: no experiment may be run to compare\nthe performance of MTE-based models of real world processes against real world\ndata.\n  In this paper we develop a frequentist model of the MTE bringing to fall the\nabove argument against MTE. We describe, how to interpret data in terms of MTE\nbelief functions, how to reason from data about conditional belief functions,\nhow to generate a random sample out of a MTE model, how to derive MTE model\nfrom data and how to compare results of reasoning in MTE model and reasoning\nfrom data.\n  It is claimed in this paper that MTE is suitable to model some types of\ndestructive processes\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 11:41:10 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw", ""]]}, {"id": "1811.04854", "submitter": "Flavio Correa Da Silva", "authors": "Flavio S Correa da Silva and Frederico P Costa and Antonio F Iemma", "title": "On the practice of classification learning for clinical diagnosis and\n  therapy advice in oncology", "comments": "Submitted to Artificial Intelligence in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence and medicine have a longstanding and proficuous\nrelationship. In the present work we develop a brief assessment of this\nrelationship with specific focus on machine learning, in which we highlight\nsome critical points which may hinder the use of machine learning techniques\nfor clinical diagnosis and therapy advice in practice. We then suggest a\nconceptual framework to build successful systems to aid clinical diagnosis and\ntherapy advice, grounded on a novel concept we have coined drifting domains. We\nfocus on oncology to build our arguments, as this area of medicine furnishes\nstrong evidence for the critical points we take into account here.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:59:39 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["da Silva", "Flavio S Correa", ""], ["Costa", "Frederico P", ""], ["Iemma", "Antonio F", ""]]}, {"id": "1811.04860", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Xingyi Song, Angus Roberts", "title": "Bio-YODIE: A Named Entity Linking System for Biomedical Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ever-expanding volumes of biomedical text require automated semantic\nannotation techniques to curate and put to best use. An established field of\nresearch seeks to link mentions in text to knowledge bases such as those\nincluded in the UMLS (Unified Medical Language System), in order to enable a\nmore sophisticated understanding. This work has yielded good results for tasks\nsuch as curating literature, but increasingly, annotation systems are more\nbroadly applied. Medical vocabularies are expanding in size, and with them the\nextent of term ambiguity. Document collections are increasing in size and\ncomplexity, creating a greater need for speed and robustness. Furthermore, as\nthe technologies are turned to new tasks, requirements change; for example\ngreater coverage of expressions may be required in order to annotate patient\nrecords, and greater accuracy may be needed for applications that affect\npatients. This places new demands on the approaches currently in use. In this\nwork, we present a new system, Bio-YODIE, and compare it to two other popular\nsystems in order to give guidance about suitable approaches in different\nscenarios and how systems might be designed to accommodate future needs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 17:06:53 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Song", "Xingyi", ""], ["Roberts", "Angus", ""]]}, {"id": "1811.04896", "submitter": "Michael Hind", "authors": "Michael Hind, Dennis Wei, Murray Campbell, Noel C. F. Codella, Amit\n  Dhurandhar, Aleksandra Mojsilovi\\'c, Karthikeyan Natesan Ramamurthy, Kush R.\n  Varshney", "title": "TED: Teaching AI to Explain its Decisions", "comments": "This article leverages some content from arXiv:1805.11648; presented\n  at ACM/AAAI AIES'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence systems are being increasingly deployed due to their\npotential to increase the efficiency, scale, consistency, fairness, and\naccuracy of decisions. However, as many of these systems are opaque in their\noperation, there is a growing demand for such systems to provide explanations\nfor their decisions. Conventional approaches to this problem attempt to expose\nor discover the inner workings of a machine learning model with the hope that\nthe resulting explanations will be meaningful to the consumer. In contrast,\nthis paper suggests a new approach to this problem. It introduces a simple,\npractical framework, called Teaching Explanations for Decisions (TED), that\nprovides meaningful explanations that match the mental model of the consumer.\nWe illustrate the generality and effectiveness of this approach with two\ndifferent examples, resulting in highly accurate explanations with no loss of\nprediction accuracy for these two examples.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:29:12 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 21:00:14 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Hind", "Michael", ""], ["Wei", "Dennis", ""], ["Campbell", "Murray", ""], ["Codella", "Noel C. F.", ""], ["Dhurandhar", "Amit", ""], ["Mojsilovi\u0107", "Aleksandra", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1811.04983", "submitter": "Dimitri Kartsaklis", "authors": "Victor Prokhorov, Mohammad Taher Pilehvar, Dimitri Kartsaklis, Pietro\n  Lio, Nigel Collier", "title": "Unseen Word Representation by Aligning Heterogeneous Lexical Semantic\n  Spaces", "comments": "Accepted for presentation at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding techniques heavily rely on the abundance of training data for\nindividual words. Given the Zipfian distribution of words in natural language\ntexts, a large number of words do not usually appear frequently or at all in\nthe training data. In this paper we put forward a technique that exploits the\nknowledge encoded in lexical resources, such as WordNet, to induce embeddings\nfor unseen words. Our approach adapts graph embedding and cross-lingual vector\nspace transformation techniques in order to merge lexical knowledge encoded in\nontologies with that derived from corpus statistics. We show that the approach\ncan provide consistent performance improvements across multiple evaluation\nbenchmarks: in-vitro, on multiple rare word similarity datasets, and in-vivo,\nin two downstream text classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 20:02:00 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Prokhorov", "Victor", ""], ["Pilehvar", "Mohammad Taher", ""], ["Kartsaklis", "Dimitri", ""], ["Lio", "Pietro", ""], ["Collier", "Nigel", ""]]}, {"id": "1811.05013", "submitter": "Ankesh Anand", "authors": "Ankesh Anand, Eugene Belilovsky, Kyle Kastner, Hugo Larochelle, Aaron\n  Courville", "title": "Blindfold Baselines for Embodied QA", "comments": "NIPS 2018 Visually-Grounded Interaction and Language (ViGilL)\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore blindfold (question-only) baselines for Embodied Question\nAnswering. The EmbodiedQA task requires an agent to answer a question by\nintelligently navigating in a simulated environment, gathering necessary visual\ninformation only through first-person vision before finally answering.\nConsequently, a blindfold baseline which ignores the environment and visual\ninformation is a degenerate solution, yet we show through our experiments on\nthe EQAv1 dataset that a simple question-only baseline achieves\nstate-of-the-art results on the EmbodiedQA task in all cases except when the\nagent is spawned extremely close to the object.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 21:45:41 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Anand", "Ankesh", ""], ["Belilovsky", "Eugene", ""], ["Kastner", "Kyle", ""], ["Larochelle", "Hugo", ""], ["Courville", "Aaron", ""]]}, {"id": "1811.05027", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Shiyang Cheng and Evangelos Ververas and Irene\n  Kotsia and Stefanos Zafeiriou", "title": "Deep Neural Network Augmentation: Generating Faces for Affect Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for synthesizing facial affect; either\nin terms of the six basic expressions (i.e., anger, disgust, fear, joy, sadness\nand surprise), or in terms of valence (i.e., how positive or negative is an\nemotion) and arousal (i.e., power of the emotion activation). The proposed\napproach accepts the following inputs: i) a neutral 2D image of a person; ii) a\nbasic facial expression or a pair of valence-arousal (VA) emotional state\ndescriptors to be generated, or a path of affect in the 2D VA Space to be\ngenerated as an image sequence. In order to synthesize affect in terms of VA,\nfor this person, $600,000$ frames from the 4DFAB database were annotated. The\naffect synthesis is implemented by fitting a 3D Morphable Model on the neutral\nimage, then deforming the reconstructed face and adding the inputted affect,\nand blending the new face with the given affect into the original image.\nQualitative experiments illustrate the generation of realistic images, when the\nneutral image is sampled from thirteen well known lab-controlled or in-the-wild\ndatabases, including Aff-Wild, AffectNet, RAF-DB; comparisons with Generative\nAdversarial Networks (GANs) show the higher quality achieved by the proposed\napproach. Then, quantitative experiments are conducted, in which the\nsynthesized images are used for data augmentation in training Deep Neural\nNetworks to perform affect recognition over all databases; greatly improved\nperformances are achieved when compared with state-of-the-art methods, as well\nas with GAN-based data augmentation, in all cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 22:42:40 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 21:33:58 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Cheng", "Shiyang", ""], ["Ververas", "Evangelos", ""], ["Kotsia", "Irene", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1811.05039", "submitter": "Zhenyu A. Liao", "authors": "Zhenyu A. Liao, Charupriya Sharma, James Cussens and Peter van Beek", "title": "Finding All Bayesian Network Structures within a Factor of Optimal", "comments": "11 pages with supplemental material, to appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a widely used probabilistic graphical model with\napplications in knowledge discovery and prediction. Learning a Bayesian network\n(BN) from data can be cast as an optimization problem using the well-known\nscore-and-search approach. However, selecting a single model (i.e., the best\nscoring BN) can be misleading or may not achieve the best possible accuracy. An\nalternative to committing to a single model is to perform some form of Bayesian\nor frequentist model averaging, where the space of possible BNs is sampled or\nenumerated in some fashion. Unfortunately, existing approaches for model\naveraging either severely restrict the structure of the Bayesian network or\nhave only been shown to scale to networks with fewer than 30 random variables.\nIn this paper, we propose a novel approach to model averaging inspired by\nperformance guarantees in approximation algorithms. Our approach has two\nprimary advantages. First, our approach only considers credible models in that\nthey are optimal or near-optimal in score. Second, our approach is more\nefficient and scales to significantly larger Bayesian networks than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 23:19:51 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Liao", "Zhenyu A.", ""], ["Sharma", "Charupriya", ""], ["Cussens", "James", ""], ["van Beek", "Peter", ""]]}, {"id": "1811.05067", "submitter": "Peter Hase", "authors": "John Benhardt, Peter Hase, Liuyi Zhu, Cynthia Rudin", "title": "Shall I Compare Thee to a Machine-Written Sonnet? An Approach to\n  Algorithmic Sonnet Generation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an approach for generating beautiful poetry. Our sonnet-generation\nalgorithm includes several novel elements that improve over the state of the\nart, leading to metrical, rhyming poetry with many human-like qualities. These\nnovel elements include in-line punctuation, part of speech restrictions, and\nmore appropriate training corpora. Our work is the winner of the 2018 PoetiX\nLiterary Turing Test Award for computer-generated poetry.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 02:04:42 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 22:52:16 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Benhardt", "John", ""], ["Hase", "Peter", ""], ["Zhu", "Liuyi", ""], ["Rudin", "Cynthia", ""]]}, {"id": "1811.05106", "submitter": "David Keetae Park", "authors": "Sungmin Kang, David Keetae Park, Jaehyuk Chang, Jaegul Choo", "title": "Interpreting Models by Allowing to Ask", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Questions convey information about the questioner, namely what one does not\nknow. In this paper, we propose a novel approach to allow a learning agent to\nask what it considers as tricky to predict, in the course of producing a final\noutput. By analyzing when and what it asks, we can make our model more\ntransparent and interpretable. We first develop this idea to propose a general\nframework of deep neural networks that can ask questions, which we call asking\nnetworks. A specific architecture and training process for an asking network is\nproposed for the task of colorization, which is an exemplar one-to-many task\nand thus a task where asking questions is helpful in performing the task\naccurately. Our results show that the model learns to generate meaningful\nquestions, asks difficult questions first, and utilizes the provided hint more\nefficiently than baseline models. We conclude that the proposed asking\nframework makes the learning agent reveal its weaknesses, which poses a\npromising new direction in developing interpretable and interactive models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 04:57:48 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kang", "Sungmin", ""], ["Park", "David Keetae", ""], ["Chang", "Jaehyuk", ""], ["Choo", "Jaegul", ""]]}, {"id": "1811.05245", "submitter": "Luca Costabello", "authors": "Rory Mc Grath, Luca Costabello, Chan Le Van, Paul Sweeney, Farbod\n  Kamiab, Zhao Shen, Freddy Lecue", "title": "Interpretable Credit Application Predictions With Counterfactual\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We predict credit applications with off-the-shelf, interchangeable black-box\nclassifiers and we explain single predictions with counterfactual explanations.\nCounterfactual explanations expose the minimal changes required on the input\ndata to obtain a different result e.g., approved vs rejected application.\nDespite their effectiveness, counterfactuals are mainly designed for changing\nan undesired outcome of a prediction i.e. loan rejected. Counterfactuals,\nhowever, can be difficult to interpret, especially when a high number of\nfeatures are involved in the explanation. Our contribution is two-fold: i) we\npropose positive counterfactuals, i.e. we adapt counterfactual explanations to\nalso explain accepted loan applications, and ii) we propose two weighting\nstrategies to generate more interpretable counterfactuals. Experiments on the\nHELOC loan applications dataset show that our contribution outperforms the\nbaseline counterfactual generation strategy, by leading to smaller and hence\nmore interpretable counterfactuals.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 12:12:57 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 10:04:21 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Grath", "Rory Mc", ""], ["Costabello", "Luca", ""], ["Van", "Chan Le", ""], ["Sweeney", "Paul", ""], ["Kamiab", "Farbod", ""], ["Shen", "Zhao", ""], ["Lecue", "Freddy", ""]]}, {"id": "1811.05249", "submitter": "Louis Kirsch", "authors": "Louis Kirsch, Julius Kunze, David Barber", "title": "Modular Networks: Learning to Decompose Neural Computation", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling model capacity has been vital in the success of deep learning. For a\ntypical network, necessary compute resources and training time grow\ndramatically with model size. Conditional computation is a promising way to\nincrease the number of parameters with a relatively small increase in\nresources. We propose a training algorithm that flexibly chooses neural modules\nbased on the data to be processed. Both the decomposition and modules are\nlearned end-to-end. In contrast to existing approaches, training does not rely\non regularization to enforce diversity in module use. We apply modular networks\nboth to image recognition and language modeling tasks, where we achieve\nsuperior performance compared to several baselines. Introspection reveals that\nmodules specialize in interpretable contexts.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 12:24:23 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kirsch", "Louis", ""], ["Kunze", "Julius", ""], ["Barber", "David", ""]]}, {"id": "1811.05269", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Andrea Bartolini, Michele Lombardi, Michela Milano,\n  Luca Benini", "title": "Anomaly Detection using Autoencoders in High Performance Computing\n  Systems", "comments": "9 pages, 3 figures", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  Vol. 33, pages 9428-9433, 2019", "doi": "10.1609/aaai.v33i01.33019428", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in supercomputers is a very difficult problem due to the\nbig scale of the systems and the high number of components. The current state\nof the art for automated anomaly detection employs Machine Learning methods or\nstatistical regression models in a supervised fashion, meaning that the\ndetection tool is trained to distinguish among a fixed set of behaviour classes\n(healthy and unhealthy states).\n  We propose a novel approach for anomaly detection in High Performance\nComputing systems based on a Machine (Deep) Learning technique, namely a type\nof neural network called autoencoder. The key idea is to train a set of\nautoencoders to learn the normal (healthy) behaviour of the supercomputer nodes\nand, after training, use them to identify abnormal conditions. This is\ndifferent from previous approaches which where based on learning the abnormal\ncondition, for which there are much smaller datasets (since it is very hard to\nidentify them to begin with).\n  We test our approach on a real supercomputer equipped with a fine-grained,\nscalable monitoring infrastructure that can provide large amount of data to\ncharacterize the system behaviour. The results are extremely promising: after\nthe training phase to learn the normal system behaviour, our method is capable\nof detecting anomalies that have never been seen before with a very good\naccuracy (values ranging between 88% and 96%).\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:08:47 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Borghesi", "Andrea", ""], ["Bartolini", "Andrea", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""], ["Benini", "Luca", ""]]}, {"id": "1811.05291", "submitter": "Vincenzo Lomonaco", "authors": "Vincenzo Lomonaco, Angelo Trotta, Marta Ziosi, Juan de Dios Y\\'a\\~nez\n  \\'Avila, Natalia D\\'iaz-Rodr\\'iguez", "title": "Intelligent Drone Swarm for Search and Rescue Operations at Sea", "comments": "4 Pages, 1 Figure, extended abstract accepted to the \"AI for Social\n  Good\" NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a rising numbers of people arrived in the European Union,\ntraveling across the Mediterranean Sea or overland through Southeast Europe in\nwhat has been later named as the European migrant crisis. In the last 5 years,\nmore than 16 thousands people have lost their lives in the Mediterranean sea\nduring the crossing. The United Nations Secretary General Strategy on New\nTechnologies is supporting the use of Artificial Intelligence (AI) and Robotics\nto accelerate the achievement of the 2030 Sustainable Development Agenda, which\nincludes safe and regular migration processes among the others. In the same\nspirit, the central idea of this project aims at using AI technology for Search\nAnd Rescue (SAR) operations at sea. In particular, we propose an autonomous\nfleet of self-organizing intelligent drones that would enable the coverage of a\nbroader area, speeding-up the search processes and finally increasing the\nefficiency and effectiveness of migrants rescue operations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:56:56 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Trotta", "Angelo", ""], ["Ziosi", "Marta", ""], ["\u00c1vila", "Juan de Dios Y\u00e1\u00f1ez", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "1811.05297", "submitter": "Mateo Sanchez", "authors": "Esteban Quintero, Mateo Sanchez, Nicolas Roldan, and Mauricio Toro", "title": "Genetic algorithm for optimal distribution in cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem to deal with in this project is the problem of routing electric\nvehicles, which consists of finding the best routes for this type of vehicle,\nso that they reach their destination, without running out of power and\noptimizing to the maximum transportation costs. The importance of this problem\nis mainly in the sector of shipments in the recent future, when obsolete energy\nsources are replaced with renewable sources, where each vehicle contains a\nnumber of packages that must be delivered at specific points in the city , but,\nbeing electric, they do not have an optimal battery life, so having the ideal\nroutes traced is a vital aspect for the proper functioning of these. Now days\nyou can see applications of this problem in the cleaning sector, specifically\nwith the trucks responsible for collecting garbage, which aims to travel the\nentire city in the most efficient way, without letting excessive garbage\naccumulate.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 14:02:29 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Quintero", "Esteban", ""], ["Sanchez", "Mateo", ""], ["Roldan", "Nicolas", ""], ["Toro", "Mauricio", ""]]}, {"id": "1811.05303", "submitter": "Denis Lukovnikov", "authors": "Denis Lukovnikov, Nilesh Chakraborty, Jens Lehmann, Asja Fischer", "title": "Translating Natural Language to SQL using Pointer-Generator Networks and\n  How Decoding Order Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating natural language to SQL queries for table-based question\nanswering is a challenging problem and has received significant attention from\nthe research community. In this work, we extend a pointer-generator and\ninvestigate the order-matters problem in semantic parsing for SQL. Even though\nour model is a straightforward extension of a general-purpose\npointer-generator, it outperforms early works for WikiSQL and remains\ncompetitive to concurrently introduced, more complex models. Moreover, we\nprovide a deeper investigation of the potential order-matters problem that\ncould arise due to having multiple correct decoding paths, and investigate the\nuse of REINFORCE as well as a dynamic oracle in this context.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 14:06:58 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Lukovnikov", "Denis", ""], ["Chakraborty", "Nilesh", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1811.05321", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, A. Golubkov, B. Grechuk, E.M. Mirkes, I.Y. Tyukin", "title": "Correction of AI systems by linear discriminants: Probabilistic\n  foundations", "comments": "arXiv admin note: text overlap with arXiv:1809.07656 and\n  arXiv:1802.02172", "journal-ref": "Information Sciences 466 (2018), 303-322", "doi": "10.1016/j.ins.2018.07.040", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) systems sometimes make errors and will make\nerrors in the future, from time to time. These errors are usually unexpected,\nand can lead to dramatic consequences. Intensive development of AI and its\npractical applications makes the problem of errors more important. Total\nre-engineering of the systems can create new errors and is not always possible\ndue to the resources involved. The important challenge is to develop fast\nmethods to correct errors without damaging existing skills. We formulated the\ntechnical requirements to the 'ideal' correctors. Such correctors include\nbinary classifiers, which separate the situations with high risk of errors from\nthe situations where the AI systems work properly. Surprisingly, for\nessentially high-dimensional data such methods are possible: simple linear\nFisher discriminant can separate the situations with errors from correctly\nsolved tasks even for exponentially large samples. The paper presents the\nprobabilistic basis for fast non-destructive correction of AI systems. A series\nof new stochastic separation theorems is proven. These theorems provide new\ninstruments for fast non-iterative correction of errors of legacy AI systems.\nThe new approaches become efficient in high-dimensions, for correction of\nhigh-dimensional systems in high-dimensional world (i.e. for processing of\nessentially high-dimensional data by large systems).\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 13:11:13 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gorban", "A. N.", ""], ["Golubkov", "A.", ""], ["Grechuk", "B.", ""], ["Mirkes", "E. M.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1811.05370", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Anuj Goyal, Angeliki Metallinou", "title": "Unsupervised Transfer Learning for Spoken Language Understanding in\n  Intelligent Agents", "comments": "To appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interaction with voice-powered agents generates large amounts of\nunlabeled utterances. In this paper, we explore techniques to efficiently\ntransfer the knowledge from these unlabeled utterances to improve model\nperformance on Spoken Language Understanding (SLU) tasks. We use Embeddings\nfrom Language Model (ELMo) to take advantage of unlabeled data by learning\ncontextualized word representations. Additionally, we propose ELMo-Light\n(ELMoL), a faster and simpler unsupervised pre-training method for SLU. Our\nfindings suggest unsupervised pre-training on a large corpora of unlabeled\nutterances leads to significantly better SLU performance compared to training\nfrom scratch and it can even outperform conventional supervised transfer.\nAdditionally, we show that the gains from unsupervised transfer techniques can\nbe further improved by supervised transfer. The improvements are more\npronounced in low resource settings and when using only 1000 labeled in-domain\nsamples, our techniques match the performance of training from scratch on\n10-15x more labeled in-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:44:31 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Siddhant", "Aditya", ""], ["Goyal", "Anuj", ""], ["Metallinou", "Angeliki", ""]]}, {"id": "1811.05372", "submitter": "Abhishek Divekar", "authors": "Abhishek Divekar (1 and 5), Meet Parekh (2 and 5), Vaibhav Savla (3\n  and 5), Rudra Mishra (4 and 5), Mahesh Shirole (5) ((1) Amazon, (2) New York\n  University, (3) Infosys, (4) Samsung, (5) Veermata Jijabai Technological\n  Institute)", "title": "Benchmarking datasets for Anomaly-based Network Intrusion Detection: KDD\n  CUP 99 alternatives", "comments": "Paper accepted into Proceedings of IEEE International Conference on\n  Computing, Communication and Security 2018 (ICCCS-2018) Statistics: 8 pages,\n  7 tables, 3 figures, 34 references", "journal-ref": "2018 3rd IEEE International Conference on Computing, Communication\n  and Security (ICCCS)", "doi": "10.1109/CCCS.2018.8586840", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been steadily gaining traction for its use in\nAnomaly-based Network Intrusion Detection Systems (A-NIDS). Research into this\ndomain is frequently performed using the KDD~CUP~99 dataset as a benchmark.\nSeveral studies question its usability while constructing a contemporary NIDS,\ndue to the skewed response distribution, non-stationarity, and failure to\nincorporate modern attacks. In this paper, we compare the performance for\nKDD-99 alternatives when trained using classification models commonly found in\nliterature: Neural Network, Support Vector Machine, Decision Tree, Random\nForest, Naive Bayes and K-Means. Applying the SMOTE oversampling technique and\nrandom undersampling, we create a balanced version of NSL-KDD and prove that\nskewed target classes in KDD-99 and NSL-KDD hamper the efficacy of classifiers\non minority classes (U2R and R2L), leading to possible security risks. We\nexplore UNSW-NB15, a modern substitute to KDD-99 with greater uniformity of\npattern distribution. We benchmark this dataset before and after SMOTE\noversampling to observe the effect on minority performance. Our results\nindicate that classifiers trained on UNSW-NB15 match or better the Weighted\nF1-Score of those trained on NSL-KDD and KDD-99 in the binary case, thus\nadvocating UNSW-NB15 as a modern substitute to these datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 15:49:54 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Divekar", "Abhishek", "", "1 and 5"], ["Parekh", "Meet", "", "2 and 5"], ["Savla", "Vaibhav", "", "3\n  and 5"], ["Mishra", "Rudra", "", "4 and 5"], ["Shirole", "Mahesh", ""]]}, {"id": "1811.05389", "submitter": "Songwei Ge", "authors": "Chun-Liang Li, Eunsu Kang, Songwei Ge, Lingyao Zhang, Austin Dill,\n  Manzil Zaheer, Barnabas Poczos", "title": "Hallucinating Point Cloud into 3D Sculptural Object", "comments": "Accepted by Second Workshop on Machine Learning for Creativity and\n  Design, NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our team of artists and machine learning researchers designed a creative\nalgorithm that can generate authentic sculptural artworks. These artworks do\nnot mimic any given forms and cannot be easily categorized into the dataset\ncategories. Our approach extends DeepDream from images to 3D point clouds. The\nproposed algorithm, Amalgamated DeepDream (ADD), leverages the properties of\npoint clouds to create objects with better quality than the naive extension.\nADD presents promise for the creativity of machines, the kind of creativity\nthat pushes artists to explore novel methods or materials and to create new\ngenres instead of creating variations of existing forms or styles within one\ngenre. For example, from Realism to Abstract Expressionism, or to Minimalism.\nLastly, we present the sculptures that are 3D printed based on the point clouds\ncreated by ADD.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:28:32 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 23:08:27 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 04:41:54 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Li", "Chun-Liang", ""], ["Kang", "Eunsu", ""], ["Ge", "Songwei", ""], ["Zhang", "Lingyao", ""], ["Dill", "Austin", ""], ["Zaheer", "Manzil", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1811.05420", "submitter": "Warren Del-Pinto", "authors": "Warren Del-Pinto, Renate A. Schmidt", "title": "ABox Abduction via Forgetting in ALC (Long Version)", "comments": "Long version of a paper accepted for publication in the proceedings\n  of AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive reasoning generates explanatory hypotheses for new observations\nusing prior knowledge. This paper investigates the use of forgetting, also\nknown as uniform interpolation, to perform ABox abduction in description logic\n(ALC) ontologies. Non-abducibles are specified by a forgetting signature which\ncan contain concept, but not role, symbols. The resulting hypotheses are\nsemantically minimal and each consist of a set of disjuncts. These disjuncts\nare each independent explanations, and are not redundant with respect to the\nbackground ontology or the other disjuncts, representing a form of hypothesis\nspace. The observations and hypotheses handled by the method can contain both\natomic or complex ALC concepts, excluding role assertions, and are not\nrestricted to Horn clauses. Two approaches to redundancy elimination are\nexplored for practical use: full and approximate. Using a prototype\nimplementation, experiments were performed over a corpus of real world\nontologies to investigate the practicality of both approaches across several\nsettings.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 17:18:48 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Del-Pinto", "Warren", ""], ["Schmidt", "Renate A.", ""]]}, {"id": "1811.05432", "submitter": "Coline Devin", "authors": "Dequan Wang, Coline Devin, Qi-Zhi Cai, Fisher Yu, Trevor Darrell", "title": "Deep Object-Centric Policies for Autonomous Driving", "comments": "Accepted at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning visuomotor skills in an end-to-end manner is appealing, deep\nneural networks are often uninterpretable and fail in surprising ways. For\nrobotics tasks, such as autonomous driving, models that explicitly represent\nobjects may be more robust to new scenes and provide intuitive visualizations.\nWe describe a taxonomy of \"object-centric\" models which leverage both object\ninstances and end-to-end learning. In the Grand Theft Auto V simulator, we show\nthat object-centric models outperform object-agnostic methods in scenes with\nother vehicles and pedestrians, even with an imperfect detector. We also\ndemonstrate that our architectures perform well on real-world environments by\nevaluating on the Berkeley DeepDrive Video dataset, where an object-centric\nmodel outperforms object-agnostic models in the low-data regimes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 17:44:24 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 17:39:36 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wang", "Dequan", ""], ["Devin", "Coline", ""], ["Cai", "Qi-Zhi", ""], ["Yu", "Fisher", ""], ["Darrell", "Trevor", ""]]}, {"id": "1811.05437", "submitter": "Kristijonas \\v{C}yras", "authors": "Kristijonas \\v{C}yras, Dimitrios Letsios, Ruth Misener, Francesca Toni", "title": "Argumentation for Explainable Scheduling (Full Paper with Proofs)", "comments": "Full version (including proofs) of the paper published at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical optimization offers highly-effective tools for finding solutions\nfor problems with well-defined goals, notably scheduling. However, optimization\nsolvers are often unexplainable black boxes whose solutions are inaccessible to\nusers and which users cannot interact with. We define a novel paradigm using\nargumentation to empower the interaction between optimization solvers and\nusers, supported by tractable explanations which certify or refute solutions. A\nsolution can be from a solver or of interest to a user (in the context of\n'what-if' scenarios). Specifically, we define argumentative and natural\nlanguage explanations for why a schedule is (not) feasible, (not) efficient or\n(not) satisfying fixed user decisions, based on models of the fundamental\nmakespan scheduling problem in terms of abstract argumentation frameworks\n(AFs). We define three types of AFs, whose stable extensions are in one-to-one\ncorrespondence with schedules that are feasible, efficient and satisfying fixed\ndecisions, respectively. We extract the argumentative explanations from these\nAFs and the natural language explanations from the argumentative ones.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 18:04:26 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 11:45:03 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["\u010cyras", "Kristijonas", ""], ["Letsios", "Dimitrios", ""], ["Misener", "Ruth", ""], ["Toni", "Francesca", ""]]}, {"id": "1811.05521", "submitter": "Mandar Kulkarni Mr.", "authors": "Mandar Kulkarni", "title": "Deep Q learning for fooling neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to external attacks. In this paper, we\npropose a Reinforcement Learning (RL) based approach to generate adversarial\nexamples for the pre-trained (target) models. We assume a semi black-box\nsetting where the only access an adversary has to the target model is the class\nprobabilities obtained for the input queries. We train a Deep Q Network (DQN)\nagent which, with experience, learns to attack only a small portion of image\npixels to generate non-targeted adversarial images. Initially, an agent\nexplores an environment by sequentially modifying random sets of image pixels\nand observes its effect on the class probabilities. At the end of an episode,\nit receives a positive (negative) reward if it succeeds (fails) to alter the\nlabel of the image. Experimental results with MNIST, CIFAR-10 and Imagenet\ndatasets demonstrate that our RL framework is able to learn an effective attack\npolicy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 20:23:37 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Kulkarni", "Mandar", ""]]}, {"id": "1811.05527", "submitter": "Gabriel Peyr\\'e", "authors": "Marco Cuturi and Gabriel Peyr\\'e", "title": "Semi-dual Regularized Optimal Transport", "comments": null, "journal-ref": "SIAM Review, 60(4), 941-965, 2018", "doi": "10.1137/18M1208654", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational problems that involve Wasserstein distances and more generally\noptimal transport (OT) theory are playing an increasingly important role in\ndata sciences. Such problems can be used to form an examplar measure out of\nvarious probability measures, as in the Wasserstein barycenter problem, or to\ncarry out parametric inference and density fitting, where the loss is measured\nin terms of an optimal transport cost to the measure of observations. Despite\nbeing conceptually simple, such problems are computationally challenging\nbecause they involve minimizing over quantities (Wasserstein distances) that\nare themselves hard to compute. Entropic regularization has recently emerged as\nan efficient tool to approximate the solution of such variational Wasserstein\nproblems. In this paper, we give a thorough duality tour of these\nregularization techniques. In particular, we show how important concepts from\nclassical OT such as c-transforms and semi-discrete approaches translate into\nsimilar ideas in a regularized setting. These dual formulations lead to smooth\nvariational problems, which can be solved using smooth, differentiable and\nconvex optimization problems that are simpler to implement and numerically more\nstable that their un-regularized counterparts. We illustrate the versatility of\nthis approach by applying it to the computation of Wasserstein barycenters and\ngradient flows of spatial regularization functionals.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 20:56:14 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Cuturi", "Marco", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1811.05577", "submitter": "Pedro Saleiro", "authors": "Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby\n  Stevens, Ari Anisfeld, Kit T. Rodolfa, Rayid Ghani", "title": "Aequitas: A Bias and Fairness Audit Toolkit", "comments": "Aequitas website: http://dsapp.uchicago.edu/aequitas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has raised concerns on the risk of unintended bias in AI systems\nbeing used nowadays that can affect individuals unfairly based on race, gender\nor religion, among other possible characteristics. While a lot of bias metrics\nand fairness definitions have been proposed in recent years, there is no\nconsensus on which metric/definition should be used and there are very few\navailable resources to operationalize them. Therefore, despite recent\nawareness, auditing for bias and fairness when developing and deploying AI\nsystems is not yet a standard practice. We present Aequitas, an open source\nbias and fairness audit toolkit that is an intuitive and easy to use addition\nto the machine learning workflow, enabling users to seamlessly test models for\nseveral bias and fairness metrics in relation to multiple population\nsub-groups. Aequitas facilitates informed and equitable decisions around\ndeveloping and deploying algorithmic decision making systems for both data\nscientists, machine learning researchers and policymakers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 00:34:01 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 16:28:23 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Saleiro", "Pedro", ""], ["Kuester", "Benedict", ""], ["Hinkson", "Loren", ""], ["London", "Jesse", ""], ["Stevens", "Abby", ""], ["Anisfeld", "Ari", ""], ["Rodolfa", "Kit T.", ""], ["Ghani", "Rayid", ""]]}, {"id": "1811.05590", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan, Roman V. Yampolskiy and Arslan Munir", "title": "Emergence of Addictive Behaviors in Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the technical analysis of wireheading\nin intelligent agents. Inspired by the natural analogues of wireheading and\ntheir prevalent manifestations, we propose the modeling of such phenomenon in\nReinforcement Learning (RL) agents as psychological disorders. In a preliminary\nstep towards evaluating this proposal, we study the feasibility and dynamics of\nemergent addictive policies in Q-learning agents in the tractable environment\nof the game of Snake. We consider a slightly modified settings for this game,\nin which the environment provides a \"drug\" seed alongside the original\n\"healthy\" seed for the consumption of the snake. We adopt and extend an\nRL-based model of natural addiction to Q-learning agents in this settings, and\nderive sufficient parametric conditions for the emergence of addictive\nbehaviors in such agents. Furthermore, we evaluate our theoretical analysis\nwith three sets of simulation-based experiments. The results demonstrate the\nfeasibility of addictive wireheading in RL agents, and provide promising venues\nof further research on the psychopathological modeling of complex AI safety\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:30:00 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Behzadan", "Vahid", ""], ["Yampolskiy", "Roman V.", ""], ["Munir", "Arslan", ""]]}, {"id": "1811.05592", "submitter": "C. H. Huck Yang", "authors": "Rise Ooi, Chao-Han Huck Yang, Pin-Yu Chen, V\\`ictor Egu\\`iluz, Narsis\n  Kiani, Hector Zenil, David Gomez-Cabrero, Jesper Tegn\\`er", "title": "Controllability, Multiplexing, and Transfer Learning in Networks using\n  Evolutionary Learning", "comments": "A revised version. (word source code to pdf; owing to the algo\n  package conflicts)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Networks are fundamental building blocks for representing data, and\ncomputations. Remarkable progress in learning in structurally defined (shallow\nor deep) networks has recently been achieved. Here we introduce evolutionary\nexploratory search and learning method of topologically flexible networks under\nthe constraint of producing elementary computational steady-state input-output\noperations.\n  Our results include; (1) the identification of networks, over four orders of\nmagnitude, implementing computation of steady-state input-output functions,\nsuch as a band-pass filter, a threshold function, and an inverse band-pass\nfunction. Next, (2) the learned networks are technically controllable as only a\nsmall number of driver nodes are required to move the system to a new state.\nFurthermore, we find that the fraction of required driver nodes is constant\nduring evolutionary learning, suggesting a stable system design. (3), our\nframework allows multiplexing of different computations using the same network.\nFor example, using a binary representation of the inputs, the network can\nreadily compute three different input-output functions. Finally, (4) the\nproposed evolutionary learning demonstrates transfer learning. If the system\nlearns one function A, then learning B requires on average less number of steps\nas compared to learning B from tabula rasa.\n  We conclude that the constrained evolutionary learning produces large robust\ncontrollable circuits, capable of multiplexing and transfer learning. Our study\nsuggests that network-based computations of steady-state functions,\nrepresenting either cellular modules of cell-to-cell communication networks or\ninternal molecular circuits communicating within a cell, could be a powerful\nmodel for biologically inspired computing. This complements conceptualizations\nsuch as attractor based models, or reservoir computing.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:36:52 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 02:51:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ooi", "Rise", ""], ["Yang", "Chao-Han Huck", ""], ["Chen", "Pin-Yu", ""], ["Egu\u00ecluz", "V\u00ecctor", ""], ["Kiani", "Narsis", ""], ["Zenil", "Hector", ""], ["Gomez-Cabrero", "David", ""], ["Tegn\u00e8r", "Jesper", ""]]}, {"id": "1811.05594", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan, James Minton and Arslan Munir", "title": "TrolleyMod v1.0: An Open-Source Simulation and Data-Collection Platform\n  for Ethical Decision Making in Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents TrolleyMod v1.0, an open-source platform based on the\nCARLA simulator for the collection of ethical decision-making data for\nautonomous vehicles. This platform is designed to facilitate experiments aiming\nto observe and record human decisions and actions in high-fidelity simulations\nof ethical dilemmas that occur in the context of driving. Targeting experiments\nin the class of trolley problems, TrolleyMod provides a seamless approach to\ncreating new experimental settings and environments with the realistic\nphysics-engine and the high-quality graphical capabilities of CARLA and the\nUnreal Engine. Also, TrolleyMod provides a straightforward interface between\nthe CARLA environment and Python to enable the implementation of custom\ncontrollers, such as deep reinforcement learning agents. The results of such\nexperiments can be used for sociological analyses, as well as the training and\ntuning of value-aligned autonomous vehicles based on social values that are\ninferred from observations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:50:20 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Behzadan", "Vahid", ""], ["Minton", "James", ""], ["Munir", "Arslan", ""]]}, {"id": "1811.05612", "submitter": "Sammie Katt", "authors": "Sammie Katt, Frans Oliehoek, Christopher Amato", "title": "Bayesian Reinforcement Learning in Factored POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian approaches provide a principled solution to the\nexploration-exploitation trade-off in Reinforcement Learning. Typical\napproaches, however, either assume a fully observable environment or scale\npoorly. This work introduces the Factored Bayes-Adaptive POMDP model, a\nframework that is able to exploit the underlying structure while learning the\ndynamics in partially observable systems. We also present a belief tracking\nmethod to approximate the joint posterior over state and model variables, and\nan adaptation of the Monte-Carlo Tree Search solution method, which together\nare capable of solving the underlying problem near-optimally. Our method is\nable to learn efficiently given a known factorization or also learn the\nfactorization and the model parameters at the same time. We demonstrate that\nthis approach is able to outperform current methods and tackle problems that\nwere previously infeasible.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 02:47:05 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Katt", "Sammie", ""], ["Oliehoek", "Frans", ""], ["Amato", "Christopher", ""]]}, {"id": "1811.05616", "submitter": "Shanchan Wu", "authors": "Shanchan Wu, Kai Fan, Qiong Zhang", "title": "Improving Distantly Supervised Relation Extraction with Neural Noise\n  Converter and Conditional Optimal Selector", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervised relation extraction has been successfully applied to large\ncorpus with thousands of relations. However, the inevitable wrong labeling\nproblem by distant supervision will hurt the performance of relation\nextraction. In this paper, we propose a method with neural noise converter to\nalleviate the impact of noisy data, and a conditional optimal selector to make\nproper prediction. Our noise converter learns the structured transition matrix\non logit level and captures the property of distant supervised relation\nextraction dataset. The conditional optimal selector on the other hand helps to\nmake proper prediction decision of an entity pair even if the group of\nsentences is overwhelmed by no-relation sentences. We conduct experiments on a\nwidely used dataset and the results show significant improvement over\ncompetitive baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 03:02:12 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Wu", "Shanchan", ""], ["Fan", "Kai", ""], ["Zhang", "Qiong", ""]]}, {"id": "1811.05685", "submitter": "Haifeng Zhang", "authors": "Haifeng Zhang, Zilong Guo, Han Cai, Chris Wang, Weinan Zhang, Yong Yu,\n  Wenxin Li, Jun Wang", "title": "Layout Design for Intelligent Warehouse by Evolution with Fitness\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the express industry, intelligent warehouses that\nemploy autonomous robots for carrying parcels have been widely used to handle\nthe vast express volume. For such warehouses, the warehouse layout design plays\na key role in improving the transportation efficiency. However, this work is\nstill done by human experts, which is expensive and leads to suboptimal\nresults. In this paper, we aim to automate the warehouse layout designing\nprocess. We propose a two-layer evolutionary algorithm to efficiently explore\nthe warehouse layout space, where an auxiliary objective fitness approximation\nmodel is introduced to predict the outcome of the designed warehouse layout and\na two-layer population structure is proposed to incorporate the approximation\nmodel into the ordinary evolution framework. Empirical experiments show that\nour method can efficiently design effective warehouse layouts that outperform\nboth heuristic-designed and vanilla evolution-designed warehouse layouts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 08:37:01 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Zhang", "Haifeng", ""], ["Guo", "Zilong", ""], ["Cai", "Han", ""], ["Wang", "Chris", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Li", "Wenxin", ""], ["Wang", "Jun", ""]]}, {"id": "1811.05724", "submitter": "Umberto Straccia", "authors": "Umberto Straccia", "title": "An Introduction to Fuzzy & Annotated Semantic Web Languages", "comments": "This is an updated version of [291] and acts as accompanying material\n  to my invited talk and slides at the 2018 Artificial Intelligence\n  International Conference (A2IC-18)", "journal-ref": null, "doi": "10.1007/978-3-319-49493-7_6", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the state of the art in representing and reasoning with fuzzy\nknowledge in Semantic Web Languages such as triple languages RDF/RDFS,\nconceptual languages of the OWL 2 family and rule languages. We further show\nhow one may generalise them to so-called annotation domains, that cover also\ne.g. temporal and provenance extensions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 11:02:55 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Straccia", "Umberto", ""]]}, {"id": "1811.05768", "submitter": "Shaun D'Souza", "authors": "Shaun D'Souza", "title": "Parser Extraction of Triples in Unstructured Text", "comments": null, "journal-ref": "IAES International Journal of Artificial Intelligence (IJ-AI),\n  5(4):143-148, 2017", "doi": "10.11591/ij-ai.v5.i4.pp143-148", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web contains vast repositories of unstructured text. We investigate the\nopportunity for building a knowledge graph from these text sources. We generate\na set of triples which can be used in knowledge gathering and integration. We\ndefine the architecture of a language compiler for processing\nsubject-predicate-object triples using the OpenNLP parser. We implement a\ndepth-first search traversal on the POS tagged syntactic tree appending\npredicate and object information. A parser enables higher precision and higher\nrecall extractions of syntactic relationships across conjunction boundaries. We\nare able to extract 2-2.5 times the correct extractions of ReVerb. The\nextractions are used in a variety of semantic web applications and question\nanswering. We verify extraction of 50,000 triples on the ClueWeb dataset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:12:00 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["D'Souza", "Shaun", ""]]}, {"id": "1811.05770", "submitter": "EPTCS", "authors": "Bob Coecke (University of Oxford), Martha Lewis (University of\n  Amsterdam), Dan Marsden (University of Oxford)", "title": "Internal Wiring of Cartesian Verbs and Prepositions", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 75-88", "doi": "10.4204/EPTCS.283.6", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical compositional distributional semantics (CCDS) allows one to\ncompute the meaning of phrases and sentences from the meaning of their\nconstituent words. A type-structure carried over from the traditional\ncategorial model of grammar a la Lambek becomes a 'wire-structure' that\nmediates the interaction of word meanings. However, CCDS has a much richer\nlogical structure than plain categorical semantics in that certain words can\nalso be given an 'internal wiring' that either provides their entire meaning or\nreduces the size their meaning space. Previous examples of internal wiring\ninclude relative pronouns and intersective adjectives. Here we establish the\nsame for a large class of well-behaved transitive verbs to which we refer as\nCartesian verbs, and reduce the meaning space from a ternary tensor to a unary\none. Some experimental evidence is also provided.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:11:59 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Coecke", "Bob", "", "University of Oxford"], ["Lewis", "Martha", "", "University of\n  Amsterdam"], ["Marsden", "Dan", "", "University of Oxford"]]}, {"id": "1811.05785", "submitter": "Nelson Fernandez Pinto", "authors": "Nelson Fernandez", "title": "Two-stream convolutional networks for end-to-end learning of\n  self-driving cars", "comments": null, "journal-ref": "NeurIPS 2018 Workshop on modeling and decision-making in the\n  spatiotemporal domain, Montreal, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology to extend the concept of Two-Stream Convolutional\nNetworks to perform end-to-end learning for self-driving cars with temporal\ncues. The system has the ability to learn spatiotemporal features by\nsimultaneously mapping raw images and pre-calculated optical flows directly to\nsteering commands. Although optical flows encode temporal-rich information, we\nfound that 2D-CNNs are prone to capturing features only as spatial\nrepresentations. We show how the use of Multitask Learning favors the learning\nof temporal features via inductive transfer from a shared spatiotemporal\nrepresentation. Preliminary results demonstrate a competitive improvement of\n30% in prediction accuracy and stability compared to widely used regression\nmethods trained on the Comma.ai dataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 12:34:42 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 15:16:02 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Fernandez", "Nelson", ""]]}, {"id": "1811.05788", "submitter": "Robin Spiess", "authors": "Robin Spiess, Felix Berkenkamp, Jan Poland, Andreas Krause", "title": "Learning to Compensate Photovoltaic Power Fluctuations from Images of\n  the Sky by Imitating an Optimal Policy", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy output of photovoltaic (PV) power plants depends on the\nenvironment and thus fluctuates over time. As a result, PV power can cause\ninstability in the power grid, in particular when increasingly used. Limiting\nthe rate of change of the power output is a common way to mitigate these\nfluctuations, often with the help of large batteries. A reactive controller\nthat uses these batteries to compensate ramps works in practice, but causes\nstress on the battery due to a high energy throughput. In this paper, we\npresent a deep learning approach that uses images of the sky to compensate\npower fluctuations predictively and reduces battery stress. In particular, we\nshow that the optimal control policy can be computed using information that is\nonly available in hindsight. Based on this, we use imitation learning to train\na neural network that approximates this hindsight-optimal policy, but uses only\ncurrently available sky images and sensor data. We evaluate our method on a\nlarge dataset of measurements and images from a real power plant and show that\nthe trained policy reduces stress on the battery.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 09:39:53 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Spiess", "Robin", ""], ["Berkenkamp", "Felix", ""], ["Poland", "Jan", ""], ["Krause", "Andreas", ""]]}, {"id": "1811.05817", "submitter": "Alexander Wong", "authors": "Xiaodan Hu, Audrey G. Chung, Paul Fieguth, Farzad Khalvati, Masoom A.\n  Haider, and Alexander Wong", "title": "ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging\n  Synthesis with Generative Adversarial Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown considerable promise for\nmitigating the challenge of data scarcity when building machine learning-driven\nanalysis algorithms. Specifically, a number of studies have shown that\nGAN-based image synthesis for data augmentation can aid in improving\nclassification accuracy in a number of medical image analysis tasks, such as\nbrain and liver image analysis. However, the efficacy of leveraging GANs for\ntackling prostate cancer analysis has not been previously explored. Motivated\nby this, in this study we introduce ProstateGAN, a GAN-based model for\nsynthesizing realistic prostate diffusion imaging data. More specifically, in\norder to generate new diffusion imaging data corresponding to a particular\ncancer grade (Gleason score), we propose a conditional deep convolutional GAN\narchitecture that takes Gleason scores into consideration during the training\nprocess. Experimental results show that high-quality synthetic prostate\ndiffusion imaging data can be generated using the proposed ProstateGAN for\nspecified Gleason scores.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 14:44:42 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 01:35:54 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Hu", "Xiaodan", ""], ["Chung", "Audrey G.", ""], ["Fieguth", "Paul", ""], ["Khalvati", "Farzad", ""], ["Haider", "Masoom A.", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.05831", "submitter": "Jarrid Rector-Brooks", "authors": "Jarrid Rector-Brooks, Jun-Kun Wang, Barzan Mozafari", "title": "Revisiting Projection-Free Optimization for Strongly Convex Constraint\n  Sets", "comments": "Extended version of paper accepted at AAAI-19, 19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the Frank-Wolfe (FW) optimization under strongly convex constraint\nsets. We provide a faster convergence rate for FW without line search, showing\nthat a previously overlooked variant of FW is indeed faster than the standard\nvariant. With line search, we show that FW can converge to the global optimum,\neven for smooth functions that are not convex, but are quasi-convex and\nlocally-Lipschitz. We also show that, for the general case of (smooth)\nnon-convex functions, FW with line search converges with high probability to a\nstationary point at a rate of $O\\left(\\frac{1}{t}\\right)$, as long as the\nconstraint set is strongly convex -- one of the fastest convergence rates in\nnon-convex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:09:39 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 01:59:07 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 09:24:15 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Rector-Brooks", "Jarrid", ""], ["Wang", "Jun-Kun", ""], ["Mozafari", "Barzan", ""]]}, {"id": "1811.05869", "submitter": "Haokun Chen", "authors": "Haokun Chen, Xinyi Dai, Han Cai, Weinan Zhang, Xuejian Wang, Ruiming\n  Tang, Yuzhou Zhang, Yong Yu", "title": "Large-scale Interactive Recommendation with Tree-structured Policy\n  Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has recently been introduced to interactive\nrecommender systems (IRS) because of its nature of learning from dynamic\ninteractions and planning for long-run performance. As IRS is always with\nthousands of items to recommend (i.e., thousands of actions), most existing\nRL-based methods, however, fail to handle such a large discrete action space\nproblem and thus become inefficient. The existing work that tries to deal with\nthe large discrete action space problem by utilizing the deep deterministic\npolicy gradient framework suffers from the inconsistency between the continuous\naction representation (the output of the actor network) and the real discrete\naction. To avoid such inconsistency and achieve high efficiency and\nrecommendation effectiveness, in this paper, we propose a Tree-structured\nPolicy Gradient Recommendation (TPGR) framework, where a balanced hierarchical\nclustering tree is built over the items and picking an item is formulated as\nseeking a path from the root to a certain leaf of the tree. Extensive\nexperiments on carefully-designed environments based on two real-world datasets\ndemonstrate that our model provides superior recommendation performance and\nsignificant efficiency improvement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:53:25 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Chen", "Haokun", ""], ["Dai", "Xinyi", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Wang", "Xuejian", ""], ["Tang", "Ruiming", ""], ["Zhang", "Yuzhou", ""], ["Yu", "Yong", ""]]}, {"id": "1811.06032", "submitter": "Amy Zhang", "authors": "Amy Zhang, Yuxin Wu, Joelle Pineau", "title": "Natural Environment Benchmarks for Reinforcement Learning", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current benchmark reinforcement learning (RL) tasks have been useful to\ndrive progress in the field, they are in many ways poor substitutes for\nlearning with real-world data. By testing increasingly complex RL algorithms on\nlow-complexity simulation environments, we often end up with brittle RL\npolicies that generalize poorly beyond the very specific domain. To combat\nthis, we propose three new families of benchmark RL domains that contain some\nof the complexity of the natural world, while still supporting fast and\nextensive data acquisition. The proposed domains also permit a characterization\nof generalization through fair train/test separation, and easy comparison and\nreplication of results. Through this work, we challenge the RL research\ncommunity to develop more robust algorithms that meet high standards of\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 19:50:54 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhang", "Amy", ""], ["Wu", "Yuxin", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.06052", "submitter": "Georgios Mastorakis", "authors": "Georgios Mastorakis", "title": "Human-like machine learning: limitations and suggestions", "comments": "Preprint, 24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to address the issues of machine learning in its current\nimplementation. It is known that machine learning algorithms require a\nsignificant amount of data for training purposes, whereas recent developments\nin deep learning have increased this requirement dramatically. The performance\nof an algorithm depends on the quality of data and hence, algorithms are as\ngood as the data they are trained on. Supervised learning is developed based on\nhuman learning processes by analysing named (i.e. annotated) objects, scenes\nand actions. Whether training on large quantities of data (i.e. big data) is\nthe right or the wrong approach, is debatable. The fact is, that training\nalgorithms the same way we learn ourselves, comes with limitations. This paper\ndiscusses the issues around applying a human-like approach to train algorithms\nand the implications of this approach when using limited data. Several current\nstudies involving non-data-driven algorithms and natural examples are also\ndiscussed and certain alternative approaches are suggested.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 20:44:50 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Mastorakis", "Georgios", ""]]}, {"id": "1811.06086", "submitter": "Amin Hosseininasab", "authors": "Amin Hosseininasab, Willem-Jan van Hoeve, Andre A. Cire", "title": "Constraint-based Sequential Pattern Mining with Decision Diagrams", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained sequential pattern mining aims at identifying frequent patterns\non a sequential database of items while observing constraints defined over the\nitem attributes. We introduce novel techniques for constraint-based sequential\npattern mining that rely on a multi-valued decision diagram representation of\nthe database. Specifically, our representation can accommodate multiple item\nattributes and various constraint types, including a number of non-monotone\nconstraints. To evaluate the applicability of our approach, we develop an\nMDD-based prefix-projection algorithm and compare its performance against a\ntypical generate-and-check variant, as well as a state-of-the-art\nconstraint-based sequential pattern mining algorithm. Results show that our\napproach is competitive with or superior to these other methods in terms of\nscalability and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 21:54:58 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Hosseininasab", "Amin", ""], ["van Hoeve", "Willem-Jan", ""], ["Cire", "Andre A.", ""]]}, {"id": "1811.06106", "submitter": "Jonathan Rubin", "authors": "Jwala Dhamala, Emmanuel Azuh, Abdullah Al-Dujaili, Jonathan Rubin and\n  Una-May O'Reilly", "title": "Multivariate Time-series Similarity Assessment via Unsupervised\n  Representation Learning and Stratified Locality Sensitive Hashing:\n  Application to Early Acute Hypotensive Episode Detection", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/66", "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely prediction of clinically critical events in Intensive Care Unit (ICU)\nis important for improving care and survival rate. Most of the existing\napproaches are based on the application of various classification methods on\nexplicitly extracted statistical features from vital signals. In this work, we\npropose to eliminate the high cost of engineering hand-crafted features from\nmultivariate time-series of physiologic signals by learning their\nrepresentation with a sequence-to-sequence auto-encoder. We then propose to\nhash the learned representations to enable signal similarity assessment for the\nprediction of critical events. We apply this methodological framework to\npredict Acute Hypotensive Episodes (AHE) on a large and diverse dataset of\nvital signal recordings. Experiments demonstrate the ability of the presented\nframework in accurately predicting an upcoming AHE.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 22:53:40 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 22:11:23 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 15:25:50 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Dhamala", "Jwala", ""], ["Azuh", "Emmanuel", ""], ["Al-Dujaili", "Abdullah", ""], ["Rubin", "Jonathan", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1811.06145", "submitter": "Jing Shi", "authors": "Jing Shi, Jiaming Xu, Yiqun Yao, Bo Xu", "title": "Concept Learning through Deep Reinforcement Learning with\n  Memory-Augmented Neural Networks", "comments": "27 pages, 2 figures", "journal-ref": null, "doi": "10.1016/j.neunet.2018.10.018", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown superior performance in many regimes to\nremember familiar patterns with large amounts of data. However, the standard\nsupervised deep learning paradigm is still limited when facing the need to\nlearn new concepts efficiently from scarce data. In this paper, we present a\nmemory-augmented neural network which is motivated by the process of human\nconcept learning. The training procedure, imitating the concept formation\ncourse of human, learns how to distinguish samples from different classes and\naggregate samples of the same kind. In order to better utilize the advantages\noriginated from the human behavior, we propose a sequential process, during\nwhich the network should decide how to remember each sample at every step. In\nthis sequential process, a stable and interactive memory serves as an important\nmodule. We validate our model in some typical one-shot learning tasks and also\nan exploratory outlier detection problem. In all the experiments, our model\ngets highly competitive to reach or outperform those strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:38:57 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Shi", "Jing", ""], ["Xu", "Jiaming", ""], ["Yao", "Yiqun", ""], ["Xu", "Bo", ""]]}, {"id": "1811.06151", "submitter": "Minzhong Luo", "authors": "Mincong Luo, Yin Tong, Jiachi Liu", "title": "Orthogonal Policy Gradient and Autonomous Driving Application", "comments": "accepted as conference paper of IEEE/ICSESS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One less addressed issue of deep reinforcement learning is the lack of\ngeneralization capability based on new state and new target, for complex tasks,\nit is necessary to give the correct strategy and evaluate all possible actions\nfor current state. Fortunately, deep reinforcement learning has enabled\nenormous progress in both subproblems: giving the correct strategy and\nevaluating all actions based on the state.\n  In this paper we present an approach called orthogonal policy gradient\ndescent(OPGD) that can make agent learn the policy gradient based on the\ncurrent state and the actions set, by which the agent can learn a policy\nnetwork with generalization capability. we evaluate the proposed method on the\n3D autonomous driving enviroment TORCS compared with the baseline model,\ndetailed analyses of experimental results and proofs are also given.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:52:43 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Luo", "Mincong", ""], ["Tong", "Yin", ""], ["Liu", "Jiachi", ""]]}, {"id": "1811.06156", "submitter": "Yu Hao", "authors": "Yu Hao, Xien Liu, Ji Wu, Ping Lv", "title": "Exploiting Sentence Embedding for Medical Question Answering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success of word embedding, sentence embedding remains a\nnot-well-solved problem. In this paper, we present a supervised learning\nframework to exploit sentence embedding for the medical question answering\ntask. The learning framework consists of two main parts: 1) a sentence\nembedding producing module, and 2) a scoring module. The former is developed\nwith contextual self-attention and multi-scale techniques to encode a sentence\ninto an embedding tensor. This module is shortly called Contextual\nself-Attention Multi-scale Sentence Embedding (CAMSE). The latter employs two\nscoring strategies: Semantic Matching Scoring (SMS) and Semantic Association\nScoring (SAS). SMS measures similarity while SAS captures association between\nsentence pairs: a medical question concatenated with a candidate choice, and a\npiece of corresponding supportive evidence. The proposed framework is examined\nby two Medical Question Answering(MedicalQA) datasets which are collected from\nreal-world applications: medical exam and clinical diagnosis based on\nelectronic medical records (EMR). The comparison results show that our proposed\nframework achieved significant improvements compared to competitive baseline\napproaches. Additionally, a series of controlled experiments are also conducted\nto illustrate that the multi-scale strategy and the contextual self-attention\nlayer play important roles for producing effective sentence embedding, and the\ntwo kinds of scoring strategies are highly complementary to each other for\nquestion answering problems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 03:38:20 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Hao", "Yu", ""], ["Liu", "Xien", ""], ["Wu", "Ji", ""], ["Lv", "Ping", ""]]}, {"id": "1811.06179", "submitter": "Yuan Luo", "authors": "Yuan Luo, Peter Szolovits", "title": "Implementing a Portable Clinical NLP System with a Common Data Model - a\n  Lisp Perspective", "comments": "6 pages, accepted by IEEE BIBM 2018 as regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Lisp architecture for a portable NLP system, termed\nLAPNLP, for processing clinical notes. LAPNLP integrates multiple standard,\ncustomized and in-house developed NLP tools. Our system facilitates portability\nacross different institutions and data systems by incorporating an enriched\nCommon Data Model (CDM) to standardize necessary data elements. It utilizes\nUMLS to perform domain adaptation when integrating generic domain NLP tools. It\nalso features stand-off annotations that are specified by positional reference\nto the original document. We built an interval tree based search engine to\nefficiently query and retrieve the stand-off annotations by specifying\npositional requirements. We also developed a utility to convert an inline\nannotation format to stand-off annotations to enable the reuse of clinical text\ndatasets with inline annotations. We experimented with our system on several\nNLP facilitated tasks including computational phenotyping for lymphoma patients\nand semantic relation extraction for clinical notes. These experiments\nshowcased the broader applicability and utility of LAPNLP.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 04:58:21 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Luo", "Yuan", ""], ["Szolovits", "Peter", ""]]}, {"id": "1811.06183", "submitter": "Yuan Luo", "authors": "Yizhen Zhong, Luke Rasmussen, Yu Deng, Jennifer Pacheco, Maureen\n  Smith, Justin Starren, Wei-Qi Wei, Peter Speltz, Joshua Denny, Nephi Walton,\n  George Hripcsak, Christopher G Chute, Yuan Luo", "title": "Characterizing Design Patterns of EHR-Driven Phenotype Extraction\n  Algorithms", "comments": "4 pages, accepted by IEEE BIBM 2018 as short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic development of phenotype algorithms from Electronic Health\nRecord data with machine learning (ML) techniques is of great interest given\nthe current practice is very time-consuming and resource intensive. The\nextraction of design patterns from phenotype algorithms is essential to\nunderstand their rationale and standard, with great potential to automate the\ndevelopment process. In this pilot study, we perform network visualization on\nthe design patterns and their associations with phenotypes and sites. We\nclassify design patterns using the fragments from previously annotated\nphenotype algorithms as the ground truth. The classification performance is\nused as a proxy for coherence at the attribution level. The bag-of-words\nrepresentation with knowledge-based features generated a good performance in\nthe classification task (0.79 macro-f1 scores). Good classification accuracy\nwith simple features demonstrated the attribution coherence and the feasibility\nof automatic identification of design patterns. Our results point to both the\nfeasibility and challenges of automatic identification of phenotyping design\npatterns, which would power the automatic development of phenotype algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 05:12:33 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhong", "Yizhen", ""], ["Rasmussen", "Luke", ""], ["Deng", "Yu", ""], ["Pacheco", "Jennifer", ""], ["Smith", "Maureen", ""], ["Starren", "Justin", ""], ["Wei", "Wei-Qi", ""], ["Speltz", "Peter", ""], ["Denny", "Joshua", ""], ["Walton", "Nephi", ""], ["Hripcsak", "George", ""], ["Chute", "Christopher G", ""], ["Luo", "Yuan", ""]]}, {"id": "1811.06187", "submitter": "Fan Wang Mr.", "authors": "Fan Wang, Bo Zhou, Ke Chen, Tingxiang Fan, Xi Zhang, Jiangyong Li, Hao\n  Tian, Jia Pan", "title": "Intervention Aided Reinforcement Learning for Safe and Practical Policy\n  Optimization in Navigation", "comments": null, "journal-ref": "Wang, F., Zhou, B., Chen, K., Fan, T., Zhang, X., Li, J., ... &\n  Pan, J. (2018, October). Intervention Aided Reinforcement Learning for Safe\n  and Practical Policy Optimization in Navigation. In Conference on Robot\n  Learning (pp. 410-421)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining deep neural networks with reinforcement learning has shown great\npotential in the next-generation intelligent control. However, there are\nchallenges in terms of safety and cost in practical applications. In this\npaper, we propose the Intervention Aided Reinforcement Learning (IARL)\nframework, which utilizes human intervened robot-environment interaction to\nimprove the policy. We used the Unmanned Aerial Vehicle (UAV) as the test\nplatform. We built neural networks as our policy to map sensor readings to\ncontrol signals on the UAV. Our experiment scenarios cover both simulation and\nreality. We show that our approach substantially reduces the human intervention\nand improves the performance in autonomous navigation, at the same time it\nensures safety and keeps training cost acceptable.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 05:26:38 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Fan", ""], ["Zhou", "Bo", ""], ["Chen", "Ke", ""], ["Fan", "Tingxiang", ""], ["Zhang", "Xi", ""], ["Li", "Jiangyong", ""], ["Tian", "Hao", ""], ["Pan", "Jia", ""]]}, {"id": "1811.06193", "submitter": "Kamran Kowsari", "authors": "Mojtaba Heidarysafa, James Reed, Kamran Kowsari, April Celeste\n  R.Leviton, Janet I. Warren, and Donald E. Brown", "title": "From Videos to URLs: A Multi-Browser Guide To Extract User's Behavior\n  with Optical Character Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM cs.RO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking users' activities on the World Wide Web (WWW) allows researchers to\nanalyze each user's internet behavior as time passes and for the amount of time\nspent on a particular domain. This analysis can be used in research design, as\nresearchers may access to their participant's behaviors while browsing the web.\nWeb search behavior has been a subject of interest because of its real-world\napplications in marketing, digital advertisement, and identifying potential\nthreats online. In this paper, we present an image-processing based method to\nextract domains which are visited by a participant over multiple browsers\nduring a lab session. This method could provide another way to collect users'\nactivities during an online session given that the session recorder collected\nthe data. The method can also be used to collect the textual content of\nweb-pages that an individual visits for later analysis\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 05:59:05 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 00:24:34 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Heidarysafa", "Mojtaba", ""], ["Reed", "James", ""], ["Kowsari", "Kamran", ""], ["Leviton", "April Celeste R.", ""], ["Warren", "Janet I.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1811.06199", "submitter": "Trung Le", "authors": "Trung Le, Khanh Nguyen, Nhat Ho, Hung Bui, Dinh Phung", "title": "On Deep Domain Adaptation: Some Theoretical Understandings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with shallow domain adaptation, recent progress in deep domain\nadaptation has shown that it can achieve higher predictive performance and\nstronger capacity to tackle structural data (e.g., image and sequential data).\nThe underlying idea of deep domain adaptation is to bridge the gap between\nsource and target domains in a joint space so that a supervised classifier\ntrained on labeled source data can be nicely transferred to the target domain.\nThis idea is certainly intuitive and powerful, however, limited theoretical\nunderstandings have been developed to support its underpinning principle. In\nthis paper, we have provided a rigorous framework to explain why it is possible\nto close the gap of the target and source domains in the joint space. More\nspecifically, we first study the loss incurred when performing transfer\nlearning from the source to the target domain. This provides a theory that\nexplains and generalizes existing work in deep domain adaptation which was\nmainly empirical. This enables us to further explain why closing the gap in the\njoint space can directly minimize the loss incurred for transfer learning\nbetween the two domains. To our knowledge, this offers the first theoretical\nresult that characterizes a direct bound on the joint space and the gain of\ntransfer learning via deep domain adaptation\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 06:27:15 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 00:48:19 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 23:41:40 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Le", "Trung", ""], ["Nguyen", "Khanh", ""], ["Ho", "Nhat", ""], ["Bui", "Hung", ""], ["Phung", "Dinh", ""]]}, {"id": "1811.06203", "submitter": "Masashi Yoshikawa", "authors": "Masashi Yoshikawa, Koji Mineshima, Hiroshi Noji, Daisuke Bekki", "title": "Combining Axiom Injection and Knowledge Base Completion for Efficient\n  Natural Language Inference", "comments": "9 pages, accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In logic-based approaches to reasoning tasks such as Recognizing Textual\nEntailment (RTE), it is important for a system to have a large amount of\nknowledge data. However, there is a tradeoff between adding more knowledge data\nfor improved RTE performance and maintaining an efficient RTE system, as such a\nbig database is problematic in terms of the memory usage and computational\ncomplexity. In this work, we show the processing time of a state-of-the-art\nlogic-based RTE system can be significantly reduced by replacing its\nsearch-based axiom injection (abduction) mechanism by that based on Knowledge\nBase Completion (KBC). We integrate this mechanism in a Coq plugin that\nprovides a proof automation tactic for natural language inference.\nAdditionally, we show empirically that adding new knowledge data contributes to\nbetter RTE performance while not harming the processing speed in this\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 06:40:39 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Yoshikawa", "Masashi", ""], ["Mineshima", "Koji", ""], ["Noji", "Hiroshi", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1811.06237", "submitter": "Anton Tsitsulin", "authors": "Anton Tsitsulin, Davide Mottin, Panagiotis Karras, Alex Bronstein,\n  Emmanuel M\\\"uller", "title": "SGR: Self-Supervised Spectral Graph Representation Learning", "comments": "As appeared in KDD Deep Learning Day workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing a graph as a vector is a challenging task; ideally, the\nrepresentation should be easily computable and conducive to efficient\ncomparisons among graphs, tailored to the particular data and analytical task\nat hand. Unfortunately, a \"one-size-fits-all\" solution is unattainable, as\ndifferent analytical tasks may require different attention to global or local\ngraph features. We develop SGR, the first, to our knowledge, method for\nlearning graph representations in a self-supervised manner. Grounded on\nspectral graph analysis, SGR seamlessly combines all aforementioned desirable\nproperties. In extensive experiments, we show how our approach works on large\ngraph collections, facilitates self-supervised representation learning across a\nvariety of application domains, and performs competitively to state-of-the-art\nmethods without re-training.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 08:50:34 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Tsitsulin", "Anton", ""], ["Mottin", "Davide", ""], ["Karras", "Panagiotis", ""], ["Bronstein", "Alex", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "1811.06284", "submitter": "Guansong Lu", "authors": "Guansong Lu, Zhiming Zhou, Yuxuan Song, Kan Ren, Yong Yu", "title": "Guiding the One-to-one Mapping in CycleGAN via Optimal Transport", "comments": "The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CycleGAN is capable of learning a one-to-one mapping between two data\ndistributions without paired examples, achieving the task of unsupervised data\ntranslation. However, there is no theoretical guarantee on the property of the\nlearned one-to-one mapping in CycleGAN. In this paper, we experimentally find\nthat, under some circumstances, the one-to-one mapping learned by CycleGAN is\njust a random one within the large feasible solution space. Based on this\nobservation, we explore to add extra constraints such that the one-to-one\nmapping is controllable and satisfies more properties related to specific\ntasks. We propose to solve an optimal transport mapping restrained by a\ntask-specific cost function that reflects the desired properties, and use the\nbarycenters of optimal transport mapping to serve as references for CycleGAN.\nOur experiments indicate that the proposed algorithm is capable of learning a\none-to-one mapping with the desired properties.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 10:34:33 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Lu", "Guansong", ""], ["Zhou", "Zhiming", ""], ["Song", "Yuxuan", ""], ["Ren", "Kan", ""], ["Yu", "Yong", ""]]}, {"id": "1811.06363", "submitter": "Thierry Garaix", "authors": "C. Rodriguez, Thierry Garaix (LIMOS, CIS-ENSMSE), X. Xie, V. Augusto", "title": "Staff dimensioning in homecare services with uncertain demands", "comments": null, "journal-ref": "International Journal of Production Research, Taylor & Francis,\n  2015, 53 (24), pp.7396 - 7410", "doi": "10.1080/00207543.2015.1081427", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem addressed in this paper is how to calculate the amount of\npersonnel required to ensure the activity of a home health care (HHC) center on\na tactical horizon. Design of quantitative approaches for this question is\nchallenging. The number of caregivers has to be determined for each profession\nin order to balance the coverage of patients in a region and the workforce cost\nover several months. Unknown demand in care and spatial dimensions, combination\nof skills to cover a care and individual trips visiting patients make the\nunderlaying optimization problem very hard. Few studies are dedicated to staff\ndimensioning for HHC compared to patient to nurses assignment/sequencing and\ncenters location problems. We propose an original two-stage approach based on\ninteger linear stochastic programming, that exploits historical medical data.\nThe first stage calculates (near-)optimal levels of resources for possible\ndemand scenarios , while the second stage computes the optimal number of\ncaregiver for each profession to meet a target coverage indicator. For\ndecision-makers, our algorithm gives the number of employees for each category\nrequired to satisfy the demand without any recourse (overtime, external\nresources) with fixed probability and confidence interval. The approach has\nbeen tested on various instances built from data of the French agency of\nhospitalization data (ATIH).\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:32:56 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Rodriguez", "C.", "", "LIMOS, CIS-ENSMSE"], ["Garaix", "Thierry", "", "LIMOS, CIS-ENSMSE"], ["Xie", "X.", ""], ["Augusto", "V.", ""]]}, {"id": "1811.06395", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Xuesong Wang, Andrew P. Tarko, Shou'en Fang", "title": "Modeling car-following behavior on urban expressways in Shanghai: A\n  naturalistic driving study", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies Volume 93,\n  August 2018, Pages 425-445", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Five car-following models were calibrated, validated and cross-compared. The\nintelligent driver model performed best among the evaluated models.\nConsiderable behavioral differences between different drivers were found.\nCalibrated model parameters may not be numerically equivalent with observed\nones.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 18:40:52 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Zhu", "Meixin", ""], ["Wang", "Xuesong", ""], ["Tarko", "Andrew P.", ""], ["Fang", "Shou'en", ""]]}, {"id": "1811.06447", "submitter": "Lars Fischer", "authors": "Lars Fischer, Jan-Menno Memmen, Eric MSP Veith, Martin Tr\\\"oschel", "title": "Adversarial Resilience Learning - Towards Systemic Vulnerability\n  Analysis for Large and Complex Systems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Adversarial Resilience Learning (ARL), a concept to\nmodel, train, and analyze artificial neural networks as representations of\ncompetitive agents in highly complex systems. In our examples, the agents\nnormally take the roles of attackers or defenders that aim at worsening or\nimproving-or keeping, respectively-defined performance indicators of the\nsystem. Our concept provides adaptive, repeatable, actor-based testing with a\nchance of detecting previously unknown attack vectors. We provide the\nconstitutive nomenclature of ARL and, based on it, the description of\nexperimental setups and results of a preliminary implementation of ARL in\nsimulated power systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 16:08:05 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Fischer", "Lars", ""], ["Memmen", "Jan-Menno", ""], ["Veith", "Eric MSP", ""], ["Tr\u00f6schel", "Martin", ""]]}, {"id": "1811.06471", "submitter": "Mark Ibrahim", "authors": "Ceena Modarres, Mark Ibrahim, Melissa Louie, John Paisley", "title": "Towards Explainable Deep Learning for Credit Lending: A Case Study", "comments": "Accepted NIPS 2018 FEAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning adoption in the financial services industry has been limited\ndue to a lack of model interpretability. However, several techniques have been\nproposed to explain predictions made by a neural network. We provide an initial\ninvestigation into these techniques for the assessment of credit risk with\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 17:03:59 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 21:16:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Modarres", "Ceena", ""], ["Ibrahim", "Mark", ""], ["Louie", "Melissa", ""], ["Paisley", "John", ""]]}, {"id": "1811.06521", "submitter": "Jan Leike", "authors": "Borja Ibarz and Jan Leike and Tobias Pohlen and Geoffrey Irving and\n  Shane Legg and Dario Amodei", "title": "Reward learning from human preferences and demonstrations in Atari", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To solve complex real-world problems with reinforcement learning, we cannot\nrely on manually specified reward functions. Instead, we can have humans\ncommunicate an objective to the agent directly. In this work, we combine two\napproaches to learning from human feedback: expert demonstrations and\ntrajectory preferences. We train a deep neural network to model the reward\nfunction and use its predicted reward to train an DQN-based deep reinforcement\nlearning agent on 9 Atari games. Our approach beats the imitation learning\nbaseline in 7 games and achieves strictly superhuman performance on 2 games\nwithout using game rewards. Additionally, we investigate the goodness of fit of\nthe reward model, present some reward hacking problems, and study the effects\nof noise in the human labels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:33:43 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ibarz", "Borja", ""], ["Leike", "Jan", ""], ["Pohlen", "Tobias", ""], ["Irving", "Geoffrey", ""], ["Legg", "Shane", ""], ["Amodei", "Dario", ""]]}, {"id": "1811.06533", "submitter": "Siyu He", "authors": "Siyu He, Yin Li, Yu Feng, Shirley Ho, Siamak Ravanbakhsh, Wei Chen,\n  and Barnab\\'as P\\'oczos", "title": "Learning to Predict the Cosmological Structure Formation", "comments": "8 pages, 5 figures, 1 table", "journal-ref": "PNAS July 9, 2019 116 (28) 13825-13832", "doi": "10.1073/pnas.1821458116", "report-no": null, "categories": "astro-ph.CO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matter evolved under influence of gravity from minuscule density\nfluctuations. Non-perturbative structure formed hierarchically over all scales,\nand developed non-Gaussian features in the Universe, known as the Cosmic Web.\nTo fully understand the structure formation of the Universe is one of the holy\ngrails of modern astrophysics. Astrophysicists survey large volumes of the\nUniverse and employ a large ensemble of computer simulations to compare with\nthe observed data in order to extract the full information of our own Universe.\nHowever, to evolve trillions of galaxies over billions of years even with the\nsimplest physics is a daunting task. We build a deep neural network, the Deep\nDensity Displacement Model (hereafter D$^3$M), to predict the non-linear\nstructure formation of the Universe from simple linear perturbation theory. Our\nextensive analysis, demonstrates that D$^3$M outperforms the second order\nperturbation theory (hereafter 2LPT), the commonly used fast approximate\nsimulation method, in point-wise comparison, 2-point correlation, and 3-point\ncorrelation. We also show that D$^3$M is able to accurately extrapolate far\nbeyond its training data, and predict structure formation for significantly\ndifferent cosmological parameters. Our study proves, for the first time, that\ndeep learning is a practical and accurate alternative to approximate\nsimulations of the gravitational structure formation of the Universe.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:56:58 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 05:47:15 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["He", "Siyu", ""], ["Li", "Yin", ""], ["Feng", "Yu", ""], ["Ho", "Shirley", ""], ["Ravanbakhsh", "Siamak", ""], ["Chen", "Wei", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1811.06560", "submitter": "Mani A", "authors": "A. Mani", "title": "High Granular Operator Spaces, and Less-Contaminated General Rough\n  Mereologies", "comments": "Research paper: Preprint: Final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granular operator spaces and variants had been introduced and used in\ntheoretical investigations on the foundations of general rough sets by the\npresent author over the last few years. In this research, higher order versions\nof these are presented uniformly as partial algebraic systems. They are also\nadapted for practical applications when the data is representable by data\ntable-like structures according to a minimalist schema for avoiding\ncontamination. Issues relating to valuations used in information systems or\ntables are also addressed. The concept of contamination introduced and studied\nby the present author across a number of her papers, concerns mixing up of\ninformation across semantic domains (or domains of discourse). Rough inclusion\nfunctions (\\textsf{RIF}s), variants, and numeric functions often have a direct\nor indirect role in contaminating algorithms. Some solutions that seek to\nreplace or avoid them have been proposed and investigated by the present author\nin some of her earlier papers. Because multiple kinds of solution are of\ninterest to the contamination problem, granular generalizations of RIFs are\nproposed, and investigated. Interesting representation results are proved and a\ncore algebraic strategy for generalizing Skowron-Polkowski style of rough\nmereology (though for a very different purpose) is formulated. A number of\nexamples have been added to illustrate key parts of the proposal in higher\norder variants of granular operator spaces. Further algorithms grounded in\nmereological nearness, suited for decision-making in human-machine interaction\ncontexts, are proposed by the present author. Applications of granular\n\\textsf{RIF}s to partial/soft solutions of the inverse problem are also\ninvented in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 19:03:38 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 22:27:50 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2019 01:20:36 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 04:59:05 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1811.06564", "submitter": "Juan Leni", "authors": "Juan Leni, John Levine, John Quigley", "title": "Seq2Seq Mimic Games: A Signaling Perspective", "comments": "NIPS 2018 Workshop on Emergent Communication (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence of communication in multiagent adversarial settings\ninspired by the classic Imitation game. A class of three player games is used\nto explore how agents based on sequence to sequence (Seq2Seq) models can learn\nto communicate information in adversarial settings. We propose a modeling\napproach, an initial set of experiments and use signaling theory to support our\nanalysis. In addition, we describe how we operationalize the learning process\nof actor-critic Seq2Seq based agents in these communicational games.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 19:16:18 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Leni", "Juan", ""], ["Levine", "John", ""], ["Quigley", "John", ""]]}, {"id": "1811.06596", "submitter": "M. Shazan Mohomed Jabbar", "authors": "Mohomed Shazan Mohomed Jabbar, Luke Kumar, Hamman Samuel, Mi-Young\n  Kim, Sankalp Prabhakar, Randy Goebel, Osmar Za\\\"iane", "title": "On Generality and Knowledge Transferability in Cross-Domain Duplicate\n  Question Detection for Heterogeneous Community Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Duplicate question detection is an ongoing challenge in community question\nanswering because semantically equivalent questions can have significantly\ndifferent words and structures. In addition, the identification of duplicate\nquestions can reduce the resources required for retrieval, when the same\nquestions are not repeated. This study compares the performance of deep neural\nnetworks and gradient tree boosting, and explores the possibility of domain\nadaptation with transfer learning to improve the under-performing target\ndomains for the text-pair duplicates classification task, using three\nheterogeneous datasets: general-purpose Quora, technical Ask Ubuntu, and\nacademic English Stack Exchange. Ultimately, our study exposes the alternative\nhypothesis that the meaning of a \"duplicate\" is not inherently general-purpose,\nbut rather is dependent on the domain of learning, hence reducing the chance of\ntransfer learning through adapting to the domain.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 21:29:26 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Jabbar", "Mohomed Shazan Mohomed", ""], ["Kumar", "Luke", ""], ["Samuel", "Hamman", ""], ["Kim", "Mi-Young", ""], ["Prabhakar", "Sankalp", ""], ["Goebel", "Randy", ""], ["Za\u00efane", "Osmar", ""]]}, {"id": "1811.06606", "submitter": "Daniel Muller", "authors": "Daniel Muller", "title": "Economics of Human-AI Ecosystem: Value Bias and Lost Utility in\n  Multi-Dimensional Gaps", "comments": "8 pages, typos corrected, examples added to Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, artificial intelligence (AI) decision-making and autonomous\nsystems became an integrated part of the economy, industry, and society. The\nevolving economy of the human-AI ecosystem raising concerns regarding the risks\nand values inherited in AI systems. This paper investigates the dynamics of\ncreation and exchange of values and points out gaps in perception of\ncost-value, knowledge, space and time dimensions. It shows aspects of value\nbias in human perception of achievements and costs that encoded in AI systems.\nIt also proposes rethinking hard goals definitions and cost-optimal\nproblem-solving principles in the lens of effectiveness and efficiency in the\ndevelopment of trusted machines. The paper suggests a value-driven with cost\nawareness strategy and principles for problem-solving and planning of effective\nresearch progress to address real-world problems that involve diverse forms of\nachievements, investments, and survival scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 21:59:41 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:48:49 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Muller", "Daniel", ""]]}, {"id": "1811.06622", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Concept-Oriented Deep Learning: Generative Concept Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative concept representations have three major advantages over\ndiscriminative ones: they can represent uncertainty, they support integration\nof learning and reasoning, and they are good for unsupervised and\nsemi-supervised learning. We discuss probabilistic and generative deep\nlearning, which generative concept representations are based on, and the use of\nvariational autoencoders and generative adversarial networks for learning\ngenerative concept representations, particularly for concepts whose data are\nsequences, structured data or graphs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:13:26 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1811.06626", "submitter": "Raksha Kumaraswamy", "authors": "Vincent Liu, Raksha Kumaraswamy, Lei Le, Martha White", "title": "The Utility of Sparse Representations for Control in Reinforcement\n  Learning", "comments": "Association for the Advancement of Artificial Intelligence 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate sparse representations for control in reinforcement learning.\nWhile these representations are widely used in computer vision, their\nprevalence in reinforcement learning is limited to sparse coding where\nextracting representations for new data can be computationally intensive. Here,\nwe begin by demonstrating that learning a control policy incrementally with a\nrepresentation from a standard neural network fails in classic control domains,\nwhereas learning with a representation obtained from a neural network that has\nsparsity properties enforced is effective. We provide evidence that the reason\nfor this is that the sparse representation provides locality, and so avoids\ncatastrophic interference, and particularly keeps consistent, stable values for\nbootstrapping. We then discuss how to learn such sparse representations. We\nexplore the idea of Distributional Regularizers, where the activation of hidden\nnodes is encouraged to match a particular distribution that results in sparse\nactivation across time. We identify a simple but effective way to obtain sparse\nrepresentations, not afforded by previously proposed strategies, making it more\npractical for further investigation into sparse representations for\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:23:36 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Liu", "Vincent", ""], ["Kumaraswamy", "Raksha", ""], ["Le", "Lei", ""], ["White", "Martha", ""]]}, {"id": "1811.06629", "submitter": "Raksha Kumaraswamy", "authors": "Raksha Kumaraswamy, Matthew Schlegel, Adam White, Martha White", "title": "Context-Dependent Upper-Confidence Bounds for Directed Exploration", "comments": "Neural Information Processing Systems 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed exploration strategies for reinforcement learning are critical for\nlearning an optimal policy in a minimal number of interactions with the\nenvironment. Many algorithms use optimism to direct exploration, either through\nvisitation estimates or upper confidence bounds, as opposed to data-inefficient\nstrategies like \\epsilon-greedy that use random, undirected exploration. Most\ndata-efficient exploration methods require significant computation, typically\nrelying on a learned model to guide exploration. Least-squares methods have the\npotential to provide some of the data-efficiency benefits of model-based\napproaches -- because they summarize past interactions -- with the computation\ncloser to that of model-free approaches. In this work, we provide a novel,\ncomputationally efficient, incremental exploration strategy, leveraging this\nproperty of least-squares temporal difference learning (LSTD). We derive upper\nconfidence bounds on the action-values learned by LSTD, with context-dependent\n(or state-dependent) noise variance. Such context-dependent noise focuses\nexploration on a subset of variable states, and allows for reduced exploration\nin other states. We empirically demonstrate that our algorithm can converge\nmore quickly than other incremental exploration strategies using confidence\nestimates on action-values.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:43:56 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 16:42:14 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Kumaraswamy", "Raksha", ""], ["Schlegel", "Matthew", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1811.06630", "submitter": "Sungjin Lee", "authors": "Sungjin Lee", "title": "Nudging Neural Conversational Model with Domain Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversation models are attractive because one can train a model\ndirectly on dialog examples with minimal labeling. With a small amount of data,\nhowever, they often fail to generalize over test data since they tend to\ncapture spurious features instead of semantically meaningful domain knowledge.\nTo address this issue, we propose a novel approach that allows any human\nteachers to transfer their domain knowledge to the conversation model in the\nform of natural language rules. We tested our method with three different\ndialog datasets. The improved performance across all domains demonstrates the\nefficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 23:47:39 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Lee", "Sungjin", ""]]}, {"id": "1811.06654", "submitter": "Qian Xu", "authors": "Qian Xu, Shuqi Xu", "title": "Neural network state estimation for full quantum state tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An efficient state estimation model, neural network estimation (NNE),\nempowered by machine learning techniques, is presented for full quantum state\ntomography (FQST). A parameterized function based on neural network is applied\nto map the measurement outcomes to the estimated quantum states. Parameters are\nupdated with supervised learning procedures. From the computational complexity\nperspective our algorithm is the most efficient one among existing state\nestimation algorithms for full quantum state tomography. We perform numerical\ntests to prove both the accuracy and scalability of our model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 02:16:48 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 02:18:44 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Xu", "Qian", ""], ["Xu", "Shuqi", ""]]}, {"id": "1811.06672", "submitter": "Haruna Isah", "authors": "Sazia Mahfuz, Haruna Isah, Farhana Zulkernine, Peter Nicholls", "title": "Detecting Irregular Patterns in IoT Streaming Data for Fall Detection", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/IEMCON.2018.8614822", "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting patterns in real time streaming data has been an interesting and\nchallenging data analytics problem. With the proliferation of a variety of\nsensor devices, real-time analytics of data from the Internet of Things (IoT)\nto learn regular and irregular patterns has become an important machine\nlearning problem to enable predictive analytics for automated notification and\ndecision support. In this work, we address the problem of learning an irregular\nhuman activity pattern, fall, from streaming IoT data from wearable sensors. We\npresent a deep neural network model for detecting fall based on accelerometer\ndata giving 98.75 percent accuracy using an online physical activity monitoring\ndataset called \"MobiAct\", which was published by Vavoulas et al. The initial\nmodel was developed using IBM Watson studio and then later transferred and\ndeployed on IBM Cloud with the streaming analytics service supported by IBM\nStreams for monitoring real-time IoT data. We also present the systems\narchitecture of the real-time fall detection framework that we intend to use\nwith mbientlabs wearable health monitoring sensors for real time patient\nmonitoring at retirement homes or rehabilitation clinics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:59:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Mahfuz", "Sazia", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""], ["Nicholls", "Peter", ""]]}, {"id": "1811.06747", "submitter": "Teresa Scantamburlo", "authors": "Teresa Scantamburlo, Andrew Charlesworth, Nello Cristianini", "title": "Machine Decisions and Human Consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we increasingly delegate decision-making to algorithms, whether directly\nor indirectly, important questions emerge in circumstances where those\ndecisions have direct consequences for individual rights and personal\nopportunities, as well as for the collective good. A key problem for\npolicymakers is that the social implications of these new methods can only be\ngrasped if there is an adequate comprehension of their general technical\nunderpinnings. The discussion here focuses primarily on the case of enforcement\ndecisions in the criminal justice system, but draws on similar situations\nemerging from other algorithms utilised in controlling access to opportunities,\nto explain how machine learning works and, as a result, how decisions are made\nby modern intelligent algorithms or 'classifiers'. It examines the key aspects\nof the performance of classifiers, including how classifiers learn, the fact\nthat they operate on the basis of correlation rather than causation, and that\nthe term 'bias' in machine learning has a different meaning to common usage. An\nexample of a real world 'classifier', the Harm Assessment Risk Tool (HART), is\nexamined, through identification of its technical features: the classification\nmethod, the training data and the test data, the features and the labels,\nvalidation and performance measures. Four normative benchmarks are then\nconsidered by reference to HART: (a) prediction accuracy (b) fairness and\nequality before the law (c) transparency and accountability (d) informational\nprivacy and freedom of expression, in order to demonstrate how its technical\nfeatures have important normative dimensions that bear directly on the extent\nto which the system can be regarded as a viable and legitimate support for, or\neven alternative to, existing human decision-makers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 10:56:36 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 14:41:51 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Scantamburlo", "Teresa", ""], ["Charlesworth", "Andrew", ""], ["Cristianini", "Nello", ""]]}, {"id": "1811.06825", "submitter": "Jerome Feldman", "authors": "Jerome Feldman (ICSI and UC Berkeley)", "title": "Towards a Science of Mind", "comments": "18 pages and 1 Figure. The ancient mind/body remains a scientific and\n  existential mystery. This article develops a methodology for an incremental\n  Science of Mind and describes some ongoing prospects and successes. Updates\n  include additional phenomena, including emotions,and several more references.\n  A major addition is a postulated general (mysterious) brain-mind mapping", "journal-ref": null, "doi": "10.1007/s41470-019-00041-4", "report-no": null, "categories": "cs.GL cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ancient mind/body problem continues to be one of deepest mysteries of\nscience and of the human spirit. Despite major advances in many fields, there\nis still no plausible link between subjective experience (qualia) and its\nrealization in the body. This paper outlines some of the elements of a rigorous\nscience of mind (SoM) - key ideas include scientific realism of mind, agnostic\nmysterianism, careful attention to language, and a focus on concrete\n(touchstone) questions and results. A core suggestion is to focus effort on the\n(still mysterious) mapping from neural activity to subjective experience.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:02:40 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 20:44:15 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 16:58:06 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Feldman", "Jerome", "", "ICSI and UC Berkeley"]]}, {"id": "1811.06889", "submitter": "Lisa Lee", "authors": "Maruan Al-Shedivat, Lisa Lee, Ruslan Salakhutdinov, Eric Xing", "title": "On the Complexity of Exploration in Goal-Driven Navigation", "comments": "Relational Representation Learning Workshop (NIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building agents that can explore their environments intelligently is a\nchallenging open problem. In this paper, we make a step towards understanding\nhow a hierarchical design of the agent's policy can affect its exploration\ncapabilities. First, we design EscapeRoom environments, where the agent must\nfigure out how to navigate to the exit by accomplishing a number of\nintermediate tasks (\\emph{subgoals}), such as finding keys or opening doors.\nOur environments are procedurally generated and vary in complexity, which can\nbe controlled by the number of subgoals and relationships between them. Next,\nwe propose to measure the complexity of each environment by constructing\ndependency graphs between the goals and analytically computing \\emph{hitting\ntimes} of a random walk in the graph. We empirically evaluate Proximal Policy\nOptimization (PPO) with sparse and shaped rewards, a variation of policy\nsketches, and a hierarchical version of PPO (called HiPPO) akin to h-DQN. We\nshow that analytically estimated \\emph{hitting time} in goal dependency graphs\nis an informative metric of the environment complexity. We conjecture that the\nresult should hold for environments other than navigation. Finally, we show\nthat solving environments beyond certain level of complexity requires\nhierarchical approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:17:27 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Lee", "Lisa", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1811.06943", "submitter": "Shintaro Yamamoto", "authors": "Shintaro Yamamoto, Yoshihiro Fukuhara, Ryota Suzuki, Shigeo Morishima,\n  Hirokatsu Kataoka", "title": "Automatic Paper Summary Generation from Visual and Textual Information", "comments": "International Conference on Machine Vision 2018, Munich, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent boom in artificial intelligence (AI) research, including\ncomputer vision (CV), it has become impossible for researchers in these fields\nto keep up with the exponentially increasing number of manuscripts. In response\nto this situation, this paper proposes the paper summary generation (PSG) task\nusing a simple but effective method to automatically generate an academic paper\nsummary from raw PDF data. We realized PSG by combination of vision-based\nsupervised components detector and language-based unsupervised important\nsentence extractor, which is applicable for a trained format of manuscripts. We\nshow the quantitative evaluation of ability of simple vision-based components\nextraction, and the qualitative evaluation that our system can extract both\nvisual item and sentence that are helpful for understanding. After processing\nvia our PSG, the 979 manuscripts accepted by the Conference on Computer Vision\nand Pattern Recognition (CVPR) 2018 are available. It is believed that the\nproposed method will provide a better way for researchers to stay caught with\nimportant academic papers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 17:52:25 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Yamamoto", "Shintaro", ""], ["Fukuhara", "Yoshihiro", ""], ["Suzuki", "Ryota", ""], ["Morishima", "Shigeo", ""], ["Kataoka", "Hirokatsu", ""]]}, {"id": "1811.06962", "submitter": "Fernando De Mesentier Silva", "authors": "Fernando de Mesentier Silva, Igor Borovikov, John Kolen, Navid Aghdaie\n  and Kazi Zaman", "title": "Exploring Gameplay With AI Agents", "comments": "8 pages, 5 images. Published on The 14th AAAI Conference on\n  Artificial Intelligence and Interactive Digital Entertainment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of playtesting a game is subjective, expensive and incomplete. In\nthis paper, we present a playtesting approach that explores the game space with\nautomated agents and collects data to answer questions posed by the designers.\nRather than have agents interacting with an actual game client, this approach\nrecreates the bare bone mechanics of the game as a separate system. Our agent\nis able to play in minutes what would take testers days of organic gameplay.\nThe analysis of thousands of game simulations exposed imbalances in game\nactions, identified inconsequential rewards and evaluated the effectiveness of\noptional strategic choices. Our test case game, The Sims Mobile, was recently\nreleased and the findings shown here influenced design changes that resulted in\nimproved player experience.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 18:37:25 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Silva", "Fernando de Mesentier", ""], ["Borovikov", "Igor", ""], ["Kolen", "John", ""], ["Aghdaie", "Navid", ""], ["Zaman", "Kazi", ""]]}, {"id": "1811.06964", "submitter": "Coline Devin", "authors": "Eric Jang, Coline Devin, Vincent Vanhoucke, Sergey Levine", "title": "Grasp2Vec: Learning Object Representations from Self-Supervised Grasping", "comments": "CoRL 2018. Eric Jang and Coline Devin contributed equally to this\n  work", "journal-ref": "Proceedings of The 2nd Conference on Robot Learning, in PMLR\n  87:99-112 (2018)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well structured visual representations can make robot learning faster and can\nimprove generalization. In this paper, we study how we can acquire effective\nobject-centric representations for robotic manipulation tasks without human\nlabeling by using autonomous robot interaction with the environment. Such\nrepresentation learning methods can benefit from continuous refinement of the\nrepresentation as the robot collects more experience, allowing them to scale\neffectively without human intervention. Our representation learning approach is\nbased on object persistence: when a robot removes an object from a scene, the\nrepresentation of that scene should change according to the features of the\nobject that was removed. We formulate an arithmetic relationship between\nfeature vectors from this observation, and use it to learn a representation of\nscenes and objects that can then be used to identify object instances, localize\nthem in the scene, and perform goal-directed grasping tasks where the robot\nmust retrieve commanded objects from a bin. The same grasping procedure can\nalso be used to automatically collect training data for our method, by\nrecording images of scenes, grasping and removing an object, and recording the\noutcome. Our experiments demonstrate that this self-supervised approach for\ntasked grasping substantially outperforms direct reinforcement learning from\nimages and prior representation learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 18:42:02 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 18:25:51 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Jang", "Eric", ""], ["Devin", "Coline", ""], ["Vanhoucke", "Vincent", ""], ["Levine", "Sergey", ""]]}, {"id": "1811.07004", "submitter": "Tom Schaul", "authors": "Tom Schaul, Hado van Hasselt, Joseph Modayil, Martha White, Adam\n  White, Pierre-Luc Bacon, Jean Harb, Shibl Mourad, Marc Bellemare, Doina\n  Precup", "title": "The Barbados 2018 List of Open Issues in Continual Learning", "comments": "NIPS Continual Learning Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to make progress toward artificial general intelligence, namely\ngeneral-purpose agents that autonomously learn how to competently act in\ncomplex environments. The purpose of this report is to sketch a research\noutline, share some of the most important open issues we are facing, and\nstimulate further discussion in the community. The content is based on some of\nour discussions during a week-long workshop held in Barbados in February 2018.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 19:41:42 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Schaul", "Tom", ""], ["van Hasselt", "Hado", ""], ["Modayil", "Joseph", ""], ["White", "Martha", ""], ["White", "Adam", ""], ["Bacon", "Pierre-Luc", ""], ["Harb", "Jean", ""], ["Mourad", "Shibl", ""], ["Bellemare", "Marc", ""], ["Precup", "Doina", ""]]}, {"id": "1811.07017", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Sarath Chandar, Yoshua Bengio", "title": "Towards Training Recurrent Neural Networks for Lifelong Learning", "comments": "Accepted at Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting and capacity saturation are the central challenges of\nany parametric lifelong learning system. In this work, we study these\nchallenges in the context of sequential supervised learning with an emphasis on\nrecurrent neural networks. To evaluate the models in the lifelong learning\nsetting, we propose a curriculum-based, simple, and intuitive benchmark where\nthe models are trained on tasks with increasing levels of difficulty. To\nmeasure the impact of catastrophic forgetting, the model is tested on all the\nprevious tasks as it completes any task. As a step towards developing true\nlifelong learning systems, we unify Gradient Episodic Memory (a catastrophic\nforgetting alleviation approach) and Net2Net(a capacity expansion approach).\nBoth these models are proposed in the context of feedforward networks and we\nevaluate the feasibility of using them for recurrent networks. Evaluation on\nthe proposed benchmark shows that the unified model is more suitable than the\nconstituent models for lifelong learning setting.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:13:23 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 16:21:06 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 05:23:46 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Sodhani", "Shagun", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1811.07029", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhengchao Zhang, Zhen Xiao, and Zhibo Gong", "title": "Modelling the Dynamic Joint Policy of Teammates with Attention\n  Multi-agent DDPG", "comments": "Attention-based Multi-agent DDPG. Experimental results show that it\n  not only outperforms the state-of-the-art RL-based methods and rule-based\n  methods by a large margin, but also achieves better performance in terms of\n  scalability and robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modelling and exploiting teammates' policies in cooperative multi-agent\nsystems have long been an interest and also a big challenge for the\nreinforcement learning (RL) community. The interest lies in the fact that if\nthe agent knows the teammates' policies, it can adjust its own policy\naccordingly to arrive at proper cooperations; while the challenge is that the\nagents' policies are changing continuously due to they are learning\nconcurrently, which imposes difficulty to model the dynamic policies of\nteammates accurately. In this paper, we present \\emph{ATTention Multi-Agent\nDeep Deterministic Policy Gradient} (ATT-MADDPG) to address this challenge.\nATT-MADDPG extends DDPG, a single-agent actor-critic RL method, with two\nspecial designs. First, in order to model the teammates' policies, the agent\nshould get access to the observations and actions of teammates. ATT-MADDPG\nadopts a centralized critic to collect such information. Second, to model the\nteammates' policies using the collected information in an effective way,\nATT-MADDPG enhances the centralized critic with an attention mechanism. This\nattention mechanism introduces a special structure to explicitly model the\ndynamic joint policy of teammates, making sure that the collected information\ncan be processed efficiently. We evaluate ATT-MADDPG on both benchmark tasks\nand the real-world packet routing tasks. Experimental results show that it not\nonly outperforms the state-of-the-art RL-based methods and rule-based methods\nby a large margin, but also achieves better performance in terms of scalability\nand robustness.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:30:29 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Mao", "Hangyu", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Gong", "Zhibo", ""]]}, {"id": "1811.07033", "submitter": "Yixin Nie", "authors": "Yixin Nie, Yicheng Wang, Mohit Bansal", "title": "Analyzing Compositionality-Sensitivity of NLI Models", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success in natural language inference (NLI) should require a model to\nunderstand both lexical and compositional semantics. However, through\nadversarial evaluation, we find that several state-of-the-art models with\ndiverse architectures are over-relying on the former and fail to use the\nlatter. Further, this compositionality unawareness is not reflected via\nstandard evaluation on current datasets. We show that removing RNNs in existing\nmodels or shuffling input words during training does not induce large\nperformance loss despite the explicit removal of compositional information.\nTherefore, we propose a compositionality-sensitivity testing setup that\nanalyzes models on natural examples from existing datasets that cannot be\nsolved via lexical features alone (i.e., on which a bag-of-words model gives a\nhigh probability to one wrong label), hence revealing the models' actual\ncompositionality awareness. We show that this setup not only highlights the\nlimited compositional ability of current NLI models, but also differentiates\nmodel performance based on design, e.g., separating shallow bag-of-words models\nfrom deeper, linguistically-grounded tree-based models. Our evaluation setup is\nan important analysis tool: complementing currently existing adversarial and\nlinguistically driven diagnostic evaluations, and exposing opportunities for\nfuture work on evaluating models' compositional understanding.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 21:12:24 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Nie", "Yixin", ""], ["Wang", "Yicheng", ""], ["Bansal", "Mohit", ""]]}, {"id": "1811.07039", "submitter": "Yixin Nie", "authors": "Yixin Nie, Haonan Chen, Mohit Bansal", "title": "Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 21:37:59 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Nie", "Yixin", ""], ["Chen", "Haonan", ""], ["Bansal", "Mohit", ""]]}, {"id": "1811.07078", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, Chunyan Miao", "title": "An Affect-Rich Neural Conversational Model with Biased Attention and\n  Weighted Cross-Entropy Loss", "comments": "AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affect conveys important implicit information in human communication. Having\nthe capability to correctly express affect during human-machine conversations\nis one of the major milestones in artificial intelligence. In recent years,\nextensive research on open-domain neural conversational models has been\nconducted. However, embedding affect into such models is still under explored.\nIn this paper, we propose an end-to-end affect-rich open-domain neural\nconversational model that produces responses not only appropriate in syntax and\nsemantics, but also with rich affect. Our model extends the Seq2Seq model and\nadopts VAD (Valence, Arousal and Dominance) affective notations to embed each\nword with affects. In addition, our model considers the effect of negators and\nintensifiers via a novel affective attention mechanism, which biases attention\ntowards affect-rich words in input sentences. Lastly, we train our model with\nan affect-incorporated objective function to encourage the generation of\naffect-rich words in the output responses. Evaluations based on both perplexity\nand human evaluations show that our model outperforms the state-of-the-art\nbaseline model of comparable size in producing natural and affect-rich\nresponses.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 02:29:18 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Miao", "Chunyan", ""]]}, {"id": "1811.07146", "submitter": "Guillermo P\\'erez", "authors": "Micha\\\"el Cadilhac, Guillermo A. P\\'erez, and Marie van den Bogaard", "title": "The Impatient May Use Limited Optimism to Minimize Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discounted-sum games provide a formal model for the study of reinforcement\nlearning, where the agent is enticed to get rewards early since later rewards\nare discounted. When the agent interacts with the environment, she may regret\nher actions, realizing that a previous choice was suboptimal given the behavior\nof the environment. The main contribution of this paper is a PSPACE algorithm\nfor computing the minimum possible regret of a given game. To this end, several\nresults of independent interest are shown. (1) We identify a class of\nregret-minimizing and admissible strategies that first assume that the\nenvironment is collaborating, then assume it is adversarial---the precise\ntiming of the switch is key here. (2) Disregarding the computational cost of\nnumerical analysis, we provide an NP algorithm that checks that the regret\nentailed by a given time-switching strategy exceeds a given value. (3) We show\nthat determining whether a strategy minimizes regret is decidable in PSPACE.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 11:23:58 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Cadilhac", "Micha\u00ebl", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Bogaard", "Marie van den", ""]]}, {"id": "1811.07155", "submitter": "Salvador Garc\\'ia", "authors": "Jos\\'e-Ram\\'on Cano and Pedro Antonio Guti\\'errez and Bartosz Krawczyk\n  and Micha{\\l} Wo\\'zniak and Salvador Garc\\'ia", "title": "Monotonic classification: an overview on algorithms, performance\n  measures and data sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, knowledge discovery in databases is an essential step to identify\nvalid, novel and useful patterns for decision making. There are many real-world\nscenarios, such as bankruptcy prediction, option pricing or medical diagnosis,\nwhere the classification models to be learned need to fulfil restrictions of\nmonotonicity (i.e. the target class label should not decrease when input\nattributes values increase). For instance, it is rational to assume that a\nhigher debt ratio of a company should never result in a lower level of\nbankruptcy risk. Consequently, there is a growing interest from the data mining\nresearch community concerning monotonic predictive models. This paper aims to\npresent an overview about the literature in the field, analyzing existing\ntechniques and proposing a taxonomy of the algorithms based on the type of\nmodel generated. For each method, we review the quality metrics considered in\nthe evaluation and the different data sets and monotonic problems used in the\nanalysis. In this way, this paper serves as an overview of the research about\nmonotonic classification in specialized literature and can be used as a\nfunctional guide of the field.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 12:36:38 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Cano", "Jos\u00e9-Ram\u00f3n", ""], ["Guti\u00e9rrez", "Pedro Antonio", ""], ["Krawczyk", "Bartosz", ""], ["Wo\u017aniak", "Micha\u0142", ""], ["Garc\u00eda", "Salvador", ""]]}, {"id": "1811.07206", "submitter": "Neha Baranwal", "authors": "Neha Baranwal", "title": "On Human Robot Interaction using Multiple Modes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Humanoid robots have apparently similar body structure like human beings. Due\nto their technical design, they are sharing the same workspace with humans.\nThey are placed to clean things, to assist old age people, to entertain us and\nmost importantly to serve us. To be acceptable in the household, they must have\nhigher level of intelligence than industrial robots and they must be social and\ncapable of interacting people around it, who are not supposed to be robot\nspecialist. All these come under the field of human robot interaction (HRI).\nThere are various modes like speech, gesture, behavior etc. through which human\ncan interact with robots. To solve all these challenges, a multimodel technique\nhas been introduced where gesture as well as speech is used as a mode of\ninteraction.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 18:28:44 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Baranwal", "Neha", ""]]}, {"id": "1811.07214", "submitter": "Phaniteja S", "authors": "Meha Kaushik, Phaniteja S and K. Madhava Krishna", "title": "Parameter Sharing Reinforcement Learning Architecture for Multi Agent\n  Driving Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent learning provides a potential framework for learning and\nsimulating traffic behaviors. This paper proposes a novel architecture to learn\nmultiple driving behaviors in a traffic scenario. The proposed architecture can\nlearn multiple behaviors independently as well as simultaneously. We take\nadvantage of the homogeneity of agents and learn in a parameter sharing\nparadigm. To further speed up the training process asynchronous updates are\nemployed into the architecture. While learning different behaviors\nsimultaneously, the given framework was also able to learn cooperation between\nthe agents, without any explicit communication. We applied this framework to\nlearn two important behaviors in driving: 1) Lane-Keeping and 2) Over-Taking.\nResults indicate faster convergence and learning of a more generic behavior,\nthat is scalable to any number of agents. When compared the results with\nexisting approaches, our results indicate equal and even better performance in\nsome cases.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 19:51:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kaushik", "Meha", ""], ["S", "Phaniteja", ""], ["Krishna", "K. Madhava", ""]]}, {"id": "1811.07231", "submitter": "Guillem Franc\\`es", "authors": "Blai Bonet, Guillem Franc\\`es, Hector Geffner", "title": "Learning Features and Abstract Actions for Computing Generalized Plans", "comments": "Preprint of paper accepted at AAAI'19 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized planning is concerned with the computation of plans that solve\nnot one but multiple instances of a planning domain. Recently, it has been\nshown that generalized plans can be expressed as mappings of feature values\ninto actions, and that they can often be computed with fully observable\nnon-deterministic (FOND) planners. The actions in such plans, however, are not\nthe actions in the instances themselves, which are not necessarily common to\nother instances, but abstract actions that are defined on a set of common\nfeatures. The formulation assumes that the features and the abstract actions\nare given. In this work, we address this limitation by showing how to learn\nthem automatically. The resulting account of generalized planning combines\nlearning and planning in a novel way: a learner, based on a Max SAT\nformulation, yields the features and abstract actions from sampled state\ntransitions, and a FOND planner uses this information, suitably transformed, to\nproduce the general plans. Correctness guarantees are given and experimental\nresults on several domains are reported.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 22:05:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Bonet", "Blai", ""], ["Franc\u00e8s", "Guillem", ""], ["Geffner", "Hector", ""]]}, {"id": "1811.07236", "submitter": "Vicky Zayats", "authors": "Vicky Zayats and Mari Ostendorf", "title": "Robust cross-domain disfluency detection with pattern match networks", "comments": "This paper was submitted to EMNLP 2018 and was rejected. Our EMNLP\n  submission is posted here to establish concurrency with \"Disfluency Detection\n  using Auto-Correlational Neural Networks\" by P. Lou, P. Anderson, M. Johnson\n  which was submitted to EMNLP at the same time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel pattern match neural network architecture\nthat uses neighbor similarity scores as features, eliminating the need for\nfeature engineering in a disfluency detection task. We evaluate the approach in\ndisfluency detection for four different speech genres, showing that the\napproach is as effective as hand-engineered pattern match features when used on\nin-domain data and achieves superior performance in cross-domain scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 22:34:20 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zayats", "Vicky", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1811.07243", "submitter": "Samuel Gomes", "authors": "Samuel Gomes, Carlos Martinho, Jo\\~ao Dias", "title": "Dynamic Social Interaction Mechanics CrossAnt", "comments": "5 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, big effort is being put to study gamification and how game elements\ncan be used to engage players. In this scope, we believe there is a growing\nneed to explore the impact game mechanics have on the players' interactions and\nperception. This work focuses on the application of game mechanics to lead\nplayers to achieve certain types of social interaction (we named this type of\nmechanics social interaction mechanics). A word matching game called CrossAnt\nwas modified so that it could dynamically generate different social interaction\nmechanics. These mechanics consisted in different key combinations needed to\nplay the game and were aimed to promote what we think are three important types\nof social interactions: cooperation, competition and individual exploration.\nOur evaluation consisted on the execution of several sessions where two players\ninteracted with the game for several levels and had to find for themselves how\nto perform the actions needed to succeed. While some of the levels required the\ninput from both players in order to be completed, others could be completed by\neach player independently. Our results show that cooperation was perceived when\nboth players had to intervene to perform the game actions. However, longer\ninteractions may still be needed so that the other types of interactions are\npromoted.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 23:13:12 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 18:02:00 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Gomes", "Samuel", ""], ["Martinho", "Carlos", ""], ["Dias", "Jo\u00e3o", ""]]}, {"id": "1811.07253", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, William Yang Wang", "title": "Quantifying Uncertainties in Natural Language Processing Tasks", "comments": "To appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable uncertainty quantification is a first step towards building\nexplainable, transparent, and accountable artificial intelligent systems.\nRecent progress in Bayesian deep learning has made such quantification\nrealizable. In this paper, we propose novel methods to study the benefits of\ncharacterizing model and data uncertainties for natural language processing\n(NLP) tasks. With empirical experiments on sentiment analysis, named entity\nrecognition, and language modeling using convolutional and recurrent neural\nnetwork models, we show that explicitly modeling uncertainties is not only\nnecessary to measure output confidence levels, but also useful at enhancing\nmodel performances in various NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 01:36:05 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Xiao", "Yijun", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.07255", "submitter": "James Foulds", "authors": "James Foulds, Rashidul Islam, Kamrun Keya, Shimei Pan", "title": "Bayesian Modeling of Intersectional Fairness: The Variance of Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersectionality is a framework that analyzes how interlocking systems of\npower and oppression affect individuals along overlapping dimensions including\nrace, gender, sexual orientation, class, and disability. Intersectionality\ntheory therefore implies it is important that fairness in artificial\nintelligence systems be protected with regard to multi-dimensional protected\nattributes. However, the measurement of fairness becomes statistically\nchallenging in the multi-dimensional setting due to data sparsity, which\nincreases rapidly in the number of dimensions, and in the values per dimension.\nWe present a Bayesian probabilistic modeling approach for the reliable,\ndata-efficient estimation of fairness with multi-dimensional protected\nattributes, which we apply to two existing intersectional fairness metrics.\nExperimental results on census data and the COMPAS criminal justice recidivism\ndataset demonstrate the utility of our methodology, and show that Bayesian\nmethods are valuable for the modeling and measurement of fairness in an\nintersectional context.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 01:54:24 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 16:58:05 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Foulds", "James", ""], ["Islam", "Rashidul", ""], ["Keya", "Kamrun", ""], ["Pan", "Shimei", ""]]}, {"id": "1811.07260", "submitter": "Zhizhong Wang", "authors": "Zhizhong Wang and Lei Zhao and Wei Xing and Dongming Lu", "title": "GLStyleNet: Higher Quality Style Transfer Combining Global and Local\n  Pyramid Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies using deep neural networks have shown remarkable success in\nstyle transfer especially for artistic and photo-realistic images. However, the\napproaches using global feature correlations fail to capture small, intricate\ntextures and maintain correct texture scales of the artworks, and the\napproaches based on local patches are defective on global effect. In this\npaper, we present a novel feature pyramid fusion neural network, dubbed\nGLStyleNet, which sufficiently takes into consideration multi-scale and\nmulti-level pyramid features by best aggregating layers across a VGG network,\nand performs style transfer hierarchically with multiple losses of different\nscales. Our proposed method retains high-frequency pixel information and low\nfrequency construct information of images from two aspects: loss function\nconstraint and feature fusion. Our approach is not only flexible to adjust the\ntrade-off between content and style, but also controllable between global and\nlocal. Compared to state-of-the-art methods, our method can transfer not just\nlarge-scale, obvious style cues but also subtle, exquisite ones, and\ndramatically improves the quality of style transfer. We demonstrate the\neffectiveness of our approach on portrait style transfer, artistic style\ntransfer, photo-realistic style transfer and Chinese ancient painting style\ntransfer tasks. Experimental results indicate that our unified approach\nimproves image style transfer quality over previous state-of-the-art methods,\nwhile also accelerating the whole process in a certain extent. Our code is\navailable at https://github.com/EndyWon/GLStyleNet.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 02:39:45 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wang", "Zhizhong", ""], ["Zhao", "Lei", ""], ["Xing", "Wei", ""], ["Lu", "Dongming", ""]]}, {"id": "1811.07308", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Yilin Shen, Hongxia Jin, William Wang", "title": "A Variational Dirichlet Framework for Out-of-Distribution Detection", "comments": "Tech Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recently rapid development in deep learning, deep neural networks\nhave been widely adopted in many real-life applications. However, deep neural\nnetworks are also known to have very little control over its uncertainty for\nunseen examples, which potentially causes very harmful and annoying\nconsequences in practical scenarios. In this paper, we are particularly\ninterested in designing a higher-order uncertainty metric for deep neural\nnetworks and investigate its effectiveness under the out-of-distribution\ndetection task proposed by~\\cite{hendrycks2016baseline}. Our method first\nassumes there exists an underlying higher-order distribution $\\mathbb{P}(z)$,\nwhich controls label-wise categorical distribution $\\mathbb{P}(y)$ over classes\non the K-dimension simplex, and then approximate such higher-order distribution\nvia parameterized posterior function $p_{\\theta}(z|x)$ under variational\ninference framework, finally we use the entropy of learned posterior\ndistribution $p_{\\theta}(z|x)$ as uncertainty measure to detect\nout-of-distribution examples. Further, we propose an auxiliary objective\nfunction to discriminate against synthesized adversarial examples to further\nincrease the robustness of the proposed uncertainty measure. Through\ncomprehensive experiments on various datasets, our proposed framework is\ndemonstrated to consistently outperform competing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 10:24:58 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2019 19:48:44 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 01:51:41 GMT"}, {"version": "v4", "created": "Sat, 20 Apr 2019 22:53:10 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Chen", "Wenhu", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""], ["Wang", "William", ""]]}, {"id": "1811.07342", "submitter": "Xiao-Yang Liu", "authors": "Weijun Lu, Xiao-Yang Liu, Qingwei Wu, Yue Sun, Anwar Walid", "title": "Transform-Based Multilinear Dynamical System for Tensor Time Series\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel multilinear dynamical system (MLDS) in a transform domain,\nnamed $\\mathcal{L}$-MLDS, to model tensor time series. With transformations\napplied to a tensor data, the latent multidimensional correlations among the\nfrontal slices are built, and thus resulting in the computational independence\nin the transform domain. This allows the exact separability of the\nmulti-dimensional problem into multiple smaller LDS problems. To estimate the\nsystem parameters, we utilize the expectation-maximization (EM) algorithm to\ndetermine the parameters of each LDS. Further, $\\mathcal{L}$-MLDSs\nsignificantly reduce the model parameters and allows parallel processing. Our\ngeneral $\\mathcal{L}$-MLDS model is implemented based on different transforms:\ndiscrete Fourier transform, discrete cosine transform and discrete wavelet\ntransform. Due to the nonlinearity of these transformations, $\\mathcal{L}$-MLDS\nis able to capture the nonlinear correlations within the data unlike the MLDS\n\\cite{rogers2013multilinear} which assumes multi-way linear correlations. Using\nfour real datasets, the proposed $\\mathcal{L}$-MLDS is shown to achieve much\nhigher prediction accuracy than the state-of-the-art MLDS and LDS with an equal\nnumber of parameters under different noise models. In particular, the relative\nerrors are reduced by $50\\% \\sim 99\\%$. Simultaneously, $\\mathcal{L}$-MLDS\nachieves an exponential improvement in the model's training time than MLDS.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 15:45:31 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lu", "Weijun", ""], ["Liu", "Xiao-Yang", ""], ["Wu", "Qingwei", ""], ["Sun", "Yue", ""], ["Walid", "Anwar", ""]]}, {"id": "1811.07407", "submitter": "Faisal Mahmood", "authors": "Faisal Mahmood, Ziyun Yang, Thomas Ashley and Nicholas J. Durr", "title": "Multimodal Densenet", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans make accurate decisions by interpreting complex data from multiple\nsources. Medical diagnostics, in particular, often hinge on human\ninterpretation of multi-modal information. In order for artificial intelligence\nto make progress in automated, objective, and accurate diagnosis and prognosis,\nmethods to fuse information from multiple medical imaging modalities are\nrequired. However, combining information from multiple data sources has several\nchallenges, as current deep learning architectures lack the ability to extract\nuseful representations from multimodal information, and often simple\nconcatenation is used to fuse such information. In this work, we propose\nMultimodal DenseNet, a novel architecture for fusing multimodal data. Instead\nof focusing on concatenation or early and late fusion, our proposed\narchitectures fuses information over several layers and gives the model\nflexibility in how it combines information from multiple sources. We apply this\narchitecture to the challenge of polyp characterization and landmark\nidentification in endoscopy. Features from white light images are fused with\nfeatures from narrow band imaging or depth maps. This study demonstrates that\nMultimodal DenseNet outperforms monomodal classification as well as other\nmultimodal fusion techniques by a significant margin on two different datasets.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 21:31:22 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Mahmood", "Faisal", ""], ["Yang", "Ziyun", ""], ["Ashley", "Thomas", ""], ["Durr", "Nicholas J.", ""]]}, {"id": "1811.07416", "submitter": "Shenghe Xu", "authors": "Shenghe Xu, Pei Liu, Ran Wang and Shivendra S. Panwar", "title": "Realtime Scheduling and Power Allocation Using Deep Neural Networks", "comments": "Submitted to WCNC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of base stations (BSs) and network densification\nin 5G, interference management using link scheduling and power control are\nvital for better utilization of radio resources. However, the complexity of\nsolving link scheduling and the power control problem grows exponentially with\nthe number of BS. Due to high computation time, previous methods are useful for\nresearch purposes but impractical for real time usage. In this paper we propose\nto use deep neural networks (DNNs) to approximate optimal link scheduling and\npower control for the case with multiple small cells. A deep Q-network (DQN)\nestimates a suitable schedule, then a DNN allocates power for the corresponding\nschedule. Simulation results show that the proposed method achieves over five\norders of magnitude speed-up with less than nine percent performance loss,\nmaking real time usage practical.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 22:37:16 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Xu", "Shenghe", ""], ["Liu", "Pei", ""], ["Wang", "Ran", ""], ["Panwar", "Shivendra S.", ""]]}, {"id": "1811.07488", "submitter": "Seunghwan Cha", "authors": "Seunghwan Cha, James Ainooson, Maithilee Kunda", "title": "Quantifying Human Behavior on the Block Design Test Through Automated\n  Multi-Level Analysis of Overhead Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The block design test is a standardized, widely used neuropsychological\nassessment of visuospatial reasoning that involves a person recreating a series\nof given designs out of a set of colored blocks. In current testing procedures,\nan expert neuropsychologist observes a person's accuracy and completion time as\nwell as overall impressions of the person's problem-solving procedures, errors,\netc., thus obtaining a holistic though subjective and often qualitative view of\nthe person's cognitive processes. We propose a new framework that combines room\nsensors and AI techniques to augment the information available to\nneuropsychologists from block design and similar tabletop assessments. In\nparticular, a ceiling-mounted camera captures an overhead view of the table\nsurface. From this video, we demonstrate how automated classification using\nmachine learning can produce a frame-level description of the state of the\nblock task and the person's actions over the course of each test problem. We\nalso show how a sequence-comparison algorithm can classify one individual's\nproblem-solving strategy relative to a database of simulated strategies, and\nhow these quantitative results can be visualized for use by neuropsychologists.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 04:03:03 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Cha", "Seunghwan", ""], ["Ainooson", "James", ""], ["Kunda", "Maithilee", ""]]}, {"id": "1811.07516", "submitter": "Rahma Fourati", "authors": "Rahma Fourati, Boudour Ammar, Javier Sanchez-Medina and Adel M. Alimi", "title": "Unsupervised Learning in Reservoir Computing for EEG-based Emotion\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications such as emotion recognition from recorded brain\nactivity, data are captured from electrodes over time. These signals constitute\na multidimensional time series. In this paper, Echo State Network (ESN), a\nrecurrent neural network with a great success in time series prediction and\nclassification, is optimized with different neural plasticity rules for\nclassification of emotions based on electroencephalogram (EEG) time series.\nActually, the neural plasticity rules are a kind of unsupervised learning\nadapted for the reservoir, i.e. the hidden layer of ESN. More specifically, an\ninvestigation of Oja's rule, BCM rule and gaussian intrinsic plasticity rule\nwas carried out in the context of EEG-based emotion recognition. The study,\nalso, includes a comparison of the offline and online training of the ESN. When\ntesting on the well-known affective benchmark \"DEAP dataset\" which contains EEG\nsignals from 32 subjects, we find that pretraining ESN with gaussian intrinsic\nplasticity enhanced the classification accuracy and outperformed the results\nachieved with an ESN pretrained with synaptic plasticity. Four classification\nproblems were conducted in which the system complexity is increased and the\ndiscrimination is more challenging, i.e. inter-subject emotion discrimination.\nOur proposed method achieves higher performance over the state of the art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:07:33 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 03:24:25 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Fourati", "Rahma", ""], ["Ammar", "Boudour", ""], ["Sanchez-Medina", "Javier", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1811.07531", "submitter": "Aurelien Pelissier", "authors": "Aurelien Pelissier, Atsuyoshi Nakamura, Koji Tabata", "title": "Feature selection as Monte-Carlo Search in Growing Single Rooted\n  Directed Acyclic Graph by Best Leaf Identification", "comments": null, "journal-ref": "Proceedings of the 2019 SIAM International Conference on Data\n  Mining. 2019, 450-458", "doi": "10.1137/1.9781611975673.51", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo tree search (MCTS) has received considerable interest due to its\nspectacular success in the difficult problem of computer Go and also proved\nbeneficial in a range of other domains. A major issue that has received little\nattention in the MCTS literature is the fact that, in most games, different\nactions can lead to the same state, that may lead to a high degree of\nredundancy in tree representation and unnecessary additional computational\ncost. We extend MCTS to single rooted directed acyclic graph (SR-DAG), and\nconsider the Best Arm Identification (BAI) and the Best Leaf Identification\n(BLI) problem of an expanding SR-DAG of arbitrary depth. We propose algorithms\nthat are (epsilon, delta)-correct in the fixed confidence setting, and prove an\nasymptotic upper bounds of sample complexity for our BAI algorithm. As a major\napplication for our BLI algorithm, a novel approach for Feature Selection is\nproposed by representing the feature set space as a SR-DAG and repeatedly\nevaluating feature subsets until a candidate for the best leaf is returned, a\nproof of concept is shown on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 07:29:51 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 17:57:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Pelissier", "Aurelien", ""], ["Nakamura", "Atsuyoshi", ""], ["Tabata", "Koji", ""]]}, {"id": "1811.07536", "submitter": "Constance Thierry", "authors": "Constance Thierry (DRUID), Jean-Christophe Dubois (DRUID), Yolande Le\n  Gall (DRUID), Arnaud Martin (DRUID)", "title": "Contributors profile modelization in crowdsourcing platforms", "comments": "in French, 27\\`emes rencontres francophones sur la logique floue et\n  ses applications, Nov 2018, Arras, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The crowdsourcing consists in the externalisation of tasks to a crowd of\npeople remunerated to execute this ones. The crowd, usually diversified, can\ninclude users without qualification and/or motivation for the tasks. In this\npaper we will introduce a new method of user expertise modelization in the\ncrowdsourcing platforms based on the theory of belief functions in order to\nidentify serious and qualificated users.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 07:51:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Thierry", "Constance", "", "DRUID"], ["Dubois", "Jean-Christophe", "", "DRUID"], ["Gall", "Yolande Le", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"]]}, {"id": "1811.07545", "submitter": "Yunxiao Qin", "authors": "Yunxiao Qin, Chenxu Zhao, Zezheng Wang, Junliang Xing, Jun Wan, Zhen\n  Lei", "title": "Representation based and Attention augmented Meta learning", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based computer vision fails to work when labeled images are\nscarce. Recently, Meta learning algorithm has been confirmed as a promising way\nto improve the ability of learning from few images for computer vision.\nHowever, previous Meta learning approaches expose problems:\n  1) they ignored the importance of attention mechanism for the Meta learner;\n  2) they didn't give the Meta learner the ability of well using the past\nknowledge which can help to express images into high representations, resulting\nin that the Meta learner has to solve few shot learning task directly from the\noriginal high dimensional RGB images.\n  In this paper, we argue that the attention mechanism and the past knowledge\nare crucial for the Meta learner, and the Meta learner should be trained on\nhigh representations of the RGB images instead of directly on the original\nones. Based on these arguments, we propose two methods: Attention augmented\nMeta Learning (AML) and Representation based and Attention augmented Meta\nLearning(RAML). The method AML aims to improve the Meta learner's attention\nability by explicitly embedding an attention model into its network. The method\nRAML aims to give the Meta learner the ability of leveraging the past learned\nknowledge to reduce the dimension of the original input data by expressing it\ninto high representations, and help the Meta learner to perform well. Extensive\nexperiments demonstrate the effectiveness of the proposed models, with\nstate-of-the-art few shot learning performances on several few shot learning\nbenchmarks. The source code of our proposed methods will be released soon to\nfacilitate further studies on those aforementioned problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 08:08:00 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 03:27:02 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 07:11:59 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Qin", "Yunxiao", ""], ["Zhao", "Chenxu", ""], ["Wang", "Zezheng", ""], ["Xing", "Junliang", ""], ["Wan", "Jun", ""], ["Lei", "Zhen", ""]]}, {"id": "1811.07550", "submitter": "Xiujun Li", "authors": "Yuexin Wu and Xiujun Li and Jingjing Liu and Jianfeng Gao and Yiming\n  Yang", "title": "Switch-based Active Deep Dyna-Q: Efficient Adaptive Planning for\n  Task-Completion Dialogue Policy Learning", "comments": "8 pages, 9 figures, AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training task-completion dialogue agents with reinforcement learning usually\nrequires a large number of real user experiences. The Dyna-Q algorithm extends\nQ-learning by integrating a world model, and thus can effectively boost\ntraining efficiency using simulated experiences generated by the world model.\nThe effectiveness of Dyna-Q, however, depends on the quality of the world model\n- or implicitly, the pre-specified ratio of real vs. simulated experiences used\nfor Q-learning. To this end, we extend the recently proposed Deep Dyna-Q (DDQ)\nframework by integrating a switcher that automatically determines whether to\nuse a real or simulated experience for Q-learning. Furthermore, we explore the\nuse of active learning for improving sample efficiency, by encouraging the\nworld model to generate simulated experiences in the state-action space where\nthe agent has not (fully) explored. Our results show that by combining switcher\nand active learning, the new framework named as Switch-based Active Deep Dyna-Q\n(Switch-DDQ), leads to significant improvement over DDQ and Q-learning\nbaselines in both simulation and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 08:23:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wu", "Yuexin", ""], ["Li", "Xiujun", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Yang", "Yiming", ""]]}, {"id": "1811.07594", "submitter": "Lucas Lamata", "authors": "J. Olivares-S\\'anchez, J. Casanova, E. Solano, L. Lamata", "title": "Measurement-based adaptation protocol with quantum reinforcement\n  learning in a Rigetti quantum computer", "comments": null, "journal-ref": "Quantum Reports 2, 293 (2020)", "doi": "10.3390/quantum2020019", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an experimental realization of a measurement-based adaptation\nprotocol with quantum reinforcement learning in a Rigetti cloud quantum\ncomputer. The experiment in this few-qubit superconducting chip faithfully\nreproduces the theoretical proposal, setting the first steps towards a\nsemiautonomous quantum agent. This experiment paves the way towards quantum\nreinforcement learning with superconducting circuits.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:33:14 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 16:36:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Olivares-S\u00e1nchez", "J.", ""], ["Casanova", "J.", ""], ["Solano", "E.", ""], ["Lamata", "L.", ""]]}, {"id": "1811.07600", "submitter": "Anshuman Suri", "authors": "Parag Agrawal, Anshuman Suri, Tulasi Menon", "title": "A Trustworthy, Responsible and Interpretable System to Handle Chit Chat\n  in Conversational Bots", "comments": "7 pages, 5 figures, The Second AAAI Workshop on Reasoning and\n  Learning for Human-Machine Dialogues (DEEP-DIAL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most often, chat-bots are built to solve the purpose of a search engine or a\nhuman assistant: Their primary goal is to provide information to the user or\nhelp them complete a task. However, these chat-bots are incapable of responding\nto unscripted queries like \"Hi, what's up\", \"What's your favourite food\". Human\nevaluation judgments show that 4 humans come to a consensus on the intent of a\ngiven query which is from chat domain only 77% of the time, thus making it\nevident how non-trivial this task is. In our work, we show why it is difficult\nto break the chitchat space into clearly defined intents. We propose a system\nto handle this task in chat-bots, keeping in mind scalability,\ninterpretability, appropriateness, trustworthiness, relevance and coverage. Our\nwork introduces a pipeline for query understanding in chitchat using\nhierarchical intents as well as a way to use seq-seq auto-generation models in\nprofessional bots. We explore an interpretable model for chat domain detection\nand also show how various components such as adult/offensive classification,\ngrammars/regex patterns, curated personality based responses, generic guided\nevasive responses and response generation models can be combined in a scalable\nway to solve this problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:45:13 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 12:10:30 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Agrawal", "Parag", ""], ["Suri", "Anshuman", ""], ["Menon", "Tulasi", ""]]}, {"id": "1811.07603", "submitter": "Aswani Kumar Cherukuri Dr", "authors": "Ishwarya M S, Aswani Kumar Ch", "title": "Quantum Inspired High Dimensional Conceptual Space as KID Model for\n  Elderly Assistance", "comments": "18th International conference on Intelligent Systems Design and\n  Applications, (ISDA) to be held from December 6th, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a cognitive system that acquires knowledge on\nelderly daily activities to ensure their wellness in a smart home using a\nKnowledge-Information-Data (KID) model. The novel cognitive framework called\nhigh dimensional conceptual space is proposed and used as KID model. This KID\nmodel is built using geometrical framework of conceptual spaces and formal\nconcept analysis (FCA) to overcome imprecise concept notation of conceptual\nspace with the help of topology based FCA. By doing so, conceptual space can be\nrepresented using Hilbert space. This high dimensional conceptual space is\nquantum inspired in terms of its concept representation. The knowledge learnt\nby the KID model recognizes the daily activities of the elderly. Consequently,\nthe model identifies the scenario on which the wellness of the elderly has to\nbe ensured.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:51:00 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["S", "Ishwarya M", ""], ["Ch", "Aswani Kumar", ""]]}, {"id": "1811.07694", "submitter": "Dmytro Terletskyi", "authors": "Dmytro O. Terletskyi", "title": "Algorithms for Runtime Generation of Homogeneous Classes of Objects", "comments": "International Conference on Cyber Security and Computer Science\n  (ICONCS'18), October 18-20, 2018, Safranbolu, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper contains analysis of main modern approaches to dynamic code\ngeneration, in particular generation of new classes of objects during program\nexecution. The main attention was paid to universal exploiters of homogeneous\nclasses of objects, which were proposed as a part of such knowledge\nrepresentation model as object-oriented dynamic networks, as the tools for\ngeneration of new classes of objects in program runtime. As the result,\nalgorithms for implementation of such universal exploiters of classes of\nobjects as union, intersection, difference and symmetric difference were\ndeveloped. These algorithms can be used knowledge-based intelligent systems,\nwhich are based on object-oriented dynamic networks, and they can be adapted\nfor some object-oriented programming languages with powerful metaprogramming\nopportunities.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 12:58:37 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Terletskyi", "Dmytro O.", ""]]}, {"id": "1811.07727", "submitter": "Ping Luo", "authors": "Ping Luo, Zhanglin Peng, Jiamin Ren, Ruimao Zhang", "title": "Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?", "comments": "Preprint. Work in Progress. 14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yes, they do. This work investigates a perspective for deep learning: whether\ndifferent normalization layers in a ConvNet require different normalizers. This\nis the first step towards understanding this phenomenon. We allow each\nconvolutional layer to be stacked before a switchable normalization (SN) that\nlearns to choose a normalizer from a pool of normalization methods. Through\nsystematic experiments in ImageNet, COCO, Cityscapes, and ADE20K, we answer\nthree questions: (a) Is it useful to allow each normalization layer to select\nits own normalizer? (b) What impacts the choices of normalizers? (c) Do\ndifferent tasks and datasets prefer different normalizers? Our results suggest\nthat (1) using distinct normalizers improves both learning and generalization\nof a ConvNet; (2) the choices of normalizers are more related to depth and\nbatch size, but less relevant to parameter initialization, learning rate decay,\nand solver; (3) different tasks and datasets have different behaviors when\nlearning to select normalizers.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 14:36:25 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Luo", "Ping", ""], ["Peng", "Zhanglin", ""], ["Ren", "Jiamin", ""], ["Zhang", "Ruimao", ""]]}, {"id": "1811.07770", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "Aff-Wild2: Extending the Aff-Wild Database for Affect Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of human affect using visual signals is a problem\nthat has attracted significant interest over the past 20 years. However, human\nemotional states are quite complex. To appraise such states displayed in\nreal-world settings, we need expressive emotional descriptors that are capable\nof capturing and describing this complexity. The circumplex model of affect,\nwhich is described in terms of valence (i.e., how positive or negative is an\nemotion) and arousal (i.e., power of the activation of the emotion), can be\nused for this purpose. Recent progress in the emotion recognition domain has\nbeen achieved through the development of deep neural architectures and the\navailability of very large training databases. To this end, Aff-Wild has been\nthe first large-scale \"in-the-wild\" database, containing around 1,200,000\nframes. In this paper, we build upon this database, extending it with 260 more\nsubjects and 1,413,000 new video frames. We call the union of Aff-Wild with the\nadditional data, Aff-Wild2. The videos are downloaded from Youtube and have\nlarge variations in pose, age, illumination conditions, ethnicity and\nprofession. Both database-specific as well as cross-database experiments are\nperformed in this paper, by utilizing the Aff-Wild2, along with the RECOLA\ndatabase. The developed deep neural architectures are based on the joint\ntraining of state-of-the-art convolutional and recurrent neural networks with\nattention mechanism; thus exploiting both the invariant properties of\nconvolutional features, while modeling temporal dynamics that arise in human\nbehaviour via the recurrent layers. The obtained results show premise for\nutilization of the extended Aff-Wild, as well as of the developed deep neural\narchitectures for visual analysis of human behaviour in terms of continuous\nemotion dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 01:57:15 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:44:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1811.07771", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias and Stefanos Zafeiriou", "title": "A Multi-Task Learning & Generation Framework: Valence-Arousal, Action\n  Units & Primary Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years many research efforts have been devoted to the field\nof affect analysis. Various approaches have been proposed for: i) discrete\nemotion recognition in terms of the primary facial expressions; ii) emotion\nanalysis in terms of facial Action Units (AUs), assuming a fixed expression\nintensity; iii) dimensional emotion analysis, in terms of valence and arousal\n(VA). These approaches can only be effective, if they are developed using\nlarge, appropriately annotated databases, showing behaviors of people\nin-the-wild, i.e., in uncontrolled environments. Aff-Wild has been the first,\nlarge-scale, in-the-wild database (including around 1,200,000 frames of 300\nvideos), annotated in terms of VA. In the vast majority of existing emotion\ndatabases, their annotation is limited to either primary expressions, or\nvalence-arousal, or action units. In this paper, we first annotate a part\n(around $234,000$ frames) of the Aff-Wild database in terms of $8$ AUs and\nanother part (around $288,000$ frames) in terms of the $7$ basic emotion\ncategories, so that parts of this database are annotated in terms of VA, as\nwell as AUs, or primary expressions. Then, we set up and tackle multi-task\nlearning for emotion recognition, as well as for facial image generation.\nMulti-task learning is performed using: i) a deep neural network with shared\nhidden layers, which learns emotional attributes by exploiting their\ninter-dependencies; ii) a discriminator of a generative adversarial network\n(GAN). On the other hand, image generation is implemented through the generator\nof the GAN. For these two tasks, we carefully design loss functions that fit\nthe examined set-up. Experiments are presented which illustrate the good\nperformance of the proposed approach when applied to the new annotated parts of\nthe Aff-Wild database.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 15:40:23 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 23:39:14 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1811.07791", "submitter": "David Fuentes-Jimenez", "authors": "David Fuentes-Jimenez, David Casillas-Perez, Daniel Pizarro, Toby\n  Collins and Adrien Bartoli", "title": "Deep Shape-from-Template: Wide-Baseline, Dense and Fast Registration and\n  Deformable Reconstruction from a Single Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Deep Shape-from-Template (DeepSfT), a novel Deep Neural Network\n(DNN) method for solving real-time automatic registration and 3D reconstruction\nof a deformable object viewed in a single monocular image.DeepSfT advances the\nstate-of-the-art in various aspects. Compared to existing DNN SfT methods, it\nis the first fully convolutional real-time approach that handles an arbitrary\nobject geometry, topology and surface representation. It also does not require\nground truth registration with real data and scales well to very complex object\nmodels with large numbers of elements. Compared to previous non-DNN SfT\nmethods, it does not involve numerical optimization at run-time, and is a\ndense, wide-baseline solution that does not demand, and does not suffer from,\nfeature-based matching. It is able to process a single image with significant\ndeformation and viewpoint changes, and handles well the core challenges of\nocclusions, weak texture and blur. DeepSfT is based on residual encoder-decoder\nstructures and refining blocks. It is trained end-to-end with a novel\ncombination of supervised learning from simulated renderings of the object\nmodel and semi-supervised automatic fine-tuning using real data captured with a\nstandard RGB-D camera. The cameras used for fine-tuning and run-time can be\ndifferent, making DeepSfT practical for real-world use. We show that DeepSfT\nsignificantly outperforms state-of-the-art wide-baseline approaches for\nnon-trivial templates, with quantitative and qualitative evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 16:39:27 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 15:13:33 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 03:12:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Fuentes-Jimenez", "David", ""], ["Casillas-Perez", "David", ""], ["Pizarro", "Daniel", ""], ["Collins", "Toby", ""], ["Bartoli", "Adrien", ""]]}, {"id": "1811.07819", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Abhishek Gupta, Sergey Levine", "title": "Learning Actionable Representations with Goal-Conditioned Policies", "comments": "To be presented at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a central challenge across a range of machine\nlearning areas. In reinforcement learning, effective and functional\nrepresentations have the potential to tremendously accelerate learning progress\nand solve more challenging problems. Most prior work on representation learning\nhas focused on generative approaches, learning representations that capture all\nunderlying factors of variation in the observation space in a more disentangled\nor well-ordered manner. In this paper, we instead aim to learn functionally\nsalient representations: representations that are not necessarily complete in\nterms of capturing all factors of variation in the observation space, but\nrather aim to capture those factors of variation that are important for\ndecision making -- that are \"actionable.\" These representations are aware of\nthe dynamics of the environment, and capture only the elements of the\nobservation that are necessary for decision making rather than all factors of\nvariation, without explicit reconstruction of the observation. We show how\nthese representations can be useful to improve exploration for sparse reward\nproblems, to enable long horizon hierarchical reinforcement learning, and as a\nstate representation for learning policies for downstream tasks. We evaluate\nour method on a number of simulated environments, and compare it to prior\nmethods for representation learning, exploration, and hierarchical\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 17:30:36 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 06:44:13 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ghosh", "Dibya", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""]]}, {"id": "1811.07868", "submitter": "Patrick Klose", "authors": "Patrick Klose, Rudolf Mester", "title": "Simulated Autonomous Driving in a Realistic Driving Environment using\n  Deep Reinforcement Learning and a Deterministic Finite State Machine", "comments": "This paper is submitted to Applications of Intelligent Systems\n  (APPIS) 2019 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of Autonomous Driving, the system controlling the vehicle can be\nseen as an agent acting in a complex environment and thus naturally fits into\nthe modern framework of Reinforcement Learning. However, learning to drive can\nbe a challenging task and current results are often restricted to simplified\ndriving environments. To advance the field, we present a method to adaptively\nrestrict the action space of the agent according to its current driving\nsituation and show that it can be used to swiftly learn to drive in a realistic\nenvironment based on the Deep Q-Network algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:45:00 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 07:47:48 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Klose", "Patrick", ""], ["Mester", "Rudolf", ""]]}, {"id": "1811.07871", "submitter": "Jan Leike", "authors": "Jan Leike and David Krueger and Tom Everitt and Miljan Martic and\n  Vishal Maini and Shane Legg", "title": "Scalable agent alignment via reward modeling: a research direction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One obstacle to applying reinforcement learning algorithms to real-world\nproblems is the lack of suitable reward functions. Designing such reward\nfunctions is difficult in part because the user only has an implicit\nunderstanding of the task objective. This gives rise to the agent alignment\nproblem: how do we create agents that behave in accordance with the user's\nintentions? We outline a high-level research direction to solve the agent\nalignment problem centered around reward modeling: learning a reward function\nfrom interaction with the user and optimizing the learned reward function with\nreinforcement learning. We discuss the key challenges we expect to face when\nscaling reward modeling to complex and general domains, concrete approaches to\nmitigate these challenges, and ways to establish trust in the resulting agents.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:48:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Leike", "Jan", ""], ["Krueger", "David", ""], ["Everitt", "Tom", ""], ["Martic", "Miljan", ""], ["Maini", "Vishal", ""], ["Legg", "Shane", ""]]}, {"id": "1811.07882", "submitter": "John Co-Reyes", "authors": "John D. Co-Reyes, Abhishek Gupta, Suvansh Sanjeev, Nick Altieri, Jacob\n  Andreas, John DeNero, Pieter Abbeel, Sergey Levine", "title": "Guiding Policies with Language via Meta-Learning", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral skills or policies for autonomous agents are conventionally\nlearned from reward functions, via reinforcement learning, or from\ndemonstrations, via imitation learning. However, both modes of task\nspecification have their disadvantages: reward functions require manual\nengineering, while demonstrations require a human expert to be able to actually\nperform the task in order to generate the demonstration. Instruction following\nfrom natural language instructions provides an appealing alternative: in the\nsame way that we can specify goals to other humans simply by speaking or\nwriting, we would like to be able to specify tasks for our machines. However, a\nsingle instruction may be insufficient to fully communicate our intent or, even\nif it is, may be insufficient for an autonomous agent to actually understand\nhow to perform the desired task. In this work, we propose an interactive\nformulation of the task specification problem, where iterative language\ncorrections are provided to an autonomous agent, guiding it in acquiring the\ndesired skill. Our proposed language-guided policy learning algorithm can\nintegrate an instruction and a sequence of corrections to acquire new skills\nvery quickly. In our experiments, we show that this method can enable a policy\nto follow instructions and corrections for simulated navigation and\nmanipulation tasks, substantially outperforming direct, non-interactive\ninstruction following.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:58:42 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 18:54:15 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Co-Reyes", "John D.", ""], ["Gupta", "Abhishek", ""], ["Sanjeev", "Suvansh", ""], ["Altieri", "Nick", ""], ["Andreas", "Jacob", ""], ["DeNero", "John", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1811.07901", "submitter": "Vivian Lai", "authors": "Vivian Lai, Chenhao Tan", "title": "On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection", "comments": "17 pages, 19 figures, in Proceedings of ACM FAT* 2019, dataset & demo\n  available at https://deception.machineintheloop.com", "journal-ref": null, "doi": "10.1145/3287560.3287590", "report-no": null, "categories": "cs.AI cs.CL cs.CY physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 19:00:01 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 20:47:12 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 03:52:47 GMT"}, {"version": "v4", "created": "Tue, 8 Jan 2019 21:15:07 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Lai", "Vivian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1811.07966", "submitter": "Alexander Wong", "authors": "Audrey Chung, Paul Fieguth, Alexander Wong", "title": "Mitigating Architectural Mismatch During the Evolutionary Synthesis of\n  Deep Neural Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary deep intelligence has recently shown great promise for producing\nsmall, powerful deep neural network models via the organic synthesis of\nincreasingly efficient architectures over successive generations. Existing\nevolutionary synthesis processes, however, have allowed the mating of parent\nnetworks independent of architectural alignment, resulting in a mismatch of\nnetwork structures. We present a preliminary study into the effects of\narchitectural alignment during evolutionary synthesis using a gene tagging\nsystem. Surprisingly, the network architectures synthesized using the gene\ntagging approach resulted in slower decreases in performance accuracy and\nstorage size; however, the resultant networks were comparable in size and\nperformance accuracy to the non-gene tagging networks. Furthermore, we\nspeculate that there is a noticeable decrease in network variability for\nnetworks synthesized with gene tagging, indicating that enforcing a\nlike-with-like mating policy potentially restricts the exploration of the\nsearch space of possible network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:36:16 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chung", "Audrey", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.07982", "submitter": "Minzhong Luo", "authors": "Mincong Luo, Xinfu He, Li Liu", "title": "Generative Model for Material Experiments Based on Prior Knowledge and\n  Attention Mechanism", "comments": "Accepted by NIPS2018 MMLM workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Material irradiation experiment is dangerous and complex, thus it requires\nthose with a vast advanced expertise to process the images and data manually.\nIn this paper, we propose a generative adversarial model based on prior\nknowledge and attention mechanism to achieve the generation of irradiated\nmaterial images (data-to-image model), and a prediction model for corresponding\nindustrial performance (image-to-data model). With the proposed models,\nresearchers can skip the dangerous and complex irradiation experiments and\nobtain the irradiation images and industrial performance parameters directly by\ninputing some experimental parameters only. We also introduce a new dataset\nISMD which contains 22000 irradiated images with 22,143 sets of corresponding\nparameters. Our model achieved high quality results by compared with several\nbaseline models. The evaluation and detailed analysis are also performed.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 02:40:00 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Luo", "Mincong", ""], ["He", "Xinfu", ""], ["Liu", "Li", ""]]}, {"id": "1811.07987", "submitter": "Li Conghui", "authors": "Conghui Li, Zhaocheng Zhu, and Yuming Zhao", "title": "Saliency Supervision: An Intuitive and Effective Approach for Pain\n  Intensity Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting pain intensity from face images is an important problem in autonomous\nnursing systems. However, due to the limitation in data sources and the\nsubjectiveness in pain intensity values, it is hard to adopt modern deep neural\nnetworks for this problem without domain-specific auxiliary design. Inspired by\nhuman vision priori, we propose a novel approach called saliency supervision,\nwhere we directly regularize deep networks to focus on facial area that is\ndiscriminative for pain regression. Through alternative training between\nsaliency supervision and global loss, our method can learn sparse and robust\nfeatures, which is proved helpful for pain intensity regression. We verified\nsaliency supervision with face-verification network backbone on the widely-used\ndataset, and achieved state-of-art performance without bells and whistles. Our\nsaliency supervision is intuitive in spirit, yet effective in performance. We\nbelieve such saliency supervision is essential in dealing with ill-posed\ndatasets, and has potential in a wide range of vision tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 15:18:09 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Li", "Conghui", ""], ["Zhu", "Zhaocheng", ""], ["Zhao", "Yuming", ""]]}, {"id": "1811.07996", "submitter": "Abon Chaudhuri", "authors": "Abon Chaudhuri, Paolo Messina, Samrat Kokkula, Aditya Subramanian,\n  Abhinandan Krishnan, Shreyansh Gandhi, Alessandro Magnani, Venkatesh\n  Kandaswamy", "title": "A Smart System for Selection of Optimal Product Images in E-Commerce", "comments": "Accepted in IEEE Big Data Conference 2018 (Industry & Government\n  Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce, content quality of the product catalog plays a key role in\ndelivering a satisfactory experience to the customers. In particular, visual\ncontent such as product images influences customers' engagement and purchase\ndecisions. With the rapid growth of e-commerce and the advent of artificial\nintelligence, traditional content management systems are giving way to\nautomated scalable systems. In this paper, we present a machine learning driven\nvisual content management system for extremely large e-commerce catalogs. For a\ngiven product, the system aggregates images from various suppliers, understands\nand analyzes them to produce a superior image set with optimal image count and\nquality, and arranges them in an order tailored to the demands of the\ncustomers. The system makes use of an array of technologies, ranging from deep\nlearning to traditional computer vision, at different stages of analysis. In\nthis paper, we outline how the system works and discuss the unique challenges\nrelated to applying machine learning techniques to real-world data from\ne-commerce domain. We emphasize how we tune state-of-the-art image\nclassification techniques to develop solutions custom made for a massive,\ndiverse, and constantly evolving product catalog. We also provide the details\nof how we measure the system's impact on various customer engagement metrics.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 02:35:48 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chaudhuri", "Abon", ""], ["Messina", "Paolo", ""], ["Kokkula", "Samrat", ""], ["Subramanian", "Aditya", ""], ["Krishnan", "Abhinandan", ""], ["Gandhi", "Shreyansh", ""], ["Magnani", "Alessandro", ""], ["Kandaswamy", "Venkatesh", ""]]}, {"id": "1811.08073", "submitter": "Pengyuan Ren", "authors": "Pengyuan Ren, Jianmin Li", "title": "Factorized Distillation: Training Holistic Person Re-identification\n  Model by Distilling an Ensemble of Partial ReID Models", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (ReID) is aimed at identifying the same person\nacross videos captured from different cameras. In the view that networks\nextracting global features using ordinary network architectures are difficult\nto extract local features due to their weak attention mechanisms, researchers\nhave proposed a lot of elaborately designed ReID networks, while greatly\nimproving the accuracy, the model size and the feature extraction latency are\nalso soaring. We argue that a relatively compact ordinary network extracting\nglobally pooled features has the capability to extract discriminative local\nfeatures and can achieve state-of-the-art precision if only the model's\nparameters are properly learnt. In order to reduce the difficulty in learning\nhard identity labels, we propose a novel knowledge distillation method:\nFactorized Distillation, which factorizes both feature maps and retrieval\nfeatures of holistic ReID network to mimic representations of multiple partial\nReID models, thus transferring the knowledge from partial ReID models to the\nholistic network. Experiments show that the performance of model trained with\nthe proposed method can outperform state-of-the-art with relatively few network\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 04:50:09 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ren", "Pengyuan", ""], ["Li", "Jianmin", ""]]}, {"id": "1811.08086", "submitter": "Arpit Agarwal Mr.", "authors": "Arpit Agarwal, Katharina Muelling and Katerina Fragkiadaki", "title": "Model Learning for Look-ahead Exploration in Continuous Control", "comments": "This is a pre-print of our paper which is accepted in AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an exploration method that incorporates look-ahead search over\nbasic learnt skills and their dynamics, and use it for reinforcement learning\n(RL) of manipulation policies . Our skills are multi-goal policies learned in\nisolation in simpler environments using existing multigoal RL formulations,\nanalogous to options or macroactions. Coarse skill dynamics, i.e., the state\ntransition caused by a (complete) skill execution, are learnt and are unrolled\nforward during lookahead search. Policy search benefits from temporal\nabstraction during exploration, though itself operates over low-level primitive\nactions, and thus the resulting policies does not suffer from suboptimality and\ninflexibility caused by coarse skill chaining. We show that the proposed\nexploration strategy results in effective learning of complex manipulation\npolicies faster than current state-of-the-art RL methods, and converges to\nbetter policies than methods that use options or parametrized skills as\nbuilding blocks of the policy itself, as opposed to guiding exploration. We\nshow that the proposed exploration strategy results in effective learning of\ncomplex manipulation policies faster than current state-of-the-art RL methods,\nand converges to better policies than methods that use options or parameterized\nskills as building blocks of the policy itself, as opposed to guiding\nexploration.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 06:11:26 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Agarwal", "Arpit", ""], ["Muelling", "Katharina", ""], ["Fragkiadaki", "Katerina", ""]]}, {"id": "1811.08120", "submitter": "Weiyu Cheng", "authors": "Weiyu Cheng, Yanyan Shen, Yanmin Zhu, Linpeng Huang", "title": "Explaining Latent Factor Models for Recommendation with Influence\n  Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330857", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models (LFMs) such as matrix factorization achieve the\nstate-of-the-art performance among various Collaborative Filtering (CF)\napproaches for recommendation. Despite the high recommendation accuracy of\nLFMs, a critical issue to be resolved is the lack of explainability. Extensive\nefforts have been made in the literature to incorporate explainability into\nLFMs. However, they either rely on auxiliary information which may not be\navailable in practice, or fail to provide easy-to-understand explanations. In\nthis paper, we propose a fast influence analysis method named FIA, which\nsuccessfully enforces explicit neighbor-style explanations to LFMs with the\ntechnique of influence functions stemmed from robust statistics. We first\ndescribe how to employ influence functions to LFMs to deliver neighbor-style\nexplanations. Then we develop a novel influence computation algorithm for\nmatrix factorization with high efficiency. We further extend it to the more\ngeneral neural collaborative filtering and introduce an approximation algorithm\nto accelerate influence analysis over neural network models. Experimental\nresults on real datasets demonstrate the correctness, efficiency and usefulness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:31:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cheng", "Weiyu", ""], ["Shen", "Yanyan", ""], ["Zhu", "Yanmin", ""], ["Huang", "Linpeng", ""]]}, {"id": "1811.08186", "submitter": "Fernando Mart\\'inez Plumed", "authors": "Fernando Mart\\'inez-Plumed and Jos\\'e Hern\\'andez-Orallo", "title": "Analysing Results from AI Benchmarks: Key Indicators and How to Obtain\n  Them", "comments": "This report is a preliminary version of a related paper with title\n  \"Dual Indicators to Analyse AI Benchmarks: Difficulty, Discrimination,\n  Ability and Generality\", accepted for publication at IEEE Transactions on\n  Games. Please refer to and cite the journal paper\n  (https://doi.org/10.1109/TG.2018.2883773)", "journal-ref": "IEEE Transactions on Games, 2018", "doi": "10.1109/TG.2018.2883773", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item response theory (IRT) can be applied to the analysis of the evaluation\nof results from AI benchmarks. The two-parameter IRT model provides two\nindicators (difficulty and discrimination) on the side of the item (or AI\nproblem) while only one indicator (ability) on the side of the respondent (or\nAI agent). In this paper we analyse how to make this set of indicators dual, by\nadding a fourth indicator, generality, on the side of the respondent.\nGenerality is meant to be dual to discrimination, and it is based on\ndifficulty. Namely, generality is defined as a new metric that evaluates\nwhether an agent is consistently good at easy problems and bad at difficult\nones. With the addition of generality, we see that this set of four key\nindicators can give us more insight on the results of AI benchmarks. In\nparticular, we explore two popular benchmarks in AI, the Arcade Learning\nEnvironment (Atari 2600 games) and the General Video Game AI competition. We\nprovide some guidelines to estimate and interpret these indicators for other AI\nbenchmarks and competitions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 11:26:36 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 17:31:24 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Mart\u00ednez-Plumed", "Fernando", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""]]}, {"id": "1811.08212", "submitter": "Alexandre Garcia", "authors": "Christelle Marfaing, Alexandre Garcia", "title": "Computer-Assisted Fraud Detection, From Active Learning to Reward\n  Maximization", "comments": "NeurIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of frauds in banking transactions has been recently\nstudied as a way to help the analysts finding fraudulent operations. Due to the\navailability of a human feedback, this task has been studied in the framework\nof active learning: the fraud predictor is allowed to sequentially call on an\noracle. This human intervention is used to label new examples and improve the\nclassification accuracy of the latter. Such a setting is not adapted in the\ncase of fraud detection with financial data in European countries. Actually, as\na human verification is mandatory to consider a fraud as really detected, it is\nnot necessary to focus on improving the classifier. We introduce the setting of\n'Computer-assisted fraud detection' where the goal is to minimize the number of\nnon fraudulent operations submitted to an oracle. The existing methods are\napplied to this task and we show that a simple meta-algorithm provides\ncompetitive results in this scenario on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:37:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Marfaing", "Christelle", ""], ["Garcia", "Alexandre", ""]]}, {"id": "1811.08225", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers: First Steps in Structured Evolutionary\n  Machine Learning", "comments": null, "journal-ref": "Evolutionary Intelligence 6 (2), 57-72 (2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) are evolutionary machine learning\nalgorithms, flexible enough to be applied to reinforcement, supervised and\nunsupervised learning problems with good performance. Recently, self organizing\nclassifiers were proposed which are similar to LCSs but have the advantage that\nin its structured population no balance between niching and fitness pressure is\nnecessary. However, more tests and analysis are required to verify its\nbenefits. Here, a variation of the first algorithm is proposed which uses a\nparameterless self organizing map (SOM). This algorithm is applied in\nchallenging problems such as big, noisy as well as dynamically changing\ncontinuous input-action mazes (growing and compressing mazes are included) with\ngood performance. Moreover, a genetic operator is proposed which utilizes the\ntopological information of the SOM's population structure, improving the\nresults. Thus, the first steps in structured evolutionary machine learning are\nshown, nonetheless, the problems faced are more difficult than the state-of-art\ncontinuous input-action multi-step ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:00:51 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08226", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers and Niched Fitness", "comments": "arXiv admin note: text overlap with arXiv:1811.08225", "journal-ref": "Proceedings of the 15th annual conference on Genetic and\n  evolutionary computation (GECCO 2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems are adaptive learning systems which have been\nwidely applied in a multitude of application domains. However, there are still\nsome generalization problems unsolved. The hurdle is that fitness and niching\npressures are difficult to balance. Here, a new algorithm called Self\nOrganizing Classifiers is proposed which faces this problem from a different\nperspective. Instead of balancing the pressures, both pressures are separated\nand no balance is necessary. In fact, the proposed algorithm possesses a\ndynamical population structure that self-organizes itself to better project the\ninput space into a map. The niched fitness concept is defined along with its\ndynamical population structure, both are indispensable for the understanding of\nthe proposed method. Promising results are shown on two continuous multi-step\nproblems. One of which is yet more challenging than previous problems of this\nclass in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:01:29 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08241", "submitter": "Martin  Biehl", "authors": "Martin Biehl", "title": "Geometry of Friston's active inference", "comments": "6 pages, 3 figures, Extended abstract accepted as a poster at\n  AABI2018, 1st Symposium on Advances in Approximate Bayesian Inference, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reconstruct Karl Friston's active inference and give a geometrical\ninterpretation of it.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:33:02 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Biehl", "Martin", ""]]}, {"id": "1811.08275", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari, Fatemeh Afghah, Matthew E. Taylor", "title": "Autonomous Extraction of a Hierarchical Structure of Tasks in\n  Reinforcement Learning, A Sequential Associate Rule Mining Approach", "comments": "arXiv admin note: text overlap with arXiv:1709.04579", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) techniques, while often powerful, can suffer from\nslow learning speeds, particularly in high dimensional spaces. Decomposition of\ntasks into a hierarchical structure holds the potential to significantly speed\nup learning, generalization, and transfer learning. However, the current task\ndecomposition techniques often rely on high-level knowledge provided by an\nexpert (e.g. using dynamic Bayesian networks) to extract a hierarchical task\nstructure; which is not necessarily available in autonomous systems. In this\npaper, we propose a novel method based on Sequential Association Rule Mining\nthat can extract Hierarchical Structure of Tasks in Reinforcement Learning\n(SARM-HSTRL) in an autonomous manner for both Markov decision processes (MDPs)\nand factored MDPs. The proposed method leverages association rule mining to\ndiscover the causal and temporal relationships among states in different\ntrajectories, and extracts a task hierarchy that captures these relationships\namong sub-goals as termination conditions of different sub-tasks. We prove that\nthe extracted hierarchical policy offers a hierarchically optimal policy in\nMDPs and factored MDPs. It should be noted that SARM-HSTRL extracts this\nhierarchical optimal policy without having dynamic Bayesian networks in\nscenarios with a single task trajectory and also with multiple tasks'\ntrajectories. Furthermore, it has been theoretically and empirically shown that\nthe extracted hierarchical task structure is consistent with trajectories and\nprovides the most efficient, reliable, and compact structure under appropriate\nassumptions. The numerical results compare the performance of the proposed\nSARM-HSTRL method with conventional HRL algorithms in terms of the accuracy in\ndetecting the sub-goals, the validity of the extracted hierarchies, and the\nspeed of learning in several testbeds.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 02:09:35 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Afghah", "Fatemeh", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1811.08318", "submitter": "Thommen George Karimpanal", "authors": "Thommen George Karimpanal and Roland Bouffanais", "title": "Self-Organizing Maps for Storage and Transfer of Knowledge in\n  Reinforcement Learning", "comments": "35 pages, 11 figures, Accepted in the journal Adaptive Behavior.\n  arXiv admin note: substantial text overlap with arXiv:1807.07530", "journal-ref": "Adaptive Behavior, vol. 27(2), 111-126, 2018", "doi": "10.1177/1059712318818568", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of reusing or transferring information from previously learned tasks\n(source tasks) for the learning of new tasks (target tasks) has the potential\nto significantly improve the sample efficiency of a reinforcement learning\nagent. In this work, we describe a novel approach for reusing previously\nacquired knowledge by using it to guide the exploration of an agent while it\nlearns new tasks. In order to do so, we employ a variant of the growing\nself-organizing map algorithm, which is trained using a measure of similarity\nthat is defined directly in the space of the vectorized representations of the\nvalue functions. In addition to enabling transfer across tasks, the resulting\nmap is simultaneously used to enable the efficient storage of previously\nacquired task knowledge in an adaptive and scalable manner. We empirically\nvalidate our approach in a simulated navigation environment, and also\ndemonstrate its utility through simple experiments using a mobile\nmicro-robotics platform. In addition, we demonstrate the scalability of this\napproach, and analytically examine its relation to the proposed network growth\nmechanism. Further, we briefly discuss some of the possible improvements and\nextensions to this approach, as well as its relevance to real world scenarios\nin the context of continual learning.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 07:27:21 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Karimpanal", "Thommen George", ""], ["Bouffanais", "Roland", ""]]}, {"id": "1811.08372", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Linyuan Lu, Marco Valtorta, Zhiyu Wang", "title": "On a hypergraph probabilistic graphical model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a directed acyclic hypergraph framework for a probabilistic\ngraphical model that we call Bayesian hypergraphs. The space of directed\nacyclic hypergraphs is much larger than the space of chain graphs. Hence\nBayesian hypergraphs can model much finer factorizations than Bayesian networks\nor LWF chain graphs and provide simpler and more computationally efficient\nprocedures for factorizations and interventions. Bayesian hypergraphs also\nallow a modeler to represent causal patterns of interaction such as Noisy-OR\ngraphically (without additional annotations). We introduce global, local and\npairwise Markov properties of Bayesian hypergraphs and prove under which\nconditions they are equivalent. We define a projection operator, called shadow,\nthat maps Bayesian hypergraphs to chain graphs, and show that the Markov\nproperties of a Bayesian hypergraph are equivalent to those of its\ncorresponding chain graph. We extend the causal interpretation of LWF chain\ngraphs to Bayesian hypergraphs and provide corresponding formulas and a\ngraphical criterion for intervention.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:11:47 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Lu", "Linyuan", ""], ["Valtorta", "Marco", ""], ["Wang", "Zhiyu", ""]]}, {"id": "1811.08380", "submitter": "Ke Chen", "authors": "Ke Chen, Weilin Zhang, Shlomo Dubnov, Gus Xia, Wei Li", "title": "The Effect of Explicit Structure Encoding of Deep Neural Networks for\n  Symbolic Music Generation", "comments": "8 pages, 13 figures", "journal-ref": "2019 International Workshop on Multilayer Music Representation and\n  Processing (MMRP)", "doi": "10.1109/MMRP.2019.00022", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent breakthroughs in artificial neural networks, deep generative\nmodels have become one of the leading techniques for computational creativity.\nDespite very promising progress on image and short sequence generation,\nsymbolic music generation remains a challenging problem since the structure of\ncompositions are usually complicated. In this study, we attempt to solve the\nmelody generation problem constrained by the given chord progression. This\nmusic meta-creation problem can also be incorporated into a plan recognition\nsystem with user inputs and predictive structural outputs. In particular, we\nexplore the effect of explicit architectural encoding of musical structure via\ncomparing two sequential generative models: LSTM (a type of RNN) and WaveNet\n(dilated temporal-CNN). As far as we know, this is the first study of applying\nWaveNet to symbolic music generation, as well as the first systematic\ncomparison between temporal-CNN and RNN for music generation. We conduct a\nsurvey for evaluation in our generations and implemented Variable Markov Oracle\nin music pattern discovery. Experimental results show that to encode structure\nmore explicitly using a stack of dilated convolution layers improved the\nperformance significantly, and a global encoding of underlying chord\nprogression into the generation procedure gains even more.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:35:43 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 16:53:15 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2019 12:42:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Ke", ""], ["Zhang", "Weilin", ""], ["Dubnov", "Shlomo", ""], ["Xia", "Gus", ""], ["Li", "Wei", ""]]}, {"id": "1811.08469", "submitter": "Alistair Letcher", "authors": "Alistair Letcher, Jakob Foerster, David Balduzzi, Tim Rockt\\\"aschel,\n  Shimon Whiteson", "title": "Stable Opponent Shaping in Differentiable Games", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of learning methods are actually differentiable games whose\nplayers optimise multiple, interdependent objectives in parallel -- from GANs\nand intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful\napproach to improve learning dynamics in these games, accounting for player\ninfluence on others' updates. Learning with Opponent-Learning Awareness (LOLA)\nis a recent algorithm that exploits this response and leads to cooperation in\nsettings like the Iterated Prisoner's Dilemma. Although experimentally\nsuccessful, we show that LOLA agents can exhibit 'arrogant' behaviour directly\nat odds with convergence. In fact, remarkably few algorithms have theoretical\nguarantees applying across all (n-player, non-convex) games. In this paper we\npresent Stable Opponent Shaping (SOS), a new method that interpolates between\nLOLA and a stable variant named LookAhead. We prove that LookAhead converges\nlocally to equilibria and avoids strict saddles in all differentiable games.\nSOS inherits these essential guarantees, while also shaping the learning of\nopponents and consistently either matching or outperforming LOLA\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 20:06:37 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 15:56:30 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 09:21:26 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Letcher", "Alistair", ""], ["Foerster", "Jakob", ""], ["Balduzzi", "David", ""], ["Rockt\u00e4schel", "Tim", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1811.08484", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo\n  Bremer", "title": "MimicGAN: Corruption-Mimicking for Blind Image Recovery & Adversarial\n  Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems continues to be a central challenge in computer\nvision. Existing techniques either explicitly construct an inverse mapping\nusing prior knowledge about the corruption, or learn the inverse directly using\na large collection of examples. However, in practice, the nature of corruption\nmay be unknown, and thus it is challenging to regularize the problem of\ninferring a plausible solution. On the other hand, collecting task-specific\ntraining data is tedious for known corruptions and impossible for unknown ones.\nWe present MimicGAN, an unsupervised technique to solve general inverse\nproblems based on image priors in the form of generative adversarial networks\n(GANs). Using a GAN prior, we show that one can reliably recover solutions to\nunderdetermined inverse problems through a surrogate network that learns to\nmimic the corruption at test time. Our system successively estimates the\ncorruption and the clean image without the need for supervisory training, while\noutperforming existing baselines in blind image recovery. We also demonstrate\nthat MimicGAN improves upon recent GAN-based defenses against adversarial\nattacks and represents one of the strongest test-time defenses available today.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 20:59:38 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Kailkhura", "Bhavya", ""], ["Bremer", "Timo", ""]]}, {"id": "1811.08541", "submitter": "Zhaopeng Tu", "authors": "Xiang Kong, Zhaopeng Tu, Shuming Shi, Eduard Hovy, Tong Zhang", "title": "Neural Machine Translation with Adequacy-Oriented Learning", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Neural Machine Translation (NMT) models have advanced\nstate-of-the-art performance in machine translation, they face problems like\nthe inadequate translation. We attribute this to that the standard Maximum\nLikelihood Estimation (MLE) cannot judge the real translation quality due to\nits several limitations. In this work, we propose an adequacy-oriented learning\nmechanism for NMT by casting translation as a stochastic policy in\nReinforcement Learning (RL), where the reward is estimated by explicitly\nmeasuring translation adequacy. Benefiting from the sequence-level training of\nRL strategy and a more accurate reward designed specifically for translation,\nour model outperforms multiple strong baselines, including (1) standard and\ncoverage-augmented attention models with MLE-based training, and (2) advanced\nreinforcement and adversarial training strategies with rewards based on both\nword-level BLEU and character-level chrF3. Quantitative and qualitative\nanalyses on different language pairs and NMT architectures demonstrate the\neffectiveness and universality of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 01:48:22 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Kong", "Xiang", ""], ["Tu", "Zhaopeng", ""], ["Shi", "Shuming", ""], ["Hovy", "Eduard", ""], ["Zhang", "Tong", ""]]}, {"id": "1811.08549", "submitter": "Alexander Peysakhovich", "authors": "Alexander Peysakhovich", "title": "Reinforcement Learning and Inverse Reinforcement Learning with System 1\n  and System 2", "comments": "Published in AAAI-AIES 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring a person's goal from their behavior is an important problem in\napplications of AI (e.g. automated assistants, recommender systems). The\nworkhorse model for this task is the rational actor model - this amounts to\nassuming that people have stable reward functions, discount the future\nexponentially, and construct optimal plans. Under the rational actor assumption\ntechniques such as inverse reinforcement learning (IRL) can be used to infer a\nperson's goals from their actions. A competing model is the dual-system model.\nHere decisions are the result of an interplay between a fast, automatic,\nheuristic-based system 1 and a slower, deliberate, calculating system 2. We\ngeneralize the dual system framework to the case of Markov decision problems\nand show how to compute optimal plans for dual-system agents. We show that\ndual-system agents exhibit behaviors that are incompatible with rational actor\nassumption. We show that naive applications of rational-actor IRL to the\nbehavior of dual-system agents can generate wrong inference about the agents'\ngoals and suggest interventions that actually reduce the agent's overall\nutility. Finally, we adapt a simple IRL algorithm to correctly infer the goals\nof dual system decision-makers. This allows us to make interventions that help,\nrather than hinder, the dual-system agent's ability to reach their true goals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 22:36:53 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 18:41:08 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Peysakhovich", "Alexander", ""]]}, {"id": "1811.08586", "submitter": "Changjian Li", "authors": "Changjian Li, Krzysztof Czarnecki", "title": "Urban Driving with Multi-Objective Deep Reinforcement Learning", "comments": "Accepted at AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous driving is a challenging domain that entails multiple aspects: a\nvehicle should be able to drive to its destination as fast as possible while\navoiding collision, obeying traffic rules and ensuring the comfort of\npassengers. In this paper, we present a deep learning variant of thresholded\nlexicographic Q-learning for the task of urban driving. Our multi-objective DQN\nagent learns to drive on multi-lane roads and intersections, yielding and\nchanging lanes according to traffic rules. We also propose an extension for\nfactored Markov Decision Processes to the DQN architecture that provides\nauxiliary features for the Q function. This is shown to significantly improve\ndata efficiency. We then show that the learned policy is able to zero-shot\ntransfer to a ring road without sacrificing performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 03:36:52 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 22:03:26 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Li", "Changjian", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "1811.08687", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Konark Jain, Arpit Kapoor, and Ashray Aman", "title": "Surrogate-assisted parallel tempering for Bayesian neural learning", "comments": "Engineering Applications of Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the need for robust uncertainty quantification, Bayesian neural\nlearning has gained attention in the era of deep learning and big data. Markov\nChain Monte-Carlo (MCMC) methods typically implement Bayesian inference which\nfaces several challenges given a large number of parameters, complex and\nmultimodal posterior distributions, and computational complexity of large\nneural network models. Parallel tempering MCMC addresses some of these\nlimitations given that they can sample multimodal posterior distributions and\nutilize high-performance computing. However, certain challenges remain given\nlarge neural network models and big data. Surrogate-assisted optimization\nfeatures the estimation of an objective function for models which are\ncomputationally expensive. In this paper, we address the inefficiency of\nparallel tempering MCMC for large-scale problems by combining parallel\ncomputing features with surrogate assisted likelihood estimation that describes\nthe plausibility of a model parameter value, given specific observed data.\nHence, we present surrogate-assisted parallel tempering for Bayesian neural\nlearning for simple to computationally expensive models. Our results\ndemonstrate that the methodology significantly lowers the computational cost\nwhile maintaining quality in decision making with Bayesian neural networks. The\nmethod has applications for a Bayesian inversion and uncertainty quantification\nfor a broad range of numerical models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 11:14:05 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 06:28:07 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 12:41:47 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Chandra", "Rohitash", ""], ["Jain", "Konark", ""], ["Kapoor", "Arpit", ""], ["Aman", "Ashray", ""]]}, {"id": "1811.08759", "submitter": "Sonam Damani", "authors": "Khyatti Gupta, Sonam Damani, Kedhar Nath Narahari", "title": "Using AI to Design Stone Jewelry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jewelry has been an integral part of human culture since ages. One of the\nmost popular styles of jewelry is created by putting together precious and\nsemi-precious stones in diverse patterns. While technology is finding its way\nin the production process of such jewelry, designing it remains a\ntime-consuming and involved task. In this paper, we propose a unique approach\nusing optimization methods coupled with machine learning techniques to generate\nnovel stone jewelry designs at scale. Our evaluation shows that designs\ngenerated by our approach are highly likeable and visually appealing.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 14:46:36 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gupta", "Khyatti", ""], ["Damani", "Sonam", ""], ["Narahari", "Kedhar Nath", ""]]}, {"id": "1811.08792", "submitter": "Miao Yao", "authors": "Miao Yao, Munawwar Sohul, Vuk Marojevic, Jeffrey H. Reed", "title": "Artificial Intelligence-Defined 5G Radio Access Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output antenna systems, millimeter wave\ncommunications, and ultra-dense networks have been widely perceived as the\nthree key enablers that facilitate the development and deployment of 5G\nsystems. This article discusses the intelligent agent in 5G base station which\ncombines sensing, learning, understanding and optimizing to facilitate these\nenablers. We present a flexible, rapidly deployable, and cross-layer artificial\nintelligence (AI)-based framework to enable the imminent and future demands on\n5G and beyond infrastructure. We present example AI-enabled 5G use cases that\naccommodate important 5G-specific capabilities and discuss the value of AI for\nenabling beyond 5G network evolution.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:44:10 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 17:01:03 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Yao", "Miao", ""], ["Sohul", "Munawwar", ""], ["Marojevic", "Vuk", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "1811.08853", "submitter": "Ya-Hui An", "authors": "Ya-Hui An, Liangming Pan, Min-Yen Kan, Qiang Dong, Yan Fu", "title": "Resource Mention Extraction for MOOC Discussion Forums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In discussions hosted on discussion forums for MOOCs, references to online\nlearning resources are often of central importance. They contextualize the\ndiscussion, anchoring the discussion participants' presentation of the issues\nand their understanding. However they are usually mentioned in free text,\nwithout appropriate hyperlinking to their associated resource. Automated\nlearning resource mention hyperlinking and categorization will facilitate\ndiscussion and searching within MOOC forums, and also benefit the\ncontextualization of such resources across disparate views. We propose the\nnovel problem of learning resource mention identification in MOOC forums. As\nthis is a novel task with no publicly available data, we first contribute a\nlarge-scale labeled dataset, dubbed the Forum Resource Mention (FoRM) dataset,\nto facilitate our current research and future research on this task. We then\nformulate this task as a sequence tagging problem and investigate solution\narchitectures to address the problem. Importantly, we identify two major\nchallenges that hinder the application of sequence tagging models to the task:\n(1) the diversity of resource mention expression, and (2) long-range contextual\ndependencies. We address these challenges by incorporating character-level and\nthread context information into a LSTM-CRF model. First, we incorporate a\ncharacter encoder to address the out-of-vocabulary problem caused by the\ndiversity of mention expressions. Second, to address the context dependency\nchallenge, we encode thread contexts using an RNN-based context encoder, and\napply the attention mechanism to selectively leverage useful context\ninformation during sequence tagging. Experiments on FoRM show that the proposed\nmethod improves the baseline deep sequence tagging models notably,\nsignificantly bettering performance on instances that exemplify the two\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 17:59:56 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["An", "Ya-Hui", ""], ["Pan", "Liangming", ""], ["Kan", "Min-Yen", ""], ["Dong", "Qiang", ""], ["Fu", "Yan", ""]]}, {"id": "1811.08888", "submitter": "Quanquan Gu", "authors": "Difan Zou, Yuan Cao, Dongruo Zhou, Quanquan Gu", "title": "Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU\n  Networks", "comments": "54 pages. This version relaxes the assumptions on the loss functions\n  and data distribution, and improves the dependency on the problem-specific\n  parameters in the main theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training deep neural networks with Rectified Linear\nUnit (ReLU) activation function using gradient descent and stochastic gradient\ndescent. In particular, we study the binary classification problem and show\nthat for a broad family of loss functions, with proper random weight\ninitialization, both gradient descent and stochastic gradient descent can find\nthe global minima of the training loss for an over-parameterized deep ReLU\nnetwork, under mild assumption on the training data. The key idea of our proof\nis that Gaussian random initialization followed by (stochastic) gradient\ndescent produces a sequence of iterates that stay inside a small perturbation\nregion centering around the initial weights, in which the empirical loss\nfunction of deep ReLU networks enjoys nice local curvature properties that\nensure the global convergence of (stochastic) gradient descent. Our theoretical\nresults shed light on understanding the optimization for deep learning, and\npave the way for studying the optimization dynamics of training modern deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 18:58:46 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 18:44:38 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 18:57:43 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Zou", "Difan", ""], ["Cao", "Yuan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "1811.08890", "submitter": "Nils Holzenberger", "authors": "Nils Holzenberger, Shruti Palaskar, Pranava Madhyastha, Florian Metze,\n  Raman Arora", "title": "Learning from Multiview Correlations in Open-Domain Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of datasets contain multiple views, such as video, sound\nand automatic captions. A basic challenge in representation learning is how to\nleverage multiple views to learn better representations. This is further\ncomplicated by the existence of a latent alignment between views, such as\nbetween speech and its transcription, and by the multitude of choices for the\nlearning objective. We explore an advanced, correlation-based representation\nlearning method on a 4-way parallel, multimodal dataset, and assess the quality\nof the learned representations on retrieval-based tasks. We show that the\nproposed approach produces rich representations that capture most of the\ninformation shared across views. Our best models for speech and textual\nmodalities achieve retrieval rates from 70.7% to 96.9% on open-domain,\nuser-generated instructional videos. This shows it is possible to learn\nreliable representations across disparate, unaligned and noisy modalities, and\nencourages using the proposed approach on larger datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 19:57:11 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 18:21:28 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Holzenberger", "Nils", ""], ["Palaskar", "Shruti", ""], ["Madhyastha", "Pranava", ""], ["Metze", "Florian", ""], ["Arora", "Raman", ""]]}, {"id": "1811.08955", "submitter": "Fangkai Yang", "authors": "Yuqian Jiang, Fangkai Yang, Shiqi Zhang, Peter Stone", "title": "Integrating Task-Motion Planning with Reinforcement Learning for Robust\n  Decision Making in Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-motion planning (TMP) addresses the problem of efficiently generating\nexecutable and low-cost task plans in a discrete space such that the (initially\nunknown) action costs are determined by motion plans in a corresponding\ncontinuous space. However, a task-motion plan can be sensitive to unexpected\ndomain uncertainty and changes, leading to suboptimal behaviors or execution\nfailures. In this paper, we propose a novel framework, TMP-RL, which is an\nintegration of TMP and reinforcement learning (RL) from the execution\nexperience, to solve the problem of robust task-motion planning in dynamic and\nuncertain domains. TMP-RL features two nested planning-learning loops. In the\ninner TMP loop, the robot generates a low-cost, feasible task-motion plan by\niteratively planning in the discrete space and updating relevant action costs\nevaluated by the motion planner in continuous space. In the outer loop, the\nplan is executed, and the robot learns from the execution experience via\nmodel-free RL, to further improve its task-motion plans. RL in the outer loop\nis more accurate to the current domain but also more expensive, and using less\ncostly task and motion planning leads to a jump-start for learning in the real\nworld. Our approach is evaluated on a mobile service robot conducting\nnavigation tasks in an office area. Results show that TMP-RL approach\nsignificantly improves adaptability and robustness (in comparison to TMP\nmethods) and leads to rapid convergence (in comparison to task planning (TP)-RL\nmethods). We also show that TMP-RL can reuse learned values to smoothly adapt\nto new scenarios during long-term deployments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 21:20:24 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Jiang", "Yuqian", ""], ["Yang", "Fangkai", ""], ["Zhang", "Shiqi", ""], ["Stone", "Peter", ""]]}, {"id": "1811.08973", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Gideon Mann, and David Rosenberg", "title": "Improving Grey-Box Fuzzing by Modeling Program Behavior", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grey-box fuzzers such as American Fuzzy Lop (AFL) are popular tools for\nfinding bugs and potential vulnerabilities in programs. While these fuzzers\nhave been able to find vulnerabilities in many widely used programs, they are\nnot efficient; of the millions of inputs executed by AFL in a typical fuzzing\nrun, only a handful discover unseen behavior or trigger a crash. The remaining\ninputs are redundant, exhibiting behavior that has already been observed. Here,\nwe present an approach to increase the efficiency of fuzzers like AFL by\napplying machine learning to directly model how programs behave. We learn a\nforward prediction model that maps program inputs to execution traces, training\non the thousands of inputs collected during standard fuzzing. This learned\nmodel guides exploration by focusing on fuzzing inputs on which our model is\nthe most uncertain (measured via the entropy of the predicted execution trace\ndistribution). By focusing on executing inputs our learned model is unsure\nabout, and ignoring any input whose behavior our model is certain about, we\nshow that we can significantly limit wasteful execution. Through testing our\napproach on a set of binaries released as part of the DARPA Cyber Grand\nChallenge, we show that our approach is able to find a set of inputs that\nresult in more code coverage and discovered crashes than baseline fuzzers with\nsignificantly fewer executions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 23:34:57 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Mann", "Gideon", ""], ["Rosenberg", "David", ""]]}, {"id": "1811.09026", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal and Theja Tulabandhula", "title": "Bandits with Temporal Stochastic Constraints", "comments": "An extended abstract appeared in the 4th Multi-disciplinary\n  Conference on Reinforcement Learning and Decision Making (RLDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of impairment on stochastic multi-armed bandits and\ndevelop new ways to mitigate it. Impairment effect is the phenomena where an\nagent only accrues reward for an action if they have played it at least a few\ntimes in the recent past. It is practically motivated by repetition and recency\neffects in domains such as advertising (here consumer behavior may require\nrepeat actions by advertisers) and vocational training (here actions are\ncomplex skills that can only be mastered with repetition to get a payoff).\nImpairment can be naturally modelled as a temporal constraint on the strategy\nspace, and we provide two novel algorithms that achieve sublinear regret, each\nworking with different assumptions on the impairment effect. We introduce a new\nnotion called bucketing in our algorithm design, and show how it can\neffectively address impairment as well as a broader class of temporal\nconstraints. Our regret bounds explicitly capture the cost of impairment and\nshow that it scales (sub-)linearly with the degree of impairment. Our work\ncomplements recent work on modeling delays and corruptions, and we provide\nexperimental evidence supporting our claims.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 05:40:53 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 01:24:54 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Agrawal", "Priyank", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1811.09231", "submitter": "Anas Shrinah", "authors": "Anas Shrinah, Kerstin Eder", "title": "Goal-constrained Planning Domain Model Verification of Safety Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification of planning domain models is crucial to ensure the safety,\nintegrity and correctness of planning-based automated systems. This task is\nusually performed using model checking techniques. However, unconstrained\napplication of model checkers to verify planning domain models can result in\nfalse positives, i.e.counterexamples that are unreachable by a sound planner\nwhen using the domain under verification during a planning task. In this paper,\nwe discuss the downside of unconstrained planning domain model verification. We\nthen introduce the notion of a valid planning counterexample, and demonstrate\nhow model checkers, as well as state trajectory constraints planning\ntechniques, should be used to verify planning domain models so that invalid\nplanning counterexamples are not returned.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 16:33:52 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 01:18:37 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 10:17:02 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 17:04:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shrinah", "Anas", ""], ["Eder", "Kerstin", ""]]}, {"id": "1811.09244", "submitter": "Fahdi Kanavati", "authors": "Fahdi Kanavati, Shah Islam, Eric O. Aboagye, Andrea Rockall", "title": "Automatic L3 slice detection in 3D CT images using fully-convolutional\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of single CT slices extracted at the third lumbar vertebra (L3)\nhas garnered significant clinical interest in the past few years, in particular\nin regards to quantifying sarcopenia (muscle loss). In this paper, we propose\nan efficient method to automatically detect the L3 slice in 3D CT images. Our\nmethod works with images with a variety of fields of view, occlusions, and\nslice thicknesses. 3D CT images are first converted into 2D via Maximal\nIntensity Projection (MIP), reducing the dimensionality of the problem. The MIP\nimages are then used as input to a 2D fully-convolutional network to predict\nthe L3 slice locations in the form of 2D confidence maps. In addition we\npropose a variant architecture with less parameters allowing 1D confidence map\nprediction and slightly faster prediction time without loss of accuracy.\nQuantitative evaluation of our method on a dataset of 1006 3D CT images yields\na median error of 1mm, similar to the inter-rater median error of 1mm obtained\nfrom two annotators, demonstrating the effectiveness of our method in\nefficiently and accurately detecting the L3 slice.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 17:31:18 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Kanavati", "Fahdi", ""], ["Islam", "Shah", ""], ["Aboagye", "Eric O.", ""], ["Rockall", "Andrea", ""]]}, {"id": "1811.09246", "submitter": "David Manheim", "authors": "David Manheim", "title": "Oversight of Unsafe Systems via Dynamic Safety Envelopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reviews the reasons that Human-in-the-Loop is both critical for\npreventing widely-understood failure modes for machine learning, and not a\npractical solution. Following this, we review two current heuristic methods for\naddressing this. The first is provable safety envelopes, which are possible\nonly when the dynamics of the system are fully known, but can be useful safety\nguarantees when optimal behavior is based on machine learning with\npoorly-understood safety characteristics. The second is the simpler circuit\nbreaker model, which can forestall or prevent catastrophic outcomes by stopping\nthe system, without any specific model of the system. This paper proposes using\nheuristic, dynamic safety envelopes, which are a plausible halfway point\nbetween these approaches that allows human oversight without some of the more\ndifficult problems faced by Human-in-the-Loop systems. Finally, the paper\nconcludes with how this approach can be used for governance of systems where\notherwise unsafe systems are deployed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 17:31:41 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Manheim", "David", ""]]}, {"id": "1811.09347", "submitter": "Bowen Cheng", "authors": "Bowen Cheng, Yunchao Wei, Jiahui Yu, Shiyu Chang, Jinjun Xiong,\n  Wen-Mei Hwu, Thomas S. Huang, Humphrey Shi", "title": "A Simple Non-i.i.d. Sampling Approach for Efficient Training and Better\n  Generalization", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training on samples drawn from independent and identical distribution\nhas been a de facto paradigm for optimizing image classification networks,\nhumans learn new concepts in an easy-to-hard manner and on the selected\nexamples progressively. Driven by this fact, we investigate the training\nparadigms where the samples are not drawn from independent and identical\ndistribution. We propose a data sampling strategy, named Drop-and-Refresh\n(DaR), motivated by the learning behaviors of humans that selectively drop easy\nsamples and refresh them only periodically. We show in our experiments that the\nproposed DaR strategy can maintain (and in many cases improve) the predictive\naccuracy even when the training cost is reduced by 15% on various datasets\n(CIFAR 10, CIFAR 100 and ImageNet) and with different backbone architectures\n(ResNets, DenseNets and MobileNets). Furthermore and perhaps more importantly,\nwe find the ImageNet pre-trained models using our DaR sampling strategy\nachieves better transferability for the downstream tasks including object\ndetection (+0.3 AP), instance segmentation (+0.3 AP), scene parsing (+0.5 mIoU)\nand human pose estimation (+0.6 AP). Our investigation encourages people to\nrethink the connections between the sampling strategy for training and the\ntransferability of its learned features for pre-training ImageNet models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 02:49:47 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:39:15 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Cheng", "Bowen", ""], ["Wei", "Yunchao", ""], ["Yu", "Jiahui", ""], ["Chang", "Shiyu", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-Mei", ""], ["Huang", "Thomas S.", ""], ["Shi", "Humphrey", ""]]}, {"id": "1811.09362", "submitter": "Yansen Wang", "authors": "Yansen Wang, Ying Shen, Zhun Liu, Paul Pu Liang, Amir Zadeh,\n  Louis-Philippe Morency", "title": "Words Can Shift: Dynamically Adjusting Word Representations Using\n  Nonverbal Behaviors", "comments": "Accepted by AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans convey their intentions through the usage of both verbal and nonverbal\nbehaviors during face-to-face communication. Speaker intentions often vary\ndynamically depending on different nonverbal contexts, such as vocal patterns\nand facial expressions. As a result, when modeling human language, it is\nessential to not only consider the literal meaning of the words but also the\nnonverbal contexts in which these words appear. To better model human language,\nwe first model expressive nonverbal representations by analyzing the\nfine-grained visual and acoustic patterns that occur during word segments. In\naddition, we seek to capture the dynamic nature of nonverbal intents by\nshifting word representations based on the accompanying nonverbal behaviors. To\nthis end, we propose the Recurrent Attended Variation Embedding Network (RAVEN)\nthat models the fine-grained structure of nonverbal subword sequences and\ndynamically shifts word representations based on nonverbal cues. Our proposed\nmodel achieves competitive performance on two publicly available datasets for\nmultimodal sentiment analysis and emotion recognition. We also visualize the\nshifted word representations in different nonverbal contexts and summarize\ncommon patterns regarding multimodal variations of word representations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 05:13:38 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 03:28:36 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Wang", "Yansen", ""], ["Shen", "Ying", ""], ["Liu", "Zhun", ""], ["Liang", "Paul Pu", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1811.09429", "submitter": "Lars Jaffke", "authors": "Michael R. Fellows, Lars Jaffke, Aliz Izabella Kir\\'aly, Frances A.\n  Rosamond, and Mathias Weller", "title": "What is known about Vertex Cover Kernelization?", "comments": "25 pages, 10 figures. Appeared in volume 11011 of LNCS, pages\n  330-356, see Reference [29] in the text. Compared to [29], this arXiv-upload\n  contains a fixed version of Reduction R.8, the order of presentation of\n  Reductions R.6 and R.7 has been switched, and a few observations have been\n  added in Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are pleased to dedicate this survey on kernelization of the Vertex Cover\nproblem, to Professor Juraj Hromkovi\\v{c} on the occasion of his 60th birthday.\nThe Vertex Cover problem is often referred to as the Drosophila of\nparameterized complexity. It enjoys a long history. New and worthy perspectives\nwill always be demonstrated first with concrete results here. This survey\ndiscusses several research directions in Vertex Cover kernelization. The\nBarrier Degree of Vertex Cover kernelization is discussed. We have reduction\nrules that kernelize vertices of small degree, including in this paper new\nresults that reduce graphs almost to minimum degree five. Can this process go\non forever? What is the minimum vertex-degree barrier for polynomial-time\nkernelization? Assuming the Exponential-Time Hypothesis, there is a minimum\ndegree barrier. The idea of automated kernelization is discussed. We here\nreport the first experimental results of an AI-guided branching algorithm for\nVertex Cover whose logic seems amenable for application in finding reduction\nrules to kernelize small-degree vertices. The survey highlights a central open\nproblem in parameterized complexity. Happy Birthday, Juraj!\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 11:13:10 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 08:58:33 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2019 08:15:14 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 01:16:22 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Fellows", "Michael R.", ""], ["Jaffke", "Lars", ""], ["Kir\u00e1ly", "Aliz Izabella", ""], ["Rosamond", "Frances A.", ""], ["Weller", "Mathias", ""]]}, {"id": "1811.09435", "submitter": "Petr Savick\\'y", "authors": "Petr Ku\\v{c}era, Petr Savick\\'y", "title": "Backdoor Decomposable Monotone Circuits and their Propagation Complete\n  Encodings", "comments": "The paper was significantly rewritten to improve readability, it is\n  now an extended version of the paper accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a compilation language of backdoor decomposable monotone circuits\n(BDMCs) which generalizes several concepts appearing in the literature, e.g.\nDNNFs and backdoor trees. A $\\mathcal{C}$-BDMC sentence is a monotone circuit\nwhich satisfies decomposability property (such as in DNNF) in which the inputs\n(or leaves) are associated with CNF encodings from a given base class\n$\\mathcal{C}$. We consider the class of propagation complete (PC) encodings as\na base class and we show that PC-BDMCs are polynomially equivalent to PC\nencodings. Additionally, we use this to determine the properties of PC-BDMCs\nand PC encodings with respect to the knowledge compilation map including the\nlist of efficient operations on the languages.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 11:31:29 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 13:18:12 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 22:11:43 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 22:42:13 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Ku\u010dera", "Petr", ""], ["Savick\u00fd", "Petr", ""]]}, {"id": "1811.09491", "submitter": "Quanming Yao", "authors": "Quanming Yao, Xiawei Guo, James T. Kwok, WeiWei Tu, Yuqiang Chen,\n  Wenyuan Dai, Qiang Yang", "title": "Differential Private Stack Generalization with an Application to\n  Diabetes Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the standard of differential privacy, noise is usually added into the\noriginal data, which inevitably deteriorates the predicting performance of\nsubsequent learning algorithms. In this paper, motivated by the success of\nimproving predicting performance by ensemble learning, we propose to enhance\nprivacy-preserving logistic regression by stacking. We show that this can be\ndone either by sample-based or feature-based partitioning. However, we prove\nthat when privacy-budgets are the same, feature-based partitioning requires\nfewer samples than sample-based one, and thus likely has better empirical\nperformance. As transfer learning is difficult to be integrated with a\ndifferential privacy guarantee, we further combine the proposed method with\nhypothesis transfer learning to address the problem of learning across\ndifferent organizations. Finally, we not only demonstrate the effectiveness of\nour method on two benchmark data sets, i.e., MNIST and NEWS20, but also apply\nit into a real application of cross-organizational diabetes prediction from\nRUIJIN data set, where privacy is of significant concern.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 14:26:03 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 16:17:41 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 06:57:25 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yao", "Quanming", ""], ["Guo", "Xiawei", ""], ["Kwok", "James T.", ""], ["Tu", "WeiWei", ""], ["Chen", "Yuqiang", ""], ["Dai", "Wenyuan", ""], ["Yang", "Qiang", ""]]}, {"id": "1811.09529", "submitter": "Agnieszka Lawrynowicz", "authors": "Dawid Wisniewski, Jedrzej Potoniec, Agnieszka Lawrynowicz, C. Maria\n  Keet", "title": "Competency Questions and SPARQL-OWL Queries Dataset and Analysis", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competency Questions (CQs) are natural language questions outlining and\nconstraining the scope of knowledge represented by an ontology. Despite that\nCQs are a part of several ontology engineering methodologies, we have observed\nthat the actual publication of CQs for the available ontologies is very limited\nand even scarcer is the publication of their respective formalisations in terms\nof, e.g., SPARQL queries. This paper aims to contribute to addressing the\nengineering shortcomings of using CQs in ontology development, to facilitate\nwider use of CQs. In order to understand the relation between CQs and the\nqueries over the ontology to test the CQs on an ontology, we gather, analyse,\nand publicly release a set of 234 CQs and their translations to SPARQL-OWL for\nseveral ontologies in different domains developed by different groups. We\nanalysed the CQs in two principal ways. The first stage focused on a linguistic\nanalysis of the natural language text itself, i.e., a lexico-syntactic analysis\nwithout any presuppositions of ontology elements, and a subsequent step of\nsemantic analysis in order to find patterns. This increased diversity of CQ\nsources resulted in a 5-fold increase of hitherto published patterns, to 106\ndistinct CQ patterns, which have a limited subset of few patterns shared across\nthe CQ sets from the different ontologies. Next, we analysed the relation\nbetween the found CQ patterns and the 46 SPARQL-OWL query signatures, which\nrevealed that one CQ pattern may be realised by more than one SPARQL-OWL query\nsignature, and vice versa. We hope that our work will contribute to\nestablishing common practices, templates, automation, and user tools that will\nsupport CQ formulation, formalisation, execution, and general management.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:00:51 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wisniewski", "Dawid", ""], ["Potoniec", "Jedrzej", ""], ["Lawrynowicz", "Agnieszka", ""], ["Keet", "C. Maria", ""]]}, {"id": "1811.09556", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Karol Gregor, Timothy Lillicrap", "title": "Learning Attractor Dynamics for Generative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge faced by memory systems is the robust retrieval of a\nstored pattern in the presence of interference due to other stored patterns and\nnoise. A theoretically well-founded solution to robust retrieval is given by\nattractor dynamics, which iteratively clean up patterns during recall. However,\nincorporating attractor dynamics into modern deep learning systems poses\ndifficulties: attractor basins are characterised by vanishing gradients, which\nare known to make training neural networks difficult. In this work, we avoid\nthe vanishing gradient problem by training a generative distributed memory\nwithout simulating the attractor dynamics. Based on the idea of memory writing\nas inference, as proposed in the Kanerva Machine, we show that a\nlikelihood-based Lyapunov function emerges from maximising the variational\nlower-bound of a generative memory. Experiments shows it converges to correct\npatterns upon iterative retrieval and achieves competitive performance as both\na memory model and a generative model.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:49:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Gregor", "Karol", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1811.09558", "submitter": "Zi Wang", "authors": "Zi Wang and Beomjoon Kim and Leslie Pack Kaelbling", "title": "Regret bounds for meta Bayesian optimization with an unknown Gaussian\n  process prior", "comments": "Proceedings of the Thirty-second Conference on Neural Information\n  Processing Systems, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization usually assumes that a Bayesian prior is given.\nHowever, the strong theoretical guarantees in Bayesian optimization are often\nregrettably compromised in practice because of unknown parameters in the prior.\nIn this paper, we adopt a variant of empirical Bayes and show that, by\nestimating the Gaussian process prior from offline data sampled from the same\nprior and constructing unbiased estimators of the posterior, variants of both\nGP-UCB and probability of improvement achieve a near-zero regret bound, which\ndecreases to a constant proportional to the observational noise as the number\nof offline data and the number of online evaluations increase. Empirically, we\nhave verified our approach on challenging simulated robotic problems featuring\ntask and motion planning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 16:54:45 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wang", "Zi", ""], ["Kim", "Beomjoon", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1811.09595", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Xiao Lin, Mohamed R. Amer, Graham W. Taylor", "title": "Spectral Multigraph Networks for Discovering and Fusing Relationships in\n  Molecules", "comments": "11 pages, 5 figures, NIPS 2018 Workshop on Machine Learning for\n  Molecules and Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Graph Convolutional Networks (GCNs) are a generalization of\nconvolutional networks to learning on graph-structured data. Applications of\nspectral GCNs have been successful, but limited to a few problems where the\ngraph is fixed, such as shape correspondence and node classification. In this\nwork, we address this limitation by revisiting a particular family of spectral\ngraph networks, Chebyshev GCNs, showing its efficacy in solving graph\nclassification tasks with a variable graph structure and size. Chebyshev GCNs\nrestrict graphs to have at most one edge between any pair of nodes. To this\nend, we propose a novel multigraph network that learns from multi-relational\ngraphs. We model learned edges with abstract meaning and experiment with\ndifferent ways to fuse the representations extracted from annotated and learned\nedges, achieving competitive results on a variety of chemical classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:46:59 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Knyazev", "Boris", ""], ["Lin", "Xiao", ""], ["Amer", "Mohamed R.", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1811.09602", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Matthieu Komorowski, Sumeetpal Singh", "title": "Model-Based Reinforcement Learning for Sepsis Treatment", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "Report number: ML4H/2018/41", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a dangerous condition that is a leading cause of patient mortality.\nTreating sepsis is highly challenging, because individual patients respond very\ndifferently to medical interventions and there is no universally agreed-upon\ntreatment for sepsis. In this work, we explore the use of continuous\nstate-space model-based reinforcement learning (RL) to discover high-quality\ntreatment policies for sepsis patients. Our quantitative evaluation reveals\nthat by blending the treatment strategy discovered with RL with what clinicians\nfollow, we can obtain improved policies, potentially allowing for better\nmedical treatment for sepsis.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:57:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Komorowski", "Matthieu", ""], ["Singh", "Sumeetpal", ""]]}, {"id": "1811.09656", "submitter": "Josh Merel", "authors": "Josh Merel, Arun Ahuja, Vu Pham, Saran Tunyasuvunakool, Siqi Liu,\n  Dhruva Tirumala, Nicolas Heess, Greg Wayne", "title": "Hierarchical visuomotor control of humanoids", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to build complex humanoid agents that integrate perception, motor\ncontrol, and memory. In this work, we partly factor this problem into low-level\nmotor control from proprioception and high-level coordination of the low-level\nskills informed by vision. We develop an architecture capable of surprisingly\nflexible, task-directed motor control of a relatively high-DoF humanoid body by\ncombining pre-training of low-level motor controllers with a high-level,\ntask-focused controller that switches among low-level sub-policies. The\nresulting system is able to control a physically-simulated humanoid body to\nsolve tasks that require coupling visual perception from an unstabilized\negocentric RGB camera during locomotion in the environment. For a supplementary\nvideo link, see https://youtu.be/7GISvfbykLE .\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 19:55:55 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 17:28:36 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Merel", "Josh", ""], ["Ahuja", "Arun", ""], ["Pham", "Vu", ""], ["Tunyasuvunakool", "Saran", ""], ["Liu", "Siqi", ""], ["Tirumala", "Dhruva", ""], ["Heess", "Nicolas", ""], ["Wayne", "Greg", ""]]}, {"id": "1811.09714", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Arturas Grauslys, Pietro Li\\`o, Francesco\n  Falciani", "title": "Structure-Based Networks for Drug Validation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/89", "categories": "q-bio.QM cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying chemicals according to putative modes of action (MOAs) is of\nparamount importance in the context of risk assessment. However, current\nmethods are only able to handle a very small proportion of the existing\nchemicals. We address this issue by proposing an integrative deep learning\narchitecture that learns a joint representation from molecular structures of\ndrugs and their effects on human cells. Our choice of architecture is motivated\nby the significant influence of a drug's chemical structure on its MOA. We\nimprove on the strong ability of a unimodal architecture (F1 score of 0.803) to\nclassify drugs by their toxic MOAs (Verhaar scheme) through adding another\nlearning stream that processes transcriptional responses of human cells\naffected by drugs. Our integrative model achieves an even higher classification\nperformance on the LINCS L1000 dataset - the error is reduced by 4.6%. We\nbelieve that our method can be used to extend the current Verhaar scheme and\nconstitute a basis for fast drug validation and risk assessment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 12:39:19 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Grauslys", "Arturas", ""], ["Li\u00f2", "Pietro", ""], ["Falciani", "Francesco", ""]]}, {"id": "1811.09722", "submitter": "Tathagata Chakraborti", "authors": "Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreedharan, David E.\n  Smith, Subbarao Kambhampati", "title": "Explicability? Legibility? Predictability? Transparency? Privacy?\n  Security? The Emerging Landscape of Interpretable Agent Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant interest of late in generating behavior of agents\nthat is interpretable to the human (observer) in the loop. However, the work in\nthis area has typically lacked coherence on the topic, with proposed solutions\nfor \"explicable\", \"legible\", \"predictable\" and \"transparent\" planning with\noverlapping, and sometimes conflicting, semantics all aimed at some notion of\nunderstanding what intentions the observer will ascribe to an agent by\nobserving its behavior. This is also true for the recent works on \"security\"\nand \"privacy\" of plans which are also trying to answer the same question, but\nfrom the opposite point of view -- i.e. when the agent is trying to hide\ninstead of revealing its intentions. This paper attempts to provide a workable\ntaxonomy of relevant concepts in this exciting and emerging field of inquiry.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 22:38:49 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Kulkarni", "Anagha", ""], ["Sreedharan", "Sarath", ""], ["Smith", "David E.", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1811.09740", "submitter": "Zhiting Hu", "authors": "Bowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Eric Xing", "title": "Connecting the Dots Between MLE and RL for Sequence Prediction", "comments": "Major revision. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence prediction models can be learned from example sequences with a\nvariety of training algorithms. Maximum likelihood learning is simple and\nefficient, yet can suffer from compounding error at test time. Reinforcement\nlearning such as policy gradient addresses the issue but can have prohibitively\npoor exploration efficiency. A rich set of other algorithms such as RAML, SPG,\nand data noising, have also been developed from different perspectives. This\npaper establishes a formal connection between these algorithms. We present a\ngeneralized entropy regularized policy optimization formulation, and show that\nthe apparently distinct algorithms can all be reformulated as special instances\nof the framework, with the only difference being the configurations of a reward\nfunction and a couple of hyperparameters. The unified interpretation offers a\nsystematic view of the varying properties of exploration and learning\nefficiency. Besides, inspired from the framework, we present a new algorithm\nthat dynamically interpolates among the family of algorithms for scheduled\nsequence model learning. Experiments on machine translation, text\nsummarization, and game imitation learning demonstrate the superiority of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 01:33:39 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:44:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Tan", "Bowen", ""], ["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric", ""]]}, {"id": "1811.09766", "submitter": "Rim Assouel", "authors": "Rim Assouel, Mohamed Ahmed, Marwin H Segler, Amir Saffari, Yoshua\n  Bengio", "title": "DEFactor: Differentiable Edge Factorization-based Probabilistic Graph\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating novel molecules with optimal properties is a crucial step in many\nindustries such as drug discovery. Recently, deep generative models have shown\na promising way of performing de-novo molecular design. Although graph\ngenerative models are currently available they either have a graph size\ndependency in their number of parameters, limiting their use to only very small\ngraphs or are formulated as a sequence of discrete actions needed to construct\na graph, making the output graph non-differentiable w.r.t the model parameters,\ntherefore preventing them to be used in scenarios such as conditional graph\ngeneration. In this work we propose a model for conditional graph generation\nthat is computationally efficient and enables direct optimisation of the graph.\nWe demonstrate favourable performance of our model on prototype-based molecular\ngraph conditional generation tasks.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 05:23:39 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Assouel", "Rim", ""], ["Ahmed", "Mohamed", ""], ["Segler", "Marwin H", ""], ["Saffari", "Amir", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1811.09782", "submitter": "Sabri Boughorbel", "authors": "Sabri Boughorbel, Fethi Jarray, Neethu Venugopal, Haithum Elhadi", "title": "Alternating Loss Correction for Preterm-Birth Prediction from EHR Data\n  with Noisy Labels", "comments": "Submission Id: 79, Machine Learning for Health (ML4H) Workshop at\n  NeurIPS 2018 arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/79", "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are interested in the prediction of preterm birth based on\ndiagnosis codes from longitudinal EHR. We formulate the prediction problem as a\nsupervised classification with noisy labels. Our base classifier is a Recurrent\nNeural Network with an attention mechanism. We assume the availability of a\ndata subset with both noisy and clean labels. For the cohort definition, most\nof the diagnosis codes on mothers' records related to pregnancy are ambiguous\nfor the definition of full-term and preterm classes. On the other hand,\ndiagnosis codes on babies' records provide fine-grained information on\nprematurity. Due to data de-identification, the links between mothers and\nbabies are not available. We developed a heuristic based on admission and\ndischarge times to match babies to their mothers and hence enrich mothers'\nrecords with additional information on delivery status. The obtained additional\ndataset from the matching heuristic has noisy labels and was used to leverage\nthe training of the deep learning model. We propose an Alternating Loss\nCorrection (ALC) method to train deep models with both clean and noisy labels.\nFirst, the label corruption matrix is estimated using the data subset with both\nnoisy and clean labels. Then it is used in the model as a dense output layer to\ncorrect for the label noise. The network is alternately trained on epochs with\nthe clean dataset with a simple cross-entropy loss and on next epoch with the\nnoisy dataset and a loss corrected with the estimated corruption matrix. The\nexperiments for the prediction of preterm birth at 90 days before delivery\nshowed an improvement in performance compared with baseline and state\nof-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 07:47:01 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Boughorbel", "Sabri", ""], ["Jarray", "Fethi", ""], ["Venugopal", "Neethu", ""], ["Elhadi", "Haithum", ""]]}, {"id": "1811.09786", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Recurrently Controlled Recurrent Networks", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) such as long short-term memory and gated\nrecurrent units are pivotal building blocks across a broad spectrum of sequence\nmodeling problems. This paper proposes a recurrently controlled recurrent\nnetwork (RCRN) for expressive and powerful sequence encoding. More concretely,\nthe key idea behind our approach is to learn the recurrent gating functions\nusing recurrent networks. Our architecture is split into two components - a\ncontroller cell and a listener cell whereby the recurrent controller actively\ninfluences the compositionality of the listener cell. We conduct extensive\nexperiments on a myriad of tasks in the NLP domain such as sentiment analysis\n(SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment\nclassification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading\ncomprehension (NarrativeQA). Across all 26 datasets, our results demonstrate\nthat RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs,\nsuggesting that our controller architecture might be a suitable replacement for\nthe widely adopted stacked architecture.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 08:15:50 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1811.09813", "submitter": "Aditya Grover", "authors": "Aditya Grover, Tudor Achim, Stefano Ermon", "title": "Streamlining Variational Inference for Constraint Satisfaction Problems", "comments": "NeurIPS 2018", "journal-ref": null, "doi": "10.1088/1742-5468/ab371f", "report-no": null, "categories": "cs.AI cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several algorithms for solving constraint satisfaction problems are based on\nsurvey propagation, a variational inference scheme used to obtain approximate\nmarginal probability estimates for variable assignments. These marginals\ncorrespond to how frequently each variable is set to true among satisfying\nassignments, and are used to inform branching decisions during search; however,\nmarginal estimates obtained via survey propagation are approximate and can be\nself-contradictory. We introduce a more general branching strategy based on\nstreamlining constraints, which sidestep hard assignments to variables. We show\nthat streamlined solvers consistently outperform decimation-based solvers on\nrandom k-SAT instances for several problem sizes, shrinking the gap between\nempirical performance and theoretical limits of satisfiability by 16.3% on\naverage for k=3,4,5,6.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 11:08:14 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Grover", "Aditya", ""], ["Achim", "Tudor", ""], ["Ermon", "Stefano", ""]]}, {"id": "1811.09864", "submitter": "Tao Chen", "authors": "Tao Chen, Adithyavairavan Murali, Abhinav Gupta", "title": "Hardware Conditioned Policies for Multi-Robot Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning could be used to learn dexterous robotic policies\nbut it is challenging to transfer them to new robots with vastly different\nhardware properties. It is also prohibitively expensive to learn a new policy\nfrom scratch for each robot hardware due to the high sample complexity of\nmodern state-of-the-art algorithms. We propose a novel approach called\n\\textit{Hardware Conditioned Policies} where we train a universal policy\nconditioned on a vector representation of robot hardware. We considered robots\nin simulation with varied dynamics, kinematic structure, kinematic lengths and\ndegrees-of-freedom. First, we use the kinematic structure directly as the\nhardware encoding and show great zero-shot transfer to completely novel robots\nnot seen during training. For robots with lower zero-shot success rate, we also\ndemonstrate that fine-tuning the policy network is significantly more\nsample-efficient than training a model from scratch. In tasks where knowing the\nagent dynamics is important for success, we learn an embedding for robot\nhardware and show that policies conditioned on the encoding of hardware tend to\ngeneralize and transfer well. The code and videos are available on the project\nwebpage: https://sites.google.com/view/robot-transfer-hcp.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 17:29:11 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2019 03:19:49 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Chen", "Tao", ""], ["Murali", "Adithyavairavan", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1811.09900", "submitter": "Sriram Gopalakrishnan", "authors": "Sriram Gopalakrishnan, Subbarao Kambhampati", "title": "TGE-viz : Transition Graph Embedding for Visualization of Plan Traces\n  and Domains", "comments": "Supplemental material follows the references of the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work for plan trace visualization in automated planning uses\npipeline-style visualizations, similar to plans in Gantt charts. Such\nvisualization do not capture the domain structure or dependencies between the\nvarious fluents and actions. Additionally, plan traces in such visualizations\ncannot be easily compared with one another without parsing the details of\nindividual actions, which imposes a higher cognitive load. We introduce\nTGE-viz, a technique to visualize plan traces within an embedding of the entire\ntransition graph of a domain in low dimensional space. TGE-viz allows users to\nvisualize and criticize plans more intuitively for mixed-initiative planning.\nIt also allows users to visually appraise the structure of domains and the\ndependencies in it.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 21:27:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Gopalakrishnan", "Sriram", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1811.09914", "submitter": "Aaron Huang", "authors": "Aaron Huang, Benjamin J. Ayton, Brian C. Williams", "title": "RADMPC: A Fast Decentralized Approach for Chance-Constrained\n  Multi-Vehicle Path-Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust multi-vehicle path-planning is important for ensuring the safety of\nmulti-vehicle systems in applications like transportation, search and rescue,\nand robotic exploration. Chance-constrained methods like Iterative Risk\nAllocation (IRA)\\cite{IRA} have been developed for situations where\nenvironmental disturbances are unbounded. However, chance-constrained methods\nfor the multi-vehicle case generally use centralized strategies where the\nvehicle set is planned with couplings between all vehicle pairs. This approach\nis intractable as fleet size increases because computation time is exponential\nwith respect to the number of vehicles being planned over due to a polynomial\nincrease in coupling constraints between vehicle pairs. We present a faster\napproach for chance-constrained multi-vehicle path-planning that relies upon a\ndecentralized path-planning method called Risk-Aware Decentralized Model\nPredictive Control (RADMPC) to rapidly approximate a centralized IRA approach.\nThe RADMPC approximation is evaluated for vehicle interactions to determine the\nvehicle sets that should be planned in a coupled manner. Applying IRA to the\nsmaller vehicle sets determined from the RADMPC approximation rapidly plans\nsafe paths for the entire fleet. A Monte Carlo simulation analysis demonstrates\nthe correctness of our approach and a significant improvement in computation\ntime compared to a centralized IRA approach.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 00:43:32 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Huang", "Aaron", ""], ["Ayton", "Benjamin J.", ""], ["Williams", "Brian C.", ""]]}, {"id": "1811.09920", "submitter": "Bo Zhang", "authors": "Bo Zhang, Bin Chen, Jinyu Yang, Wenjing Yang, Jiankang Zhang", "title": "An Unified Intelligence-Communication Model for Multi-Agent System\n  Part-I: Overview", "comments": "12 pages, 5 figures, submitted for publications in IEEE Journals\n  Interactive Vesion @ https://uicm-mas.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Motivated by Shannon's model and recent rehabilitation of self-supervised\nartificial intelligence having a \"World Model\", this paper propose an unified\nintelligence-communication (UIC) model for describing a single agent and any\nmulti-agent system.\n  Firstly, the environment is modelled as the generic communication channel\nbetween agents. Secondly, the UIC model adopts a learning-agent model for\nunifying several well-adopted agent architecture, e.g. rule-based agent model\nin complex adaptive systems, layered model for describing human-level\nintelligence, world-model based agent model. The model may also provide an\nunified approach to investigate a multi-agent system (MAS) having multiple\naction-perception modalities, e.g. explicitly information transfer and implicit\ninformation transfer.\n  This treatise would be divided into three parts, and this first part provides\nan overview of the UIC model without introducing cumbersome mathematical\nanalysis and optimizations. In the second part of this treatise, case studies\nwith quantitative analysis driven by the UIC model would be provided,\nexemplifying the adoption of the UIC model in multi-agent system. Specifically,\ntwo representative cases would be studied, namely the analysis of a natural\nmulti-agent system, as well as the co-design of communication, perception and\naction in an artificial multi-agent system. In the third part of this treatise,\nthe paper provides further insights and future research directions motivated by\nthe UIC model, such as unification of single intelligence and collective\nintelligence, a possible explanation of intelligence emergence and a dual model\nfor agent-environment intelligence hypothesis.\n  Notes: This paper is a Previewed Version, the extended full-version would be\nreleased after being accepted.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 01:31:38 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Zhang", "Bo", ""], ["Chen", "Bin", ""], ["Yang", "Jinyu", ""], ["Yang", "Wenjing", ""], ["Zhang", "Jiankang", ""]]}, {"id": "1811.09960", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, Michael Osborne and Stephen Roberts", "title": "Intersectionality: Multiple Group Fairness in Expectation Constraints", "comments": "NeurIPS (previously NIPS) 2018, Workshop on Ethical, Social and\n  Governance Issues in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness is an important concern for machine learning researchers,\ndevelopers, and regulators. However, the strictness to which models must be\nconstrained to be considered fair is still under debate. The focus of this work\nis on constraining the expected outcome of subpopulations in kernel regression\nand, in particular, decision tree regression, with application to random\nforests, boosted trees and other ensemble models. While individual constraints\nwere previously addressed, this work addresses concerns about incorporating\nmultiple constraints simultaneously. The proposed solution does not affect the\norder of computational or memory complexity of the decision trees and is easily\nintegrated into models post training.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 06:31:13 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1811.10092", "submitter": "Xin Wang", "authors": "Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen,\n  Yuan-Fang Wang, William Yang Wang, Lei Zhang", "title": "Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning\n  for Vision-Language Navigation", "comments": "CVPR 2019 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-language navigation (VLN) is the task of navigating an embodied agent\nto carry out natural language instructions inside real 3D environments. In this\npaper, we study how to address three critical challenges for this task: the\ncross-modal grounding, the ill-posed feedback, and the generalization problems.\nFirst, we propose a novel Reinforced Cross-Modal Matching (RCM) approach that\nenforces cross-modal grounding both locally and globally via reinforcement\nlearning (RL). Particularly, a matching critic is used to provide an intrinsic\nreward to encourage global matching between instructions and trajectories, and\na reasoning navigator is employed to perform cross-modal grounding in the local\nvisual scene. Evaluation on a VLN benchmark dataset shows that our RCM model\nsignificantly outperforms previous methods by 10% on SPL and achieves the new\nstate-of-the-art performance. To improve the generalizability of the learned\npolicy, we further introduce a Self-Supervised Imitation Learning (SIL) method\nto explore unseen environments by imitating its own past, good decisions. We\ndemonstrate that SIL can approximate a better and more efficient policy, which\ntremendously minimizes the success rate performance gap between seen and unseen\nenvironments (from 30.7% to 11.7%).\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 20:49:58 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 05:43:50 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Wang", "Xin", ""], ["Huang", "Qiuyuan", ""], ["Celikyilmaz", "Asli", ""], ["Gao", "Jianfeng", ""], ["Shen", "Dinghan", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""], ["Zhang", "Lei", ""]]}, {"id": "1811.10097", "submitter": "Johanna Hansen", "authors": "Johanna Hansen, Kyle Kastner, Aaron Courville, Gregory Dudek", "title": "Planning in Dynamic Environments with Conditional Autoregressive Models", "comments": "6 pages, 1 figure, in Proceedings of the Prediction and Generative\n  Modeling in Reinforcement Learning Workshop at the International Conference\n  on Machine Learning (ICML) in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate the use of conditional autoregressive generative models (van\nden Oord et al., 2016a) over a discrete latent space (van den Oord et al.,\n2017b) for forward planning with MCTS. In order to test this method, we\nintroduce a new environment featuring varying difficulty levels, along with\nmoving goals and obstacles. The combination of high-quality frame generation\nand classical planning approaches nearly matches true environment performance\nfor our task, demonstrating the usefulness of this method for model-based\nplanning in dynamic environments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 21:10:10 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Hansen", "Johanna", ""], ["Kastner", "Kyle", ""], ["Courville", "Aaron", ""], ["Dudek", "Gregory", ""]]}, {"id": "1811.10104", "submitter": "Ben Hutchinson", "authors": "Ben Hutchinson and Margaret Mitchell", "title": "50 Years of Test (Un)fairness: Lessons for Machine Learning", "comments": "FAT* '19: Conference on Fairness, Accountability, and Transparency\n  (FAT* '19), January 29--31, 2019, Atlanta, GA, USA", "journal-ref": null, "doi": "10.1145/3287560.3287600", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative definitions of what is unfair and what is fair have been\nintroduced in multiple disciplines for well over 50 years, including in\neducation, hiring, and machine learning. We trace how the notion of fairness\nhas been defined within the testing communities of education and hiring over\nthe past half century, exploring the cultural and social context in which\ndifferent fairness definitions have emerged. In some cases, earlier definitions\nof fairness are similar or identical to definitions of fairness in current\nmachine learning research, and foreshadow current formal work. In other cases,\ninsights into what fairness means and how to measure it have largely gone\noverlooked. We compare past and current notions of fairness along several\ndimensions, including the fairness criteria, the focus of the criteria (e.g., a\ntest, a model, or its use), the relationship of fairness to individuals,\ngroups, and subgroups, and the mathematical method for measuring fairness\n(e.g., classification, regression). This work points the way towards future\nresearch and measurement of (un)fairness that builds from our modern\nunderstanding of fairness while incorporating insights from the past.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 21:48:19 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 23:18:49 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hutchinson", "Ben", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1811.10120", "submitter": "Martin Weiss", "authors": "Martin Weiss, Margaux Luck, Roger Girgis, Chris Pal, Joseph Paul Cohen", "title": "A Survey of Mobile Computing for the Visually Impaired", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of visually impaired or blind (VIB) people in the world is\nestimated at several hundred million. Based on a series of interviews with the\nVIB and developers of assistive technology, this paper provides a survey of\nmachine-learning based mobile applications and identifies the most relevant\napplications. We discuss the functionality of these apps, how they align with\nthe needs and requirements of the VIB users, and how they can be improved with\ntechniques such as federated learning and model compression. As a result of\nthis study we identify promising future directions of research in mobile\nperception, micro-navigation, and content-summarization.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:58:42 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 19:02:35 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Weiss", "Martin", ""], ["Luck", "Margaux", ""], ["Girgis", "Roger", ""], ["Pal", "Chris", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "1811.10144", "submitter": "Yang Fu", "authors": "Yang Fu, Yunchao Wei, Guanshuo Wang, Yuqian Zhou, Honghui Shi, Thomas\n  Huang", "title": "Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation\n  Approach for Person Re-identification", "comments": "This work has been accepted as an Oral presentation at ICCV2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in person re-identification (re-ID) has always been a\nchallenging task. In this work, we explore how to harness the natural similar\ncharacteristics existing in the samples from the target domain for learning to\nconduct person re-ID in an unsupervised manner. Concretely, we propose a\nSelf-similarity Grouping (SSG) approach, which exploits the potential\nsimilarity (from global body to local parts) of unlabeled samples to\nautomatically build multiple clusters from different views. These independent\nclusters are then assigned with labels, which serve as the pseudo identities to\nsupervise the training process. We repeatedly and alternatively conduct such a\ngrouping and training process until the model is stable. Despite the apparent\nsimplify, our SSG outperforms the state-of-the-arts by more than 4.6% (DukeMTMC\nto Market1501) and 4.4% (Market1501 to DukeMTMC) in mAP, respectively. Upon our\nSSG, we further introduce a clustering-guided semisupervised approach named SSG\n++ to conduct the one-shot domain adaption in an open set setting (i.e. the\nnumber of independent identities from the target domain is unknown). Without\nspending much effort on labeling, our SSG ++ can further promote the mAP upon\nSSG by 10.7% and 6.9%, respectively. Our Code is available at:\nhttps://github.com/OasisYang/SSG .\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 02:17:17 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 21:34:49 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 03:43:29 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Fu", "Yang", ""], ["Wei", "Yunchao", ""], ["Wang", "Guanshuo", ""], ["Zhou", "Yuqian", ""], ["Shi", "Honghui", ""], ["Huang", "Thomas", ""]]}, {"id": "1811.10146", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu", "title": "Frequency Principle in Deep Learning with General Loss Functions and Its\n  Potential Application", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have shown that deep neural networks (DNNs) with common\nsettings often capture target functions from low to high frequency, which is\ncalled Frequency Principle (F-Principle). It has also been shown that\nF-Principle can provide an understanding to the often observed good\ngeneralization ability of DNNs. However, previous studies focused on the loss\nfunction of mean square error, while various loss functions are used in\npractice. In this work, we show that the F-Principle holds for a general loss\nfunction (e.g., mean square error, cross entropy, etc.). In addition, DNN's\nF-Principle may be applied to develop numerical schemes for solving various\nproblems which would benefit from a fast converging of low frequency. As an\nexample of the potential usage of F-Principle, we apply DNN in solving\ndifferential equations, in which conventional methods (e.g., Jacobi method) is\nusually slow in solving problems due to the convergence from high to low\nfrequency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 02:27:44 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Xu", "Zhi-Qin John", ""]]}, {"id": "1811.10191", "submitter": "Alok Chauhan", "authors": "Alok Chauhan, Vijayakumar V, Layth Sliman", "title": "Ontology Matching Techniques: A Gold Standard Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically an ontology matching technique is a combination of much different\ntype of matchers operating at various abstraction levels such as structure,\nsemantic, syntax, instance etc. An ontology matching technique which employs\nmatchers at all possible abstraction levels is expected to give, in general,\nbest results in terms of precision, recall and F-measure due to improvement in\nmatching opportunities and if we discount efficiency issues which may improve\nwith better computing resources such as parallel processing. A gold standard\nontology matching model is derived from a model classification of ontology\nmatching techniques. A suitable metric is also defined based on gold standard\nontology matching model. A review of various ontology matching techniques\nspecified in recent research papers in the area was undertaken to categorize an\nontology matching technique as per newly proposed gold standard model and a\nmetric value for the whole group was computed. The results of the above study\nsupport proposed gold standard ontology matching model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 06:10:01 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Chauhan", "Alok", ""], ["V", "Vijayakumar", ""], ["Sliman", "Layth", ""]]}, {"id": "1811.10229", "submitter": "Tom Williams", "authors": "Tom Williams and Ravenna Thielstrom and Evan Krause and Bradley\n  Oosterveld and Matthias Scheutz", "title": "Augmenting Robot Knowledge Consultants with Distributed Short Term\n  Memory", "comments": "International Conference on Social Robotics (ICSR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-robot communication in situated environments involves a complex\ninterplay between knowledge representations across a wide variety of\nmodalities. Crucially, linguistic information must be associated with\nrepresentations of objects, locations, people, and goals, which may be\nrepresented in very different ways. In previous work, we developed a Consultant\nFramework that facilitates modality-agnostic access to information distributed\nacross a set of heterogeneously represented knowledge sources. In this work, we\ndraw inspiration from cognitive science to augment these distributed knowledge\nsources with Short Term Memory Buffers to create an STM-augmented algorithm for\nreferring expression generation. We then discuss the potential performance\nbenefits of this approach and insights from cognitive science that may inform\nfuture refinements in the design of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 08:28:21 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Williams", "Tom", ""], ["Thielstrom", "Ravenna", ""], ["Krause", "Evan", ""], ["Oosterveld", "Bradley", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1811.10238", "submitter": "Amit Sangroya", "authors": "Aishwarya Chhabra, Pratik Saini, Amit Sangroya, C. Anantaram", "title": "Learning Latent Beliefs and Performing Epistemic Reasoning for Efficient\n  and Meaningful Dialog Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many dialogue management frameworks allow the system designer to directly\ndefine belief rules to implement an efficient dialog policy. Because these\nrules are directly defined, the components are said to be hand-crafted. As\ndialogues become more complex, the number of states, transitions, and policy\ndecisions becomes very large. To facilitate the dialog policy design process,\nwe propose an approach to automatically learn belief rules using a supervised\nmachine learning approach. We validate our ideas in Student-Advisor\nconversation domain, where we extract latent beliefs like student is curious,\nconfused and neutral, etc. Further, we also perform epistemic reasoning that\nhelps to tailor the dialog according to student's emotional state and hence\nimprove the overall effectiveness of the dialog system. Our latent belief\nidentification approach shows an accuracy of 87% and this results in efficient\nand meaningful dialog management.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 09:12:12 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 09:36:02 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Chhabra", "Aishwarya", ""], ["Saini", "Pratik", ""], ["Sangroya", "Amit", ""], ["Anantaram", "C.", ""]]}, {"id": "1811.10264", "submitter": "Qihao Liu", "authors": "Qihao Liu, Xiaofeng Liu, Guoping Cai", "title": "PNS: Population-Guided Novelty Search Learning Method for Reinforcement\n  Learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has made remarkable achievements, but it still\nsuffers from inadequate exploration strategies, sparse reward signals, and\ndeceptive reward functions. These problems motivate the need for a more\nefficient and directed exploration. For solving this, a Population-guided\nNovelty Search (PNS) parallel learning method is proposed. In PNS, the\npopulation is divided into multiple sub-populations, each of which has one\nchief agent and several exploring agents. The role of the chief agent is to\nevaluate the policies learned by exploring agents and to share the optimal\npolicy with all sub-populations. The role of exploring agents is to learn their\npolicies in collaboration with the guidance of the optimal policy and,\nsimultaneously, upload their policies to the chief agent. To balance\nexploration and exploitation, the Novelty Search (NS) is employed in chief\nagents to encourage policies with high novelty while maximizing per-episode\nperformance. The introduction of sub-populations and NS mechanisms promote\ndirected exploration and enables better policy search. In the numerical\nexperiment section, the proposed scheme is applied to the twin delayed deep\ndeterministic (TD3) policy gradient algorithm, and the effectiveness of PNS to\npromote exploration and improve performance in both continuous control domains\nand discrete control domains is demonstrated. Notably, the proposed method\nachieves rewards that far exceed the SOTA methods in Delayed MoJoCo\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 10:05:15 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 07:01:59 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 04:58:44 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Liu", "Qihao", ""], ["Liu", "Xiaofeng", ""], ["Cai", "Guoping", ""]]}, {"id": "1811.10347", "submitter": "Sonali Parbhoo", "authors": "Sonali Parbhoo, Mario Wieser and Volker Roth", "title": "Estimating Causal Effects With Partial Covariates For Clinical\n  Interpretability", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the causal effects of an intervention in the presence of\nconfounding is a frequently occurring problem in applications such as medicine.\nThe task is challenging since there may be multiple confounding factors, some\nof which may be missing, and inferences must be made from high-dimensional,\nnoisy measurements. In this paper, we propose a decision-theoretic approach to\nestimate the causal effects of interventions where a subset of the covariates\nis unavailable for some patients during testing. Our approach uses the\ninformation bottleneck principle to perform a discrete, low-dimensional\nsufficient reduction of the covariate data to estimate a distribution over\nconfounders. In doing so, we can estimate the causal effect of an intervention\nwhere only partial covariate information is available. Our results on a causal\ninference benchmark and a real application for treating sepsis show that our\nmethod achieves state-of-the-art performance, without sacrificing\ninterpretability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 13:10:42 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Parbhoo", "Sonali", ""], ["Wieser", "Mario", ""], ["Roth", "Volker", ""]]}, {"id": "1811.10355", "submitter": "Benjamin Graham", "authors": "Benjamin Graham", "title": "Unsupervised learning with sparse space-and-time autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use spatially-sparse two, three and four dimensional convolutional\nautoencoder networks to model sparse structures in 2D space, 3D space, and\n3+1=4 dimensional space-time. We evaluate the resulting latent spaces by\ntesting their usefulness for downstream tasks. Applications are to handwriting\nrecognition in 2D, segmentation for parts in 3D objects, segmentation for\nobjects in 3D scenes, and body-part segmentation for 4D wire-frame models\ngenerated from motion capture data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 13:22:17 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Graham", "Benjamin", ""]]}, {"id": "1811.10364", "submitter": "Joeran Beel", "authors": "Joeran Beel, Andrew Collins, Akiko Aizawa", "title": "The Architecture of Mr. DLib's Scientific Recommender-System API", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems in academia are not widely available. This may be in part\ndue to the difficulty and cost of developing and maintaining recommender\nsystems. Many operators of academic products such as digital libraries and\nreference managers avoid this effort, although a recommender system could\nprovide significant benefits to their users. In this paper, we introduce Mr.\nDLib's \"Recommendations as-a-Service\" (RaaS) API that allows operators of\nacademic products to easily integrate a scientific recommender system into\ntheir products. Mr. DLib generates recommendations for research articles but in\nthe future, recommendations may include call for papers, grants, etc. Operators\nof academic products can request recommendations from Mr. DLib and display\nthese recommendations to their users. Mr. DLib can be integrated in just a few\nhours or days; creating an equivalent recommender system from scratch would\nrequire several months for an academic operator. Mr. DLib has been used by\nGESIS Sowiport and by the reference manager JabRef. Mr. DLib is open source and\nits goal is to facilitate the application of, and research on, scientific\nrecommender systems. In this paper, we present the motivation for Mr. DLib, the\narchitecture and details about the effectiveness. Mr. DLib has delivered 94m\nrecommendations over a span of two years with an average click-through rate of\n0.12%.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 13:41:03 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Beel", "Joeran", ""], ["Collins", "Andrew", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1811.10422", "submitter": "Nikola Milo\\v{s}evi\\'c MSc", "authors": "Nikola Milosevic, Goran Nenadic", "title": "Creating a contemporary corpus of similes in Serbian by using natural\n  language processing", "comments": "15 pages, submitted to journal Slovo, however, later withdrawn to\n  correct. Additional work was not done on it, so it is still waiting to be\n  extended. Output of the system can be seen here:\n  http://ezbirka.starisloveni.com/. arXiv admin note: text overlap with\n  arXiv:1605.06319", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simile is a figure of speech that compares two things through the use of\nconnection words, but where comparison is not intended to be taken literally.\nThey are often used in everyday communication, but they are also a part of\nlinguistic cultural heritage. In this paper we present a methodology for\nsemi-automated collection of similes from the World Wide Web using text mining\nand machine learning techniques. We expanded an existing corpus by collecting\n442 similes from the internet and adding them to the existing corpus collected\nby Vuk Stefanovic Karadzic that contained 333 similes. We, also, introduce\ncrowdsourcing to the collection of figures of speech, which helped us to build\ncorpus containing 787 unique similes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 12:55:40 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Milosevic", "Nikola", ""], ["Nenadic", "Goran", ""]]}, {"id": "1811.10433", "submitter": "Buser Say", "authors": "Buser Say, Scott Sanner", "title": "Compact and Efficient Encodings for Planning in Factored State and\n  Action Spaces with Learned Binarized Neural Network Transition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we leverage the efficiency of Binarized Neural Networks (BNNs)\nto learn complex state transition models of planning domains with discretized\nfactored state and action spaces. In order to directly exploit this transition\nstructure for planning, we present two novel compilations of the learned\nfactored planning problem with BNNs based on reductions to Weighted Partial\nMaximum Boolean Satisfiability (FD-SAT-Plan+) as well as Binary Linear\nProgramming (FD-BLP-Plan+). Theoretically, we show that our SAT-based\nBi-Directional Neuron Activation Encoding is asymptotically the most compact\nencoding relative to the current literature and supports Unit Propagation (UP)\n-- an important property that facilitates efficiency in SAT solvers.\nExperimentally, we validate the computational efficiency of our Bi-Directional\nNeuron Activation Encoding in comparison to an existing neuron activation\nencoding and demonstrate the ability to learn complex transition models with\nBNNs. We test the runtime efficiency of both FD-SAT-Plan+ and FD-BLP-Plan+ on\nthe learned factored planning problem showing that FD-SAT-Plan+ scales better\nwith increasing BNN size and complexity. Finally, we present a finite-time\nincremental constraint generation algorithm based on generalized landmark\nconstraints to improve the planning accuracy of our encodings through simulated\nor real-world interaction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 14:59:29 GMT"}, {"version": "v10", "created": "Tue, 9 Apr 2019 00:23:16 GMT"}, {"version": "v11", "created": "Thu, 3 Oct 2019 13:08:37 GMT"}, {"version": "v12", "created": "Fri, 6 Mar 2020 17:47:58 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 18:48:51 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 02:08:22 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 15:31:00 GMT"}, {"version": "v5", "created": "Fri, 30 Nov 2018 17:15:31 GMT"}, {"version": "v6", "created": "Thu, 6 Dec 2018 18:13:01 GMT"}, {"version": "v7", "created": "Fri, 7 Dec 2018 14:38:28 GMT"}, {"version": "v8", "created": "Mon, 10 Dec 2018 02:21:17 GMT"}, {"version": "v9", "created": "Thu, 10 Jan 2019 11:25:20 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Say", "Buser", ""], ["Sanner", "Scott", ""]]}, {"id": "1811.10455", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Timothy Cannings, Fergal Cotter, Hannah\n  Thompson, Nirmesh Patel, John W Cassidy, Harry W Clifford", "title": "A Framework for Implementing Machine Learning on Omics Data", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/102", "categories": "cs.LG cs.AI q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential benefits of applying machine learning methods to -omics data\nare becoming increasingly apparent, especially in clinical settings. However,\nthe unique characteristics of these data are not always well suited to machine\nlearning techniques. These data are often generated across different\ntechnologies in different labs, and frequently with high dimensionality. In\nthis paper we present a framework for combining -omics data sets, and for\nhandling high dimensional data, making -omics research more accessible to\nmachine learning applications. We demonstrate the success of this framework\nthrough integration and analysis of multi-analyte data for a set of 3,533\nbreast cancers. We then use this data-set to predict breast cancer patient\nsurvival for individuals at risk of an impending event, with higher accuracy\nand lower variance than methods trained on individual data-sets. We hope that\nour pipelines for data-set generation and transformation will open up -omics\ndata to machine learning researchers. We have made these freely available for\nnoncommercial use at www.ccg.ai.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:35:57 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Cannings", "Timothy", ""], ["Cotter", "Fergal", ""], ["Thompson", "Hannah", ""], ["Patel", "Nirmesh", ""], ["Cassidy", "John W", ""], ["Clifford", "Harry W", ""]]}, {"id": "1811.10475", "submitter": "Lei Yu", "authors": "Lei Yu, Cyprien de Masson d'Autume, Chris Dyer, Phil Blunsom, Lingpeng\n  Kong, Wang Ling", "title": "Sentence Encoding with Tree-constrained Relation Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meaning of a sentence is a function of the relations that hold between\nits words. We instantiate this relational view of semantics in a series of\nneural models based on variants of relation networks (RNs) which represent a\nset of objects (for us, words forming a sentence) in terms of representations\nof pairs of objects. We propose two extensions to the basic RN model for\nnatural language. First, building on the intuition that not all word pairs are\nequally informative about the meaning of a sentence, we use constraints based\non both supervised and unsupervised dependency syntax to control which\nrelations influence the representation. Second, since higher-order relations\nare poorly captured by a sum of pairwise relations, we use a recurrent\nextension of RNs to propagate information so as to form representations of\nhigher order relations. Experiments on sentence classification, sentence pair\nclassification, and machine translation reveal that, while basic RNs are only\nmodestly effective for sentence representation, recurrent RNs with latent\nsyntax are a reliably powerful representational device.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 16:07:36 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Yu", "Lei", ""], ["d'Autume", "Cyprien de Masson", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""], ["Kong", "Lingpeng", ""], ["Ling", "Wang", ""]]}, {"id": "1811.10550", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Christian M. Meyer, Michael Sailer, Jan Kiesewetter,\n  Elisabeth Bauer, Frank Fischer, Martin R. Fischer, Iryna Gurevych", "title": "Challenges in the Automatic Analysis of Students' Diagnostic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnostic reasoning is a key component of many professions. To improve\nstudents' diagnostic reasoning skills, educational psychologists analyse and\ngive feedback on epistemic activities used by these students while diagnosing,\nin particular, hypothesis generation, evidence generation, evidence evaluation,\nand drawing conclusions. However, this manual analysis is highly\ntime-consuming. We aim to enable the large-scale adoption of diagnostic\nreasoning analysis and feedback by automating the epistemic activity\nidentification. We create the first corpus for this task, comprising diagnostic\nreasoning self-explanations of students from two domains annotated with\nepistemic activities. Based on insights from the corpus creation and the task's\ncharacteristics, we discuss three challenges for the automatic identification\nof epistemic activities using AI methods: the correct identification of\nepistemic activity spans, the reliable distinction of similar epistemic\nactivities, and the detection of overlapping epistemic activities. We propose a\nseparate performance metric for each challenge and thus provide an evaluation\nframework for future research. Indeed, our evaluation of various\nstate-of-the-art recurrent neural network architectures reveals that current\ntechniques fail to address some of these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:53:17 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Schulz", "Claudia", ""], ["Meyer", "Christian M.", ""], ["Sailer", "Michael", ""], ["Kiesewetter", "Jan", ""], ["Bauer", "Elisabeth", ""], ["Fischer", "Frank", ""], ["Fischer", "Martin R.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1811.10553", "submitter": "Alvaro Ulloa Cerna", "authors": "Alvaro Ulloa, Linyuan Jing, Christopher W Good, David P vanMaanen,\n  Sushravya Raghunath, Jonathan D Suever, Christopher D Nevius, Gregory J\n  Wehner, Dustin Hartzel, Joseph B Leader, Amro Alsaid, Aalpen A Patel, H\n  Lester Kirchner, Marios S Pattichis, Christopher M Haggerty, Brandon K\n  Fornwalt", "title": "A deep neural network to enhance prediction of 1-year mortality using\n  echocardiographic videos of the heart", "comments": "We updated results with improved performance after dropout bug in\n  tensorflow v1.12. We also added learning curves showing promise in video\n  model with more samples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future clinical events helps physicians guide appropriate\nintervention. Machine learning has tremendous promise to assist physicians with\npredictions based on the discovery of complex patterns from historical data,\nsuch as large, longitudinal electronic health records (EHR). This study is a\nfirst attempt to demonstrate such capabilities using raw echocardiographic\nvideos of the heart. We show that a large dataset of 723,754\nclinically-acquired echocardiographic videos (~45 million images) linked to\nlongitudinal follow-up data in 27,028 patients can be used to train a deep\nneural network to predict 1-year mortality with good accuracy (area under the\ncurve (AUC) in an independent test set = 0.839). Prediction accuracy was\nfurther improved by adding EHR data (AUC = 0.858). Finally, we demonstrate that\nthe trained neural network was more accurate in mortality prediction than two\nexpert cardiologists. These results highlight the potential of neural networks\nto add new power to clinical predictions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:58:57 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 20:36:00 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ulloa", "Alvaro", ""], ["Jing", "Linyuan", ""], ["Good", "Christopher W", ""], ["vanMaanen", "David P", ""], ["Raghunath", "Sushravya", ""], ["Suever", "Jonathan D", ""], ["Nevius", "Christopher D", ""], ["Wehner", "Gregory J", ""], ["Hartzel", "Dustin", ""], ["Leader", "Joseph B", ""], ["Alsaid", "Amro", ""], ["Patel", "Aalpen A", ""], ["Kirchner", "H Lester", ""], ["Pattichis", "Marios S", ""], ["Haggerty", "Christopher M", ""], ["Fornwalt", "Brandon K", ""]]}, {"id": "1811.10597", "submitter": "David Bau iii", "authors": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B.\n  Tenenbaum, William T. Freeman, Antonio Torralba", "title": "GAN Dissection: Visualizing and Understanding Generative Adversarial\n  Networks", "comments": "18 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have recently achieved impressive\nresults for many real-world applications, and many GAN variants have emerged\nwith improvements in sample quality and training stability. However, they have\nnot been well visualized or understood. How does a GAN represent our visual\nworld internally? What causes the artifacts in GAN results? How do\narchitectural choices affect GAN learning? Answering such questions could\nenable us to develop new insights and better models.\n  In this work, we present an analytic framework to visualize and understand\nGANs at the unit-, object-, and scene-level. We first identify a group of\ninterpretable units that are closely related to object concepts using a\nsegmentation-based network dissection method. Then, we quantify the causal\neffect of interpretable units by measuring the ability of interventions to\ncontrol objects in the output. We examine the contextual relationship between\nthese units and their surroundings by inserting the discovered object concepts\ninto new images. We show several practical applications enabled by our\nframework, from comparing internal representations across different layers,\nmodels, and datasets, to improving GANs by locating and removing\nartifact-causing units, to interactively manipulating objects in a scene. We\nprovide open source interpretation tools to help researchers and practitioners\nbetter understand their GAN models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 18:59:07 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 22:56:10 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Bau", "David", ""], ["Zhu", "Jun-Yan", ""], ["Strobelt", "Hendrik", ""], ["Zhou", "Bolei", ""], ["Tenenbaum", "Joshua B.", ""], ["Freeman", "William T.", ""], ["Torralba", "Antonio", ""]]}, {"id": "1811.10656", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev, Nina Narodytska, Joao Marques-Silva", "title": "Abduction-Based Explanations for Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing range of applications of Machine Learning (ML) in a multitude of\nsettings motivates the ability of computing small explanations for predictions\nmade. Small explanations are generally accepted as easier for human decision\nmakers to understand. Most earlier work on computing explanations is based on\nheuristic approaches, providing no guarantees of quality, in terms of how close\nsuch solutions are from cardinality- or subset-minimal explanations. This paper\ndevelops a constraint-agnostic solution for computing explanations for any ML\nmodel. The proposed solution exploits abductive reasoning, and imposes the\nrequirement that the ML model can be represented as sets of constraints using\nsome target constraint reasoning system for which the decision problem can be\nanswered with some oracle. The experimental results, obtained on well-known\ndatasets, validate the scalability of the proposed approach as well as the\nquality of the computed solutions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:27:26 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Narodytska", "Nina", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "1811.10665", "submitter": "Christopher Rosin", "authors": "Christopher D. Rosin", "title": "Stepping Stones to Inductive Synthesis of Low-Level Looping Programs", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive program synthesis, from input/output examples, can provide an\nopportunity to automatically create programs from scratch without presupposing\nthe algorithmic form of the solution. For induction of general programs with\nloops (as opposed to loop-free programs, or synthesis for domain-specific\nlanguages), the state of the art is at the level of introductory programming\nassignments. Most problems that require algorithmic subtlety, such as fast\nsorting, have remained out of reach without the benefit of significant\nproblem-specific background knowledge. A key challenge is to identify cues that\nare available to guide search towards correct looping programs. We present\nMAKESPEARE, a simple delayed-acceptance hillclimbing method that synthesizes\nlow-level looping programs from input/output examples. During search, delayed\nacceptance bypasses small gains to identify significantly-improved stepping\nstone programs that tend to generalize and enable further progress. The method\nperforms well on a set of established benchmarks, and succeeds on the\npreviously unsolved \"Collatz Numbers\" program synthesis problem. Additional\nbenchmarks include the problem of rapidly sorting integer arrays, in which we\nobserve the emergence of comb sort (a Shell sort variant that is empirically\nfast). MAKESPEARE has also synthesized a record-setting program on one of the\npuzzles from the TIS-100 assembly language programming game.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:51:27 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Rosin", "Christopher D.", ""]]}, {"id": "1811.10667", "submitter": "Xuelu Chen", "authors": "Xuelu Chen, Muhao Chen, Weijia Shi, Yizhou Sun, Carlo Zaniolo", "title": "Embedding Uncertain Knowledge Graphs", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence.\n  Vol. 33. 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models for deterministic Knowledge Graphs (KG) have been\nextensively studied, with the purpose of capturing latent semantic relations\nbetween entities and incorporating the structured knowledge into machine\nlearning. However, there are many KGs that model uncertain knowledge, which\ntypically model the inherent uncertainty of relations facts with a confidence\nscore, and embedding such uncertain knowledge represents an unresolved\nchallenge. The capturing of uncertain knowledge will benefit many\nknowledge-driven applications such as question answering and semantic search by\nproviding more natural characterization of the knowledge. In this paper, we\npropose a novel uncertain KG embedding model UKGE, which aims to preserve both\nstructural and uncertainty information of relation facts in the embedding\nspace. Unlike previous models that characterize relation facts with binary\nclassification techniques, UKGE learns embeddings according to the confidence\nscores of uncertain relation facts. To further enhance the precision of UKGE,\nwe also introduce probabilistic soft logic to infer confidence scores for\nunseen relation facts during training. We propose and evaluate two variants of\nUKGE based on different learning objectives. Experiments are conducted on three\nreal-world uncertain KGs via three tasks, i.e. confidence prediction, relation\nfact ranking, and relation fact classification. UKGE shows effectiveness in\ncapturing uncertain knowledge by achieving promising results on these tasks,\nand consistently outperforms baselines on these tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:57:14 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 00:59:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chen", "Xuelu", ""], ["Chen", "Muhao", ""], ["Shi", "Weijia", ""], ["Sun", "Yizhou", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1811.10670", "submitter": "Shari Trewin", "authors": "Shari Trewin", "title": "AI Fairness for People with Disabilities: Point of View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how fair treatment in society for people with disabilities might\nbe impacted by the rise in the use of artificial intelligence, and especially\nmachine learning methods. We argue that fairness for people with disabilities\nis different to fairness for other protected attributes such as age, gender or\nrace. One major difference is the extreme diversity of ways disabilities\nmanifest, and people adapt. Secondly, disability information is highly\nsensitive and not always shared, precisely because of the potential for\ndiscrimination. Given these differences, we explore definitions of fairness and\nhow well they work in the disability space. Finally, we suggest ways of\napproaching fairness for people with disabilities in AI applications.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 20:11:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Trewin", "Shari", ""]]}, {"id": "1811.10719", "submitter": "Hiroharu Kato", "authors": "Hiroharu Kato, Tatsuya Harada", "title": "Learning View Priors for Single-view 3D Reconstruction", "comments": "CVPR 2019. Project page:\n  http://hiroharu-kato.com/projects_en/view_prior_learning.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is some ambiguity in the 3D shape of an object when the number of\nobserved views is small. Because of this ambiguity, although a 3D object\nreconstructor can be trained using a single view or a few views per object,\nreconstructed shapes only fit the observed views and appear incorrect from the\nunobserved viewpoints. To reconstruct shapes that look reasonable from any\nviewpoint, we propose to train a discriminator that learns prior knowledge\nregarding possible views. The discriminator is trained to distinguish the\nreconstructed views of the observed viewpoints from those of the unobserved\nviewpoints. The reconstructor is trained to correct unobserved views by fooling\nthe discriminator. Our method outperforms current state-of-the-art methods on\nboth synthetic and natural image datasets; this validates the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 22:23:44 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 15:18:48 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Kato", "Hiroharu", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1811.10728", "submitter": "Hisao Katsumi", "authors": "Hisao Katsumi, Takuya Hiraoka, Koichiro Yoshino, Kazeto Yamamoto,\n  Shota Motoura, Kunihiko Sadamasa and Satoshi Nakamura", "title": "Optimization of Information-Seeking Dialogue Strategy for\n  Argumentation-Based Dialogue System", "comments": "Accepted by AAAI2019 DEEP-DIAL 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation-based dialogue systems, which can handle and exchange arguments\nthrough dialogue, have been widely researched. It is required that these\nsystems have sufficient supporting information to argue their claims\nrationally; however, the systems often do not have enough of such information\nin realistic situations. One way to fill in the gap is acquiring such missing\ninformation from dialogue partners (information-seeking dialogue). Existing\ninformation-seeking dialogue systems are based on handcrafted dialogue\nstrategies that exhaustively examine missing information. However, the proposed\nstrategies are not specialized in collecting information for constructing\nrational arguments. Moreover, the number of system's inquiry candidates grows\nin accordance with the size of the argument set that the system deal with. In\nthis paper, we formalize the process of information-seeking dialogue as Markov\ndecision processes (MDPs) and apply deep reinforcement learning (DRL) for\nautomatically optimizing a dialogue strategy. By utilizing DRL, our dialogue\nstrategy can successfully minimize objective functions, the number of turns it\ntakes for our system to collect necessary information in a dialogue. We\nconducted dialogue experiments using two datasets from different domains of\nargumentative dialogue. Experimental results show that the proposed\nformalization based on MDP works well, and the policy optimized by DRL\noutperformed existing heuristic dialogue strategies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 22:56:07 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Katsumi", "Hisao", ""], ["Hiraoka", "Takuya", ""], ["Yoshino", "Koichiro", ""], ["Yamamoto", "Kazeto", ""], ["Motoura", "Shota", ""], ["Sadamasa", "Kunihiko", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1811.10732", "submitter": "Shagun Sodhani", "authors": "Khimya Khetarpal, Shagun Sodhani, Sarath Chandar, Doina Precup", "title": "Environments for Lifelong Reinforcement Learning", "comments": "Accepted at 2nd Continual Learning Workshop, Neural Information\n  Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve general artificial intelligence, reinforcement learning (RL)\nagents should learn not only to optimize returns for one specific task but also\nto constantly build more complex skills and scaffold their knowledge about the\nworld, without forgetting what has already been learned. In this paper, we\ndiscuss the desired characteristics of environments that can support the\ntraining and evaluation of lifelong reinforcement learning agents, review\nexisting environments from this perspective, and propose recommendations for\ndevising suitable environments in the future.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:01:49 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 06:17:16 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Sodhani", "Shagun", ""], ["Chandar", "Sarath", ""], ["Precup", "Doina", ""]]}, {"id": "1811.10734", "submitter": "Palash Goyal", "authors": "Palash Goyal, Sujit Rokka Chhetri, Ninareh Mehrabi, Emilio Ferrara,\n  Arquimedes Canedo", "title": "DynamicGEM: A Library for Dynamic Graph Embedding Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DynamicGEM is an open-source Python library for learning node representations\nof dynamic graphs. It consists of state-of-the-art algorithms for defining\nembeddings of nodes whose connections evolve over time. The library also\ncontains the evaluation framework for four downstream tasks on the network:\ngraph reconstruction, static and temporal link prediction, node classification,\nand temporal visualization. We have implemented various metrics to evaluate the\nstate-of-the-art methods, and examples of evolving networks from various\ndomains. We have easy-to-use functions to call and evaluate the methods and\nhave extensive usage documentation. Furthermore, DynamicGEM provides a template\nto add new algorithms with ease to facilitate further research on the topic.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 23:05:38 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Goyal", "Palash", ""], ["Chhetri", "Sujit Rokka", ""], ["Mehrabi", "Ninareh", ""], ["Ferrara", "Emilio", ""], ["Canedo", "Arquimedes", ""]]}, {"id": "1811.10758", "submitter": "Mat\\'ias Pavez", "authors": "Mat\\'ias Pavez, Javier Ruiz del Solar, Victoria Amo, Felix Meyer zu\n  Driehausen", "title": "Towards Long-Term Memory for Social Robots: Proposing a New Challenge\n  for the RoboCup@Home League", "comments": "11 pages, 1 figure, robocup 2018 symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Long-term memory is essential to feel like a continuous being, and to be able\nto interact/communicate coherently. Social robots need long-term memories in\norder to establish long-term relationships with humans and other robots, and do\nnot act just for the moment. In this paper this challenge is highlighted, open\nquestions are identified, the need of addressing this challenge in the\nRoboCup@Home League with new tests is motivated, and a new test is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 00:45:31 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Pavez", "Mat\u00edas", ""], ["del Solar", "Javier Ruiz", ""], ["Amo", "Victoria", ""], ["Driehausen", "Felix Meyer zu", ""]]}, {"id": "1811.10792", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, Michael Rabbat", "title": "Stochastic Gradient Push for Distributed Deep Learning", "comments": "ICML 2019", "journal-ref": "International Conference on Machine Learning 97 (2019) 344-353", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data-parallel algorithms aim to accelerate the training of deep\nneural networks by parallelizing the computation of large mini-batch gradient\nupdates across multiple nodes. Approaches that synchronize nodes using exact\ndistributed averaging (e.g., via AllReduce) are sensitive to stragglers and\ncommunication delays. The PushSum gossip algorithm is robust to these issues,\nbut only performs approximate distributed averaging. This paper studies\nStochastic Gradient Push (SGP), which combines PushSum with stochastic gradient\nupdates. We prove that SGP converges to a stationary point of smooth,\nnon-convex objectives at the same sub-linear rate as SGD, and that all nodes\nachieve consensus. We empirically validate the performance of SGP on image\nclassification (ResNet-50, ImageNet) and machine translation (Transformer,\nWMT'16 En-De) workloads. Our code will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:47:26 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 02:58:36 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 19:59:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Assran", "Mahmoud", ""], ["Loizou", "Nicolas", ""], ["Ballas", "Nicolas", ""], ["Rabbat", "Michael", ""]]}, {"id": "1811.10840", "submitter": "Thomas Dietterich", "authors": "Thomas G. Dietterich", "title": "Robust Artificial Intelligence and Robust Human Organizations", "comments": "To appear as a Perspective in Frontiers in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every AI system is deployed by a human organization. In high risk\napplications, the combined human plus AI system must function as a\nhigh-reliability organization in order to avoid catastrophic errors. This short\nnote reviews the properties of high-reliability organizations and draws\nimplications for the development of AI technology and the safe application of\nthat technology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 06:58:59 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Dietterich", "Thomas G.", ""]]}, {"id": "1811.10901", "submitter": "Taolue Chen", "authors": "Yedi Zhang and Fu Song and Taolue Chen", "title": "Making Agents' Abilities Explicit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating-time temporal logics (ATL/ATL*) represent a family of modal\nlogics for reasoning about agents' strategic abilities in multiagent systems\n(MAS). The interpretations of ATL/ATL* over the semantic model Concurrent Game\nStructures (CGS) usually vary depending on the agents' abilities, for instance,\nperfect vs. imperfect information, perfect vs. imperfect recall, resulting in a\nvariety of variants which have been studied extensively in literature. However,\nthey are defined at the semantic level, which may limit modeling flexibilities\nand may give counter-intuitive interpretations. To mitigate these issues, in\nthis work, we propose to extend CGS with agents' abilities and study the new\nsemantics of ATL/ATL* under this model. We give PSACE/2EXPTIME model-checking\nalgorithms for ATL/ATL* and implement them as a prototype tool. Experiment\nresults show the practical feasibility of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 10:22:09 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Yedi", ""], ["Song", "Fu", ""], ["Chen", "Taolue", ""]]}, {"id": "1811.10928", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Levi H. S. Lelis, Tor Lattimore, Th\\'eophane Weber", "title": "Single-Agent Policy Tree Search With Guarantees", "comments": null, "journal-ref": "32nd Conference on Neural Information Processing Systems (NIPS\n  2018), Montr\\'eal, Canada", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two novel tree search algorithms that use a policy to guide\nsearch. The first algorithm is a best-first enumeration that uses a cost\nfunction that allows us to prove an upper bound on the number of nodes to be\nexpanded before reaching a goal state. We show that this best-first algorithm\nis particularly well suited for `needle-in-a-haystack' problems. The second\nalgorithm is based on sampling and we prove an upper bound on the expected\nnumber of nodes it expands before reaching a set of goal states. We show that\nthis algorithm is better suited for problems where many paths lead to a goal.\nWe validate these tree search algorithms on 1,000 computer-generated levels of\nSokoban, where the policy used to guide the search comes from a neural network\ntrained using A3C. Our results show that the policy tree search algorithms we\nintroduce are competitive with a state-of-the-art domain-independent planner\nthat uses heuristic search.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 11:53:33 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 10:32:36 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Orseau", "Laurent", ""], ["Lelis", "Levi H. S.", ""], ["Lattimore", "Tor", ""], ["Weber", "Th\u00e9ophane", ""]]}, {"id": "1811.10990", "submitter": "Chenyang Huang", "authors": "Chenyang Huang and Osmar R. Za\\\"iane", "title": "Generating Responses Expressing Emotion in an Open-domain Dialogue\n  System", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-17705-8", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based Open-ended conversational agents automatically generate\nresponses based on predictive models learned from a large number of pairs of\nutterances. The generated responses are typically acceptable as a sentence but\nare often dull, generic, and certainly devoid of any emotion. In this paper, we\npresent neural models that learn to express a given emotion in the generated\nresponse. We propose four models and evaluate them against 3 baselines. An\nencoder-decoder framework-based model with multiple attention layers provides\nthe best overall performance in terms of expressing the required emotion. While\nit does not outperform other models on all emotions, it presents promising\nresults in most cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 22:59:25 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Huang", "Chenyang", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "1811.10996", "submitter": "Ning Miao", "authors": "Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li", "title": "CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling", "comments": "AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications of natural language generation, there are often\nconstraints on the target sentences in addition to fluency and naturalness\nrequirements. Existing language generation techniques are usually based on\nrecurrent neural networks (RNNs). However, it is non-trivial to impose\nconstraints on RNNs while maintaining generation quality, since RNNs generate\nsentences sequentially (or with beam search) from the first word to the last.\nIn this paper, we propose CGMH, a novel approach using Metropolis-Hastings\nsampling for constrained sentence generation. CGMH allows complicated\nconstraints such as the occurrence of multiple keywords in the target\nsentences, which cannot be handled in traditional RNN-based approaches.\nMoreover, CGMH works in the inference stage, and does not require parallel\ncorpora for training. We evaluate our method on a variety of tasks, including\nkeywords-to-sentence generation, unsupervised sentence paraphrasing, and\nunsupervised sentence error correction. CGMH achieves high performance compared\nwith previous supervised methods for sentence generation. Our code is released\nat https://github.com/NingMiao/CGMH\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 15:46:57 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Mou", "Lili", ""], ["Yan", "Rui", ""], ["Li", "Lei", ""]]}, {"id": "1811.11041", "submitter": "EPTCS", "authors": "Tai-Danae Bradley (Graduate Center, CUNY), Martha Lewis (ILLC,\n  University of Amsterdam), Jade Master (Dept. Mathematics, UC Riverside), Brad\n  Theilman (Gentner Lab, UC San Diego)", "title": "Translating and Evolving: Towards a Model of Language Change in DisCoCat", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 50-61", "doi": "10.4204/EPTCS.283.4", "report-no": null, "categories": "cs.CL cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The categorical compositional distributional (DisCoCat) model of meaning\ndeveloped by Coecke et al. (2010) has been successful in modeling various\naspects of meaning. However, it fails to model the fact that language can\nchange. We give an approach to DisCoCat that allows us to represent language\nmodels and translations between them, enabling us to describe translations from\none language to another, or changes within the same language. We unify the\nproduct space representation given in (Coecke et al., 2010) and the functorial\ndescription in (Kartsaklis et al., 2013), in a way that allows us to view a\nlanguage as a catalogue of meanings. We formalize the notion of a lexicon in\nDisCoCat, and define a dictionary of meanings between two lexicons. All this is\ndone within the framework of monoidal categories. We give examples of how to\napply our methods, and give a concrete suggestion for compositional translation\nin corpora.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:11:18 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Bradley", "Tai-Danae", "", "Graduate Center, CUNY"], ["Lewis", "Martha", "", "ILLC,\n  University of Amsterdam"], ["Master", "Jade", "", "Dept. Mathematics, UC Riverside"], ["Theilman", "Brad", "", "Gentner Lab, UC San Diego"]]}, {"id": "1811.11064", "submitter": "Nikhil Krishnaswamy", "authors": "Nikhil Krishnaswamy, Scott Friedman, James Pustejovsky", "title": "Combining Deep Learning and Qualitative Spatial Reasoning to Learn\n  Complex Structures from Sparse Examples with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern machine learning approaches require vast amounts of training data\nto learn new concepts; conversely, human learning often requires few\nexamples--sometimes only one--from which the learner can abstract structural\nconcepts. We present a novel approach to introducing new spatial structures to\nan AI agent, combining deep learning over qualitative spatial relations with\nvarious heuristic search algorithms. The agent extracts spatial relations from\na sparse set of noisy examples of block-based structures, and trains\nconvolutional and sequential models of those relation sets. To create novel\nexamples of similar structures, the agent begins placing blocks on a virtual\ntable, uses a CNN to predict the most similar complete example structure after\neach placement, an LSTM to predict the most likely set of remaining moves\nneeded to complete it, and recommends one using heuristic search. We verify\nthat the agent learned the concept by observing its virtual block-building\nactivities, wherein it ranks each potential subsequent action toward building\nits learned concept. We empirically assess this approach with human\nparticipants' ratings of the block structures. Initial results and qualitative\nevaluations of structures generated by the trained agent show where it has\ngeneralized concepts from the training data, which heuristics perform best\nwithin the search space, and how we might improve learning and execution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 15:48:27 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Krishnaswamy", "Nikhil", ""], ["Friedman", "Scott", ""], ["Pustejovsky", "James", ""]]}, {"id": "1811.11067", "submitter": "Elizaveta Logacheva", "authors": "Pavel Solovev, Vladimir Aliev, Pavel Ostyakov, Gleb Sterkin, Elizaveta\n  Logacheva, Stepan Troeshestov, Roman Suvorov, Anton Mashikhin, Oleg Khomenko,\n  Sergey I. Nikolenko", "title": "Learning State Representations in Complex Systems with Multimodal Data", "comments": "Fixed references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning becomes especially important for complex systems with\nmultimodal data sources such as cameras or sensors. Recent advances in\nreinforcement learning and optimal control make it possible to design control\nalgorithms on these latent representations, but the field still lacks a\nlarge-scale standard dataset for unified comparison. In this work, we present a\nlarge-scale dataset and evaluation framework for representation learning for\nthe complex task of landing an airplane. We implement and compare several\napproaches to representation learning on this dataset in terms of the quality\nof simple supervised learning tasks and disentanglement scores. The resulting\nrepresentations can be used for further tasks such as anomaly detection,\noptimal control, model-based reinforcement learning, and other applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 15:55:42 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 13:48:24 GMT"}, {"version": "v3", "created": "Tue, 15 Jan 2019 20:13:43 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Solovev", "Pavel", ""], ["Aliev", "Vladimir", ""], ["Ostyakov", "Pavel", ""], ["Sterkin", "Gleb", ""], ["Logacheva", "Elizaveta", ""], ["Troeshestov", "Stepan", ""], ["Suvorov", "Roman", ""], ["Mashikhin", "Anton", ""], ["Khomenko", "Oleg", ""], ["Nikolenko", "Sergey I.", ""]]}, {"id": "1811.11155", "submitter": "Krishna Kumar Singh", "authors": "Krishna Kumar Singh, Utkarsh Ojha, Yong Jae Lee", "title": "FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained\n  Object Generation and Discovery", "comments": null, "journal-ref": "CVPR 2019 (Oral Presentation)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose FineGAN, a novel unsupervised GAN framework, which disentangles\nthe background, object shape, and object appearance to hierarchically generate\nimages of fine-grained object categories. To disentangle the factors without\nsupervision, our key idea is to use information theory to associate each factor\nto a latent code, and to condition the relationships between the codes in a\nspecific way to induce the desired hierarchy. Through extensive experiments, we\nshow that FineGAN achieves the desired disentanglement to generate realistic\nand diverse images belonging to fine-grained classes of birds, dogs, and cars.\nUsing FineGAN's automatically learned features, we also cluster real images as\na first attempt at solving the novel problem of unsupervised fine-grained\nobject category discovery. Our code/models/demo can be found at\nhttps://github.com/kkanshul/finegan\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 18:44:37 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 17:44:24 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Singh", "Krishna Kumar", ""], ["Ojha", "Utkarsh", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1811.11190", "submitter": "Alexander New", "authors": "Alexander New, Sabbir M. Rashid, John S. Erickson, Deborah L.\n  McGuinness, and Kristin P. Bennett", "title": "Semantically-aware population health risk analyses", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One primary task of population health analysis is the identification of risk\nfactors that, for some subpopulation, have a significant association with some\nhealth condition. Examples include finding lifestyle factors associated with\nchronic diseases and finding genetic mutations associated with diseases in\nprecision health. We develop a combined semantic and machine learning system\nthat uses a health risk ontology and knowledge graph (KG) to dynamically\ndiscover risk factors and their associated subpopulations. Semantics and the\nnovel supervised cadre model make our system explainable. Future population\nhealth studies are easily performed and documented with provenance by\nspecifying additional input and output KG cartridges.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:00:07 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["New", "Alexander", ""], ["Rashid", "Sabbir M.", ""], ["Erickson", "John S.", ""], ["McGuinness", "Deborah L.", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1811.11206", "submitter": "Thang Bui", "authors": "Thang D. Bui, Cuong V. Nguyen, Siddharth Swaroop, Richard E. Turner", "title": "Partitioned Variational Inference: A unified framework encompassing\n  federated and continual learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference (VI) has become the method of choice for fitting many\nmodern probabilistic models. However, practitioners are faced with a fragmented\nliterature that offers a bewildering array of algorithmic options. First, the\nvariational family. Second, the granularity of the updates e.g. whether the\nupdates are local to each data point and employ message passing or global.\nThird, the method of optimization (bespoke or blackbox, closed-form or\nstochastic updates, etc.). This paper presents a new framework, termed\nPartitioned Variational Inference (PVI), that explicitly acknowledges these\nalgorithmic dimensions of VI, unifies disparate literature, and provides\nguidance on usage. Crucially, the proposed PVI framework allows us to identify\nnew ways of performing VI that are ideally suited to challenging learning\nscenarios including federated learning (where distributed computing is\nleveraged to process non-centralized data) and continual learning (where new\ndata and tasks arrive over time and must be accommodated quickly). We showcase\nthese new capabilities by developing communication-efficient federated training\nof Bayesian neural networks and continual learning for Gaussian process models\nwith private pseudo-points. The new methods significantly outperform the\nstate-of-the-art, whilst being almost as straightforward to implement as\nstandard VI.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:16:00 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Bui", "Thang D.", ""], ["Nguyen", "Cuong V.", ""], ["Swaroop", "Siddharth", ""], ["Turner", "Richard E.", ""]]}, {"id": "1811.11218", "submitter": "Berk Gulmezoglu", "authors": "Berk Gulmezoglu, Andreas Zankl, M. Caner Tol, Saad Islam, Thomas\n  Eisenbarth and Berk Sunar", "title": "Undermining User Privacy on Mobile Devices Using AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, literature has shown that attacks exploiting the\nmicroarchitecture of modern processors pose a serious threat to the privacy of\nmobile phone users. This is because applications leave distinct footprints in\nthe processor, which can be used by malware to infer user activities. In this\nwork, we show that these inference attacks are considerably more practical when\ncombined with advanced AI techniques. In particular, we focus on profiling the\nactivity in the last-level cache (LLC) of ARM processors. We employ a simple\nPrime+Probe based monitoring technique to obtain cache traces, which we\nclassify with Deep Learning methods including Convolutional Neural Networks. We\ndemonstrate our approach on an off-the-shelf Android phone by launching a\nsuccessful attack from an unprivileged, zeropermission App in well under a\nminute. The App thereby detects running applications with an accuracy of 98%\nand reveals opened websites and streaming videos by monitoring the LLC for at\nmost 6 seconds. This is possible, since Deep Learning compensates measurement\ndisturbances stemming from the inherently noisy LLC monitoring and unfavorable\ncache characteristics such as random line replacement policies. In summary, our\nresults show that thanks to advanced AI techniques, inference attacks are\nbecoming alarmingly easy to implement and execute in practice. This once more\ncalls for countermeasures that confine microarchitectural leakage and protect\nmobile phone applications, especially those valuing the privacy of their users.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:44:12 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 20:53:54 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Gulmezoglu", "Berk", ""], ["Zankl", "Andreas", ""], ["Tol", "M. Caner", ""], ["Islam", "Saad", ""], ["Eisenbarth", "Thomas", ""], ["Sunar", "Berk", ""]]}, {"id": "1811.11233", "submitter": "Mark Schutera", "authors": "Mark Schutera and Niklas Goby and Stefan Smolarek and Markus Reischl", "title": "Distributed traffic light control at uncoupled intersections with\n  real-world topology by deep reinforcement learning", "comments": "32nd Conference on Neural Information Processing Systems, within\n  Workshop on Machine Learning for Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the implications of uncoupled intersections with local\nreal-world topology and sensor setup on traffic light control approaches.\nControl approaches are evaluated with respect to: Traffic flow, fuel\nconsumption and noise emission at intersections.\n  The real-world road network of Friedrichshafen is depicted, preprocessed and\nthe present traffic light controlled intersections are modeled with respect to\nstate space and action space.\n  Different strategies, containing fixed-time, gap-based and time-based control\napproaches as well as our deep reinforcement learning based control approach,\nare implemented and assessed. Our novel DRL approach allows for modeling the\nTLC action space, with respect to phase selection as well as selection of\ntransition timings. It was found that real-world topologies, and thus\nirregularly arranged intersections have an influence on the performance of\ntraffic light control approaches. This is even to be observed within the same\nintersection types (n-arm, m-phases). Moreover we could show, that these\ninfluences can be efficiently dealt with by our deep reinforcement learning\nbased control approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:08:28 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Schutera", "Mark", ""], ["Goby", "Niklas", ""], ["Smolarek", "Stefan", ""], ["Reischl", "Markus", ""]]}, {"id": "1811.11259", "submitter": "Francesco Fraternali", "authors": "Francesco Fraternali, Bharathan Balaji, Rajesh Gupta", "title": "Scaling Configuration of Energy Harvesting Sensors with Reinforcement\n  Learning", "comments": "7 pages, 5 figures", "journal-ref": "ENSsys '18: International Workshop on Energy Harvesting &\n  Energy-Neutral Sensing Systems}{November 4, 2018}{Shenzhen, China", "doi": "10.1145/3279755.3279760", "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the Internet of Things (IoT), an increasing number of\nenergy harvesting methods are being used to supplement or supplant battery\nbased sensors. Energy harvesting sensors need to be configured according to the\napplication, hardware, and environmental conditions to maximize their\nusefulness. As of today, the configuration of sensors is either manual or\nheuristics based, requiring valuable domain expertise. Reinforcement learning\n(RL) is a promising approach to automate configuration and efficiently scale\nIoT deployments, but it is not yet adopted in practice. We propose solutions to\nbridge this gap: reduce the training phase of RL so that nodes are operational\nwithin a short time after deployment and reduce the computational requirements\nto scale to large deployments. We focus on configuration of the sampling rate\nof indoor solar panel based energy harvesting sensors. We created a simulator\nbased on 3 months of data collected from 5 sensor nodes subject to different\nlighting conditions. Our simulation results show that RL can effectively learn\nenergy availability patterns and configure the sampling rate of the sensor\nnodes to maximize the sensing data while ensuring that energy storage is not\ndepleted. The nodes can be operational within the first day by using our\nmethods. We show that it is possible to reduce the number of RL policies by\nusing a single policy for nodes that share similar lighting conditions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:05:43 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Fraternali", "Francesco", ""], ["Balaji", "Bharathan", ""], ["Gupta", "Rajesh", ""]]}, {"id": "1811.11273", "submitter": "Henry Bendekgey", "authors": "Henry Bendekgey", "title": "Clustering Player Strategies from Variable-Length Game Logs in Dominion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for encoding game logs as numeric features in the card\ngame Dominion. We then run the manifold learning algorithm t-SNE on these\nencodings to visualize the landscape of player strategies. By quantifying game\nstates as the relative prevalence of cards in a player's deck, we create\nvisualizations that capture qualitative differences in player strategies.\nDifferent ways of deviating from the starting game state appear as different\nrays in the visualization, giving it an intuitive explanation. This is a\npromising new direction for understanding player strategies across games that\nvary in length.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:48:42 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 07:30:02 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Bendekgey", "Henry", ""]]}, {"id": "1811.11277", "submitter": "Junyao Guo", "authors": "Junyao Guo, Unmesh Kurup, Mohak Shah", "title": "Is it Safe to Drive? An Overview of Factors, Challenges, and Datasets\n  for Driveability Assessment in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in learning algorithms and hardware development,\nautonomous cars have shown promise when operating in structured environments\nunder good driving conditions. However, for complex, cluttered and unseen\nenvironments with high uncertainty, autonomous driving systems still frequently\ndemonstrate erroneous or unexpected behaviors, that could lead to catastrophic\noutcomes. Autonomous vehicles should ideally adapt to driving conditions; while\nthis can be achieved through multiple routes, it would be beneficial as a first\nstep to be able to characterize Driveability in some quantified form. To this\nend, this paper aims to create a framework for investigating different factors\nthat can impact driveability. Also, one of the main mechanisms to adapt\nautonomous driving systems to any driving condition is to be able to learn and\ngeneralize from representative scenarios. The machine learning algorithms that\ncurrently do so learn predominantly in a supervised manner and consequently\nneed sufficient data for robust and efficient learning. Therefore, we also\nperform a comparative overview of 45 public driving datasets that enable\nlearning and publish this dataset index at\nhttps://sites.google.com/view/driveability-survey-datasets. Specifically, we\ncategorize the datasets according to use cases, and highlight the datasets that\ncapture complicated and hazardous driving conditions which can be better used\nfor training robust driving models. Furthermore, by discussions of what driving\nscenarios are not covered by existing public datasets and what driveability\nfactors need more investigation and data acquisition, this paper aims to\nencourage both targeted dataset collection and the proposal of novel\ndriveability metrics that enhance the robustness of autonomous cars in adverse\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 21:53:09 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Guo", "Junyao", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1811.11283", "submitter": "Raviteja Vemulapalli", "authors": "Raviteja Vemulapalli and Aseem Agarwala", "title": "A Compact Embedding for Facial Expression Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing work on automatic facial expression analysis focuses on\ndiscrete emotion recognition, or facial action unit detection. However, facial\nexpressions do not always fall neatly into pre-defined semantic categories.\nAlso, the similarity between expressions measured in the action unit space need\nnot correspond to how humans perceive expression similarity. Different from\nprevious work, our goal is to describe facial expressions in a continuous\nfashion using a compact embedding space that mimics human visual preferences.\nTo achieve this goal, we collect a large-scale faces-in-the-wild dataset with\nhuman annotations in the form: Expressions A and B are visually more similar\nwhen compared to expression C, and use this dataset to train a neural network\nthat produces a compact (16-dimensional) expression embedding. We\nexperimentally demonstrate that the learned embedding can be successfully used\nfor various applications such as expression retrieval, photo album\nsummarization, and emotion recognition. We also show that the embedding learned\nusing the proposed dataset performs better than several other embeddings\nlearned using existing emotion or action unit datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:00:06 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 22:46:44 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Vemulapalli", "Raviteja", ""], ["Agarwala", "Aseem", ""]]}, {"id": "1811.11296", "submitter": "Richard Marriott", "authors": "Richard T. Marriott, Sami Romdhani and Liming Chen", "title": "Taking Control of Intra-class Variation in Conditional GANs Under Weak\n  Supervision", "comments": null, "journal-ref": "in 2020 15th IEEE International Conference on Automatic Face and\n  Gesture Recognition (FG 2020) (FG), Buenos Aires, AR, 2020 pp. 283-290", "doi": "10.1109/FG47880.2020.00042", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are able to learn mappings between\nsimple, relatively low-dimensional, random distributions and points on the\nmanifold of realistic images in image-space. The semantics of this mapping,\nhowever, are typically entangled such that meaningful image properties cannot\nbe controlled independently of one another. Conditional GANs (cGANs) provide a\npotential solution to this problem, allowing specific semantics to be enforced\nduring training. This solution, however, depends on the availability of precise\nlabels, which are sometimes difficult or near impossible to obtain, e.g. labels\nrepresenting lighting conditions or describing the background. In this paper we\nintroduce a new formulation of the cGAN that is able to learn disentangled,\nmultivariate models of semantically meaningful variation and which has the\nadvantage of requiring only the weak supervision of binary attribute labels.\nFor example, given only labels of ambient / non-ambient lighting, our method is\nable to learn multivariate lighting models disentangled from other factors such\nas the identity and pose. We coin the method intra-class variation isolation\n(IVI) and the resulting network the IVI-GAN. We evaluate IVI-GAN on the CelebA\ndataset and on synthetic 3D morphable model data, learning to disentangle\nattributes such as lighting, pose, expression, and even the background.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:38:29 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 00:10:05 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Marriott", "Richard T.", ""], ["Romdhani", "Sami", ""], ["Chen", "Liming", ""]]}, {"id": "1811.11298", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Vitaly Levdik, Riashat Islam, Christopher M. Smith,\n  Petar Kormushev", "title": "Exploring Restart Distributions", "comments": "RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the generic approach of using an experience memory to help\nexploration by adapting a restart distribution. That is, given the capacity to\nreset the state with those corresponding to the agent's past observations, we\nhelp exploration by promoting faster state-space coverage via restarting the\nagent from a more diverse set of initial states, as well as allowing it to\nrestart in states associated with significant past experiences. This approach\nis compatible with both on-policy and off-policy methods. However, a caveat is\nthat altering the distribution of initial states could change the optimal\npolicies when searching within a restricted class of policies. To reduce this\nunsought learning bias, we evaluate our approach in deep reinforcement learning\nwhich benefits from the high representational capacity of deep neural networks.\nWe instantiate three variants of our approach, each inspired by an idea in the\ncontext of experience replay. Using these variants, we show that performance\ngains can be achieved, especially in hard exploration problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 22:40:01 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 21:28:54 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 03:42:32 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Tavakoli", "Arash", ""], ["Levdik", "Vitaly", ""], ["Islam", "Riashat", ""], ["Smith", "Christopher M.", ""], ["Kormushev", "Petar", ""]]}, {"id": "1811.11312", "submitter": "Rivindu Weerasekera", "authors": "Shamane Siriwardhana, Rivindu Weerasekera, Suranga Nanayakkara", "title": "Target Driven Visual Navigation with Hybrid Asynchronous Universal\n  Successor Representations", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to navigate to a target with minimal supervision and prior\nknowledge is critical to creating human-like assistive agents. Prior work on\nmap-based and map-less approaches have limited generalizability. In this paper,\nwe present a novel approach, Hybrid Asynchronous Universal Successor\nRepresentations (HAUSR), which overcomes the problem of generalizability to new\ngoals by adapting recent work on Universal Successor Representations with\nAsynchronous Actor-Critic Agents. We show that the agent was able to\nsuccessfully reach novel goals and we were able to quickly fine-tune the\nnetwork for adapting to new scenes. This opens up novel application scenarios\nwhere intelligent agents could learn from and adapt to a wide range of\nenvironments with minimal human input.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 23:37:19 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Weerasekera", "Rivindu", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "1811.11353", "submitter": "Alex De Sa'", "authors": "Alex G. C. de S\\'a, Cristiano G. Pimenta, Gisele L. Pappa and Alex A.\n  Freitas", "title": "Multi-label classification search space in the MEKA software", "comments": "Supplementary Material (GECCO'2020): Proposed Search Spaces", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This supplementary material aims to describe the proposed multi-label\nclassification (MLC) search spaces based on the MEKA and WEKA softwares. First,\nwe overview 26 MLC algorithms and meta-algorithms in MEKA, presenting their\nmain characteristics, such as hyper-parameters, dependencies and constraints.\nSecond, we review 28 single-label classification (SLC) algorithms,\npreprocessing algorithms and meta-algorithms in the WEKA software. These SLC\nalgorithms were also studied because they are part of the proposed MLC search\nspaces. Fundamentally, this occurs due to the problem transformation nature of\nseveral MLC algorithms used in this work. These algorithms transform an MLC\nproblem into one or several SLC problems in the first place and solve them with\nSLC model(s) in a next step. Therefore, understanding their main\ncharacteristics is crucial to this work. Finally, we present a formal\ndescription of the search spaces by proposing a context-free grammar that\nencompasses the 54 learning algorithms. This grammar basically comprehends the\npossible combinations, the constraints and dependencies among the learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:19:33 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 02:42:25 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 13:52:01 GMT"}, {"version": "v4", "created": "Thu, 14 May 2020 14:32:48 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2020 17:06:56 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["de S\u00e1", "Alex G. C.", ""], ["Pimenta", "Cristiano G.", ""], ["Pappa", "Gisele L.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "1811.11359", "submitter": "David Warde-Farley", "authors": "David Warde-Farley, Tom Van de Wiele, Tejas Kulkarni, Catalin Ionescu,\n  Steven Hansen, Volodymyr Mnih", "title": "Unsupervised Control Through Non-Parametric Discriminative Rewards", "comments": "10 pages + references & 5 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to control an environment without hand-crafted rewards or expert\ndata remains challenging and is at the frontier of reinforcement learning\nresearch. We present an unsupervised learning algorithm to train agents to\nachieve perceptually-specified goals using only a stream of observations and\nactions. Our agent simultaneously learns a goal-conditioned policy and a goal\nachievement reward function that measures how similar a state is to the goal\nstate. This dual optimization leads to a co-operative game, giving rise to a\nlearned reward function that reflects similarity in controllable aspects of the\nenvironment instead of distance in the space of observations. We demonstrate\nthe efficacy of our agent to learn, in an unsupervised manner, to reach a\ndiverse set of goals on three domains -- Atari, the DeepMind Control Suite and\nDeepMind Lab.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 02:35:24 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Warde-Farley", "David", ""], ["Van de Wiele", "Tom", ""], ["Kulkarni", "Tejas", ""], ["Ionescu", "Catalin", ""], ["Hansen", "Steven", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "1811.11435", "submitter": "Chiaki Sakama", "authors": "Chiaki Sakama, Hien D. Nguyen, Taisuke Sato, Katsumi Inoue", "title": "Partial Evaluation of Logic Programs in Vector Spaces", "comments": "Proceedings of the 11th Workshop on Answer Set Programming and Other\n  Computing Paradigms 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce methods of encoding propositional logic programs\nin vector spaces. Interpretations are represented by vectors and programs are\nrepresented by matrices. The least model of a definite program is computed by\nmultiplying an interpretation vector and a program matrix. To optimize\ncomputation in vector spaces, we provide a method of partial evaluation of\nprograms using linear algebra. Partial evaluation is done by unfolding rules in\na program, and it is realized in a vector space by multiplying program\nmatrices. We perform experiments using randomly generated programs and show\nthat partial evaluation has potential for realizing efficient computation in\nhuge scale of programs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 08:24:03 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Sakama", "Chiaki", ""], ["Nguyen", "Hien D.", ""], ["Sato", "Taisuke", ""], ["Inoue", "Katsumi", ""]]}, {"id": "1811.11501", "submitter": "Markus Hecher", "authors": "Johannes K. Fichte, Markus Hecher, Arne Meier", "title": "Counting Complexity for Reasoning in Abstract Argumentation", "comments": "Extended version of a paper published at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider counting and projected model counting of\nextensions in abstract argumentation for various semantics. When asking for\nprojected counts we are interested in counting the number of extensions of a\ngiven argumentation framework while multiple extensions that are identical when\nrestricted to the projected arguments count as only one projected extension. We\nestablish classical complexity results and parameterized complexity results\nwhen the problems are parameterized by treewidth of the undirected\nargumentation graph. To obtain upper bounds for counting projected extensions,\nwe introduce novel algorithms that exploit small treewidth of the undirected\nargumentation graph of the input instance by dynamic programming (DP). Our\nalgorithms run in time double or triple exponential in the treewidth depending\non the considered semantics. Finally, we take the exponential time hypothesis\n(ETH) into account and establish lower bounds of bounded treewidth algorithms\nfor counting extensions and projected extension.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 11:21:43 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Meier", "Arne", ""]]}, {"id": "1811.11522", "submitter": "Amey Kasar", "authors": "Sarang Mahajan and Amey Kasar", "title": "Towards Decentralization of Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Facebook uses Artificial Intelligence for targeting users with advertisements\nbased on the events in which they engage like sharing, liking, making comments,\nposts by a friend, a group creation, etcetera. Each user interacts with these\nevents in different ways, thus receiving different recommendations curated by\nFacebook's intelligent systems. Facebook segregates its users into chambers,\nfragmenting them into communities. The technology has completely changed the\nmarketing domain. It is however caught in a race for our finite attention with\na motive to make more and more money. Facebook is not a neutral product. It is\nprogrammed to get users addicted to it with a goal of gaining added information\nabout the users and optimizing the recommendations provided to the users\naccording to his or her preferences. This paper delineates how Facebook's\nrecommendation system works and presents three methods to safeguard human\nvulnerabilities exploited by Facebook and other corporations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 12:35:03 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Mahajan", "Sarang", ""], ["Kasar", "Amey", ""]]}, {"id": "1811.11597", "submitter": "Pascal Kerschke", "authors": "Pascal Kerschke, Holger H. Hoos, Frank Neumann, Heike Trautmann", "title": "Automated Algorithm Selection: Survey and Perspectives", "comments": "This is the author's final version, and the article has been accepted\n  for publication in Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been observed that for practically any computational problem that\nhas been intensely studied, different instances are best solved using different\nalgorithms. This is particularly pronounced for computationally hard problems,\nwhere in most cases, no single algorithm defines the state of the art; instead,\nthere is a set of algorithms with complementary strengths. This performance\ncomplementarity can be exploited in various ways, one of which is based on the\nidea of selecting, from a set of given algorithms, for each problem instance to\nbe solved the one expected to perform best. The task of automatically selecting\nan algorithm from a given set is known as the per-instance algorithm selection\nproblem and has been intensely studied over the past 15 years, leading to major\nimprovements in the state of the art in solving a growing number of discrete\ncombinatorial problems, including propositional satisfiability and AI planning.\nPer-instance algorithm selection also shows much promise for boosting\nperformance in solving continuous and mixed discrete/continuous optimisation\nproblems.\n  This survey provides an overview of research in automated algorithm\nselection, ranging from early and seminal works to recent and promising\napplication areas. Different from earlier work, it covers applications to\ndiscrete and continuous problems, and discusses algorithm selection in context\nwith conceptually related approaches, such as algorithm configuration,\nscheduling or portfolio selection. Since informative and cheaply computable\nproblem instance features provide the basis for effective per-instance\nalgorithm selection systems, we also provide an overview of such features for\ndiscrete and continuous problems. Finally, we provide perspectives on future\nwork in the area and discuss a number of open research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 14:43:49 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Kerschke", "Pascal", ""], ["Hoos", "Holger H.", ""], ["Neumann", "Frank", ""], ["Trautmann", "Heike", ""]]}, {"id": "1811.11623", "submitter": "Alexander Schindler", "authors": "Alexander Schindler, Martin Boyer, Andrew Lindley, David Schreiber,\n  Thomas Philipp", "title": "Large Scale Audio-Visual Video Analytics Platform for Forensic\n  Investigations of Terroristic Attacks", "comments": null, "journal-ref": "25th International Conference on MultiMedia Modeling (MMM2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forensic investigation of a terrorist attack poses a huge challenge to\nthe investigative authorities, as several thousand hours of video footage need\nto be spotted. To assist law enforcement agencies (LEA) in identifying suspects\nand securing evidences, we present a platform which fuses information of\nsurveillance cameras and video uploads from eyewitnesses. The platform\nintegrates analytical modules for different input-modalities on a scalable\narchitecture. Videos are analyzed according their acoustic and visual content.\nSpecifically, Audio Event Detection is applied to index the content according\nto attack-specific acoustic concepts. Audio similarity search is utilized to\nidentify similar video sequences recorded from different perspectives. Visual\nobject detection and tracking are used to index the content according to\nrelevant concepts. The heterogeneous results of the analytical modules are\nfused into a distributed index of visual and acoustic concepts to facilitate\nrapid start of investigations, following traits and investigating witness\nreports.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:22:03 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Schindler", "Alexander", ""], ["Boyer", "Martin", ""], ["Lindley", "Andrew", ""], ["Schreiber", "David", ""], ["Philipp", "Thomas", ""]]}, {"id": "1811.11682", "submitter": "David Rolnick", "authors": "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy P. Lillicrap,\n  Greg Wayne", "title": "Experience Replay for Continual Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is the problem of learning new tasks or knowledge while\nprotecting old knowledge and ideally generalizing from old experience to learn\nnew tasks faster. Neural networks trained by stochastic gradient descent often\ndegrade on old tasks when trained successively on new tasks with different data\ndistributions. This phenomenon, referred to as catastrophic forgetting, is\nconsidered a major hurdle to learning with non-stationary data or sequences of\nnew tasks, and prevents networks from continually accumulating knowledge and\nskills. We examine this issue in the context of reinforcement learning, in a\nsetting where an agent is exposed to tasks in a sequence. Unlike most other\nwork, we do not provide an explicit indication to the model of task boundaries,\nwhich is the most general circumstance for a learning agent exposed to\ncontinuous experience. While various methods to counteract catastrophic\nforgetting have recently been proposed, we explore a straightforward, general,\nand seemingly overlooked solution - that of using experience replay buffers for\nall past events - with a mixture of on- and off-policy learning, leveraging\nbehavioral cloning. We show that this strategy can still learn new tasks\nquickly yet can substantially reduce catastrophic forgetting in both Atari and\nDMLab domains, even matching the performance of methods that require task\nidentities. When buffer storage is constrained, we confirm that a simple\nmechanism for randomly discarding data allows a limited size buffer to perform\nalmost as well as an unbounded one.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:04:27 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 13:01:45 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Rolnick", "David", ""], ["Ahuja", "Arun", ""], ["Schwarz", "Jonathan", ""], ["Lillicrap", "Timothy P.", ""], ["Wayne", "Greg", ""]]}, {"id": "1811.11707", "submitter": "Vladimir Vlasov", "authors": "Vladimir Vlasov, Akela Drissner-Schmid, Alan Nichol", "title": "Few-Shot Generalization Across Dialogue Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning based dialogue managers are able to learn complex behaviors\nin order to complete a task, but it is not straightforward to extend their\ncapabilities to new domains. We investigate different policies' ability to\nhandle uncooperative user behavior, and how well expertise in completing one\ntask (such as restaurant reservations) can be reapplied when learning a new one\n(e.g. booking a hotel). We introduce the Recurrent Embedding Dialogue Policy\n(REDP), which embeds system actions and dialogue states in the same vector\nspace. REDP contains a memory component and attention mechanism based on a\nmodified Neural Turing Machine, and significantly outperforms a baseline LSTM\nclassifier on this task. We also show that both our architecture and baseline\nsolve the bAbI dialogue task, achieving 100% test accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:51:39 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Vlasov", "Vladimir", ""], ["Drissner-Schmid", "Akela", ""], ["Nichol", "Alan", ""]]}, {"id": "1811.11711", "submitter": "Josh Merel", "authors": "Josh Merel, Leonard Hasenclever, Alexandre Galashov, Arun Ahuja, Vu\n  Pham, Greg Wayne, Yee Whye Teh, Nicolas Heess", "title": "Neural probabilistic motor primitives for humanoid control", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of learning a single motor module that can flexibly\nexpress a range of behaviors for the control of high-dimensional physically\nsimulated humanoids. To do this, we propose a motor architecture that has the\ngeneral structure of an inverse model with a latent-variable bottleneck. We\nshow that it is possible to train this model entirely offline to compress\nthousands of expert policies and learn a motor primitive embedding space. The\ntrained neural probabilistic motor primitive system can perform one-shot\nimitation of whole-body humanoid behaviors, robustly mimicking unseen\ntrajectories. Additionally, we demonstrate that it is also straightforward to\ntrain controllers to reuse the learned motor primitive space to solve tasks,\nand the resulting movements are relatively naturalistic. To support the\ntraining of our model, we compare two approaches for offline policy cloning,\nincluding an experience efficient method which we call linear feedback policy\ncloning. We encourage readers to view a supplementary video (\nhttps://youtu.be/CaDEf-QcKwA ) summarizing our results.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 18:00:03 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 18:02:52 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Merel", "Josh", ""], ["Hasenclever", "Leonard", ""], ["Galashov", "Alexandre", ""], ["Ahuja", "Arun", ""], ["Pham", "Vu", ""], ["Wayne", "Greg", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "1811.11815", "submitter": "Georgios Mastorakis", "authors": "Georgios Mastorakis", "title": "Unrepresentative video data: A review and evaluation", "comments": "35 pages, 14 figures. Submitted to Computer Vision and Image\n  Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the quality and quantity of training data are\nsignificant factors which affect the development and performance of machine\nintelligence algorithms. Without representative data, neither scientists nor\nalgorithms would be able to accurately capture the visual details of objects,\nactions or scenes. An evaluation methodology which filters data quality does\nnot yet exist, and currently, the validation of the data depends solely on\nhuman factor. This study reviews several public datasets and discusses their\nlimitations and issues regarding quality, feasibility, adaptation and\navailability of training data. A simple approach to evaluate (i.e.\nautomatically \"clean\" samples) training data is proposed with the use of real\nevents recorded on the YouTube platform. This study focuses on action\nrecognition data and particularly on human fall detection datasets. However,\nthe limitations described in this paper apply in virtually all datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 20:28:11 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 21:14:00 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Mastorakis", "Georgios", ""]]}, {"id": "1811.11876", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and\n  Encoding in Brain-Computer Interfaces", "comments": "Invited submission to the journal Current Opinion in Neurobiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of brain-computer interfaces is poised to advance from the\ntraditional goal of controlling prosthetic devices using brain signals to\ncombining neural decoding and encoding within a single neuroprosthetic device.\nSuch a device acts as a \"co-processor\" for the brain, with applications ranging\nfrom inducing Hebbian plasticity for rehabilitation after brain injury to\nreanimating paralyzed limbs and enhancing memory. We review recent progress in\nsimultaneous decoding and encoding for closed-loop control and plasticity\ninduction. To address the challenge of multi-channel decoding and encoding, we\nintroduce a unifying framework for developing brain co-processors based on\nartificial neural networks and deep learning. These \"neural co-processors\" can\nbe used to jointly optimize cost functions with the nervous system to achieve\ndesired behaviors ranging from targeted neuro-rehabilitation to augmentation of\nbrain function.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:13:24 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 18:56:32 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "1811.11880", "submitter": "Andrew McGough", "authors": "Daniel Justus, John Brennan, Stephen Bonner, Andrew Stephen McGough", "title": "Predicting the Computational Cost of Deep Learning Models", "comments": "Accepted for publication at the IEEE International Conference on Big\n  Data, (C) IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is rapidly becoming a go-to tool for many artificial\nintelligence problems due to its ability to outperform other approaches and\neven humans at many problems. Despite its popularity we are still unable to\naccurately predict the time it will take to train a deep learning network to\nsolve a given problem. This training time can be seen as the product of the\ntraining time per epoch and the number of epochs which need to be performed to\nreach the desired level of accuracy. Some work has been carried out to predict\nthe training time for an epoch -- most have been based around the assumption\nthat the training time is linearly related to the number of floating point\noperations required. However, this relationship is not true and becomes\nexacerbated in cases where other activities start to dominate the execution\ntime. Such as the time to load data from memory or loss of performance due to\nnon-optimal parallel execution. In this work we propose an alternative approach\nin which we train a deep learning network to predict the execution time for\nparts of a deep learning network. Timings for these individual parts can then\nbe combined to provide a prediction for the whole execution time. This has\nadvantages over linear approaches as it can model more complex scenarios. But,\nalso, it has the ability to predict execution times for scenarios unseen in the\ntraining data. Therefore, our approach can be used not only to infer the\nexecution time for a batch, or entire epoch, but it can also support making a\nwell-informed choice for the appropriate hardware and model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:36:50 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Justus", "Daniel", ""], ["Brennan", "John", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "1811.11925", "submitter": "Vaneet Aggarwal", "authors": "Mridul Agarwal and Vaneet Aggarwal", "title": "Regret Bounds for Stochastic Combinatorial Multi-Armed Bandits with\n  Linear Space Complexity", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems face the dilemma of choosing best $K$ out of $N$\noptions at a given time instant. This setup can be modelled as combinatorial\nbandit which chooses $K$ out of $N$ arms at each time, with an aim to achieve\nan efficient tradeoff between exploration and exploitation. This is the first\nwork for combinatorial bandit where the reward received can be a non-linear\nfunction of the chosen $K$ arms. The direct use of multi-armed bandit requires\nchoosing among $N$-choose-$K$ options making the state space large. In this\npaper, we present a novel algorithm which is computationally efficient and the\nstorage is linear in $N$. The proposed algorithm is a divide-and-conquer based\nstrategy, that we call CMAB-SM. Further, the proposed algorithm achieves a\nregret bound of $\\tilde O(K^\\frac{1}{2}N^\\frac{1}{3}T^\\frac{2}{3})$ for a time\nhorizon $T$, which is sub-linear in all parameters $T$, $N$, and $K$. The\nevaluation results on different reward functions and arm distribution functions\nshow significantly improved performance as compared to standard multi-armed\nbandit approach with $\\binom{N}{K}$ choices.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:12:37 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1811.11945", "submitter": "Yonghao Jin", "authors": "Yonghao Jin, Fei Li and Hong Yu", "title": "HYPE: A High Performing NLP System for Automatically Detecting\n  Hypoglycemia Events from Electronic Health Record Notes", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/104", "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypoglycemia is common and potentially dangerous among those treated for\ndiabetes. Electronic health records (EHRs) are important resources for\nhypoglycemia surveillance. In this study, we report the development and\nevaluation of deep learning-based natural language processing systems to\nautomatically detect hypoglycemia events from the EHR narratives. Experts in\nPublic Health annotated 500 EHR notes from patients with diabetes. We used this\nannotated dataset to train and evaluate HYPE, supervised NLP systems for\nhypoglycemia detection. In our experiment, the convolutional neural network\nmodel yielded promising performance $Precision=0.96 \\pm 0.03, Recall=0.86 \\pm\n0.03, F1=0.91 \\pm 0.03$ in a 10-fold cross-validation setting. Despite the\nannotated data is highly imbalanced, our CNN-based HYPE system still achieved a\nhigh performance for hypoglycemia detection. HYPE could be used for EHR-based\nhypoglycemia surveillance and to facilitate clinicians for timely treatment of\nhigh-risk patients.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 03:40:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Jin", "Yonghao", ""], ["Li", "Fei", ""], ["Yu", "Hong", ""]]}, {"id": "1811.11987", "submitter": "Laurent Bou\\'e", "authors": "Laurent Bou\\'e", "title": "Deep learning for pedestrians: backpropagation in CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this document is to provide a pedagogical introduction to the\nmain concepts underpinning the training of deep neural networks using gradient\ndescent; a process known as backpropagation. Although we focus on a very\ninfluential class of architectures called \"convolutional neural networks\"\n(CNNs) the approach is generic and useful to the machine learning community as\na whole. Motivated by the observation that derivations of backpropagation are\noften obscured by clumsy index-heavy narratives that appear somewhat\nmathemagical, we aim to offer a conceptually clear, vectorized description that\narticulates well the higher level logic. Following the principle of \"writing is\nnature's way of letting you know how sloppy your thinking is\", we try to make\nthe calculations meticulous, self-contained and yet as intuitive as possible.\nTaking nothing for granted, ample illustrations serve as visual guides and an\nextensive bibliography is provided for further explorations.\n  (For the sake of clarity, long mathematical derivations and visualizations\nhave been broken up into short \"summarized views\" and longer \"detailed views\"\nencoded into the PDF as optional content groups. Some figures contain\nanimations designed to illustrate important concepts in a more engaging style.\nFor these reasons, we advise to download the document locally and open it using\nAdobe Acrobat Reader. Other viewers were not tested and may not render the\ndetailed views, animations correctly.)\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 07:00:09 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Bou\u00e9", "Laurent", ""]]}, {"id": "1811.12028", "submitter": "Naoto Yanai", "authors": "Hiromasa Kitai, Jason Paul Cruz, Naoto Yanai, Naohisa Nishida, Tatsumi\n  Oba, Yuji Unagami, Tadanori Teruya, Nuttapong Attrapadung, Takahiro Matsuda,\n  Goichiro Hanaoka", "title": "MOBIUS: Model-Oblivious Binarized Neural Networks", "comments": null, "journal-ref": "IEEE Access (Volume: 7, Issue:1. 04 September 2019)", "doi": "10.1109/ACCESS.2019.2939410", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A privacy-preserving framework in which a computational resource provider\nreceives encrypted data from a client and returns prediction results without\ndecrypting the data, i.e., oblivious neural network or encrypted prediction,\nhas been studied in machine learning that provides prediction services. In this\nwork, we present MOBIUS (Model-Oblivious BInary neUral networkS), a new system\nthat combines Binarized Neural Networks (BNNs) and secure computation based on\nsecret sharing as tools for scalable and fast privacy-preserving machine\nlearning. BNNs improve computational performance by binarizing values in\ntraining to $-1$ and $+1$, while secure computation based on secret sharing\nprovides fast and various computations under encrypted forms via modulo\noperations with a short bit length. However, combining these tools is not\ntrivial because their operations have different algebraic structures and the\nuse of BNNs downgrades prediction accuracy in general. MOBIUS uses improved\nprocedures of BNNs and secure computation that have compatible algebraic\nstructures without downgrading prediction accuracy. We created an\nimplementation of MOBIUS in C++ using the ABY library (NDSS 2015). We then\nconducted experiments using the MNIST dataset, and the results show that MOBIUS\ncan return a prediction within 0.76 seconds, which is six times faster than\nSecureML (IEEE S\\&P 2017). MOBIUS allows a client to request for encrypted\nprediction and allows a trainer to obliviously publish an encrypted model to a\ncloud provided by a computational resource provider, i.e., without revealing\nthe original model itself to the provider.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 09:18:38 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kitai", "Hiromasa", ""], ["Cruz", "Jason Paul", ""], ["Yanai", "Naoto", ""], ["Nishida", "Naohisa", ""], ["Oba", "Tatsumi", ""], ["Unagami", "Yuji", ""], ["Teruya", "Tadanori", ""], ["Attrapadung", "Nuttapong", ""], ["Matsuda", "Takahiro", ""], ["Hanaoka", "Goichiro", ""]]}, {"id": "1811.12083", "submitter": "Nico Potyka", "authors": "Nico Potyka", "title": "A Polynomial-time Fragment of Epistemic Probabilistic Argumentation\n  (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic argumentation allows reasoning about argumentation problems in\na way that is well-founded by probability theory. However, in practice, this\napproach can be severely limited by the fact that probabilities are defined by\nadding an exponential number of terms. We show that this exponential blowup can\nbe avoided in an interesting fragment of epistemic probabilistic argumentation\nand that some computational problems that have been considered intractable can\nbe solved in polynomial time. We give efficient convex programming formulations\nfor these problems and explore how far our fragment can be extended without\nloosing tractability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:52:21 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:25:25 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Potyka", "Nico", ""]]}, {"id": "1811.12127", "submitter": "Anton Fuxjaeger", "authors": "Anton Fuxjaeger and Vaishak Belle", "title": "Scaling up Probabilistic Inference in Linear and Non-Linear Hybrid\n  Domains by Leveraging Knowledge Compilation", "comments": "In proceedings of ICAART, 2020. A version also appears in AAAI\n  Workshop: Statistical Relational Artificial Intelligence (StarAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted model integration (WMI) extends weighted model counting (WMC) in\nproviding a computational abstraction for probabilistic inference in mixed\ndiscrete-continuous domains. WMC has emerged as an assembly language for\nstate-of-the-art reasoning in Bayesian networks, factor graphs, probabilistic\nprograms and probabilistic databases. In this regard, WMI shows immense promise\nto be much more widely applicable, especially as many real-world applications\ninvolve attribute and feature spaces that are continuous and mixed.\nNonetheless, state-of-the-art tools for WMI are limited and less mature than\ntheir propositional counterparts. In this work, we propose a new implementation\nregime that leverages propositional knowledge compilation for scaling up\ninference. In particular, we use sentential decision diagrams, a tractable\nrepresentation of Boolean functions, as the underlying model counting and model\nenumeration scheme. Our regime performs competitively to state-of-the-art WMI\nsystems but is also shown to handle a specific class of non-linear constraints\nover non-linear potentials.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:24:23 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 15:15:37 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Fuxjaeger", "Anton", ""], ["Belle", "Vaishak", ""]]}, {"id": "1811.12146", "submitter": "Michael Hartisch", "authors": "Michael Hartisch and Ulf Lorenz", "title": "Game Tree Search in a Robust Multistage Optimization Framework:\n  Exploiting Pruning Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate pruning in search trees of so-called quantified integer linear\nprograms (QIPs). QIPs consist of a set of linear inequalities and a minimax\nobjective function, where some variables are existentially and others are\nuniversally quantified. They can be interpreted as two-person zero-sum games\nbetween an existential and a universal player on the one hand, or multistage\noptimization problems under uncertainty on the other hand. Solutions are\nso-called winning strategies for the existential player that specify how to\nreact on moves of the universal player - i.e. certain assignments of\nuniversally quantified variables - to certainly win the game.\n  QIPs can be solved with the help of game tree search that is enhanced with\nnon-chronological back-jumping. We develop and theoretically substantiate\npruning techniques based upon (algebraic) properties similar to pruning\nmechanisms known from linear programming and quantified boolean formulas. The\npresented Strategic Copy-Pruning mechanism allows to \\textit{implicitly} deduce\nthe existence of a strategy in linear time (by static examination of the\nQIP-matrix) without explicitly traversing the strategy itself. We show that the\nimplementation of our findings can massively speed up the search process.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 14:00:12 GMT"}], "update_date": "2018-12-02", "authors_parsed": [["Hartisch", "Michael", ""], ["Lorenz", "Ulf", ""]]}, {"id": "1811.12155", "submitter": "Christian Jilek", "authors": "Christian Jilek, Yannick Runge, Claudia Nieder\\'ee, Heiko Maus, Tobias\n  Tempel, Andreas Dengel, Christian Frings", "title": "Managed Forgetting to Support Information Management and Knowledge Work", "comments": "10 pages, 2 figures, preprint, final version to appear in KI -\n  K\\\"unstliche Intelligenz, Special Issue: Intentional Forgetting", "journal-ref": "KI - K\\\"nstliche Intelligenz, German Journal on Artificial\n  Intelligence, 33.1 (Mar. 2019), pp. 45-55, Springer, 2019", "doi": "10.1007/s13218-018-00568-9", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trends like digital transformation even intensify the already overwhelming\nmass of information knowledge workers face in their daily life. To counter\nthis, we have been investigating knowledge work and information management\nsupport measures inspired by human forgetting. In this paper, we give an\noverview of solutions we have found during the last five years as well as\nchallenges that still need to be tackled. Additionally, we share experiences\ngained with the prototype of a first forgetful information system used 24/7 in\nour daily work for the last three years. We also address the untapped potential\nof more explicated user context as well as features inspired by Memory\nInhibition, which is our current focus of research.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 09:33:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Jilek", "Christian", ""], ["Runge", "Yannick", ""], ["Nieder\u00e9e", "Claudia", ""], ["Maus", "Heiko", ""], ["Tempel", "Tobias", ""], ["Dengel", "Andreas", ""], ["Frings", "Christian", ""]]}, {"id": "1811.12157", "submitter": "Ruiqi Hu", "authors": "Ruiqi Hu, Celina Ping Yu, Sai-Fu Fung, Shirui Pan, Haishuai Wang,\n  Guodong Long", "title": "Universal Network Representation for Heterogeneous Information Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation aims to represent the nodes in a network as continuous\nand compact vectors, and has attracted much attention in recent years due to\nits ability to capture complex structure relationships inside networks.\nHowever, existing network representation methods are commonly designed for\nhomogeneous information networks where all the nodes (entities) of a network\nare of the same type, e.g., papers in a citation network. In this paper, we\npropose a universal network representation approach (UNRA), that represents\ndifferent types of nodes in heterogeneous information networks in a continuous\nand common vector space. The UNRA is built on our latest mutually updated\nneural language module, which simultaneously captures inter-relationship among\nhomogeneous nodes and node-content correlation. Relationships between different\ntypes of nodes are also assembled and learned in a unified framework.\nExperiments validate that the UNRA achieves outstanding performance, compared\nto six other state-of-the-art algorithms, in node representation, node\nclassification, and network visualization. In node classification, the UNRA\nachieves a 3\\% to 132\\% performance improvement in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 13:43:01 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Hu", "Ruiqi", ""], ["Yu", "Celina Ping", ""], ["Fung", "Sai-Fu", ""], ["Pan", "Shirui", ""], ["Wang", "Haishuai", ""], ["Long", "Guodong", ""]]}, {"id": "1811.12164", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, and Srinivasan Parthasarathy", "title": "Symmetrization for Embedding Directed Graphs", "comments": "has been accepted to The Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI 2019) Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, one has seen a surge of interest in developing such methods\nincluding ones for learning such representations for (undirected) graphs (while\npreserving important properties). However, most of the work to date on\nembedding graphs has targeted undirected networks and very little has focused\non the thorny issue of embedding directed networks. In this paper, we instead\npropose to solve the directed graph embedding problem via a two-stage approach:\nin the first stage, the graph is symmetrized in one of several possible ways,\nand in the second stage, the so-obtained symmetrized graph is embedded using\nany state-of-the-art (undirected) graph embedding algorithm. Note that it is\nnot the objective of this paper to propose a new (undirected) graph embedding\nalgorithm or discuss the strengths and weaknesses of existing ones; all we are\nsaying is that whichever be the suitable graph embedding algorithm, it will fit\nin the above proposed symmetrization framework.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 14:20:44 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sun", "Jiankai", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1811.12165", "submitter": "Yukio Ohsawa", "authors": "Yukio Ohsawa", "title": "Graph based Entropy for Detecting Explanatory Signs of Changes in Market", "comments": "21 pages, 7 figures, 2 Tables. Copyright remains with the author", "journal-ref": "Rev Socionetwork Strat (2018)", "doi": "10.1007/s12626-018-0023-8", "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph based entropy, an index of the diversity of events in their\ndistribution to parts of a co-occurrence graph, is proposed for detecting signs\nof structural changes in the data that are informative in explaining latent\ndynamics of consumers behavior. For obtaining graph-based entropy, connected\nsubgraphs are first obtained from the graph of co-occurrences of items in the\ndata. Then, the distribution of items occurring in events in the data to these\nsub-graphs is reflected on the value of graph-based entropy. For the data on\nthe position of sale, a change in this value is regarded as a sign of the\nappearance, the separation, the disappearance, or the uniting of consumers\ninterests. These phenomena are regarded as the signs of dynamic changes in\nconsumers behavior that may be the effects of external events and information.\nExperiments show that graph-based entropy outperforms baseline methods that can\nbe used for change detection, in explaining substantial changes and their signs\nin consumers preference of items in supermarket stores.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 04:52:16 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Ohsawa", "Yukio", ""]]}, {"id": "1811.12177", "submitter": "Christian Jilek", "authors": "Christian Jilek, Jessica Chwalek, Sven Schwarz, Markus Schr\\\"oder,\n  Heiko Maus, Andreas Dengel", "title": "Advanced Memory Buoyancy for Forgetful Information Systems", "comments": "15 pages, 11 figures, preprint, final version to appear in AIS\n  Transactions on Enterprise Systems, Special Issue: Intentional Forgetting in\n  Organizations and Work Settings", "journal-ref": "AIS Transactions on Enterprise Systems. 4, 1 (May 2019)", "doi": "10.30844/ais-tes.v4i1.11", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge workers face an ever increasing flood of information in their daily\nlives. To counter this and provide better support for information management\nand knowledge work in general, we have been investigating solutions inspired by\nhuman forgetting since 2013. These solutions are based on Semantic Desktop (SD)\nand Managed Forgetting (MF) technology. A key concept of the latter is the\nso-called Memory Buoyancy (MB), which is intended to represent an information\nitem's current value for the user and allows to employ forgetting mechanisms.\nThe SD thus continuously performs information value assessment updating MB and\ntriggering respective MF measures. We extended an SD-based organizational\nmemory system, which we have been using in daily work for over seven years now,\nwith MF mechanisms directly embedding them in daily activities, too, and\nenabling us to test and optimize them in real-world scenarios. In this paper,\nwe first present our initial version of MB and discuss success and failure\nstories we have been experiencing with it during three years of practical\nusage. We learned from cognitive psychology that our previous research on\ncontext can be beneficial for MF. Thus, we created an advanced MB version\nespecially taking user context, and in particular context switches, into\naccount. These enhancements as well as a first prototypical implementation are\npresented, too.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 09:29:17 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Jilek", "Christian", ""], ["Chwalek", "Jessica", ""], ["Schwarz", "Sven", ""], ["Schr\u00f6der", "Markus", ""], ["Maus", "Heiko", ""], ["Dengel", "Andreas", ""]]}, {"id": "1811.12182", "submitter": "Vahid Pourahmadi Dr.", "authors": "Peyman Yazdanian and Vahid Pourahmadi", "title": "DeepPos: Deep Supervised Autoencoder Network for CSI Based Indoor\n  Localization", "comments": "10 pages, 15 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread mobile devices facilitated the emergence of many new\napplications and services. Among them are location-based services (LBS) that\nprovide services based on user's location. Several techniques have been\npresented to enable LBS even in indoor environments where Global Positioning\nSystem (GPS) has low localization accuracy. These methods use some environment\nmeasurements (like Channel State Information (CSI) or Received Signal Strength\n(RSS)) for user localization. In this paper, we will use CSI and a novel deep\nlearning algorithm to design a robust and efficient system for indoor\nlocalization. More precisely, we use supervised autoencoder (SAE) to model the\nenvironment using the data collected during the training phase. Then, during\nthe testing phase, we use the trained model and estimate the coordinates of the\nunknown point by checking different possible labels. Unlike the previous\nfingerprinting approaches, in this work, we do not store the {CSI/RSS} of\nfingerprints and instead we model the environment only with a single SAE. The\nperformance of the proposed scheme is then evaluated in two indoor environments\nand compared with that of similar approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:30:36 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Yazdanian", "Peyman", ""], ["Pourahmadi", "Vahid", ""]]}, {"id": "1811.12199", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Marco Cavallo and \\c{C}a\\u{g}atay Demiralp", "title": "A Visual Interaction Framework for Dimensionality Reduction Based Data\n  Exploration", "comments": "CHI'18. arXiv admin note: text overlap with arXiv:1707.04281", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is a common method for analyzing and visualizing\nhigh-dimensional data. However, reasoning dynamically about the results of a\ndimensionality reduction is difficult. Dimensionality-reduction algorithms use\ncomplex optimizations to reduce the number of dimensions of a dataset, but\nthese new dimensions often lack a clear relation to the initial data\ndimensions, thus making them difficult to interpret. Here we propose a visual\ninteraction framework to improve dimensionality-reduction based exploratory\ndata analysis. We introduce two interaction techniques, forward projection and\nbackward projection, for dynamically reasoning about dimensionally reduced\ndata. We also contribute two visualization techniques, prolines and feasibility\nmaps, to facilitate the effective use of the proposed interactions. We apply\nour framework to PCA and autoencoder-based dimensionality reductions. Through\ndata-exploration examples, we demonstrate how our visual interactions can\nimprove the use of dimensionality reduction in exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 01:47:49 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Cavallo", "Marco", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "1811.12211", "submitter": "Wei Wang", "authors": "Jiangyi Liu, Chunping Wang and Wei Wang", "title": "Particle Probability Hypothesis Density Filter based on Pairwise Markov\n  Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most multi-target tracking filters assume that one target and its observation\nfollow a Hidden Markov Chain (HMC) model, but the implicit independence\nassumption of HMC model is invalid in many practical applications, and a\nPairwise Markov Chain (PMC) model is more universally suitable than traditional\nHMC model. A particle probability hypothesis density filter based on PMC model\n(PF-PMC-PHD) is proposed for the nonlinear multi-target tracking system.\nSimulation results show the effectiveness of PF-PMC-PHD filter, and that the\ntracking performance of PF-PMC-PHD filter is superior to the particle PHD\nfilter based on HMC model in a scenario where we kept the local physical\nproperties of nonlinear and Gaussian HMC models while relaxing their\nindependence assumption.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 04:56:32 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Liu", "Jiangyi", ""], ["Wang", "Chunping", ""], ["Wang", "Wei", ""]]}, {"id": "1811.12231", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge,\n  Felix A. Wichmann, Wieland Brendel", "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias\n  improves accuracy and robustness", "comments": "Accepted at ICLR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 13:59:09 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Geirhos", "Robert", ""], ["Rubisch", "Patricia", ""], ["Michaelis", "Claudio", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "1811.12234", "submitter": "Thomas Janssoone", "authors": "Thomas Janssoone and Cl\\'emence Bic and Dorra Kanoun and Pierre Hornus\n  and Pierre Rinder", "title": "Machine Learning on Electronic Health Records: Models and Features\n  Usages to predict Medication Non-Adherence", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adherence can be defined as \"the extent to which patients take their\nmedications as prescribed by their healthcare providers\"[Osterberg and\nBlaschke, 2005]. World Health Organization's reports point out that, in\ndeveloped countries, only about 50% of patients with chronic diseases correctly\nfollow their treatments. This severely compromises the efficiency of long-term\ntherapy and increases the cost of health services. We propose in this paper\ndifferent models of patient drug consumption in breast cancer treatments. The\naim of these different approaches is to predict medication non-adherence while\ngiving insights to doctors of the underlying reasons of these illegitimate\ndrop-outs. Working with oncologists, we show the interest of Machine- Learning\nalgorithms fined tune by the feedback of experts to estimate a risk score of a\npatient's non-adherence and thus improve support throughout their care path.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:08:55 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Janssoone", "Thomas", ""], ["Bic", "Cl\u00e9mence", ""], ["Kanoun", "Dorra", ""], ["Hornus", "Pierre", ""], ["Rinder", "Pierre", ""]]}, {"id": "1811.12238", "submitter": "Siyu Huang", "authors": "Siyu Huang, Zhi-Qi Cheng, Xi Li, Xiao Wu, Zhongfei Zhang, Alexander\n  Hauptmann", "title": "Perceiving Physical Equation by Observing Visual Scenarios", "comments": "NIPS 2018 Workshop on Modeling the Physical World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring universal laws of the environment is an important ability of human\nintelligence as well as a symbol of general AI. In this paper, we take a step\ntoward this goal such that we introduce a new challenging problem of inferring\ninvariant physical equation from visual scenarios. For instance, teaching a\nmachine to automatically derive the gravitational acceleration formula by\nwatching a free-falling object. To tackle this challenge, we present a novel\npipeline comprised of an Observer Engine and a Physicist Engine by respectively\nimitating the actions of an observer and a physicist in the real world.\nGenerally, the Observer Engine watches the visual scenarios and then extracting\nthe physical properties of objects. The Physicist Engine analyses these data\nand then summarizing the inherent laws of object dynamics. Specifically, the\nlearned laws are expressed by mathematical equations such that they are more\ninterpretable than the results given by common probabilistic models.\nExperiments on synthetic videos have shown that our pipeline is able to\ndiscover physical equations on various physical worlds with different visual\nappearances.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:13:26 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Huang", "Siyu", ""], ["Cheng", "Zhi-Qi", ""], ["Li", "Xi", ""], ["Wu", "Xiao", ""], ["Zhang", "Zhongfei", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1811.12276", "submitter": "Parminder Bhatia", "authors": "Mengqi Jin, Mohammad Taha Bahadori, Aaron Colak, Parminder Bhatia,\n  Busra Celikkaya, Ram Bhakta, Selvan Senthivel, Mohammed Khalilia, Daniel\n  Navarro, Borui Zhang, Tiberiu Doman, Arun Ravi, Matthieu Liger, Taha\n  Kass-hout", "title": "Improving Hospital Mortality Prediction with Medical Named Entities and\n  Multimodal Learning", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical text provides essential information to estimate the acuity of a\npatient during hospital stays in addition to structured clinical data. In this\nstudy, we explore how clinical text can complement a clinical predictive\nlearning task. We leverage an internal medical natural language processing\nservice to perform named entity extraction and negation detection on clinical\nnotes and compose selected entities into a new text corpus to train document\nrepresentations. We then propose a multimodal neural network to jointly train\ntime series signals and unstructured clinical text representations to predict\nthe in-hospital mortality risk for ICU patients. Our model outperforms the\nbenchmark by 2% AUC.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 16:10:41 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 01:37:07 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Jin", "Mengqi", ""], ["Bahadori", "Mohammad Taha", ""], ["Colak", "Aaron", ""], ["Bhatia", "Parminder", ""], ["Celikkaya", "Busra", ""], ["Bhakta", "Ram", ""], ["Senthivel", "Selvan", ""], ["Khalilia", "Mohammed", ""], ["Navarro", "Daniel", ""], ["Zhang", "Borui", ""], ["Doman", "Tiberiu", ""], ["Ravi", "Arun", ""], ["Liger", "Matthieu", ""], ["Kass-hout", "Taha", ""]]}, {"id": "1811.12354", "submitter": "Yoav Artzi", "authors": "Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, and Yoav Artzi", "title": "Touchdown: Natural Language Navigation and Spatial Reasoning in Visual\n  Street Environments", "comments": "arXiv admin note: text overlap with arXiv:1809.00786", "journal-ref": "Published in CVPR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of jointly reasoning about language and vision through a\nnavigation and spatial reasoning task. We introduce the Touchdown task and\ndataset, where an agent must first follow navigation instructions in a\nreal-life visual urban environment, and then identify a location described in\nnatural language to find a hidden object at the goal position. The data\ncontains 9,326 examples of English instructions and spatial descriptions paired\nwith demonstrations. Empirical analysis shows the data presents an open\nchallenge to existing methods, and qualitative linguistic analysis shows that\nthe data displays richer use of spatial reasoning compared to related\nresources.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:06:22 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 02:17:42 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 17:27:38 GMT"}, {"version": "v4", "created": "Sat, 6 Apr 2019 17:35:24 GMT"}, {"version": "v5", "created": "Wed, 10 Apr 2019 18:43:40 GMT"}, {"version": "v6", "created": "Mon, 3 Jun 2019 16:24:49 GMT"}, {"version": "v7", "created": "Sat, 16 May 2020 23:36:36 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Howard", ""], ["Suhr", "Alane", ""], ["Misra", "Dipendra", ""], ["Snavely", "Noah", ""], ["Artzi", "Yoav", ""]]}, {"id": "1811.12359", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf, Olivier Bachem", "title": "Challenging Common Assumptions in the Unsupervised Learning of\n  Disentangled Representations", "comments": null, "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning (ICML 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key idea behind the unsupervised learning of disentangled representations\nis that real-world data is generated by a few explanatory factors of variation\nwhich can be recovered by unsupervised learning algorithms. In this paper, we\nprovide a sober look at recent progress in the field and challenge some common\nassumptions. We first theoretically show that the unsupervised learning of\ndisentangled representations is fundamentally impossible without inductive\nbiases on both the models and the data. Then, we train more than 12000 models\ncovering most prominent methods and evaluation metrics in a reproducible\nlarge-scale experimental study on seven different data sets. We observe that\nwhile the different methods successfully enforce properties ``encouraged'' by\nthe corresponding losses, well-disentangled models seemingly cannot be\nidentified without supervision. Furthermore, increased disentanglement does not\nseem to lead to a decreased sample complexity of learning for downstream tasks.\nOur results suggest that future work on disentanglement learning should be\nexplicit about the role of inductive biases and (implicit) supervision,\ninvestigate concrete benefits of enforcing disentanglement of the learned\nrepresentations, and consider a reproducible experimental setup covering\nseveral data sets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 18:10:40 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 16:42:28 GMT"}, {"version": "v3", "created": "Tue, 5 Mar 2019 17:15:53 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 08:58:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Locatello", "Francesco", ""], ["Bauer", "Stefan", ""], ["Lucic", "Mario", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""]]}, {"id": "1811.12454", "submitter": "Eduardo Tavares Costa", "authors": "R. C. Fernandes, T. M. Machado, H. J. Onisto, A. D. Mu\\~noz, R. O.\n  Silva, L. R. Domingues, G. C. Fonseca, J. E. Bertuzzo, M. T. Pereira, B.\n  Biazotto, E. T. Costa", "title": "A rule-based system proposal to aid in the evaluation and\n  decision-making in external beam radiation treatment planning", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As part of a plan launched by the Ministry of Health of Brazil to increase\nthe availability of linear accelerators for radiotherapy treatment for the\nwhole country, for which Varian Medical Systems company has won the bidding, a\ntechnical cooperation agreement was signed inviting Brazilian Scientific and\nTechnological Institutions to participate in a technology transfer program. As\na result, jointly, the Eldorado Research Institute and the Center for\nBiomedical Engineering of the University of Campinas presents in this work, the\nconcepts behind of a proposed rule engine to aid in the evaluation and\ndecision-making in radiotherapy treatment planning. Normally, the determination\nof the radiation dose for a given patient is a complex and intensive procedure,\nwhich requires a lot of domain knowledge and subjective experience from the\noncologists' team. In order to help them in this complex task, and\nadditionally, provide an auxiliary tool for less experienced oncologists, it is\npresented a project conception of a software system that will make use of a\nhybrid data-oriented approach. The proposed rule engine will apply both\ninference mechanism and expression evaluation to verify and accredit the\nquality of an external beam radiation treatment plan by considering, at first,\nthe 3D-conformal radiotherapy (3DCRT) technique.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 19:49:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Fernandes", "R. C.", ""], ["Machado", "T. M.", ""], ["Onisto", "H. J.", ""], ["Mu\u00f1oz", "A. D.", ""], ["Silva", "R. O.", ""], ["Domingues", "L. R.", ""], ["Fonseca", "G. C.", ""], ["Bertuzzo", "J. E.", ""], ["Pereira", "M. T.", ""], ["Biazotto", "B.", ""], ["Costa", "E. T.", ""]]}, {"id": "1811.12455", "submitter": "Catarina Moreira", "authors": "Catarina Moreira", "title": "Unifying Decision-Making: a Review on Evolutionary Theories on\n  Rationality and Cognitive Biases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we make a review on the concepts of rationality across several\ndifferent fields, namely in economics, psychology and evolutionary biology and\nbehavioural ecology. We review how processes like natural selection can help us\nunderstand the evolution of cognition and how cognitive biases might be a\nconsequence of this natural selection. In the end we argue that humans are not\nirrational, but rather rationally bounded and we complement the discussion on\nhow quantum cognitive models can contribute for the modelling and prediction of\nhuman paradoxical decisions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 19:56:19 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Moreira", "Catarina", ""]]}, {"id": "1811.12470", "submitter": "Arjun Nitin Bhagoji", "authors": "Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, Seraphin\n  Calo", "title": "Analyzing Federated Learning through an Adversarial Lens", "comments": "Extended version of paper accepted to ICML 2019, code available at\n  https://github.com/inspire-group/ModelPoisoning; 19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning distributes model training among a multitude of agents,\nwho, guided by privacy concerns, perform training using their local data but\nshare only model parameter updates, for iterative aggregation at the server. In\nthis work, we explore the threat of model poisoning attacks on federated\nlearning initiated by a single, non-colluding malicious agent where the\nadversarial objective is to cause the model to misclassify a set of chosen\ninputs with high confidence. We explore a number of strategies to carry out\nthis attack, starting with simple boosting of the malicious agent's update to\novercome the effects of other agents' updates. To increase attack stealth, we\npropose an alternating minimization strategy, which alternately optimizes for\nthe training loss and the adversarial objective. We follow up by using\nparameter estimation for the benign agents' updates to improve on attack\nsuccess. Finally, we use a suite of interpretability techniques to generate\nvisual explanations of model decisions for both benign and malicious models and\nshow that the explanations are nearly visually indistinguishable. Our results\nindicate that even a highly constrained adversary can carry out model poisoning\nattacks while simultaneously maintaining stealth, thus highlighting the\nvulnerability of the federated learning setting and the need to develop\neffective defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 20:27:14 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 17:14:03 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 22:04:18 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 00:34:14 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bhagoji", "Arjun Nitin", ""], ["Chakraborty", "Supriyo", ""], ["Mittal", "Prateek", ""], ["Calo", "Seraphin", ""]]}, {"id": "1811.12535", "submitter": "Jiaming Zeng", "authors": "Jiaming Zeng, Adam Lesnikowski, Jose M. Alvarez", "title": "The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep\n  Bayesian Active Learning", "comments": null, "journal-ref": "Third workshop on Bayesian Deep Learning (NeurIPS 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges of deep learning tools is their inability to\ncapture model uncertainty. While Bayesian deep learning can be used to tackle\nthe problem, Bayesian neural networks often require more time and computational\npower to train than deterministic networks. Our work explores whether fully\nBayesian networks are needed to successfully capture model uncertainty. We vary\nthe number and position of Bayesian layers in a network and compare their\nperformance on active learning with the MNIST dataset. We found that we can\nfully capture the model uncertainty by using only a few Bayesian layers near\nthe output of the network, combining the advantages of deterministic and\nBayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 23:36:25 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zeng", "Jiaming", ""], ["Lesnikowski", "Adam", ""], ["Alvarez", "Jose M.", ""]]}, {"id": "1811.12556", "submitter": "Dhaval Adjodah", "authors": "Dhaval Adjodah, Dan Calacci, Abhimanyu Dubey, Peter Krafft, Esteban\n  Moro, Alex `Sandy' Pentland", "title": "How to Organize your Deep Reinforcement Learning Agents: The Importance\n  of Communication Topology", "comments": "please refer to arXiv:1902.06740 for updated paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this empirical paper, we investigate how learning agents can be arranged\nin more efficient communication topologies for improved learning. This is an\nimportant problem because a common technique to improve speed and robustness of\nlearning in deep reinforcement learning and many other machine learning\nalgorithms is to run multiple learning agents in parallel. The standard\ncommunication architecture typically involves all agents intermittently\ncommunicating with each other (fully connected topology) or with a centralized\nserver (star topology). Unfortunately, optimizing the topology of communication\nover the space of all possible graphs is a hard problem, so we borrow results\nfrom the networked optimization and collective intelligence literatures which\nsuggest that certain families of network topologies can lead to strong\nimprovements over fully-connected networks. We start by introducing alternative\nnetwork topologies to DRL benchmark tasks under the Evolution Strategies\nparadigm which we call Network Evolution Strategies. We explore the relative\nperformance of the four main graph families and observe that one such family\n(Erdos-Renyi random graphs) empirically outperforms all other families,\nincluding the de facto fully-connected communication topologies. Additionally,\nthe use of alternative network topologies has a multiplicative performance\neffect: we observe that when 1000 learning agents are arranged in a carefully\ndesigned communication topology, they can compete with 3000 agents arranged in\nthe de facto fully-connected topology. Overall, our work suggests that\ndistributed machine learning algorithms would learn more efficiently if the\ncommunication topology between learning agents was optimized.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:36:34 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 21:10:11 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Adjodah", "Dhaval", ""], ["Calacci", "Dan", ""], ["Dubey", "Abhimanyu", ""], ["Krafft", "Peter", ""], ["Moro", "Esteban", ""], ["Pentland", "Alex `Sandy'", ""]]}, {"id": "1811.12560", "submitter": "Vincent Francois-Lavet", "authors": "Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G.\n  Bellemare, Joelle Pineau", "title": "An Introduction to Deep Reinforcement Learning", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning: Vol. 11, No. 3-4, 2018", "doi": "10.1561/2200000071", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is the combination of reinforcement learning (RL)\nand deep learning. This field of research has been able to solve a wide range\nof complex decision-making tasks that were previously out of reach for a\nmachine. Thus, deep RL opens up many new applications in domains such as\nhealthcare, robotics, smart grids, finance, and many more. This manuscript\nprovides an introduction to deep reinforcement learning models, algorithms and\ntechniques. Particular focus is on the aspects related to generalization and\nhow deep RL can be used for practical applications. We assume the reader is\nfamiliar with basic machine learning concepts.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 00:57:30 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 09:10:53 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Francois-Lavet", "Vincent", ""], ["Henderson", "Peter", ""], ["Islam", "Riashat", ""], ["Bellemare", "Marc G.", ""], ["Pineau", "Joelle", ""]]}, {"id": "1811.12589", "submitter": "Benjamin Glicksberg", "authors": "Beau Norgeot, Dmytro Lituiev, Benjamin S. Glicksberg, Atul J. Butte", "title": "Time Aggregation and Model Interpretation for Deep Multivariate\n  Longitudinal Patient Outcome Forecasting Systems in Chronic Ambulatory Care", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/121", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical data for ambulatory care, which accounts for 90% of the nations\nhealthcare spending, is characterized by relatively small sample sizes of\nlongitudinal data, unequal spacing between visits for each patient, with\nunequal numbers of data points collected across patients. While deep learning\nhas become state-of-the-art for sequence modeling, it is unknown which methods\nof time aggregation may be best suited for these challenging temporal use\ncases. Additionally, deep models are often considered uninterpretable by\nphysicians which may prevent the clinical adoption, even of well performing\nmodels. We show that time-distributed-dense layers combined with GRUs produce\nthe most generalizable models. Furthermore, we provide a framework for the\nclinical interpretation of the models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 02:43:33 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Norgeot", "Beau", ""], ["Lituiev", "Dmytro", ""], ["Glicksberg", "Benjamin S.", ""], ["Butte", "Atul J.", ""]]}, {"id": "1811.12627", "submitter": "Hyungu Kahng", "authors": "Hyungu Kahng, Yonghyun Jeong, Yoon Sang Cho, Gonie Ahn, Young Joon\n  Park, Uk Jo, Hankyu Lee, Hyungrok Do, Junseung Lee, Hyunjin Choi, Iljoo Yoon,\n  Hyunjae Lee, Daehun Jun, Changhyeon Bae, Seoung Bum Kim", "title": "Clear the Fog: Combat Value Assessment in Incomplete Information Games\n  with Convolutional Encoder-Decoders", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StarCraft, one of the most popular real-time strategy games, is a compelling\nenvironment for artificial intelligence research for both micro-level unit\ncontrol and macro-level strategic decision making. In this study, we address an\neminent problem concerning macro-level decision making, known as the\n'fog-of-war', which rises naturally from the fact that information regarding\nthe opponent's state is always provided in the incomplete form. For intelligent\nagents to play like human players, it is obvious that making accurate\npredictions of the opponent's status under incomplete information will increase\nits chance of winning. To reflect this fact, we propose a convolutional\nencoder-decoder architecture that predicts potential counts and locations of\nthe opponent's units based on only partially visible and noisy information. To\nevaluate the performance of our proposed method, we train an additional\nclassifier on the encoder-decoder output to predict the game outcome (win or\nlose). Finally, we designed an agent incorporating the proposed method and\nconducted simulation games against rule-based agents to demonstrate both\neffectiveness and practicality. All experiments were conducted on actual game\nreplay data acquired from professional players.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:02:09 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 09:42:35 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kahng", "Hyungu", ""], ["Jeong", "Yonghyun", ""], ["Cho", "Yoon Sang", ""], ["Ahn", "Gonie", ""], ["Park", "Young Joon", ""], ["Jo", "Uk", ""], ["Lee", "Hankyu", ""], ["Do", "Hyungrok", ""], ["Lee", "Junseung", ""], ["Choi", "Hyunjin", ""], ["Yoon", "Iljoo", ""], ["Lee", "Hyunjae", ""], ["Jun", "Daehun", ""], ["Bae", "Changhyeon", ""], ["Kim", "Seoung Bum", ""]]}, {"id": "1811.12640", "submitter": "Sudeshna Roy", "authors": "Sudeshna Roy, Meghana Madhyastha, Sheril Lawrence, Vaibhav Rajan", "title": "Inferring Concept Prerequisite Relations from Online Educational\n  Resources", "comments": "Accepted at the AAAI Conference on Innovative Applications of\n  Artificial Intelligence (IAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has rich and rapidly increasing sources of high quality\neducational content. Inferring prerequisite relations between educational\nconcepts is required for modern large-scale online educational technology\napplications such as personalized recommendations and automatic curriculum\ncreation. We present PREREQ, a new supervised learning method for inferring\nconcept prerequisite relations. PREREQ is designed using latent representations\nof concepts obtained from the Pairwise Latent Dirichlet Allocation model, and a\nneural network based on the Siamese network architecture. PREREQ can learn\nunknown concept prerequisites from course prerequisites and labeled concept\nprerequisite data. It outperforms state-of-the-art approaches on benchmark\ndatasets and can effectively learn from very less training data. PREREQ can\nalso use unlabeled video playlists, a steadily growing source of training data,\nto learn concept prerequisites, thus obviating the need for manual annotation\nof course prerequisites.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:55:20 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2019 00:39:00 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Roy", "Sudeshna", ""], ["Madhyastha", "Meghana", ""], ["Lawrence", "Sheril", ""], ["Rajan", "Vaibhav", ""]]}, {"id": "1811.12642", "submitter": "Tomasz Rutkowski", "authors": "Tomasz M. Rutkowski, Qibin Zhao, Masao S. Abe, Mihoko Otake", "title": "AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG\n  Digital Biomarker Development Using Information Geometry Machine Learning\n  Methods", "comments": "5 pages, 2 figures, NeurIPS 2018 AI for Social Good Workshop at the\n  Neural Information Processing Systems (NeurIPS = formerly NIPS) 2018.\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dementia and especially Alzheimer's disease (AD) are the most common causes\nof cognitive decline in elderly people. A spread of the above mentioned mental\nhealth problems in aging societies is causing a significant medical and\neconomic burden in many countries around the world. According to a recent World\nHealth Organization (WHO) report, it is approximated that currently, worldwide,\nabout 47 million people live with a dementia spectrum of neurocognitive\ndisorders. This number is expected to triple by 2050, which calls for possible\napplication of AI-based technologies to support an early screening for\npreventive interventions and a subsequent mental wellbeing monitoring as well\nas maintenance with so-called digital-pharma or beyond a pill therapeutical\napproaches. This paper discusses our attempt and preliminary results of\nbrainwave (EEG) techniques to develop digital biomarkers for dementia progress\ndetection and monitoring. We present an information geometry-based\nclassification approach for automatic EEG-derived event related responses\n(ERPs) discrimination of low versus high task-load auditory or tactile stimuli\nrecognition, of which amplitude and latency variabilities are similar to those\nin dementia. The discussed approach is a step forward to develop AI, and\nespecially machine learning (ML) approaches, for the subsequent application to\nmild-cognitive impairment (MCI) and AD diagnostics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:58:16 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Rutkowski", "Tomasz M.", ""], ["Zhao", "Qibin", ""], ["Abe", "Masao S.", ""], ["Otake", "Mihoko", ""]]}, {"id": "1811.12667", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Xinjie Yu", "title": "Improved Crowding Distance for NSGA-II", "comments": "EC course paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-dominated sorting genetic algorithm II (NSGA-II) does well in dealing\nwith multi-objective problems. When evaluating validity of an algorithm for\nmulti-objective problems, two kinds of indices are often considered\nsimultaneously, i.e. the convergence to Pareto Front and the distribution\ncharacteristic. The crowding distance in the standard NSGA-II has the property\nthat solutions within a cubic have the same crowding distance, which has no\ncontribution to the convergence of the algorithm. Actually the closer to the\nPareto Front a solution is, the higher priority it should have. In the paper,\nthe crowding distance is redefined while keeping almost all the advantages of\nthe original one. Moreover, the speed of converging to the Pareto Front is\nfaster. Finally, the improvement is proved to be effective by applying it to\nsolve nine Benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 08:18:05 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Yu", "Xinjie", ""]]}, {"id": "1811.12693", "submitter": "Oliver Joseph David Barrowclough", "authors": "Konstantinos Gavriil, Georg Muntingh and Oliver J. D. Barrowclough", "title": "Void Filling of Digital Elevation Models with Deep Generative Models", "comments": "5 pages; 4 figures; corrected names in references; clarifications\n  regarding the two generators in the paper; added reference (Borji 2018) on\n  GAN evaluation measures; extended future work discussion; changed (Fig. 4.f)\n  to show a failure case", "journal-ref": null, "doi": "10.1109/LGRS.2019.2902222", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, advances in machine learning algorithms, cheap computational\nresources, and the availability of big data have spurred the deep learning\nrevolution in various application domains. In particular, supervised learning\ntechniques in image analysis have led to superhuman performance in various\ntasks, such as classification, localization, and segmentation, while\nunsupervised learning techniques based on increasingly advanced generative\nmodels have been applied to generate high-resolution synthetic images\nindistinguishable from real images.\n  In this paper we consider a state-of-the-art machine learning model for image\ninpainting, namely a Wasserstein Generative Adversarial Network based on a\nfully convolutional architecture with a contextual attention mechanism. We show\nthat this model can successfully be transferred to the setting of digital\nelevation models (DEMs) for the purpose of generating semantically plausible\ndata for filling voids. Training, testing and experimentation is done on\nGeoTIFF data from various regions in Norway, made openly available by the\nNorwegian Mapping Authority.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:04:30 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 13:24:22 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Gavriil", "Konstantinos", ""], ["Muntingh", "Georg", ""], ["Barrowclough", "Oliver J. D.", ""]]}, {"id": "1811.12707", "submitter": "Yihan Jiang", "authors": "Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan, Sewoong Oh,\n  Pramod Viswanath", "title": "LEARN Codes: Inventing Low-latency Codes via Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing channel codes under low-latency constraints is one of the most\ndemanding requirements in 5G standards. However, a sharp characterization of\nthe performance of traditional codes is available only in the large\nblock-length limit. Guided by such asymptotic analysis, code designs require\nlarge block lengths as well as latency to achieve the desired error rate.\nTail-biting convolutional codes and other recent state-of-the-art short block\ncodes, while promising reduced latency, are neither robust to channel-mismatch\nnor adaptive to varying channel conditions. When the codes designed for one\nchannel (e.g.,~Additive White Gaussian Noise (AWGN) channel) are used for\nanother (e.g.,~non-AWGN channels), heuristics are necessary to achieve\nnon-trivial performance.\n  In this paper, we first propose an end-to-end learned neural code, obtained\nby jointly designing a Recurrent Neural Network (RNN) based encoder and\ndecoder. This code outperforms canonical convolutional code under block\nsettings. We then leverage this experience to propose a new class of codes\nunder low-latency constraints, which we call Low-latency Efficient Adaptive\nRobust Neural (LEARN) codes. These codes outperform state-of-the-art\nlow-latency codes and exhibit robustness and adaptivity properties. LEARN codes\nshow the potential to design new versatile and universal codes for future\ncommunications via tools of modern deep learning coupled with communication\nengineering insights.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 10:40:31 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 17:08:26 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Jiang", "Yihan", ""], ["Kim", "Hyeji", ""], ["Asnani", "Himanshu", ""], ["Kannan", "Sreeram", ""], ["Oh", "Sewoong", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1811.12787", "submitter": "Nico Potyka", "authors": "Nico Potyka", "title": "A Tutorial for Weighted Bipolar Argumentation with Continuous Dynamical\n  Systems and the Java Library Attractor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted bipolar argumentation frameworks allow modeling decision problems\nand online discussions by defining arguments and their relationships. The\nstrength of arguments can be computed based on an initial weight and the\nstrength of attacking and supporting arguments. While previous approaches\nassumed an acyclic argumentation graph and successively set arguments' strength\nbased on the strength of their parents, recently continuous dynamical systems\nhave been proposed as an alternative. Continuous models update arguments'\nstrength simultaneously and continuously. While there are currently no\nanalytical guarantees for convergence in general graphs, experiments show that\ncontinuous models can converge quickly in large cyclic graphs with thousands of\narguments. Here, we focus on the high-level ideas of this approach and explain\nkey results and applications. We also introduce Attractor, a Java library that\ncan be used to solve weighted bipolar argumentation problems. Attractor\ncontains implementations of several discrete and continuous models and\nnumerical algorithms to compute solutions. It also provides base classes that\ncan be used to implement, to evaluate and to compare continuous models easily.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:31:04 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Potyka", "Nico", ""]]}, {"id": "1811.12823", "submitter": "Daniil Polykovskiy", "authors": "Daniil Polykovskiy, Alexander Zhebrak, Benjamin Sanchez-Lengeling,\n  Sergey Golovanov, Oktai Tatanov, Stanislav Belyaev, Rauf Kurbanov, Aleksey\n  Artamonov, Vladimir Aladinskiy, Mark Veselov, Artur Kadurin, Simon Johansson,\n  Hongming Chen, Sergey Nikolenko, Alan Aspuru-Guzik, Alex Zhavoronkov", "title": "Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative models are becoming a tool of choice for exploring the molecular\nspace. These models learn on a large training dataset and produce novel\nmolecular structures with similar properties. Generated structures can be\nutilized for virtual screening or training semi-supervised predictive models in\nthe downstream tasks. While there are plenty of generative models, it is\nunclear how to compare and rank them. In this work, we introduce a benchmarking\nplatform called Molecular Sets (MOSES) to standardize training and comparison\nof molecular generative models. MOSES provides a training and testing datasets,\nand a set of metrics to evaluate the quality and diversity of generated\nstructures. We have implemented and compared several molecular generation\nmodels and suggest to use our results as reference points for further\nadvancements in generative chemistry research. The platform and source code are\navailable at https://github.com/molecularsets/moses.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 08:48:20 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 20:03:21 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 07:23:45 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 16:15:59 GMT"}, {"version": "v5", "created": "Wed, 28 Oct 2020 14:11:16 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Polykovskiy", "Daniil", ""], ["Zhebrak", "Alexander", ""], ["Sanchez-Lengeling", "Benjamin", ""], ["Golovanov", "Sergey", ""], ["Tatanov", "Oktai", ""], ["Belyaev", "Stanislav", ""], ["Kurbanov", "Rauf", ""], ["Artamonov", "Aleksey", ""], ["Aladinskiy", "Vladimir", ""], ["Veselov", "Mark", ""], ["Kadurin", "Artur", ""], ["Johansson", "Simon", ""], ["Chen", "Hongming", ""], ["Nikolenko", "Sergey", ""], ["Aspuru-Guzik", "Alan", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "1811.12824", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr, Carsten Witt, Jing Yang", "title": "Runtime Analysis for Self-adaptive Mutation Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a self-adaptive version of the $(1,\\lambda)$\nevolutionary algorithm in which the current mutation rate is part of the\nindividual and thus also subject to mutation. A rigorous runtime analysis on\nthe OneMax benchmark function reveals that a simple local mutation scheme for\nthe rate leads to an expected optimization time (number of fitness evaluations)\nof $O(n\\lambda/\\log\\lambda+n\\log n)$ when $\\lambda$ is at least $C \\ln n$ for\nsome constant $C > 0$. For all values of $\\lambda \\ge C \\ln n$, this\nperformance is asymptotically best possible among all $\\lambda$-parallel\nmutation-based unbiased black-box algorithms.\n  Our result shows that self-adaptation in evolutionary computation can find\ncomplex optimal parameter settings on the fly. At the same time, it proves that\na relatively complicated self-adjusting scheme for the mutation rate proposed\nby Doerr, Gie{\\ss}en, Witt, and Yang~(GECCO~2017) can be replaced by our simple\nendogenous scheme.\n  On the technical side, the paper contributes new tools for the analysis of\ntwo-dimensional drift processes arising in the analysis of dynamic parameter\nchoices in EAs, including bounds on occupation probabilities in processes with\nnon-constant drift.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 14:38:05 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Doerr", "Benjamin", ""], ["Witt", "Carsten", ""], ["Yang", "Jing", ""]]}, {"id": "1811.12889", "submitter": "Dzmitry Bahdanau", "authors": "Dzmitry Bahdanau, Shikhar Murty, Michael Noukhovitch, Thien Huu\n  Nguyen, Harm de Vries, Aaron Courville", "title": "Systematic Generalization: What Is Required and Can It Be Learned?", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous models for grounded language understanding have been recently\nproposed, including (i) generic models that can be easily adapted to any given\ntask and (ii) intuitively appealing modular models that require background\nknowledge to be instantiated. We compare both types of models in how much they\nlend themselves to a particular form of systematic generalization. Using a\nsynthetic VQA test, we evaluate which models are capable of reasoning about all\npossible object pairs after training on only a small subset of them. Our\nfindings show that the generalization of modular models is much more systematic\nand that it is highly sensitive to the module layout, i.e. to how exactly the\nmodules are connected. We furthermore investigate if modular models that\ngeneralize well could be made more end-to-end by learning their layout and\nparametrization. We find that end-to-end methods from prior work often learn\ninappropriate layouts or parametrizations that do not facilitate systematic\ngeneralization. Our results suggest that, in addition to modularity, systematic\ngeneralization in language understanding may require explicit regularizers or\npriors.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 17:01:28 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 14:58:38 GMT"}, {"version": "v3", "created": "Sun, 21 Apr 2019 15:37:46 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bahdanau", "Dzmitry", ""], ["Murty", "Shikhar", ""], ["Noukhovitch", "Michael", ""], ["Nguyen", "Thien Huu", ""], ["de Vries", "Harm", ""], ["Courville", "Aaron", ""]]}, {"id": "1811.12891", "submitter": "Rahul Goel", "authors": "Rahul Goel, Shachi Paul, Tagyoung Chung, Jeremie Lecomte, Arindam\n  Mandal, Dilek Hakkani-Tur", "title": "Flexible and Scalable State Tracking Framework for Goal-Oriented\n  Dialogue Systems", "comments": "NIPS CONVAI Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialogue systems typically rely on components specifically\ndeveloped for a single task or domain. This limits such systems in two\ndifferent ways: If there is an update in the task domain, the dialogue system\nusually needs to be updated or completely re-trained. It is also harder to\nextend such dialogue systems to different and multiple domains. The dialogue\nstate tracker in conventional dialogue systems is one such component - it is\nusually designed to fit a well-defined application domain. For example, it is\ncommon for a state variable to be a categorical distribution over a\nmanually-predefined set of entities (Henderson et al., 2013), resulting in an\ninflexible and hard-to-extend dialogue system. In this paper, we propose a new\napproach for dialogue state tracking that can generalize well over multiple\ndomains without incorporating any domain-specific knowledge. Under this\nframework, discrete dialogue state variables are learned independently and the\ninformation of a predefined set of possible values for dialogue state variables\nis not required. Furthermore, it enables adding arbitrary dialogue context as\nfeatures and allows for multiple values to be associated with a single state\nvariable. These characteristics make it much easier to expand the dialogue\nstate space. We evaluate our framework using the widely used dialogue state\ntracking challenge data set (DSTC2) and show that our framework yields\ncompetitive results with other state-of-the-art results despite incorporating\nlittle domain knowledge. We also show that this framework can benefit from\nwidely available external resources such as pre-trained word embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 17:01:48 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Goel", "Rahul", ""], ["Paul", "Shachi", ""], ["Chung", "Tagyoung", ""], ["Lecomte", "Jeremie", ""], ["Mandal", "Arindam", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1811.12917", "submitter": "Daniel Muller", "authors": "Daniel Muller and Erez Karpas", "title": "Automated Tactical Decision Planning Model with Strategic Values\n  Guidance for Local Action-Value-Ambiguity", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world planning problems, action's impact differs with a place,\ntime and the context in which the action is applied. The same action with the\nsame effects in a different context or states can cause a different change. In\nactions with incomplete precondition list, that applicable in several states\nand circumstances, ambiguity regarding the impact of the action is challenging\neven in small domains. To estimate the real impact of actions, an evaluation of\nthe effect list will not be enough; a relative estimation is more informative\nand suitable for estimation of action's real impact. Recent work on\nOver-subscription Planning (OSP) defined the net utility of action as the net\nchange in the state's value caused by the action. The notion of net utility of\naction allows for a broader perspective on value action impact and use for a\nmore accurate evaluation of achievements of the action, considering inter-state\nand intra-state dependencies. To achieve value-rational decisions in complex\nreality often requires strategic, high level, planning with a global\nperspective and values, while many local tactical decisions require real-time\ninformation to estimate the impact of actions. This paper proposes an offline\naction-value structure analysis to exploit the compactly represented\ninformativeness of net utility of actions to extend the scope of planning to\nvalue uncertainty scenarios and to provide a real-time value-rational decision\nplanning tool. The result of the offline pre-processing phase is a compact\ndecision planning model representation for flexible, local reasoning of net\nutility of actions with (offline) value ambiguity. The obtained flexibility is\nbeneficial for the online planning phase and real-time execution of actions\nwith value ambiguity. Our empirical evaluation shows the effectiveness of this\napproach in domains with value ambiguity in their action-value-structure.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 18:04:19 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Muller", "Daniel", ""], ["Karpas", "Erez", ""]]}]