[{"id": "0910.0013", "submitter": "Radu Grigore", "authors": "Mikolas Janota, Joao Marques-Silva, Radu Grigore", "title": "Algorithms for finding dispensable variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note reviews briefly three algorithms for finding the set of\ndispensable variables of a boolean formula. The presentation is light on proofs\nand heavy on intuitions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2009 20:10:03 GMT"}], "update_date": "2009-10-02", "authors_parsed": [["Janota", "Mikolas", ""], ["Marques-Silva", "Joao", ""], ["Grigore", "Radu", ""]]}, {"id": "0910.0542", "submitter": "Om Patri", "authors": "Om Prasad Patri, Amit Kumar Mishra", "title": "Pre-processing in AI based Prediction of QSARs", "comments": "6 pages, 12 figures, In the Proceedings of the 12th International\n  Conference on Information Technology, ICIT 2009, December 21-24 2009,\n  Bhubaneswar, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning, data mining and artificial intelligence (AI) based methods\nhave been used to determine the relations between chemical structure and\nbiological activity, called quantitative structure activity relationships\n(QSARs) for the compounds. Pre-processing of the dataset, which includes the\nmapping from a large number of molecular descriptors in the original high\ndimensional space to a small number of components in the lower dimensional\nspace while retaining the features of the original data, is the first step in\nthis process. A common practice is to use a mapping method for a dataset\nwithout prior analysis. This pre-analysis has been stressed in our work by\napplying it to two important classes of QSAR prediction problems: drug design\n(predicting anti-HIV-1 activity) and predictive toxicology (estimating\nhepatocarcinogenicity of chemicals). We apply one linear and two nonlinear\nmapping methods on each of the datasets. Based on this analysis, we conclude\nthe nature of the inherent relationships between the elements of each dataset,\nand hence, the mapping method best suited for it. We also show that proper\npreprocessing can help us in choosing the right feature extraction tool as well\nas give an insight about the type of classifier pertinent for the given\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 3 Oct 2009 18:46:00 GMT"}], "update_date": "2009-10-06", "authors_parsed": [["Patri", "Om Prasad", ""], ["Mishra", "Amit Kumar", ""]]}, {"id": "0910.0902", "submitter": "Sajid Siddiqi", "authors": "Sajid M. Siddiqi, Byron Boots, Geoffrey J. Gordon", "title": "Reduced-Rank Hidden Markov Models", "comments": "Updated robot experiment figure, added details on KDE, fixed a couple\n  of errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization\nof HMMs that can model smooth state evolution as in Linear Dynamical Systems\n(LDSs) as well as non-log-concave predictive distributions as in\ncontinuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n\ndiscrete observations, with a transition matrix of rank k <= m. This implies\nthe dynamics evolve in a k-dimensional subspace, while the shape of the set of\npredictive distributions is determined by m. Latent state belief is represented\nwith a k-dimensional state vector and inference is carried out entirely in R^k,\nmaking RR-HMMs as computationally efficient as k-state HMMs yet more\nexpressive. To learn RR-HMMs, we relax the assumptions of a recently proposed\nspectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it\nto learn k-dimensional observable representations of rank-k RR-HMMs. The\nalgorithm is consistent and free of local optima, and we extend its performance\nguarantees to cover the RR-HMM case. We show how this algorithm can be used in\nconjunction with a kernel density estimator to efficiently model\nhigh-dimensional multivariate continuous data. We also relax the assumption\nthat single observations are sufficient to disambiguate state, and extend the\nalgorithm accordingly. Experiments on synthetic data and a toy video, as well\nas on a difficult robot vision modeling problem, yield accurate models that\ncompare favorably with standard alternatives in simulation quality and\nprediction capability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 06:00:47 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2009 07:52:37 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2009 23:31:57 GMT"}], "update_date": "2009-12-23", "authors_parsed": [["Siddiqi", "Sajid M.", ""], ["Boots", "Byron", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "0910.1014", "submitter": "Pierrick Tranouez", "authors": "Pierrick Tranouez (LITIS), Antoine Dutot (LITIS)", "title": "Building upon Fast Multipole Methods to Detect and Model Organizations", "comments": null, "journal-ref": "DCDIS Series B: Applications & Algorithms 16, 4 (2009) 489 - 500", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models in natural and social sciences are comprised of sets of\ninter-acting entities whose intensity of interaction decreases with distance.\nThis often leads to structures of interest in these models composed of dense\npacks of entities. Fast Multipole Methods are a family of methods developed to\nhelp with the calculation of a number of computable models such as described\nabove. We propose a method that builds upon FMM to detect and model the dense\nstructures of these systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 14:19:56 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2009 08:35:15 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Tranouez", "Pierrick", "", "LITIS"], ["Dutot", "Antoine", "", "LITIS"]]}, {"id": "0910.1026", "submitter": "Pierrick Tranouez", "authors": "Eric Daud\\'e (IDEES), Pierrick Tranouez (LITIS), Patrice Langlois\n  (IDEES)", "title": "A multiagent urban traffic simulation. Part II: dealing with the\n  extraordinary", "comments": null, "journal-ref": "ICCSA 2009, France (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Probabilistic Risk Management, risk is characterized by two quantities:\nthe magnitude (or severity) of the adverse consequences that can potentially\nresult from the given activity or action, and by the likelihood of occurrence\nof the given adverse consequences. But a risk seldom exists in isolation: chain\nof consequences must be examined, as the outcome of one risk can increase the\nlikelihood of other risks. Systemic theory must complement classic PRM. Indeed\nthese chains are composed of many different elements, all of which may have a\ncritical importance at many different levels. Furthermore, when urban\ncatastrophes are envisioned, space and time constraints are key determinants of\nthe workings and dynamics of these chains of catastrophes: models must include\na correct spatial topology of the studied risk. Finally, literature insists on\nthe importance small events can have on the risk on a greater scale: urban\nrisks management models belong to self-organized criticality theory. We chose\nmultiagent systems to incorporate this property in our model: the behavior of\nan agent can transform the dynamics of important groups of them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 14:41:57 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Daud\u00e9", "Eric", "", "IDEES"], ["Tranouez", "Pierrick", "", "LITIS"], ["Langlois", "Patrice", "", "IDEES"]]}, {"id": "0910.1238", "submitter": "Yves Deville", "authors": "Quang Dung Pham, Yves Deville, Pascal Van Hentenryck", "title": "A Local Search Modeling for Constrained Optimum Paths Problems (Extended\n  Abstract)", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 5-11", "doi": "10.4204/EPTCS.5.1", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Optimum Path (COP) problems appear in many real-life\napplications, especially on communication networks. Some of these problems have\nbeen considered and solved by specific techniques which are usually difficult\nto extend. In this paper, we introduce a novel local search modeling for\nsolving some COPs by local search. The modeling features the compositionality,\nmodularity, reuse and strengthens the benefits of Constrained-Based Local\nSearch. We also apply the modeling to the edge-disjoint paths problem (EDP). We\nshow that side constraints can easily be added in the model. Computational\nresults show the significance of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 12:36:40 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Pham", "Quang Dung", ""], ["Deville", "Yves", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "0910.1239", "submitter": "Yves Deville", "authors": "Farshid Hassani Bijarbooneh, Pierre Flener, Justin Pearson", "title": "Dynamic Demand-Capacity Balancing for Air Traffic Management Using\n  Constraint-Based Local Search: First Results", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 27-40", "doi": "10.4204/EPTCS.5.3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using constraint-based local search, we effectively model and efficiently\nsolve the problem of balancing the traffic demands on portions of the European\nairspace while ensuring that their capacity constraints are satisfied. The\ntraffic demand of a portion of airspace is the hourly number of flights planned\nto enter it, and its capacity is the upper bound on this number under which\nair-traffic controllers can work. Currently, the only form of demand-capacity\nbalancing we allow is ground holding, that is the changing of the take-off\ntimes of not yet airborne flights. Experiments with projected European flight\nplans of the year 2030 show that already this first form of demand-capacity\nbalancing is feasible without incurring too much total delay and that it can\nlead to a significantly better demand-capacity balance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 12:50:34 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Bijarbooneh", "Farshid Hassani", ""], ["Flener", "Pierre", ""], ["Pearson", "Justin", ""]]}, {"id": "0910.1244", "submitter": "Yves Deville", "authors": "David Pereira, In\\^es Lynce, Steven Prestwich", "title": "On Improving Local Search for Unsatisfiability", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 41-53", "doi": "10.4204/EPTCS.5.4", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic local search (SLS) has been an active field of research in the\nlast few years, with new techniques and procedures being developed at an\nastonishing rate. SLS has been traditionally associated with satisfiability\nsolving, that is, finding a solution for a given problem instance, as its\nintrinsic nature does not address unsatisfiable problems. Unsatisfiable\ninstances were therefore commonly solved using backtrack search solvers. For\nthis reason, in the late 90s Selman, Kautz and McAllester proposed a challenge\nto use local search instead to prove unsatisfiability. More recently, two SLS\nsolvers - Ranger and Gunsat - have been developed, which are able to prove\nunsatisfiability albeit being SLS solvers. In this paper, we first compare\nRanger with Gunsat and then propose to improve Ranger performance using some of\nGunsat's techniques, namely unit propagation look-ahead and extended\nresolution.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 16:08:44 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Pereira", "David", ""], ["Lynce", "In\u00eas", ""], ["Prestwich", "Steven", ""]]}, {"id": "0910.1247", "submitter": "Yves Deville", "authors": "Gilles Audenard, Jean-Marie Lagniez, Bertrand Mazure, Lakhdar Sa\\\"is", "title": "Integrating Conflict Driven Clause Learning to Local Search", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 55-68", "doi": "10.4204/EPTCS.5.5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces SatHyS (SAT HYbrid Solver), a novel hybrid approach\nfor propositional satisfiability. It combines local search and conflict driven\nclause learning (CDCL) scheme. Each time the local search part reaches a local\nminimum, the CDCL is launched. For SAT problems it behaves like a tabu list,\nwhereas for UNSAT ones, the CDCL part tries to focus on minimum unsatisfiable\nsub-formula (MUS). Experimental results show good performances on many classes\nof SAT instances from the last SAT competitions.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 16:06:29 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Audenard", "Gilles", ""], ["Lagniez", "Jean-Marie", ""], ["Mazure", "Bertrand", ""], ["Sa\u00efs", "Lakhdar", ""]]}, {"id": "0910.1253", "submitter": "Yves Deville", "authors": "Fang He, Rong Qu", "title": "A Constraint-directed Local Search Approach to Nurse Rostering Problems", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 69-80", "doi": "10.4204/EPTCS.5.6", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the hybridization of constraint programming and\nlocal search techniques within a large neighbourhood search scheme for solving\nhighly constrained nurse rostering problems. As identified by the research, a\ncrucial part of the large neighbourhood search is the selection of the fragment\n(neighbourhood, i.e. the set of variables), to be relaxed and re-optimized\niteratively. The success of the large neighbourhood search depends on the\nadequacy of this identified neighbourhood with regard to the problematic part\nof the solution assignment and the choice of the neighbourhood size. We\ninvestigate three strategies to choose the fragment of different sizes within\nthe large neighbourhood search scheme. The first two strategies are tailored\nconcerning the problem properties. The third strategy is more general, using\nthe information of the cost from the soft constraint violations and their\npropagation as the indicator to choose the variables added into the fragment.\nThe three strategies are analyzed and compared upon a benchmark nurse rostering\nproblem. Promising results demonstrate the possibility of future work in the\nhybrid approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 13:17:36 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["He", "Fang", ""], ["Qu", "Rong", ""]]}, {"id": "0910.1255", "submitter": "Yves Deville", "authors": "Marie Pelleau, Pascal Van Hentenryck, Charlotte Truchet", "title": "Sonet Network Design Problems", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 81-95", "doi": "10.4204/EPTCS.5.7", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method and a constraint-based objective function to\nsolve two problems related to the design of optical telecommunication networks,\nnamely the Synchronous Optical Network Ring Assignment Problem (SRAP) and the\nIntra-ring Synchronous Optical Network Design Problem (IDP). These network\ntopology problems can be represented as a graph partitioning with capacity\nconstraints as shown in previous works. We present here a new objective\nfunction and a new local search algorithm to solve these problems. Experiments\nconducted in Comet allow us to compare our method to previous ones and show\nthat we obtain better results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 13:22:22 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Pelleau", "Marie", ""], ["Van Hentenryck", "Pascal", ""], ["Truchet", "Charlotte", ""]]}, {"id": "0910.1264", "submitter": "Yves Deville", "authors": "Salvator Abreu, Daniel Diaz, Philippe Codognet", "title": "Parallel local search for solving Constraint Problems on the Cell\n  Broadband Engine (Preliminary Results)", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 97-111", "doi": "10.4204/EPTCS.5.8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of the Cell Broadband Engine (Cell/BE for short) for\ncombinatorial optimization applications: we present a parallel version of a\nconstraint-based local search algorithm that has been implemented on a\nmultiprocessor BladeCenter machine with twin Cell/BE processors (total of 16\nSPUs per blade). This algorithm was chosen because it fits very well the\nCell/BE architecture and requires neither shared memory nor communication\nbetween processors, while retaining a compact memory footprint. We study the\nperformance on several large optimization benchmarks and show that this\nachieves mostly linear time speedups, even sometimes super-linear. This is\npossible because the parallel implementation might explore simultaneously\ndifferent parts of the search space and therefore converge faster towards the\nbest sub-space and thus towards a solution. Besides getting speedups, the\nresulting times exhibit a much smaller variance, which benefits applications\nwhere a timely reply is critical.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 13:44:11 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Abreu", "Salvator", ""], ["Diaz", "Daniel", ""], ["Codognet", "Philippe", ""]]}, {"id": "0910.1266", "submitter": "Yves Deville", "authors": "Jun He, Pierre Flener, Justin Pearson", "title": "Toward an automaton Constraint for Local Search", "comments": null, "journal-ref": "EPTCS 5, 2009, pp. 13-25", "doi": "10.4204/EPTCS.5.2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the idea of using finite automata to implement new constraints for\nlocal search (this is already a successful technique in constraint-based global\nsearch). We show how it is possible to maintain incrementally the violations of\na constraint and its decision variables from an automaton that describes a\nground checker for that constraint. We establish the practicality of our\napproach idea on real-life personnel rostering problems, and show that it is\ncompetitive with the approach of [Pralong, 2007].\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 13:49:26 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["He", "Jun", ""], ["Flener", "Pierre", ""], ["Pearson", "Justin", ""]]}, {"id": "0910.1404", "submitter": "EPTCS", "authors": "Yves Deville, Christine Solnon", "title": "Proceedings 6th International Workshop on Local Search Techniques in\n  Constraint Satisfaction", "comments": null, "journal-ref": "EPTCS 5, 2009", "doi": "10.4204/EPTCS.5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSCS is a satellite workshop of the international conference on principles\nand practice of Constraint Programming (CP), since 2004. It is devoted to local\nsearch techniques in constraint satisfaction, and focuses on all aspects of\nlocal search techniques, including: design and implementation of new\nalgorithms, hybrid stochastic-systematic search, reactive search optimization,\nadaptive search, modeling for local-search, global constraints, flexibility and\nrobustness, learning methods, and specific applications.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 06:27:26 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Deville", "Yves", ""], ["Solnon", "Christine", ""]]}, {"id": "0910.1433", "submitter": "Jean Dezert", "authors": "Albena Tchamova (IPP BAS), Jean Dezert (ONERA), Florentin Smarandache\n  (UNM)", "title": "Tracking object's type changes with fuzzy based fusion rule", "comments": null, "journal-ref": "First International Conference on Modelling and Development of\n  Intelligent Systems, Sibiu : Romania (2009)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the behavior of three combinational rules for\ntemporal/sequential attribute data fusion for target type estimation are\nanalyzed. The comparative analysis is based on: Dempster's fusion rule proposed\nin Dempster-Shafer Theory; Proportional Conflict Redistribution rule no. 5\n(PCR5), proposed in Dezert-Smarandache Theory and one alternative class fusion\nrule, connecting the combination rules for information fusion with particular\nfuzzy operators, focusing on the t-norm based Conjunctive rule as an analog of\nthe ordinary conjunctive rule and t-conorm based Disjunctive rule as an analog\nof the ordinary disjunctive rule. The way how different t-conorms and t-norms\nfunctions within TCN fusion rule influence over target type estimation\nperformance is studied and estimated.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 07:53:27 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Tchamova", "Albena", "", "IPP BAS"], ["Dezert", "Jean", "", "ONERA"], ["Smarandache", "Florentin", "", "UNM"]]}, {"id": "0910.1800", "submitter": "Cyril Furtlehner", "authors": "Cyril Furtlehner, Michele Sebag and Xiangliang Zhang", "title": "Scaling Analysis of Affinity Propagation", "comments": "28 pages, 14 figures, Inria research report", "journal-ref": "Phys. Rev. E 81,066102 (2010)", "doi": "10.1103/PhysRevE.81.066102", "report-no": "7046", "categories": "cs.AI cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze and exploit some scaling properties of the Affinity Propagation\n(AP) clustering algorithm proposed by Frey and Dueck (2007). First we observe\nthat a divide and conquer strategy, used on a large data set hierarchically\nreduces the complexity ${\\cal O}(N^2)$ to ${\\cal O}(N^{(h+2)/(h+1)})$, for a\ndata-set of size $N$ and a depth $h$ of the hierarchical strategy. For a\ndata-set embedded in a $d$-dimensional space, we show that this is obtained\nwithout notably damaging the precision except in dimension $d=2$. In fact, for\n$d$ larger than 2 the relative loss in precision scales like\n$N^{(2-d)/(h+1)d}$. Finally, under some conditions we observe that there is a\nvalue $s^*$ of the penalty coefficient, a free parameter used to fix the number\nof clusters, which separates a fragmentation phase (for $s<s^*$) from a\ncoalescent one (for $s>s^*$) of the underlying hidden cluster structure. At\nthis precise point holds a self-similarity property which can be exploited by\nthe hierarchical strategy to actually locate its position. From this\nobservation, a strategy based on \\AP can be defined to find out how many\nclusters are present in a given dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 17:43:35 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Furtlehner", "Cyril", ""], ["Sebag", "Michele", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "0910.2039", "submitter": "Keyan Zahedi", "authors": "Keyan Zahedi, Nihat Ay and Ralf Der", "title": "Higher coordination with less control - A result of information\n  maximization in the sensorimotor loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.RO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel learning method in the context of embodied\nartificial intelligence and self-organization, which has as few assumptions and\nrestrictions as possible about the world and the underlying model. The learning\nrule is derived from the principle of maximizing the predictive information in\nthe sensorimotor loop. It is evaluated on robot chains of varying length with\nindividually controlled, non-communicating segments. The comparison of the\nresults shows that maximizing the predictive information per wheel leads to a\nhigher coordinated behavior of the physically connected robots compared to a\nmaximization per robot. Another focus of this paper is the analysis of the\neffect of the robot chain length on the overall behavior of the robots. It will\nbe shown that longer chains with less capable controllers outperform those of\nshorter length and more complex controllers. The reason is found and discussed\nin the information-geometric interpretation of the learning process.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2009 20:06:04 GMT"}, {"version": "v2", "created": "Tue, 18 May 2010 12:00:44 GMT"}], "update_date": "2010-05-19", "authors_parsed": [["Zahedi", "Keyan", ""], ["Ay", "Nihat", ""], ["Der", "Ralf", ""]]}, {"id": "0910.2217", "submitter": "Tshilidzi Marwala", "authors": "Linda Mthembu, Tshilidzi Marwala, Michael I. Friswell, Sondipon\n  Adhikari", "title": "Finite element model selection using Particle Swarm Optimization", "comments": "Accepted for the Proceedings of the International Modal Analysis\n  Conference 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the application of particle swarm optimization (PSO) to\nthe problem of finite element model (FEM) selection. This problem arises when a\nchoice of the best model for a system has to be made from set of competing\nmodels, each developed a priori from engineering judgment. PSO is a\npopulation-based stochastic search algorithm inspired by the behaviour of\nbiological entities in nature when they are foraging for resources. Each\npotentially correct model is represented as a particle that exhibits both\nindividualistic and group behaviour. Each particle moves within the model\nsearch space looking for the best solution by updating the parameters values\nthat define it. The most important step in the particle swarm algorithm is the\nmethod of representing models which should take into account the number,\nlocation and variables of parameters to be updated. One example structural\nsystem is used to show the applicability of PSO in finding an optimal FEM. An\noptimal model is defined as the model that has the least number of updated\nparameters and has the smallest parameter variable variation from the mean\nmaterial properties. Two different objective functions are used to compare\nperformance of the PSO algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 19:10:58 GMT"}], "update_date": "2009-10-13", "authors_parsed": [["Mthembu", "Linda", ""], ["Marwala", "Tshilidzi", ""], ["Friswell", "Michael I.", ""], ["Adhikari", "Sondipon", ""]]}, {"id": "0910.2276", "submitter": "Tshilidzi Marwala", "authors": "Evan Hurwitz and Tshilidzi Marwala", "title": "State of the Art Review for Applying Computational Intelligence and\n  Machine Learning Techniques to Portfolio Optimisation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational techniques have shown much promise in the field of Finance,\nowing to their ability to extract sense out of dauntingly complex systems. This\npaper reviews the most promising of these techniques, from traditional\ncomputational intelligence methods to their machine learning siblings, with\nparticular view to their application in optimising the management of a\nportfolio of financial instruments. The current state of the art is assessed,\nand prospective further work is assessed and recommended\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 15:53:45 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Hurwitz", "Evan", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "0910.2593", "submitter": "Uwe Aickelin", "authors": "Jingpeng Li, Uwe Aickelin, Edmund Burke", "title": "A Component Based Heuristic Search Method with Evolutionary Eliminations", "comments": "27 pages, 4 figures", "journal-ref": "INFORMS Journal of Computing, 21 (3), 468-479, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nurse rostering is a complex scheduling problem that affects hospital\npersonnel on a daily basis all over the world. This paper presents a new\ncomponent-based approach with evolutionary eliminations, for a nurse scheduling\nproblem arising at a major UK hospital. The main idea behind this technique is\nto decompose a schedule into its components (i.e. the allocated shift pattern\nof each nurse), and then to implement two evolutionary elimination strategies\nmimicking natural selection and natural mutation process on these components\nrespectively to iteratively deliver better schedules. The worthiness of all\ncomponents in the schedule has to be continuously demonstrated in order for\nthem to remain there. This demonstration employs an evaluation function which\nevaluates how well each component contributes towards the final objective. Two\nelimination steps are then applied: the first elimination eliminates a number\nof components that are deemed not worthy to stay in the current schedule; the\nsecond elimination may also throw out, with a low level of probability, some\nworthy components. The eliminated components are replenished with new ones\nusing a set of constructive heuristics using local optimality criteria.\nComputational results using 52 data instances demonstrate the applicability of\nthe proposed approach in solving real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 11:44:57 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Li", "Jingpeng", ""], ["Aickelin", "Uwe", ""], ["Burke", "Edmund", ""]]}, {"id": "0910.2874", "submitter": "Uwe Aickelin", "authors": "Feng Gu, Uwe Aickelin, Julie Greensmith", "title": "An Agent Based Classification Model", "comments": "4 pages, 2 figures, 9th European Agent Systems Summer School, Durham,\n  UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The major function of this model is to access the UCI Wisconsin Breast Can-\ncer data-set[1] and classify the data items into two categories, which are\nnormal and anomalous. This kind of classifi cation can be referred as anomaly\ndetection, which discriminates anomalous behaviour from normal behaviour in\ncomputer systems. One popular solution for anomaly detection is Artifi cial\nImmune Sys- tems (AIS). AIS are adaptive systems inspired by theoretical\nimmunology and observed immune functions, principles and models which are\napplied to prob- lem solving. The Dendritic Cell Algorithm (DCA)[2] is an AIS\nalgorithm that is developed specifi cally for anomaly detection. It has been\nsuccessfully applied to intrusion detection in computer security. It is\nbelieved that agent-based mod- elling is an ideal approach for implementing\nAIS, as intelligent agents could be the perfect representations of immune\nentities in AIS. This model evaluates the feasibility of re-implementing the\nDCA in an agent-based simulation environ- ment called AnyLogic, where the\nimmune entities in the DCA are represented by intelligent agents. If this model\ncan be successfully implemented, it makes it possible to implement more\ncomplicated and adaptive AIS models in the agent-based simulation environment.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2009 13:47:02 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Gu", "Feng", ""], ["Aickelin", "Uwe", ""], ["Greensmith", "Julie", ""]]}, {"id": "0910.3068", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin, Jingpeng Li, Edmund Burke", "title": "An Evolutionary Squeaky Wheel Optimisation Approach to Personnel\n  Scheduling", "comments": "21 pages, 5 tables, 1 figure, IEEE Transactions on Evolutionary\n  Computation", "journal-ref": "IEEE Transactions on Evolutionary Computation, 13 (2), 433-443,\n  2009", "doi": "10.2139/ssrn.2823393", "report-no": null, "categories": "cs.AI cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for robust heuristics that are able to solve more than one problem\nis ongoing. In this paper, we present, discuss and analyse a technique called\nEvolutionary Squeaky Wheel Optimisation and apply it to two different personnel\nscheduling problems. Evolutionary Squeaky Wheel Optimisation improves the\noriginal Squeaky Wheel Optimisation's effectiveness and execution speed by\nincorporating two extra steps (Selection and Mutation) for added evolution. In\nthe Evolutionary Squeaky Wheel Optimisation, a cycle of\nAnalysis-Selection-Mutation-Prioritization-Construction continues until\nstopping conditions are reached. The aim of the Analysis step is to identify\nbelow average solution components by calculating a fitness value for all\ncomponents. The Selection step then chooses amongst these underperformers and\ndiscards some probabilistically based on fitness. The Mutation step further\ndiscards a few components at random. Solutions can become incomplete and thus\nrepairs may be required. The repairs are carried out by using the\nPrioritization to first produce priorities that determine an order by which the\nfollowing Construction step then schedules the remaining components. Therefore,\nimprovement in the Evolutionary Squeaky Wheel Optimisation is achieved by\nselective solution disruption mixed with interative improvement and\nconstructive repair. Strong experimental results are reported on two different\ndomains of personnel scheduling: bus and rail driver scheduling and hospital\nnurse scheduling.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 13:36:01 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Aickelin", "Uwe", ""], ["Li", "Jingpeng", ""], ["Burke", "Edmund", ""]]}, {"id": "0910.3115", "submitter": "Uwe Aickelin", "authors": "Amanda Whitbrook, Uwe Aickelin, Jonathan M Garibaldi", "title": "An Idiotypic Immune Network as a Short Term Learning Architecture for\n  Mobile Robots", "comments": "13 pages, 5 tables, 4 figures, 7th International Conference on\n  Artificial Immune Systems (ICARIS2008), Phuket, Thailand", "journal-ref": "Proceedings of the 7th International Conference on Artificial\n  Imune Systems (ICARIS2008), Phuket, Thailand, 266-278, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to\nsolving mobile robot navigation problems is presented and tested in both real\nand simulated environments. The LTL consists of rapid simulations that use a\nGenetic Algorithm to derive diverse sets of behaviours. These sets are then\ntransferred to an idiotypic Artificial Immune System (AIS), which forms the STL\nphase, and the system is said to be seeded. The combined LTL-STL approach is\ncompared with using STL only, and with using a handdesigned controller. In\naddition, the STL phase is tested when the idiotypic mechanism is turned off.\nThe results provide substantial evidence that the best option is the seeded\nidiotypic system, i.e. the architecture that merges LTL with an idiotypic AIS\nfor the STL. They also show that structurally different environments can be\nused for the two phases without compromising transferability\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 13:40:49 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Whitbrook", "Amanda", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M", ""]]}, {"id": "0910.3117", "submitter": "Uwe Aickelin", "authors": "Jamie Twycross, Uwe Aickelin", "title": "An Immune Inspired Approach to Anomaly Detection", "comments": "19 pages, 4 tables, 2 figures, Handbook of Research on Information\n  Security and Assurance", "journal-ref": "Handbook of Research on Information Security and Assurance,\n  Chapter X, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The immune system provides a rich metaphor for computer security: anomaly\ndetection that works in nature should work for machines. However, early\nartificial immune system approaches for computer security had only limited\nsuccess. Arguably, this was due to these artificial systems being based on too\nsimplistic a view of the immune system. We present here a second generation\nartificial immune system for process anomaly detection. It improves on earlier\nsystems by having different artificial cell types that process information.\nFollowing detailed information about how to build such second generation\nsystems, we find that communication between cells types is key to performance.\nThrough realistic testing and validation we show that second generation\nartificial immune systems are capable of anomaly detection beyond generic\nsystem policies. The paper concludes with a discussion and outline of the next\nsteps in this exciting area of computer security.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 13:44:37 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Twycross", "Jamie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "0910.3124", "submitter": "Uwe Aickelin", "authors": "Gianni Tedesco, Uwe Aickelin", "title": "An Immune Inspired Network Intrusion Detection System Utilising\n  Correlation Context", "comments": "2 pages, Workshop on Artificial Immune Systems and Immune System\n  Modelling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Intrusion Detection Systems (NIDS) are computer systems which monitor\na network with the aim of discerning malicious from benign activity on that\nnetwork. While a wide range of approaches have met varying levels of success,\nmost IDSs rely on having access to a database of known attack signatures which\nare written by security experts. Nowadays, in order to solve problems with\nfalse positive alerts, correlation algorithms are used to add additional\nstructure to sequences of IDS alerts. However, such techniques are of no help\nin discovering novel attacks or variations of known attacks, something the\nhuman immune system (HIS) is capable of doing in its own specialised domain.\nThis paper presents a novel immune algorithm for application to the IDS\nproblem. The goal is to discover packets containing novel variations of attacks\ncovered by an existing signature base.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 13:55:41 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Tedesco", "Gianni", ""], ["Aickelin", "Uwe", ""]]}, {"id": "0910.3301", "submitter": "Julian McAuley", "authors": "Julian J. McAuley, Tiberio S. Caetano", "title": "Faster Algorithms for Max-Product Message-Passing", "comments": "34 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum A Posteriori inference in graphical models is often solved via\nmessage-passing algorithms, such as the junction-tree algorithm, or loopy\nbelief-propagation. The exact solution to this problem is well known to be\nexponential in the size of the model's maximal cliques after it is\ntriangulated, while approximate inference is typically exponential in the size\nof the model's factors. In this paper, we take advantage of the fact that many\nmodels have maximal cliques that are larger than their constituent factors, and\nalso of the fact that many factors consist entirely of latent variables (i.e.,\nthey do not depend on an observation). This is a common case in a wide variety\nof applications, including grids, trees, and ring-structured models. In such\ncases, we are able to decrease the exponent of complexity for message-passing\nby 0.5 for both exact and approximate inference.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2009 13:42:35 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2009 04:02:16 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2009 03:41:24 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2010 05:24:55 GMT"}], "update_date": "2010-04-09", "authors_parsed": [["McAuley", "Julian J.", ""], ["Caetano", "Tiberio S.", ""]]}, {"id": "0910.3348", "submitter": "Harris Georgiou", "authors": "Harris Georgiou", "title": "Algorithms for Image Analysis and Combination of Pattern Classifiers\n  with Application to Medical Diagnosis", "comments": "PhD thesis summary, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GT cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Medical Informatics and the application of modern signal processing in the\nassistance of the diagnostic process in medical imaging is one of the more\nrecent and active research areas today. This thesis addresses a variety of\nissues related to the general problem of medical image analysis, specifically\nin mammography, and presents a series of algorithms and design approaches for\nall the intermediate levels of a modern system for computer-aided diagnosis\n(CAD). The diagnostic problem is analyzed with a systematic approach, first\ndefining the imaging characteristics and features that are relevant to probable\npathology in mammo-grams. Next, these features are quantified and fused into\nnew, integrated radio-logical systems that exhibit embedded digital signal\nprocessing, in order to improve the final result and minimize the radiological\ndose for the patient. In a higher level, special algorithms are designed for\ndetecting and encoding these clinically interest-ing imaging features, in order\nto be used as input to advanced pattern classifiers and machine learning\nmodels. Finally, these approaches are extended in multi-classifier models under\nthe scope of Game Theory and optimum collective deci-sion, in order to produce\nefficient solutions for combining classifiers with minimum computational costs\nfor advanced diagnostic systems. The material covered in this thesis is related\nto a total of 18 published papers, 6 in scientific journals and 12 in\ninternational conferences.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2009 03:31:33 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Georgiou", "Harris", ""]]}, {"id": "0910.3485", "submitter": "Yongzhi Cao", "authors": "Yongzhi Cao and Guoqing Chen", "title": "A Fuzzy Petri Nets Model for Computing With Words", "comments": "double columns 14 pages, 8 figures", "journal-ref": "IEEE Trans. Fuzzy Syst., vol. 18, no. 3, pp. 486-499, 2010", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by Zadeh's paradigm of computing with words rather than numbers,\nseveral formal models of computing with words have recently been proposed.\nThese models are based on automata and thus are not well-suited for concurrent\ncomputing. In this paper, we incorporate the well-known model of concurrent\ncomputing, Petri nets, together with fuzzy set theory and thereby establish a\nconcurrency model of computing with words--fuzzy Petri nets for computing with\nwords (FPNCWs). The new feature of such fuzzy Petri nets is that the labels of\ntransitions are some special words modeled by fuzzy sets. By employing the\nmethodology of fuzzy reasoning, we give a faithful extension of an FPNCW which\nmakes it possible for computing with more words. The language expressiveness of\nthe two formal models of computing with words, fuzzy automata for computing\nwith words and FPNCWs, is compared as well. A few small examples are provided\nto illustrate the theoretical development.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 09:09:43 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Cao", "Yongzhi", ""], ["Chen", "Guoqing", ""]]}, {"id": "0910.3913", "submitter": "Radu Grigore", "authors": "Mikolas Janota, Goetz Botterweck, Radu Grigore, Joao Marques-Silva", "title": "How to Complete an Interactive Configuration Process?", "comments": "to appear in SOFSEM 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When configuring customizable software, it is useful to provide interactive\ntool-support that ensures that the configuration does not breach given\nconstraints.\n  But, when is a configuration complete and how can the tool help the user to\ncomplete it?\n  We formalize this problem and relate it to concepts from non-monotonic\nreasoning well researched in Artificial Intelligence. The results are\ninteresting for both practitioners and theoreticians. Practitioners will find a\ntechnique facilitating an interactive configuration process and experiments\nsupporting feasibility of the approach. Theoreticians will find links between\nwell-known formal concepts and a concrete practical application.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2009 17:30:33 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Janota", "Mikolas", ""], ["Botterweck", "Goetz", ""], ["Grigore", "Radu", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "0910.4116", "submitter": "M Sabu THAMPI", "authors": "Sabu M. Thampi", "title": "Swarm Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biologically inspired computing is an area of computer science which uses the\nadvantageous properties of biological systems. It is the amalgamation of\ncomputational intelligence and collective intelligence. Biologically inspired\nmechanisms have already proved successful in achieving major advances in a wide\nrange of problems in computing and communication systems. The consortium of\nbio-inspired computing are artificial neural networks, evolutionary algorithms,\nswarm intelligence, artificial immune systems, fractal geometry, DNA computing\nand quantum computing, etc. This article gives an introduction to swarm\nintelligence.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2009 15:02:12 GMT"}], "update_date": "2009-10-22", "authors_parsed": [["Thampi", "Sabu M.", ""]]}, {"id": "0910.4699", "submitter": "Ariel  Procaccia", "authors": "Noga Alon, Felix Fischer, Ariel D. Procaccia, Moshe Tennenholtz", "title": "Sum of Us: Strategyproof Selection from the Selectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider directed graphs over a set of n agents, where an edge (i,j) is\ntaken to mean that agent i supports or trusts agent j. Given such a graph and\nan integer k\\leq n, we wish to select a subset of k agents that maximizes the\nsum of indegrees, i.e., a subset of k most popular or most trusted agents. At\nthe same time we assume that each individual agent is only interested in being\nselected, and may misreport its outgoing edges to this end. This problem\nformulation captures realistic scenarios where agents choose among themselves,\nwhich can be found in the context of Internet search, social networks like\nTwitter, or reputation systems like Epinions.\n  Our goal is to design mechanisms without payments that map each graph to a\nk-subset of agents to be selected and satisfy the following two constraints:\nstrategyproofness, i.e., agents cannot benefit from misreporting their outgoing\nedges, and approximate optimality, i.e., the sum of indegrees of the selected\nsubset of agents is always close to optimal. Our first main result is a\nsurprising impossibility: for k \\in {1,...,n-1}, no deterministic strategyproof\nmechanism can provide a finite approximation ratio. Our second main result is a\nrandomized strategyproof mechanism with an approximation ratio that is bounded\nfrom above by four for any value of k, and approaches one as k grows.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2009 02:01:09 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Alon", "Noga", ""], ["Fischer", "Felix", ""], ["Procaccia", "Ariel D.", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "0910.4899", "submitter": "Uwe Aickelin", "authors": "Uwe Aickelin, Dipankar Dasgupta", "title": "Artificial Immune Systems", "comments": "29 pages,4 figures,", "journal-ref": "Search Methodologies: Introductory Tutorials in Optimisation and\n  Decision Support Techniques, 375-399, 2005", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biological immune system is a robust, complex, adaptive system that\ndefends the body from foreign pathogens. It is able to categorize all cells (or\nmolecules) within the body as self-cells or non-self cells. It does this with\nthe help of a distributed task force that has the intelligence to take action\nfrom a local and also a global perspective using its network of chemical\nmessengers for communication. There are two major branches of the immune\nsystem. The innate immune system is an unchanging mechanism that detects and\ndestroys certain invading organisms, whilst the adaptive immune system responds\nto previously unknown foreign cells and builds a response to them that can\nremain in the body over a long period of time. This remarkable information\nprocessing biological system has caught the attention of computer science in\nrecent years. A novel computational intelligence technique, inspired by\nimmunology, has emerged, called Artificial Immune Systems. Several concepts\nfrom the immune have been extracted and applied for solution to real world\nscience and engineering problems. In this tutorial, we briefly describe the\nimmune system metaphors that are relevant to existing Artificial Immune Systems\nmethods. We will then show illustrative real-world problems suitable for\nArtificial Immune Systems and give a step-by-step algorithm walkthrough for one\nsuch problem. A comparison of the Artificial Immune Systems to other well-known\nalgorithms, areas for future work, tips & tricks and a list of resources will\nround this tutorial off. It should be noted that as Artificial Immune Systems\nis still a young and evolving field, there is not yet a fixed algorithm\ntemplate and hence actual implementations might differ somewhat from time to\ntime and from those examples given here.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 14:54:46 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Aickelin", "Uwe", ""], ["Dasgupta", "Dipankar", ""]]}, {"id": "0910.4903", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Uwe Aickelin, Jamie Twycross", "title": "Articulation and Clarification of the Dendritic Cell Algorithm", "comments": "14 pages, 4 figures, 5th International Conference on Artificial\n  Immune Systems (ICARIS2006)", "journal-ref": "Proceedings of 5th International Conference on Artificial Immune\n  Systems (ICARIS2006), 404-417, 2006", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dendritic Cell algorithm (DCA) is inspired by recent work in innate\nimmunity. In this paper a formal description of the DCA is given. The DCA is\ndescribed in detail, and its use as an anomaly detector is illustrated within\nthe context of computer security. A port scan detection task is performed to\nsubstantiate the influence of signal selection on the behaviour of the\nalgorithm. Experimental results provide a comparison of differing input signal\nmappings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 15:13:04 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""], ["Twycross", "Jamie", ""]]}, {"id": "0910.5405", "submitter": "Uwe Aickelin", "authors": "Jan Feyereisl, Uwe Aickelin", "title": "Artificial Immune Tissue using Self-Orgamizing Networks", "comments": "2 pages, 1 figure, Workshop on Artificial Immune Systems and Immune\n  Systems Modelling (AISB06)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As introduced by Bentley et al. (2005), artificial immune systems (AIS) are\nlacking tissue, which is present in one form or another in all living\nmulti-cellular organisms. Some have argued that this concept in the context of\nAIS brings little novelty to the already saturated field of the immune inspired\ncomputational research. This article aims to show that such a component of an\nAIS has the potential to bring an advantage to a data processing algorithm in\nterms of data pre-processing, clustering and extraction of features desired by\nthe immune inspired system. The proposed tissue algorithm is based on\nself-organizing networks, such as self-organizing maps (SOM) developed by\nKohonen (1996) and an analogy of the so called Toll-Like Receptors (TLR)\naffecting the activation function of the clusters developed by the SOM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 15:36:33 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Feyereisl", "Jan", ""], ["Aickelin", "Uwe", ""]]}, {"id": "0910.5410", "submitter": "David Fernandez-Amoros", "authors": "David Fernandez-Amoros, Julio Gonzalo, Felisa Verdejo", "title": "The Uned systems at Senseval-2", "comments": "latex2e, 5 pages, appeared in SENSEVAL-2, held with ACL-02", "journal-ref": "In Proceedings of the Second International Workshop on Evaluating\n  Word Sense Disambiguation Systems (SENSEVAL), Toulouse 2002", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have participated in the SENSEVAL-2 English tasks (all words and lexical\nsample) with an unsupervised system based on mutual information measured over a\nlarge corpus (277 million words) and some additional heuristics. A supervised\nextension of the system was also presented to the lexical sample task.\n  Our system scored first among unsupervised systems in both tasks: 56.9%\nrecall in all words, 40.2% in lexical sample. This is slightly worse than the\nfirst sense heuristic for all words and 3.6% better for the lexical sample, a\nstrong indication that unsupervised Word Sense Disambiguation remains being a\nstrong challenge.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 16:58:27 GMT"}], "update_date": "2009-10-29", "authors_parsed": [["Fernandez-Amoros", "David", ""], ["Gonzalo", "Julio", ""], ["Verdejo", "Felisa", ""]]}, {"id": "0910.5419", "submitter": "David Fernandez-Amoros", "authors": "David Fernandez-Amoros", "title": "Word Sense Disambiguation Based on Mutual Information and Syntactic\n  Patterns", "comments": "latex2e, 5 pages, appeared in SENSEVAL-3, Barcelona 2004", "journal-ref": "In proceedings of the Third International Workshop on Evaluating\n  Word Sense Disambiguation Systems (SENSEVAL) 2004, Barcelona", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a hybrid system for WSD, presented to the English\nall-words and lexical-sample tasks, that relies on two different unsupervised\napproaches. The first one selects the senses according to mutual information\nproximity between a context word a variant of the sense. The second heuristic\nanalyzes the examples of use in the glosses of the senses so that simple\nsyntactic patterns are inferred. This patterns are matched against the\ndisambiguation contexts. We show that the first heuristic obtains a precision\nand recall of .58 and .35 respectively in the all words task while the second\nobtains .80 and .25. The high precision obtained recommends deeper research of\nthe techniques. Results for the lexical sample task are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 17:03:00 GMT"}], "update_date": "2009-10-29", "authors_parsed": [["Fernandez-Amoros", "David", ""]]}, {"id": "0910.5542", "submitter": "Alexander Spirov", "authors": "Alexander V. Spirov, Alexander B. Kazansky, Leonid Zamdborg, Juan J.\n  Merelo and Vladimir F. Levchenko", "title": "Forced Evolution in Silico by Artificial Transposons and their Genetic\n  Operators: The John Muir Ant Problem", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern evolutionary computation utilizes heuristic optimizations based upon\nconcepts borrowed from the Darwinian theory of natural selection. We believe\nthat a vital direction in this field must be algorithms that model the activity\nof genomic parasites, such as transposons, in biological evolution. This\npublication is our first step in the direction of developing a minimal\nassortment of algorithms that simulate the role of genomic parasites.\nSpecifically, we started in the domain of genetic algorithms (GA) and selected\nthe Artificial Ant Problem as a test case. We define these artificial\ntransposons as a fragment of an ant's code that possesses properties that cause\nit to stand apart from the rest. We concluded that artificial transposons,\nanalogous to real transposons, are truly capable of acting as intelligent\nmutators that adapt in response to an evolutionary problem in the course of\nco-evolution with their hosts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2009 03:11:12 GMT"}], "update_date": "2009-10-30", "authors_parsed": [["Spirov", "Alexander V.", ""], ["Kazansky", "Alexander B.", ""], ["Zamdborg", "Leonid", ""], ["Merelo", "Juan J.", ""], ["Levchenko", "Vladimir F.", ""]]}, {"id": "0910.5682", "submitter": "David Fernandez-Amoros", "authors": "David Fernandez-Amoros", "title": "Word Sense Disambiguation Using English-Spanish Aligned Phrases over\n  Comparable Corpora", "comments": "latex2e, 8 pages, 1 figure, published in the Proceedings of\n  Cross-Language Knowledge Induction Workshop, 2005 Cluj-Napoca, held during\n  the summer school EUROLAN 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a WSD experiment based on bilingual English-Spanish\ncomparable corpora in which individual noun phrases have been identified and\naligned with their respective counterparts in the other language. The\nevaluation of the experiment has been carried out against SemCor.\n  We show that, with the alignment algorithm employed, potential precision is\nhigh (74.3%), however the coverage of the method is low (2.7%), due to\nalignments being far less frequent than we expected.\n  Contrary to our intuition, precision does not rise consistently with the\nnumber of alignments. The coverage is low due to several factors; there are\nimportant domain differences, and English and Spanish are too close languages\nfor this approach to be able to discriminate efficiently between senses,\nrendering it unsuitable for WSD, although the method may prove more productive\nin machine translation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2009 17:19:01 GMT"}], "update_date": "2009-10-30", "authors_parsed": [["Fernandez-Amoros", "David", ""]]}]