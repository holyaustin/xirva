[{"id": "1409.0069", "submitter": "Amir Zidi", "authors": "Amir Zidi and Amna Bouhana and Afef Fekih and Mourad Abed", "title": "Personalization of Itineraries search using Ontology and Rules to Avoid\n  Congestion in Urban Areas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a relatively small amount of research covering urban freight\nmovements. Most research dealing with the subject of urban mobility focuses on\npassenger vehicles, not commercial vehicles hauling freight. However, in many\nways, urban freight transport contributes to congestion, air pollution, noise,\naccident and more fuel consumption which raises logistic costs, and hence the\nprice of products. The main focus of this paper is to propose a new solution\nfor congestion in order to improve the distribution process of goods in urban\nareas and optimize transportation cost, time of delivery, fuel consumption, and\nenvironmental impact, while guaranteeing the safety of goods and passengers. A\nnovel technique for personalization in itinerary search based on city logistics\nontology and rules is proposed to overcome this problem. The integration of\npersonalization plays a key role in capturing or inferring the needs of each\nstakeholder (user), and then satisfying these needs in a given context. The\nproposed approach is implemented to an itinerary search problem for freight\ntransportation in urban areas to demonstrate its ability in facilitating\nintelligent decision support by retrieving the best itinerary that satisfies\nthe most users preferences (stakeholders).\n", "versions": [{"version": "v1", "created": "Sat, 30 Aug 2014 00:24:27 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Zidi", "Amir", ""], ["Bouhana", "Amna", ""], ["Fekih", "Afef", ""], ["Abed", "Mourad", ""]]}, {"id": "1409.0302", "submitter": "Muthukumaran Chandrasekaran", "authors": "Muthukumaran Chandrasekaran, Prashant Doshi, Yifeng Zeng and Yingke\n  Chen", "title": "Team Behavior in Interactive Dynamic Influence Diagrams with\n  Applications to Ad Hoc Teams", "comments": "8 pages, Appeared in the MSDM Workshop at AAMAS 2014, Extended\n  Abstract version appeared at AAMAS 2014, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for ad hoc teamwork is challenging because it involves agents\ncollaborating without any prior coordination or communication. The focus is on\nprincipled methods for a single agent to cooperate with others. This motivates\ninvestigating the ad hoc teamwork problem in the context of individual decision\nmaking frameworks. However, individual decision making in multiagent settings\nfaces the task of having to reason about other agents' actions, which in turn\ninvolves reasoning about others. An established approximation that\noperationalizes this approach is to bound the infinite nesting from below by\nintroducing level 0 models. We show that a consequence of the finitely-nested\nmodeling is that we may not obtain optimal team solutions in cooperative\nsettings. We address this limitation by including models at level 0 whose\nsolutions involve learning. We demonstrate that the learning integrated into\nplanning in the context of interactive dynamic influence diagrams facilitates\noptimal team behavior, and is applicable to ad hoc teamwork.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 06:53:27 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Chandrasekaran", "Muthukumaran", ""], ["Doshi", "Prashant", ""], ["Zeng", "Yifeng", ""], ["Chen", "Yingke", ""]]}, {"id": "1409.0703", "submitter": "Alejandro Sanchez Guinea", "authors": "Alejandro Sanchez Guinea", "title": "On computable abstractions (a conceptual introduction)", "comments": "17 pages; clearer and more precise motivation; clearer concepts\n  presented; review on related works added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces abstractions that are meaningful for computers and that\ncan be built and used according to computers' own criteria, i.e., computable\nabstractions. It is analyzed how abstractions can be seen to serve as the\nbuilding blocks for the creation of one own's understanding of things, which is\nessential in performing intellectual tasks. Thus, abstractional machines are\ndefined, which following a mechanical process can, based on computable\nabstractions, build and use their own understanding of things. Abstractional\nmachines are illustrated through an example that outlines their application to\nthe task of natural language processing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 18:29:53 GMT"}, {"version": "v2", "created": "Tue, 9 Dec 2014 14:50:58 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2015 13:21:52 GMT"}, {"version": "v4", "created": "Sun, 29 Mar 2015 14:27:16 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Guinea", "Alejandro Sanchez", ""]]}, {"id": "1409.0791", "submitter": "Jian Yang", "authors": "Jian Yang, Liqiu Meng", "title": "Feature Selection in Conditional Random Fields for Map Matching of GPS\n  Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Map matching of the GPS trajectory serves the purpose of recovering the\noriginal route on a road network from a sequence of noisy GPS observations. It\nis a fundamental technique to many Location Based Services. However, map\nmatching of a low sampling rate on urban road network is still a challenging\ntask. In this paper, the characteristics of Conditional Random Fields with\nregard to inducing many contextual features and feature selection are explored\nfor the map matching of the GPS trajectories at a low sampling rate.\nExperiments on a taxi trajectory dataset show that our method may achieve\ncompetitive results along with the success of reducing model complexity for\ncomputation-limited applications.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 16:52:53 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Yang", "Jian", ""], ["Meng", "Liqiu", ""]]}, {"id": "1409.0813", "submitter": "Max Tegmark", "authors": "Max Tegmark (MIT)", "title": "Friendly Artificial Intelligence: the Physics Challenge", "comments": "3 pages", "journal-ref": "In proceedings of the AAAI 2015 Workshop On AI and Ethics, p87,\n  Toby Walsh, Ed. (2015)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relentless progress in artificial intelligence (AI) is increasingly raising\nconcerns that machines will replace humans on the job market, and perhaps\naltogether. Eliezer Yudkowski and others have explored the possibility that a\npromising future for humankind could be guaranteed by a superintelligent\n\"Friendly AI\", designed to safeguard humanity and its values. I argue that,\nfrom a physics perspective where everything is simply an arrangement of\nelementary particles, this might be even harder than it appears. Indeed, it may\nrequire thinking rigorously about the meaning of life: What is \"meaning\" in a\nparticle arrangement? What is \"life\"? What is the ultimate ethical imperative,\ni.e., how should we strive to rearrange the particles of our Universe and shape\nits future? If we fail to answer the last question rigorously, this future is\nunlikely to contain humans.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 18:20:28 GMT"}, {"version": "v2", "created": "Wed, 3 Sep 2014 15:05:07 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Tegmark", "Max", "", "MIT"]]}, {"id": "1409.0824", "submitter": "Daniel Osherson", "authors": "Daniel Osherson and Scott Weinstein", "title": "Deontic modality based on preference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deontic modalities are here defined in terms of the preference relation\nexplored in our previous work (Osherson and Weinstein, 2012). Some consequences\nof the system are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 19:01:01 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Osherson", "Daniel", ""], ["Weinstein", "Scott", ""]]}, {"id": "1409.0925", "submitter": "Ahmad Hassanat", "authors": "Ahmad B. A. Hassanat", "title": "Bypassing Captcha By Machine A Proof For Passing The Turing Test", "comments": "European Scientific Journal May 2014 edition vol.10, No.15 ISSN:\n  1857-7881 (Print) e-ISSN 1857-7431", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last ten years, CAPTCHAs have been widely used by websites to prevent\ntheir data being automatically updated by machines. By supposedly allowing only\nhumans to do so, CAPTCHAs take advantage of the reverse Turing test (TT),\nknowing that humans are more intelligent than machines. Generally, CAPTCHAs\nhave defeated machines, but things are changing rapidly as technology improves.\nHence, advanced research into optical character recognition (OCR) is overtaking\nattempts to strengthen CAPTCHAs against machine-based attacks. This paper\ninvestigates the immunity of CAPTCHA, which was built on the failure of the TT.\nWe show that some CAPTCHAs are easily broken using a simple OCR machine built\nfor the purpose of this study. By reviewing other techniques, we show that even\nmore difficult CAPTCHAs can be broken using advanced OCR machines. Current\nadvances in OCR should enable machines to pass the TT in the image recognition\ndomain, which is exactly where machines are seeking to overcome CAPTCHAs. We\nenhance traditional CAPTCHAs by employing not only characters, but also natural\nlanguage and multiple objects within the same CAPTCHA. The proposed CAPTCHAs\nmight be able to hold out against machines, at least until the advent of a\nmachine that passes the TT completely.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 00:05:28 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Hassanat", "Ahmad B. A.", ""]]}, {"id": "1409.1045", "submitter": "Uwe Aickelin", "authors": "Josie C. McCullochy, Chris J. Hinde, Christian Wagner and Uwe Aickelin", "title": "A Fuzzy Directional Distance Measure", "comments": "Proceedings of the 2014 World Congress on Computational Intelligence\n  (WCCI 2014), pp. 141-148, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measure of distance between two fuzzy sets is a fundamental tool within\nfuzzy set theory, however, distance measures currently within the literature\nuse a crisp value to represent the distance between fuzzy sets. A real valued\ndistance measure is developed into a fuzzy distance measure which better\nreflects the uncertainty inherent in fuzzy sets and a fuzzy directional\ndistance measure is presented, which accounts for the direction of change\nbetween fuzzy sets. A multiplicative version is explored as a full maximal\nassignment is computationally intractable so an intermediate solution is\noffered.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 11:48:23 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["McCullochy", "Josie C.", ""], ["Hinde", "Chris J.", ""], ["Wagner", "Christian", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1409.1046", "submitter": "Uwe Aickelin", "authors": "Josie McCulloch, Christian Wagner and Uwe Aickelin", "title": "Analysing Fuzzy Sets Through Combining Measures of Similarity and\n  Distance", "comments": "Proceedings of the 2014 World Congress on Computational Intelligence\n  (WCCI 2014), pp. 155-162, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with fuzzy sets can be achieved through measures such as similarity\nand distance. However, these measures can often give misleading results when\nconsidered independently, for example giving the same value for two different\npairs of fuzzy sets. This is particularly a problem where many fuzzy sets are\ngenerated from real data, and while two different measures may be used to\nautomatically compare such fuzzy sets, it is difficult to interpret two\ndifferent results. This is especially true where a large number of fuzzy sets\nare being compared as part of a reasoning system. This paper introduces a\nmethod for combining the results of multiple measures into a single measure for\nthe purpose of analysing and comparing fuzzy sets. The combined measure\nalleviates ambiguous results and aids in the automatic comparison of fuzzy\nsets. The properties of the combined measure are given, and demonstrations are\npresented with discussions on the advantages over using a single measure.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 11:52:07 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["McCulloch", "Josie", ""], ["Wagner", "Christian", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1409.1170", "submitter": "Kamran Latif", "authors": "Kamran Latif", "title": "Hybrid Systems Knowledge Representation Using Modelling Environment\n  System Techniques Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge-based or Artificial Intelligence techniques are used increasingly\nas alternatives to more classical techniques to model ENVIRONMENTAL SYSTEMS.\nUse of Artificial Intelligence (AI) in environmental modelling has increased\nwith recognition of its potential. In this paper we examine the DIFFERENT\nTECHNIQUES of Artificial intelligence with profound examples of human\nperception, learning and reasoning to solve complex problems. However with the\nincrease of complexity better methods are required. Keeping in view of the\nabove some researchers introduced the idea of hybrid mechanism in which two or\nmore methods can be combined which seems to be a positive effort for creating a\nmore complex; advanced and intelligent system which has the capability to in-\ncooperate human decisions thus driving the landscape changes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 17:04:58 GMT"}, {"version": "v2", "created": "Sat, 13 Sep 2014 18:23:11 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Latif", "Kamran", ""]]}, {"id": "1409.1455", "submitter": "Vasumathi Raman", "authors": "Vasumathi Raman and Hadas Kress-Gazit", "title": "Unsynthesizable Cores - Minimal Explanations for Unsynthesizable\n  High-Level Robot Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing ubiquity of multi-capable, general-purpose robots arises\nthe need for enabling non-expert users to command these robots to perform\ncomplex high-level tasks. To this end, high-level robot control has seen the\napplication of formal methods to automatically synthesize\ncorrect-by-construction controllers from user-defined specifications; synthesis\nfails if and only if there exists no controller that achieves the specified\nbehavior. Recent work has also addressed the challenge of providing\neasy-to-understand feedback to users when a specification fails to yield a\ncorresponding controller. Existing techniques provide feedback on portions of\nthe specification that cause the failure, but do so at a coarse granularity.\nThis work presents techniques for refining this feedback, extracting minimal\nexplanations of unsynthesizability.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 14:50:54 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Raman", "Vasumathi", ""], ["Kress-Gazit", "Hadas", ""]]}, {"id": "1409.1456", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh, Philip Liu, Trent Bjorndahl, Rupasri Mandal, Jason\n  R. Grant, Michael Wilson, Roman Eisner, Igor Sinelnikov, Xiaoyu Hu, Claudio\n  Luchinat, Russell Greiner and David S. Wishart", "title": "Accurate, fully-automated NMR spectral profiling for metabolomics", "comments": null, "journal-ref": "PLoS ONE 10(5): e0124219, 2015", "doi": "10.1371/journal.pone.0124219", "report-no": null, "categories": "cs.AI cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many diseases cause significant changes to the concentrations of small\nmolecules (aka metabolites) that appear in a person's biofluids, which means\nsuch diseases can often be readily detected from a person's \"metabolic\nprofile\". This information can be extracted from a biofluid's NMR spectrum.\nToday, this is often done manually by trained human experts, which means this\nprocess is relatively slow, expensive and error-prone. This paper presents a\ntool, Bayesil, that can quickly, accurately and autonomously produce a complex\nbiofluid's (e.g., serum or CSF) metabolic profile from a 1D1H NMR spectrum.\nThis requires first performing several spectral processing steps then matching\nthe resulting spectrum against a reference compound library, which contains the\n\"signatures\" of each relevant metabolite. Many of these steps are novel\nalgorithms and our matching step views spectral matching as an inference\nproblem within a probabilistic graphical model that rapidly approximates the\nmost probable metabolic profile. Our extensive studies on a diverse set of\ncomplex mixtures, show that Bayesil can autonomously find the concentration of\nall NMR-detectable metabolites accurately (~90% correct identification and ~10%\nquantification error), in <5minutes on a single CPU. These results demonstrate\nthat Bayesil is the first fully-automatic publicly-accessible system that\nprovides quantitative NMR spectral profiling effectively -- with an accuracy\nthat meets or exceeds the performance of trained experts. We anticipate this\ntool will usher in high-throughput metabolomics and enable a wealth of new\napplications of NMR in clinical settings. Available at http://www.bayesil.ca.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 14:50:56 GMT"}, {"version": "v2", "created": "Fri, 5 Sep 2014 16:23:42 GMT"}, {"version": "v3", "created": "Mon, 8 Sep 2014 01:25:52 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Liu", "Philip", ""], ["Bjorndahl", "Trent", ""], ["Mandal", "Rupasri", ""], ["Grant", "Jason R.", ""], ["Wilson", "Michael", ""], ["Eisner", "Roman", ""], ["Sinelnikov", "Igor", ""], ["Hu", "Xiaoyu", ""], ["Luchinat", "Claudio", ""], ["Greiner", "Russell", ""], ["Wishart", "David S.", ""]]}, {"id": "1409.1686", "submitter": "Fr\\'ed\\'eric Saubion", "authors": "Adrien Go\\\"effon and Fr\\'ed\\'eric Lardeux and Fr\\'ed\\'eric Saubion", "title": "Simulating Non Stationary Operators in Search Algorithms", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2015.09.024", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model for simulating search operators whose\nbehaviour often changes continuously during the search. In these scenarios, the\nperformance of the operators decreases when they are applied. This is motivated\nby the fact that operators for optimization problems are often roughly\nclassified into exploitation operators and exploration operators. Our\nsimulation model is used to compare the different performances of operator\nselection policies and clearly identify their ability to adapt to such specific\noperators behaviours. The experimental study provides interesting results on\nthe respective behaviours of operator selection policies when faced to such non\nstationary search scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 08:29:35 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Go\u00ebffon", "Adrien", ""], ["Lardeux", "Fr\u00e9d\u00e9ric", ""], ["Saubion", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1409.2287", "submitter": "Andreas Damianou Mr", "authors": "Andreas C. Damianou, Michalis K. Titsias, Neil D. Lawrence", "title": "Variational Inference for Uncertainty on the Inputs of Gaussian Process\n  Models", "comments": "51 pages (of which 10 is Appendix), 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process latent variable model (GP-LVM) provides a flexible\napproach for non-linear dimensionality reduction that has been widely applied.\nHowever, the current approach for training GP-LVMs is based on maximum\nlikelihood, where the latent projection variables are maximized over rather\nthan integrated out. In this paper we present a Bayesian method for training\nGP-LVMs by introducing a non-standard variational inference framework that\nallows to approximately integrate out the latent variables and subsequently\ntrain a GP-LVM by maximizing an analytic lower bound on the exact marginal\nlikelihood. We apply this method for learning a GP-LVM from iid observations\nand for learning non-linear dynamical systems where the observations are\ntemporally correlated. We show that a benefit of the variational Bayesian\nprocedure is its robustness to overfitting and its ability to automatically\nselect the dimensionality of the nonlinear latent space. The resulting\nframework is generic, flexible and easy to extend for other purposes, such as\nGaussian process regression with uncertain inputs and semi-supervised Gaussian\nprocesses. We demonstrate our method on synthetic data and standard machine\nlearning benchmarks, as well as challenging real world datasets, including high\nresolution video data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 10:47:23 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Damianou", "Andreas C.", ""], ["Titsias", "Michalis K.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1409.2399", "submitter": "Michal \\v{C}\\'ap", "authors": "Michal \\v{C}\\'ap, Peter Nov\\'ak, Alexander Kleiner, Martin Seleck\\'y", "title": "Prioritized Planning Algorithms for Trajectory Coordination of Multiple\n  Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important capability of autonomous multi-robot systems is to prevent\ncollision among the individual robots. One approach to this problem is to plan\nconflict-free trajectories and let each of the robots follow its pre-planned\ntrajectory. A widely used practical method for multi-robot trajectory planning\nis prioritized planning, which has been shown to be effective in practice, but\nis in general incomplete. Formal analysis of instances that are provably\nsolvable by prioritized planning is still missing. Moreover, prioritized\nplanning is a centralized algorithm, which may be in many situations\nundesirable.\n  In this paper we a) propose a revised version of prioritized planning and\ncharacterize the class of instances that are provably solvable by the algorithm\nand b) propose an asynchronous decentralized variant of prioritized planning,\nwhich maintains the desirable properties of the centralized version and in the\nsame time exploits the distributed computational power of the individual\nrobots, which in most situations allows to find the joint trajectories faster.\n  The experimental evaluation performed on real-world indoor maps shows that a)\nthe revised version of prioritized planning reliably solves a wide class of\ninstances on which both classical prioritized planning and popular reactive\ntechnique ORCA fail and b) the asynchronous decentralized algorithm provides\nsolution faster than the previously proposed synchronized decentralized\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 15:38:31 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["\u010c\u00e1p", "Michal", ""], ["Nov\u00e1k", "Peter", ""], ["Kleiner", "Alexander", ""], ["Seleck\u00fd", "Martin", ""]]}, {"id": "1409.2650", "submitter": "Ihab Sbeity", "authors": "Ihab Sbeity, Mohamed Dbouk, Habib Kobeissi", "title": "Combining the analytical hierarchy process and the genetic algorithm to\n  solve the timetable problem", "comments": "International Journal of Software Engineering & Applications (IJSEA),\n  Vol.5, No.4, July 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main problems of school course timetabling are time, curriculum, and\nclassrooms. In addition there are other problems that vary from one institution\nto another. This paper is intended to solve the problem of satisfying the\nteachers preferred schedule in a way that regards the importance of the teacher\nto the supervising institute, i.e. his score according to some criteria.\nGenetic algorithm (GA) has been presented as an elegant method in solving\ntimetable problem (TTP) in order to produce solutions with no conflict. In this\npaper, we consider the analytic hierarchy process (AHP) to efficiently obtain a\nscore for each teacher, and consequently produce a GA-based TTP solution that\nsatisfies most of the teachers preferences.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 09:30:48 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Sbeity", "Ihab", ""], ["Dbouk", "Mohamed", ""], ["Kobeissi", "Habib", ""]]}, {"id": "1409.2821", "submitter": "Nasser Ghadiri", "authors": "Meysam Ghaffari, Nasser Ghadiri", "title": "Ambiguity-Driven Fuzzy C-Means Clustering: How to Detect Uncertain\n  Clustered Records", "comments": null, "journal-ref": null, "doi": "10.1007/s10489-016-0759-1", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a well-known clustering algorithm, Fuzzy C-Means (FCM) allows each input\nsample to belong to more than one cluster, providing more flexibility than\nnon-fuzzy clustering methods. However, the accuracy of FCM is subject to false\ndetections caused by noisy records, weak feature selection and low certainty of\nthe algorithm in some cases. The false detections are very important in some\ndecision-making application domains like network security and medical\ndiagnosis, where weak decisions based on such false detections may lead to\ncatastrophic outcomes. They are mainly emerged from making decisions about a\nsubset of records that do not provide enough evidence to make a good decision.\nIn this paper, we propose a method for detecting such ambiguous records in FCM\nby introducing a certainty factor to decrease invalid detections. This approach\nenables us to send the detected ambiguous records to another discrimination\nmethod for a deeper investigation, thus increasing the accuracy by lowering the\nerror rate. Most of the records are still processed quickly and with low error\nrate which prevents performance loss compared to similar hybrid methods.\nExperimental results of applying the proposed method on several datasets from\ndifferent domains show a significant decrease in error rate as well as improved\nsensitivity of the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 17:17:48 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Ghaffari", "Meysam", ""], ["Ghadiri", "Nasser", ""]]}, {"id": "1409.2897", "submitter": "Sunsern Cheamanunkul", "authors": "Sunsern Cheamanunkul and Yoav Freund", "title": "Co-adaptation in a Handwriting Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting is a natural and versatile method for human-computer interaction,\nespecially on small mobile devices such as smart phones. However, as\nhandwriting varies significantly from person to person, it is difficult to\ndesign handwriting recognizers that perform well for all users. A natural\nsolution is to use machine learning to adapt the recognizer to the user. One\ncomplicating factor is that, as the computer adapts to the user, the user also\nadapts to the computer and probably changes their handwriting. This paper\ninvestigates the dynamics of co-adaptation, a process in which both the\ncomputer and the user are adapting their behaviors in order to improve the\nspeed and accuracy of the communication through handwriting. We devised an\ninformation-theoretic framework for quantifying the efficiency of a handwriting\nsystem where the system includes both the user and the computer. Using this\nframework, we analyzed data collected from an adaptive handwriting recognition\nsystem and characterized the impact of machine adaptation and of human\nadaptation. We found that both machine adaptation and human adaptation have\nsignificant impact on the input rate and must be considered together in order\nto improve the efficiency of the system as a whole.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 21:06:14 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Cheamanunkul", "Sunsern", ""], ["Freund", "Yoav", ""]]}, {"id": "1409.3653", "submitter": "Lihong Li", "authors": "Lihong Li and Remi Munos and Csaba Szepesvari", "title": "On Minimax Optimal Offline Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the off-policy evaluation problem, where one aims to\nestimate the value of a target policy based on a sample of observations\ncollected by another policy. We first consider the multi-armed bandit case,\nestablish a minimax risk lower bound, and analyze the risk of two standard\nestimators. It is shown, and verified in simulation, that one is minimax\noptimal up to a constant, while another can be arbitrarily worse, despite its\nempirical success and popularity. The results are applied to related problems\nin contextual bandits and fixed-horizon Markov decision processes, and are also\nrelated to semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 06:10:15 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Li", "Lihong", ""], ["Munos", "Remi", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1409.3717", "submitter": "Francisco Coelho", "authors": "Francisco Coelho and Vitor Nogueira", "title": "Probabilistic Selection in AgentSpeak(L)", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent programming is mostly a symbolic discipline and, as such, draws little\nbenefits from probabilistic areas as machine learning and graphical models.\nHowever, the greatest objective of agent research is the achievement of\nautonomy in dynamical and complex environments --- a goal that implies\nembracing uncertainty and therefore the entailed representations, algorithms\nand techniques. This paper proposes an innovative and conflict free two layer\napproach to agent programming that uses already established methods and tools\nfrom both symbolic and probabilistic artificial intelligence. Moreover, this\nframework is illustrated by means of a widely used agent programming example,\nGoldMiners.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 12:27:44 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Coelho", "Francisco", ""], ["Nogueira", "Vitor", ""]]}, {"id": "1409.3836", "submitter": "Guy Bresler", "authors": "Guy Bresler, David Gamarnik, and Devavrat Shah", "title": "Hardness of parameter estimation in graphical models", "comments": "15 pages. To appear in NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.IT math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the canonical parameters specifying an\nundirected graphical model (Markov random field) from the mean parameters. For\ngraphical models representing a minimal exponential family, the canonical\nparameters are uniquely determined by the mean parameters, so the problem is\nfeasible in principle. The goal of this paper is to investigate the\ncomputational feasibility of this statistical task. Our main result shows that\nparameter estimation is in general intractable: no algorithm can learn the\ncanonical parameters of a generic pair-wise binary graphical model from the\nmean parameters in time bounded by a polynomial in the number of variables\n(unless RP = NP). Indeed, such a result has been believed to be true (see the\nmonograph by Wainwright and Jordan (2008)) but no proof was known.\n  Our proof gives a polynomial time reduction from approximating the partition\nfunction of the hard-core model, known to be hard, to learning approximate\nparameters. Our reduction entails showing that the marginal polytope boundary\nhas an inherent repulsive property, which validates an optimization procedure\nover the polytope that does not use any knowledge of its structure (as required\nby the ellipsoid method and others).\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 19:57:59 GMT"}, {"version": "v2", "created": "Wed, 17 Sep 2014 19:57:51 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Bresler", "Guy", ""], ["Gamarnik", "David", ""], ["Shah", "Devavrat", ""]]}, {"id": "1409.4161", "submitter": "Chengkai Li", "authors": "Abolfazl Asudeh, Gensheng Zhang, Naeemul Hassan, Chengkai Li, Gergely\n  V. Zaruba", "title": "Crowdsourcing Pareto-Optimal Object Finding by Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the first study on crowdsourcing Pareto-optimal object finding, which\nhas applications in public opinion collection, group decision making, and\ninformation exploration. Departing from prior studies on crowdsourcing skyline\nand ranking queries, it considers the case where objects do not have explicit\nattributes and preference relations on objects are strict partial orders. The\npartial orders are derived by aggregating crowdsourcers' responses to pairwise\ncomparison questions. The goal is to find all Pareto-optimal objects by the\nfewest possible questions. It employs an iterative question-selection\nframework. Guided by the principle of eagerly identifying non-Pareto optimal\nobjects, the framework only chooses candidate questions which must satisfy\nthree conditions. This design is both sufficient and efficient, as it is proven\nto find a short terminal question sequence. The framework is further steered by\ntwo ideas---macro-ordering and micro-ordering. By different micro-ordering\nheuristics, the framework is instantiated into several algorithms with varying\npower in pruning questions. Experiment results using both real crowdsourcing\nmarketplace and simulations exhibited not only orders of magnitude reductions\nin questions when compared with a brute-force approach, but also\nclose-to-optimal performance from the most efficient instantiation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 06:38:57 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Asudeh", "Abolfazl", ""], ["Zhang", "Gensheng", ""], ["Hassan", "Naeemul", ""], ["Li", "Chengkai", ""], ["Zaruba", "Gergely V.", ""]]}, {"id": "1409.4164", "submitter": "Tomas Trescak", "authors": "Tomas Trescak, Carles Sierra, Simeon Simoff, Ramon Lopez de Mantaras", "title": "Dispute Resolution Using Argumentation-Based Mediation", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Mediation is a process, in which both parties agree to resolve their dispute\nby negotiating over alternative solutions presented by a mediator. In order to\nconstruct such solutions, mediation brings more information and knowledge, and,\nif possible, resources to the negotiation table. The contribution of this paper\nis the automated mediation machinery which does that. It presents an\nargumentation-based mediation approach that extends the logic-based approach to\nargumentation-based negotiation involving BDI agents. The paper describes the\nmediation algorithm. For comparison it illustrates the method with a case study\nused in an earlier work. It demonstrates how the computational mediator can\ndeal with realistic situations in which the negotiating agents would otherwise\nfail due to lack of knowledge and/or resources.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 07:14:37 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Trescak", "Tomas", ""], ["Sierra", "Carles", ""], ["Simoff", "Simeon", ""], ["de Mantaras", "Ramon Lopez", ""]]}, {"id": "1409.4814", "submitter": "Patrice Simard", "authors": "Patrice Simard, David Chickering, Aparna Lakshmiratan, Denis Charles,\n  Leon Bottou, Carlos Garcia Jurado Suarez, David Grangier, Saleema Amershi,\n  Johan Verwey, Jina Suh", "title": "ICE: Enabling Non-Experts to Build Models Interactively for Large-Scale\n  Lopsided Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quick interaction between a human teacher and a learning machine presents\nnumerous benefits and challenges when working with web-scale data. The human\nteacher guides the machine towards accomplishing the task of interest. The\nlearning machine leverages big data to find examples that maximize the training\nvalue of its interaction with the teacher. When the teacher is restricted to\nlabeling examples selected by the machine, this problem is an instance of\nactive learning. When the teacher can provide additional information to the\nmachine (e.g., suggestions on what examples or predictive features should be\nused) as the learning task progresses, then the problem becomes one of\ninteractive learning.\n  To accommodate the two-way communication channel needed for efficient\ninteractive learning, the teacher and the machine need an environment that\nsupports an interaction language. The machine can access, process, and\nsummarize more examples than the teacher can see in a lifetime. Based on the\nmachine's output, the teacher can revise the definition of the task or make it\nmore precise. Both the teacher and the machine continuously learn and benefit\nfrom the interaction.\n  We have built a platform to (1) produce valuable and deployable models and\n(2) support research on both the machine learning and user interface challenges\nof the interactive learning problem. The platform relies on a dedicated,\nlow-latency, distributed, in-memory architecture that allows us to construct\nweb-scale learning machines with quick interaction speed. The purpose of this\npaper is to describe this architecture and demonstrate how it supports our\nresearch efforts. Preliminary results are presented as illustrations of the\narchitecture but are not the primary focus of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 21:45:22 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Simard", "Patrice", ""], ["Chickering", "David", ""], ["Lakshmiratan", "Aparna", ""], ["Charles", "Denis", ""], ["Bottou", "Leon", ""], ["Suarez", "Carlos Garcia Jurado", ""], ["Grangier", "David", ""], ["Amershi", "Saleema", ""], ["Verwey", "Johan", ""], ["Suh", "Jina", ""]]}, {"id": "1409.4936", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall and Reda Younsi", "title": "Ensembles of Random Sphere Cover Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate alternative ensemble schemes for a new instance based\nlearning classifier, the Randomised Sphere Cover (RSC) classifier. RSC fuses\ninstances into spheres, then bases classification on distance to spheres rather\nthan distance to instances. The randomised nature of RSC makes it ideal for use\nin ensembles. We propose two ensemble methods tailored to the RSC classifier;\n$\\alpha \\beta$RSE, an ensemble based on instance resampling and $\\alpha$RSSE, a\nsubspace ensemble. We compare $\\alpha \\beta$RSE and $\\alpha$RSSE to tree based\nensembles on a set of UCI datasets and demonstrates that RSC ensembles perform\nsignificantly better than some of these ensembles, and not significantly worse\nthan the others. We demonstrate via a case study on six gene expression data\nsets that $\\alpha$RSSE can outperform other subspace ensemble methods on high\ndimensional data when used in conjunction with an attribute filter. Finally, we\nperform a set of Bias/Variance decomposition experiments to analyse the source\nof improvement in comparison to a base classifier.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 10:18:34 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Bagnall", "Anthony", ""], ["Younsi", "Reda", ""]]}, {"id": "1409.5166", "submitter": "Hu Qin", "authors": "Hu Qin, Zizhen Zhang, Yubin Xie, Andrew Lim", "title": "A Tabu Search Algorithm for the Multi-period Inspector Scheduling\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a multi-period inspector scheduling problem (MPISP),\nwhich is a new variant of the multi-trip vehicle routing problem with time\nwindows (VRPTW). In the MPISP, each inspector is scheduled to perform a route\nin a given multi-period planning horizon. At the end of each period, each\ninspector is not required to return to the depot but has to stay at one of the\nvertices for recuperation. If the remaining time of the current period is\ninsufficient for an inspector to travel from his/her current vertex $A$ to a\ncertain vertex B, he/she can choose either waiting at vertex A until the start\nof the next period or traveling to a vertex C that is closer to vertex B.\nTherefore, the shortest transit time between any vertex pair is affected by the\nlength of the period and the departure time. We first describe an approach of\ncomputing the shortest transit time between any pair of vertices with an\narbitrary departure time. To solve the MPISP, we then propose several local\nsearch operators adapted from classical operators for the VRPTW and integrate\nthem into a tabu search framework. In addition, we present a constrained\nknapsack model that is able to produce an upper bound for the problem. Finally,\nwe evaluate the effectiveness of our algorithm with extensive experiments based\non a set of test instances. Our computational results indicate that our\napproach generates high-quality solutions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 23:29:46 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Qin", "Hu", ""], ["Zhang", "Zizhen", ""], ["Xie", "Yubin", ""], ["Lim", "Andrew", ""]]}, {"id": "1409.5189", "submitter": "Michael Codish", "authors": "Michael Codish and Michael Frank and Avraham Itzhakov and Alice Miller", "title": "Solving Graph Coloring Problems with Abstraction and Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a general methodology, based on abstraction and\nsymmetry, that applies to solve hard graph edge-coloring problems and\ndemonstrates its use to provide further evidence that the Ramsey number\n$R(4,3,3)=30$. The number $R(4,3,3)$ is often presented as the unknown Ramsey\nnumber with the best chances of being found \"soon\". Yet, its precise value has\nremained unknown for more than 50 years. We illustrate our approach by showing\nthat: (1) there are precisely 78{,}892 $(3,3,3;13)$ Ramsey colorings; and (2)\nif there exists a $(4,3,3;30)$ Ramsey coloring then it is (13,8,8) regular.\nSpecifically each node has 13 edges in the first color, 8 in the second, and 8\nin the third. We conjecture that these two results will help provide a proof\nthat no $(4,3,3;30)$ Ramsey coloring exists implying that $R(4,3,3)=30$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 04:46:44 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2014 04:55:43 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2015 06:17:41 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Codish", "Michael", ""], ["Frank", "Michael", ""], ["Itzhakov", "Avraham", ""], ["Miller", "Alice", ""]]}, {"id": "1409.5223", "submitter": "Ben Ruijl", "authors": "Ben Ruijl, Aske Plaat, Jos Vermaseren, Jaap van den Herik", "title": "Why Local Search Excels in Expression Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplifying expressions is important to make numerical integration of large\nexpressions from High Energy Physics tractable. To this end, Horner's method\ncan be used. Finding suitable Horner schemes is assumed to be hard, due to the\nlack of local heuristics. Recently, MCTS was reported to be able to find near\noptimal schemes. However, several parameters had to be fine-tuned manually. In\nthis work, we investigate the state space properties of Horner schemes and find\nthat the domain is relatively flat and contains only a few local minima. As a\nresult, the Horner space is appropriate to be explored by Stochastic Local\nSearch (SLS), which has only two parameters: the number of iterations\n(computation time) and the neighborhood structure. We found a suitable\nneighborhood structure, leaving only the allowed computation time as a\nparameter. We performed a range of experiments. The results obtained by SLS are\nsimilar or better than those obtained by MCTS. Furthermore, we show that SLS\nobtains the good results at least 10 times faster. Using SLS, we can speed up\nnumerical integration of many real-world large expressions by at least a factor\nof 24. For High Energy Physics this means that numerical integrations that took\nweeks can now be done in hours.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 08:21:25 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Ruijl", "Ben", ""], ["Plaat", "Aske", ""], ["Vermaseren", "Jos", ""], ["Herik", "Jaap van den", ""]]}, {"id": "1409.5317", "submitter": "Scott MacLean", "authors": "Scott MacLean and George Labahn", "title": "A Bayesian model for recognizing handwritten mathematical expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing handwritten mathematics is a challenging classification problem,\nrequiring simultaneous identification of all the symbols comprising an input as\nwell as the complex two-dimensional relationships between symbols and\nsubexpressions. Because of the ambiguity present in handwritten input, it is\noften unrealistic to hope for consistently perfect recognition accuracy. We\npresent a system which captures all recognizable interpretations of the input\nand organizes them in a parse forest from which individual parse trees may be\nextracted and reported. If the top-ranked interpretation is incorrect, the user\nmay request alternates and select the recognition result they desire. The tree\nextraction step uses a novel probabilistic tree scoring strategy in which a\nBayesian network is constructed based on the structure of the input, and each\njoint variable assignment corresponds to a different parse tree. Parse trees\nare then reported in order of decreasing probability. Two accuracy evaluations\ndemonstrate that the resulting recognition system is more accurate than\nprevious versions (which used non-probabilistic methods) and other academic\nmath recognizers.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 14:45:24 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["MacLean", "Scott", ""], ["Labahn", "George", ""]]}, {"id": "1409.5326", "submitter": "Marcus Kaiser", "authors": "Richard J. Tomsett, Matt Ainsworth, Alexander Thiele, Mehdi Sanayei,\n  Xing Chen, Alwin Gieselmann, Miles A. Whittington, Mark O. Cunningham and\n  Marcus Kaiser", "title": "Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX):\n  Comparing multi-electrode recordings from simulated and biological mammalian\n  cortical tissue", "comments": "appears in Brain Struct Funct 2014", "journal-ref": null, "doi": "10.1007/s00429-014-0793-x", "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local field potentials (LFPs) sampled with extracellular electrodes are\nfrequently used as a measure of population neuronal activity. However, relating\nsuch measurements to underlying neuronal behaviour and connectivity is\nnon-trivial. To help study this link, we developed the Virtual Electrode\nRecording Tool for EXtracellular potentials (VERTEX). We first identified a\nreduced neuron model that retained the spatial and frequency filtering\ncharacteristics of extracellular potentials from neocortical neurons. We then\ndeveloped VERTEX as an easy-to-use Matlab tool for simulating LFPs from large\npopulations (>100 000 neurons). A VERTEX-based simulation successfully\nreproduced features of the LFPs from an in vitro multi-electrode array\nrecording of macaque neocortical tissue. Our model, with virtual electrodes\nplaced anywhere in 3D, allows direct comparisons with the in vitro recording\nsetup. We envisage that VERTEX will stimulate experimentalists, clinicians, and\ncomputational neuroscientists to use models to understand the mechanisms\nunderlying measured brain dynamics in health and disease.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 15:04:53 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Tomsett", "Richard J.", ""], ["Ainsworth", "Matt", ""], ["Thiele", "Alexander", ""], ["Sanayei", "Mehdi", ""], ["Chen", "Xing", ""], ["Gieselmann", "Alwin", ""], ["Whittington", "Miles A.", ""], ["Cunningham", "Mark O.", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1409.5340", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "Belief revision by examples", "comments": null, "journal-ref": null, "doi": "10.1145/2818645", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in belief revision is that the reliability of the\ninformation sources is either given, derived from temporal information, or the\nsame for all. This article does not describe a new semantics for integration\nbut the problem of obtaining the reliability of the sources given the result of\na previous merging. As an example, the relative reliability of two sensors can\nbe assessed given some certain observation, and allows for subsequent mergings\nof data coming from them.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 15:31:03 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "1409.5671", "submitter": "Ebru Aydin Gol", "authors": "Ebru Aydin Gol and Ezio Bartocci and Calin Belta", "title": "A Formal Methods Approach to Pattern Synthesis in Reaction Diffusion\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique to detect and generate patterns in a network of\nlocally interacting dynamical systems. Central to our approach is a novel\nspatial superposition logic, whose semantics is defined over the quad-tree of a\npartitioned image. We show that formulas in this logic can be efficiently\nlearned from positive and negative examples of several types of patterns. We\nalso demonstrate that pattern detection, which is implemented as a model\nchecking algorithm, performs very well for test data sets different from the\nlearning sets. We define a quantitative semantics for the logic and integrate\nthe model checking algorithm with particle swarm optimization in a\ncomputational framework for synthesis of parameters leading to desired patterns\nin reaction-diffusion systems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2014 05:21:06 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Gol", "Ebru Aydin", ""], ["Bartocci", "Ezio", ""], ["Belta", "Calin", ""]]}, {"id": "1409.5719", "submitter": "Sebastien Verel", "authors": "Manuel L\\'opez-Ib\\'a\\~nez (IRIDIA), Arnaud Liefooghe (INRIA Lille -\n  Nord Europe, LIFL), S\\'ebastien Verel (LISIC)", "title": "Local Optimal Sets and Bounded Archiving on Multi-objective\n  NK-Landscapes with Correlated Objectives", "comments": "appears in Parallel Problem Solving from Nature - PPSN XIII,\n  Ljubljana : Slovenia (2014)", "journal-ref": null, "doi": "10.1007/978-3-319-10762-2_61", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The properties of local optimal solutions in multi-objective combinatorial\noptimization problems are crucial for the effectiveness of local search\nalgorithms, particularly when these algorithms are based on Pareto dominance.\nSuch local search algorithms typically return a set of mutually nondominated\nPareto local optimal (PLO) solutions, that is, a PLO-set. This paper\ninvestigates two aspects of PLO-sets by means of experiments with Pareto local\nsearch (PLS). First, we examine the impact of several problem characteristics\non the properties of PLO-sets for multi-objective NK-landscapes with correlated\nobjectives. In particular, we report that either increasing the number of\nobjectives or decreasing the correlation between objectives leads to an\nexponential increment on the size of PLO-sets, whereas the variable correlation\nhas only a minor effect. Second, we study the running time and the quality\nreached when using bounding archiving methods to limit the size of the archive\nhandled by PLS, and thus, the maximum size of the PLO-set found. We argue that\nthere is a clear relationship between the running time of PLS and the\ndifficulty of a problem instance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 16:44:40 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["L\u00f3pez-Ib\u00e1\u00f1ez", "Manuel", "", "IRIDIA"], ["Liefooghe", "Arnaud", "", "INRIA Lille -\n  Nord Europe, LIFL"], ["Verel", "S\u00e9bastien", "", "LISIC"]]}, {"id": "1409.5752", "submitter": "Sebastien Verel", "authors": "Bilel Derbel (INRIA Lille - Nord Europe, LIFL), Dimo Brockhoff (INRIA\n  Lille - Nord Europe), Arnaud Liefooghe (INRIA Lille - Nord Europe, LIFL),\n  S\\'ebastien Verel (LISIC)", "title": "On the Impact of Multiobjective Scalarizing Functions", "comments": "appears in Parallel Problem Solving from Nature - PPSN XIII,\n  Ljubljana : Slovenia (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a renewed interest in decomposition-based approaches\nfor evolutionary multiobjective optimization. However, the impact of the choice\nof the underlying scalarizing function(s) is still far from being well\nunderstood. In this paper, we investigate the behavior of different scalarizing\nfunctions and their parameters. We thereby abstract firstly from any specific\nalgorithm and only consider the difficulty of the single scalarized problems in\nterms of the search ability of a (1+lambda)-EA on biobjective NK-landscapes.\nSecondly, combining the outcomes of independent single-objective runs allows\nfor more general statements on set-based performance measures. Finally, we\ninvestigate the correlation between the opening angle of the scalarizing\nfunction's underlying contour lines and the position of the final solution in\nthe objective space. Our analysis is of fundamental nature and sheds more light\non the key characteristics of multiobjective scalarizing functions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 18:41:36 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Derbel", "Bilel", "", "INRIA Lille - Nord Europe, LIFL"], ["Brockhoff", "Dimo", "", "INRIA\n  Lille - Nord Europe"], ["Liefooghe", "Arnaud", "", "INRIA Lille - Nord Europe, LIFL"], ["Verel", "S\u00e9bastien", "", "LISIC"]]}, {"id": "1409.5758", "submitter": "Pierre De Loor", "authors": "Elisabetta Bevacqua (CERV, Lab-STICC), Sankovic Igor (CERV,\n  Lab-STICC), Maatalaoui Ayoub (Lab-STICC), A. N\\'ed\\'elec (Lab-STICC), Pierre\n  De Loor (CERV, Lab-STICC)", "title": "Effects of Coupling in Human-Virtual Agent Body Interaction", "comments": "appears in Intelligent Virtual Agents, 14th International Conference,\n  IVA 2014, Boston : \\'Etats-Unis (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of the dynamic coupling between a user and a\nvirtual character during body interaction. Coupling is directly linked with\nother dimensions, such as co-presence, engagement, and believability, and was\nmeasured in an experiment that allowed users to describe their subjective\nfeelings about those dimensions of interest. The experiment was based on a\ntheatrical game involving the imitation of slow upper-body movements and the\nproposal of new movements by the user and virtual agent. The agent's behaviour\nvaried in autonomy: the agent could limit itself to imitating the user's\nmovements only, initiate new movements, or combine both behaviours. After the\ngame, each participant completed a questionnaire regarding their engagement in\nthe interaction, their subjective feeling about the co-presence of the agent,\netc. Based on four main dimensions of interest, we tested several hypotheses\nagainst our experimental results, which are discussed here.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 18:49:11 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Bevacqua", "Elisabetta", "", "CERV, Lab-STICC"], ["Igor", "Sankovic", "", "CERV,\n  Lab-STICC"], ["Ayoub", "Maatalaoui", "", "Lab-STICC"], ["N\u00e9d\u00e9lec", "A.", "", "Lab-STICC"], ["De Loor", "Pierre", "", "CERV, Lab-STICC"]]}, {"id": "1409.6041", "submitter": "Muhammad Ghifary", "authors": "Muhammad Ghifary and W. Bastiaan Kleijn and Mengjie Zhang", "title": "Domain Adaptive Neural Networks for Object Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple neural network model to deal with the domain adaptation\nproblem in object recognition. Our model incorporates the Maximum Mean\nDiscrepancy (MMD) measure as a regularization in the supervised learning to\nreduce the distribution mismatch between the source and target domains in the\nlatent space. From experiments, we demonstrate that the MMD regularization is\nan effective tool to provide good domain adaptation models on both SURF\nfeatures and raw image pixels of a particular image data set. We also show that\nour proposed model, preceded by the denoising auto-encoder pretraining,\nachieves better performance than recent benchmark models on the same data sets.\nThis work represents the first study of MMD measure in the context of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 20:42:00 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Ghifary", "Muhammad", ""], ["Kleijn", "W. Bastiaan", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1409.6052", "submitter": "Wolfgang Gatterbauer", "authors": "Wolfgang Gatterbauer and Dan Suciu", "title": "Oblivious Bounds on the Probability of Boolean Functions", "comments": "34 pages, 14 figures, supersedes: http://arxiv.org/abs/1105.2813", "journal-ref": "Pre-print for ACM Transactions on Database Systems, January 2014,\n  Vol 39, No 1, Article 5", "doi": "10.1145/2532641", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops upper and lower bounds for the probability of Boolean\nfunctions by treating multiple occurrences of variables as independent and\nassigning them new individual probabilities. We call this approach dissociation\nand give an exact characterization of optimal oblivious bounds, i.e. when the\nnew probabilities are chosen independent of the probabilities of all other\nvariables. Our motivation comes from the weighted model counting problem (or,\nequivalently, the problem of computing the probability of a Boolean function),\nwhich is #P-hard in general. By performing several dissociations, one can\ntransform a Boolean formula whose probability is difficult to compute, into one\nwhose probability is easy to compute, and which is guaranteed to provide an\nupper or lower bound on the probability of the original formula by choosing\nappropriate probabilities for the dissociated variables. Our new bounds shed\nlight on the connection between previous relaxation-based and model-based\napproximations and unify them as concrete choices in a larger design space. We\nalso show how our theory allows a standard relational database management\nsystem (DBMS) to both upper and lower bound hard probabilistic queries in\nguaranteed polynomial time.\n", "versions": [{"version": "v1", "created": "Sun, 21 Sep 2014 23:32:34 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Gatterbauer", "Wolfgang", ""], ["Suciu", "Dan", ""]]}, {"id": "1409.6287", "submitter": "Ji\\v{r}\\'i Vomlel", "authors": "Ji\\v{r}\\'i Vomlel and Petr Tichavsk\\'y", "title": "On tensor rank of conditional probability tables in Bayesian networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A difficult task in modeling with Bayesian networks is the elicitation of\nnumerical parameters of Bayesian networks. A large number of parameters is\nneeded to specify a conditional probability table (CPT) that has a larger\nparent set. In this paper we show that, most CPTs from real applications of\nBayesian networks can actually be very well approximated by tables that require\nsubstantially less parameters. This observation has practical consequence not\nonly for model elicitation but also for efficient probabilistic reasoning with\nthese networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 19:32:15 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Vomlel", "Ji\u0159\u00ed", ""], ["Tichavsk\u00fd", "Petr", ""]]}, {"id": "1409.6359", "submitter": "Bartlomiej Placzek", "authors": "Bartlomiej Placzek", "title": "Neighborhood Selection and Rules Identification for Cellular Automata: A\n  Rough Sets Approach", "comments": "11 pages, 3 figures", "journal-ref": "Lecture Notes in Computer Science, vol. 8385, pp. 721-730 (2014)", "doi": "10.1007/978-3-642-55195-6_68", "report-no": null, "categories": "cs.AI nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a method is proposed which uses data mining techniques based on\nrough sets theory to select neighborhood and determine update rule for cellular\nautomata (CA). According to the proposed approach, neighborhood is detected by\nreducts calculations and a rule-learning algorithm is applied to induce a set\nof decision rules that define the evolution of CA. Experiments were performed\nwith use of synthetic as well as real-world data sets. The results show that\nthe introduced method allows identification of both deterministic and\nprobabilistic CA-based models of real-world phenomena.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 22:11:50 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Placzek", "Bartlomiej", ""]]}, {"id": "1409.6831", "submitter": "Shang Shang", "authors": "Shang Shang, Tiance Wang, Paul Cuff, Sanjeev Kulkarni", "title": "The Application of Differential Privacy for Rank Aggregation: Privacy\n  and Accuracy", "comments": "Fusion 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential risk of privacy leakage prevents users from sharing their\nhonest opinions on social platforms. This paper addresses the problem of\nprivacy preservation if the query returns the histogram of rankings. The\nframework of differential privacy is applied to rank aggregation. The error\nprobability of the aggregated ranking is analyzed as a result of noise added in\norder to achieve differential privacy. Upper bounds on the error rates for any\npositional ranking rule are derived under the assumption that profiles are\nuniformly distributed. Simulation results are provided to validate the\nprobabilistic analysis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 05:19:32 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Shang", "Shang", ""], ["Wang", "Tiance", ""], ["Cuff", "Paul", ""], ["Kulkarni", "Sanjeev", ""]]}, {"id": "1409.7186", "submitter": "Andrea Schaerf", "authors": "Ruggero Bellio, Sara Ceschia, Luca Di Gaspero, Andrea Schaerf, Tommaso\n  Urli", "title": "Feature-based tuning of simulated annealing applied to the\n  curriculum-based course timetabling problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the university course timetabling problem, which is one of the\nmost studied problems in educational timetabling. In particular, we focus our\nattention on the formulation known as the curriculum-based course timetabling\nproblem, which has been tackled by many researchers and for which there are\nmany available benchmarks.\n  The contribution of this paper is twofold. First, we propose an effective and\nrobust single-stage simulated annealing method for solving the problem.\nSecondly, we design and apply an extensive and statistically-principled\nmethodology for the parameter tuning procedure. The outcome of this analysis is\na methodology for modeling the relationship between search method parameters\nand instance features that allows us to set the parameters for unseen instances\non the basis of a simple inspection of the instance itself. Using this\nmethodology, our algorithm, despite its apparent simplicity, has been able to\nachieve high quality results on a set of popular benchmarks.\n  A final contribution of the paper is a novel set of real-world instances,\nwhich could be used as a benchmark for future comparison.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 08:53:04 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 07:53:36 GMT"}], "update_date": "2015-07-09", "authors_parsed": [["Bellio", "Ruggero", ""], ["Ceschia", "Sara", ""], ["Di Gaspero", "Luca", ""], ["Schaerf", "Andrea", ""], ["Urli", "Tommaso", ""]]}, {"id": "1409.7281", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Michael Fink", "title": "Causal Graph Justifications of Logic Programs", "comments": null, "journal-ref": "Theory and Practice of Logic Programming (2014), volume 14, issue\n  4-5, pp. 603-618", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a multi-valued extension of logic programs under the\nstable models semantics where each true atom in a model is associated with a\nset of justifications. These justifications are expressed in terms of causal\ngraphs formed by rule labels and edges that represent their application\nordering. For positive programs, we show that the causal justifications\nobtained for a given atom have a direct correspon- dence to (relevant)\nsyntactic proofs of that atom using the program rules involved in the graphs.\nThe most interesting contribution is that this causal information is obtained\nin a purely semantic way, by algebraic op- erations (product, sum and\napplication) on a lattice of causal values whose ordering relation expresses\nwhen a justification is stronger than another. Finally, for programs with\nnegation, we define the concept of causal stable model by introducing an\nanalogous transformation to Gelfond and Lifschitz's program reduct. As a\nresult, default negation behaves as \"absence of proof\" and no justification is\nderived from negative liter\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 14:56:57 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Fink", "Michael", ""]]}, {"id": "1409.7403", "submitter": "Simon DeDeo", "authors": "David H. Wolpert, Joshua A. Grochow, Eric Libby, Simon DeDeo", "title": "Optimal high-level descriptions of dynamical systems", "comments": "33 pages. Updated discussion and references", "journal-ref": null, "doi": null, "report-no": "SFI Working Paper #15-06-017", "categories": "cs.IT cond-mat.stat-mech cs.AI cs.CE math.IT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To analyze high-dimensional systems, many fields in science and engineering\nrely on high-level descriptions, sometimes called \"macrostates,\"\n\"coarse-grainings,\" or \"effective theories\". Examples of such descriptions\ninclude the thermodynamic properties of a large collection of point particles\nundergoing reversible dynamics, the variables in a macroeconomic model\ndescribing the individuals that participate in an economy, and the summary\nstate of a cell composed of a large set of biochemical networks.\n  Often these high-level descriptions are constructed without considering the\nultimate reason for needing them in the first place. Here, we formalize and\nquantify one such purpose: the need to predict observables of interest\nconcerning the high-dimensional system with as high accuracy as possible, while\nminimizing the computational cost of doing so. The resulting State Space\nCompression (SSC) framework provides a guide for how to solve for the {optimal}\nhigh-level description of a given dynamical system, rather than constructing it\nbased on human intuition alone.\n  In this preliminary report, we introduce SSC, and illustrate it with several\ninformation-theoretic quantifications of \"accuracy\", all with different\nimplications for the optimal compression. We also discuss some other possible\napplications of SSC beyond the goal of accurate prediction. These include SSC\nas a measure of the complexity of a dynamical system, and as a way to quantify\ninformation flow between the scales of a system.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 20:01:47 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2015 19:31:07 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Wolpert", "David H.", ""], ["Grochow", "Joshua A.", ""], ["Libby", "Eric", ""], ["DeDeo", "Simon", ""]]}, {"id": "1409.7410", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Russell Greiner", "title": "Revisiting Algebra and Complexity of Inference in Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the form and complexity of inference in graphical models\nusing the abstraction offered by algebraic structures. In particular, we\nbroadly formalize inference problems in graphical models by viewing them as a\nsequence of operations based on commutative semigroups. We then study the\ncomputational complexity of inference by organizing various problems into an\n\"inference hierarchy\". When the underlying structure of an inference problem is\na commutative semiring -- i.e. a combination of two commutative semigroups with\nthe distributive law -- a message passing procedure called belief propagation\ncan leverage this distributive law to perform polynomial-time inference for\ncertain problems. After establishing the NP-hardness of inference in any\ncommutative semiring, we investigate the relation between algebraic properties\nin this setting and further show that polynomial-time inference using\ndistributive law does not (trivially) extend to inference problems that are\nexpressed using more than two commutative semigroups. We then extend the\nalgebraic treatment of message passing procedures to survey propagation,\nproviding a novel perspective using a combination of two commutative semirings.\nThis formulation generalizes the application of survey propagation to new\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 20:18:47 GMT"}, {"version": "v2", "created": "Mon, 29 Sep 2014 15:26:27 GMT"}, {"version": "v3", "created": "Thu, 6 Nov 2014 17:52:35 GMT"}, {"version": "v4", "created": "Sun, 3 May 2015 23:38:03 GMT"}], "update_date": "2015-05-05", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Greiner", "Russell", ""]]}, {"id": "1409.7580", "submitter": "Christian Blum", "authors": "Christian Blum and Verena V. Hafner", "title": "Gradient-based Taxis Algorithms for Network Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the physical location of a specific network node is a prototypical\ntask for navigation inside a wireless network. In this paper, we consider in\ndepth the implications of wireless communication as a measurement input of\ngradient-based taxis algorithms. We discuss how gradients can be measured and\ndetermine the errors of this estimation. We then introduce a gradient-based\ntaxis algorithm as an example of a family of gradient-based, convergent\nalgorithms and discuss its convergence in the context of network robotics. We\nalso conduct an exemplary experiment to show how to overcome some of the\nspecific problems related to network robotics. Finally, we show how to adapt\nthis framework to more complex objectives.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 14:11:03 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Blum", "Christian", ""], ["Hafner", "Verena V.", ""]]}, {"id": "1409.7777", "submitter": "Thomas Guyet", "authors": "Thomas Guyet (INRIA - IRISA), Yves Moinard (INRIA - IRISA), Ren\\'e\n  Quiniou (INRIA - IRISA)", "title": "Using Answer Set Programming for pattern mining", "comments": "Intelligence Artificielle Fondamentale (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serial pattern mining consists in extracting the frequent sequential patterns\nfrom a unique sequence of itemsets. This paper explores the ability of a\ndeclarative language, such as Answer Set Programming (ASP), to solve this issue\nefficiently. We propose several ASP implementations of the frequent sequential\npattern mining task: a non-incremental and an incremental resolution. The\nresults show that the incremental resolution is more efficient than the\nnon-incremental one, but both ASP programs are less efficient than dedicated\nalgorithms. Nonetheless, this approach can be seen as a first step toward a\ngeneric framework for sequential pattern mining with constraints.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 07:27:17 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Guyet", "Thomas", "", "INRIA - IRISA"], ["Moinard", "Yves", "", "INRIA - IRISA"], ["Quiniou", "Ren\u00e9", "", "INRIA - IRISA"]]}, {"id": "1409.7830", "submitter": "Szymon Matejczyk", "authors": "Kamil Adamczewski, Szymon Matejczyk and Tomasz P. Michalak", "title": "How good is the Shapley value-based approach to the influence\n  maximization problem?", "comments": "21st European Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapley value has been recently advocated as a method to choose the seed\nnodes for the process of information diffusion. Intuitively, since the Shapley\nvalue evaluates the average marginal contribution of a player to the\ncoalitional game, it can be used in the network context to evaluate the\nmarginal contribution of a node in the process of information diffusion given\nvarious groups of already 'infected' nodes. Although the above direction of\nresearch seems promising, the current liter- ature is missing a throughout\nassessment of its performance. The aim of this work is to provide such an\nassessment of the existing Shapley value-based approaches to information\ndiffusion.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 18:59:36 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Matejczyk", "Szymon", ""], ["Michalak", "Tomasz P.", ""]]}, {"id": "1409.7985", "submitter": "Yanchuan Sim", "authors": "Yanchuan Sim and Bryan Routledge and Noah A. Smith", "title": "The Utility of Text: The Case of Amicus Briefs and the Supreme Court", "comments": "Working draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.GT cs.LG", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We explore the idea that authoring a piece of text is an act of maximizing\none's expected utility. To make this idea concrete, we consider the societally\nimportant decisions of the Supreme Court of the United States. Extensive past\nwork in quantitative political science provides a framework for empirically\nmodeling the decisions of justices and how they relate to text. We incorporate\ninto such a model texts authored by amici curiae (\"friends of the court\"\nseparate from the litigants) who seek to weigh in on the decision, then\nexplicitly model their goals in a random utility model. We demonstrate the\nbenefits of this approach in improved vote prediction and the ability to\nperform counterfactual analysis.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 03:04:26 GMT"}, {"version": "v2", "created": "Tue, 30 Sep 2014 14:54:53 GMT"}, {"version": "v3", "created": "Tue, 7 Oct 2014 18:47:43 GMT"}, {"version": "v4", "created": "Fri, 10 Oct 2014 00:20:33 GMT"}, {"version": "v5", "created": "Tue, 25 Nov 2014 21:29:15 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Sim", "Yanchuan", ""], ["Routledge", "Bryan", ""], ["Smith", "Noah A.", ""]]}, {"id": "1409.8027", "submitter": "J. G. Wolff", "authors": "J. Gerard Wolff", "title": "Autonomous robots and the SP theory of intelligence", "comments": null, "journal-ref": "IEEE Access, 2, 1629-1651, 2014", "doi": "10.1109/ACCESS.2014.2382753", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about how the \"SP theory of intelligence\" and its realisation\nin the \"SP machine\" (both outlined in the article) may help to solve\ncomputer-related problems in the design of autonomous robots, meaning robots\nthat do not depend on external intelligence or power supplies, are mobile, and\nare designed to exhibit as much human-like intelligence as possible. The\narticle is about: how to increase the computational and energy efficiency of\ncomputers and reduce their bulk; how to achieve human-like versatility in\nintelligence; and likewise for human-like adaptability in intelligence. The SP\nsystem has potential for substantial gains in computational and energy\nefficiency and reductions in the bulkiness of computers: by reducing the size\nof data to be processed; by exploiting statistical information that the system\ngathers; and via an updated version of Donald Hebb's concept of a \"cell\nassembly\". Towards human-like versatility in intelligence, the SP system has\nstrengths in unsupervised learning, natural language processing, pattern\nrecognition, information retrieval, several kinds of reasoning, planning,\nproblem solving, and more, with seamless integration amongst structures and\nfunctions. The SP system's strengths in unsupervised learning and other aspects\nof intelligence may help to achieve human-like adaptability in intelligence\nvia: the learning of natural language; learning to see; building 3D models of\nobjects and of a robot's surroundings; learning regularities in the workings of\na robot and in the robot's environment; exploration and play; learning major\nskills; and secondary forms of learning. Also discussed are: how the SP system\nmay process parallel streams of information; generalisation of knowledge,\ncorrection of over-generalisations, and learning from dirty data; how to cut\nthe cost of learning; and reinforcements, motivations, goals, and\ndemonstration.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 08:41:01 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2015 08:47:02 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Wolff", "J. Gerard", ""]]}, {"id": "1409.8053", "submitter": "J. G. Wolff", "authors": "J. Gerard Wolff", "title": "Medical diagnosis as pattern recognition in a framework of information\n  compression by multiple alignment, unification and search", "comments": null, "journal-ref": "Decision Support Systems 42, 608-625, 2006", "doi": "10.1016/j.dss.2005.02.005", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach to medical diagnosis based on the SP\ntheory of computing and cognition. The main attractions of this approach are: a\nformat for representing diseases that is simple and intuitive; an ability to\ncope with errors and uncertainties in diagnostic information; the simplicity of\nstoring statistical information as frequencies of occurrence of diseases; a\nmethod for evaluating alternative diagnostic hypotheses that yields true\nprobabilities; and a framework that should facilitate unsupervised learning of\nmedical knowledge and the integration of medical diagnosis with other AI\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 10:11:31 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Wolff", "J. Gerard", ""]]}, {"id": "1409.8470", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Andreas Wichert", "title": "Interference Effects in Quantum Belief Networks", "comments": null, "journal-ref": "Applied Soft Computing, Volume 25, December 2014, Pages 64 - 85", "doi": "10.1016/j.asoc.2014.09.008", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models such as Bayesian Networks are one of the most\npowerful structures known by the Computer Science community for deriving\nprobabilistic inferences. However, modern cognitive psychology has revealed\nthat human decisions could not follow the rules of classical probability\ntheory, because humans cannot process large amounts of data in order to make\njudgements. Consequently, the inferences performed are based on limited data\ncoupled with several heuristics, leading to violations of the law of total\nprobability. This means that probabilistic graphical models based on classical\nprobability theory are too limited to fully simulate and explain various\naspects of human decision making.\n  Quantum probability theory was developed in order to accommodate the\nparadoxical findings that the classical theory could not explain. Recent\nfindings in cognitive psychology revealed that quantum probability can fully\ndescribe human decisions in an elegant framework. Their findings suggest that,\nbefore taking a decision, human thoughts are seen as superposed waves that can\ninterfere with each other, influencing the final decision.\n  In this work, we propose a new Bayesian Network based on the psychological\nfindings of cognitive scientists. We made experiments with two very well known\nBayesian Networks from the literature. The results obtained revealed that the\nquantum like Bayesian Network can affect drastically the probabilistic\ninferences, specially when the levels of uncertainty of the network are very\nhigh (no pieces of evidence observed). When the levels of uncertainty are very\nlow, then the proposed quantum like network collapses to its classical\ncounterpart.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 10:43:30 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Moreira", "Catarina", ""], ["Wichert", "Andreas", ""]]}, {"id": "1409.8484", "submitter": "Christian Napoli", "authors": "Christian Napoli, Giuseppe Pappalardo, Emiliano Tramontana", "title": "An agent-driven semantical identifier using radial basis neural networks\n  and reinforcement learning", "comments": "Published on: Proceedings of the XV Workshop \"Dagli Oggetti agli\n  Agenti\" (WOA 2014), Catania, Italy, Sepember. 25-26, 2014", "journal-ref": "Proceedings of the XV Workshop \"Dagli Oggetti agli Agenti\" (WOA\n  2014), on CEUR-WS, volume 1260, ISSN: 1613-073, Catania, Italy, Sepember.\n  25-26, 2014. http://ceur-ws.org/Vol-1260/", "doi": "10.13140/2.1.1446.7843", "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the huge availability of documents in digital form, and the deception\npossibility raise bound to the essence of digital documents and the way they\nare spread, the authorship attribution problem has constantly increased its\nrelevance. Nowadays, authorship attribution,for both information retrieval and\nanalysis, has gained great importance in the context of security, trust and\ncopyright preservation. This work proposes an innovative multi-agent driven\nmachine learning technique that has been developed for authorship attribution.\nBy means of a preprocessing for word-grouping and time-period related analysis\nof the common lexicon, we determine a bias reference level for the recurrence\nfrequency of the words within analysed texts, and then train a Radial Basis\nNeural Networks (RBPNN)-based classifier to identify the correct author. The\nmain advantage of the proposed approach lies in the generality of the semantic\nanalysis, which can be applied to different contexts and lexical domains,\nwithout requiring any modification. Moreover, the proposed system is able to\nincorporate an external input, meant to tune the classifier, and then\nself-adjust by means of continuous learning reinforcement.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 11:10:23 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Napoli", "Christian", ""], ["Pappalardo", "Giuseppe", ""], ["Tramontana", "Emiliano", ""]]}, {"id": "1409.8498", "submitter": "Jacob Crandall", "authors": "Jacob W. Crandall", "title": "Non-myopic learning in repeated stochastic games", "comments": null, "journal-ref": "Robust Learning for Repeated Stochastic Games via Meta-Gaming,\n  Proceedings of the 24th International Joint Conference on Artificial\n  Intelligence (IJCAI), pp. 3416-3422, 2015", "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In repeated stochastic games (RSGs), an agent must quickly adapt to the\nbehavior of previously unknown associates, who may themselves be learning. This\nmachine-learning problem is particularly challenging due, in part, to the\npresence of multiple (even infinite) equilibria and inherently large strategy\nspaces. In this paper, we introduce a method to reduce the strategy space of\ntwo-player general-sum RSGs to a handful of expert strategies. This process,\ncalled Mega, effectually reduces an RSG to a bandit problem. We show that the\nresulting strategy space preserves several important properties of the original\nRSG, thus enabling a learner to produce robust strategies within a reasonably\nsmall number of interactions. To better establish strengths and weaknesses of\nthis approach, we empirically evaluate the resulting learning system against\nother algorithms in three different RSGs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 11:46:29 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 15:30:04 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 13:54:51 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Crandall", "Jacob W.", ""]]}]