[{"id": "1712.00004", "submitter": "Martin Klissarov", "authors": "Martin Klissarov, Pierre-Luc Bacon, Jean Harb and Doina Precup", "title": "Learnings Options End-to-End for Continuous Action Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new results on learning temporally extended actions for\ncontinuoustasks, using the options framework (Suttonet al.[1999b], Precup\n[2000]). In orderto achieve this goal we work with the option-critic\narchitecture (Baconet al.[2017])using a deliberation cost and train it with\nproximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy\ngradient. Results on Mujoco domains arepromising, but lead to interesting\nquestions aboutwhena given option should beused, an issue directly connected to\nthe use of initiation sets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 00:45:09 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Klissarov", "Martin", ""], ["Bacon", "Pierre-Luc", ""], ["Harb", "Jean", ""], ["Precup", "Doina", ""]]}, {"id": "1712.00006", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Osmar R. Zaiane", "title": "Comparing Deep Reinforcement Learning and Evolutionary Methods in\n  Continuous Control", "comments": "NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning and the Evolutionary Strategy are two major approaches\nin addressing complicated control problems. Both are strong contenders and have\ntheir own devotee communities. Both groups have been very active in developing\nnew advances in their own domain and devising, in recent years, leading-edge\ntechniques to address complex continuous control tasks. Here, in the context of\nDeep Reinforcement Learning, we formulate a parallelized version of the\nProximal Policy Optimization method and a Deep Deterministic Policy Gradient\nmethod. Moreover, we conduct a thorough comparison between the state-of-the-art\ntechniques in both camps fro continuous control; evolutionary methods and Deep\nReinforcement Learning methods. The results show there is no consistent winner.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 03:40:06 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:35:22 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Zhang", "Shangtong", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1712.00166", "submitter": "Sungkyun Chang", "authors": "Sungkyun Chang, Juheon Lee, Sang Keun Choe and Kyogu Lee", "title": "Audio Cover Song Identification using Convolutional Neural Network", "comments": "NIPS 2017 Workshop on Machine Learning for Audio (ML4A), Long Beach,\n  CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new approach to cover song identification using a\nCNN (convolutional neural network). Most previous studies extract the feature\nvectors that characterize the cover song relation from a pair of songs and used\nit to compute the (dis)similarity between the two songs. Based on the\nobservation that there is a meaningful pattern between cover songs and that\nthis can be learned, we have reformulated the cover song identification problem\nin a machine learning framework. To do this, we first build the CNN using as an\ninput a cross-similarity matrix generated from a pair of songs. We then\nconstruct the data set composed of cover song pairs and non-cover song pairs,\nwhich are used as positive and negative training samples, respectively. The\ntrained CNN outputs the probability of being in the cover song relation given a\ncross-similarity matrix generated from any two pieces of music and identifies\nthe cover song by ranking on the probability. Experimental results show that\nthe proposed algorithm achieves performance better than or comparable to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 02:45:46 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:34:40 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chang", "Sungkyun", ""], ["Lee", "Juheon", ""], ["Choe", "Sang Keun", ""], ["Lee", "Kyogu", ""]]}, {"id": "1712.00180", "submitter": "Jason Bernard", "authors": "Jason Bernard, Ian McQuillan", "title": "New Techniques for Inferring L-Systems Using Genetic Algorithm", "comments": "18 pages. 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lindenmayer systems (L-systems) are a formal grammar system that iteratively\nrewrites all symbols of a string, in parallel. When visualized with a graphical\ninterpretation, the images have self-similar shapes that appear frequently in\nnature, and they have been particularly successful as a concise, reusable\ntechnique for simulating plants. The L-system inference problem is to find an\nL-system to simulate a given plant. This is currently done mainly by experts,\nbut this process is limited by the availability of experts, the complexity that\nmay be solved by humans, and time. This paper introduces the Plant Model\nInference Tool (PMIT) that infers deterministic context-free L-systems from an\ninitial sequence of strings generated by the system using a genetic algorithm.\nPMIT is able to infer more complex systems than existing approaches. Indeed,\nwhile existing approaches are limited to L-systems with a total sum of 20\ncombined symbols in the productions, PMIT can infer almost all L-systems tested\nwhere the total sum is 140 symbols. This was validated using a test bed of 28\npreviously developed L-system models, in addition to models created\nartificially by bootstrapping larger models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 03:55:59 GMT"}, {"version": "v2", "created": "Mon, 4 Dec 2017 15:00:14 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Bernard", "Jason", ""], ["McQuillan", "Ian", ""]]}, {"id": "1712.00193", "submitter": "Hee Jung Ryu", "authors": "Hee Jung Ryu, Hartwig Adam, Margaret Mitchell", "title": "InclusiveFaceNet: Improving Face Attribute Detection with Race and\n  Gender Diversity", "comments": "Presented as a talk at the 2018 Workshop on Fairness, Accountability,\n  and Transparency in Machine Learning (FAT/ML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate an approach to face attribute detection that retains or\nimproves attribute detection accuracy across gender and race subgroups by\nlearning demographic information prior to learning the attribute detection\ntask. The system, which we call InclusiveFaceNet, detects face attributes by\ntransferring race and gender representations learned from a held-out dataset of\npublic race and gender identities. Leveraging learned demographic\nrepresentations while withholding demographic inference from the downstream\nface attribute detection task preserves potential users' demographic privacy\nwhile resulting in some of the best reported numbers to date on attribute\ndetection in the Faces of the World and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 05:00:16 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 20:52:18 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 12:29:08 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ryu", "Hee Jung", ""], ["Adam", "Hartwig", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1712.00222", "submitter": "Chong Di", "authors": "Chong Di", "title": "A double competitive strategy based learning automata algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Automata (LA) are considered as one of the most powerful tools in\nthe field of reinforcement learning. The family of estimator algorithms is\nproposed to improve the convergence rate of LA and has made great achievements.\nHowever, the estimators perform poorly on estimating the reward probabilities\nof actions in the initial stage of the learning process of LA. In this\nsituation, a lot of rewards would be added to the probabilities of non-optimal\nactions. Thus, a large number of extra iterations are needed to compensate for\nthese wrong rewards. In order to improve the speed of convergence, we propose a\nnew P-model absorbing learning automaton by utilizing a double competitive\nstrategy which is designed for updating the action probability vector. In this\nway, the wrong rewards can be corrected instantly. Hence, the proposed Double\nCompetitive Algorithm overcomes the drawbacks of existing estimator algorithms.\nA refined analysis is presented to show the $\\epsilon-optimality$ of the\nproposed scheme. The extensive experimental results in benchmark environments\ndemonstrate that our proposed learning automata perform more efficiently than\nthe most classic LA $SE_{RI}$ and the current fastest LA $DGCPA^{*}$.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 07:54:53 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Di", "Chong", ""]]}, {"id": "1712.00377", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Dhruv Batra, Devi Parikh, Aniruddha Kembhavi", "title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering", "comments": "15 pages, 10 figures. To appear in IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:48:50 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 15:32:06 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "1712.00428", "submitter": "Sekou Remy", "authors": "Oliver Bent, Sekou L. Remy, Stephen Roberts, Aisha Walcott-Bryant", "title": "Novel Exploration Techniques (NETs) for Malaria Policy Interventions", "comments": "Under-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of decision-making under uncertainty is daunting, especially for\nproblems which have significant complexity. Healthcare policy makers across the\nglobe are facing problems under challenging constraints, with limited tools to\nhelp them make data driven decisions. In this work we frame the process of\nfinding an optimal malaria policy as a stochastic multi-armed bandit problem,\nand implement three agent based strategies to explore the policy space. We\napply a Gaussian Process regression to the findings of each agent, both for\ncomparison and to account for stochastic results from simulating the spread of\nmalaria in a fixed population. The generated policy spaces are compared with\npublished results to give a direct reference with human expert decisions for\nthe same simulated population. Our novel approach provides a powerful resource\nfor policy makers, and a platform which can be readily extended to capture\nfuture more nuanced policy spaces.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 17:59:49 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Bent", "Oliver", ""], ["Remy", "Sekou L.", ""], ["Roberts", "Stephen", ""], ["Walcott-Bryant", "Aisha", ""]]}, {"id": "1712.00489", "submitter": "Abhinav Gupta", "authors": "Abhinav Gupta, Yajie Miao, Leonardo Neves, Florian Metze", "title": "Visual Features for Context-Aware Speech Recognition", "comments": "5 pages and 3 figures", "journal-ref": "IEEE Xplore (ICASSP) (2017) 5020-5024", "doi": "10.1109/ICASSP.2017.7953112", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic transcriptions of consumer-generated multi-media content such as\n\"Youtube\" videos still exhibit high word error rates. Such data typically\noccupies a very broad domain, has been recorded in challenging conditions, with\ncheap hardware and a focus on the visual modality, and may have been\npost-processed or edited. In this paper, we extend our earlier work on adapting\nthe acoustic model of a DNN-based speech recognition system to an RNN language\nmodel and show how both can be adapted to the objects and scenes that can be\nautomatically detected in the video. We are working on a corpus of \"how-to\"\nvideos from the web, and the idea is that an object that can be seen (\"car\"),\nor a scene that is being detected (\"kitchen\") can be used to condition both\nmodels on the \"context\" of the recording, thereby reducing perplexity and\nimproving transcription. We achieve good improvements in both cases and compare\nand analyze the respective reductions in word error rate. We expect that our\nresults can be used for any type of speech processing in which \"context\"\ninformation is available, for example in robotics, man-machine interaction, or\nwhen indexing large audio-visual archives, and should ultimately help to bring\ntogether the \"video-to-text\" and \"speech-to-text\" communities.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 20:56:31 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Gupta", "Abhinav", ""], ["Miao", "Yajie", ""], ["Neves", "Leonardo", ""], ["Metze", "Florian", ""]]}, {"id": "1712.00547", "submitter": "Tim Miller", "authors": "Tim Miller, Piers Howe, Liz Sonenberg", "title": "Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to\n  Stop Worrying and Love the Social and Behavioural Sciences", "comments": "IJCAI 2017 Workshop on Explainable Artificial Intelligence (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his seminal book `The Inmates are Running the Asylum: Why High-Tech\nProducts Drive Us Crazy And How To Restore The Sanity' [2004, Sams\nIndianapolis, IN, USA], Alan Cooper argues that a major reason why software is\noften poorly designed (from a user perspective) is that programmers are in\ncharge of design decisions, rather than interaction designers. As a result,\nprogrammers design software for themselves, rather than for their target\naudience, a phenomenon he refers to as the `inmates running the asylum'. This\npaper argues that explainable AI risks a similar fate. While the re-emergence\nof explainable AI is positive, this paper argues most of us as AI researchers\nare building explanatory agents for ourselves, rather than for the intended\nusers. But explainable AI is more likely to succeed if researchers and\npractitioners understand, adopt, implement, and improve models from the vast\nand valuable bodies of research in philosophy, psychology, and cognitive\nscience, and if evaluation of these models is focused more on people than on\ntechnology. From a light scan of literature, we demonstrate that there is\nconsiderable scope to infuse more results from the social and behavioural\nsciences into explainable AI, and present some key results from these fields\nthat are relevant to explainable AI.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 04:21:14 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 04:23:25 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Miller", "Tim", ""], ["Howe", "Piers", ""], ["Sonenberg", "Liz", ""]]}, {"id": "1712.00576", "submitter": "Yan Zhu", "authors": "Yan Zhu, Shaoting Zhang, Dimitris Metaxas", "title": "Interactive Reinforcement Learning for Object Grounding via Self-Talking", "comments": "NIPS 2017 - Visually-Grounded Interaction and Language (ViGIL)\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to identify a referred visual object in a complex scene via a\nfew rounds of natural language communications. Success communication requires\nboth parties to engage and learn to adapt for each other. In this paper, we\nintroduce an interactive training method to improve the natural language\nconversation system for a visual grounding task. During interactive training,\nboth agents are reinforced by the guidance from a common reward function. The\nparametrized reward function also cooperatively updates itself via\ninteractions, and contribute to accomplishing the task. We evaluate the method\non GuessWhat?! visual grounding task, and significantly improve the task\nsuccess rate. However, we observe language drifting problem during training and\npropose to use reward engineering to improve the interpretability for the\ngenerated conversations. Our result also indicates evaluating goal-ended visual\nconversation tasks require semantic relevant metrics beyond task success rate.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 09:15:10 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Zhu", "Yan", ""], ["Zhang", "Shaoting", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1712.00600", "submitter": "Weinan Zhang", "authors": "Lianmin Zheng, Jiacheng Yang, Han Cai, Weinan Zhang, Jun Wang, Yong Yu", "title": "MAgent: A Many-Agent Reinforcement Learning Platform for Artificial\n  Collective Intelligence", "comments": "NIPS 2017 & AAAI 2018 Demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce MAgent, a platform to support research and development of\nmany-agent reinforcement learning. Unlike previous research platforms on single\nor multi-agent reinforcement learning, MAgent focuses on supporting the tasks\nand the applications that require hundreds to millions of agents. Within the\ninteractions among a population of agents, it enables not only the study of\nlearning algorithms for agents' optimal polices, but more importantly, the\nobservation and understanding of individual agent's behaviors and social\nphenomena emerging from the AI society, including communication languages,\nleaderships, altruism. MAgent is highly scalable and can host up to one million\nagents on a single GPU server. MAgent also provides flexible configurations for\nAI researchers to design their customized environments and agents. In this\ndemo, we present three environments designed on MAgent and show emerged\ncollective intelligence by learning from scratch.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 12:41:11 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Zheng", "Lianmin", ""], ["Yang", "Jiacheng", ""], ["Cai", "Han", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""]]}, {"id": "1712.00634", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "PFAx: Predictable Feature Analysis to Perform Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictable Feature Analysis (PFA) (Richthofer, Wiskott, ICMLA 2015) is an\nalgorithm that performs dimensionality reduction on high dimensional input\nsignal. It extracts those subsignals that are most predictable according to a\ncertain prediction model. We refer to these extracted signals as predictable\nfeatures.\n  In this work we extend the notion of PFA to take supplementary information\ninto account for improving its predictions. Such information can be a\nmultidimensional signal like the main input to PFA, but is regarded external.\nThat means it won't participate in the feature extraction - no features get\nextracted or composed of it. Features will be exclusively extracted from the\nmain input such that they are most predictable based on themselves and the\nsupplementary information. We refer to this enhanced PFA as PFAx (PFA\nextended).\n  Even more important than improving prediction quality is to observe the\neffect of supplementary information on feature selection. PFAx transparently\nprovides insight how the supplementary information adds to prediction quality\nand whether it is valuable at all. Finally we show how to invert that relation\nand can generate the supplementary information such that it would yield a\ncertain desired outcome of the main signal.\n  We apply this to a setting inspired by reinforcement learning and let the\nalgorithm learn how to control an agent in an environment. With this method it\nis feasible to locally optimize the agent's state, i.e. reach a certain goal\nthat is near enough. We are preparing a follow-up paper that extends this\nmethod such that also global optimization is feasible.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 16:44:10 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1712.00646", "submitter": "Eyke H\\\"ullermeier", "authors": "Eyke H\\\"ullermeier", "title": "From knowledge-based to data-driven modeling of fuzzy rule-based\n  systems: A critical reflection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper briefly elaborates on a development in (applied) fuzzy logic that\nhas taken place in the last couple of decades, namely, the complementation or\neven replacement of the traditional knowledge-based approach to fuzzy\nrule-based systems design by a data-driven one. It is argued that the classical\nrule-based modeling paradigm is actually more amenable to the knowledge-based\napproach, for which it has originally been conceived, while being less apt to\ndata-driven model design. An important reason that prevents fuzzy (rule-based)\nsystems from being leveraged in large-scale applications is the flat structure\nof rule bases, along with the local nature of fuzzy rules and their limited\nability to express complex dependencies between variables. This motivates\nalternative approaches to fuzzy systems modeling, in which functional\ndependencies can be represented more flexibly and more compactly in terms of\nhierarchical structures.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 17:42:49 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1712.00709", "submitter": "Alper Kose", "authors": "Alper Kose, Berke Aral Sonmez and Metin Balaban", "title": "Simulated Annealing Algorithm for Graph Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this Random Walks project is to code and experiment the Markov\nChain Monte Carlo (MCMC) method for the problem of graph coloring. In this\nreport, we present the plots of cost function \\(\\mathbf{H}\\) by varying the\nparameters like \\(\\mathbf{q}\\) (Number of colors that can be used in coloring)\nand \\(\\mathbf{c}\\) (Average node degree). The results are obtained by using\nsimulated annealing scheme, where the temperature (inverse of\n\\(\\mathbf{\\beta}\\)) parameter in the MCMC is lowered progressively.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 05:34:54 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kose", "Alper", ""], ["Sonmez", "Berke Aral", ""], ["Balaban", "Metin", ""]]}, {"id": "1712.00712", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Ricardo Emmanuel de Souza, Pl\\'inio B.\n  dos Santos Filho", "title": "Evaluation of Alzheimer's Disease by Analysis of MR Images using\n  Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the\n  ADC Maps", "comments": "29th Annual Conference of the IEEE Engineering in Medicine and\n  Biology Society - EMBC 2007", "journal-ref": null, "doi": "10.1109/IEMBS.2007.4352740", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is the most common cause of dementia, yet hard to\ndiagnose precisely without invasive techniques, particularly at the onset of\nthe disease. This work approaches image analysis and classification of\nsynthetic multispectral images composed by diffusion-weighted magnetic\nresonance (MR) cerebral images for the evaluation of cerebrospinal fluid area\nand measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging\nsystem was used to acquire all images presented. The classification methods are\nbased on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We\nassume the classes of interest can be separated by hyperquadrics. Therefore, a\n2-degree polynomial network is used to classify the original image, generating\nthe ground truth image. The classification results are used to improve the\nusual analysis of the apparent diffusion coefficient map.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 05:54:40 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Filho", "Pl\u00ednio B. dos Santos", ""]]}, {"id": "1712.00725", "submitter": "Abhinav Gupta", "authors": "Laura Graesser, Abhinav Gupta, Lakshay Sharma, Evelina Bakhturina", "title": "Sentiment Classification using Images and Label Embeddings", "comments": "13 pages, 3 figures, 9 tables. Technical report for Statistical\n  Natural Language Processing Project (NYU CS - Fall 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project we analysed how much semantic information images carry, and\nhow much value image data can add to sentiment analysis of the text associated\nwith the images. To better understand the contribution from images, we compared\nmodels which only made use of image data, models which only made use of text\ndata, and models which combined both data types. We also analysed if this\napproach could help sentiment classifiers generalize to unknown sentiments.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 07:20:15 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Graesser", "Laura", ""], ["Gupta", "Abhinav", ""], ["Sharma", "Lakshay", ""], ["Bakhturina", "Evelina", ""]]}, {"id": "1712.00779", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Yuandong Tian, Barnabas Poczos, Aarti Singh", "title": "Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of\n  Spurious Local Minima", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a one-hidden-layer neural network with\nnon-overlapping convolutional layer and ReLU activation, i.e., $f(\\mathbf{Z},\n\\mathbf{w}, \\mathbf{a}) = \\sum_j a_j\\sigma(\\mathbf{w}^T\\mathbf{Z}_j)$, in which\nboth the convolutional weights $\\mathbf{w}$ and the output weights $\\mathbf{a}$\nare parameters to be learned. When the labels are the outputs from a teacher\nnetwork of the same architecture with fixed weights $(\\mathbf{w}^*,\n\\mathbf{a}^*)$, we prove that with Gaussian input $\\mathbf{Z}$, there is a\nspurious local minimizer. Surprisingly, in the presence of the spurious local\nminimizer, gradient descent with weight normalization from randomly initialized\nweights can still be proven to recover the true parameters with constant\nprobability, which can be boosted to probability $1$ with multiple restarts. We\nalso show that with constant probability, the same procedure could also\nconverge to the spurious local minimum, showing that the local minimum plays a\nnon-trivial role in the dynamics of gradient descent. Furthermore, a\nquantitative analysis shows that the gradient descent dynamics has two phases:\nit starts off slow, but converges much faster after several iterations.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 15:00:35 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 00:41:03 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Tian", "Yuandong", ""], ["Poczos", "Barnabas", ""], ["Singh", "Aarti", ""]]}, {"id": "1712.00840", "submitter": "Mehul Bhatt", "authors": "Jakob Suchan and Mehul Bhatt and Przemys{\\l}aw Wa{\\l}\\k{e}ga and Carl\n  Schultz", "title": "Visual Explanation by High-Level Abduction: On Answer-Set Programming\n  Driven Reasoning about Moving Objects", "comments": "Preprint of final publication published as part of AAAI 2018: J.\n  Suchan., M. Bhatt, Wa{\\l}\\k{e}ga, P., Schultz, C. (2018). Visual Explanation\n  by High-Level Abduction: On Answer-Set Programming Driven Reasoning about\n  Moving Objects. In AAAI 2018: Proceedings of the Thirty-Second AAAI\n  Conference on Artificial Intelligence, February 2-7, 2018, New Orleans, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid architecture for systematically computing robust visual\nexplanation(s) encompassing hypothesis formation, belief revision, and default\nreasoning with video data. The architecture consists of two tightly integrated\nsynergistic components: (1) (functional) answer set programming based abductive\nreasoning with space-time tracklets as native entities; and (2) a visual\nprocessing pipeline for detection based object tracking and motion analysis.\n  We present the formal framework, its general implementation as a\n(declarative) method in answer set programming, and an example application and\nevaluation based on two diverse video datasets: the MOTChallenge benchmark\ndeveloped by the vision community, and a recently developed Movie Dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 21:17:07 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Suchan", "Jakob", ""], ["Bhatt", "Mehul", ""], ["Wa\u0142\u0119ga", "Przemys\u0142aw", ""], ["Schultz", "Carl", ""]]}, {"id": "1712.00846", "submitter": "Thamme Gowda", "authors": "Kyle Hundman, Thamme Gowda, Mayank Kejriwal, and Benedikt Boecking", "title": "Always Lurking: Understanding and Mitigating Bias in Online Human\n  Trafficking Detection", "comments": "Submitted to 2018 AAAI 1st conference on AI, Ethics, and Society.\n  Awaiting review", "journal-ref": "AAAI/ACM First conference on Artificial Intelligence, Ethics, and\n  Society, New Orleans, USA, February 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-based human trafficking activity has increased in recent years but it\nremains sparsely dispersed among escort advertisements and difficult to\nidentify due to its often-latent nature. The use of intelligent systems to\ndetect trafficking can thus have a direct impact on investigative resource\nallocation and decision-making, and, more broadly, help curb a widespread\nsocial problem. Trafficking detection involves assigning a normalized score to\na set of escort advertisements crawled from the Web -- a higher score indicates\na greater risk of trafficking-related (involuntary) activities. In this paper,\nwe define and study the problem of trafficking detection and present a\ntrafficking detection pipeline architecture developed over three years of\nresearch within the DARPA Memex program. Drawing on multi-institutional data,\nsystems, and experiences collected during this time, we also conduct post hoc\nbias analyses and present a bias mitigation plan. Our findings show that, while\nautomatic trafficking detection is an important application of AI for social\ngood, it also provides cautionary lessons for deploying predictive machine\nlearning algorithms without appropriate de-biasing. This ultimately led to\nintegration of an interpretable solution into a search system that contains\nover 100 million advertisements and is used by over 200 law enforcement\nagencies to investigate leads.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 22:34:43 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Hundman", "Kyle", ""], ["Gowda", "Thamme", ""], ["Kejriwal", "Mayank", ""], ["Boecking", "Benedikt", ""]]}, {"id": "1712.00898", "submitter": "EPTCS", "authors": "Catherine Dubois, Bruno Woltzenlogel Paleo", "title": "Proceedings of the Fifth Workshop on Proof eXchange for Theorem Proving", "comments": null, "journal-ref": "EPTCS 262, 2017", "doi": "10.4204/EPTCS.262", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of EPTCS contains the proceedings of the Fifth Workshop on Proof\nExchange for Theorem Proving (PxTP 2017), held on September 23-24, 2017 as part\nof the Tableaux, FroCoS and ITP conferences in Brasilia, Brazil. The PxTP\nworkshop series brings together researchers working on various aspects of\ncommunication, integration, and cooperation between reasoning systems and\nformalisms, with a special focus on proofs. The progress in computer-aided\nreasoning, both automated and interactive, during the past decades, made it\npossible to build deduction tools that are increasingly more applicable to a\nwider range of problems and are able to tackle larger problems progressively\nfaster. In recent years, cooperation between such tools in larger systems has\ndemonstrated the potential to reduce the amount of manual intervention.\nCooperation between reasoning systems relies on availability of theoretical\nformalisms and practical tools to exchange problems, proofs, and models. The\nPxTP workshop series strives to encourage such cooperation by inviting\ncontributions on all aspects of cooperation between reasoning tools, whether\nautomatic or interactive.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 04:24:11 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Dubois", "Catherine", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1712.00912", "submitter": "Jong Chul Ye", "authors": "Jaejun Yoo, Sohail Sabir, Duchang Heo, Kee Hyun Kim, Abdul Wahab,\n  Yoonseok Choi, Seul-I Lee, Eun Young Chae, Hak Hee Kim, Young Min Bae,\n  Young-wook Choi, Seungryong Cho, and Jong Chul Ye", "title": "Deep Learning Diffuse Optical Tomography", "comments": "Accepted for IEEE Trans. on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2019.2936522", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffuse optical tomography (DOT) has been investigated as an alternative\nimaging modality for breast cancer detection thanks to its excellent contrast\nto hemoglobin oxidization level. However, due to the complicated non-linear\nphoton scattering physics and ill-posedness, the conventional reconstruction\nalgorithms are sensitive to imaging parameters such as boundary conditions. To\naddress this, here we propose a novel deep learning approach that learns\nnon-linear photon scattering physics and obtains an accurate three dimensional\n(3D) distribution of optical anomalies. In contrast to the traditional\nblack-box deep learning approaches, our deep network is designed to invert the\nLippman-Schwinger integral equation using the recent mathematical theory of\ndeep convolutional framelets. As an example of clinical relevance, we applied\nthe method to our prototype DOT system. We show that our deep neural network,\ntrained with only simulation data, can accurately recover the location of\nanomalies within biomimetic phantoms and live animals without the use of an\nexogenous contrast agent.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 05:47:10 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 03:46:33 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yoo", "Jaejun", ""], ["Sabir", "Sohail", ""], ["Heo", "Duchang", ""], ["Kim", "Kee Hyun", ""], ["Wahab", "Abdul", ""], ["Choi", "Yoonseok", ""], ["Lee", "Seul-I", ""], ["Chae", "Eun Young", ""], ["Kim", "Hak Hee", ""], ["Bae", "Young Min", ""], ["Choi", "Young-wook", ""], ["Cho", "Seungryong", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.00929", "submitter": "Tomoaki Nakamura", "authors": "Tomoaki Nakamura, Takayuki Nagai, Tadahiro Taniguchi", "title": "SERKET: An Architecture for Connecting Stochastic Models to Realize a\n  Large-Scale Cognitive Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To realize human-like robot intelligence, a large-scale cognitive\narchitecture is required for robots to understand the environment through a\nvariety of sensors with which they are equipped. In this paper, we propose a\nnovel framework named Serket that enables the construction of a large-scale\ngenerative model and its inference easily by connecting sub-modules to allow\nthe robots to acquire various capabilities through interaction with their\nenvironments and others. We consider that large-scale cognitive models can be\nconstructed by connecting smaller fundamental models hierarchically while\nmaintaining their programmatic independence. Moreover, connected modules are\ndependent on each other, and parameters are required to be optimized as a\nwhole. Conventionally, the equations for parameter estimation have to be\nderived and implemented depending on the models. However, it becomes harder to\nderive and implement those of a larger scale model. To solve these problems, in\nthis paper, we propose a method for parameter estimation by communicating the\nminimal parameters between various modules while maintaining their programmatic\nindependence. Therefore, Serket makes it easy to construct large-scale models\nand estimate their parameters via the connection of modules. Experimental\nresults demonstrated that the model can be constructed by connecting modules,\nthe parameters can be optimized as a whole, and they are comparable with the\noriginal models that we have proposed.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 06:58:39 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 03:17:44 GMT"}, {"version": "v3", "created": "Wed, 6 Dec 2017 01:26:54 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Nakamura", "Tomoaki", ""], ["Nagai", "Takayuki", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1712.00948", "submitter": "Andrew Levy", "authors": "Andrew Levy, George Konidaris, Robert Platt, Kate Saenko", "title": "Learning Multi-Level Hierarchies with Hindsight", "comments": "ICLR 2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical agents have the potential to solve sequential decision making\ntasks with greater sample efficiency than their non-hierarchical counterparts\nbecause hierarchical agents can break down tasks into sets of subtasks that\nonly require short sequences of decisions. In order to realize this potential\nof faster learning, hierarchical agents need to be able to learn their multiple\nlevels of policies in parallel so these simpler subproblems can be solved\nsimultaneously. Yet, learning multiple levels of policies in parallel is hard\nbecause it is inherently unstable: changes in a policy at one level of the\nhierarchy may cause changes in the transition and reward functions at higher\nlevels in the hierarchy, making it difficult to jointly learn multiple levels\nof policies. In this paper, we introduce a new Hierarchical Reinforcement\nLearning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome\nthe instability issues that arise when agents try to jointly learn multiple\nlevels of policies. The main idea behind HAC is to train each level of the\nhierarchy independently of the lower levels by training each level as if the\nlower level policies are already optimal. We demonstrate experimentally in both\ngrid world and simulated robotics domains that our approach can significantly\naccelerate learning relative to other non-hierarchical and hierarchical\nmethods. Indeed, our framework is the first to successfully learn 3-level\nhierarchies in parallel in tasks with continuous state and action spaces.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 08:18:08 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 16:01:40 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 17:45:42 GMT"}, {"version": "v4", "created": "Fri, 1 Mar 2019 18:21:33 GMT"}, {"version": "v5", "created": "Tue, 3 Sep 2019 21:05:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Levy", "Andrew", ""], ["Konidaris", "George", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1712.00988", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Pushpak Bhattacharya, and Girish K. Palshikar", "title": "End-to-End Relation Extraction using Markov Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of end-to-end relation extraction consists of two sub-tasks: i)\nidentifying entity mentions along with their types and ii) recognizing semantic\nrelations among the entity mention pairs. %Identifying entity mentions along\nwith their types and recognizing semantic relations among the entity mentions,\nare two very important problems in Information Extraction. It has been shown\nthat for better performance, it is necessary to address these two sub-tasks\njointly. We propose an approach for simultaneous extraction of entity mentions\nand relations in a sentence, by using inference in Markov Logic Networks (MLN).\nWe learn three different classifiers : i) local entity classifier, ii) local\nrelation classifier and iii) \"pipeline\" relation classifier which uses\npredictions of the local entity classifier. Predictions of these classifiers\nmay be inconsistent with each other. We represent these predictions along with\nsome domain knowledge using weighted first-order logic rules in an MLN and\nperform joint inference over the MLN to obtain a global output with minimum\ninconsistencies. Experiments on the ACE (Automatic Content Extraction) 2004\ndataset demonstrate that our approach of joint extraction using MLNs\noutperforms the baselines of individual classifiers. Our end-to-end relation\nextraction performance is better than 2 out of 3 previous results reported on\nthe ACE 2004 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 10:26:59 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Pawar", "Sachin", ""], ["Bhattacharya", "Pushpak", ""], ["Palshikar", "Girish K.", ""]]}, {"id": "1712.00991", "submitter": "Sachin Pawar", "authors": "Girish Keshav Palshikar, Sachin Pawar, Saheb Chourasia, Nitin\n  Ramrakhiyani", "title": "Mining Supervisor Evaluation and Peer Feedback in Performance Appraisals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance appraisal (PA) is an important HR process to periodically measure\nand evaluate every employee's performance vis-a-vis the goals established by\nthe organization. A PA process involves purposeful multi-step multi-modal\ncommunication between employees, their supervisors and their peers, such as\nself-appraisal, supervisor assessment and peer feedback. Analysis of the\nstructured data and text produced in PA is crucial for measuring the quality of\nappraisals and tracking actual improvements. In this paper, we apply text\nmining techniques to produce insights from PA text. First, we perform sentence\nclassification to identify strengths, weaknesses and suggestions of\nimprovements found in the supervisor assessments and then use clustering to\ndiscover broad categories among them. Next we use multi-class multi-label\nclassification techniques to match supervisor assessments to predefined broad\nperspectives on performance. Finally, we propose a short-text summarization\ntechnique to produce a summary of peer feedback comments for a given employee\nand compare it with manual summaries. All techniques are illustrated using a\nreal-life dataset of supervisor assessment and peer feedback text produced\nduring the PA of 4528 employees in a large multi-national IT company.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 10:30:18 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Palshikar", "Girish Keshav", ""], ["Pawar", "Sachin", ""], ["Chourasia", "Saheb", ""], ["Ramrakhiyani", "Nitin", ""]]}, {"id": "1712.01001", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Specifying and Computing Causes for Query Answers in Databases via\n  Database Repairs and Repair Programs", "comments": "To appear in \"Knowledge and Information Systems\" journal. This is the\n  final version, and a much revised, corrected and extended version of:\n  Bertossi, L. \"Characterizing and Computing Causes for Query Answers in\n  Databases from Database Repairs and Repair Programs\". Proc. FoIKs, 2018,\n  Springer LNCS 10833, pp. 55-76", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A correspondence between database tuples as causes for query answers in\ndatabases and tuple-based repairs of inconsistent databases with respect to\ndenial constraints has already been established. In this work, answer-set\nprograms that specify repairs of databases are used as a basis for solving\ncomputational and reasoning problems about causes. Here, causes are also\nintroduced at the attribute level by appealing to a both null-based and\nattribute-based repair semantics. The corresponding repair programs are\npresented, and they are used as a basis for computation and reasoning about\nattribute-level causes. They are extended to deal with the case of causality\nunder integrity constraints.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:00:38 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 00:16:47 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 21:38:17 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2019 16:12:27 GMT"}, {"version": "v5", "created": "Sat, 2 Mar 2019 22:07:45 GMT"}, {"version": "v6", "created": "Fri, 24 Jul 2020 22:50:14 GMT"}, {"version": "v7", "created": "Mon, 28 Sep 2020 19:26:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "1712.01093", "submitter": "Christoph Adami", "authors": "Christoph Adami", "title": "The mind as a computational system", "comments": "17 pages with three figures. In memory of Jerry Fodor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present document is an excerpt of an essay that I wrote as part of my\napplication material to graduate school in Computer Science (with a focus on\nArtificial Intelligence), in 1986. I was not invited by any of the schools that\nreceived it, so I became a theoretical physicist instead. The essay's full\ntitle was \"Some Topics in Philosophy and Computer Science\". I am making this\ntext (unchanged from 1985, preserving the typesetting as much as possible)\navailable now in memory of Jerry Fodor, whose writings had influenced me\nsignificantly at the time (even though I did not always agree).\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 16:34:54 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Adami", "Christoph", ""]]}, {"id": "1712.01106", "submitter": "Akansel Cosgun", "authors": "David Isele and Akansel Cosgun", "title": "Transferring Autonomous Driving Knowledge on Simulated and Real\n  Intersections", "comments": "Appeared in Lifelong Learning Workshop @ ICML 2017. arXiv admin note:\n  text overlap with arXiv:1705.01197", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view intersection handling on autonomous vehicles as a reinforcement\nlearning problem, and study its behavior in a transfer learning setting. We\nshow that a network trained on one type of intersection generally is not able\nto generalize to other intersections. However, a network that is pre-trained on\none intersection and fine-tuned on another performs better on the new task\ncompared to training in isolation. This network also retains knowledge of the\nprior task, even though some forgetting occurs. Finally, we show that the\nbenefits of fine-tuning hold when transferring simulated intersection handling\nknowledge to a real autonomous vehicle.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 06:46:19 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Isele", "David", ""], ["Cosgun", "Akansel", ""]]}, {"id": "1712.01235", "submitter": "Abhinav Jauhri", "authors": "Abhinav Jauhri, Carlee Joe-Wong, John Paul Shen", "title": "On the Real-time Vehicle Placement Problem", "comments": "Presented at NIPS Workshop on Machine Learning for Intelligent\n  Transportation Systems, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by ride-sharing platforms' efforts to reduce their riders' wait\ntimes for a vehicle, this paper introduces a novel problem of placing vehicles\nto fulfill real-time pickup requests in a spatially and temporally changing\nenvironment. The real-time nature of this problem makes it fundamentally\ndifferent from other placement and scheduling problems, as it requires not only\nreal-time placement decisions but also handling real-time request dynamics,\nwhich are influenced by human mobility patterns. We use a dataset of ten\nmillion ride requests from four major U.S. cities to show that the requests\nexhibit significant self-similarity. We then propose distributed online\nlearning algorithms for the real-time vehicle placement problem and bound their\nexpected performance under this observed self-similarity.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:21:38 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Jauhri", "Abhinav", ""], ["Joe-Wong", "Carlee", ""], ["Shen", "John Paul", ""]]}, {"id": "1712.01252", "submitter": "Jun Lu", "authors": "Wei Ma, Jun Lu", "title": "An Equivalence of Fully Connected Layer and Convolutional Layer", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article demonstrates that convolutional operation can be converted to\nmatrix multiplication, which has the same calculation way with fully connected\nlayer. The article is helpful for the beginners of the neural network to\nunderstand how fully connected layer and the convolutional layer work in the\nbackend. To be concise and to make the article more readable, we only consider\nthe linear case. It can be extended to the non-linear case easily through\nplugging in a non-linear encapsulation to the values like this $\\sigma(x)$\ndenoted as $x^{\\prime}$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 18:53:01 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Ma", "Wei", ""], ["Lu", "Jun", ""]]}, {"id": "1712.01262", "submitter": "Yong-Siang Shih", "authors": "Yong-Siang Shih, Kai-Yueh Chang, Hsuan-Tien Lin, Min Sun", "title": "Compatibility Family Learning for Item Recommendation and Generation", "comments": "9 pages, accepted to AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compatibility between items, such as clothes and shoes, is a major factor\namong customer's purchasing decisions. However, learning \"compatibility\" is\nchallenging due to (1) broader notions of compatibility than those of\nsimilarity, (2) the asymmetric nature of compatibility, and (3) only a small\nset of compatible and incompatible items are observed. We propose an end-to-end\ntrainable system to embed each item into a latent vector and project a query\nitem into K compatible prototypes in the same space. These prototypes reflect\nthe broad notions of compatibility. We refer to both the embedding and\nprototypes as \"Compatibility Family\". In our learned space, we introduce a\nnovel Projected Compatibility Distance (PCD) function which is differentiable\nand ensures diversity by aiming for at least one prototype to be close to a\ncompatible item, whereas none of the prototypes are close to an incompatible\nitem. We evaluate our system on a toy dataset, two Amazon product datasets, and\nPolyvore outfit dataset. Our method consistently achieves state-of-the-art\nperformance. Finally, we show that we can visualize the candidate compatible\nprototypes using a Metric-regularized Conditional Generative Adversarial\nNetwork (MrCGAN), where the input is a projected prototype and the output is a\ngenerated image of a compatible item. We ask human evaluators to judge the\nrelative compatibility between our generated images and images generated by\nCGANs conditioned directly on query items. Our generated images are\nsignificantly preferred, with roughly twice the number of votes as others.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 04:22:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Shih", "Yong-Siang", ""], ["Chang", "Kai-Yueh", ""], ["Lin", "Hsuan-Tien", ""], ["Sun", "Min", ""]]}, {"id": "1712.01275", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Richard S. Sutton", "title": "A Deeper Look at Experience Replay", "comments": "NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently experience replay is widely used in various deep reinforcement\nlearning (RL) algorithms, in this paper we rethink the utility of experience\nreplay. It introduces a new hyper-parameter, the memory buffer size, which\nneeds carefully tuning. However unfortunately the importance of this new\nhyper-parameter has been underestimated in the community for a long time. In\nthis paper we did a systematic empirical study of experience replay under\nvarious function representations. We showcase that a large replay buffer can\nsignificantly hurt the performance. Moreover, we propose a simple O(1) method\nto remedy the negative influence of a large replay buffer. We showcase its\nutility in both simple grid world and challenging domains like Atari games.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 06:03:26 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 16:35:12 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 04:24:26 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhang", "Shangtong", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1712.01328", "submitter": "Rakshit Agrawal", "authors": "Rakshit Agrawal, Anwar Habeeb, Chih-Hsin Hsueh", "title": "Learning User Intent from Action Sequences on Interactive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive systems have taken over the web and mobile space with increasing\nparticipation from users. Applications across every marketing domain can now be\naccessed through mobile or web where users can directly perform certain actions\nand reach a desired outcome. Actions of user on a system, though, can be\nrepresentative of a certain intent. Ability to learn this intent through user's\nactions can help draw certain insight into the behavior of users on a system.\n  In this paper, we present models to optimize interactive systems by learning\nand analyzing user intent through their actions on the system. We present a\nfour phased model that uses time-series of interaction actions sequentially\nusing a Long Short-Term Memory (LSTM) based sequence learning system that helps\nbuild a model for intent recognition. Our system then provides an objective\nspecific maximization followed by analysis and contrasting methods in order to\nidentify spaces of improvement in the interaction system. We discuss deployment\nscenarios for such a system and present results from evaluation on an online\nmarketplace using user clickstream data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 20:16:25 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Agrawal", "Rakshit", ""], ["Habeeb", "Anwar", ""], ["Hsueh", "Chih-Hsin", ""]]}, {"id": "1712.01329", "submitter": "Dana Kianfar", "authors": "Mircea Mironenco, Dana Kianfar, Ke Tran, Evangelos Kanoulas,\n  Efstratios Gavves", "title": "Examining Cooperation in Visual Dialog Models", "comments": "9 pages, 5 figures, 2 tables, code at\n  http://github.com/danakianfar/Examining-Cooperation-in-VDM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a blackbox intervention method for visual dialog\nmodels, with the aim of assessing the contribution of individual linguistic or\nvisual components. Concretely, we conduct structured or randomized\ninterventions that aim to impair an individual component of the model, and\nobserve changes in task performance. We reproduce a state-of-the-art visual\ndialog model and demonstrate that our methodology yields surprising insights,\nnamely that both dialog and image information have minimal contributions to\ntask performance. The intervention method presented here can be applied as a\nsanity check for the strength and robustness of each component in visual dialog\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 20:16:52 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Mironenco", "Mircea", ""], ["Kianfar", "Dana", ""], ["Tran", "Ke", ""], ["Kanoulas", "Evangelos", ""], ["Gavves", "Efstratios", ""]]}, {"id": "1712.01455", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Xuchao Zhang, Arnold P. Boedihardjo, Jing Dai and\n  Chang-Tien Lu", "title": "Multimodal Storytelling via Generative Adversarial Imitation Learning", "comments": "IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deriving event storylines is an effective summarization method to succinctly\norganize extensive information, which can significantly alleviate the pain of\ninformation overload. The critical challenge is the lack of widely recognized\ndefinition of storyline metric. Prior studies have developed various approaches\nbased on different assumptions about users' interests. These works can extract\ninteresting patterns, but their assumptions do not guarantee that the derived\npatterns will match users' preference. On the other hand, their exclusiveness\nof single modality source misses cross-modality information. This paper\nproposes a method, multimodal imitation learning via generative adversarial\nnetworks(MIL-GAN), to directly model users' interests as reflected by various\ndata. In particular, the proposed model addresses the critical challenge by\nimitating users' demonstrated storylines. Our proposed model is designed to\nlearn the reward patterns given user-provided storylines and then applies the\nlearned policy to unseen data. The proposed approach is demonstrated to be\ncapable of acquiring the user's implicit intent and outperforming competing\nmethods by a substantial margin with a user study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:51:35 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Chen", "Zhiqian", ""], ["Zhang", "Xuchao", ""], ["Boedihardjo", "Arnold P.", ""], ["Dai", "Jing", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1712.01456", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Chih-Wei Wu, Yen-Cheng Lu, Alexander Lerch and\n  Chang-Tien Lu", "title": "Learning to Fuse Music Genres with Generative Adversarial Dual Learning", "comments": "International Conference on Data Mining - New Orleans, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FusionGAN is a novel genre fusion framework for music generation that\nintegrates the strengths of generative adversarial networks and dual learning.\nIn particular, the proposed method offers a dual learning extension that can\neffectively integrate the styles of the given domains. To efficiently quantify\nthe difference among diverse domains and avoid the vanishing gradient issue,\nFusionGAN provides a Wasserstein based metric to approximate the distance\nbetween the target domain and the existing domains. Adopting the Wasserstein\ndistance, a new domain is created by combining the patterns of the existing\ndomains using adversarial learning. Experimental results on public music\ndatasets demonstrated that our approach could effectively merge two genres.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 02:53:27 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Chen", "Zhiqian", ""], ["Wu", "Chih-Wei", ""], ["Lu", "Yen-Cheng", ""], ["Lerch", "Alexander", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1712.01488", "submitter": "EPTCS", "authors": "Tomer Libal (Inria, Paris), Xaviera Steele (American University of\n  Paris)", "title": "Determinism in the Certification of UNSAT Proofs", "comments": "In Proceedings PxTP 2017, arXiv:1712.00898", "journal-ref": "EPTCS 262, 2017, pp. 55-76", "doi": "10.4204/EPTCS.262.6", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for increased trustworthiness of SAT solvers is very active and\nuses various methods. Some of these methods obtain a proof from the provers\nthen check it, normally by replicating the search based on the proof's\ninformation. Because the certification process involves another nontrivial\nproof search, the trust we can place in it is decreased. Some attempts to amend\nthis use certifiers which have been verified by proofs assistants such as\nIsabelle/HOL and Coq. Our approach is different because it is based on an\nextremely simplified certifier. This certifier enjoys a very high level of\ntrust but is very inefficient. In this paper, we experiment with this approach\nand conclude that by placing some restrictions on the formats, one can mostly\neliminate the need for search and in principle, can certify proofs of arbitrary\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 05:49:02 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Libal", "Tomer", "", "Inria, Paris"], ["Steele", "Xaviera", "", "American University of\n  Paris"]]}, {"id": "1712.01626", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Autonomous development and learning in artificial intelligence and\n  robotics: Scaling up deep learning to human--like learning", "comments": null, "journal-ref": "Behavioral and Brain Sciences, Cambridge University Press (CUP),\n  2017, 40", "doi": "10.1017/S0140525X17000243", "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:03:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]]}, {"id": "1712.01643", "submitter": "Qingxiang Feng", "authors": "Qingxiang Feng and Yicong Zhou", "title": "Discriminant Projection Representation-based Classification for Vision\n  Recognition", "comments": "Accepted by the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation-based classification methods such as sparse\nrepresentation-based classification (SRC) and linear regression classification\n(LRC) have attracted a lot of attentions. In order to obtain the better\nrepresentation, a novel method called projection representation-based\nclassification (PRC) is proposed for image recognition in this paper. PRC is\nbased on a new mathematical model. This model denotes that the 'ideal\nprojection' of a sample point $x$ on the hyper-space $H$ may be gained by\niteratively computing the projection of $x$ on a line of hyper-space $H$ with\nthe proper strategy. Therefore, PRC is able to iteratively approximate the\n'ideal representation' of each subject for classification. Moreover, the\ndiscriminant PRC (DPRC) is further proposed, which obtains the discriminant\ninformation by maximizing the ratio of the between-class reconstruction error\nover the within-class reconstruction error. Experimental results on five\ntypical databases show that the proposed PRC and DPRC are effective and\noutperform other state-of-the-art methods on several vision recognition tasks.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 06:25:17 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Feng", "Qingxiang", ""], ["Zhou", "Yicong", ""]]}, {"id": "1712.01651", "submitter": "Shun Miao", "authors": "Shun Miao, Sebastien Piat, Peter Fischer, Ahmet Tuysuzoglu, Philip\n  Mewes, Tommaso Mansi, Rui Liao", "title": "Dilated FCN for Multi-Agent 2D/3D Medical Image Registration", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2D/3D image registration to align a 3D volume and 2D X-ray images is a\nchallenging problem due to its ill-posed nature and various artifacts presented\nin 2D X-ray images. In this paper, we propose a multi-agent system with an auto\nattention mechanism for robust and efficient 2D/3D image registration.\nSpecifically, an individual agent is trained with dilated Fully Convolutional\nNetwork (FCN) to perform registration in a Markov Decision Process (MDP) by\nobserving a local region, and the final action is then taken based on the\nproposals from multiple agents and weighted by their corresponding confidence\nlevels. The contributions of this paper are threefold. First, we formulate\n2D/3D registration as a MDP with observations, actions, and rewards properly\ndefined with respect to X-ray imaging systems. Second, to handle various\nartifacts in 2D X-ray images, multiple local agents are employed efficiently\nvia FCN-based structures, and an auto attention mechanism is proposed to favor\nthe proposals from regions with more reliable visual cues. Third, a dilated\nFCN-based training mechanism is proposed to significantly reduce the Degree of\nFreedom in the simulation of registration environment, and drastically improve\ntraining efficiency by an order of magnitude compared to standard CNN-based\ntraining method. We demonstrate that the proposed method achieves high\nrobustness on both spine cone beam Computed Tomography data with a low\nsignal-to-noise ratio and data from minimally invasive spine surgery where\nsevere image artifacts and occlusions are presented due to metal screws and\nguide wires, outperforming other state-of-the-art methods (single agent-based\nand optimization-based) by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 03:22:17 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Miao", "Shun", ""], ["Piat", "Sebastien", ""], ["Fischer", "Peter", ""], ["Tuysuzoglu", "Ahmet", ""], ["Mewes", "Philip", ""], ["Mansi", "Tommaso", ""], ["Liao", "Rui", ""]]}, {"id": "1712.01668", "submitter": "Siyu Yu", "authors": "Siyu Yu, Nanning Zheng, Yongqiang Ma, Hao Wu, Badong Chen", "title": "A Novel Brain Decoding Method: a Correlation Network Framework for\n  Revealing Brain Connections", "comments": "10 pages, 8 figures, IEEE Transactions on Cognitive and Developmental\n  Systems(TCDS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain decoding is a hot spot in cognitive science, which focuses on\nreconstructing perceptual images from brain activities. Analyzing the\ncorrelations of collected data from human brain activities and representing\nactivity patterns are two problems in brain decoding based on functional\nmagnetic resonance imaging (fMRI) signals. However, existing correlation\nanalysis methods mainly focus on the strength information of voxel, which\nreveals functional connectivity in the cerebral cortex. They tend to neglect\nthe structural information that implies the intracortical or intrinsic\nconnections; that is, structural connectivity. Hence, the effective\nconnectivity inferred by these methods is relatively unilateral. Therefore, we\nproposed a correlation network (CorrNet) framework that could be flexibly\ncombined with diverse pattern representation models. In the CorrNet framework,\nthe topological correlation was introduced to reveal structural information.\nRich correlations were obtained, which contributed to specifying the underlying\neffective connectivity. We also combined the CorrNet framework with a linear\nsupport vector machine (SVM) and a dynamic evolving spike neuron network (SNN)\nfor pattern representation separately, thus providing a novel method for\ndecoding cognitive activity patterns. Experimental results verified the\nreliability and robustness of our CorrNet framework and demonstrated that the\nnew method achieved significant improvement in brain decoding over comparable\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 11:24:54 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Yu", "Siyu", ""], ["Zheng", "Nanning", ""], ["Ma", "Yongqiang", ""], ["Wu", "Hao", ""], ["Chen", "Badong", ""]]}, {"id": "1712.01694", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo\n  Emmanuel de Souza, Priscilla B. Mendes, Henrique S. S. Monteiro, Havana Diogo\n  Alves", "title": "Fuzzy-Based Dialectical Non-Supervised Image Classification and\n  Clustering", "comments": null, "journal-ref": "International Journal of Hybrid Intelligent Systems, v. 7, p.\n  115-124, 2010", "doi": "10.3233/HIS-2010-0108", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The materialist dialectical method is a philosophical investigative method to\nanalyze aspects of reality. These aspects are viewed as complex processes\ncomposed by basic units named poles, which interact with each other. Dialectics\nhas experienced considerable progress in the 19th century, with Hegel's\ndialectics and, in the 20th century, with the works of Marx, Engels, and\nGramsci, in Philosophy and Economics. The movement of poles through their\ncontradictions is viewed as a dynamic process with intertwined phases of\nevolution and revolutionary crisis. In order to build a computational process\nbased on dialectics, the interaction between poles can be modeled using fuzzy\nmembership functions. Based on this assumption, we introduce the Objective\nDialectical Classifier (ODC), a non-supervised map for classification based on\nmaterialist dialectics and designed as an extension of fuzzy c-means\nclassifier. As a case study, we used ODC to classify 181 magnetic resonance\nsynthetic multispectral images composed by proton density, $T_1$- and\n$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,\nand Kohonen's self-organized maps, concerning with image fidelity indexes as\nestimatives of quantization distortion, we proved that ODC can reach almost the\nsame quantization performance as optimal non-supervised classifiers like\nKohonen's self-organized maps.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 17:56:15 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Assis", "Francisco Marcos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Mendes", "Priscilla B.", ""], ["Monteiro", "Henrique S. S.", ""], ["Alves", "Havana Diogo", ""]]}, {"id": "1712.01815", "submitter": "David Silver", "authors": "David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou,\n  Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran,\n  Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis", "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement\n  Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game of chess is the most widely-studied domain in the history of\nartificial intelligence. The strongest programs are based on a combination of\nsophisticated search techniques, domain-specific adaptations, and handcrafted\nevaluation functions that have been refined by human experts over several\ndecades. In contrast, the AlphaGo Zero program recently achieved superhuman\nperformance in the game of Go, by tabula rasa reinforcement learning from games\nof self-play. In this paper, we generalise this approach into a single\nAlphaZero algorithm that can achieve, tabula rasa, superhuman performance in\nmany challenging domains. Starting from random play, and given no domain\nknowledge except the game rules, AlphaZero achieved within 24 hours a\nsuperhuman level of play in the games of chess and shogi (Japanese chess) as\nwell as Go, and convincingly defeated a world-champion program in each case.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 18:45:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Silver", "David", ""], ["Hubert", "Thomas", ""], ["Schrittwieser", "Julian", ""], ["Antonoglou", "Ioannis", ""], ["Lai", "Matthew", ""], ["Guez", "Arthur", ""], ["Lanctot", "Marc", ""], ["Sifre", "Laurent", ""], ["Kumaran", "Dharshan", ""], ["Graepel", "Thore", ""], ["Lillicrap", "Timothy", ""], ["Simonyan", "Karen", ""], ["Hassabis", "Demis", ""]]}, {"id": "1712.01930", "submitter": "Kyriaki Kalimeri", "authors": "Kyriaki Kalimeri, Mariano G. Beiro, Matteo Delfino, Robert Raleigh and\n  Ciro Cattuto", "title": "Predicting Demographics, Moral Foundations, and Human Values from\n  Digital Behaviors", "comments": null, "journal-ref": null, "doi": "10.1016/j.chb.2018.11.024", "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal electronic devices including smartphones give access to behavioural\nsignals that can be used to learn about the characteristics and preferences of\nindividuals. In this study, we explore the connection between demographic and\npsychological attributes and the digital behavioural records, for a cohort of\n7,633 people, closely representative of the US population with respect to\ngender, age, geographical distribution, education, and income. Along with the\ndemographic data, we collected self-reported assessments on validated\npsychometric questionnaires for moral traits and basic human values and\ncombined this information with passively collected multi-modal digital data\nfrom web browsing behaviour and smartphone usage. A machine learning framework\nwas then designed to infer both the demographic and psychological attributes\nfrom the behavioural data. In a cross-validated setting, our models predicted\ndemographic attributes with good accuracy as measured by the weighted AUROC\nscore (Area Under the Receiver Operating Characteristic), but were less\nperformant for the moral traits and human values. These results call for\nfurther investigation since they are still far from unveiling individuals'\npsychological fabric. This connection, along with the most predictive features\nthat we provide for each attribute, might prove useful for designing\npersonalised services, communication strategies, and interventions, and can be\nused to sketch a portrait of people with a similar worldview.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:20:34 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:33:55 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 16:08:49 GMT"}, {"version": "v4", "created": "Wed, 21 Nov 2018 15:21:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Kalimeri", "Kyriaki", ""], ["Beiro", "Mariano G.", ""], ["Delfino", "Matteo", ""], ["Raleigh", "Robert", ""], ["Cattuto", "Ciro", ""]]}, {"id": "1712.01949", "submitter": "Yantian Zha", "authors": "Yantian Zha, Yikang Li, Sriram Gopalakrishnan, Baoxin Li, Subbarao\n  Kambhampati", "title": "Recognizing Plans by Learning Embeddings from Observed Action\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in visual activity recognition have raised the possibility of\napplications such as automated video surveillance. Effective approaches for\nsuch problems however require the ability to recognize the plans of agents from\nvideo information. Although traditional plan recognition algorithms depend on\naccess to sophisticated planning domain models, one recent promising direction\ninvolves learning approximated (or shallow) domain models directly from the\nobserved activity sequences DUP. One limitation is that such approaches expect\nobserved action sequences as inputs. In many cases involving vision/sensing\nfrom raw data, there is considerable uncertainty about the specific action at\nany given time point. The most we can expect in such cases is probabilistic\ninformation about the action at that point. The input will then be sequences of\nsuch observed action distributions. In this work, we address the problem of\nconstructing an effective data-interface that allows a plan recognition module\nto directly handle such observation distributions. Such an interface works like\na bridge between the low-level perception module, and the high-level plan\nrecognition module. We propose two approaches. The first involves resampling\nthe distribution sequences to single action sequences, from which we could\nlearn an action affinity model based on learned action (word) embeddings for\nplan recognition. The second is to directly learn action distribution\nembeddings by our proposed Distr2vec (distribution to vector) model, to\nconstruct an affinity model for plan recognition.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 22:06:25 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 17:30:54 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Zha", "Yantian", ""], ["Li", "Yikang", ""], ["Gopalakrishnan", "Sriram", ""], ["Li", "Baoxin", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1712.01996", "submitter": "Anjuli Kannan", "authors": "Anjuli Kannan, Yonghui Wu, Patrick Nguyen, Tara N. Sainath, Zhifeng\n  Chen, Rohit Prabhavalkar", "title": "An analysis of incorporating an external language model into a\n  sequence-to-sequence model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models for automatic speech recognition\njointly train an acoustic model, language model, and alignment mechanism. Thus,\nthe language model component is only trained on transcribed audio-text pairs.\nThis leads to the use of shallow fusion with an external language model at\ninference time. Shallow fusion refers to log-linear interpolation with a\nseparately trained language model at each step of the beam search. In this\nwork, we investigate the behavior of shallow fusion across a range of\nconditions: different types of language models, different decoding units, and\ndifferent tasks. On Google Voice Search, we demonstrate that the use of shallow\nfusion with a neural LM with wordpieces yields a 9.1% relative word error rate\nreduction (WERR) over our competitive attention-based sequence-to-sequence\nmodel, obviating the need for second-pass rescoring.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 01:30:54 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Kannan", "Anjuli", ""], ["Wu", "Yonghui", ""], ["Nguyen", "Patrick", ""], ["Sainath", "Tara N.", ""], ["Chen", "Zhifeng", ""], ["Prabhavalkar", "Rohit", ""]]}, {"id": "1712.02034", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Nathan O. Hodas, Charles Siegel, Abhinav Vishnu", "title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties", "comments": "Submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 04:29:28 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:50:32 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Goh", "Garrett B.", ""], ["Hodas", "Nathan O.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1712.02046", "submitter": "Borui Wang", "authors": "Borui Wang, Geoffrey Gordon", "title": "Learning General Latent-Variable Graphical Models with Predictive Belief\n  Propagation", "comments": "In AAAI 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning general latent-variable probabilistic graphical models is a key\ntheoretical challenge in machine learning and artificial intelligence. All\nprevious methods, including the EM algorithm and the spectral algorithms, face\nsevere limitations that largely restrict their applicability and affect their\nperformance. In order to overcome these limitations, in this paper we introduce\na novel formulation of message-passing inference over junction trees named\npredictive belief propagation, and propose a new learning and inference\nalgorithm for general latent-variable graphical models based on this\nformulation. Our proposed algorithm reduces the hard parameter learning problem\ninto a sequence of supervised learning problems, and unifies the learning of\ndifferent kinds of latent graphical models into a single learning framework,\nwhich is local-optima-free and statistically consistent. We then give a proof\nof the correctness of our algorithm and show in experiments on both synthetic\nand real datasets that our algorithm significantly outperforms both the EM\nalgorithm and the spectral algorithm while also being orders of magnitude\nfaster to compute.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 05:38:25 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 14:50:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wang", "Borui", ""], ["Gordon", "Geoffrey", ""]]}, {"id": "1712.02047", "submitter": "Jinbae Im", "authors": "Jinbae Im and Sungzoon Cho", "title": "Distance-based Self-Attention Network for Natural Language Inference", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism has been used as an ancillary means to help RNN or CNN.\nHowever, the Transformer (Vaswani et al., 2017) recently recorded the\nstate-of-the-art performance in machine translation with a dramatic reduction\nin training time by solely using attention. Motivated by the Transformer,\nDirectional Self Attention Network (Shen et al., 2017), a fully attention-based\nsentence encoder, was proposed. It showed good performance with various data by\nusing forward and backward directional information in a sentence. But in their\nstudy, not considered at all was the distance between words, an important\nfeature when learning the local dependency to help understand the context of\ninput text. We propose Distance-based Self-Attention Network, which considers\nthe word distance by using a simple distance mask in order to model the local\ndependency without losing the ability of modeling global dependency which\nattention has inherent. Our model shows good performance with NLI data, and it\nrecords the new state-of-the-art result with SNLI data. Additionally, we show\nthat our model has a strength in long sentences or documents.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 05:38:29 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Im", "Jinbae", ""], ["Cho", "Sungzoon", ""]]}, {"id": "1712.02224", "submitter": "Luca Pappalardo", "authors": "Luca Pappalardo and Paolo Cintia and Dino Pedreschi and Fosca\n  Giannotti and Albert-Laszlo Barabasi", "title": "Human Perception of Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are routinely asked to evaluate the performance of other individuals,\nseparating success from failure and affecting outcomes from science to\neducation and sports. Yet, in many contexts, the metrics driving the human\nevaluation process remain unclear. Here we analyse a massive dataset capturing\nplayers' evaluations by human judges to explore human perception of performance\nin soccer, the world's most popular sport. We use machine learning to design an\nartificial judge which accurately reproduces human evaluation, allowing us to\ndemonstrate how human observers are biased towards diverse contextual features.\nBy investigating the structure of the artificial judge, we uncover the aspects\nof the players' behavior which attract the attention of human judges,\ndemonstrating that human evaluation is based on a noticeability heuristic where\nonly feature values far from the norm are considered to rate an individual's\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 09:13:32 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Pappalardo", "Luca", ""], ["Cintia", "Paolo", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""], ["Barabasi", "Albert-Laszlo", ""]]}, {"id": "1712.02225", "submitter": "Xuelin Qian", "authors": "Xuelin Qian, Yanwei Fu, Tao Xiang, Wenxuan Wang, Jie Qiu, Yang Wu,\n  Yu-Gang Jiang, Xiangyang Xue", "title": "Pose-Normalized Image Generation for Person Re-identification", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person Re-identification (re-id) faces two major challenges: the lack of\ncross-view paired training data and learning discriminative identity-sensitive\nand view-invariant features in the presence of large pose variations. In this\nwork, we address both problems by proposing a novel deep person image\ngeneration model for synthesizing realistic person images conditional on the\npose. The model is based on a generative adversarial network (GAN) designed\nspecifically for pose normalization in re-id, thus termed pose-normalization\nGAN (PN-GAN). With the synthesized images, we can learn a new type of deep\nre-id feature free of the influence of pose variations. We show that this\nfeature is strong on its own and complementary to features learned with the\noriginal images. Importantly, under the transfer learning setting, we show that\nour model generalizes well to any new re-id dataset without the need for\ncollecting any training data for model fine-tuning. The model thus has the\npotential to make re-id model truly scalable.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 15:18:53 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 04:55:01 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 00:28:00 GMT"}, {"version": "v4", "created": "Fri, 2 Feb 2018 06:59:45 GMT"}, {"version": "v5", "created": "Tue, 13 Feb 2018 06:22:12 GMT"}, {"version": "v6", "created": "Wed, 25 Apr 2018 05:57:05 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Qian", "Xuelin", ""], ["Fu", "Yanwei", ""], ["Xiang", "Tao", ""], ["Wang", "Wenxuan", ""], ["Qiu", "Jie", ""], ["Wu", "Yang", ""], ["Jiang", "Yu-Gang", ""], ["Xue", "Xiangyang", ""]]}, {"id": "1712.02316", "submitter": "Mahdi Namazifar", "authors": "Mahdi Namazifar", "title": "Named Entity Sequence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) aims at locating and classifying named\nentities in text. In some use cases of NER, including cases where detected\nnamed entities are used in creating content recommendations, it is crucial to\nhave a reliable confidence level for the detected named entities. In this work\nwe study the problem of finding confidence levels for detected named entities.\nWe refer to this problem as Named Entity Sequence Classification (NESC). We\nframe NESC as a binary classification problem and we use NER as well as\nrecurrent neural networks to find the probability of candidate named entity is\na real named entity. We apply this approach to Tweet texts and we show how we\ncould find named entities with high confidence levels from Tweets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:33:55 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Namazifar", "Mahdi", ""]]}, {"id": "1712.02494", "submitter": "Jiajun Lu", "authors": "Jiajun Lu, Hussein Sibai, Evan Fabry", "title": "Adversarial Examples that Fool Detectors", "comments": "Follow up paper for adversarial stop signs. Submitted to CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial example is an example that has been adjusted to produce a\nwrong label when presented to a system at test time. To date, adversarial\nexample constructions have been demonstrated for classifiers, but not for\ndetectors. If adversarial examples that could fool a detector exist, they could\nbe used to (for example) maliciously create security hazards on roads populated\nwith smart vehicles. In this paper, we demonstrate a construction that\nsuccessfully fools two standard detectors, Faster RCNN and YOLO. The existence\nof such examples is surprising, as attacking a classifier is very different\nfrom attacking a detector, and that the structure of detectors - which must\nsearch for their own bounding box, and which cannot estimate that box very\naccurately - makes it quite likely that adversarial patterns are strongly\ndisrupted. We show that our construction produces adversarial examples that\ngeneralize well across sequences digitally, even though large perturbations are\nneeded. We also show that our construction yields physical objects that are\nadversarial.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 05:13:54 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Lu", "Jiajun", ""], ["Sibai", "Hussein", ""], ["Fabry", "Evan", ""]]}, {"id": "1712.02734", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas", "title": "Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for\n  Transferable Chemical Property Prediction", "comments": "Submitted to SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With access to large datasets, deep neural networks (DNN) have achieved\nhuman-level accuracy in image and speech recognition tasks. However, in\nchemistry, data is inherently small and fragmented. In this work, we develop an\napproach of using rule-based knowledge for training ChemNet, a transferable and\ngeneralizable deep neural network for chemical property prediction that learns\nin a weak-supervised manner from large unlabeled chemical databases. When\ncoupled with transfer learning approaches to predict other smaller datasets for\nchemical properties that it was not originally trained on, we show that\nChemNet's accuracy outperforms contemporary DNN models that were trained using\nconventional supervised learning. Furthermore, we demonstrate that the ChemNet\npre-training approach is equally effective on both CNN (Chemception) and RNN\n(SMILES2vec) models, indicating that this approach is network architecture\nagnostic and is effective across multiple data modalities. Our results indicate\na pre-trained ChemNet that incorporates chemistry domain knowledge, enables the\ndevelopment of generalizable neural networks for more accurate prediction of\nnovel chemical properties.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 17:25:48 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:50:02 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Goh", "Garrett B.", ""], ["Siegel", "Charles", ""], ["Vishnu", "Abhinav", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "1712.02820", "submitter": "Heri Ramampiaro", "authors": "Basant Agarwal, Heri Ramampiaro, Helge Langseth, Massimiliano Ruocco", "title": "A Deep Network Model for Paraphrase Detection in Short Text Messages", "comments": null, "journal-ref": "B Agarwal, H. Ramampiaro, H Langseth, M Ruocco, (2018), \"A Deep\n  Network Model for Paraphrase Detection in Short Text Messages\". In\n  Information Processing & Management Journal (IPM), 54(6), pp. 922-937.\n  Elsevier", "doi": "10.1016/j.ipm.2018.06.005", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with paraphrase detection. The ability to detect\nsimilar sentences written in natural language is crucial for several\napplications, such as text mining, text summarization, plagiarism detection,\nauthorship authentication and question answering. Given two sentences, the\nobjective is to detect whether they are semantically identical. An important\ninsight from this work is that existing paraphrase systems perform well when\napplied on clean texts, but they do not necessarily deliver good performance\nagainst noisy texts. Challenges with paraphrase detection on user generated\nshort texts, such as Twitter, include language irregularity and noise. To cope\nwith these challenges, we propose a novel deep neural network-based approach\nthat relies on coarse-grained sentence modeling using a convolutional neural\nnetwork and a long short-term memory model, combined with a specific\nfine-grained word-level similarity matching model. Our experimental results\nshow that the proposed approach outperforms existing state-of-the-art\napproaches on user-generated noisy social media data, such as Twitter texts,\nand achieves highly competitive performance on a cleaner corpus.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:10:45 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Agarwal", "Basant", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""], ["Ruocco", "Massimiliano", ""]]}, {"id": "1712.02838", "submitter": "Li Zhou", "authors": "Li Zhou, Kevin Small, Oleg Rokhlenko, Charles Elkan", "title": "End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy\n  Gradient", "comments": "Workshop on Conversational AI, NIPS 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a goal-oriented dialog policy is generally performed offline with\nsupervised learning algorithms or online with reinforcement learning (RL).\nAdditionally, as companies accumulate massive quantities of dialog transcripts\nbetween customers and trained human agents, encoder-decoder methods have gained\npopularity as agent utterances can be directly treated as supervision without\nthe need for utterance-level annotations. However, one potential drawback of\nsuch approaches is that they myopically generate the next agent utterance\nwithout regard for dialog-level considerations. To resolve this concern, this\npaper describes an offline RL method for learning from unannotated corpora that\ncan optimize a goal-oriented policy at both the utterance and dialog level. We\nintroduce a novel reward function and use both on-policy and off-policy policy\ngradient to learn a policy offline without requiring online user interaction or\nan explicit state space definition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 19:52:50 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""], ["Rokhlenko", "Oleg", ""], ["Elkan", "Charles", ""]]}, {"id": "1712.02869", "submitter": "Harold Boley", "authors": "Harold Boley, Gen Zou", "title": "Perspectival Knowledge in PSOA RuleML: Representation, Model Theory, and\n  Translation", "comments": "39 pages, 5 figures, 2 tables; updates for PSOATransRun 1.3.1 to\n  1.4.2; refined terminology and metamodel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Positional-Slotted Object-Applicative (PSOA) RuleML, a predicate\napplication (atom) can have an Object IDentifier (OID) and descriptors that may\nbe positional arguments (tuples) or attribute-value pairs (slots). PSOA RuleML\nexplicitly specifies for each descriptor whether it is to be interpreted under\nthe perspective of the predicate in whose scope it occurs. This\npredicate-dependency dimension refines the space between oidless, positional\natoms (relationships) and oidful, slotted atoms (framepoints): While\nrelationships use only a predicate-scope-sensitive (predicate-dependent) tuple\nand framepoints use only predicate-scope-insensitive (predicate-independent)\nslots, PSOA uses a systematics of orthogonal constructs also permitting atoms\nwith (predicate-)independent tuples and atoms with (predicate-)dependent slots.\nThis supports data and knowledge representation where a slot attribute can have\ndifferent values depending on the predicate. PSOA thus extends object-oriented\nmulti-membership and multiple inheritance. Based on objectification, PSOA laws\nare given: Besides unscoping and centralization, the semantic restriction and\ntransformation of describution permits rescoping of one atom's independent\ndescriptors to another atom with the same OID but a different predicate. For\ninheritance, default descriptors are realized by rules. On top of a metamodel\nand a Grailog visualization, PSOA's atom systematics for facts, queries, and\nrules is explained. The presentation and (XML-)serialization syntaxes of PSOA\nRuleML are introduced. Its model-theoretic semantics is formalized by extending\nthe interpretation functions for dependent descriptors. The open-source\nPSOATransRun system realizes PSOA RuleML by a translator to runtime predicates,\nincluding for dependent tuples (prdtupterm) and slots (prdsloterm). Our tests\nshow efficiency advantages of dependent and tupled modeling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 21:36:21 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 00:19:21 GMT"}, {"version": "v3", "created": "Sun, 21 Jul 2019 17:58:15 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Boley", "Harold", ""], ["Zou", "Gen", ""]]}, {"id": "1712.02975", "submitter": "Chen Zhu", "authors": "Chen Zhu, Hengshu Zhu, Hui Xiong, Pengliang Ding, Fang Xie", "title": "Recruitment Market Trend Analysis with Sequential Latent Variable Models", "comments": "11 pages, 30 figure, SIGKDD 2016", "journal-ref": null, "doi": "10.1145/2939672.2939689", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recruitment market analysis provides valuable understanding of\nindustry-specific economic growth and plays an important role for both\nemployers and job seekers. With the rapid development of online recruitment\nservices, massive recruitment data have been accumulated and enable a new\nparadigm for recruitment market analysis. However, traditional methods for\nrecruitment market analysis largely rely on the knowledge of domain experts and\nclassic statistical models, which are usually too general to model large-scale\ndynamic recruitment data, and have difficulties to capture the fine-grained\nmarket trends. To this end, in this paper, we propose a new research paradigm\nfor recruitment market analysis by leveraging unsupervised learning techniques\nfor automatically discovering recruitment market trends based on large-scale\nrecruitment data. Specifically, we develop a novel sequential latent variable\nmodel, named MTLVM, which is designed for capturing the sequential dependencies\nof corporate recruitment states and is able to automatically learn the latent\nrecruitment topics within a Bayesian generative framework. In particular, to\ncapture the variability of recruitment topics over time, we design hierarchical\ndirichlet processes for MTLVM. These processes allow to dynamically generate\nthe evolving recruitment topics. Finally, we implement a prototype system to\nempirically evaluate our approach based on real-world recruitment data in\nChina. Indeed, by visualizing the results from MTLVM, we can successfully\nreveal many interesting findings, such as the popularity of LBS related jobs\nreached the peak in the 2nd half of 2014, and decreased in 2015.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 08:06:03 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zhu", "Chen", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["Ding", "Pengliang", ""], ["Xie", "Fang", ""]]}, {"id": "1712.03010", "submitter": "Farnood Salehi", "authors": "Farnood Salehi, Patrick Thiran, L. Elisa Celis", "title": "Coordinate Descent with Bandit Sampling", "comments": "appearing at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinate descent methods usually minimize a cost function by updating a\nrandom decision variable (corresponding to one coordinate) at a time. Ideally,\nwe would update the decision variable that yields the largest decrease in the\ncost function. However, finding this coordinate would require checking all of\nthem, which would effectively negate the improvement in computational\ntractability that coordinate descent is intended to afford. To address this, we\npropose a new adaptive method for selecting a coordinate. First, we find a\nlower bound on the amount the cost function decreases when a coordinate is\nupdated. We then use a multi-armed bandit algorithm to learn which coordinates\nresult in the largest lower bound by interleaving this learning with\nconventional coordinate descent updates except that the coordinate is selected\nproportionately to the expected decrease. We show that our approach improves\nthe convergence of coordinate descent methods both theoretically and\nexperimentally.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 10:23:30 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 15:25:14 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Salehi", "Farnood", ""], ["Thiran", "Patrick", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1712.03043", "submitter": "Zengkun Li", "authors": "Zengkun Li", "title": "A Heuristic Search Algorithm Using the Stability of Learning Algorithms\n  in Certain Scenarios as the Fitness Function: An Artificial General\n  Intelligence Engineering Approach", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a non-manual design engineering method based on heuristic\nsearch algorithm to search for candidate agents in the solution space which\nformed by artificial intelligence agents modeled on the base of\nbionics.Compared with the artificial design method represented by meta-learning\nand the bionics method represented by the neural architecture chip,this method\nis more feasible for realizing artificial general intelligence,and it has a\nmuch better interaction with cognitive neuroscience;at the same time,the\nengineering method is based on the theoretical hypothesis that the final\nlearning algorithm is stable in certain scenarios,and has generalization\nability in various scenarios.The paper discusses the theory preliminarily and\nproposes the possible correlation between the theory and the fixed-point\ntheorem in the field of mathematics.Limited by the author's knowledge\nlevel,this correlation is proposed only as a kind of conjecture.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 12:23:13 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 13:46:49 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 02:08:04 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Li", "Zengkun", ""]]}, {"id": "1712.03086", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Jiayuan Ding, Runqi Shao, Anoop Kumar, Pedro Szekely", "title": "FlagIt: A System for Minimally Supervised Human Trafficking Indicator\n  Mining", "comments": "6 pages, published in Workshop on Learning with Limited Labeled Data\n  co-held with NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe and study the indicator mining problem in the\nonline sex advertising domain. We present an in-development system, FlagIt\n(Flexible and adaptive generation of Indicators from text), which combines the\nbenefits of both a lightweight expert system and classical semi-supervision\n(heuristic re-labeling) with recently released state-of-the-art unsupervised\ntext embeddings to tag millions of sentences with indicators that are highly\ncorrelated with human trafficking. The FlagIt technology stack is open source.\nOn preliminary evaluations involving five indicators, FlagIt illustrates\npromising performance compared to several alternatives. The system is being\nactively developed, refined and integrated into a domain-specific search system\nused by over 200 law enforcement agencies to combat human trafficking, and is\nbeing aggressively extended to mine at least six more indicators with minimal\nprogramming effort. FlagIt is a good example of a system that operates in\nlimited label settings, and that requires creative combinations of established\nmachine learning techniques to produce outputs that could be used by real-world\nnon-technical analysts.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:15:48 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Ding", "Jiayuan", ""], ["Shao", "Runqi", ""], ["Kumar", "Anoop", ""], ["Szekely", "Pedro", ""]]}, {"id": "1712.03132", "submitter": "Enoch Yeung Ph.D.", "authors": "Charles A. Johnson, Enoch Yeung", "title": "A Class of Logistic Functions for Approximating State-Inclusive Koopman\n  Operators", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outstanding challenge in nonlinear systems theory is identification or\nlearning of a given nonlinear system's Koopman operator directly from data or\nmodels. Advances in extended dynamic mode decomposition approaches and machine\nlearning methods have enabled data-driven discovery of Koopman operators, for\nboth continuous and discrete-time systems. Since Koopman operators are often\ninfinite-dimensional, they are approximated in practice using\nfinite-dimensional systems. The fidelity and convergence of a given\nfinite-dimensional Koopman approximation is a subject of ongoing research. In\nthis paper we introduce a class of Koopman observable functions that confer an\napproximate closure property on their corresponding finite-dimensional\napproximations of the Koopman operator. We derive error bounds for the fidelity\nof this class of observable functions, as well as identify two key learning\nparameters which can be used to tune performance. We illustrate our approach on\ntwo classical nonlinear system models: the Van Der Pol oscillator and the\nbistable toggle switch.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:41:42 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Johnson", "Charles A.", ""], ["Yeung", "Enoch", ""]]}, {"id": "1712.03133", "submitter": "Kartik Audhkhasi", "authors": "Kartik Audhkhasi, Brian Kingsbury, Bhuvana Ramabhadran, George Saon,\n  Michael Picheny", "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition", "comments": "Submitted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:43:21 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""], ["Ramabhadran", "Bhuvana", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""]]}, {"id": "1712.03223", "submitter": "Majdi Mafarja Dr.", "authors": "Majdi Mafarja and Seyedali Mirjalili", "title": "S-Shaped vs. V-Shaped Transfer Functions for Antlion Optimization\n  Algorithm in Feature Selection Problems", "comments": "7 pages", "journal-ref": "Majdi Mafarja, Derar Eleyan, Salwani Abdullah, and Seyedali\n  Mirjalili. 2017. S-Shaped vs. V-Shaped Transfer Functions for Ant Lion\n  Optimization Algorithm in Feature Selection Problem. In Proceedings of ICFNDS\n  '17", "doi": "10.1145/3102304.3102325", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important preprocessing step for classification\nproblems. It deals with selecting near optimal features in the original\ndataset. Feature selection is an NP-hard problem, so meta-heuristics can be\nmore efficient than exact methods. In this work, Ant Lion Optimizer (ALO),\nwhich is a recent metaheuristic algorithm, is employed as a wrapper feature\nselection method. Six variants of ALO are proposed where each employ a transfer\nfunction to map a continuous search space to a discrete search space. The\nperformance of the proposed approaches is tested on eighteen UCI datasets and\ncompared to a number of existing approaches in the literature: Particle Swarm\nOptimization, Gravitational Search Algorithm, and two existing ALO-based\napproaches. Computational experiments show that the proposed approaches\nefficiently explore the feature space and select the most informative features,\nwhich help to improve the classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 05:17:12 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Mafarja", "Majdi", ""], ["Mirjalili", "Seyedali", ""]]}, {"id": "1712.03249", "submitter": "Tobias Moers", "authors": "Florian Krebs, Bruno Lubascher, Tobias Moers, Pieter Schaap, Gerasimos\n  Spanakis", "title": "Social Emotion Mining Techniques for Facebook Posts Reaction Prediction", "comments": "10 pages, 13 figures and accepted at ICAART 2018. (Dataset:\n  https://github.com/jerryspan/FacebookR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of February 2016 Facebook allows users to express their experienced\nemotions about a post by using five so-called `reactions'. This research paper\nproposes and evaluates alternative methods for predicting these reactions to\nuser posts on public pages of firms/companies (like supermarket chains). For\nthis purpose, we collected posts (and their reactions) from Facebook pages of\nlarge supermarket chains and constructed a dataset which is available for other\nresearches. In order to predict the distribution of reactions of a new post,\nneural network architectures (convolutional and recurrent neural networks) were\ntested using pretrained word embeddings. Results of the neural networks were\nimproved by introducing a bootstrapping approach for sentiment and emotion\nmining on the comments for each post. The final model (a combination of neural\nnetwork and a baseline emotion miner) is able to predict the reaction\ndistribution on Facebook posts with a mean squared error (or misclassification\nrate) of 0.135.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 19:05:50 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Krebs", "Florian", ""], ["Lubascher", "Bruno", ""], ["Moers", "Tobias", ""], ["Schaap", "Pieter", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1712.03280", "submitter": "Deepak Dilipkumar", "authors": "Ben Parr, Deepak Dilipkumar, Yuan Liu", "title": "Nintendo Super Smash Bros. Melee: An \"Untouchable\" Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nintendo's Super Smash Bros. Melee fighting game can be emulated on modern\nhardware allowing us to inspect internal memory states, such as character\npositions. We created an AI that avoids being hit by training using these\ninternal memory states and outputting controller button presses. After training\non a month's worth of Melee matches, our best agent learned to avoid the\ntoughest AI built into the game for a full minute 74.6% of the time.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 21:07:18 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Parr", "Ben", ""], ["Dilipkumar", "Deepak", ""], ["Liu", "Yuan", ""]]}, {"id": "1712.03333", "submitter": "Heejin Jeong", "authors": "Heejin Jeong, Clark Zhang, George J. Pappas, Daniel D. Lee", "title": "Assumed Density Filtering Q-learning", "comments": "source code: https://github.com/coco66/ADFQ.git ; IJCAI-19", "journal-ref": "Proceedings of the Twenty-Eighth International Joint Conference on\n  Artificial Intelligence, 2019", "doi": "10.24963/ijcai.2019/362", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While off-policy temporal difference (TD) methods have widely been used in\nreinforcement learning due to their efficiency and simple implementation, their\nBayesian counterparts have not been utilized as frequently. One reason is that\nthe non-linear max operation in the Bellman optimality equation makes it\ndifficult to define conjugate distributions over the value functions. In this\npaper, we introduce a novel Bayesian approach to off-policy TD methods, called\nas ADFQ, which updates beliefs on state-action values, Q, through an online\nBayesian inference method known as Assumed Density Filtering. We formulate an\nefficient closed-form solution for the value update by approximately estimating\nanalytic parameters of the posterior of the Q-beliefs. Uncertainty measures in\nthe beliefs not only are used in exploration but also provide a natural\nregularization for the value update considering all next available actions.\nADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs\ndecrease and improves common drawbacks of other Bayesian RL algorithms such as\ncomputational complexity. We extend ADFQ with a neural network. Our empirical\nresults demonstrate that ADFQ outperforms comparable algorithms on various\nAtari 2600 games, with drastic improvements in highly stochastic domains or\ndomains with a large action space.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 02:18:05 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 03:22:06 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 19:45:13 GMT"}, {"version": "v4", "created": "Mon, 3 Jun 2019 05:09:09 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Jeong", "Heejin", ""], ["Zhang", "Clark", ""], ["Pappas", "George J.", ""], ["Lee", "Daniel D.", ""]]}, {"id": "1712.03390", "submitter": "Konda Reddy Mopuri", "authors": "Konda Reddy Mopuri, Utkarsh Ojha, Utsav Garg and R. Venkatesh Babu", "title": "NAG: Network for Adversary Generation", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial perturbations can pose a serious threat for deploying machine\nlearning systems. Recent works have shown existence of image-agnostic\nperturbations that can fool classifiers over most natural images. Existing\nmethods present optimization approaches that solve for a fooling objective with\nan imperceptibility constraint to craft the perturbations. However, for a given\nclassifier, they generate one perturbation at a time, which is a single\ninstance from the manifold of adversarial perturbations. Also, in order to\nbuild robust models, it is essential to explore the manifold of adversarial\nperturbations. In this paper, we propose for the first time, a generative\napproach to model the distribution of adversarial perturbations. The\narchitecture of the proposed model is inspired from that of GANs and is trained\nusing fooling and diversity objectives. Our trained generator network attempts\nto capture the distribution of adversarial perturbations for a given classifier\nand readily generates a wide variety of such perturbations. Our experimental\nevaluation demonstrates that perturbations crafted by our model (i) achieve\nstate-of-the-art fooling rates, (ii) exhibit wide variety and (iii) deliver\nexcellent cross model generalizability. Our work can be deemed as an important\nstep in the process of inferring about the complex manifolds of adversarial\nperturbations.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 14:27:49 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 09:31:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Mopuri", "Konda Reddy", ""], ["Ojha", "Utkarsh", ""], ["Garg", "Utsav", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1712.03608", "submitter": "Philipp Oettershagen", "authors": "Philipp Oettershagen, Florian Achermann, Benjamin M\\\"uller, Daniel\n  Schneider and Roland Siegwart", "title": "Towards Fully Environment-Aware UAVs: Real-Time Path Planning with\n  Online 3D Wind Field Prediction in Complex Terrain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, low-altitude fixed-wing Unmanned Aerial Vehicles (UAVs) are largely\nlimited to primitively follow user-defined waypoints. To allow fully-autonomous\nremote missions in complex environments, real-time environment-aware navigation\nis required both with respect to terrain and strong wind drafts. This paper\npresents two relevant initial contributions: First, the literature's first-ever\n3D wind field prediction method which can run in real time onboard a UAV is\npresented. The approach retrieves low-resolution global weather data, and uses\npotential flow theory to adjust the wind field such that terrain boundaries,\nmass conservation, and the atmospheric stratification are observed. A\ncomparison with 1D LIDAR data shows an overall wind error reduction of 23% with\nrespect to the zero-wind assumption that is mostly used for UAV path planning\ntoday. However, given that the vertical winds are not resolved accurately\nenough further research is required and identified. Second, a sampling-based\npath planner that considers the aircraft dynamics in non-uniform wind\niteratively via Dubins airplane paths is presented. Performance optimizations,\ne.g. obstacle-aware sampling and fast 2.5D-map collision checks, render the\nplanner 50% faster than the Open Motion Planning Library (OMPL) implementation.\nTest cases in Alpine terrain show that the wind-aware planning performs up to\n50x less iterations than shortest-path planning and is thus slower in low\nwinds, but that it tends to deliver lower-cost paths in stronger winds. More\nimportantly, in contrast to the shortest-path planner, it always delivers\ncollision-free paths. Overall, our initial research demonstrates the\nfeasibility of 3D wind field prediction from a UAV and the advantages of\nwind-aware planning. This paves the way for follow-up research on\nfully-autonomous environment-aware navigation of UAVs in real-life missions and\ncomplex terrain.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 23:13:45 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Oettershagen", "Philipp", ""], ["Achermann", "Florian", ""], ["M\u00fcller", "Benjamin", ""], ["Schneider", "Daniel", ""], ["Siegwart", "Roland", ""]]}, {"id": "1712.03632", "submitter": "Anay Pattanaik", "authors": "Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan and\n  Girish Chowdhary", "title": "Robust Deep Reinforcement Learning with Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes adversarial attacks for Reinforcement Learning (RL) and\nthen improves the robustness of Deep Reinforcement Learning algorithms (DRL) to\nparameter uncertainties with the help of these attacks. We show that even a\nnaively engineered attack successfully degrades the performance of DRL\nalgorithm. We further improve the attack using gradient information of an\nengineered loss function which leads to further degradation in performance.\nThese attacks are then leveraged during training to improve the robustness of\nRL within robust control framework. We show that this adversarial training of\nDRL algorithms like Deep Double Q learning and Deep Deterministic Policy\nGradients leads to significant increase in robustness to parameter variations\nfor RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah\nenvironment.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 02:58:13 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Pattanaik", "Anay", ""], ["Tang", "Zhenyi", ""], ["Liu", "Shuijing", ""], ["Bommannan", "Gautham", ""], ["Chowdhary", "Girish", ""]]}, {"id": "1712.03719", "submitter": "Zlatan Ajanovic MSc", "authors": "Zlatan Ajanovic, Michael Stolz, Martin Horn", "title": "A novel model-based heuristic for energy optimal motion planning for\n  automated driving", "comments": "6 pages, 6 figures, 1 table, accepted to IFAC CTS 2018, Savona, Italy", "journal-ref": null, "doi": "10.1016/j.ifacol.2018.07.042", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive motion planning is the key to achieve energy-efficient driving,\nwhich is one of the main benefits of automated driving. Researchers have been\nstudying the planning of velocity trajectories, a simpler form of motion\nplanning, for over a decade now and many different methods are available.\nDynamic programming has shown to be the most common choice due to its numerical\nbackground and ability to include nonlinear constraints and models. Although\nplanning of an optimal trajectory is done in a systematic way, dynamic\nprogramming does not use any knowledge about the considered problem to guide\nthe exploration and therefore explores all possible trajectories.\n  A* is a search algorithm which enables using knowledge about the problem to\nguide the exploration to the most promising solutions first. Knowledge has to\nbe represented in a form of a heuristic function, which gives an optimistic\nestimate of cost for transitioning to the final state, which is not a\nstraightforward task. This paper presents a novel heuristics incorporating air\ndrag and auxiliary power as well as operational costs of the vehicle, besides\nkinetic and potential energy and rolling resistance known in the literature.\nFurthermore, optimal cruising velocity, which depends on vehicle aerodynamic\nproperties and auxiliary power, is derived. Results are compared for different\nvariants of heuristic functions and dynamic programming as well.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 11:24:23 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 09:39:34 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Ajanovic", "Zlatan", ""], ["Stolz", "Michael", ""], ["Horn", "Martin", ""]]}, {"id": "1712.03724", "submitter": "Sarthak Ahuja", "authors": "Rakesh R Pimplikar, Kushal Mukherjee, Gyana Parija, Harit Vishwakarma,\n  Ramasuri Narayanam, Sarthak Ahuja, Rohith D Vallam, Ritwik Chaudhuri, Joydeep\n  Mondal", "title": "Cogniculture: Towards a Better Human-Machine Co-evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in Artificial Intelligence is breaking technology barriers every\nday. New algorithms and high performance computing are making things possible\nwhich we could only have imagined earlier. Though the enhancements in AI are\nmaking life easier for human beings day by day, there is constant fear that AI\nbased systems will pose a threat to humanity. People in AI community have\ndiverse set of opinions regarding the pros and cons of AI mimicking human\nbehavior. Instead of worrying about AI advancements, we propose a novel idea of\ncognitive agents, including both human and machines, living together in a\ncomplex adaptive ecosystem, collaborating on human computation for producing\nessential social goods while promoting sustenance, survival and evolution of\nthe agents' life cycle. We highlight several research challenges and technology\nbarriers in achieving this goal. We propose a governance mechanism around this\necosystem to ensure ethical behaviors of all cognitive agents. Along with a\nnovel set of use-cases of Cogniculture, we discuss the road map ahead for this\njourney.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 11:31:28 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Pimplikar", "Rakesh R", ""], ["Mukherjee", "Kushal", ""], ["Parija", "Gyana", ""], ["Vishwakarma", "Harit", ""], ["Narayanam", "Ramasuri", ""], ["Ahuja", "Sarthak", ""], ["Vallam", "Rohith D", ""], ["Chaudhuri", "Ritwik", ""], ["Mondal", "Joydeep", ""]]}, {"id": "1712.03779", "submitter": "Karl Kumbier", "authors": "Bin Yu and Karl Kumbier", "title": "Artificial Intelligence and Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is intrinsically data-driven. It calls for the\napplication of statistical concepts through human-machine collaboration during\ngeneration of data, development of algorithms, and evaluation of results. This\npaper discusses how such human-machine collaboration can be approached through\nthe statistical concepts of population, question of interest,\nrepresentativeness of training data, and scrutiny of results (PQRS). The PQRS\nworkflow provides a conceptual framework for integrating statistical ideas with\nhuman input into AI products and research. These ideas include experimental\ndesign principles of randomization and local control as well as the principle\nof stability to gain reproducibility and interpretability of algorithms and\ndata results. We discuss the use of these principles in the contexts of\nself-driving cars, automated medical diagnoses, and examples from the authors'\ncollaborative research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 02:18:43 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Yu", "Bin", ""], ["Kumbier", "Karl", ""]]}, {"id": "1712.03781", "submitter": "Eunwoo Kim", "authors": "Eunwoo Kim, Chanho Ahn, Songhwai Oh", "title": "NestedNet: Learning Nested Sparse Structures in Deep Neural Networks", "comments": "To appear in CVPR 2018. Spotlight Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been increasing demands to construct compact deep\narchitectures to remove unnecessary redundancy and to improve the inference\nspeed. While many recent works focus on reducing the redundancy by eliminating\nunneeded weight parameters, it is not possible to apply a single deep\narchitecture for multiple devices with different resources. When a new device\nor circumstantial condition requires a new deep architecture, it is necessary\nto construct and train a new network from scratch. In this work, we propose a\nnovel deep learning framework, called a nested sparse network, which exploits\nan n-in-1-type nested structure in a neural network. A nested sparse network\nconsists of multiple levels of networks with a different sparsity ratio\nassociated with each level, and higher level networks share parameters with\nlower level networks to enable stable nested learning. The proposed framework\nrealizes a resource-aware versatile architecture as the same network can meet\ndiverse resource requirements. Moreover, the proposed nested network can learn\ndifferent forms of knowledge in its internal networks at different levels,\nenabling multiple tasks using a single network, such as coarse-to-fine\nhierarchical classification. In order to train the proposed nested sparse\nnetwork, we propose efficient weight connection learning and channel and layer\nscheduling strategies. We evaluate our network in multiple tasks, including\nadaptive deep compression, knowledge distillation, and learning class\nhierarchy, and demonstrate that nested sparse networks perform competitively,\nbut more efficiently, compared to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 14:09:06 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 04:44:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kim", "Eunwoo", ""], ["Ahn", "Chanho", ""], ["Oh", "Songhwai", ""]]}, {"id": "1712.03890", "submitter": "Theophilus Benson", "authors": "Christopher Streiffer, Huan Chen, Theophilus Benson, Asim Kadav", "title": "DeepConfig: Automating Data Center Network Topologies Management with\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many techniques have been developed to improve the\nperformance and efficiency of data center networks. While these techniques\nprovide high accuracy, they are often designed using heuristics that leverage\ndomain-specific properties of the workload or hardware.\n  In this vision paper, we argue that many data center networking techniques,\ne.g., routing, topology augmentation, energy savings, with diverse goals\nactually share design and architectural similarity. We present a design for\ndeveloping general intermediate representations of network topologies using\ndeep learning that is amenable to solving classes of data center problems. We\ndevelop a framework, DeepConfig, that simplifies the processing of configuring\nand training deep learning agents that use the intermediate representation to\nlearns different tasks. To illustrate the strength of our approach, we\nconfigured, implemented, and evaluated a DeepConfig-Agent that tackles the data\ncenter topology augmentation problem. Our initial results are promising ---\nDeepConfig performs comparably to the optimal.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:07:12 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Streiffer", "Christopher", ""], ["Chen", "Huan", ""], ["Benson", "Theophilus", ""], ["Kadav", "Asim", ""]]}, {"id": "1712.03931", "submitter": "Manolis Savva", "authors": "Manolis Savva, Angel X. Chang, Alexey Dosovitskiy, Thomas Funkhouser,\n  Vladlen Koltun", "title": "MINOS: Multimodal Indoor Simulator for Navigation in Complex\n  Environments", "comments": "MINOS is a simulator designed to support research on end-to-end\n  navigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MINOS, a simulator designed to support the development of\nmultisensory models for goal-directed navigation in complex indoor\nenvironments. The simulator leverages large datasets of complex 3D environments\nand supports flexible configuration of multimodal sensor suites. We use MINOS\nto benchmark deep-learning-based navigation methods, to analyze the influence\nof environmental complexity on navigation performance, and to carry out a\ncontrolled study of multimodality in sensorimotor learning. The experiments\nshow that current deep reinforcement learning approaches fail in large\nrealistic environments. The experiments also indicate that multimodality is\nbeneficial in learning to navigate cluttered scenes. MINOS is released\nopen-source to the research community at http://minosworld.org . A video that\nshows MINOS can be found at https://youtu.be/c0mL9K64q84\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 18:24:58 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Savva", "Manolis", ""], ["Chang", "Angel X.", ""], ["Dosovitskiy", "Alexey", ""], ["Funkhouser", "Thomas", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1712.04008", "submitter": "Michael Bernico", "authors": "Michael Bernico, Yuntao Li, Dingchao Zhang", "title": "Investigating the Impact of Data Volume and Domain Similarity on\n  Transfer Learning Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning allows practitioners to recognize and apply knowledge\nlearned in previous tasks (source task) to new tasks or new domains (target\ntask), which share some commonality. The two important factors impacting the\nperformance of transfer learning models are: (a) the size of the target\ndataset, and (b) the similarity in distribution between source and target\ndomains. Thus far, there has been little investigation into just how important\nthese factors are. In this paper, we investigate the impact of target dataset\nsize and source/target domain similarity on model performance through a series\nof experiments. We find that more data is always beneficial, and model\nperformance improves linearly with the log of data size, until we are out of\ndata. As source/target domains differ, more data is required and fine tuning\nwill render better performance than feature extraction. When source/target\ndomains are similar and data size is small, fine tuning and feature extraction\nrenders equivalent performance. Our hope is that by beginning this quantitative\ninvestigation on the effect of data volume and domain similarity in transfer\nlearning we might inspire others to explore the significance of data in\ndeveloping more accurate statistical models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 20:30:44 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 18:14:44 GMT"}, {"version": "v3", "created": "Thu, 24 May 2018 19:09:19 GMT"}, {"version": "v4", "created": "Wed, 30 May 2018 19:35:08 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Bernico", "Michael", ""], ["Li", "Yuntao", ""], ["Zhang", "Dingchao", ""]]}, {"id": "1712.04020", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Detecting Qualia in Natural and Artificial Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hard Problem of consciousness has been dismissed as an illusion. By\nshowing that computers are capable of experiencing, we show that they are at\nleast rudimentarily conscious with potential to eventually reach\nsuperconsciousness. The main contribution of the paper is a test for confirming\ncertain subjective experiences in a tested agent. We follow with analysis of\nbenefits and problems with conscious machines and implications of such\ncapability on future of computing, machine rights and artificial intelligence\nsafety.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 20:53:47 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1712.04034", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Shang-Wen Li, Jin Cao, Jared Casale, Peter\n  Henderson, David Whitney, Alborz Geramifard", "title": "Learning Robust Dialog Policies in Noisy Environments", "comments": "1st Workshop on Conversational AI at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern virtual personal assistants provide a convenient interface for\ncompleting daily tasks via voice commands. An important consideration for these\nassistants is the ability to recover from automatic speech recognition (ASR)\nand natural language understanding (NLU) errors. In this paper, we focus on\nlearning robust dialog policies to recover from these errors. To this end, we\ndevelop a user simulator which interacts with the assistant through voice\ncommands in realistic scenarios with noisy audio, and use it to learn dialog\npolicies through deep reinforcement learning. We show that dialogs generated by\nour simulator are indistinguishable from human generated dialogs, as determined\nby human evaluators. Furthermore, preliminary experimental results show that\nthe learned policies in noisy environments achieve the same execution success\nrate with fewer dialog turns compared to fixed rule-based policies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 21:22:01 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Li", "Shang-Wen", ""], ["Cao", "Jin", ""], ["Casale", "Jared", ""], ["Henderson", "Peter", ""], ["Whitney", "David", ""], ["Geramifard", "Alborz", ""]]}, {"id": "1712.04065", "submitter": "Miao Liu", "authors": "Miao Liu, Marlos C. Machado, Gerald Tesauro, Murray Campbell", "title": "The Eigenoption-Critic Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigenoptions (EOs) have been recently introduced as a promising idea for\ngenerating a diverse set of options through the graph Laplacian, having been\nshown to allow efficient exploration. Despite its initial promising results, a\ncouple of issues in current algorithms limit its application, namely: (1) EO\nmethods require two separate steps (eigenoption discovery and reward\nmaximization) to learn a control policy, which can incur a significant amount\nof storage and computation; (2) EOs are only defined for problems with discrete\nstate-spaces and; (3) it is not easy to take the environment's reward function\ninto consideration when discovering EOs. To addresses these issues, we\nintroduce an algorithm termed eigenoption-critic (EOC) based on the\nOption-critic (OC) framework [Bacon17], a general hierarchical reinforcement\nlearning (RL) algorithm that allows learning the intra-option policies\nsimultaneously with the policy over options. We also propose a generalization\nof EOC to problems with continuous state-spaces through the Nystr\\\"om\napproximation. EOC can also be seen as extending OC to nonstationary settings,\nwhere the discovered options are not tailored for a single task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 23:21:42 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Liu", "Miao", ""], ["Machado", "Marlos C.", ""], ["Tesauro", "Gerald", ""], ["Campbell", "Murray", ""]]}, {"id": "1712.04076", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein and Martin Zaefferer and Frederik Rehbach", "title": "In a Nutshell -- The Sequential Parameter Optimization Toolbox", "comments": "For SPOT Version >= 2.2.24", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AI math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The performance of optimization algorithms relies crucially on their\nparameterizations. Finding good parameter settings is called algorithm tuning.\nThe sequential parameter optimization (SPOT) package for R is a toolbox for\ntuning and understanding simulation and optimization algorithms. Model-based\ninvestigations are common approaches in simulation and optimization. Sequential\nparameter optimization has been developed, because there is a strong need for\nsound statistical analysis of simulation and optimization algorithms. SPOT\nincludes methods for tuning based on classical regression and analysis of\nvariance techniques; tree-based models such as CART and random forest; Gaussian\nprocess models (Kriging), and combinations of different meta-modeling\napproaches. Using a simple simulated annealing algorithm, we will demonstrate\nhow optimization algorithms can be tuned using SPOT. The underling concepts of\nthe SPOT approach are explained. This includes key techniques such as\nexploratory fitness landscape analysis and sensititvity analysis. Many examples\nillustrate how SPOT can be used for understanding the performance of algorithms\nand gaining insight into algorithm's behavior. Furthermore, we demonstrate how\nSPOT can be used as an optimizer and how a sophisticated ensemble approach is\nable to combine several meta models via stacking. This article exemplifies how\nSPOT can be used for automatic and interactive tuning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 00:03:45 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 18:55:44 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Zaefferer", "Martin", ""], ["Rehbach", "Frederik", ""]]}, {"id": "1712.04143", "submitter": "Boyi Li", "authors": "Boyi Li and Wenqi Ren and Dengpan Fu and Dacheng Tao and Dan Feng and\n  Wenjun Zeng and Zhangyang Wang", "title": "Benchmarking Single Image Dehazing and Beyond", "comments": "IEEE Transactions on Image Processing(TIP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive study and evaluation of existing single image\ndehazing algorithms, using a new large-scale benchmark consisting of both\nsynthetic and real-world hazy images, called REalistic Single Image DEhazing\n(RESIDE). RESIDE highlights diverse data sources and image contents, and is\ndivided into five subsets, each serving different training or evaluation\npurposes. We further provide a rich variety of criteria for dehazing algorithm\nevaluation, ranging from full-reference metrics, to no-reference metrics, to\nsubjective evaluation and the novel task-driven evaluation. Experiments on\nRESIDE shed light on the comparisons and limitations of state-of-the-art\ndehazing algorithms, and suggest promising future directions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 06:33:20 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 13:27:35 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 14:33:39 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 00:13:07 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Li", "Boyi", ""], ["Ren", "Wenqi", ""], ["Fu", "Dengpan", ""], ["Tao", "Dacheng", ""], ["Feng", "Dan", ""], ["Zeng", "Wenjun", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1712.04155", "submitter": "Jingyi Wang Ph.D.", "authors": "Jingyi Wang and Jun Sun and Yifan Jia and Shengchao Qin and Zhiwu Xu", "title": "Toward `verifying' a Water Treatment System", "comments": "Accepted by FM 2018", "journal-ref": null, "doi": "10.1007/978-3-319-95582-7_5", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and verifying real-world cyber-physical systems is challenging,\nwhich is especially so for complex systems where manually modeling is\ninfeasible. In this work, we report our experience on combining model learning\nand abstraction refinement to analyze a challenging system, i.e., a real-world\nSecure Water Treatment system (SWaT). Given a set of safety requirements, the\nobjective is to either show that the system is safe with a high probability (so\nthat a system shutdown is rarely triggered due to safety violation) or not. As\nthe system is too complicated to be manually modeled, we apply latest automatic\nmodel learning techniques to construct a set of Markov chains through\nabstraction and refinement, based on two long system execution logs (one for\ntraining and the other for testing). For each probabilistic safety property, we\neither report it does not hold with a certain level of probabilistic\nconfidence, or report that it holds by showing the evidence in the form of an\nabstract Markov chain. The Markov chains can subsequently be implemented as\nruntime monitors in SWaT.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 07:54:12 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 02:36:46 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Jia", "Yifan", ""], ["Qin", "Shengchao", ""], ["Xu", "Zhiwu", ""]]}, {"id": "1712.04159", "submitter": "Niek Tax", "authors": "Niek Tax, Marlon Dumas", "title": "Mining Non-Redundant Local Process Models From Sequence Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential pattern mining techniques extract patterns corresponding to\nfrequent subsequences from a sequence database. A practical limitation of these\ntechniques is that they overload the user with too many patterns. Local Process\nModel (LPM) mining is an alternative approach coming from the field of process\nmining. While in traditional sequential pattern mining, a pattern describes one\nsubsequence, an LPM captures a set of subsequences. Also, while traditional\nsequential patterns only match subsequences that are observed in the sequence\ndatabase, an LPM may capture subsequences that are not explicitly observed, but\nthat are related to observed subsequences. In other words, LPMs generalize the\nbehavior observed in the sequence database. These properties make it possible\nfor a set of LPMs to cover the behavior of a much larger set of sequential\npatterns. Yet, existing LPM mining techniques still suffer from the pattern\nexplosion problem because they produce sets of redundant LPMs. In this paper,\nwe propose several heuristics to mine a set of non-redundant LPMs either from a\nset of redundant LPMs or from a set of sequential patterns. We empirically\ncompare the proposed heuristics between them and against existing (local)\nprocess mining techniques in terms of coverage, redundancy, and complexity of\nthe produced sets of LPMs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:03:50 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 06:51:54 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Tax", "Niek", ""], ["Dumas", "Marlon", ""]]}, {"id": "1712.04170", "submitter": "Daniel Hein", "authors": "Daniel Hein, Steffen Udluft, Thomas A. Runkler", "title": "Interpretable Policies for Reinforcement Learning by Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for interpretable reinforcement learning policies is of high\nacademic and industrial interest. Especially for industrial systems, domain\nexperts are more likely to deploy autonomously learned controllers if they are\nunderstandable and convenient to evaluate. Basic algebraic equations are\nsupposed to meet these requirements, as long as they are restricted to an\nadequate complexity. Here we introduce the genetic programming for\nreinforcement learning (GPRL) approach based on model-based batch reinforcement\nlearning and genetic programming, which autonomously learns policy equations\nfrom pre-existing default state-action trajectory samples. GPRL is compared to\na straight-forward method which utilizes genetic programming for symbolic\nregression, yielding policies imitating an existing well-performing, but\nnon-interpretable policy. Experiments on three reinforcement learning\nbenchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,\ndemonstrate the superiority of our GPRL approach compared to the symbolic\nregression method. GPRL is capable of producing well-performing interpretable\nreinforcement learning policies from pre-existing default trajectory data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:31:51 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 07:23:57 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Hein", "Daniel", ""], ["Udluft", "Steffen", ""], ["Runkler", "Thomas A.", ""]]}, {"id": "1712.04172", "submitter": "Yueh-Hua Wu", "authors": "Yueh-Hua Wu and Shou-De Lin", "title": "A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning\n  Agents", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a low-cost, easily realizable strategy to equip a\nreinforcement learning (RL) agent the capability of behaving ethically. Our\nmodel allows the designers of RL agents to solely focus on the task to achieve,\nwithout having to worry about the implementation of multiple trivial ethical\npatterns to follow. Based on the assumption that the majority of human\nbehavior, regardless which goals they are achieving, is ethical, our design\nintegrates human policy with the RL policy to achieve the target objective with\nless chance of violating the ethical code that human beings normally obey.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:35:52 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 04:59:19 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wu", "Yueh-Hua", ""], ["Lin", "Shou-De", ""]]}, {"id": "1712.04182", "submitter": "Wenpin Jiao", "authors": "Wenpin Jiao", "title": "Contradiction-Centricity: A Uniform Model for Formation of Swarm\n  Intelligence and its Simulations", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a grand challenge to model the emergence of swarm intelligence and many\nprinciples or models had been proposed. However, existing models do not catch\nthe nature of swarm intelligence and they are not generic enough to describe\nvarious types of emergence phenomena. In this work, we propose a\ncontradiction-centric model for emergence of swarm intelligence, in which\nindividuals' contradictions dominate their appearances whilst they are\nassociated and interacting to update their contradictions. This model\nhypothesizes that 1) the emergence of swarm intelligence is rooted in the\ndevelopment of contradictions of individuals and the interactions among\nassociated individuals and 2) swarm intelligence is essentially a combinative\nreflection of the configurations of contradictions inside individuals and the\ndistributions of contradictions among individuals. To verify the feasibility of\nthe model, we simulate four types of swarm intelligence. As the simulations\nshow, our model is truly generic and can describe the emergence of a variety of\nswarm intelligence, and it is also very simple and can be easily applied to\ndemonstrate the emergence of swarm intelligence without needing complicated\ncomputations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 09:25:02 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Jiao", "Wenpin", ""]]}, {"id": "1712.04306", "submitter": "Mihai Nadin", "authors": "Mihai Nadin", "title": "In folly ripe. In reason rotten. Putting machine theology to rest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation has changed the world more than any previous expressions of\nknowledge. In its particular algorithmic embodiment, it offers a perspective,\nwithin which the digital computer (one of many possible) exercises a role\nreminiscent of theology. Since it is closed to meaning, algorithmic digital\ncomputation can at most mimic the creative aspects of life. AI, in the\nperspective of time, proved to be less an acronym for artificial intelligence\nand more of automating tasks associated with intelligence. The entire\ndevelopment led to the hypostatized role of the machine: outputting nothing\nelse but reality, including that of the humanity that made the machine happen.\nThe convergence machine called deep learning is only the latest form through\nwhich the deterministic theology of the machine claims more than what extremely\neffective data processing actually is. A new understanding of complexity, as\nwell as the need to distinguish between the reactive nature of the artificial\nand the anticipatory nature of the living are suggested as practical responses\nto the challenges posed by machine theology.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 23:26:16 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Nadin", "Mihai", ""]]}, {"id": "1712.04307", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma, Nick J. Hay, and Adam Safron", "title": "AI Safety and Reproducibility: Establishing Robust Foundations for the\n  Neuropsychology of Human Values", "comments": "5 pages", "journal-ref": "In: Gallina B., Skavhaug A., Schoitsch E., Bitsch F. (eds)\n  Computer Safety, Reliability, and Security. SAFECOMP 2018. Lecture Notes in\n  Computer Science, vol 11094. Springer, Cham", "doi": "10.1007/978-3-319-99229-7_45", "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the creation of a systematic effort to identify and replicate key\nfindings in neuropsychology and allied fields related to understanding human\nvalues. Our aim is to ensure that research underpinning the value alignment\nproblem of artificial intelligence has been sufficiently validated to play a\nrole in the design of AI systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 19:40:15 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 20:30:26 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 20:44:43 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Sarma", "Gopal P.", ""], ["Hay", "Nick J.", ""], ["Safron", "Adam", ""]]}, {"id": "1712.04323", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Deep Echo State Network (DeepESN): A Brief Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of deep recurrent neural networks (RNNs) and, in particular, of\ndeep Reservoir Computing (RC) is gaining an increasing research attention in\nthe neural networks community. The recently introduced Deep Echo State Network\n(DeepESN) model opened the way to an extremely efficient approach for designing\ndeep neural networks for temporal data. At the same time, the study of DeepESNs\nallowed to shed light on the intrinsic properties of state dynamics developed\nby hierarchical compositions of recurrent layers, i.e. on the bias of depth in\nRNNs architectural design. In this paper, we summarize the advancements in the\ndevelopment, analysis and applications of DeepESNs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:50:51 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 14:01:34 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 19:59:13 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 17:53:57 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "1712.04363", "submitter": "Patrick Klose", "authors": "Patrick Klose, Rudolf Mester", "title": "Simulated Autonomous Driving on Realistic Road Networks using Deep\n  Reinforcement Learning", "comments": "The paper is submitted to be included in the proceedings of\n  Applications of Intelligent Systems 2018 (APPIS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Deep Reinforcement Learning (DRL) can be a promising approach to handle\nvarious tasks in the field of (simulated) autonomous driving. However, recent\npublications mainly consider learning in unusual driving environments. This\npaper presents Driving School for Autonomous Agents (DSA^2), a software for\nvalidating DRL algorithms in more usual driving environments based on\nartificial and realistic road networks. We also present the results of applying\nDSA^2 for handling the task of driving on a straight road while regulating the\nvelocity of one vehicle according to different speed limits.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 15:55:53 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 14:16:19 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Klose", "Patrick", ""], ["Mester", "Rudolf", ""]]}, {"id": "1712.04386", "submitter": "Amrita Gupta", "authors": "Amrita Gupta, Mehrdad Farajtabar, Bistra Dilkina and Hongyuan Zha", "title": "Hawkes Processes for Invasive Species Modeling and Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.AI cs.CE cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of invasive species to new areas threatens the stability of\necosystems and causes major economic losses in agriculture and forestry. We\npropose a novel approach to minimizing the spread of an invasive species given\na limited intervention budget. We first model invasive species propagation\nusing Hawkes processes, and then derive closed-form expressions for\ncharacterizing the effect of an intervention action on the invasion process. We\nuse this to obtain an optimal intervention plan based on an integer programming\nformulation, and compare the optimal plan against several\necologically-motivated heuristic strategies used in practice. We present an\nempirical study of two variants of the invasive control problem: minimizing the\nfinal rate of invasions, and minimizing the number of invasions at the end of a\ngiven time horizon. Our results show that the optimized intervention achieves\nnearly the same level of control that would be attained by completely\neradicating the species, with a 20% cost saving. Additionally, we design a\nheuristic intervention strategy based on a combination of the density and life\nstage of the invasive individuals, and find that it comes surprisingly close to\nthe optimized strategy, suggesting that this could serve as a good rule of\nthumb in invasive species management.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 16:54:27 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Gupta", "Amrita", ""], ["Farajtabar", "Mehrdad", ""], ["Dilkina", "Bistra", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1712.04402", "submitter": "Ignacio Martin", "authors": "Ignacio Mart\\'in, Jos\\'e Alberto Hern\\'andez, Alfonso Mu\\~noz, Antonio\n  Guzm\\'an", "title": "Android Malware Characterization using Metadata and Machine Learning\n  Techniques", "comments": "4 figures, 2 tables and 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android Malware has emerged as a consequence of the increasing popularity of\nsmartphones and tablets. While most previous work focuses on inherent\ncharacteristics of Android apps to detect malware, this study analyses indirect\nfeatures and meta-data to identify patterns in malware applications. Our\nexperiments show that: (1) the permissions used by an application offer only\nmoderate performance results; (2) other features publicly available at Android\nMarkets are more relevant in detecting malware, such as the application\ndeveloper and certificate issuer, and (3) compact and efficient classifiers can\nbe constructed for the early detection of malware applications prior to code\ninspection or sandboxing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 17:39:33 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Mart\u00edn", "Ignacio", ""], ["Hern\u00e1ndez", "Jos\u00e9 Alberto", ""], ["Mu\u00f1oz", "Alfonso", ""], ["Guzm\u00e1n", "Antonio", ""]]}, {"id": "1712.04415", "submitter": "Zhe Wu", "authors": "Zhe Wu, Bharat Singh, Larry S. Davis, V. S. Subrahmanian", "title": "Deception Detection in Videos", "comments": "AAAI 2018, project page: https://doubaibai.github.io/DARE/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for covert automated deception detection in real-life\ncourtroom trial videos. We study the importance of different modalities like\nvision, audio and text for this task. On the vision side, our system uses\nclassifiers trained on low level video features which predict human\nmicro-expressions. We show that predictions of high-level micro-expressions can\nbe used as features for deception prediction. Surprisingly, IDT (Improved Dense\nTrajectory) features which have been widely used for action recognition, are\nalso very good at predicting deception in videos. We fuse the score of\nclassifiers trained on IDT features and high-level micro-expressions to improve\nperformance. MFCC (Mel-frequency Cepstral Coefficients) features from the audio\ndomain also provide a significant boost in performance, while information from\ntranscripts is not very beneficial for our system. Using various classifiers,\nour automated system obtains an AUC of 0.877 (10-fold cross-validation) when\nevaluated on subjects which were not part of the training set. Even though\nstate-of-the-art methods use human annotations of micro-expressions for\ndeception detection, our fully automated approach outperforms them by 5%. When\ncombined with human annotations of micro-expressions, our AUC improves to\n0.922. We also present results of a user-study to analyze how well do average\nhumans perform on this task, what modalities they use for deception detection\nand how they perform if only one modality is accessible. Our project page can\nbe found at \\url{https://doubaibai.github.io/DARE/}.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 18:16:43 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Wu", "Zhe", ""], ["Singh", "Bharat", ""], ["Davis", "Larry S.", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "1712.04443", "submitter": "Bo Wu", "authors": "Bo Wu, Wen-Huang Cheng, Yongdong Zhang, Qiushi Huang, Jintao Li, Tao\n  Mei", "title": "Sequential Prediction of Social Media Popularity with Deep Temporal\n  Context Networks", "comments": "accepted in IJCAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of popularity has profound impact for social media, since it\noffers opportunities to reveal individual preference and public attention from\nevolutionary social systems. Previous research, although achieves promising\nresults, neglects one distinctive characteristic of social data, i.e.,\nsequentiality. For example, the popularity of online content is generated over\ntime with sequential post streams of social media. To investigate the\nsequential prediction of popularity, we propose a novel prediction framework\ncalled Deep Temporal Context Networks (DTCN) by incorporating both temporal\ncontext and temporal attention into account. Our DTCN contains three main\ncomponents, from embedding, learning to predicting. With a joint embedding\nnetwork, we obtain a unified deep representation of multi-modal user-post data\nin a common embedding space. Then, based on the embedded data sequence over\ntime, temporal context learning attempts to recurrently learn two adaptive\ntemporal contexts for sequential popularity. Finally, a novel temporal\nattention is designed to predict new popularity (the popularity of a new\nuser-post pair) with temporal coherence across multiple time-scales.\nExperiments on our released image dataset with about 600K Flickr photos\ndemonstrate that DTCN outperforms state-of-the-art deep prediction algorithms,\nwith an average of 21.51% relative performance improvement in the popularity\nprediction (Spearman Ranking Correlation).\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 05:28:12 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Wu", "Bo", ""], ["Cheng", "Wen-Huang", ""], ["Zhang", "Yongdong", ""], ["Huang", "Qiushi", ""], ["Li", "Jintao", ""], ["Mei", "Tao", ""]]}, {"id": "1712.04596", "submitter": "Son-Il Kwak", "authors": "Son-Il Kwak, Oh-Chol Gwon, Chung-Jin Kwak", "title": "Consideration on Example 2 of \"An Algorithm of General Fuzzy\n  InferenceWith The Reductive Property\"", "comments": "6 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will show that (1) the results about the fuzzy reasoning\nalgoritm obtained in the paper \"Computer Sciences Vol. 34, No.4, pp.145-148,\n2007\" according to the paper \"IEEE Transactions On systems, Man and\ncybernetics, 18, pp.1049-1056, 1988\" are correct; (2) example 2 in the paper\n\"An Algorithm of General Fuzzy Inference With The Reductive Property\" presented\nby He Ying-Si, Quan Hai-Jin and Deng Hui-Wen according to the paper \"An\napproximate analogical reasoning approach based on similarity measures\"\npresented by Tursken I.B. and Zhong zhao is incorrect; (3) the mistakes in\ntheir paper are modified and then a calculation example of FMT is supplemented.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 03:13:25 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Kwak", "Son-Il", ""], ["Gwon", "Oh-Chol", ""], ["Kwak", "Chung-Jin", ""]]}, {"id": "1712.04603", "submitter": "Jinyoung Choi", "authors": "Jinyoung Choi, Beom-Jin Lee, and Byoung-Tak Zhang", "title": "Multi-focus Attention Network for Efficient Deep Reinforcement Learning", "comments": "AAAI 2017 Workshop on What's next for AI in games (WNAIG 2017), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has shown incredible performance in\nlearning various tasks to the human level. However, unlike human perception,\ncurrent DRL models connect the entire low-level sensory input to the\nstate-action values rather than exploiting the relationship between and among\nentities that constitute the sensory input. Because of this difference, DRL\nneeds vast amount of experience samples to learn. In this paper, we propose a\nMulti-focus Attention Network (MANet) which mimics human ability to spatially\nabstract the low-level sensory input into multiple entities and attend to them\nsimultaneously. The proposed method first divides the low-level input into\nseveral segments which we refer to as partial states. After this segmentation,\nparallel attention layers attend to the partial states relevant to solving the\ntask. Our model estimates state-action values using these attended partial\nstates. In our experiments, MANet attains highest scores with significantly\nless experience samples. Additionally, the model shows higher performance\ncompared to the Deep Q-network and the single attention model as benchmarks.\nFurthermore, we extend our model to attentive communication model for\nperforming multi-agent cooperative tasks. In multi-agent cooperative task\nexperiments, our model shows 20% faster learning than existing state-of-the-art\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 04:04:29 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Choi", "Jinyoung", ""], ["Lee", "Beom-Jin", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1712.04612", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "Inverse Reinforcement Learning for Marketing", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning customer preferences from an observed behaviour is an important\ntopic in the marketing literature. Structural models typically model\nforward-looking customers or firms as utility-maximizing agents whose utility\nis estimated using methods of Stochastic Optimal Control. We suggest an\nalternative approach to study dynamic consumer demand, based on Inverse\nReinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL\nthat leads to a highly tractable model formulation that amounts to\nlow-dimensional convex optimization in the search for optimal model parameters.\nUsing simulations of consumer demand, we show that observational noise for\nidentical customers can be easily confused with an apparent consumer\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 05:46:22 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1712.04909", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Reasoning in Systems with Elements that Randomly Switch Characteristics", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the issue of stability of probability in reasoning about complex\nsystems with uncertainty in structure. Normally, propositions are viewed as\nprobability functions on an abstract random graph where it is implicitly\nassumed that the nodes of the graph have stable properties. But what if some of\nthe nodes change their characteristics? This is a situation that cannot be\ncovered by abstractions of either static or dynamic sets when these changes\ntake place at regular intervals. We propose the use of sets with elements that\nchange, and modular forms are proposed to account for one type of such change.\nAn expression for the dependence of the mean on the probability of the\nswitching elements has been determined. The system is also analyzed from the\nperspective of decision between different hypotheses. Such sets are likely to\nbe of use in complex system queries and in analysis of surveys.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 18:25:20 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1712.05087", "submitter": "Yi-Hsuan Tsai", "authors": "Yi-Hsuan Tsai, Ming-Yu Liu, Deqing Sun, Ming-Hsuan Yang, Jan Kautz", "title": "Learning Binary Residual Representations for Domain-specific Video\n  Streaming", "comments": "Accepted in AAAI'18. Project website at\n  https://research.nvidia.com/publication/2018-02_Learning-Binary-Residual", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study domain-specific video streaming. Specifically, we target a streaming\nsetting where the videos to be streamed from a server to a client are all in\nthe same domain and they have to be compressed to a small size for low-latency\ntransmission. Several popular video streaming services, such as the video game\nstreaming services of GeForce Now and Twitch, fall in this category. While\nconventional video compression standards such as H.264 are commonly used for\nthis task, we hypothesize that one can leverage the property that the videos\nare all in the same domain to achieve better video quality. Based on this\nhypothesis, we propose a novel video compression pipeline. Specifically, we\nfirst apply H.264 to compress domain-specific videos. We then train a novel\nbinary autoencoder to encode the leftover domain-specific residual information\nframe-by-frame into binary representations. These binary representations are\nthen compressed and sent to the client together with the H.264 stream. In our\nexperiments, we show that our pipeline yields consistent gains over standard\nH.264 compression across several benchmark datasets while using the same\nchannel bandwidth.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 04:06:33 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Tsai", "Yi-Hsuan", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Deqing", ""], ["Yang", "Ming-Hsuan", ""], ["Kautz", "Jan", ""]]}, {"id": "1712.05181", "submitter": "Nick Pawlowski", "authors": "Tom Bocklisch, Joey Faulkner, Nick Pawlowski, Alan Nichol", "title": "Rasa: Open Source Language Understanding and Dialogue Management", "comments": "Presented at NIPS Workshop on Conversational AI, Code at\n  https://github.com/RasaHQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source\npython libraries for building conversational software. Their purpose is to make\nmachine-learning based dialogue management and language understanding\naccessible to non-specialist software developers. In terms of design\nphilosophy, we aim for ease of use, and bootstrapping from minimal (or no)\ninitial training data. Both packages are extensively documented and ship with a\ncomprehensive suite of tests. The code is available at\nhttps://github.com/RasaHQ/\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 11:37:18 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 09:33:11 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Bocklisch", "Tom", ""], ["Faulkner", "Joey", ""], ["Pawlowski", "Nick", ""], ["Nichol", "Alan", ""]]}, {"id": "1712.05191", "submitter": "Sachin Pawar", "authors": "Sachin Pawar, Girish K. Palshikar, Pushpak Bhattacharyya", "title": "Relation Extraction : A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the Internet, large amount of digital text is generated\neveryday in the form of news articles, research publications, blogs, question\nanswering forums and social media. It is important to develop techniques for\nextracting information automatically from these documents, as lot of important\ninformation is hidden within them. This extracted information can be used to\nimprove access and management of knowledge hidden in large text corpora.\nSeveral applications such as Question Answering, Information Retrieval would\nbenefit from this information. Entities like persons and organizations, form\nthe most basic unit of the information. Occurrences of entities in a sentence\nare often linked through well-defined relations; e.g., occurrences of person\nand organization in a sentence may be linked through relations such as employed\nat. The task of Relation Extraction (RE) is to identify such relations\nautomatically. In this paper, we survey several important supervised,\nsemi-supervised and unsupervised RE techniques. We also cover the paradigms of\nOpen Information Extraction (OIE) and Distant Supervision. Finally, we describe\nsome of the recent trends in the RE techniques and possible future research\ndirections. This survey would be useful for three kinds of readers - i)\nNewcomers in the field who want to quickly learn about RE; ii) Researchers who\nwant to know how the various RE techniques evolved over time and what are\npossible future research directions and iii) Practitioners who just need to\nknow which RE technique works best in various settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:04:10 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Pawar", "Sachin", ""], ["Palshikar", "Girish K.", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1712.05247", "submitter": "Matthew Piekenbrock", "authors": "Matthew Piekenbrock, Derek Doran", "title": "Intrinsic Point of Interest Discovery from Trajectory Data", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for intrinsic point of interest discovery\nfrom trajectory databases. Intrinsic points of interest are regions of a\ngeospatial area innately defined by the spatial and temporal aspects of\ntrajectory data, and can be of varying size, shape, and resolution. Any\ntrajectory database exhibits such points of interest, and hence are intrinsic,\nas compared to most other point of interest definitions which are said to be\nextrinsic, as they require trajectory metadata, external knowledge about the\nregion the trajectories are observed, or other application-specific\ninformation. Spatial and temporal aspects are qualities of any trajectory\ndatabase, making the framework applicable to data from any domain and of any\nresolution. The framework is developed under recent developments on the\nconsistency of nonparametric hierarchical density estimators and enables the\npossibility of formal statistical inference and evaluation over such intrinsic\npoints of interest. Comparisons of the POIs uncovered by the framework in\nsynthetic truth data to thousands of parameter settings for common POI\ndiscovery methods show a marked improvement in fidelity without the need to\ntune any parameters by hand.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:26:39 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Piekenbrock", "Matthew", ""], ["Doran", "Derek", ""]]}, {"id": "1712.05249", "submitter": "Pierre-Yves Oudeyer", "authors": "Freek Stulp and Pierre-Yves Oudeyer", "title": "Proximodistal Exploration in Motor Learning as an Emergent Property of\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness the complexity of their high-dimensional bodies during\nsensorimotor development, infants are guided by patterns of freezing and\nfreeing of degrees of freedom. For instance, when learning to reach, infants\nfree the degrees of freedom in their arm proximodistally, i.e. from joints that\nare closer to the body to those that are more distant. Here, we formulate and\nstudy computationally the hypothesis that such patterns can emerge\nspontaneously as the result of a family of stochastic optimization processes\n(evolution strategies with covariance-matrix adaptation), without an innate\nencoding of a maturational schedule. In particular, we present simulated\nexperiments with an arm where a computational learner progressively acquires\nreaching skills through adaptive exploration, and we show that a proximodistal\norganization appears spontaneously, which we denote PDFF (ProximoDistal\nFreezing and Freeing of degrees of freedom). We also compare this emergent\norganization between different arm morphologies -- from human-like to quite\nunnatural ones -- to study the effect of different kinematic structures on the\nemergence of PDFF. Keywords: human motor learning; proximo-distal exploration;\nstochastic optimization; modelling; evolution strategies; cross-entropy\nmethods; policy search; morphology.}\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:31:51 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Stulp", "Freek", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1712.05291", "submitter": "Gianluca Brero", "authors": "Gianluca Brero and S\\'ebastien Lahaie", "title": "A Bayesian Clearing Mechanism for Combinatorial Auctions", "comments": "9 pages, 4 figures, AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cast the problem of combinatorial auction design in a Bayesian framework\nin order to incorporate prior information into the auction process and minimize\nthe number of rounds to convergence. We first develop a generative model of\nagent valuations and market prices such that clearing prices become maximum a\nposteriori estimates given observed agent valuations. This generative model\nthen forms the basis of an auction process which alternates between refining\nestimates of agent valuations and computing candidate clearing prices. We\nprovide an implementation of the auction using assumed density filtering to\nestimate valuations and expectation maximization to compute prices. An\nempirical evaluation over a range of valuation domains demonstrates that our\nBayesian auction mechanism is highly competitive against the combinatorial\nclock auction in terms of rounds to convergence, even under the most favorable\nchoices of price increment for this baseline.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 15:34:42 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 16:38:03 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Brero", "Gianluca", ""], ["Lahaie", "S\u00e9bastien", ""]]}, {"id": "1712.05302", "submitter": "Damla Kizilay", "authors": "Damla Kizilay, Deniz T. Eliiyi, Pascal Van Hentenryck", "title": "Constraint and Mathematical Programming Models for Integrated Port\n  Container Terminal Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the integrated problem of quay crane assignment, quay\ncrane scheduling, yard location assignment, and vehicle dispatching operations\nat a container terminal. The main objective is to minimize vessel turnover\ntimes and maximize the terminal throughput, which are key economic drivers in\nterminal operations. Due to their computational complexities, these problems\nare not optimized jointly in existing work. This paper revisits this limitation\nand proposes Mixed Integer Programming (MIP) and Constraint Programming (CP)\nmodels for the integrated problem, under some realistic assumptions.\nExperimental results show that the MIP formulation can only solve small\ninstances, while the CP model finds optimal solutions in reasonable times for\nrealistic instances derived from actual container terminal operations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 15:56:46 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Kizilay", "Damla", ""], ["Eliiyi", "Deniz T.", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1712.05403", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "Learning to Attend via Word-Aspect Associative Fusion for Aspect-based\n  Sentiment Analysis", "comments": "Accepted to AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a\ngiven document with respect to a given aspect entity. While neural network\narchitectures have been successful in predicting the overall polarity of\nsentences, aspect-specific sentiment analysis still remains as an open problem.\nIn this paper, we propose a novel method for integrating aspect information\ninto the neural model. More specifically, we incorporate aspect information\ninto the neural model by modeling word-aspect relationships. Our novel model,\n\\textit{Aspect Fusion LSTM} (AF-LSTM) learns to attend based on associative\nrelationships between sentence words and aspect which allows our model to\nadaptively focus on the correct words given an aspect term. This ameliorates\nthe flaws of other state-of-the-art models that utilize naive concatenations to\nmodel word-aspect similarity. Instead, our model adopts circular convolution\nand circular correlation to model the similarity between aspect and words and\nelegantly incorporates this within a differentiable neural attention framework.\nFinally, our model is end-to-end differentiable and highly related to\nconvolution-correlation (holographic like) memories. Our proposed neural model\nachieves state-of-the-art performance on benchmark datasets, outperforming\nATAE-LSTM by $4\\%-5\\%$ on average across multiple datasets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:46:44 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1712.05474", "submitter": "Roozbeh Mottaghi", "authors": "Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs,\n  Alvaro Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, Ali Farhadi", "title": "AI2-THOR: An Interactive 3D Environment for Visual AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce The House Of inteRactions (THOR), a framework for visual AI\nresearch, available at http://ai2thor.allenai.org. AI2-THOR consists of near\nphoto-realistic 3D indoor scenes, where AI agents can navigate in the scenes\nand interact with objects to perform tasks. AI2-THOR enables research in many\ndifferent domains including but not limited to deep reinforcement learning,\nimitation learning, learning by interaction, planning, visual question\nanswering, unsupervised representation learning, object detection and\nsegmentation, and learning models of cognition. The goal of AI2-THOR is to\nfacilitate building visually intelligent models and push the research forward\nin this domain.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 23:17:24 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 23:45:48 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 18:29:15 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kolve", "Eric", ""], ["Mottaghi", "Roozbeh", ""], ["Han", "Winson", ""], ["VanderBilt", "Eli", ""], ["Weihs", "Luca", ""], ["Herrasti", "Alvaro", ""], ["Gordon", "Daniel", ""], ["Zhu", "Yuke", ""], ["Gupta", "Abhinav", ""], ["Farhadi", "Ali", ""]]}, {"id": "1712.05497", "submitter": "Ashwin Khadke", "authors": "Ashwin Khadke and Manuela Veloso", "title": "What Can This Robot Do? Learning from Appearance and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When presented with an unknown robot (subject) how can an autonomous agent\n(learner) figure out what this new robot can do? The subject's appearance can\nprovide cues to its physical as well as cognitive capabilities. Seeing a\nhumanoid can make one wonder if it can kick balls, climb stairs or recognize\nfaces. What if the learner can request the subject to perform these tasks? We\npresent an approach to make the learner build a model of the subject at a task\nbased on the latter's appearance and refine it by experimentation. Apart from\nthe subject's inherent capabilities, certain extrinsic factors may affect its\nperformance at a task. Based on the subject's appearance and prior knowledge\nabout the task a learner can identify a set of potential factors, a subset of\nwhich we assume are controllable. Our approach picks values of controllable\nfactors to generate the most informative experiments to test the subject at.\nAdditionally, we present a metric to determine if a factor should be\nincorporated in the model. We present results of our approach on modeling a\nhumanoid robot at the task of kicking a ball. Firstly, we show that actively\npicking values for controllable factors, even in noisy experiments, leads to\nfaster learning of the subject's model for the task. Secondly, starting from a\nminimal set of factors our metric identifies the set of relevant factors to\nincorporate in the model. Lastly, we show that the refined model better\nrepresents the subject's performance at the task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 01:20:51 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 18:47:34 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Khadke", "Ashwin", ""], ["Veloso", "Manuela", ""]]}, {"id": "1712.05514", "submitter": "Siddharthan Perundurai Rajaskaran", "authors": "Siddharthan Rajasekaran, Jinwei Zhang, and Jie Fu", "title": "Inverse Reinforce Learning with Nonparametric Behavior Clustering", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse Reinforcement Learning (IRL) is the task of learning a single reward\nfunction given a Markov Decision Process (MDP) without defining the reward\nfunction, and a set of demonstrations generated by humans/experts. However, in\npractice, it may be unreasonable to assume that human behaviors can be\nexplained by one reward function since they may be inherently inconsistent.\nAlso, demonstrations may be collected from various users and aggregated to\ninfer and predict user's behaviors. In this paper, we introduce the\nNon-parametric Behavior Clustering IRL algorithm to simultaneously cluster\ndemonstrations and learn multiple reward functions from demonstrations that may\nbe generated from more than one behaviors. Our method is iterative: It\nalternates between clustering demonstrations into different behavior clusters\nand inverse learning the reward functions until convergence. It is built upon\nthe Expectation-Maximization formulation and non-parametric clustering in the\nIRL setting. Further, to improve the computation efficiency, we remove the need\nof completely solving multiple IRL problems for multiple clusters during the\niteration steps and introduce a resampling technique to avoid generating too\nmany unlikely clusters. We demonstrate the convergence and efficiency of the\nproposed method through learning multiple driver behaviors from demonstrations\ngenerated from a grid-world environment and continuous trajectories collected\nfrom autonomous robot cars using the Gazebo robot simulator.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 03:13:23 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Rajasekaran", "Siddharthan", ""], ["Zhang", "Jinwei", ""], ["Fu", "Jie", ""]]}, {"id": "1712.05558", "submitter": "Nikita Kitaev", "authors": "Jin-Hwa Kim, Nikita Kitaev, Xinlei Chen, Marcus Rohrbach, Byoung-Tak\n  Zhang, Yuandong Tian, Dhruv Batra, Devi Parikh", "title": "CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven\n  Communication", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a goal-driven collaborative task that combines\nlanguage, perception, and action. Specifically, we develop a Collaborative\nimage-Drawing game between two agents, called CoDraw. Our game is grounded in a\nvirtual world that contains movable clip art objects. The game involves two\nplayers: a Teller and a Drawer. The Teller sees an abstract scene containing\nmultiple clip art pieces in a semantically meaningful configuration, while the\nDrawer tries to reconstruct the scene on an empty canvas using available clip\nart pieces. The two players communicate with each other using natural language.\nWe collect the CoDraw dataset of ~10K dialogs consisting of ~138K messages\nexchanged between human players. We define protocols and metrics to evaluate\nlearned agents in this testbed, highlighting the need for a novel \"crosstalk\"\nevaluation condition which pairs agents trained independently on disjoint\nsubsets of the training data. We present models for our task and benchmark them\nusing both fully automated evaluation and by having them play the game live\nwith humans.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 06:38:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 08:00:14 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:01:42 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Kitaev", "Nikita", ""], ["Chen", "Xinlei", ""], ["Rohrbach", "Marcus", ""], ["Zhang", "Byoung-Tak", ""], ["Tian", "Yuandong", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1712.05695", "submitter": "Altaf Khan", "authors": "Altaf H. Khan", "title": "Lightweight Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the weights in a Lightweight Neural Network have a value of zero,\nwhile the remaining ones are either +1 or -1. These universal approximators\nrequire approximately 1.1 bits/weight of storage, posses a quick forward pass\nand achieve classification accuracies similar to conventional continuous-weight\nnetworks. Their training regimen focuses on error reduction initially, but\nlater emphasizes discretization of weights. They ignore insignificant inputs,\nremove unnecessary weights, and drop unneeded hidden neurons. We have\nsuccessfully tested them on the MNIST, credit card fraud, and credit card\ndefaults data sets using networks having 2 to 16 hidden layers and up to 4.4\nmillion weights.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:56:05 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Khan", "Altaf H.", ""]]}, {"id": "1712.05734", "submitter": "Vyacheslav Yukalov", "authors": "V.I. Yukalov, E.P. Yukalova, and D. Sornette", "title": "Information Processing by Networks of Quantum Decision Makers", "comments": null, "journal-ref": "Physica A 492 (2018) 747-766", "doi": "10.1016/j.physa.2017.11.004", "report-no": null, "categories": "physics.soc-ph cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a model of a multi-agent society of decision makers taking\ndecisions being based on two criteria, one is the utility of the prospects and\nthe other is the attractiveness of the considered prospects. The model is the\ngeneralization of quantum decision theory, developed earlier for single\ndecision makers realizing one-step decisions, in two principal aspects. First,\nseveral decision makers are considered simultaneously, who interact with each\nother through information exchange. Second, a multistep procedure is treated,\nwhen the agents exchange information many times. Several decision makers\nexchanging information and forming their judgement, using quantum rules, form a\nkind of a quantum information network, where collective decisions develop in\ntime as a result of information exchange. In addition to characterizing\ncollective decisions that arise in human societies, such networks can describe\ndynamical processes occurring in artificial quantum intelligence composed of\nseveral parts or in a cluster of quantum computers. The practical usage of the\ntheory is illustrated on the dynamic disjunction effect for which three\nquantitative predictions are made: (i) the probabilistic behavior of decision\nmakers at the initial stage of the process is described; (ii) the decrease of\nthe difference between the initial prospect probabilities and the related\nutility factors is proved; (iii) the existence of a common consensus after\nmultiple exchange of information is predicted. The predicted numerical values\nare in very good agreement with empirical data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:22:38 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Yukalov", "V. I.", ""], ["Yukalova", "E. P.", ""], ["Sornette", "D.", ""]]}, {"id": "1712.05785", "submitter": "Xingyou Song", "authors": "Jordan Prosky, Xingyou Song, Andrew Tan, Michael Zhao", "title": "Sentiment Predictability for Stocks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present our findings and experiments for stock-market\nprediction using various textual sentiment analysis tools, such as mood\nanalysis and event extraction, as well as prediction models, such as LSTMs and\nspecific convolutional architectures.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 18:41:53 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 20:24:40 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Prosky", "Jordan", ""], ["Song", "Xingyou", ""], ["Tan", "Andrew", ""], ["Zhao", "Michael", ""]]}, {"id": "1712.05812", "submitter": "Stuart Armstrong", "authors": "Stuart Armstrong and S\\\"oren Mindermann", "title": "Occam's razor is insufficient to infer the preferences of irrational\n  agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) attempts to infer human rewards or\npreferences from observed behavior. Since human planning systematically\ndeviates from rationality, several approaches have been tried to account for\nspecific human shortcomings. However, the general problem of inferring the\nreward function of an agent of unknown rationality has received little\nattention. Unlike the well-known ambiguity problems in IRL, this one is\npractically relevant but cannot be resolved by observing the agent's policy in\nenough environments. This paper shows (1) that a No Free Lunch result implies\nit is impossible to uniquely decompose a policy into a planning algorithm and\nreward function, and (2) that even with a reasonable simplicity prior/Occam's\nrazor on the set of decompositions, we cannot distinguish between the true\ndecomposition and others that lead to high regret. To address this, we need\nsimple `normative' assumptions, which cannot be deduced exclusively from\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 19:05:01 GMT"}, {"version": "v2", "created": "Sat, 30 Dec 2017 07:35:59 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 15:48:35 GMT"}, {"version": "v4", "created": "Thu, 6 Sep 2018 16:36:54 GMT"}, {"version": "v5", "created": "Mon, 29 Oct 2018 15:39:38 GMT"}, {"version": "v6", "created": "Fri, 11 Jan 2019 14:36:40 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Armstrong", "Stuart", ""], ["Mindermann", "S\u00f6ren", ""]]}, {"id": "1712.05855", "submitter": "Joseph Gonzalez", "authors": "Ion Stoica, Dawn Song, Raluca Ada Popa, David Patterson, Michael W.\n  Mahoney, Randy Katz, Anthony D. Joseph, Michael Jordan, Joseph M.\n  Hellerstein, Joseph E. Gonzalez, Ken Goldberg, Ali Ghodsi, David Culler,\n  Pieter Abbeel", "title": "A Berkeley View of Systems Challenges for AI", "comments": "Berkeley Technical Report", "journal-ref": null, "doi": null, "report-no": "EECS-2017-159", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing commoditization of computer vision, speech recognition\nand machine translation systems and the widespread deployment of learning-based\nback-end technologies such as digital advertising and intelligent\ninfrastructures, AI (Artificial Intelligence) has moved from research labs to\nproduction. These changes have been made possible by unprecedented levels of\ndata and computation, by methodological advances in machine learning, by\ninnovations in systems software and architectures, and by the broad\naccessibility of these technologies.\n  The next generation of AI systems promises to accelerate these developments\nand increasingly impact our lives via frequent interactions and making (often\nmission-critical) decisions on our behalf, often in highly personalized\ncontexts. Realizing this promise, however, raises daunting challenges. In\nparticular, we need AI systems that make timely and safe decisions in\nunpredictable environments, that are robust against sophisticated adversaries,\nand that can process ever increasing amounts of data across organizations and\nindividuals without compromising confidentiality. These challenges will be\nexacerbated by the end of the Moore's Law, which will constrain the amount of\ndata these technologies can store and process. In this paper, we propose\nseveral open research directions in systems, architectures, and security that\ncan address these challenges and help unlock AI's potential to improve lives\nand society.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 22:01:52 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Stoica", "Ion", ""], ["Song", "Dawn", ""], ["Popa", "Raluca Ada", ""], ["Patterson", "David", ""], ["Mahoney", "Michael W.", ""], ["Katz", "Randy", ""], ["Joseph", "Anthony D.", ""], ["Jordan", "Michael", ""], ["Hellerstein", "Joseph M.", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""], ["Ghodsi", "Ali", ""], ["Culler", "David", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1712.05881", "submitter": "Zahra Mahoor", "authors": "Zahra Mahoor, Jack Felag, Josh Bongard", "title": "Morphology dictates a robot's ability to ground crowd-proposed language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more robots act in physical proximity to people, it is essential to ensure\nthey make decisions and execute actions that align with human values. To do so,\nrobots need to understand the true intentions behind human-issued commands. In\nthis paper, we define a safe robot as one that receives a natural-language\ncommand from humans, considers an action in response to that command, and\naccurately predicts how humans will judge that action if is executed in\nreality. Our contribution is two-fold: First, we introduce a web platform for\nhuman users to propose commands to simulated robots. The robots receive\ncommands and act based on those proposed commands, and then the users provide\npositive and/or negative reinforcement. Next, we train a critic for each robot\nto predict the crowd's responses to one of the crowd-proposed commands. Second,\nwe show that the morphology of a robot plays a role in the way it grounds\nlanguage: The critics show that two of the robots used in the experiment\nachieve a lower prediction error than the others. Thus, those two robots are\nsafer, according to our definition, since they ground the proposed command more\naccurately.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 00:31:36 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 22:36:04 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Mahoor", "Zahra", ""], ["Felag", "Jack", ""], ["Bongard", "Josh", ""]]}, {"id": "1712.05889", "submitter": "Robert Nishihara", "authors": "Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov,\n  Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael\n  I. Jordan, Ion Stoica", "title": "Ray: A Distributed Framework for Emerging AI Applications", "comments": "17 pages, 14 figures, 13th USENIX Symposium on Operating Systems\n  Design and Implementation, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of AI applications will continuously interact with the\nenvironment and learn from these interactions. These applications impose new\nand demanding systems requirements, both in terms of performance and\nflexibility. In this paper, we consider these requirements and present Ray---a\ndistributed system to address them. Ray implements a unified interface that can\nexpress both task-parallel and actor-based computations, supported by a single\ndynamic execution engine. To meet the performance requirements, Ray employs a\ndistributed scheduler and a distributed and fault-tolerant store to manage the\nsystem's control state. In our experiments, we demonstrate scaling beyond 1.8\nmillion tasks per second and better performance than existing specialized\nsystems for several challenging reinforcement learning applications.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 01:29:49 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 03:14:16 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Wang", "Stephanie", ""], ["Tumanov", "Alexey", ""], ["Liaw", "Richard", ""], ["Liang", "Eric", ""], ["Elibol", "Melih", ""], ["Yang", "Zongheng", ""], ["Paul", "William", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1712.06015", "submitter": "Mu Qiao", "authors": "Mu Qiao, Luis Bathen, Simon-Pierre G\\'enot, Sunhwan Lee, Ramani\n  Routray", "title": "StackInsights: Cognitive Learning for Hybrid Cloud Readiness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid cloud is an integrated cloud computing environment utilizing a mix of\npublic cloud, private cloud, and on-premise traditional IT infrastructures.\nWorkload awareness, defined as a detailed full range understanding of each\nindividual workload, is essential in implementing the hybrid cloud. While it is\ncritical to perform an accurate analysis to determine which workloads are\nappropriate for on-premise deployment versus which workloads can be migrated to\na cloud off-premise, the assessment is mainly performed by rule or policy based\napproaches. In this paper, we introduce StackInsights, a novel cognitive system\nto automatically analyze and predict the cloud readiness of workloads for an\nenterprise. Our system harnesses the critical metrics across the entire stack:\n1) infrastructure metrics, 2) data relevance metrics, and 3) application\ntaxonomy, to identify workloads that have characteristics of a) low sensitivity\nwith respect to business security, criticality and compliance, and b) low\nresponse time requirements and access patterns. Since the capture of the data\nrelevance metrics involves an intrusive and in-depth scanning of the content of\nstorage objects, a machine learning model is applied to perform the business\nrelevance classification by learning from the meta level metrics harnessed\nacross stack. In contrast to traditional methods, StackInsights significantly\nreduces the total time for hybrid cloud readiness assessment by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 20:14:53 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Qiao", "Mu", ""], ["Bathen", "Luis", ""], ["G\u00e9not", "Simon-Pierre", ""], ["Lee", "Sunhwan", ""], ["Routray", "Ramani", ""]]}, {"id": "1712.06028", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura, Jayaraman J. Thiagarajan, Charvi Rastogi, Pramod K.\n  Varshney, Peer-Timo Bremer", "title": "A Spectral Approach for the Design of Experiments: Design, Analysis and\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new approach to construct high quality space-filling\nsample designs. First, we propose a novel technique to quantify the\nspace-filling property and optimally trade-off uniformity and randomness in\nsample designs in arbitrary dimensions. Second, we connect the proposed metric\n(defined in the spatial domain) to the objective measure of the design\nperformance (defined in the spectral domain). This connection serves as an\nanalytic framework for evaluating the qualitative properties of space-filling\ndesigns in general. Using the theoretical insights provided by this\nspatial-spectral analysis, we derive the notion of optimal space-filling\ndesigns, which we refer to as space-filling spectral designs. Third, we propose\nan efficient estimator to evaluate the space-filling properties of sample\ndesigns in arbitrary dimensions and use it to develop an optimization framework\nto generate high quality space-filling designs. Finally, we carry out a\ndetailed performance comparison on two different applications in 2 to 6\ndimensions: a) image reconstruction and b) surrogate modeling on several\nbenchmark optimization functions and an inertial confinement fusion (ICF)\nsimulation code. We demonstrate that the propose spectral designs significantly\noutperform existing approaches especially in high dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 22:31:52 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Rastogi", "Charvi", ""], ["Varshney", "Pramod K.", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1712.06096", "submitter": "Jong Chul Ye", "authors": "Yeo Hun Yoon, Shujaat Khan, Jaeyoung Huh, and Jong Chul Ye", "title": "Efficient B-mode Ultrasound Image Reconstruction from Sub-sampled RF\n  Data using Deep Learning", "comments": "The title has been changed. This version will appear in IEEE Trans.\n  on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In portable, three dimensional, and ultra-fast ultrasound imaging systems,\nthere is an increasing demand for the reconstruction of high quality images\nfrom a limited number of radio-frequency (RF) measurements due to receiver (Rx)\nor transmit (Xmit) event sub-sampling. However, due to the presence of side\nlobe artifacts from RF sub-sampling, the standard beamformer often produces\nblurry images with less contrast, which are unsuitable for diagnostic purposes.\nExisting compressed sensing approaches often require either hardware changes or\ncomputationally expensive algorithms, but their quality improvements are\nlimited. To address this problem, here we propose a novel deep learning\napproach that directly interpolates the missing RF data by utilizing redundancy\nin the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF\ndata from a multi-line acquisition B-mode system confirm that the proposed\nmethod can effectively reduce the data rate without sacrificing image quality.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 12:15:08 GMT"}, {"version": "v2", "created": "Thu, 21 Dec 2017 03:58:18 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 09:19:13 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Yoon", "Yeo Hun", ""], ["Khan", "Shujaat", ""], ["Huh", "Jaeyoung", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.06180", "submitter": "Per-Arne Andersen", "authors": "Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo", "title": "Towards a Deep Reinforcement Learning Approach for Tower Line Wars", "comments": "Proceedings of the 37th SGAI International Conference on Artificial\n  Intelligence, Cambridge, UK, 2017, Artificial Intelligence XXXIV, 2017", "journal-ref": null, "doi": "10.1007/978-3-319-71078-5", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been numerous breakthroughs with reinforcement learning in the\nrecent years, perhaps most notably on Deep Reinforcement Learning successfully\nplaying and winning relatively advanced computer games. There is undoubtedly an\nanticipation that Deep Reinforcement Learning will play a major role when the\nfirst AI masters the complicated game plays needed to beat a professional\nReal-Time Strategy game player. For this to be possible, there needs to be a\ngame environment that targets and fosters AI research, and specifically Deep\nReinforcement Learning. Some game environments already exist, however, these\nare either overly simplistic such as Atari 2600 or complex such as Starcraft II\nfrom Blizzard Entertainment. We propose a game environment in between Atari\n2600 and Starcraft II, particularly targeting Deep Reinforcement Learning\nalgorithm research. The environment is a variant of Tower Line Wars from\nWarcraft III, Blizzard Entertainment. Further, as a proof of concept that the\nenvironment can harbor Deep Reinforcement algorithms, we propose and apply a\nDeep Q-Reinforcement architecture. The architecture simplifies the state space\nso that it is applicable to Q-learning, and in turn improves performance\ncompared to current state-of-the-art methods. Our experiments show that the\nproposed architecture can learn to play the environment well, and score 33%\nbetter than standard Deep Q-learning which in turn proves the usefulness of the\ngame environment.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 21:29:45 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1712.06228", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Byoung-Tak Zhang", "title": "Visual Explanations from Hadamard Product in Multimodal Deep Networks", "comments": "8 pages, 5 figures, including appendix, NIPS 2017 Workshop on\n  Visually-Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visual explanation of learned representation of models helps to\nunderstand the fundamentals of learning. The attentional models of previous\nworks used to visualize the attended regions over an image or text using their\nlearned weights to confirm their intended mechanism. Kim et al. (2016) show\nthat the Hadamard product in multimodal deep networks, which is well-known for\nthe joint function of visual question answering tasks, implicitly performs an\nattentional mechanism for visual inputs. In this work, we extend their work to\nshow that the Hadamard product in multimodal deep networks performs not only\nfor visual inputs but also for textual inputs simultaneously using the proposed\ngradient-based visualization technique. The attentional effect of Hadamard\nproduct is visualized for both visual and textual inputs by analyzing the two\ninputs and an output of the Hadamard product with the proposed method and\ncompared with learned attentional weights of a visual question answering model.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 02:37:20 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1712.06272", "submitter": "Sakyasingha Dasgupta", "authors": "Farhan Shafiq, Takato Yamada, Antonio T. Vilchez, and Sakyasingha\n  Dasgupta", "title": "Automated flow for compressing convolution neural networks for efficient\n  edge-computation with FPGA", "comments": "7 pages, 9 figures. Accepted and presented at MLPCD workshop, NIPS\n  2017 (LongBeach, California)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) based solutions are the current\nstate- of-the-art for computer vision tasks. Due to the large size of these\nmodels, they are typically run on clusters of CPUs or GPUs. However, power\nrequirements and cost budgets can be a major hindrance in adoption of CNN for\nIoT applications. Recent research highlights that CNN contain significant\nredundancy in their structure and can be quantized to lower bit-width\nparameters and activations, while maintaining acceptable accuracy. Low\nbit-width and especially single bit-width (binary) CNN are particularly\nsuitable for mobile applications based on FPGA implementation, due to the\nbitwise logic operations involved in binarized CNN. Moreover, the transition to\nlower bit-widths opens new avenues for performance optimizations and model\nimprovement. In this paper, we present an automatic flow from trained\nTensorFlow models to FPGA system on chip implementation of binarized CNN. This\nflow involves quantization of model parameters and activations, generation of\nnetwork and model in embedded-C, followed by automatic generation of the FPGA\naccelerator for binary convolutions. The automated flow is demonstrated through\nimplementation of binarized \"YOLOV2\" on the low cost, low power Cyclone- V FPGA\ndevice. Experiments on object detection using binarized YOLOV2 demonstrate\nsignificant performance benefit in terms of model size and inference speed on\nFPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire\nautomated flow from trained models to FPGA synthesis can be completed within\none hour.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 07:02:07 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Shafiq", "Farhan", ""], ["Yamada", "Takato", ""], ["Vilchez", "Antonio T.", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1712.06365", "submitter": "Stuart Armstrong", "authors": "Stuart Armstrong, Xavier O'Rourke", "title": "'Indifference' methods for managing agent rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `Indifference' refers to a class of methods used to control reward based\nagents. Indifference techniques aim to achieve one or more of three distinct\ngoals: rewards dependent on certain events (without the agent being motivated\nto manipulate the probability of those events), effective disbelief (where\nagents behave as if particular events could never happen), and seamless\ntransition from one reward function to another (with the agent acting as if\nthis change is unanticipated). This paper presents several methods for\nachieving these goals in the POMDP setting, establishing their uses, strengths,\nand requirements. These methods of control work even when the implications of\nthe agent's reward are otherwise not fully understood.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 12:28:45 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 13:32:08 GMT"}, {"version": "v3", "created": "Mon, 26 Feb 2018 11:00:29 GMT"}, {"version": "v4", "created": "Tue, 5 Jun 2018 11:10:23 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Armstrong", "Stuart", ""], ["O'Rourke", "Xavier", ""]]}, {"id": "1712.06440", "submitter": "Liu Feng", "authors": "Feng Liu, Yong Shi, Ying Liu", "title": "Three IQs of AI Systems and their Testing Methods", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of artificial intelligence has brought the artificial\nintelligence threat theory as well as the problem about how to evaluate the\nintelligence level of intelligent products. Both need to find a quantitative\nmethod to evaluate the intelligence level of intelligence systems, including\nhuman intelligence. Based on the standard intelligence system and the extended\nVon Neumann architecture, this paper proposes General IQ, Service IQ and Value\nIQ evaluation methods for intelligence systems, depending on different\nevaluation purposes. Among them, the General IQ of intelligence systems is to\nanswer the question of whether the artificial intelligence can surpass the\nhuman intelligence, which is reflected in putting the intelligence systems on\nan equal status and conducting the unified evaluation. The Service IQ and Value\nIQ of intelligence systems are used to answer the question of how the\nintelligent products can better serve the human, reflecting the intelligence\nand required cost of each intelligence system as a product in the process of\nserving human.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 17:49:04 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Liu", "Feng", ""], ["Shi", "Yong", ""], ["Liu", "Ying", ""]]}, {"id": "1712.06536", "submitter": "Erik Bodin", "authors": "Erik Bodin, Iman Malik, Carl Henrik Ek, Neill D. F. Campbell", "title": "Nonparametric Inference for Auto-Encoding Variational Bayes", "comments": "Presented at NIPS 2017 Workshop on Advances in Approximate Bayesian\n  Inference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We would like to learn latent representations that are low-dimensional and\nhighly interpretable. A model that has these characteristics is the Gaussian\nProcess Latent Variable Model. The benefits and negative of the GP-LVM are\ncomplementary to the Variational Autoencoder, the former provides interpretable\nlow-dimensional latent representations while the latter is able to handle large\namounts of data and can use non-Gaussian likelihoods. Our inspiration for this\npaper is to marry these two approaches and reap the benefits of both. In order\nto do so we will introduce a novel approximate inference scheme inspired by the\nGP-LVM and the VAE. We show experimentally that the approximation allows the\ncapacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large\nwithout losing a highly interpretable representation, allowing reconstruction\nquality to be unlimited by Z at the same time as a low-dimensional space can be\nused to perform ancestral sampling from as well as a means to reason about the\nembedded data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:22:41 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Bodin", "Erik", ""], ["Malik", "Iman", ""], ["Ek", "Carl Henrik", ""], ["Campbell", "Neill D. F.", ""]]}, {"id": "1712.06560", "submitter": "Jeff Clune", "authors": "Edoardo Conti, Vashisht Madhavan, Felipe Petroski Such, Joel Lehman,\n  Kenneth O. Stanley, Jeff Clune", "title": "Improving Exploration in Evolution Strategies for Deep Reinforcement\n  Learning via a Population of Novelty-Seeking Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution strategies (ES) are a family of black-box optimization algorithms\nable to train deep neural networks roughly as well as Q-learning and policy\ngradient methods on challenging deep reinforcement learning (RL) problems, but\nare much faster (e.g. hours vs. days) because they parallelize better. However,\nmany RL problems require directed exploration because they have reward\nfunctions that are sparse or deceptive (i.e. contain local optima), and it is\nunknown how to encourage such exploration with ES. Here we show that algorithms\nthat have been invented to promote directed exploration in small-scale evolved\nneural networks via populations of exploring agents, specifically novelty\nsearch (NS) and quality diversity (QD) algorithms, can be hybridized with ES to\nimprove its performance on sparse or deceptive deep RL tasks, while retaining\nscalability. Our experiments confirm that the resultant new algorithms, NS-ES\nand two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES\nto achieve higher performance on Atari and simulated robots learning to walk\naround a deceptive trap. This paper thus introduces a family of fast, scalable\nalgorithms for reinforcement learning that are capable of directed exploration.\nIt also adds this new family of exploration algorithms to the RL toolbox and\nraises the interesting possibility that analogous algorithms with multiple\nsimultaneous paths of exploration might also combine well with existing RL\nalgorithms outside ES.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:10:39 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 19:04:46 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 18:02:53 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Conti", "Edoardo", ""], ["Madhavan", "Vashisht", ""], ["Such", "Felipe Petroski", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1712.06563", "submitter": "Joel Lehman", "authors": "Joel Lehman, Jay Chen, Jeff Clune, Kenneth O. Stanley", "title": "Safe Mutations for Deep and Recurrent Neural Networks through Output\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neuroevolution (evolving neural networks) has a successful track record\nacross a variety of domains from reinforcement learning to artificial life, it\nis rarely applied to large, deep neural networks. A central reason is that\nwhile random mutation generally works in low dimensions, a random perturbation\nof thousands or millions of weights is likely to break existing functionality,\nproviding no learning signal even if some individual weight changes were\nbeneficial. This paper proposes a solution by introducing a family of safe\nmutation (SM) operators that aim within the mutation operator itself to find a\ndegree of change that does not alter network behavior too much, but still\nfacilitates exploration. Importantly, these SM operators do not require any\nadditional interactions with the environment. The most effective SM variant\ncapitalizes on the intriguing opportunity to scale the degree of mutation of\neach individual weight according to the sensitivity of the network's outputs to\nthat weight, which requires computing the gradient of outputs with respect to\nthe weights (instead of the gradient of error, as in conventional deep\nlearning). This safe mutation through gradients (SM-G) operator dramatically\nincreases the ability of a simple genetic algorithm-based neuroevolution method\nto find solutions in high-dimensional domains that require deep and/or\nrecurrent neural networks (which tend to be particularly brittle to mutation),\nincluding domains that require processing raw pixels. By improving our ability\nto evolve deep neural networks, this new safer approach to mutation expands the\nscope of domains amenable to neuroevolution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:16:51 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 18:45:26 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:18:32 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Lehman", "Joel", ""], ["Chen", "Jay", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1712.06568", "submitter": "Joel Lehman", "authors": "Joel Lehman, Jay Chen, Jeff Clune, Kenneth O. Stanley", "title": "ES Is More Than Just a Traditional Finite-Difference Approximator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolution strategy (ES) variant based on a simplification of a natural\nevolution strategy recently attracted attention because it performs\nsurprisingly well in challenging deep reinforcement learning domains. It\nsearches for neural network parameters by generating perturbations to the\ncurrent set of parameters, checking their performance, and moving in the\naggregate direction of higher reward. Because it resembles a traditional\nfinite-difference approximation of the reward gradient, it can naturally be\nconfused with one. However, this ES optimizes for a different gradient than\njust reward: It optimizes for the average reward of the entire population,\nthereby seeking parameters that are robust to perturbation. This difference can\nchannel ES into distinct areas of the search space relative to gradient\ndescent, and also consequently to networks with distinct properties. This\nunique robustness-seeking property, and its consequences for optimization, are\ndemonstrated in several domains. They include humanoid locomotion, where\nnetworks from policy gradient-based reinforcement learning are significantly\nless robust to parameter perturbation than ES-based policies solving the same\ntask. While the implications of such robustness and robustness-seeking remain\nopen to further study, this work's main contribution is to highlight such\ndifferences and their potential importance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:25:35 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 18:36:12 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:29:42 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Lehman", "Joel", ""], ["Chen", "Jay", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1712.06577", "submitter": "Maxim Naumov", "authors": "Maxim Naumov", "title": "Parallel Complexity of Forward and Backward Propagation", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the forward and backward propagation can be formulated as a\nsolution of lower and upper triangular systems of equations. For standard\nfeedforward (FNNs) and recurrent neural networks (RNNs) the triangular systems\nare always block bi-diagonal, while for a general computation graph (directed\nacyclic graph) they can have a more complex triangular sparsity pattern. We\ndiscuss direct and iterative parallel algorithms that can be used for their\nsolution and interpreted as different ways of performing model parallelism.\nAlso, we show that for FNNs and RNNs with $k$ layers and $\\tau$ time steps the\nbackward propagation can be performed in parallel in O($\\log k$) and O($\\log k\n\\log \\tau$) steps, respectively. Finally, we outline the generalization of this\ntechnique using Jacobians that potentially allows us to handle arbitrary\nlayers.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:46:51 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Naumov", "Maxim", ""]]}, {"id": "1712.06657", "submitter": "Andreas Holzinger", "authors": "Andreas Holzinger, Bernd Malle, Peter Kieseberg, Peter M. Roth, Heimo\n  M\\\"uller, Robert Reihs, Kurt Zatloukal", "title": "Towards the Augmented Pathologist: Challenges of Explainable-AI in\n  Digital Pathology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital pathology is not only one of the most promising fields of diagnostic\nmedicine, but at the same time a hot topic for fundamental research. Digital\npathology is not just the transfer of histopathological slides into digital\nrepresentations. The combination of different data sources (images, patient\nrecords, and *omics data) together with current advances in artificial\nintelligence/machine learning enable to make novel information accessible and\nquantifiable to a human expert, which is not yet available and not exploited in\ncurrent medical settings. The grand goal is to reach a level of usable\nintelligence to understand the data in the context of an application task,\nthereby making machine decisions transparent, interpretable and explainable.\nThe foundation of such an \"augmented pathologist\" needs an integrated approach:\nWhile machine learning algorithms require many thousands of training examples,\na human expert is often confronted with only a few data points. Interestingly,\nhumans can learn from such few examples and are able to instantly interpret\ncomplex patterns. Consequently, the grand goal is to combine the possibilities\nof artificial intelligence with human intelligence and to find a well-suited\nbalance between them to enable what neither of them could do on their own. This\ncan raise the quality of education, diagnosis, prognosis and prediction of\ncancer and other diseases. In this paper we describe some (incomplete) research\nissues which we believe should be addressed in an integrated and concerted\neffort for paving the way towards the augmented pathologist.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 20:15:02 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Holzinger", "Andreas", ""], ["Malle", "Bernd", ""], ["Kieseberg", "Peter", ""], ["Roth", "Peter M.", ""], ["M\u00fcller", "Heimo", ""], ["Reihs", "Robert", ""], ["Zatloukal", "Kurt", ""]]}, {"id": "1712.06778", "submitter": "Saptarshi Pal", "authors": "Saptarshi Pal and Soumya K Ghosh", "title": "Learning Representations from Road Network for End-to-End Urban Growth\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From our experiences in the past, we have seen that the growth of cities is\nvery much dependent on the transportation networks. In mega cities,\ntransportation networks determine to a significant extent as to where the\npeople will move and houses will be built. Hence, transportation network data\nis crucial to an urban growth prediction system. Existing works have used\nmanually derived distance based features based on the road networks to build\nmodels on urban growth. But due to the non-generic and laborious nature of the\nmanual feature engineering process, we can shift to End-to-End systems which do\nnot rely on manual feature engineering. In this paper, we propose a method to\nintegrate road network data to an existing Rule based End-to-End framework\nwithout manual feature engineering. Our method employs recurrent neural\nnetworks to represent road networks in a structured way such that it can be\nplugged into the previously proposed End-to-End framework. The proposed\napproach enhances the performance in terms of Figure of Merit, Producer's\naccuracy, User's accuracy and Overall accuracy of the existing Rule based\nEnd-to-End framework.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 04:36:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 12:06:49 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 05:25:11 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Pal", "Saptarshi", ""], ["Ghosh", "Soumya K", ""]]}, {"id": "1712.06868", "submitter": "Christoph Wernhard", "authors": "Christoph Wernhard", "title": "Heinrich Behmann's Contributions to Second-Order Quantifier Elimination\n  from the View of Computational Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": "KRR 15-05", "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For relational monadic formulas (the L\\\"owenheim class) second-order\nquantifier elimination, which is closely related to computation of uniform\ninterpolants, projection and forgetting - operations that currently receive\nmuch attention in knowledge processing - always succeeds. The decidability\nproof for this class by Heinrich Behmann from 1922 explicitly proceeds by\nelimination with equivalence preserving formula rewriting. Here we reconstruct\nthe results from Behmann's publication in detail and discuss related issues\nthat are relevant in the context of modern approaches to second-order\nquantifier elimination in computational logic. In addition, an extensive\ndocumentation of the letters and manuscripts in Behmann's bequest that concern\nsecond-order quantifier elimination is given, including a commented register\nand English abstracts of the German sources with focus on technical material.\nIn the late 1920s Behmann attempted to develop an elimination-based decision\nmethod for formulas with predicates whose arity is larger than one. His\nmanuscripts and the correspondence with Wilhelm Ackermann show technical\naspects that are still of interest today and give insight into the genesis of\nAckermann's landmark paper \"Untersuchungen \\\"uber das Eliminationsproblem der\nmathematischen Logik\" from 1935, which laid the foundation of the two\nprevailing modern approaches to second-order quantifier elimination.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 11:17:23 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Wernhard", "Christoph", ""]]}, {"id": "1712.06924", "submitter": "Romain Laroche", "authors": "Romain Laroche, Paul Trichelair, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with Baseline Bootstrapping", "comments": "accepted as a long oral at ICML2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers Safe Policy Improvement (SPI) in Batch Reinforcement\nLearning (Batch RL): from a fixed dataset and without direct access to the true\nenvironment, train a policy that is guaranteed to perform at least as well as\nthe baseline policy used to collect the data. Our approach, called SPI with\nBaseline Bootstrapping (SPIBB), is inspired by the knows-what-it-knows\nparadigm: it bootstraps the trained policy with the baseline when the\nuncertainty is high. Our first algorithm, $\\Pi_b$-SPIBB, comes with SPI\ntheoretical guarantees. We also implement a variant, $\\Pi_{\\leq b}$-SPIBB, that\nis even more efficient in practice. We apply our algorithms to a motivational\nstochastic gridworld domain and further demonstrate on randomly generated MDPs\nthe superiority of SPIBB with respect to existing algorithms, not only in\nsafety but also in mean performance. Finally, we implement a model-free version\nof SPIBB and show its benefits on a navigation task with deep RL implementation\ncalled SPIBB-DQN, which is, to the best of our knowledge, the first RL\nalgorithm relying on a neural network representation able to train efficiently\nand reliably from batch data, without any interaction with the environment.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 13:43:41 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 19:52:03 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 21:37:53 GMT"}, {"version": "v4", "created": "Thu, 14 Jun 2018 19:54:34 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 17:45:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Laroche", "Romain", ""], ["Trichelair", "Paul", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1712.06935", "submitter": "Boris Chidlovskii", "authors": "Boris Chidlovskii", "title": "Mining Smart Card Data for Travelers' Mini Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the context of public transport modeling and simulation, we address the\nproblem of mismatch between simulated transit trips and observed ones. We point\nto the weakness of the current travel demand modeling process; the trips it\ngenerates are over-optimistic and do not reflect the real passenger choices. We\nintroduce the notion of mini activities the travelers do during the trips; they\ncan explain the deviation of simulated trips from the observed trips. We\npropose to mine the smart card data to extract the mini activities. We develop\na technique to integrate them in the generated trips and learn such an\nintegration from two available sources, the trip history and trip planner\nrecommendations. For an input travel demand, we build a Markov chain over the\ntrip collection and apply the Monte Carlo Markov Chain algorithm to integrate\nmini activities in such a way that the selected characteristics converge to the\ndesired distributions. We test our method in different settings on the\npassenger trip collection of Nancy, France. We report experimental results\ndemonstrating a very important mismatch reduction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 14:05:23 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Chidlovskii", "Boris", ""]]}, {"id": "1712.06957", "submitter": "Pranav Rajpurkar", "authors": "Pranav Rajpurkar, Jeremy Irvin, Aarti Bagul, Daisy Ding, Tony Duan,\n  Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L. Ball, Curtis\n  Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng", "title": "MURA: Large Dataset for Abnormality Detection in Musculoskeletal\n  Radiographs", "comments": "1st Conference on Medical Imaging with Deep Learning (MIDL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MURA, a large dataset of musculoskeletal radiographs containing\n40,561 images from 14,863 studies, where each study is manually labeled by\nradiologists as either normal or abnormal. To evaluate models robustly and to\nget an estimate of radiologist performance, we collect additional labels from\nsix board-certified Stanford radiologists on the test set, consisting of 207\nmusculoskeletal studies. On this test set, the majority vote of a group of\nthree radiologists serves as gold standard. We train a 169-layer DenseNet\nbaseline model to detect and localize abnormalities. Our model achieves an\nAUROC of 0.929, with an operating point of 0.815 sensitivity and 0.887\nspecificity. We compare our model and radiologists on the Cohen's kappa\nstatistic, which expresses the agreement of our model and of each radiologist\nwith the gold standard. Model performance is comparable to the best radiologist\nperformance in detecting abnormalities on finger and wrist studies. However,\nmodel performance is lower than best radiologist performance in detecting\nabnormalities on elbow, forearm, hand, humerus, and shoulder studies. We\nbelieve that the task is a good challenge for future research. To encourage\nadvances, we have made our dataset freely available at\nhttps://stanfordmlgroup.github.io/competitions/mura .\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:46:55 GMT"}, {"version": "v2", "created": "Wed, 20 Dec 2017 03:32:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jan 2018 01:08:54 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:19:07 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Irvin", "Jeremy", ""], ["Bagul", "Aarti", ""], ["Ding", "Daisy", ""], ["Duan", "Tony", ""], ["Mehta", "Hershel", ""], ["Yang", "Brandon", ""], ["Zhu", "Kaylie", ""], ["Laird", "Dillon", ""], ["Ball", "Robyn L.", ""], ["Langlotz", "Curtis", ""], ["Shpanskaya", "Katie", ""], ["Lungren", "Matthew P.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1712.07004", "submitter": "Rasoul Kaljahi", "authors": "Rasoul Kaljahi, Jennifer Foster", "title": "Any-gram Kernels for Sentence Classification: A Sentiment Analysis Case\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any-gram kernels are a flexible and efficient way to employ bag-of-n-gram\nfeatures when learning from textual data. They are also compatible with the use\nof word embeddings so that word similarities can be accounted for. While the\noriginal any-gram kernels are implemented on top of tree kernels, we propose a\nnew approach which is independent of tree kernels and is more efficient. We\nalso propose a more effective way to make use of word embeddings than the\noriginal any-gram formulation. When applied to the task of sentiment\nclassification, our new formulation achieves significantly better performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 15:47:00 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Kaljahi", "Rasoul", ""], ["Foster", "Jennifer", ""]]}, {"id": "1712.07019", "submitter": "Ehsan Hemmati", "authors": "Mansour Sheikhan, Ehsan Hemmati", "title": "PSO-Optimized Hopfield Neural Network-Based Multipath Routing for Mobile\n  Ad-hoc Networks", "comments": "Mobile ad-hoc networks; Reliability; Multipath routing; Neural\n  networks; Particle swarm optimization (PSO)", "journal-ref": "International Journal of Computational Intelligence Systems, Year\n  2012, Volume 5, Number 3, Pages 568-581", "doi": "10.1080/18756891.2012.696921", "report-no": null, "categories": "cs.NE cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile ad-hoc network (MANET) is a dynamic collection of mobile computers\nwithout the need for any existing infrastructure. Nodes in a MANET act as hosts\nand routers. Designing of robust routing algorithms for MANETs is a challenging\ntask. Disjoint multipath routing protocols address this problem and increase\nthe reliability, security and lifetime of network. However, selecting an\noptimal multipath is an NP-complete problem. In this paper, Hopfield neural\nnetwork (HNN) which its parameters are optimized by particle swarm optimization\n(PSO) algorithm is proposed as multipath routing algorithm. Link expiration\ntime (LET) between each two nodes is used as the link reliability estimation\nmetric. This approach can find either node-disjoint or link-disjoint paths in\nsingle phase route discovery. Simulation results confirm that PSO-HNN routing\nalgorithm has better performance as compared to backup path set selection\nalgorithm (BPSA) in terms of the path set reliability and number of paths in\nthe set.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 23:36:59 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Sheikhan", "Mansour", ""], ["Hemmati", "Ehsan", ""]]}, {"id": "1712.07040", "submitter": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y", "authors": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Jonathan Schwarz, Phil Blunsom, Chris Dyer,\n  Karl Moritz Hermann, G\\'abor Melis, Edward Grefenstette", "title": "The NarrativeQA Reading Comprehension Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension (RC)---in contrast to information retrieval---requires\nintegrating information and reasoning about events, entities, and their\nrelations across a full document. Question answering is conventionally used to\nassess RC ability, in both artificial agents and children learning to read.\nHowever, existing RC datasets and tasks are dominated by questions that can be\nsolved by selecting answers using superficial information (e.g., local context\nsimilarity or global term frequency); they thus fail to test for the essential\nintegrative aspect of RC. To encourage progress on deeper comprehension of\nlanguage, we present a new dataset and set of tasks in which the reader must\nanswer questions about stories by reading entire books or movie scripts. These\ntasks are designed so that successfully answering their questions requires\nunderstanding the underlying narrative rather than relying on shallow pattern\nmatching or salience. We show that although humans solve the tasks easily,\nstandard RC models struggle on the tasks presented here. We provide an analysis\nof the dataset and the challenges it presents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 16:48:05 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Schwarz", "Jonathan", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Hermann", "Karl Moritz", ""], ["Melis", "G\u00e1bor", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1712.07081", "submitter": "Serdar Kadioglu", "authors": "Serdar Kadioglu", "title": "Column Generation for Interaction Coverage in Combinatorial Software\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel column generation framework for combinatorial\nsoftware testing. In particular, it combines Mathematical Programming and\nConstraint Programming in a hybrid decomposition to generate covering arrays.\nThe approach allows generating parameterized test cases with coverage\nguarantees between parameter interactions of a given application. Compared to\nexhaustive testing, combinatorial test case generation reduces the number of\ntests to run significantly. Our column generation algorithm is generic and can\naccommodate mixed coverage arrays over heterogeneous alphabets. The algorithm\nis realized in practice as a cloud service and recognized as one of the five\nwinners of the company-wide cloud application challenge at Oracle. The service\nis currently helping software developers from a range of different product\nteams in their testing efforts while exposing declarative constraint models and\nhybrid optimization techniques to a broader audience.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 18:01:06 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Kadioglu", "Serdar", ""]]}, {"id": "1712.07165", "submitter": "Tyler Spears", "authors": "Tyler A. Spears, Brandon G. Jacques, Marc W. Howard, Per B. Sederberg", "title": "Scale-invariant temporal history (SITH): optimal slicing of the past in\n  an uncertain world", "comments": "Preprint for submission to Neural Computation. Submitted to Neural\n  Computation - Update 12/18/2018: revised based on reviewer comments,\n  resubmitted to Neural Computation on 15 December, 2018. Restructured\n  introduction and discussion, combined figures, added section for SITH\n  parameterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In both the human brain and any general artificial intelligence (AI), a\nrepresentation of the past is necessary to predict the future. However, perfect\nstorage of all experiences is not feasible. One approach utilized in many\napplications, including reward prediction in reinforcement learning, is to\nretain recently active features of experience in a buffer. Despite its prior\nsuccesses, we show that the fixed length buffer renders Deep Q-learning\nNetworks (DQNs) fragile to changes in the scale over which information can be\nlearned. To enable learning when the relevant temporal scales in the\nenvironment are not known *a priori*, recent advances in psychology and\nneuroscience suggest that the brain maintains a compressed representation of\nthe past. Here we introduce a neurally-plausible, scale-free memory\nrepresentation we call Scale-Invariant Temporal History (SITH) for use with\nartificial agents. This representation covers an exponentially large period of\ntime by sacrificing temporal accuracy for events further in the past. We\ndemonstrate the utility of this representation by comparing the performance of\nagents given SITH, buffer, and exponential decay representations in learning to\nplay video games at different levels of complexity. In these environments, SITH\nexhibits better learning performance by storing information for longer\ntimescales than a fixed-size buffer, and representing this information more\nclearly than a set of exponentially decayed features. Finally, we discuss how\nthe application of SITH, along with other human-inspired models of cognition,\ncould improve reinforcement and machine learning algorithms in general.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 19:33:02 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 03:17:31 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 16:50:32 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Spears", "Tyler A.", ""], ["Jacques", "Brandon G.", ""], ["Howard", "Marc W.", ""], ["Sederberg", "Per B.", ""]]}, {"id": "1712.07199", "submitter": "Rajesh Bordawekar", "authors": "Rajesh Bordawekar and Bortik Bandyopadhyay and Oded Shmueli", "title": "Cognitive Database: A Step towards Endowing Relational Databases with\n  Artificial Intelligence Capabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Cognitive Databases, an approach for transparently enabling\nArtificial Intelligence (AI) capabilities in relational databases. A novel\naspect of our design is to first view the structured data source as meaningful\nunstructured text, and then use the text to build an unsupervised neural\nnetwork model using a Natural Language Processing (NLP) technique called word\nembedding. This model captures the hidden inter-/intra-column relationships\nbetween database tokens of different types. For each database token, the model\nincludes a vector that encodes contextual semantic relationships. We seamlessly\nintegrate the word embedding model into existing SQL query infrastructure and\nuse it to enable a new class of SQL-based analytics queries called cognitive\nintelligence (CI) queries. CI queries use the model vectors to enable complex\nqueries such as semantic matching, inductive reasoning queries such as\nanalogies, predictive queries using entities not present in a database, and,\nmore generally, using knowledge from external sources. We demonstrate unique\ncapabilities of Cognitive Databases using an Apache Spark based prototype to\nexecute inductive reasoning CI queries over a multi-modal database containing\ntext and images. We believe our first-of-a-kind system exemplifies using AI\nfunctionality to endow relational databases with capabilities that were\npreviously very hard to realize in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:49:26 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Bordawekar", "Rajesh", ""], ["Bandyopadhyay", "Bortik", ""], ["Shmueli", "Oded", ""]]}, {"id": "1712.07294", "submitter": "Caiming Xiong Mr", "authors": "Tianmin Shu, Caiming Xiong, Richard Socher", "title": "Hierarchical and Interpretable Skill Acquisition in Multi-task\n  Reinforcement Learning", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning policies for complex tasks that require multiple different skills is\na major challenge in reinforcement learning (RL). It is also a requirement for\nits deployment in real-world scenarios. This paper proposes a novel framework\nfor efficient multi-task reinforcement learning. Our framework trains agents to\nemploy hierarchical policies that decide when to use a previously learned\npolicy and when to learn a new skill. This enables agents to continually\nacquire new skills during different stages of training. Each learned task\ncorresponds to a human language description. Because agents can only access\npreviously learned skills through these descriptions, the agent can always\nprovide a human-interpretable description of its choices. In order to help the\nagent learn the complex temporal dependencies necessary for the hierarchical\npolicy, we provide it with a stochastic temporal grammar that modulates when to\nrely on previously learned skills and when to execute new skills. We validate\nour approach on Minecraft games designed to explicitly test the ability to\nreuse previously learned skills while simultaneously learning new skills.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 02:50:20 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Shu", "Tianmin", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07296", "submitter": "Caiming Xiong Mr", "authors": "Huishuai Zhang, Caiming Xiong, James Bradbury, Richard Socher", "title": "Block-diagonal Hessian-free Optimization for Training Neural Networks", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order methods for neural network optimization have several advantages\nover methods based on first-order gradient descent, including better scaling to\nlarge mini-batch sizes and fewer updates needed for convergence. But they are\nrarely applied to deep learning in practice because of high computational cost\nand the need for model-dependent algorithmic variations. We introduce a variant\nof the Hessian-free method that leverages a block-diagonal approximation of the\ngeneralized Gauss-Newton matrix. Our method computes the curvature\napproximation matrix only for pairs of parameters from the same layer or block\nof the neural network and performs conjugate gradient updates independently for\neach block. Experiments on deep autoencoders, deep convolutional networks, and\nmultilayer LSTMs demonstrate better convergence and generalization compared to\nthe original Hessian-free approach and the Adam method.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 02:52:35 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Zhang", "Huishuai", ""], ["Xiong", "Caiming", ""], ["Bradbury", "James", ""], ["Socher", "Richard", ""]]}, {"id": "1712.07305", "submitter": "Bo Xin", "authors": "Xiangyu Kong, Bo Xin, Fangchen Liu, Yizhou Wang", "title": "Revisiting the Master-Slave Architecture in Multi-Agent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in artificial intelligence require the collaboration of multiple\nagents. We exam deep reinforcement learning for multi-agent domains. Recent\nresearch efforts often take the form of two seemingly conflicting perspectives,\nthe decentralized perspective, where each agent is supposed to have its own\ncontroller; and the centralized perspective, where one assumes there is a\nlarger model controlling all agents. In this regard, we revisit the idea of the\nmaster-slave architecture by incorporating both perspectives within one\nframework. Such a hierarchical structure naturally leverages advantages from\none another. The idea of combining both perspectives is intuitive and can be\nwell motivated from many real world systems, however, out of a variety of\npossible realizations, we highlights three key ingredients, i.e. composed\naction representation, learnable communication and independent reasoning. With\nnetwork designs to facilitate these explicitly, our proposal consistently\noutperforms latest competing methods both in synthetic experiments and when\napplied to challenging StarCraft micromanagement tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 03:00:46 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Kong", "Xiangyu", ""], ["Xin", "Bo", ""], ["Liu", "Fangchen", ""], ["Wang", "Yizhou", ""]]}, {"id": "1712.07312", "submitter": "Wellington Pinheiro dos Santos", "authors": "Filipe Rolim Cordeiro, Wellington Pinheiro dos Santos, Abel\n  Guilhermino da Silva Filho", "title": "Analysis of supervised and semi-supervised GrowCut applied to\n  segmentation of masses in mammography images", "comments": null, "journal-ref": "Computer Methods in Biomechanics and Biomedical Engineering:\n  Imaging & Visualization, v. 5, p. 1-19, 2017", "doi": "10.1080/21681163.2015.1127775", "report-no": null, "categories": "cs.CV cs.AI cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is already one of the most common form of cancer worldwide.\nMammography image analysis is still the most effective diagnostic method to\npromote the early detection of breast cancer. Accurately segmenting tumors in\ndigital mammography images is important to improve diagnosis capabilities of\nhealth specialists and avoid misdiagnosis. In this work, we evaluate the\nfeasibility of applying GrowCut to segment regions of tumor and we propose two\nGrowCut semi-supervised versions. All the analysis was performed by evaluating\nthe application of segmentation techniques to a set of images obtained from the\nMini-MIAS mammography image database. GrowCut segmentation was compared to\nRegion Growing, Active Contours, Random Walks and Graph Cut techniques.\nExperiments showed that GrowCut, when compared to the other techniques, was\nable to acquire better results for the metrics analyzed. Moreover, the proposed\nsemi-supervised versions of GrowCut was proved to have a clinically\nsatisfactory quality of segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 03:50:15 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Cordeiro", "Filipe Rolim", ""], ["Santos", "Wellington Pinheiro dos", ""], ["Filho", "Abel Guilhermino da Silva", ""]]}, {"id": "1712.07452", "submitter": "Tobias Doernbach", "authors": "Tobias Doernbach", "title": "Self-Supervised Damage-Avoiding Manipulation Strategy Optimization via\n  Mental Simulation", "comments": null, "journal-ref": "Intelligent Service Robotics, August 2019", "doi": "10.1007/s11370-019-00286-7", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyday robotics are challenged to deal with autonomous product handling in\napplications like logistics or retail, possibly causing damage on the items\nduring manipulation. Traditionally, most approaches try to minimize physical\ninteraction with goods. However, this paper proposes to take into account any\nunintended object motion and to learn damage-minimizing manipulation strategies\nin a self-supervised way. The presented approach consists of a simulation-based\nplanning method for an optimal manipulation sequence with respect to possible\ndamage. The planned manipulation sequences are generalized to new, unseen\nscenes in the same application scenario using machine learning. This learned\nmanipulation strategy is continuously refined in a self-supervised,\nsimulation-in-the-loop optimization cycle during load-free times of the system,\ncommonly known as mental simulation. In parallel, the generated manipulation\nstrategies can be deployed in near-real time in an anytime fashion. The\napproach is validated on an industrial container-unloading scenario and on a\nretail shelf-replenishment scenario.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:47:39 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 20:41:40 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Doernbach", "Tobias", ""]]}, {"id": "1712.07686", "submitter": "Manuel Mazzara", "authors": "Vladimir Marochko, Leonard Johard, Manuel Mazzara, Luca Longo", "title": "Pseudorehearsal in actor-critic agents with neural network function\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting has a significant negative impact in reinforcement\nlearning. The purpose of this study is to investigate how pseudorehearsal can\nchange performance of an actor-critic agent with neural-network function\napproximation. We tested agent in a pole balancing task and compared different\npseudorehearsal approaches. We have found that pseudorehearsal can assist\nlearning and decrease forgetting.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 19:53:23 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 08:55:29 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Marochko", "Vladimir", ""], ["Johard", "Leonard", ""], ["Mazzara", "Manuel", ""], ["Longo", "Luca", ""]]}, {"id": "1712.07745", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Bing Liu", "title": "Context-aware Path Ranking for Knowledge Base Completion", "comments": null, "journal-ref": "Published in IJCAI 2017", "doi": "10.24963/ijcai.2017/166", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base (KB) completion aims to infer missing facts from existing ones\nin a KB. Among various approaches, path ranking (PR) algorithms have received\nincreasing attention in recent years. PR algorithms enumerate paths between\nentity pairs in a KB and use those paths as features to train a model for\nmissing fact prediction. Due to their good performances and high model\ninterpretability, several methods have been proposed. However, most existing\nmethods suffer from scalability (high RAM consumption) and feature explosion\n(trains on an exponentially large number of features) problems. This paper\nproposes a Context-aware Path Ranking (C-PR) algorithm to solve these problems\nby introducing a selective path exploration strategy. C-PR learns global\nsemantics of entities in the KB using word embedding and leverages the\nknowledge of entity semantics to enumerate contextually relevant paths using\nbidirectional random walk. Experimental results on three large KBs show that\nthe path features (fewer in number) discovered by C-PR not only improve\npredictive performance but also are more interpretable than existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 23:10:21 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""]]}, {"id": "1712.07752", "submitter": "Rajesh Chidambaram", "authors": "Rajesh Chidambaram", "title": "Towards an unanimous international regulatory body for responsible use\n  of Artificial Intelligence [UIRB-AI]", "comments": "The paper covers a diverse range of topics but doesn't get into the\n  details of any and hence the proposals remain pragmatically irrelevant", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI), is once again in the phase of drastic\nadvancements. Unarguably, the technology itself can revolutionize the way we\nlive our everyday life. But the exponential growth of technology poses a\ndaunting task for policy researchers and law makers in making amendments to the\nexisting norms. In addition, not everyone in the society is studying the\npotential socio-economic intricacies and cultural drifts that AI can bring\nabout. It is prudence to reflect from our historical past to propel the\ndevelopment of technology in the right direction. To benefit the society of the\npresent and future, I scientifically explore the societal impact of AI. While\nthere are many public and private partnerships working on similar aspects, here\nI describe the necessity for an Unanimous International Regulatory Body for all\napplications of AI (UIRB-AI). I also discuss the benefits and drawbacks of such\nan organization. To combat any drawbacks in the formation of an UIRB-AI, both\nidealistic and pragmatic perspectives are discussed alternatively. The paper\nfurther advances the discussion by proposing novel policies on how such\norganization should be structured and how it can bring about a win-win\nsituation for everyone in the society.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 00:29:48 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 16:39:50 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 22:24:09 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chidambaram", "Rajesh", ""]]}, {"id": "1712.07770", "submitter": "Seonmo Kim", "authors": "Seonmo Kim and Stephen McCamant", "title": "Bit-Vector Model Counting using Statistical Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate model counting for bit-vector SMT formulas (generalizing \\#SAT)\nhas many applications such as probabilistic inference and quantitative\ninformation-flow security, but it is computationally difficult. Adding random\nparity constraints (XOR streamlining) and then checking satisfiability is an\neffective approximation technique, but it requires a prior hypothesis about the\nmodel count to produce useful results. We propose an approach inspired by\nstatistical estimation to continually refine a probabilistic estimate of the\nmodel count for a formula, so that each XOR-streamlined query yields as much\ninformation as possible. We implement this approach, with an approximate\nprobability model, as a wrapper around an off-the-shelf SMT solver or SAT\nsolver. Experimental results show that the implementation is faster than the\nmost similar previous approaches which used simpler refinement strategies. The\ntechnique also lets us model count formulas over floating-point constraints,\nwhich we demonstrate with an application to a vulnerability in differential\nprivacy mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 02:05:25 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Kim", "Seonmo", ""], ["McCamant", "Stephen", ""]]}, {"id": "1712.07822", "submitter": "L\\'eon Bottou", "authors": "Leon Bottou and Martin Arjovsky and David Lopez-Paz and Maxime Oquab", "title": "Geometrical Insights for Implicit Generative Modeling", "comments": "this version fixes a typo in a definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning algorithms for implicit generative models can optimize a variety of\ncriteria that measure how the data distribution differs from the implicit model\ndistribution, including the Wasserstein distance, the Energy distance, and the\nMaximum Mean Discrepancy criterion. A careful look at the geometries induced by\nthese distances on the space of probability measures reveals interesting\ndifferences. In particular, we can establish surprising approximate global\nconvergence guarantees for the $1$-Wasserstein distance,even when the\nparametric generator has a nonconvex parametrization.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 08:11:44 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 20:21:04 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 21:09:56 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Bottou", "Leon", ""], ["Arjovsky", "Martin", ""], ["Lopez-Paz", "David", ""], ["Oquab", "Maxime", ""]]}, {"id": "1712.07887", "submitter": "Soma Suzuki", "authors": "Soma Suzuki", "title": "Multiagent-based Participatory Urban Simulation through Inverse\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiagent-based participatory simulation features prominently in urban\nplanning as the acquired model is considered as the hybrid system of the domain\nand the local knowledge. However, the key problem of generating realistic\nagents for particular social phenomena invariably remains. The existing models\nhave attempted to dictate the factors involving human behavior, which appeared\nto be intractable. In this paper, Inverse Reinforcement Learning (IRL) is\nintroduced to address this problem. IRL is developed for computational modeling\nof human behavior and has achieved great successes in robotics, psychology and\nmachine learning. The possibilities presented by this new style of modeling are\ndrawn out as conclusions, and the relative challenges with this modeling are\nhighlighted.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:41:13 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Suzuki", "Soma", ""]]}, {"id": "1712.07893", "submitter": "Shih-Yang Su", "authors": "Zhang-Wei Hong, Shih-Yang Su, Tzu-Yun Shann, Yi-Hsiang Chang, and\n  Chun-Yi Lee", "title": "A Deep Policy Inference Q-Network for Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DPIQN, a deep policy inference Q-network that targets multi-agent\nsystems composed of controllable agents, collaborators, and opponents that\ninteract with each other. We focus on one challenging issue in such\nsystems---modeling agents with varying strategies---and propose to employ\n\"policy features\" learned from raw observations (e.g., raw images) of\ncollaborators and opponents by inferring their policies. DPIQN incorporates the\nlearned policy features as a hidden vector into its own deep Q-network (DQN),\nsuch that it is able to predict better Q values for the controllable agents\nthan the state-of-the-art deep reinforcement learning models. We further\npropose an enhanced version of DPIQN, called deep recurrent policy inference\nQ-network (DRPIQN), for handling partial observability. Both DPIQN and DRPIQN\nare trained by an adaptive training procedure, which adjusts the network's\nattention to learn the policy features and its own Q-values at different phases\nof the training process. We present a comprehensive analysis of DPIQN and\nDRPIQN, and highlight their effectiveness and generalizability in various\nmulti-agent settings. Our models are evaluated in a classic soccer game\ninvolving both competitive and collaborative scenarios. Experimental results\nperformed on 1 vs. 1 and 2 vs. 2 games show that DPIQN and DRPIQN demonstrate\nsuperior performance to the baseline DQN and deep recurrent Q-network (DRQN)\nmodels. We also explore scenarios in which collaborators or opponents\ndynamically change their policies, and show that DPIQN and DRPIQN do lead to\nbetter overall performance in terms of stability and mean scores.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:53:35 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 06:38:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Su", "Shih-Yang", ""], ["Shann", "Tzu-Yun", ""], ["Chang", "Yi-Hsiang", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1712.07901", "submitter": "Atilim Gunes Baydin", "authors": "Mario Lezcano Casado, Atilim Gunes Baydin, David Martinez Rubio, Tuan\n  Anh Le, Frank Wood, Lukas Heinrich, Gilles Louppe, Kyle Cranmer, Karen Ng,\n  Wahid Bhimji, Prabhat", "title": "Improvements to Inference Compilation for Probabilistic Programming in\n  Large-Scale Scientific Simulators", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Bayesian inference in the family of probabilistic\nmodels implicitly defined by stochastic generative models of data. In\nscientific fields ranging from population biology to cosmology, low-level\nmechanistic components are composed to create complex generative models. These\nmodels lead to intractable likelihoods and are typically non-differentiable,\nwhich poses challenges for traditional approaches to inference. We extend\nprevious work in \"inference compilation\", which combines universal\nprobabilistic programming and deep learning methods, to large-scale scientific\nsimulators, and introduce a C++ based probabilistic programming library called\nCPProb. We successfully use CPProb to interface with SHERPA, a large code-base\nused in particle physics. Here we describe the technical innovations realized\nand planned for this library.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 12:20:01 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Casado", "Mario Lezcano", ""], ["Baydin", "Atilim Gunes", ""], ["Rubio", "David Martinez", ""], ["Le", "Tuan Anh", ""], ["Wood", "Frank", ""], ["Heinrich", "Lukas", ""], ["Louppe", "Gilles", ""], ["Cranmer", "Kyle", ""], ["Ng", "Karen", ""], ["Bhimji", "Wahid", ""], ["Prabhat", "", ""]]}, {"id": "1712.08163", "submitter": "Weiming Xiang", "authors": "Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson", "title": "Reachable Set Computation and Safety Verification for Neural Networks\n  with ReLU Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been widely used to solve complex real-world problems.\nDue to the complicate, nonlinear, non-convex nature of neural networks, formal\nsafety guarantees for the output behaviors of neural networks will be crucial\nfor their applications in safety-critical systems.In this paper, the output\nreachable set computation and safety verification problems for a class of\nneural networks consisting of Rectified Linear Unit (ReLU) activation functions\nare addressed. A layer-by-layer approach is developed to compute output\nreachable set. The computation is formulated in the form of a set of\nmanipulations for a union of polyhedra, which can be efficiently applied with\nthe aid of polyhedron computation tools. Based on the output reachable set\ncomputation results, the safety verification for a ReLU neural network can be\nperformed by checking the intersections of unsafe regions and output reachable\nset described by a union of polyhedra. A numerical example of a randomly\ngenerated ReLU neural network is provided to show the effectiveness of the\napproach developed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 08:57:06 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Xiang", "Weiming", ""], ["Tran", "Hoang-Dung", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "1712.08164", "submitter": "Boris Chidlovskii", "authors": "Boris Chidlovskii", "title": "Multi-task learning of time series and its application to the travel\n  demand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of modeling and prediction of a set of temporal events\nin the context of intelligent transportation systems. To leverage the\ninformation shared by different events, we propose a multi-task learning\nframework. We develop a support vector regression model for joint learning of\nmutually dependent time series. It is the regularization-based multi-task\nlearning previously developed for the classification case and extended to time\nseries. We discuss the relatedness of observed time series and first deploy the\ndynamic time warping distance measure to identify groups of similar series.\nThen we take into account both time and scale warping and propose to align\nmultiple time series by inferring their common latent representation. We test\nthe proposed models on the problem of travel demand prediction in Nancy\n(France) public transport system and analyze the benefits of multi-task\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 11:04:14 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Chidlovskii", "Boris", ""]]}, {"id": "1712.08266", "submitter": "Saurabh Kumar", "authors": "Saurabh Kumar, Pararth Shah, Dilek Hakkani-Tur, Larry Heck", "title": "Federated Control with Hierarchical Multi-Agent Deep Reinforcement\n  Learning", "comments": "Hierarchical Reinforcement Learning Workshop at the 31st Conference\n  on Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework combining hierarchical and multi-agent deep\nreinforcement learning approaches to solve coordination problems among a\nmultitude of agents using a semi-decentralized model. The framework extends the\nmulti-agent learning setup by introducing a meta-controller that guides the\ncommunication between agent pairs, enabling agents to focus on communicating\nwith only one other agent at any step. This hierarchical decomposition of the\ntask allows for efficient exploration to learn policies that identify globally\noptimal solutions even as the number of collaborating agents increases. We show\npromising initial experimental results on a simulated distributed scheduling\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 00:54:48 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Kumar", "Saurabh", ""], ["Shah", "Pararth", ""], ["Hakkani-Tur", "Dilek", ""], ["Heck", "Larry", ""]]}, {"id": "1712.08290", "submitter": "Gopal Sharma", "authors": "Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis,\n  Subhransu Maji", "title": "CSGNet: Neural Shape Parser for Constructive Solid Geometry", "comments": "Accepted at CVPR-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural architecture that takes as input a 2D or 3D shape and\noutputs a program that generates the shape. The instructions in our program are\nbased on constructive solid geometry principles, i.e., a set of boolean\noperations on shape primitives defined recursively. Bottom-up techniques for\nthis shape parsing task rely on primitive detection and are inherently slow\nsince the search space over possible primitive combinations is large. In\ncontrast, our model uses a recurrent neural network that parses the input shape\nin a top-down manner, which is significantly faster and yields a compact and\neasy-to-interpret sequence of modeling instructions. Our model is also more\neffective as a shape detector compared to existing state-of-the-art detection\ntechniques. We finally demonstrate that our network can be trained on novel\ndatasets without ground-truth program annotations through policy gradient\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 03:18:57 GMT"}, {"version": "v2", "created": "Sat, 31 Mar 2018 18:03:22 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Sharma", "Gopal", ""], ["Goyal", "Rishabh", ""], ["Liu", "Difan", ""], ["Kalogerakis", "Evangelos", ""], ["Maji", "Subhransu", ""]]}, {"id": "1712.08296", "submitter": "Zilong Ye", "authors": "James Sunthonlap, Phuoc Nguyen, Zilong Ye", "title": "Intelligent Device Discovery in the Internet of Things - Enabling the\n  Robot Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is continuously growing to connect billions of\nsmart devices anywhere and anytime in an Internet-like structure, which enables\na variety of applications, services and interactions between human and objects.\nIn the future, the smart devices are supposed to be able to autonomously\ndiscover a target device with desired features and generate a set of entirely\nnew services and applications that are not supervised or even imagined by human\nbeings. The pervasiveness of smart devices, as well as the heterogeneity of\ntheir design and functionalities, raise a major concern: How can a smart device\nefficiently discover a desired target device? In this paper, we propose a\nSocial-Aware and Distributed (SAND) scheme that achieves a fast, scalable and\nefficient device discovery in the IoT. The proposed SAND scheme adopts a novel\ndevice ranking criteria that measures the device's degree, social relationship\ndiversity, clustering coefficient and betweenness. Based on the device ranking\ncriteria, the discovery request can be guided to travel through critical\ndevices that stand at the major intersections of the network, and thus quickly\nreach the desired target device by contacting only a limited number of\nintermediate devices. With the help of such an intelligent device discovery as\nSAND, the IoT devices, as well as other computing facilities, software and data\non the Internet, can autonomously establish new social connections with each\nother as human being do. They can formulate self-organized computing groups to\nperform required computing tasks, facilitate a fusion of a variety of computing\nservice, network service and data to generate novel applications and services,\nevolve from the individual aritificial intelligence to the collaborative\nintelligence, and eventually enable the birth of a robot society.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 03:45:36 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 22:40:38 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Sunthonlap", "James", ""], ["Nguyen", "Phuoc", ""], ["Ye", "Zilong", ""]]}, {"id": "1712.08443", "submitter": "Thibault Laugel", "authors": "Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier\n  Renard, Marcin Detyniecki", "title": "Inverse Classification for Comparison-based Interpretability in Machine\n  Learning", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of post-hoc interpretability, this paper addresses the task of\nexplaining the prediction of a classifier, considering the case where no\ninformation is available, neither on the classifier itself, nor on the\nprocessed data (neither the training nor the test data). It proposes an\ninstance-based approach whose principle consists in determining the minimal\nchanges needed to alter a prediction: given a data point whose classification\nmust be explained, the proposed method consists in identifying a close\nneighbour classified differently, where the closeness definition integrates a\nsparsity constraint. This principle is implemented using observation generation\nin the Growing Spheres algorithm. Experimental results on two datasets\nillustrate the relevance of the proposed approach that can be used to gain\nknowledge about the classifier.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 13:51:21 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Renard", "Xavier", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1712.08588", "submitter": "Kathryn Laing", "authors": "Kathryn Laing, Peter Adam Thwaites and John Paul Gosling", "title": "Rank Pruning for Dominance Queries in CP-Nets", "comments": "58 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional preference networks (CP-nets) are a graphical representation of a\nperson's (conditional) preferences over a set of discrete variables. In this\npaper, we introduce a novel method of quantifying preference for any given\noutcome based on a CP-net representation of a user's preferences. We\ndemonstrate that these values are useful for reasoning about user preferences.\nIn particular, they allow us to order (any subset of) the possible outcomes in\naccordance with the user's preferences. Further, these values can be used to\nimprove the efficiency of outcome dominance testing. That is, given a pair of\noutcomes, we can determine which the user prefers more efficiently. Through\nexperimental results, we show that this method is more effective than existing\ntechniques for improving dominance testing efficiency. We show that the above\nresults also hold for CP-nets that express indifference between variable\nvalues.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 17:41:11 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 13:41:55 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Laing", "Kathryn", ""], ["Thwaites", "Peter Adam", ""], ["Gosling", "John Paul", ""]]}, {"id": "1712.08626", "submitter": "Fattaneh Jabbari", "authors": "Fattaneh Jabbari, Mahdi Pakdaman Naeini, Gregory F. Cooper", "title": "Obtaining Accurate Probabilistic Causal Inference by Post-Processing\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of an accurate causal Bayesian network structure from observational\ndata can be useful in many areas of science. Often the discoveries are made\nunder uncertainty, which can be expressed as probabilities. To guide the use of\nsuch discoveries, including directing further investigation, it is important\nthat those probabilities be well-calibrated. In this paper, we introduce a\nnovel framework to derive calibrated probabilities of causal relationships from\nobservational data. The framework consists of three components: (1) an\napproximate method for generating initial probability estimates of the edge\ntypes for each pair of variables, (2) the availability of a relatively small\nnumber of the causal relationships in the network for which the truth status is\nknown, which we call a calibration training set, and (3) a calibration method\nfor using the approximate probability estimates and the calibration training\nset to generate calibrated probabilities for the many remaining pairs of\nvariables. We also introduce a new calibration method based on a shallow neural\nnetwork. Our experiments on simulated data support that the proposed approach\nimproves the calibration of causal edge predictions. The results also support\nthat the approach often improves the precision and recall of predictions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 19:15:15 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Jabbari", "Fattaneh", ""], ["Naeini", "Mahdi Pakdaman", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1712.08697", "submitter": "Alexander Trott", "authors": "Alexander Trott, Caiming Xiong, Richard Socher", "title": "Interpretable Counting for Visual Question Answering", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions that require counting a variety of objects in images remain a major\nchallenge in visual question answering (VQA). The most common approaches to VQA\ninvolve either classifying answers based on fixed length representations of\nboth the image and question or summing fractional counts estimated from each\nsection of the image. In contrast, we treat counting as a sequential decision\nprocess and force our model to make discrete choices of what to count.\nSpecifically, the model sequentially selects from detected objects and learns\ninteractions between objects that influence subsequent selections. A\ndistinction of our approach is its intuitive and interpretable output, as\ndiscrete counts are automatically grounded in the image. Furthermore, our\nmethod outperforms the state of the art architecture for VQA on multiple\nmetrics that evaluate counting.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 01:44:45 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 03:00:43 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Trott", "Alexander", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1712.08858", "submitter": "Tom Hanika", "authors": "Tom Hanika and Jens Zumbr\\\"agel", "title": "Towards Collaborative Conceptual Exploration", "comments": "15 pages, 2 figures", "journal-ref": "Graph-Based Representation and Reasoning, 120-134, LNAI 10872,\n  Springer", "doi": "10.1007/978-3-319-91379-7_10", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In domains with high knowledge distribution a natural objective is to create\nprinciple foundations for collaborative interactive learning environments. We\npresent a first mathematical characterization of a collaborative learning\ngroup, a consortium, based on closure systems of attribute sets and the\nwell-known attribute exploration algorithm from formal concept analysis. To\nthis end, we introduce (weak) local experts for subdomains of a given knowledge\ndomain. These entities are able to refute and potentially accept a given\n(implicational) query for some closure system that is a restriction of the\nwhole domain. On this we build up a consortial expert and show first insights\nabout the ability of such an expert to answer queries. Furthermore, we depict\ntechniques on how to cope with falsely accepted implications and on combining\ncounterexamples. Using notions from combinatorial design theory we further\nexpand those insights as far as providing first results on the decidability\nproblem if a given consortium is able to explore some target domain.\nApplications in conceptual knowledge acquisition as well as in collaborative\ninteractive ontology learning are at hand.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 23:25:08 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 15:16:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hanika", "Tom", ""], ["Zumbr\u00e4gel", "Jens", ""]]}, {"id": "1712.08875", "submitter": "arXiv Admin", "authors": "Meng Wang", "title": "Predicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs\n  and Text Jointly Embedding", "comments": "This article has been withdrawn by arXiv administrators due to an\n  unresolvable authorship dispute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing adverse reactions caused by drug-drug interactions has always been\na momentous research topic in clinical pharmacology. Detecting all possible\ninteractions through clinical studies before a drug is released to the market\nis a demanding task. The power of big data is opening up new approaches to\ndiscover various drug-drug interactions. However, these discoveries contain a\nhuge amount of noise and provide knowledge bases far from complete and\ntrustworthy ones to be utilized. Most existing studies focus on predicting\nbinary drug-drug interactions between drug pairs but ignore other interactions.\nIn this paper, we propose a novel framework, called PRD, to predict drug-drug\ninteractions. The framework uses the graph embedding that can overcome data\nincompleteness and sparsity issues to achieve multiple DDI label prediction.\nFirst, a large-scale drug knowledge graph is generated from different sources.\nThen, the knowledge graph is embedded with comprehensive biomedical text into a\ncommon low dimensional space. Finally, the learned embeddings are used to\nefficiently compute rich DDI information through a link prediction process. To\nvalidate the effectiveness of the proposed framework, extensive experiments\nwere conducted on real-world datasets. The results demonstrate that our model\noutperforms several state-of-the-art baseline methods in terms of capability\nand accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 04:43:46 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 01:31:22 GMT"}, {"version": "v3", "created": "Sat, 17 Feb 2018 04:56:57 GMT"}, {"version": "v4", "created": "Mon, 12 Mar 2018 16:34:16 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Wang", "Meng", ""]]}, {"id": "1712.08878", "submitter": "Alan Winfield", "authors": "Alan F. T. Winfield", "title": "How Intelligent is your Intelligent Robot?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How intelligent is robot A compared with robot B? And how intelligent are\nrobots A and B compared with animals (or plants) X and Y? These are both\ninteresting and deeply challenging questions. In this paper we address the\nquestion \"how intelligent is your intelligent robot?\" by proposing that\nembodied intelligence emerges from the interaction and integration of four\ndifferent and distinct kinds of intelligence. We then suggest a simple\ndiagrammatic representation on which these kinds of intelligence are shown as\nfour axes in a star diagram. A crude qualitative comparison of the intelligence\ngraphs of animals and robots both exposes and helps to explain the chronic\nintelligence deficit of intelligent robots. Finally we examine the options for\ndetermining numerical values for the four kinds of intelligence in an effort to\nmove toward a quantifiable intelligence vector.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 05:10:42 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Winfield", "Alan F. T.", ""]]}, {"id": "1712.08883", "submitter": "Shiliang Sun", "authors": "Shiliang Sun, Changshui Zhang, Yi Zhang", "title": "Traffic Flow Forecasting Using a Spatio-Temporal Bayesian Network\n  Predictor", "comments": null, "journal-ref": "The 15th International Conference on Artificial Neural Networks\n  (ICANN), 2005, pp. 273-278", "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel predictor for traffic flow forecasting, namely spatio-temporal\nBayesian network predictor, is proposed. Unlike existing methods, our approach\nincorporates all the spatial and temporal information available in a\ntransportation network to carry our traffic flow forecasting of the current\nsite. The Pearson correlation coefficient is adopted to rank the input\nvariables (traffic flows) for prediction, and the best-first strategy is\nemployed to select a subset as the cause nodes of a Bayesian network. Given the\nderived cause nodes and the corresponding effect node in the spatio-temporal\nBayesian network, a Gaussian Mixture Model is applied to describe the\nstatistical relationship between the input and output. Finally, traffic flow\nforecasting is performed under the criterion of Minimum Mean Square Error\n(M.M.S.E.). Experimental results with the urban vehicular flow data of Beijing\ndemonstrate the effectiveness of our presented spatio-temporal Bayesian network\npredictor.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 07:29:49 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Sun", "Shiliang", ""], ["Zhang", "Changshui", ""], ["Zhang", "Yi", ""]]}, {"id": "1712.08996", "submitter": "ElMouatez Billah Karbab", "authors": "ElMouatez Billah Karbab, Mourad Debbabi, Abdelouahid Derhab, Djedjiga\n  Mouheb", "title": "Android Malware Detection using Deep Learning on API Method Sequences", "comments": "17 pages, submitted to Elsevier Digital Investigations Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android OS experiences a blazing popularity since the last few years. This\npredominant platform has established itself not only in the mobile world but\nalso in the Internet of Things (IoT) devices. This popularity, however, comes\nat the expense of security, as it has become a tempting target of malicious\napps. Hence, there is an increasing need for sophisticated, automatic, and\nportable malware detection solutions. In this paper, we propose MalDozer, an\nautomatic Android malware detection and family attribution framework that\nrelies on sequences classification using deep learning techniques. Starting\nfrom the raw sequence of the app's API method calls, MalDozer automatically\nextracts and learns the malicious and the benign patterns from the actual\nsamples to detect Android malware. MalDozer can serve as a ubiquitous malware\ndetection system that is not only deployed on servers, but also on mobile and\neven IoT devices. We evaluate MalDozer on multiple Android malware datasets\nranging from 1K to 33K malware apps, and 38K benign apps. The results show that\nMalDozer can correctly detect malware and attribute them to their actual\nfamilies with an F1-Score of 96%-99% and a false positive rate of 0.06%-2%,\nunder all tested datasets and settings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 03:26:21 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Karbab", "ElMouatez Billah", ""], ["Debbabi", "Mourad", ""], ["Derhab", "Abdelouahid", ""], ["Mouheb", "Djedjiga", ""]]}, {"id": "1712.09014", "submitter": "Michael Gagen Dr", "authors": "M. J. Gagen", "title": "Null Dynamical State Models of Human Cognitive Dysfunction", "comments": "17 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hard problem in artificial intelligence asks how the shuffling of\nsyntactical symbols in a program can lead to systems which experience semantics\nand qualia. We address this question in three stages. First, we introduce a new\nclass of human semantic symbols which appears when unexpected and drastic\nenvironmental change causes humans to become surprised, confused, uncertain,\nand in extreme cases, unresponsive, passive and dysfunctional. For this class\nof symbols, pre-learned programs become inoperative so these syntactical\nprograms cannot be the source of experienced qualia. Second, we model the\ndysfunctional human response to a radically changed environment as being the\nnatural response of any learning machine facing novel inputs from well outside\nits previous training set. In this situation, learning machines are unable to\nextract information from their input and will typically enter a dynamical state\ncharacterized by null outputs and a lack of response. This state immediately\npredicts and explains the characteristics of the semantic experiences of humans\nin similar circumstances. In the third stage, we consider learning machines\ntrained to implement multiple functions in simple sequential programs using\nenvironmental data to specify subroutine names, control flow instructions,\nmemory calls, and so on. Drastic change in any of these environmental inputs\ncan again lead to inoperative programs. By examining changes specific to people\nor locations we can model human cognitive symbols featuring these dependencies,\nsuch as attachment and grief. Our approach links known dynamical machines\nstates with human qualia and thus offers new insight into the hard problem of\nartificial intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 05:46:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gagen", "M. J.", ""]]}, {"id": "1712.09131", "submitter": "Giovanni Chierchia", "authors": "Luis M. Briceno-Arias, Giovanni Chierchia, Emilie Chouzenoux,\n  Jean-Christophe Pesquet", "title": "A Random Block-Coordinate Douglas-Rachford Splitting Method with Low\n  Computational Complexity for Binary Logistic Regression", "comments": null, "journal-ref": null, "doi": "10.1007/s10589-019-00060-6", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new optimization algorithm for sparse logistic\nregression based on a stochastic version of the Douglas-Rachford splitting\nmethod. Our algorithm sweeps the training set by randomly selecting a\nmini-batch of data at each iteration, and it allows us to update the variables\nin a block coordinate manner. Our approach leverages the proximity operator of\nthe logistic loss, which is expressed with the generalized Lambert W function.\nExperiments carried out on standard datasets demonstrate the efficiency of our\napproach w.r.t. stochastic gradient-like methods.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 21:04:03 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Briceno-Arias", "Luis M.", ""], ["Chierchia", "Giovanni", ""], ["Chouzenoux", "Emilie", ""], ["Pesquet", "Jean-Christophe", ""]]}, {"id": "1712.09227", "submitter": "Murat Ozbayoglu", "authors": "A. Murat Ozbayoglu, Gokhan Kucukayan, Erdogan Dogdu", "title": "A Real-Time Autonomous Highway Accident Detection Model Based on Big\n  Data Processing and Computational Intelligence", "comments": null, "journal-ref": "IEEE International Conference on Big Data, (2016), pp.1807-1813,\n  Washington D.C. 5-8 December, 2016", "doi": "10.1109/BigData.2016.7840798", "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing urban population and growing number of motor vehicles,\ntraffic congestion is becoming a major problem of the 21st century. One of the\nmain reasons behind traffic congestion is accidents which can not only result\nin casualties and losses for the participants, but also in wasted and lost time\nfor the others that are stuck behind the wheels. Early detection of an accident\ncan save lives, provides quicker road openings, hence decreases wasted time and\nresources, and increases efficiency. In this study, we propose a preliminary\nreal-time autonomous accident-detection system based on computational\nintelligence techniques. Istanbul City traffic-flow data for the year 2015 from\nvarious sensor locations are populated using big data processing methodologies.\nThe extracted features are then fed into a nearest neighbor model, a regression\ntree, and a feed-forward neural network model. For the output, the possibility\nof an occurrence of an accident is predicted. The results indicate that even\nthough the number of false alarms dominates the real accident cases, the system\ncan still provide useful information that can be used for status verification\nand early reaction to possible accidents.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 10:17:13 GMT"}], "update_date": "2018-01-02", "authors_parsed": [["Ozbayoglu", "A. Murat", ""], ["Kucukayan", "Gokhan", ""], ["Dogdu", "Erdogan", ""]]}, {"id": "1712.09327", "submitter": "Yousef Fadila", "authors": "Arkar Min Aung, Yousef Fadila, Radian Gondokaryono, Luis Gonzalez", "title": "Building Robust Deep Neural Networks for Road Sign Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are built to generalize outside of training set in mind\nby using techniques such as regularization, early stopping and dropout. But\nconsiderations to make them more resilient to adversarial examples are rarely\ntaken. As deep neural networks become more prevalent in mission-critical and\nreal-time systems, miscreants start to attack them by intentionally making deep\nneural networks to misclassify an object of one type to be seen as another\ntype. This can be catastrophic in some scenarios where the classification of a\ndeep neural network can lead to a fatal decision by a machine. In this work, we\nused GTSRB dataset to craft adversarial samples by Fast Gradient Sign Method\nand Jacobian Saliency Method, used those crafted adversarial samples to attack\nanother Deep Convolutional Neural Network and built the attacked network to be\nmore resilient against adversarial attacks by making it more robust by\nDefensive Distillation and Adversarial Training\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 18:52:41 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Aung", "Arkar Min", ""], ["Fadila", "Yousef", ""], ["Gondokaryono", "Radian", ""], ["Gonzalez", "Luis", ""]]}, {"id": "1712.09344", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "Whatever Does Not Kill Deep Reinforcement Learning, Makes It Stronger", "comments": "arXiv admin note: text overlap with arXiv:1701.04143", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments have established the vulnerability of deep Reinforcement\nLearning (RL) to policy manipulation attacks via adversarial perturbations. In\nthis paper, we investigate the robustness and resilience of deep RL to\ntraining-time and test-time attacks. Through experimental results, we\ndemonstrate that under noncontiguous training-time attacks, Deep Q-Network\n(DQN) agents can recover and adapt to the adversarial conditions by reactively\nadjusting the policy. Our results also show that policies learned under\nadversarial perturbations are more robust to test-time attacks. Furthermore, we\ncompare the performance of $\\epsilon$-greedy and parameter-space noise\nexploration methods in terms of robustness and resilience against adversarial\nperturbations.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 23:57:55 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1712.09356", "submitter": "Ming Zhu", "authors": "Ming Zhu, Xiao-Yang Liu, and Xiaodong Wang", "title": "An Online Ride-Sharing Path Planning Strategy for Public Vehicle Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As efficient traffic-management platforms, public vehicle (PV) systems are\nenvisioned to be a promising approach to solving traffic congestions and\npollutions for future smart cities. PV systems provide online/dynamic\npeer-to-peer ride-sharing services with the goal of serving sufficient number\nof customers with minimum number of vehicles and lowest possible cost. A key\ncomponent of the PV system is the online ride-sharing scheduling strategy. In\nthis paper, we propose an efficient path planning strategy that focuses on a\nlimited potential search area for each vehicle by filtering out the requests\nthat violate passenger service quality level, so that the global search is\nreduced to local search. We analyze the performance of the proposed solution\nsuch as reduction ratio of computational complexity. Simulations based on the\nManhattan taxi data set show that, the computing time is reduced by 22%\ncompared with the exhaustive search method under the same service quality\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 01:48:47 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Zhu", "Ming", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1712.09374", "submitter": "Hang Zhao", "authors": "Hang Zhao, Antonio Torralba, Lorenzo Torresani, Zhicheng Yan", "title": "HACS: Human Action Clips and Segments Dataset for Recognition and\n  Temporal Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new large-scale dataset for recognition and temporal\nlocalization of human actions collected from Web videos. We refer to it as HACS\n(Human Action Clips and Segments). We leverage both consensus and disagreement\namong visual classifiers to automatically mine candidate short clips from\nunlabeled videos, which are subsequently validated by human annotators. The\nresulting dataset is dubbed HACS Clips. Through a separate process we also\ncollect annotations defining action segment boundaries. This resulting dataset\nis called HACS Segments. Overall, HACS Clips consists of 1.5M annotated clips\nsampled from 504K untrimmed videos, and HACS Seg-ments contains 139K action\nsegments densely annotatedin 50K untrimmed videos spanning 200 action\ncategories. HACS Clips contains more labeled examples than any existing video\nbenchmark. This renders our dataset both a large scale action recognition\nbenchmark and an excellent source for spatiotemporal feature learning. In our\ntransferlearning experiments on three target datasets, HACS Clips outperforms\nKinetics-600, Moments-In-Time and Sports1Mas a pretraining source. On HACS\nSegments, we evaluate state-of-the-art methods of action proposal generation\nand action localization, and highlight the new challenges posed by our dense\ntemporal annotations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:09:11 GMT"}, {"version": "v2", "created": "Sat, 12 Jan 2019 21:49:09 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 07:35:48 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Zhao", "Hang", ""], ["Torralba", "Antonio", ""], ["Torresani", "Lorenzo", ""], ["Yan", "Zhicheng", ""]]}, {"id": "1712.09381", "submitter": "Richard Liaw", "authors": "Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox,\n  Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica", "title": "RLlib: Abstractions for Distributed Reinforcement Learning", "comments": "Published in the International Conference on Machine Learning (ICML\n  2018), 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms involve the deep nesting of highly\nirregular computation patterns, each of which typically exhibits opportunities\nfor distributed computation. We argue for distributing RL components in a\ncomposable way by adapting algorithms for top-down hierarchical control,\nthereby encapsulating parallelism and resource requirements within\nshort-running compute tasks. We demonstrate the benefits of this principle\nthrough RLlib: a library that provides scalable software primitives for RL.\nThese primitives enable a broad range of algorithms to be implemented with high\nperformance, scalability, and substantial code reuse. RLlib is available at\nhttps://rllib.io/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 19:43:59 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 02:40:19 GMT"}, {"version": "v3", "created": "Mon, 19 Mar 2018 00:01:53 GMT"}, {"version": "v4", "created": "Fri, 29 Jun 2018 00:19:24 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Liang", "Eric", ""], ["Liaw", "Richard", ""], ["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Fox", "Roy", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1712.09444", "submitter": "Ronan Collobert", "authors": "Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan Collobert", "title": "Letter-Based Speech Recognition with Gated ConvNets", "comments": "13 pages.arXiv admin note: text overlap with arXiv:1609.03193", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent literature, \"end-to-end\" speech systems often refer to\nletter-based acoustic models trained in a sequence-to-sequence manner, either\nvia a recurrent model or via a structured output learning approach (such as\nCTC). In contrast to traditional phone (or senone)-based approaches, these\n\"end-to-end'' approaches alleviate the need of word pronunciation modeling, and\ndo not require a \"forced alignment\" step at training time. Phone-based\napproaches remain however state of the art on classical benchmarks. In this\npaper, we propose a letter-based speech recognition system, leveraging a\nConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units\nand high dropout. The ConvNet is trained to map audio sequences to their\ncorresponding letter transcriptions, either via a classical CTC approach, or\nvia a recent variant called ASG. Coupled with a simple decoder at inference\ntime, our system matches the best existing letter-based systems on WSJ (in word\nerror rate), and shows near state of the art performance on LibriSpeech.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 17:42:15 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2019 01:19:21 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Liptchinsky", "Vitaliy", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""]]}, {"id": "1712.09644", "submitter": "William Mayner", "authors": "William G. P. Mayner, William Marshall, Larissa Albantakis, Graham\n  Findlay, Robert Marchman, Giulio Tononi", "title": "PyPhi: A toolbox for integrated information theory", "comments": "22 pages, 4 figures, 6 pages of appendices. Supporting information\n  \"S1 Calculating Phi\" can be found in the ancillary files", "journal-ref": "PLOS Computational Biology 14(7): e1006343. 2018", "doi": "10.1371/journal.pcbi.1006343", "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Integrated information theory provides a mathematical framework to fully\ncharacterize the cause-effect structure of a physical system. Here, we\nintroduce PyPhi, a Python software package that implements this framework for\ncausal analysis and unfolds the full cause-effect structure of discrete\ndynamical systems of binary elements. The software allows users to easily study\nthese structures, serves as an up-to-date reference implementation of the\nformalisms of integrated information theory, and has been applied in research\non complexity, emergence, and certain biological questions. We first provide an\noverview of the main algorithm and demonstrate PyPhi's functionality in the\ncourse of analyzing an example system, and then describe details of the\nalgorithm's design and implementation.\n  PyPhi can be installed with Python's package manager via the command 'pip\ninstall pyphi' on Linux and macOS systems equipped with Python 3.4 or higher.\nPyPhi is open-source and licensed under the GPLv3; the source code is hosted on\nGitHub at https://github.com/wmayner/pyphi . Comprehensive and\ncontinually-updated documentation is available at https://pyphi.readthedocs.io/\n. The pyphi-users mailing list can be joined at\nhttps://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical\ninterface to the software is available at\nhttp://integratedinformationtheory.org/calculate.html .\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 18:01:12 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 17:45:30 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 09:52:27 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Mayner", "William G. P.", ""], ["Marshall", "William", ""], ["Albantakis", "Larissa", ""], ["Findlay", "Graham", ""], ["Marchman", "Robert", ""], ["Tononi", "Giulio", ""]]}, {"id": "1712.09657", "submitter": "Dj Strouse", "authors": "DJ Strouse, David J Schwab", "title": "The information bottleneck and geometric clustering", "comments": "Updated to final published version with more detailed relationship to\n  GMMs/k-means", "journal-ref": "Neural Computation 31 (2019) 596-612", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck (IB) approach to clustering takes a joint\ndistribution $P\\!\\left(X,Y\\right)$ and maps the data $X$ to cluster labels $T$\nwhich retain maximal information about $Y$ (Tishby et al., 1999). This\nobjective results in an algorithm that clusters data points based upon the\nsimilarity of their conditional distributions $P\\!\\left(Y\\mid X\\right)$. This\nis in contrast to classic \"geometric clustering'' algorithms such as $k$-means\nand gaussian mixture models (GMMs) which take a set of observed data points\n$\\left\\{ \\mathbf{x}_{i}\\right\\} _{i=1:N}$ and cluster them based upon their\ngeometric (typically Euclidean) distance from one another. Here, we show how to\nuse the deterministic information bottleneck (DIB) (Strouse and Schwab, 2017),\na variant of IB, to perform geometric clustering, by choosing cluster labels\nthat preserve information about data point location on a smoothed dataset. We\nalso introduce a novel method to choose the number of clusters, based on\nidentifying solutions where the tradeoff between number of clusters used and\nspatial information preserved is strongest. We apply this approach to a variety\nof simple clustering problems, showing that DIB with our model selection\nprocedure recovers the generative cluster labels. We also show that, in\nparticular limits of our model parameters, clustering with DIB and IB is\nequivalent to $k$-means and EM fitting of a GMM with hard and soft assignments,\nrespectively. Thus, clustering with (D)IB generalizes and provides an\ninformation-theoretic perspective on these classic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 19:04:49 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 15:55:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Strouse", "DJ", ""], ["Schwab", "David J", ""]]}, {"id": "1712.09709", "submitter": "Qiangeng Xu", "authors": "Qiangeng Xu, John Kender", "title": "Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro\n  Gesture", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the research of the impact of gestures using by a lecturer, one\nchallenging task is to infer the attention of a group of audiences. Two\nimportant measurements that can help infer the level of attention are eye\nmovement data and Electroencephalography (EEG) data. Under the fundamental\nassumption that a group of people would look at the same place if they all pay\nattention at the same time, we apply a method, \"Time Warp Edit Distance\", to\ncalculate the similarity of their eye movement trajectories. Moreover, we also\ncluster eye movement pattern of audiences based on these pair-wised similarity\nmetrics. Besides, since we don't have a direct metric for the \"attention\"\nground truth, a visual assessment would be beneficial to evaluate the\ngesture-attention relationship. Thus we also implement a visualization tool.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:26:30 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 18:36:29 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Xu", "Qiangeng", ""], ["Kender", "John", ""]]}, {"id": "1712.09923", "submitter": "Andreas Holzinger", "authors": "Andreas Holzinger, Chris Biemann, Constantinos S. Pattichis, Douglas\n  B. Kell", "title": "What do we need to build explainable AI systems for the medical domain?", "comments": "This is a survey article and section 3.1. draws heavily from\n  arXiv:1706.07979", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) generally and machine learning (ML) specifically\ndemonstrate impressive practical success in many different application domains,\ne.g. in autonomous driving, speech recognition, or recommender systems. Deep\nlearning approaches, trained on extremely large data sets or using\nreinforcement learning methods have even exceeded human performance in visual\ntasks, particularly on playing games such as Atari, or mastering the game of\nGo. Even in the medical domain there are remarkable results. The central\nproblem of such models is that they are regarded as black-box models and even\nif we understand the underlying mathematical principles, they lack an explicit\ndeclarative knowledge representation, hence have difficulty in generating the\nunderlying explanatory structures. This calls for systems enabling to make\ndecisions transparent, understandable and explainable. A huge motivation for\nour approach are rising legal and privacy aspects. The new European General\nData Protection Regulation entering into force on May 25th 2018, will make\nblack-box approaches difficult to use in business. This does not imply a ban on\nautomatic learning approaches or an obligation to explain everything all the\ntime, however, there must be a possibility to make the results re-traceable on\ndemand. In this paper we outline some of our research topics in the context of\nthe relatively new area of explainable-AI with a focus on the application in\nmedicine, which is a very special domain. This is due to the fact that medical\nprofessionals are working mostly with distributed heterogeneous and complex\nsources of data. In this paper we concentrate on three sources: images, *omics\ndata and text. We argue that research in explainable-AI would generally help to\nfacilitate the implementation of AI/ML in the medical domain, and specifically\nhelp to facilitate transparency and trust.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 16:46:05 GMT"}], "update_date": "2018-01-02", "authors_parsed": [["Holzinger", "Andreas", ""], ["Biemann", "Chris", ""], ["Pattichis", "Constantinos S.", ""], ["Kell", "Douglas B.", ""]]}, {"id": "1712.09943", "submitter": "Sungjin Lee", "authors": "Sungjin Lee", "title": "Toward Continual Learning for Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end neural conversation models have led to promising advances in\nreducing hand-crafted features and errors induced by the traditional complex\nsystem architecture, they typically require an enormous amount of data due to\nthe lack of modularity. Previous studies adopted a hybrid approach with\nknowledge-based components either to abstract out domain-specific information\nor to augment data to cover more diverse patterns. On the contrary, we propose\nto directly address the problem using recent developments in the space of\ncontinual learning for neural models. Specifically, we adopt a\ndomain-independent neural conversational model and introduce a novel neural\ncontinual learning algorithm that allows a conversational agent to accumulate\nskills across different tasks in a data-efficient way. To the best of our\nknowledge, this is the first work that applies continual learning to\nconversation systems. We verified the efficacy of our method through a\nconversational skill transfer from either synthetic dialogs or human-human\ndialogs to human-computer conversations in a customer support domain.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 17:21:42 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 19:19:52 GMT"}, {"version": "v3", "created": "Tue, 9 Jan 2018 17:53:37 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Lee", "Sungjin", ""]]}, {"id": "1712.10011", "submitter": "Pooyan Ehsani", "authors": "Pooyan Ehsani, Jia Yuan Yu", "title": "The Merits of Sharing a Ride", "comments": null, "journal-ref": null, "doi": "10.1109/ALLERTON.2017.8262818", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The culture of sharing instead of ownership is sharply increasing in\nindividuals behaviors. Particularly in transportation, concepts of sharing a\nride in either carpooling or ridesharing have been recently adopted. An\nefficient optimization approach to match passengers in real-time is the core of\nany ridesharing system. In this paper, we model ridesharing as an online\nmatching problem on general graphs such that passengers do not drive private\ncars and use shared taxis. We propose an optimization algorithm to solve it.\nThe outlined algorithm calculates the optimal waiting time when a passenger\narrives. This leads to a matching with minimal overall overheads while\nmaximizing the number of partnerships. To evaluate the behavior of our\nalgorithm, we used NYC taxi real-life data set. Results represent a substantial\nreduction in overall overheads.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 15:58:24 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Ehsani", "Pooyan", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1712.10050", "submitter": "Anqi Liu", "authors": "Anqi Liu, Rizal Fathony, Brian D. Ziebart", "title": "Kernel Robust Bias-Aware Prediction under Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:23:18 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Liu", "Anqi", ""], ["Fathony", "Rizal", ""], ["Ziebart", "Brian D.", ""]]}, {"id": "1712.10054", "submitter": "Edgar Altszyler", "authors": "Edgar Altszyler, Mariano Sigman and Diego Fernandez Slezak", "title": "Corpus specificity in LSA and Word2vec: the role of out-of-domain\n  documents", "comments": null, "journal-ref": "Proceedings of the 3rd Workshop on Representation Learning for\n  NLP, pages 1-10, 2018, ACL", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Semantic Analysis (LSA) and Word2vec are some of the most widely used\nword embeddings. Despite the popularity of these techniques, the precise\nmechanisms by which they acquire new semantic relations between words remain\nunclear. In the present article we investigate whether LSA and Word2vec\ncapacity to identify relevant semantic dimensions increases with size of\ncorpus. One intuitive hypothesis is that the capacity to identify relevant\ndimensions should increase as the amount of data increases. However, if corpus\nsize grow in topics which are not specific to the domain of interest, signal to\nnoise ratio may weaken. Here we set to examine and distinguish these\nalternative hypothesis. To investigate the effect of corpus specificity and\nsize in word-embeddings we study two ways for progressive elimination of\ndocuments: the elimination of random documents vs. the elimination of documents\nunrelated to a specific task. We show that Word2vec can take advantage of all\nthe documents, obtaining its best performance when it is trained with the whole\ncorpus. On the contrary, the specialization (removal of out-of-domain\ndocuments) of the training corpus, accompanied by a decrease of dimensionality,\ncan increase LSA word-representation quality while speeding up the processing\ntime. Furthermore, we show that the specialization without the decrease in LSA\ndimensionality can produce a strong performance reduction in specific tasks.\nFrom a cognitive-modeling point of view, we point out that LSA's word-knowledge\nacquisitions may not be efficiently exploiting higher-order co-occurrences and\nglobal relations, whereas Word2vec does.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 20:56:16 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Altszyler", "Edgar", ""], ["Sigman", "Mariano", ""], ["Slezak", "Diego Fernandez", ""]]}, {"id": "1712.10070", "submitter": "James Foster", "authors": "James M. Foster and Matt Jones", "title": "Reinforcement Learning with Analogical Similarity to Guide Schema\n  Induction and Attention", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in analogical reasoning suggests that higher-order cognitive\nfunctions such as abstract reasoning, far transfer, and creativity are founded\non recognizing structural similarities among relational systems. Here we\nintegrate theories of analogy with the computational framework of reinforcement\nlearning (RL). We propose a psychology theory that is a computational synergy\nbetween analogy and RL, in which analogical comparison provides the RL learning\nalgorithm with a measure of relational similarity, and RL provides feedback\nsignals that can drive analogical learning. Simulation results support the\npower of this approach.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 22:11:53 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Foster", "James M.", ""], ["Jones", "Matt", ""]]}, {"id": "1712.10179", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan J. Merelo-Guerv\\'os, Antonio Fern\\'andez-Ares, Antonio \\'Alvarez\n  Caballero, Pablo Garc\\'ia-S\\'anchez, Victor Rivas", "title": "RedDwarfData: a simplified dataset of StarCraft matches", "comments": null, "journal-ref": null, "doi": null, "report-no": "GeNeura 2017-12-01", "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The game Starcraft is one of the most interesting arenas to test new machine\nlearning and computational intelligence techniques; however, StarCraft matches\ntake a long time and creating a good dataset for training can be hard. Besides,\nanalyzing match logs to extract the main characteristics can also be done in\nmany different ways to the point that extracting and processing data itself can\ntake an inordinate amount of time and of course, depending on what you choose,\ncan bias learning algorithms. In this paper we present a simplified dataset\nextracted from the set of matches published by Robinson and Watson, which we\nhave called RedDwarfData, containing several thousand matches processed to\nframes, so that temporal studies can also be undertaken. This dataset is\navailable from GitHub under a free license. An initial analysis and appraisal\nof these matches is also made.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 11:06:16 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Merelo-Guerv\u00f3s", "Juan J.", ""], ["Fern\u00e1ndez-Ares", "Antonio", ""], ["Caballero", "Antonio \u00c1lvarez", ""], ["Garc\u00eda-S\u00e1nchez", "Pablo", ""], ["Rivas", "Victor", ""]]}, {"id": "1712.10248", "submitter": "Jong Chul Ye", "authors": "Yoseob Han, Jawook Gu, Jong Chul Ye", "title": "Deep Learning Interior Tomography for Region-of-Interest Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interior tomography for the region-of-interest (ROI) imaging has advantages\nof using a small detector and reducing X-ray radiation dose. However, standard\nanalytic reconstruction suffers from severe cupping artifacts due to existence\nof null space in the truncated Radon transform. Existing penalized\nreconstruction methods may address this problem but they require extensive\ncomputations due to the iterative reconstruction. Inspired by the recent deep\nlearning approaches to low-dose and sparse view CT, here we propose a deep\nlearning architecture that removes null space signals from the FBP\nreconstruction. Experimental results have shown that the proposed method\nprovides near-perfect reconstruction with about 7-10 dB improvement in PSNR\nover existing methods in spite of significantly reduced run-time complexity.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 14:59:41 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 15:54:24 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Han", "Yoseob", ""], ["Gu", "Jawook", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1712.10280", "submitter": "Hongbo Jia", "authors": "Hongbo Jia", "title": "First Draft on the xInf Model for Universal Physical Computation and\n  Reverse Engineering of Natural Intelligence", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Turing Machines are universal computing machines in theory. It has been a\nlong debate whether Turing Machines can simulate the consciousness mind\nbehaviors in the materialistic universe. Three different hypotheses come out of\nsuch debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can.\nBecause Turing Machines or other kinds of theoretical computing models are\nabstract objects while behaviors are real observables, this debate involves at\nleast three distinct fields of science and technology: physics, computer\nengineering, and experimental neuroscience. However, the languages used in\nthese different fields are highly heterogeneous and not easily interpretable\nfor each other, making it very difficult to reach partial agreements regarding\nthis debate, Therefore, the main goal of this manuscript is to establish a\nproper language that can translate among those different fields. First, I\npropose a theoretical model for analyzing how theoretical computing machines\nwould physically run in physical time. This model, termed as the xInf, is at\nfirst place Turing-complete in theory, and depending on the properties of\nphysical time, it can be either Turing-equivalent or Super-Turing in the\nphysical universe. The xInf Model is demonstrated to be a suitable universal\nlanguage to translate among physics, computer engineering, and neuroscience.\nFinally, I propose a conjecture that there exists a Minimal Complete Set of\nrules in the xInf Model that enables the construction of a physical machine\nusing inorganic materials that can pass the Turing Test in physical time. I\ncannot demonstrate whether such a conjecture to be testified or falsified on\npaper using finite-order logic, my only solution is physical time itself, i.e.\nan evolutionary competition will eventually tell the conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 23:36:43 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Jia", "Hongbo", ""]]}]