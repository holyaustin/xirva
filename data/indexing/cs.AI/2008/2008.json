[{"id": "2008.00032", "submitter": "Cristina Zuheros", "authors": "Cristina Zuheros, Eugenio Mart\\'inez-C\\'amara, Enrique Herrera-Viedma,\n  and Francisco Herrera", "title": "Sentiment Analysis based Multi-person Multi-criteria Decision Making\n  Methodology using Natural Language Processing and Deep Learning for Smarter\n  Decision Aid. Case study of restaurant choice using TripAdvisor reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making models are constrained by taking the expert evaluations with\npre-defined numerical or linguistic terms. We claim that the use of sentiment\nanalysis will allow decision making models to consider expert evaluations in\nnatural language. Accordingly, we propose the Sentiment Analysis based\nMulti-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter\ndecision aid, which builds the expert evaluations from their natural language\nreviews, and even from their numerical ratings if they are available. The\nSA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model\nfor aspect based sentiment analysis, named DOC-ABSADeepL model, able to\nidentify the aspect categories mentioned in an expert review, and to distill\ntheir opinions and criteria. The individual evaluations are aggregated via the\nprocedure named criteria weighting through the attention of the experts. We\nevaluate the methodology in a case study of restaurant choice using TripAdvisor\nreviews, hence we build, manually annotate, and release the TripR-2020 dataset\nof restaurant reviews. We analyze the SA-MpMcDM methodology in different\nscenarios using and not using natural language and numerical evaluations. The\nanalysis shows that the combination of both sources of information results in a\nhigher quality preference vector.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:45:52 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:18:41 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zuheros", "Cristina", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Herrera-Viedma", "Enrique", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.00103", "submitter": "Peter Christen", "authors": "David J. Hand, Peter Christen, Nishadi Kirielle", "title": "F*: An Interpretable Transformation of the F-measure", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The F-measure, also known as the F1-score, is widely used to assess the\nperformance of classification algorithms. However, some researchers find it\nlacking in intuitive interpretation, questioning the appropriateness of\ncombining two aspects of performance as conceptually distinct as precision and\nrecall, and also questioning whether the harmonic mean is the best way to\ncombine them. To ease this concern, we describe a simple transformation of the\nF-measure, which we call F* (F-star), which has an immediate practical\ninterpretation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:37:08 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 22:26:20 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 02:03:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hand", "David J.", ""], ["Christen", "Peter", ""], ["Kirielle", "Nishadi", ""]]}, {"id": "2008.00104", "submitter": "Elliot Creager", "authors": "Martin Mladenov, Elliot Creager, Omer Ben-Porat, Kevin Swersky,\n  Richard Zemel, Craig Boutilier", "title": "Optimizing Long-term Social Welfare in Recommender Systems: A\n  Constrained Matching Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recommender systems (RS) research assumes that a user's utility can be\nmaximized independently of the utility of the other agents (e.g., other users,\ncontent providers). In realistic settings, this is often not true---the\ndynamics of an RS ecosystem couple the long-term utility of all agents. In this\nwork, we explore settings in which content providers cannot remain viable\nunless they receive a certain level of user engagement. We formulate the\nrecommendation problem in this setting as one of equilibrium selection in the\ninduced dynamical system, and show that it can be solved as an optimal\nconstrained matching problem. Our model ensures the system reaches an\nequilibrium with maximal social welfare supported by a sufficiently diverse set\nof viable providers. We demonstrate that even in a simple, stylized dynamical\nRS model, the standard myopic approach to recommendation---always matching a\nuser to the best provider---performs poorly. We develop several scalable\ntechniques to solve the matching problem, and also draw connections to various\nnotions of user regret and fairness, arguing that these outcomes are fairer in\na utilitarian sense.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:40:47 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 20:57:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Mladenov", "Martin", ""], ["Creager", "Elliot", ""], ["Ben-Porat", "Omer", ""], ["Swersky", "Kevin", ""], ["Zemel", "Richard", ""], ["Boutilier", "Craig", ""]]}, {"id": "2008.00120", "submitter": "Lasse Blaauwbroek", "authors": "Lasse Blaauwbroek, Josef Urban and Herman Geuvers", "title": "The Tactician (extended version): A Seamless, Interactive Tactic Learner\n  and Prover for Coq", "comments": "19 pages, 2 figures. This is an extended version of a paper published\n  in CICM-2020. For the project website, see https://coq-tactician.github.io", "journal-ref": "In CICM. volume 12236 of Lecture Notes in Computer Science, pages\n  271-277. Springer, 2020", "doi": "10.1007/978-3-030-53518-6_17", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Tactician, a tactic learner and prover for the Coq Proof\nAssistant. Tactician helps users make tactical proof decisions while they\nretain control over the general proof strategy. To this end, Tactician learns\nfrom previously written tactic scripts and gives users either suggestions about\nthe next tactic to be executed or altogether takes over the burden of proof\nsynthesis. Tactician's goal is to provide users with a seamless, interactive,\nand intuitive experience together with robust and adaptive proof automation. In\nthis paper, we give an overview of Tactician from the user's point of view,\nregarding both day-to-day usage and issues of package dependency management\nwhile learning in the large. Finally, we give a peek into Tactician's\nimplementation as a Coq plugin and machine learning platform.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:47:29 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Blaauwbroek", "Lasse", ""], ["Urban", "Josef", ""], ["Geuvers", "Herman", ""]]}, {"id": "2008.00150", "submitter": "Mohammed Hamzah Abed", "authors": "Sarah Hussein Toman, Mohammed Hamzah Abed, Zinah Hussein Toman", "title": "Cluster-Based Information Retrieval by using (K-means)- Hierarchical\n  Parallel Genetic Algorithms Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster-based information retrieval is one of the Information retrieval(IR)\ntools that organize, extract features and categorize the web documents\naccording to their similarity. Unlike traditional approaches, cluster-based IR\nis fast in processing large datasets of document. To improve the quality of\nretrieved documents, increase the efficiency of IR and reduce irrelevant\ndocuments from user search. in this paper, we proposed a (K-means) -\nHierarchical Parallel Genetic Algorithms Approach (HPGA) that combines the\nK-means clustering algorithm with hybrid PG of multi-deme and master/slave PG\nalgorithms. K-means uses to cluster the population to k subpopulations then\ntake most clusters relevant to the query to manipulate in a parallel way by the\ntwo levels of genetic parallelism, thus, irrelevant documents will not be\nincluded in subpopulations, as a way to improve the quality of results. Three\ncommon datasets (NLP, CISI, and CACM) are used to compute the recall,\nprecision, and F-measure averages. Finally, we compared the precision values of\nthree datasets with Genetic-IR and classic-IR. The proposed approach precision\nimprovements with IR-GA were 45% in the CACM, 27% in the CISI, and 25% in the\nNLP. While, by comparing with Classic-IR, (k-means)-HPGA got 47% in CACM, 28%\nin CISI, and 34% in NLP.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 02:05:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Toman", "Sarah Hussein", ""], ["Abed", "Mohammed Hamzah", ""], ["Toman", "Zinah Hussein", ""]]}, {"id": "2008.00178", "submitter": "Mohit Prabhushankar", "authors": "Mohit Prabhushankar, Gukyeong Kwon, Dogancan Temel, and Ghassan\n  AlRegib", "title": "Contrastive Explanations in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual explanations are logical arguments based on visual features that\njustify the predictions made by neural networks. Current modes of visual\nexplanations answer questions of the form $`Why \\text{ } P?'$. These $Why$\nquestions operate under broad contexts thereby providing answers that are\nirrelevant in some cases. We propose to constrain these $Why$ questions based\non some context $Q$ so that our explanations answer contrastive questions of\nthe form $`Why \\text{ } P, \\text{} rather \\text{ } than \\text{ } Q?'$. In this\npaper, we formalize the structure of contrastive visual explanations for neural\nnetworks. We define contrast based on neural networks and propose a methodology\nto extract defined contrasts. We then use the extracted contrasts as a plug-in\non top of existing $`Why \\text{ } P?'$ techniques, specifically Grad-CAM. We\ndemonstrate their value in analyzing both networks and data in applications of\nlarge-scale recognition, fine-grained recognition, subsurface seismic analysis,\nand image quality assessment.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:50:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Prabhushankar", "Mohit", ""], ["Kwon", "Gukyeong", ""], ["Temel", "Dogancan", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "2008.00199", "submitter": "Xin Gao", "authors": "Xin Gao, Xi Huang, Ziyu Shao, Yang Yang", "title": "Green Offloading in Fog-Assisted IoT Systems: An Online Perspective\n  Integrating Learning and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fog-assisted IoT systems, it is a common practice to offload tasks from\nIoT devices to their nearby fog nodes to reduce task processing latencies and\nenergy consumptions. However, the design of online energy-efficient scheme is\nstill an open problem because of various uncertainties in system dynamics such\nas processing capacities and transmission rates. Moreover, the decision-making\nprocess is constrained by resource limits on fog nodes and IoT devices, making\nthe design even more complicated. In this paper, we formulate such a task\noffloading problem with unknown system dynamics as a combinatorial multi-armed\nbandit (CMAB) problem with long-term constraints on time-averaged energy\nconsumptions. Through an effective integration of online learning and online\ncontrol, we propose a \\textit{Learning-Aided Green Offloading} (LAGO) scheme.\nIn LAGO, we employ bandit learning methods to handle the\nexploitation-exploration tradeoff and utilize virtual queue techniques to deal\nwith the long-term constraints. Our theoretical analysis shows that LAGO can\nreduce the average task latency with a tunable sublinear regret bound over a\nfinite time horizon and satisfy the long-term time-averaged energy constraints.\nWe conduct extensive simulations to verify such theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:27:24 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gao", "Xin", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00207", "submitter": "Simeng Bian", "authors": "Simeng Bian, Xi Huang, Ziyu Shao", "title": "Online Task Scheduling for Fog Computing with Multi-Resource Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fog computing systems, one key challenge is online task scheduling, i.e.,\nto decide the resource allocation for tasks that are continuously generated\nfrom end devices. The design is challenging because of various uncertainties\nmanifested in fog computing systems; e.g., tasks' resource demands remain\nunknown before their actual arrivals. Recent works have applied deep\nreinforcement learning (DRL) techniques to conduct online task scheduling and\nimprove various objectives. However, they overlook the multi-resource fairness\nfor different tasks, which is key to achieving fair resource sharing among\ntasks but in general non-trivial to achieve. Thusly, it is still an open\nproblem to design an online task scheduling scheme with multi-resource\nfairness. In this paper, we address the above challenges. Particularly, by\nleveraging DRL techniques and adopting the idea of dominant resource fairness\n(DRF), we propose FairTS, an online task scheduling scheme that learns directly\nfrom experience to effectively shorten average task slowdown while ensuring\nmulti-resource fairness among tasks. Simulation results show that FairTS\noutperforms state-of-the-art schemes with an ultra-low task slowdown and better\nresource fairness.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:57:40 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bian", "Simeng", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""]]}, {"id": "2008.00208", "submitter": "Simeng Bian", "authors": "Simeng Bian, Xi Huang, Ziyu Shao, Xin Gao, Yang Yang", "title": "Service Chain Composition with Failures in NFV Systems: A Game-Theoretic\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For state-of-the-art network function virtualization (NFV) systems, it\nremains a key challenge to conduct effective service chain composition for\ndifferent network services (NSs) with ultra-low request latencies and minimum\nnetwork congestion. To this end, existing solutions often require full\nknowledge of the network state, while ignoring the privacy issues and\noverlooking the non-cooperative behaviors of users. What is more, they may fall\nshort in the face of unexpected failures such as user unavailability and\nvirtual machine breakdown. In this paper, we formulate the problem of service\nchain composition in NFV systems with failures as a non-cooperative game. By\nshowing that such a game is a weighted potential game and exploiting the unique\nproblem structure, we propose two effective distributed schemes that guide the\nservice chain compositions of different NSs towards the Nash equilibrium (NE)\nstate with both near-optimal latencies and minimum congestion. Besides, we\ndevelop two novel learning-aided schemes as comparisons, which are based on\ndeep reinforcement learning (DRL) and Monte Carlo tree search (MCTS)\ntechniques, respectively. Our theoretical analysis and simulation results\ndemonstrate the effectiveness of our proposed schemes, as well as the\nadaptivity when faced with failures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:58:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Bian", "Simeng", ""], ["Huang", "Xi", ""], ["Shao", "Ziyu", ""], ["Gao", "Xin", ""], ["Yang", "Yang", ""]]}, {"id": "2008.00234", "submitter": "Fabio Angelo Maccheroni", "authors": "Carlo Baldassi, Fabio Maccheroni, Massimo Marinacci, Marco Pirazzini", "title": "Ergodic Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulated Annealing is the crowning glory of Markov Chain Monte Carlo Methods\nfor the solution of NP-hard optimization problems in which the cost function is\nknown. Here, by replacing the Metropolis engine of Simulated Annealing with a\nreinforcement learning variation -- that we call Macau Algorithm -- we show\nthat the Simulated Annealing heuristic can be very effective also when the cost\nfunction is unknown and has to be learned by an artificial agent.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 10:17:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Baldassi", "Carlo", ""], ["Maccheroni", "Fabio", ""], ["Marinacci", "Massimo", ""], ["Pirazzini", "Marco", ""]]}, {"id": "2008.00304", "submitter": "Nabil Hossain", "authors": "Nabil Hossain, John Krumm, Michael Gamon and Henry Kautz", "title": "SemEval-2020 Task 7: Assessing Humor in Edited News Headlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the SemEval-2020 shared task \"Assessing Humor in Edited\nNews Headlines.\" The task's dataset contains news headlines in which short\nedits were applied to make them funny, and the funniness of these edited\nheadlines was rated using crowdsourcing. This task includes two subtasks, the\nfirst of which is to estimate the funniness of headlines on a humor scale in\nthe interval 0-3. The second subtask is to predict, for a pair of edited\nversions of the same original headline, which is the funnier version. To date,\nthis task is the most popular shared computational humor task, attracting 48\nteams for the first subtask and 31 teams for the second.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:34:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hossain", "Nabil", ""], ["Krumm", "John", ""], ["Gamon", "Michael", ""], ["Kautz", "Henry", ""]]}, {"id": "2008.00335", "submitter": "Haoran Su", "authors": "Haoran Su, Kejian Shi, Li Jin and Joseph Y.J. Chow", "title": "V2I Connectivity-Based Dynamic Queue-Jump Lane for Emergency Vehicles: A\n  Deep Reinforcement Learning Approach", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency vehicle (EMV) service is a key function of cities and is\nexceedingly challenging due to urban traffic congestion. A main reason behind\nEMV service delay is the lack of communication and cooperation between vehicles\nblocking EMVs. In this paper, we study the improvement of EMV service under V2I\nconnectivity. We consider the establishment of dynamic queue jump lanes (DQJLs)\nbased on real-time coordination of connected vehicles. We develop a novel\nMarkov decision process formulation for the DQJL problem, which explicitly\naccounts for the uncertainty of drivers' reaction to approaching EMVs. We\npropose a deep neural network-based reinforcement learning algorithm that\nefficiently computes the optimal coordination instructions. We also validate\nour approach on a micro-simulation testbed using Simulation of Urban Mobility\n(SUMO). Validation results show that with our proposed methodology, the\ncentralized control system saves approximately 15\\% EMV passing time than the\nbenchmark system.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:34:16 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 17:53:17 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Su", "Haoran", ""], ["Shi", "Kejian", ""], ["Jin", "Li", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "2008.00357", "submitter": "Aria Khademi", "authors": "Aria Khademi, Vasant Honavar", "title": "A Causal Lens for Peeking into Black Box Predictive Models: Predictive\n  Model Interpretation via Causal Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of predictive models trained using machine\nlearning across a wide range of high-stakes applications, e.g., health care,\nsecurity, criminal justice, finance, and education, there is a growing need for\neffective techniques for explaining such models and their predictions. We aim\nto address this problem in settings where the predictive model is a black box;\nThat is, we can only observe the response of the model to various inputs, but\nhave no knowledge about the internal structure of the predictive model, its\nparameters, the objective function, and the algorithm used to optimize the\nmodel. We reduce the problem of interpreting a black box predictive model to\nthat of estimating the causal effects of each of the model inputs on the model\noutput, from observations of the model inputs and the corresponding outputs. We\nestimate the causal effects of model inputs on model output using variants of\nthe Rubin Neyman potential outcomes framework for estimating causal effects\nfrom observational data. We show how the resulting causal attribution of\nresponsibility for model output to the different model inputs can be used to\ninterpret the predictive model and to explain its predictions. We present\nresults of experiments that demonstrate the effectiveness of our approach to\nthe interpretation of black box predictive models via causal attribution in the\ncase of deep neural network models trained on one synthetic data set (where the\ninput variables that impact the output variable are known by design) and two\nreal-world data sets: Handwritten digit classification, and Parkinson's disease\nseverity prediction. Because our approach does not require knowledge about the\npredictive model algorithm and is free of assumptions regarding the black box\npredictive model except that its input-output responses be observable, it can\nbe applied, in principle, to any black box predictive model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 23:20:57 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Khademi", "Aria", ""], ["Honavar", "Vasant", ""]]}, {"id": "2008.00363", "submitter": "Satyananda Kashyap", "authors": "Satyananda Kashyap, Alexandros Karargyris, Joy Wu, Yaniv Gur, Arjun\n  Sharma, Ken C. L. Wong, Mehdi Moradi, Tanveer Syeda-Mahmood", "title": "Looking in the Right place for Anomalies: Explainable AI through\n  Automatic Location Learning", "comments": "5 pages, Paper presented as a poster at the International Symposium\n  on Biomedical Imaging, 2020, Paper Number 655", "journal-ref": "2020 IEEE 17th International Symposium on Biomedical Imaging\n  (ISBI)", "doi": "10.1109/ISBI45749.2020.9098370", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has now become the de facto approach to the recognition of\nanomalies in medical imaging. Their 'black box' way of classifying medical\nimages into anomaly labels poses problems for their acceptance, particularly\nwith clinicians. Current explainable AI methods offer justifications through\nvisualizations such as heat maps but cannot guarantee that the network is\nfocusing on the relevant image region fully containing the anomaly. In this\npaper, we develop an approach to explainable AI in which the anomaly is assured\nto be overlapping the expected location when present. This is made possible by\nautomatically extracting location-specific labels from textual reports and\nlearning the association of expected locations to labels using a hybrid\ncombination of Bi-Directional Long Short-Term Memory Recurrent Neural Networks\n(Bi-LSTM) and DenseNet-121. Use of this expected location to bias the\nsubsequent attention-guided inference network based on ResNet101 results in the\nisolation of the anomaly at the expected location when present. The method is\nevaluated on a large chest X-ray dataset.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 00:02:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kashyap", "Satyananda", ""], ["Karargyris", "Alexandros", ""], ["Wu", "Joy", ""], ["Gur", "Yaniv", ""], ["Sharma", "Arjun", ""], ["Wong", "Ken C. L.", ""], ["Moradi", "Mehdi", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "2008.00397", "submitter": "Liu Yang", "authors": "Liu Yang, Fanqi Meng, Ming-Kuang Daniel Wu, Vicent Ying, Xianchao Xu", "title": "SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic\n  Representation Space", "comments": "18 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate a visual dialog as an information flow in which\neach piece of information is encoded with the joint visual-linguistic\nrepresentation of a single dialog round. Based on this formulation, we consider\nthe visual dialog task as a sequence problem consisting of ordered\nvisual-linguistic vectors. For featurization, we use a Dense Symmetric\nCo-Attention network as a lightweight vison-language joint representation\ngenerator to fuse multimodal features (i.e., image and text), yielding better\ncomputation and data efficiencies. For inference, we propose two Sequential\nDialog Networks (SeqDialN): the first uses LSTM for information propagation\n(IP) and the second uses a modified Transformer for multi-step reasoning (MR).\nOur architecture separates the complexity of multimodal feature fusion from\nthat of inference, which allows simpler design of the inference engine. IP\nbased SeqDialN is our baseline with a simple 2-layer LSTM design that achieves\ndecent performance. MR based SeqDialN, on the other hand, recurrently refines\nthe semantic question/history representations through the self-attention stack\nof Transformer and produces promising results on the visual dialog task. On\nVisDial v1.0 test-std dataset, our best single generative SeqDialN achieves\n62.54% NDCG and 48.63% MRR; our ensemble generative SeqDialN achieves 63.78%\nNDCG and 49.98% MRR, which set a new state-of-the-art generative visual dialog\nmodel. We fine-tune discriminative SeqDialN with dense annotations and boost\nthe performance up to 72.41% NDCG and 55.11% MRR. In this work, we discuss the\nextensive experiments we have conducted to demonstrate the effectiveness of our\nmodel components. We also provide visualization for the reasoning process from\nthe relevant conversation rounds and discuss our fine-tuning methods. Our code\nis available at https://github.com/xiaoxiaoheimei/SeqDialN\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 04:57:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Liu", ""], ["Meng", "Fanqi", ""], ["Wu", "Ming-Kuang Daniel", ""], ["Ying", "Vicent", ""], ["Xu", "Xianchao", ""]]}, {"id": "2008.00408", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "Blackbox Trojanising of Deep Learning Models : Using non-intrusive\n  network structure and binary alterations", "comments": "6 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence namely in Deep Learning has\nheightened its adoption in many applications. Some are playing important roles\nto the extent that we are heavily dependent on them for our livelihood.\nHowever, as with all technologies, there are vulnerabilities that malicious\nactors could exploit. A form of exploitation is to turn these technologies,\nintended for good, to become dual-purposed instruments to support deviant acts\nlike malicious software trojans. As part of proactive defense, researchers are\nproactively identifying such vulnerabilities so that protective measures could\nbe developed subsequently. This research explores a novel blackbox trojanising\napproach using a simple network structure modification to any deep learning\nimage classification model that would transform a benign model into a deviant\none with a simple manipulation of the weights to induce specific types of\nerrors. Propositions to protect the occurrence of such simple exploits are\ndiscussed in this research. This research highlights the importance of\nproviding sufficient safeguards to these models so that the intended good of AI\ninnovation and adoption may be protected.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 06:33:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "2008.00463", "submitter": "Alessandro Antonucci", "authors": "Marco Zaffalon and Alessandro Antonucci and Rafael Caba\\~nas", "title": "Structural Causal Models Are (Solvable by) Credal Networks", "comments": "To appear in the proceedings of the 10th International Conference on\n  Probabilistic Graphical Models (PGM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A structural causal model is made of endogenous (manifest) and exogenous\n(latent) variables. We show that endogenous observations induce linear\nconstraints on the probabilities of the exogenous variables. This allows to\nexactly map a causal model into a credal network. Causal inferences, such as\ninterventions and counterfactuals, can consequently be obtained by standard\nalgorithms for the updating of credal nets. These natively return sharp values\nin the identifiable case, while intervals corresponding to the exact bounds are\nproduced for unidentifiable queries. A characterization of the causal models\nthat allow the map above to be compactly derived is given, along with a\ndiscussion about the scalability for general models. This contribution should\nbe regarded as a systematic approach to represent structural causal models by\ncredal networks and hence to systematically compute causal inferences. A number\nof demonstrative examples is presented to clarify our methodology. Extensive\nexperiments show that approximate algorithms for credal networks can\nimmediately be used to do causal inference in real-size problems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:19:36 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zaffalon", "Marco", ""], ["Antonucci", "Alessandro", ""], ["Caba\u00f1as", "Rafael", ""]]}, {"id": "2008.00520", "submitter": "Matteo Marsili", "authors": "Cl\\'elia de Mulatier, Paolo P. Mazza, Matteo Marsili", "title": "Statistical Inference of Minimally Complex Models", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.ST physics.data-an q-bio.QM stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding the best model that describes a high dimensional dataset, is a\ndaunting task. For binary data, we show that this becomes feasible, if the\nsearch is restricted to simple models. These models -- that we call Minimally\nComplex Models (MCMs) -- are simple because they are composed of independent\ncomponents of minimal complexity, in terms of description length. Simple models\nare easy to infer and to sample from. In addition, model selection within the\nMCMs' class is invariant with respect to changes in the representation of the\ndata. They portray the structure of dependencies among variables in a simple\nway. They provide robust predictions on dependencies and symmetries, as\nillustrated in several examples. MCMs may contain interactions between\nvariables of any order. So, for example, our approach reveals whether a dataset\nis appropriately described by a pairwise interaction model.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 16:57:02 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["de Mulatier", "Cl\u00e9lia", ""], ["Mazza", "Paolo P.", ""], ["Marsili", "Matteo", ""]]}, {"id": "2008.00544", "submitter": "Wentian Zhao", "authors": "Wentian Zhao, Seokhwan Kim, Ning Xu, Hailin Jin", "title": "Video Question Answering on Screencast Tutorials", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/148", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new video question answering task on screencast\ntutorials. We introduce a dataset including question, answer and context\ntriples from the tutorial videos for a software. Unlike other video question\nanswering works, all the answers in our dataset are grounded to the domain\nknowledge base. An one-shot recognition algorithm is designed to extract the\nvisual cues, which helps enhance the performance of video question answering.\nWe also propose several baseline neural network architectures based on various\naspects of video contexts from the dataset. The experimental results\ndemonstrate that our proposed models significantly improve the question\nanswering performances by incorporating multi-modal contexts and domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:27:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Wentian", ""], ["Kim", "Seokhwan", ""], ["Xu", "Ning", ""], ["Jin", "Hailin", ""]]}, {"id": "2008.00603", "submitter": "Yujin Tang", "authors": "Yujin Tang, Jie Tan and Tatsuya Harada", "title": "Learning Agile Locomotion via Adversarial Training", "comments": "To appear at the International Conference on Intelligent Robots and\n  Systems (IROS 2020) as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing controllers for agile locomotion is a long-standing challenge for\nlegged robots. Reinforcement learning (RL) and Evolution Strategy (ES) hold the\npromise of automating the design process of such controllers. However,\ndedicated and careful human effort is required to design training environments\nto promote agility. In this paper, we present a multi-agent learning system, in\nwhich a quadruped robot (protagonist) learns to chase another robot (adversary)\nwhile the latter learns to escape. We find that this adversarial training\nprocess not only encourages agile behaviors but also effectively alleviates the\nlaborious environment design effort. In contrast to prior works that used only\none adversary, we find that training an ensemble of adversaries, each of which\nspecializes in a different escaping strategy, is essential for the protagonist\nto master agility. Through extensive experiments, we show that the locomotion\ncontroller learned with adversarial training significantly outperforms\ncarefully designed baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 01:20:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tang", "Yujin", ""], ["Tan", "Jie", ""], ["Harada", "Tatsuya", ""]]}, {"id": "2008.00614", "submitter": "Xingyu Lu", "authors": "Xingyu Lu, Kimin Lee, Pieter Abbeel, Stas Tiomkin", "title": "Dynamics Generalization via Information Bottleneck in Deep Reinforcement\n  Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the significant progress of deep reinforcement learning (RL) in\nsolving sequential decision making problems, RL agents often overfit to\ntraining environments and struggle to adapt to new, unseen environments. This\nprevents robust applications of RL in real world situations, where system\ndynamics may deviate wildly from the training settings. In this work, our\nprimary contribution is to propose an information theoretic regularization\nobjective and an annealing-based optimization method to achieve better\ngeneralization ability in RL agents. We demonstrate the extreme generalization\nbenefits of our approach in different domains ranging from maze navigation to\nrobotic tasks; for the first time, we show that agents can generalize to test\nparameters more than 10 standard deviations away from the training parameter\ndistribution. This work provides a principled way to improve generalization in\nRL by gradually removing information that is redundant for task-solving; it\nopens doors for the systematic study of generalization from training to\nextremely different testing settings, focusing on the established connections\nbetween information theory and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 02:24:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Xingyu", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Tiomkin", "Stas", ""]]}, {"id": "2008.00682", "submitter": "Qiang Lyu", "authors": "Liyao Lu and Qiang Lyu", "title": "Discovering indicators of dark horse of soccer games by deep learning\n  from sequential trading data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not surprise for machine learning models to provide decent prediction\naccuracy of soccer games outcomes based on various objective metrics. However,\nthe performance is not that decent in terms of predicting difficult and\nvaluable matches. A deep learning model is designed and trained on a real\nsequential trading data from the real prediction market, with the assumption\nthat such trading data contain critical latent information to determine the\ngame outcomes. A new loss function is proposed which biases the selection\ntoward matches with high investment return to train our model. Full\ninvestigation of 4669 top soccer league matches showed that our model traded\noff prediction accuracy for high value return due to a certain ability to\ndetect dark horses. A further try is conducted to depict some indicators\ndiscovered by our model for describing key features of big dark horses and\nregular hot horses.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 07:24:29 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 01:59:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lu", "Liyao", ""], ["Lyu", "Qiang", ""]]}, {"id": "2008.00699", "submitter": "Harold Soh", "authors": "Joshua Lee, Jeffrey Fong, Bing Cai Kok, Harold Soh", "title": "Getting to Know One Another: Calibrating Intent, Capabilities and Trust\n  for Human-Robot Collaboration", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common experience suggests that agents who know each other well are better\nable to work together. In this work, we address the problem of calibrating\nintention and capabilities in human-robot collaboration. In particular, we\nfocus on scenarios where the robot is attempting to assist a human who is\nunable to directly communicate her intent. Moreover, both agents may have\ndiffering capabilities that are unknown to one another. We adopt a\ndecision-theoretic approach and propose the TICC-POMDP for modeling this\nsetting, with an associated online solver. Experiments show our approach leads\nto better team performance both in simulation and in a real-world study with\nhuman subjects.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:04:15 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lee", "Joshua", ""], ["Fong", "Jeffrey", ""], ["Kok", "Bing Cai", ""], ["Soh", "Harold", ""]]}, {"id": "2008.00727", "submitter": "Alykhan Tejani", "authors": "Dalin Guo, Sofia Ira Ktena, Ferenc Huszar, Pranay Kumar Myana, Wenzhe\n  Shi, Alykhan Tejani", "title": "Deep Bayesian Bandits: Exploring in Online Personalized Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems trained in a continuous learning fashion are plagued by\nthe feedback loop problem, also known as algorithmic bias. This causes a newly\ntrained model to act greedily and favor items that have already been engaged by\nusers. This behavior is particularly harmful in personalised ads\nrecommendations, as it can also cause new campaigns to remain unexplored.\nExploration aims to address this limitation by providing new information about\nthe environment, which encompasses user preference, and can lead to higher\nlong-term reward. In this work, we formulate a display advertising recommender\nas a contextual bandit and implement exploration techniques that require\nsampling from the posterior distribution of click-through-rates in a\ncomputationally tractable manner. Traditional large-scale deep learning models\ndo not provide uncertainty estimates by default. We approximate these\nuncertainty measurements of the predictions by employing a bootstrapped model\nwith multiple heads and dropout units. We benchmark a number of different\nmodels in an offline simulation environment using a publicly available dataset\nof user-ads engagements. We test our proposed deep Bayesian bandits algorithm\nin the offline simulation and online AB setting with large-scale production\ntraffic, where we demonstrate a positive gain of our exploration model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:58:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guo", "Dalin", ""], ["Ktena", "Sofia Ira", ""], ["Huszar", "Ferenc", ""], ["Myana", "Pranay Kumar", ""], ["Shi", "Wenzhe", ""], ["Tejani", "Alykhan", ""]]}, {"id": "2008.00766", "submitter": "Timo Philipp Gros", "authors": "Timo P. Gros and Daniel H\\\"oller and J\\\"org Hoffmann and Verena Wolf", "title": "Tracking the Race Between Deep Reinforcement Learning and Imitation\n  Learning -- Extended Version", "comments": "Extended Version of the Conference Paper published in the Proceedings\n  of the 17th International Conference on Quantitative Evaluation of SysTems\n  (QEST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based approaches for solving large sequential decision making\nproblems have become popular in recent years. The resulting agents perform\ndifferently and their characteristics depend on those of the underlying\nlearning approach. Here, we consider a benchmark planning problem from the\nreinforcement learning domain, the Racetrack, to investigate the properties of\nagents derived from different deep (reinforcement) learning approaches. We\ncompare the performance of deep supervised learning, in particular imitation\nlearning, to reinforcement learning for the Racetrack model. We find that\nimitation learning yields agents that follow more risky paths. In contrast, the\ndecisions of deep reinforcement learning are more foresighted, i.e., avoid\nstates in which fatal decisions are more likely. Our evaluations show that for\nthis sequential decision making problem, deep reinforcement learning performs\nbest in many aspects even though for imitation learning optimal decisions are\nconsidered.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:31:44 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Gros", "Timo P.", ""], ["H\u00f6ller", "Daniel", ""], ["Hoffmann", "J\u00f6rg", ""], ["Wolf", "Verena", ""]]}, {"id": "2008.00824", "submitter": "Ahnaf Lodhi", "authors": "Ahnaf Hannan Lodhi, Bar{\\i}\\c{s} Akg\\\"un, \\\"Oznur \\\"Ozkasap", "title": "State-of-the-art Techniques in Deep Edge Intelligence", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The potential held by the gargantuan volumes of data being generated across\nnetworks worldwide has been truly unlocked by machine learning techniques and\nmore recently Deep Learning. The advantages offered by the latter have seen it\nrapidly becoming a framework of choice for various applications. However, the\ncentralization of computational resources and the need for data aggregation\nhave long been limiting factors in the democratization of Deep Learning\napplications. Edge Computing is an emerging paradigm that aims to utilize the\nhitherto untapped processing resources available at the network periphery. Edge\nIntelligence (EI) has quickly emerged as a powerful alternative to enable\nlearning using the concepts of Edge Computing. Deep Learning-based Edge\nIntelligence or Deep Edge Intelligence (DEI) lies in this rapidly evolving\ndomain. In this article, we provide an overview of the major constraints in\noperationalizing DEI. The major research avenues in DEI have been consolidated\nunder Federated Learning, Distributed Computation, Compression Schemes and\nConditional Computation. We also present some of the prevalent challenges and\nhighlight prospective research avenues.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:17:23 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 17:07:03 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 07:42:01 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lodhi", "Ahnaf Hannan", ""], ["Akg\u00fcn", "Bar\u0131\u015f", ""], ["\u00d6zkasap", "\u00d6znur", ""]]}, {"id": "2008.00827", "submitter": "K Naveen Kumar", "authors": "Debaditya Roy, K. Naveen Kumar, C. Krishna Mohan", "title": "Defining Traffic States using Spatio-temporal Traffic Graphs", "comments": "Accepted in 23rd IEEE International Conference on Intelligent\n  Transportation Systems September 20 to 23, 2020. 6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersections are one of the main sources of congestion and hence, it is\nimportant to understand traffic behavior at intersections. Particularly, in\ndeveloping countries with high vehicle density, mixed traffic type, and\nlane-less driving behavior, it is difficult to distinguish between congested\nand normal traffic behavior. In this work, we propose a way to understand the\ntraffic state of smaller spatial regions at intersections using traffic graphs.\nThe way these traffic graphs evolve over time reveals different traffic states\n- a) a congestion is forming (clumping), the congestion is dispersing\n(unclumping), or c) the traffic is flowing normally (neutral). We train a\nspatio-temporal deep network to identify these changes. Also, we introduce a\nlarge dataset called EyeonTraffic (EoT) containing 3 hours of aerial videos\ncollected at 3 busy intersections in Ahmedabad, India. Our experiments on the\nEoT dataset show that the traffic graphs can help in correctly identifying\ncongestion-prone behavior in different spatial regions of an intersection.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:27:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Roy", "Debaditya", ""], ["Kumar", "K. Naveen", ""], ["Mohan", "C. Krishna", ""]]}, {"id": "2008.00905", "submitter": "Shenghe Xu", "authors": "Shenghe Xu, Murali Kodialam, T.V. Lakshman and Shivendra Panwar", "title": "Learning Based Methods for Traffic Matrix Estimation from Link\n  Measurements", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic demand matrix is a critical input for capacity planning,\nanomaly detection and many other network management related tasks. The demand\nmatrix is often computed from link load measurements. The traffic matrix (TM)\nestimation problem is the determination of the traffic demand matrix from link\nload measurements. The relationship between the link loads and the traffic\nmatrix that generated the link load can be modeled as an under-determined\nlinear system and has multiple feasible solutions. Therefore, prior knowledge\nof the traffic demand pattern has to be used in order to find a potentially\nfeasible demand matrix. In this paper, we consider the TM estimation problem\nwhere we have information about the distribution of the demand sizes. This\ninformation can be obtained from the analysis of a few traffic matrices\nmeasured in the past or from operator experience. We develop an iterative\nprojection based algorithm for the solution of this problem. If large number of\npast traffic matrices are accessible, we propose a Generative Adversarial\nNetwork (GAN) based approach for solving the problem. We compare the strengths\nof the two approaches and evaluate their performance for several networks using\nvarying amounts of past data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:34:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Xu", "Shenghe", ""], ["Kodialam", "Murali", ""], ["Lakshman", "T. V.", ""], ["Panwar", "Shivendra", ""]]}, {"id": "2008.00920", "submitter": "Jacopo Tagliabue", "authors": "Nicole Fitzgerald and Jacopo Tagliabue", "title": "On The Plurality of Graphs", "comments": "Manuscript accepted at NETREASON @ ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a series of experiments designed to empirically demonstrate the\neffects of varying the structural features of a multi-agent emergent\ncommunication game framework. Specifically, we model the interactions (edges)\nbetween individual agents (nodes)as the structure of a graph generated\naccording to a series of known random graph generating algorithms. Confirming\nthe hypothesis proposed in [10], we show that the two factors of variation\ninduced in this work, namely 1) the graph-generating process and 2) the\ncentrality measure according to which edges are sampled, in fact play a\nsignificant role in determining the dynamics of language emergence within the\npopulation at hand.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:54:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fitzgerald", "Nicole", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "2008.00928", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Dipto Sarkar, Dhaval Salwala, Edward Curry", "title": "Traffic Prediction Framework for OpenStreetMap using Deep Learning based\n  Complex Event Processing and Open Traffic Cameras", "comments": "16 pages, 9 Figures, 3 Tables, Paper accepted in GIScience 2020 (now\n  postponed to 2021)", "journal-ref": null, "doi": "10.4230/LIPIcs.GIScience.2021.I.17", "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Displaying near-real-time traffic information is a useful feature of digital\nnavigation maps. However, most commercial providers rely on\nprivacy-compromising measures such as deriving location information from\ncellphones to estimate traffic. The lack of an open-source traffic estimation\nmethod using open data platforms is a bottleneck for building sophisticated\nnavigation services on top of OpenStreetMap (OSM). We propose a deep\nlearning-based Complex Event Processing (CEP) method that relies on publicly\navailable video camera streams for traffic estimation. The proposed framework\nperforms near-real-time object detection and objects property extraction across\ncamera clusters in parallel to derive multiple measures related to traffic with\nthe results visualized on OpenStreetMap. The estimation of object properties\n(e.g. vehicle speed, count, direction) provides multidimensional data that can\nbe leveraged to create metrics and visualization for congestion beyond commonly\nused density-based measures. Our approach couples both flow and count measures\nduring interpolation by considering each vehicle as a sample point and their\nspeed as weight. We demonstrate multidimensional traffic metrics (e.g. flow\nrate, congestion estimation) over OSM by processing 22 traffic cameras from\nLondon streets. The system achieves a near-real-time performance of 1.42\nseconds median latency and an average F-score of 0.80.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 17:10:43 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Yadav", "Piyush", ""], ["Sarkar", "Dipto", ""], ["Salwala", "Dhaval", ""], ["Curry", "Edward", ""]]}, {"id": "2008.00937", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias and Abdallah Shami", "title": "The Need for Advanced Intelligence in NFV Management and Orchestration", "comments": "To Appear in IEEE Network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the constant demand for connectivity at an all-time high, Network\nService Providers (NSPs) are required to optimize their networks to cope with\nrising capital and operational expenditures required to meet the growing\nconnectivity demand. A solution to this challenge was presented through Network\nFunction Virtualization (NFV). As network complexity increases and futuristic\nnetworks take shape, NSPs are required to incorporate an increasing amount of\noperational efficiency into their NFV-enabled networks. One such technique is\nMachine Learning (ML), which has been applied to various entities in\nNFV-enabled networks, most notably in the NFV Orchestrator. While traditional\nML provides tremendous operational efficiencies, including real-time and\nhigh-volume data processing, challenges such as privacy, security, scalability,\ntransferability, and concept drift hinder its widespread implementation.\nThrough the adoption of Advanced Intelligence techniques such as Reinforcement\nLearning and Federated Learning, NSPs can leverage the benefits of traditional\nML while simultaneously addressing the major challenges traditionally\nassociated with it. This work presents the benefits of adopting these advanced\ntechniques, provides a list of potential use cases and research topics, and\nproposes a bottom-up micro-functionality approach to applying these methods of\nAdvanced Intelligence to NFV Management and Orchestration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:17:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Shami", "Abdallah", ""]]}, {"id": "2008.01062", "submitter": "Jianhao Wang", "authors": "Jianhao Wang, Zhizhou Ren, Terry Liu, Yang Yu, Chongjie Zhang", "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore value-based multi-agent reinforcement learning (MARL) in the\npopular paradigm of centralized training with decentralized execution (CTDE).\nCTDE has an important concept, Individual-Global-Max (IGM) principle, which\nrequires the consistency between joint and local action selections to support\nefficient local decision-making. However, in order to achieve scalability,\nexisting MARL methods either limit representation expressiveness of their value\nfunction classes or relax the IGM consistency, which may suffer from\ninstability risk or lead to poor performance. This paper presents a novel MARL\napproach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a\nduplex dueling network architecture to factorize the joint value function. This\nduplex dueling structure encodes the IGM principle into the neural network\narchitecture and thus enables efficient value function learning. Theoretical\nanalysis shows that QPLEX achieves a complete IGM function class. Empirical\nexperiments on StarCraft II micromanagement tasks demonstrate that QPLEX\nsignificantly outperforms state-of-the-art baselines in both online and offline\ndata collection settings, and also reveal that QPLEX achieves high sample\nefficiency and can benefit from offline datasets without additional online\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:52:09 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:13:20 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Wang", "Jianhao", ""], ["Ren", "Zhizhou", ""], ["Liu", "Terry", ""], ["Yu", "Yang", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2008.01156", "submitter": "Michael Burke Dr", "authors": "Michael Burke, Kartic Subr, Subramanian Ramamoorthy", "title": "Action sequencing using visual permutations", "comments": "This paper has been accepted for publication at IEEE RA-L", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can easily reason about the sequence of high level actions needed to\ncomplete tasks, but it is particularly difficult to instil this ability in\nrobots trained from relatively few examples. This work considers the task of\nneural action sequencing conditioned on a single reference visual state. This\ntask is extremely challenging as it is not only subject to the significant\ncombinatorial complexity that arises from large action sets, but also requires\na model that can perform some form of symbol grounding, mapping high\ndimensional input data to actions, while reasoning about action relationships.\nThis paper takes a permutation perspective and argues that action sequencing\nbenefits from the ability to reason about both permutations and ordering\nconcepts. Empirical analysis shows that neural models trained with latent\npermutations outperform standard neural architectures in constrained action\nsequencing tasks. Results also show that action sequencing using visual\npermutations is an effective mechanism to initialise and speed up traditional\nplanning techniques and successfully scales to far greater action set sizes\nthan models considered previously.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 19:49:06 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 02:34:31 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Burke", "Michael", ""], ["Subr", "Kartic", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2008.01169", "submitter": "Sayhi Yang", "authors": "Shanghui Yang, Mengxia Zhu, Jingyang Hou, Xuesong Lu", "title": "Deep Knowledge Tracing with Convolutions", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) has recently been an active research area of\ncomputational pedagogy. The task is to model students mastery level of\nknowledge based on their responses to the questions in the past, as well as\npredict the probabilities that they correctly answer subsequent questions in\nthe future. A good KT model can not only make students timely aware of their\nknowledge states, but also help teachers develop better personalized teaching\nplans for students. KT tasks were historically solved using statistical\nmodeling methods such as Bayesian inference and factor analysis, but recent\nadvances in deep learning have led to the successive proposals that leverage\ndeep neural networks, including long short-term memory networks,\nmemory-augmented networks and self-attention networks. While those deep models\ndemonstrate superior performance over the traditional approaches, they all\nneglect more or less the impact on knowledge states of the most recent\nquestions answered by students. The forgetting curve theory states that human\nmemory retention declines over time, therefore knowledge states should be\nmostly affected by the recent questions. Based on this observation, we propose\na Convolutional Knowledge Tracing (CKT) model in this paper. In addition to\nmodeling the long-term effect of the entire question-answer sequence, CKT also\nstrengthens the short-term effect of recent questions using 3D convolutions,\nthereby effectively modeling the forgetting curve in the learning process.\nExtensive experiments show that CKT achieves the new state-of-the-art in\npredicting students performance compared with existing models. Using CKT, we\ngain 1.55 and 2.03 improvements in terms of AUC over DKT and DKVMN\nrespectively, on the ASSISTments2009 dataset. And on the ASSISTments2015\ndataset, the corresponding improvements are 1.01 and 1.96 respectively.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 15:24:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Yang", "Shanghui", ""], ["Zhu", "Mengxia", ""], ["Hou", "Jingyang", ""], ["Lu", "Xuesong", ""]]}, {"id": "2008.01188", "submitter": "Quentin Cohen-Solal", "authors": "Quentin Cohen-Solal", "title": "Learning to Play Two-Player Perfect-Information Games without Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, several techniques for learning game state evaluation\nfunctions by reinforcement are proposed. The first is a generalization of tree\nbootstrapping (tree learning): it is adapted to the context of reinforcement\nlearning without knowledge based on non-linear functions. With this technique,\nno information is lost during the reinforcement learning process. The second is\na modification of minimax with unbounded depth extending the best sequences of\nactions to the terminal states. This modified search is intended to be used\nduring the learning process. The third is to replace the classic gain of a game\n(+1 / -1) with a reinforcement heuristic. We study particular reinforcement\nheuristics such as: quick wins and slow defeats ; scoring ; mobility or\npresence. The four is another variant of unbounded minimax, which plays the\nsafest action instead of playing the best action. This modified search is\nintended to be used after the learning process. The five is a new action\nselection distribution. The conducted experiments suggest that these techniques\nimprove the level of play. Finally, we apply these different techniques to\ndesign program-players to the game of Hex (size 11 and 13) surpassing the level\nof Mohex 3HNN with reinforcement learning from self-play without knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 21:01:22 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 17:50:39 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Cohen-Solal", "Quentin", ""]]}, {"id": "2008.01227", "submitter": "Stepan Dergachev", "authors": "Stepan Dergachev and Konstantin Yakovlev and Ryhor Prakapovich", "title": "A Combination of Theta*, ORCA and Push and Rotate for Multi-agent\n  Navigation", "comments": "This is a preprint of the paper accepted to ICR'20. It contains 12\n  pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multi-agent navigation in static environments when no\ncentralized controller is present. Each agent is controlled individually and\nrelies on three algorithmic components to achieve its goal while avoiding\ncollisions with the other agents and the obstacles: i) individual path planning\nwhich is done by Theta* algorithm; ii) collision avoidance while path following\nwhich is performed by ORCA* algorithm; iii) locally-confined multi-agent path\nplanning done by Push and Rotate algorithm. The latter component is crucial to\navoid deadlocks in confined areas, such as narrow passages or doors. We\ndescribe how the suggested components interact and form a coherent navigation\npipeline. We carry out an extensive empirical evaluation of this pipeline in\nsimulation. The obtained results clearly demonstrate that the number of\noccurring deadlocks significantly decreases enabling more agents to reach their\ngoals compared to techniques that rely on collision-avoidance only and do not\ninclude multi-agent path planning component\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 22:22:43 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dergachev", "Stepan", ""], ["Yakovlev", "Konstantin", ""], ["Prakapovich", "Ryhor", ""]]}, {"id": "2008.01253", "submitter": "Botros Hanna", "authors": "B. N. Hanna, L. T. Trieu, T. C. Son, and N. T. Dinh", "title": "An Application of ASP in Nuclear Engineering: Explaining the Three Mile\n  Island Nuclear Accident Scenario", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes an ongoing effort in developing a declarative system for\nsupporting operators in the Nuclear Power Plant (NPP) control room. The focus\nis on two modules: diagnosis and explanation of events that happened in NPPs.\nWe describe an Answer Set Programming (ASP) representation of an NPP, which\nconsists of declarations of state variables, components, their connections, and\nrules encoding the plant behavior. We then show how the ASP program can be used\nto explain the series of events that occurred in the Three Mile Island, Unit 2\n(TMI-2) NPP accident, the most severe accident in the USA nuclear power plant\noperating history. We also describe an explanation module aimed at addressing\nanswers to questions such as ``why an event occurs?'' or ``what should be\ndone?'' given the collected data.\n  This paper is *under consideration* for acceptance in TPLP Journal.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 00:21:27 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Hanna", "B. N.", ""], ["Trieu", "L. T.", ""], ["Son", "T. C.", ""], ["Dinh", "N. T.", ""]]}, {"id": "2008.01257", "submitter": "Sirui Song", "authors": "Sirui Song, Zefang Zong, Yong Li, Xue Liu, Yang Yu", "title": "Reinforced Epidemic Control: Saving Both Lives and Economy", "comments": "Accepted by KDD'20 \"AI For Covid-19\" Initiative", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saving lives or economy is a dilemma for epidemic control in most cities\nwhile smart-tracing technology raises people's privacy concerns. In this paper,\nwe propose a solution for the life-or-economy dilemma that does not require\nprivate data. We bypass the private-data requirement by suppressing epidemic\ntransmission through a dynamic control on inter-regional mobility that only\nrelies on Origin-Designation (OD) data. We develop DUal-objective\nReinforcement-Learning Epidemic Control Agent (DURLECA) to search\nmobility-control policies that can simultaneously minimize infection spread and\nmaximally retain mobility. DURLECA hires a novel graph neural network, namely\nFlow-GNN, to estimate the virus-transmission risk induced by urban mobility.\nThe estimated risk is used to support a reinforcement learning agent to\ngenerate mobility-control actions. The training of DURLECA is guided with a\nwell-constructed reward function, which captures the natural trade-off relation\nbetween epidemic control and mobility retaining. Besides, we design two\nexploration strategies to improve the agent's searching efficiency and help it\nget rid of local optimums. Extensive experimental results on a real-world OD\ndataset show that DURLECA is able to suppress infections at an extremely low\nlevel while retaining 76\\% of the mobility in the city. Our implementation is\navailable at https://github.com/anyleopeace/DURLECA/.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 00:44:54 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Song", "Sirui", ""], ["Zong", "Zefang", ""], ["Li", "Yong", ""], ["Liu", "Xue", ""], ["Yu", "Yang", ""]]}, {"id": "2008.01263", "submitter": "Yutaka Matsubara", "authors": "Akihisa Morikawa and Yutaka Matsubara", "title": "Safety design concepts for statistical machine learning components\n  toward accordance with functional safety standards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, curial incidents and accidents have been reported due to\nun-intended control caused by misjudgment of statistical machine learning\n(SML), which include deep learning. The international functional safety\nstandards for Electric/Electronic/Programmable (E/E/P) systems have been widely\nspread to improve safety. However, most of them do not recom-mended to use SML\nin safety critical systems so far. In practical the new concepts and methods\nare urgently required to enable SML to be safely used in safety critical\nsystems. In this paper, we organize five kinds of technical safety concepts\n(TSCs) for SML components toward accordance with functional safety standards.\nWe discuss not only quantitative evaluation criteria, but also development\nprocess based on XAI (eXplainable Artificial Intelligence) and Automotive SPICE\nto improve explainability and reliability in development phase. Fi-nally, we\nbriefly compare the TSCs in cost and difficulty, and expect to en-courage\nfurther discussion in many communities and domain.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 01:01:00 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Morikawa", "Akihisa", ""], ["Matsubara", "Yutaka", ""]]}, {"id": "2008.01302", "submitter": "Teng Liu", "authors": "Teng Liu, Bing Huang, Xingyu Mu, Fuqing Zhao, Xiaolin Tang, Dongpu Cao", "title": "A Comparative Analysis of Deep Reinforcement Learning-enabled Freeway\n  Decision-making for Automated Vehicles", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) is becoming a prevalent and powerful\nmethodology to address the artificial intelligent problems. Owing to its\ntremendous potentials in self-learning and self-improvement, DRL is broadly\nserviced in many research fields. This article conducted a comprehensive\ncomparison of multiple DRL approaches on the freeway decision-making problem\nfor autonomous vehicles. These techniques include the common deep Q learning\n(DQL), double DQL (DDQL), dueling DQL, and prioritized replay DQL. First, the\nreinforcement learning (RL) framework is introduced. As an extension, the\nimplementations of the above mentioned DRL methods are established\nmathematically. Then, the freeway driving scenario for the automated vehicles\nis constructed, wherein the decision-making problem is transferred as a control\noptimization problem. Finally, a series of simulation experiments are achieved\nto evaluate the control performance of these DRL-enabled decision-making\nstrategies. A comparative analysis is realized to connect the autonomous\ndriving results with the learning characteristics of these DRL techniques.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:21:34 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Teng", ""], ["Huang", "Bing", ""], ["Mu", "Xingyu", ""], ["Zhao", "Fuqing", ""], ["Tang", "Xiaolin", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.01307", "submitter": "Shih-Lun Wu", "authors": "Shih-Lun Wu and Yi-Hsuan Yang", "title": "The Jazz Transformer on the Front Line: Exploring the Shortcomings of\n  AI-composed Music through Quantitative Measures", "comments": "Accepted to the 21st International Society for Music Information\n  Retrieval Conference (ISMIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the Jazz Transformer, a generative model that utilizes a\nneural sequence model called the Transformer-XL for modeling lead sheets of\nJazz music. Moreover, the model endeavors to incorporate structural events\npresent in the Weimar Jazz Database (WJazzD) for inducing structures in the\ngenerated music. While we are able to reduce the training loss to a low value,\nour listening test suggests however a clear gap between the average ratings of\nthe generated and real compositions. We therefore go one step further and\nconduct a series of computational analysis of the generated compositions from\ndifferent perspectives. This includes analyzing the statistics of the pitch\nclass, grooving, and chord progression, assessing the structureness of the\nmusic with the help of the fitness scape plot, and evaluating the model's\nunderstanding of Jazz music through a MIREX-like continuation prediction task.\nOur work presents in an analytical manner why machine-generated music to date\nstill falls short of the artwork of humanity, and sets some goals for future\nwork on automatic composition to further pursue.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:32:59 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wu", "Shih-Lun", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2008.01339", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Changyeon Kim, Seungho Ryu, Chihyung Jeon, Meeyoung Cha", "title": "Collecting the Public Perception of AI and Robot Rights", "comments": "Conditionally Accepted to ACM CSCW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether to give rights to artificial intelligence (AI) and robots has been a\nsensitive topic since the European Parliament proposed advanced robots could be\ngranted \"electronic personalities.\" Numerous scholars who favor or disfavor its\nfeasibility have participated in the debate. This paper presents an experiment\n(N=1270) that 1) collects online users' first impressions of 11 possible rights\nthat could be granted to autonomous electronic agents of the future and 2)\nexamines whether debunking common misconceptions on the proposal modifies one's\nstance toward the issue. The results indicate that even though online users\nmainly disfavor AI and robot rights, they are supportive of protecting\nelectronic agents from cruelty (i.e., favor the right against cruel treatment).\nFurthermore, people's perceptions became more positive when given information\nabout rights-bearing non-human entities or myth-refuting statements. The style\nused to introduce AI and robot rights significantly affected how the\nparticipants perceived the proposal, similar to the way metaphors function in\ncreating laws. For robustness, we repeated the experiment over a more\nrepresentative sample of U.S. residents (N=164) and found that perceptions\ngathered from online users and those by the general population are similar.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 05:35:29 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lima", "Gabriel", ""], ["Kim", "Changyeon", ""], ["Ryu", "Seungho", ""], ["Jeon", "Chihyung", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2008.01394", "submitter": "Riccardo Zese", "authors": "Elena Bellodi, Marco Alberti, Fabrizio Riguzzi, Riccardo Zese", "title": "MAP Inference for Probabilistic Logic Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 641-655", "doi": "10.1017/S1471068420000174", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Probabilistic Logic Programming (PLP) the most commonly studied inference\ntask is to compute the marginal probability of a query given a program. In this\npaper, we consider two other important tasks in the PLP setting: the\nMaximum-A-Posteriori (MAP) inference task, which determines the most likely\nvalues for a subset of the random variables given evidence on other variables,\nand the Most Probable Explanation (MPE) task, the instance of MAP where the\nquery variables are the complement of the evidence variables. We present a\nnovel algorithm, included in the PITA reasoner, which tackles these tasks by\nrepresenting each problem as a Binary Decision Diagram and applying a dynamic\nprogramming procedure on it. We compare our algorithm with the version of\nProbLog that admits annotated disjunctions and can perform MAP and MPE\ninference. Experiments on several synthetic datasets show that PITA outperforms\nProbLog in many cases.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:10:51 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 15:41:46 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 07:27:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Bellodi", "Elena", ""], ["Alberti", "Marco", ""], ["Riguzzi", "Fabrizio", ""], ["Zese", "Riccardo", ""]]}, {"id": "2008.01415", "submitter": "Pierre Talbot", "authors": "Pierre Talbot, \\'Eric Monfroy and Charlotte Truchet", "title": "Modular Constraint Solver Cooperation via Abstract Interpretation", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 17 pages. v2: Fix an example in Section 3.2 (improved closure)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 848-863", "doi": "10.1017/S1471068420000162", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation among constraint solvers is difficult because different solving\nparadigms have different theoretical foundations. Recent works have shown that\nabstract interpretation can provide a unifying theory for various constraint\nsolvers. In particular, it relies on abstract domains which capture constraint\nlanguages as ordered structures. The key insight of this paper is viewing\ncooperation schemes as abstract domains combinations. We propose a modular\nframework in which solvers and cooperation schemes can be seamlessly added and\ncombined. This differs from existing approaches such as SMT where the\ncooperation scheme is usually fixed (e.g., Nelson-Oppen). We contribute to two\nnew cooperation schemes: (i) interval propagators completion that allows\nabstract domains to exchange bound constraints, and (ii) delayed product which\nexchanges over-approximations of constraints between two abstract domains.\nMoreover, the delayed product is based on delayed goal of logic programming,\nand it shows that abstract domains can also capture control aspects of\nconstraint solving. Finally, to achieve modularity, we propose the shared\nproduct to combine abstract domains and cooperation schemes. Our approach has\nbeen fully implemented, and we provide various examples on the flexible job\nshop scheduling problem. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 08:52:19 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 10:01:14 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Talbot", "Pierre", ""], ["Monfroy", "\u00c9ric", ""], ["Truchet", "Charlotte", ""]]}, {"id": "2008.01430", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione and Marco Grangetto", "title": "A non-discriminatory approach to ethical deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks perform state-of-the-art in an ever-growing number\nof tasks, nowadays they are used to solve an incredibly large variety of tasks.\nHowever, typical training strategies do not take into account lawful, ethical\nand discriminatory potential issues the trained ANN models could incur in. In\nthis work we propose NDR, a non-discriminatory regularization strategy to\nprevent the ANN model to solve the target task using some discriminatory\nfeatures like, for example, the ethnicity in an image classification task for\nhuman faces. In particular, a part of the ANN model is trained to hide the\ndiscriminatory information such that the rest of the network focuses in\nlearning the given learning task. Our experiments show that NDR can be\nexploited to achieve non-discriminatory models with both minimal computational\noverhead and performance loss.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 09:33:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Grangetto", "Marco", ""]]}, {"id": "2008.01441", "submitter": "Robert Ridley", "authors": "Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, Jiajun Chen", "title": "Prompt Agnostic Essay Scorer: A Domain Generalization Approach to\n  Cross-prompt Automated Essay Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-prompt automated essay scoring (AES) requires the system to use non\ntarget-prompt essays to award scores to a target-prompt essay. Since obtaining\na large quantity of pre-graded essays to a particular prompt is often difficult\nand unrealistic, the task of cross-prompt AES is vital for the development of\nreal-world AES systems, yet it remains an under-explored area of research.\nModels designed for prompt-specific AES rely heavily on prompt-specific\nknowledge and perform poorly in the cross-prompt setting, whereas current\napproaches to cross-prompt AES either require a certain quantity of labelled\ntarget-prompt essays or require a large quantity of unlabelled target-prompt\nessays to perform transfer learning in a multi-step manner. To address these\nissues, we introduce Prompt Agnostic Essay Scorer (PAES) for cross-prompt AES.\nOur method requires no access to labelled or unlabelled target-prompt data\nduring training and is a single-stage approach. PAES is easy to apply in\npractice and achieves state-of-the-art performance on the Automated Student\nAssessment Prize (ASAP) dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:17:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ridley", "Robert", ""], ["He", "Liang", ""], ["Dai", "Xinyu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2008.01499", "submitter": "Zhen Zhang Dr.", "authors": "Yuzhu Wu, Zhen Zhang, Gang Kou, Hengjie Zhang, Xiangrui Chao,\n  Cong-Cong Li, Yucheng Dong and Francisco Herrera", "title": "Distributed Linguistic Representations in Decision Making: Taxonomy, Key\n  Elements and Applications, and Challenges in Data Science and Explainable\n  Artificial Intelligence", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed linguistic representations are powerful tools for modelling the\nuncertainty and complexity of preference information in linguistic decision\nmaking. To provide a comprehensive perspective on the development of\ndistributed linguistic representations in decision making, we present the\ntaxonomy of existing distributed linguistic representations. Then, we review\nthe key elements of distributed linguistic information processing in decision\nmaking, including the distance measurement, aggregation methods, distributed\nlinguistic preference relations, and distributed linguistic multiple attribute\ndecision making models. Next, we provide a discussion on ongoing challenges and\nfuture research directions from the perspective of data science and explainable\nartificial intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:13:59 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 06:03:43 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Yuzhu", ""], ["Zhang", "Zhen", ""], ["Kou", "Gang", ""], ["Zhang", "Hengjie", ""], ["Chao", "Xiangrui", ""], ["Li", "Cong-Cong", ""], ["Dong", "Yucheng", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.01508", "submitter": "Xinzhi Wang Dr.", "authors": "Xinzhi Wang, Huao Li, Hui Zhang, Michael Lewis, Katia Sycara", "title": "Explanation of Reinforcement Learning Model in Dynamic Multi-Agent\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been increasing interest in transparency and\ninterpretability in Deep Reinforcement Learning (DRL) systems. Verbal\nexplanations, as the most natural way of communication in our daily life,\ndeserve more attention, since they allow users to gain a better understanding\nof the system which ultimately could lead to a high level of trust and smooth\ncollaboration. This paper reports a novel work in generating verbal\nexplanations for DRL behaviors agent. A rule-based model is designed to\nconstruct explanations using a series of rules which are predefined with prior\nknowledge. A learning model is then proposed to expand the implicit logic of\ngenerating verbal explanation to general situations by employing rule-based\nexplanations as training data. The learning model is shown to have better\nflexibility and generalizability than the static rule-based model. The\nperformance of both models is evaluated quantitatively through objective\nmetrics. The results show that verbal explanation generated by both models\nimprove subjective satisfaction of users towards the interpretability of DRL\nsystems. Additionally, seven variants of the learning model are designed to\nillustrate the contribution of input channels, attention mechanism, and\nproposed encoder in improving the quality of verbal explanation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:21:19 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 13:24:37 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Wang", "Xinzhi", ""], ["Li", "Huao", ""], ["Zhang", "Hui", ""], ["Lewis", "Michael", ""], ["Sycara", "Katia", ""]]}, {"id": "2008.01519", "submitter": "George Baryannis", "authors": "George Baryannis, Ilias Tachmazidis, Sotiris Batsakis, Grigoris\n  Antoniou, Mario Alviano, Emmanuel Papadakis", "title": "A Generalised Approach for Encoding and Reasoning with Qualitative\n  Theories in Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative reasoning involves expressing and deriving knowledge based on\nqualitative terms such as natural language expressions, rather than strict\nmathematical quantities. Well over 40 qualitative calculi have been proposed so\nfar, mostly in the spatial and temporal domains, with several practical\napplications such as naval traffic monitoring, warehouse process optimisation\nand robot manipulation. Even if a number of specialised qualitative reasoning\ntools have been developed so far, an important barrier to the wider adoption of\nthese tools is that only qualitative reasoning is supported natively, when\nreal-world problems most often require a combination of qualitative and other\nforms of reasoning. In this work, we propose to overcome this barrier by using\nASP as a unifying formalism to tackle problems that require qualitative\nreasoning in addition to non-qualitative reasoning. A family of ASP encodings\nis proposed which can handle any qualitative calculus with binary relations.\nThese encodings are experimentally evaluated using a real-world dataset based\non a case study of determining optimal coverage of telecommunication antennas,\nand compared with the performance of two well-known dedicated reasoners.\nExperimental results show that the proposed encodings outperform one of the two\nreasoners, but fall behind the other, an acceptable trade-off given the added\nbenefits of handling any type of reasoning as well as the interpretability of\nlogic programs. This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:31:25 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Baryannis", "George", ""], ["Tachmazidis", "Ilias", ""], ["Batsakis", "Sotiris", ""], ["Antoniou", "Grigoris", ""], ["Alviano", "Mario", ""], ["Papadakis", "Emmanuel", ""]]}, {"id": "2008.01572", "submitter": "Abhishek Dubey", "authors": "Abhishek K Dubey and Alina Peluso and Jacob Hinkle and Devanshu\n  Agarawal and Zilong Tan", "title": "Model Reduction of Shallow CNN Model for Reliable Deployment of\n  Information Extraction from Medical Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shallow Convolution Neural Network (CNN) is a time-tested tool for the\ninformation extraction from cancer pathology reports. Shallow CNN performs\ncompetitively on this task to other deep learning models including BERT, which\nholds the state-of-the-art for many NLP tasks. The main insight behind this\neccentric phenomenon is that the information extraction from cancer pathology\nreports require only a small number of domain-specific text segments to perform\nthe task, thus making the most of the texts and contexts excessive for the\ntask. Shallow CNN model is well-suited to identify these key short text\nsegments from the labeled training set; however, the identified text segments\nremain obscure to humans. In this study, we fill this gap by developing a model\nreduction tool to make a reliable connection between CNN filters and relevant\ntext segments by discarding the spurious connections. We reduce the complexity\nof shallow CNN representation by approximating it with a linear transformation\nof n-gram presence representation with a non-negativity and sparsity prior on\nthe transformation weights to obtain an interpretable model. Our approach\nbridge the gap between the conventionally perceived trade-off boundary between\naccuracy on the one side and explainability on the other by model reduction.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:41:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dubey", "Abhishek K", ""], ["Peluso", "Alina", ""], ["Hinkle", "Jacob", ""], ["Agarawal", "Devanshu", ""], ["Tan", "Zilong", ""]]}, {"id": "2008.01594", "submitter": "Haresh Karnan", "authors": "Siddharth Desai, Ishan Durugkar, Haresh Karnan, Garrett Warnell,\n  Josiah Hanna, Peter Stone", "title": "An Imitation from Observation Approach to Transfer Learning with\n  Dynamics Mismatch", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of transferring a policy learned in a source\nenvironment to a target environment with different dynamics, particularly in\nthe case where it is critical to reduce the amount of interaction with the\ntarget environment during learning. This problem is particularly important in\nsim-to-real transfer because simulators inevitably model real-world dynamics\nimperfectly. In this paper, we show that one existing solution to this transfer\nproblem - grounded action transformation - is closely related to the problem of\nimitation from observation (IfO): learning behaviors that mimic the\nobservations of behavior demonstrations. After establishing this relationship,\nwe hypothesize that recent state-of-the-art approaches from the IfO literature\ncan be effectively repurposed for grounded transfer learning.To validate our\nhypothesis we derive a new algorithm - generative adversarial reinforced action\ntransformation (GARAT) - based on adversarial imitation from observation\ntechniques. We run experiments in several domains with mismatched dynamics, and\nfind that agents trained with GARAT achieve higher returns in the target\nenvironment compared to existing black-box transfer methods\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:36:02 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 17:47:30 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 22:58:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Desai", "Siddharth", ""], ["Durugkar", "Ishan", ""], ["Karnan", "Haresh", ""], ["Warnell", "Garrett", ""], ["Hanna", "Josiah", ""], ["Stone", "Peter", ""]]}, {"id": "2008.01609", "submitter": "Simon Marynissen", "authors": "Simon Marynissen, Bart Bogaerts and Marc Denecker", "title": "Exploiting Game Theory for Analysing Justifications", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 15+8 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 880-894", "doi": "10.1017/S1471068420000186", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Justification theory is a unifying semantic framework. While it has its roots\nin non-monotonic logics, it can be applied to various areas in computer\nscience, especially in explainable reasoning; its most central concept is a\njustification: an explanation why a property holds (or does not hold) in a\nmodel. In this paper, we continue the study of justification theory by means of\nthree major contributions. The first is studying the relation between\njustification theory and game theory. We show that justification frameworks can\nbe seen as a special type of games. The established connection provides the\ntheoretical foundations for our next two contributions. The second contribution\nis studying under which condition two different dialects of justification\ntheory (graphs as explanations vs trees as explanations) coincide. The third\ncontribution is establishing a precise criterion of when a semantics induced by\njustification theory yields consistent results. In the past proving that such\nsemantics were consistent took cumbersome and elaborate proofs. We show that\nthese criteria are indeed satisfied for all common semantics of logic\nprogramming. This paper is under consideration for acceptance in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 14:45:08 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Marynissen", "Simon", ""], ["Bogaerts", "Bart", ""], ["Denecker", "Marc", ""]]}, {"id": "2008.01641", "submitter": "Alexander Harri Bell-Thomas", "authors": "A. H. Bell-Thomas", "title": "Exploring Variational Deep Q Networks", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study provides both analysis and a refined, research-ready\nimplementation of Tang and Kucukelbir's Variational Deep Q Network, a novel\napproach to maximising the efficiency of exploration in complex learning\nenvironments using Variational Bayesian Inference. Alongside reference\nimplementations of both Traditional and Double Deep Q Networks, a small novel\ncontribution is presented - the Double Variational Deep Q Network, which\nincorporates improvements to increase the stability and robustness of\ninference-based learning. Finally, an evaluation and discussion of the\neffectiveness of these approaches is discussed in the wider context of Bayesian\nDeep Learning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 15:36:31 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Bell-Thomas", "A. H.", ""]]}, {"id": "2008.01700", "submitter": "Athirai A. Irissappane", "authors": "Neil Hulbert, Sam Spillers, Brandon Francis, James Haines-Temons, Ken\n  Gil Romero, Benjamin De Jager, Sam Wong, Kevin Flora, Bowei Huang, Athirai A.\n  Irissappane", "title": "EasyRL: A Simple and Extensible Reinforcement Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Reinforcement Learning (RL), has become a popular field of\nstudy as well as a tool for enterprises working on cutting-edge artificial\nintelligence research. To this end, many researchers have built RL frameworks\nsuch as openAI Gym and KerasRL for ease of use. While these works have made\ngreat strides towards bringing down the barrier of entry for those new to RL,\nwe propose a much simpler framework called EasyRL, by providing an interactive\ngraphical user interface for users to train and evaluate RL agents. As it is\nentirely graphical, EasyRL does not require programming knowledge for training\nand testing simple built-in RL agents. EasyRL also supports custom RL agents\nand environments, which can be highly beneficial for RL researchers in\nevaluating and comparing their RL models.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 17:02:56 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 20:35:33 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Hulbert", "Neil", ""], ["Spillers", "Sam", ""], ["Francis", "Brandon", ""], ["Haines-Temons", "James", ""], ["Romero", "Ken Gil", ""], ["De Jager", "Benjamin", ""], ["Wong", "Sam", ""], ["Flora", "Kevin", ""], ["Huang", "Bowei", ""], ["Irissappane", "Athirai A.", ""]]}, {"id": "2008.01766", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Gregory L. Murphy", "title": "Word meaning in minds and machines", "comments": "In press at Psychological Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines have achieved a broad and growing set of linguistic competencies,\nthanks to recent progress in Natural Language Processing (NLP). Psychologists\nhave shown increasing interest in such models, comparing their output to\npsychological judgments such as similarity, association, priming, and\ncomprehension, raising the question of whether the models could serve as\npsychological theories. In this article, we compare how humans and machines\nrepresent the meaning of words. We argue that contemporary NLP systems are\nfairly successful models of human word similarity, but they fall short in many\nother respects. Current models are too strongly linked to the text-based\npatterns in large corpora, and too weakly linked to the desires, goals, and\nbeliefs that people express through words. Word meanings must also be grounded\nin perception and action and be capable of flexible combinations in ways that\ncurrent systems are not. We discuss more promising approaches to grounding NLP\nsystems and argue that they will be more successful with a more human-like,\nconceptual basis for word meaning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:45:49 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 20:53:24 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 21:05:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lake", "Brenden M.", ""], ["Murphy", "Gregory L.", ""]]}, {"id": "2008.01848", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, Florian Dorner, Niko Bernaola-Alvarez, Charlie\n  Giattino, David Manheim", "title": "Forecasting AI Progress: A Research Agenda", "comments": "40 pages including Appendices, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting AI progress is essential to reducing uncertainty in order to\nappropriately plan for research efforts on AI safety and AI governance. While\nthis is generally considered to be an important topic, little work has been\nconducted on it and there is no published document that gives and objective\noverview of the field. Moreover, the field is very diverse and there is no\npublished consensus regarding its direction. This paper describes the\ndevelopment of a research agenda for forecasting AI progress which utilized the\nDelphi technique to elicit and aggregate experts' opinions on what questions\nand methods to prioritize. The results of the Delphi are presented; the\nremainder of the paper follow the structure of these results, briefly reviewing\nrelevant literature and suggesting future work for each topic. Experts\nindicated that a wide variety of methods should be considered for forecasting\nAI progress. Moreover, experts identified salient questions that were both\ngeneral and completely unique to the problem of forecasting AI progress. Some\nof the highest priority topics include the validation of (partially unresolved)\nforecasts, how to make forecasting action-guiding and the quality of different\nperformance metrics. While statistical methods seem more promising, there is\nalso recognition that supplementing judgmental techniques can be quite\nbeneficial.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 21:46:46 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Dorner", "Florian", ""], ["Bernaola-Alvarez", "Niko", ""], ["Giattino", "Charlie", ""], ["Manheim", "David", ""]]}, {"id": "2008.01926", "submitter": "Hazhar Rahmani", "authors": "Hazhar Rahmani, Jason M. O'Kane", "title": "What to Do When You Can't Do It All: Temporal Logic Planning with Soft\n  Temporal Logic Constraints", "comments": "To appear in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a temporal logic planning problem in which the\nobjective is to find an infinite trajectory that satisfies an optimal selection\nfrom a set of soft specifications expressed in linear temporal logic (LTL)\nwhile nevertheless satisfying a hard specification expressed in LTL. Our\nprevious work considered a similar problem in which linear dynamic logic for\nfinite traces (LDLf), rather than LTL, was used to express the soft\nconstraints. In that work, LDLf was used to impose constraints on finite\nprefixes of the infinite trajectory. By using LTL, one is able not only to\nimpose constraints on the finite prefixes of the trajectory, but also to set\n`soft' goals across the entirety of the infinite trajectory. Our algorithm\nfirst constructs a product automaton, on which the planning problem is reduced\nto computing a lasso with minimum cost. Among all such lassos, it is desirable\nto compute a shortest one. Though we prove that computing such a shortest lasso\nis computationally hard, we also introduce an efficient greedy approach to\nsynthesize short lassos nonetheless. We present two case studies describing an\nimplementation of this approach, and report results of our experiment comparing\nour greedy algorithm with an optimal baseline.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 04:18:59 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Rahmani", "Hazhar", ""], ["O'Kane", "Jason M.", ""]]}, {"id": "2008.01976", "submitter": "Tuomas Oikarinen", "authors": "Tuomas Oikarinen, Tsui-Wei Weng, Luca Daniel", "title": "Robust Deep Reinforcement Learning through Adversarial Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, including reinforcement learning agents, have been\nproven vulnerable to small adversarial changes in the input, thus making\ndeploying such networks in the real world problematic. In this paper, we\npropose RADIAL-RL, a method to train reinforcement learning agents with\nimproved robustness against any $l_p$-bounded adversarial attack. By simply\nminimizing an upper bound of the loss functions under worst case adversarial\nperturbation derived from efficient robustness verification methods, we\nsignificantly improve robustness of RL-agents trained on Atari-2600 games and\nshow that RADIAL-RL can beat state-of-the-art robust training algorithms when\nevaluated against PGD-attacks. We also propose a new evaluation method, Greedy\nWorst-Case Reward (GWC), for measuring attack agnostic robustness of RL agents.\nGWC can be evaluated efficiently and it serves as a good estimate of the reward\nunder the worst possible sequence of adversarial attacks; in particular, GWC\naccounts for the importance of each action and their temporal dependency,\nimproving upon previous approaches that only evaluate whether each single\naction can change under input perturbations. Our code is available at\nhttps://github.com/tuomaso/radial_rl.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:49:42 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Oikarinen", "Tuomas", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "2008.02015", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Yuliya Lierler", "title": "Modular Answer Set Programming as a Formal Specification Language", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 767-782", "doi": "10.1017/S1471068420000265", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of formal verification for Answer Set\nProgramming (ASP), namely, obtaining a formal proof showing that the answer\nsets of a given (non-ground) logic program P correctly correspond to the\nsolutions to the problem encoded by P, regardless of the problem instance. To\nthis aim, we use a formal specification language based on ASP modules, so that\neach module can be proved to capture some informal aspect of the problem in an\nisolated way. This specification language relies on a novel definition of\n(possibly nested, first order) program modules that may incorporate local\nhidden atoms at different levels. Then, verifying the logic program P amounts\nto prove some kind of equivalence between P and its modular specification.\nUnder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:25:51 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 09:40:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Lierler", "Yuliya", ""]]}, {"id": "2008.02018", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno, Javier Garea, Javier Romero and Torsten\n  Schaub", "title": "eclingo: A solver for Epistemic Logic Programs", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe eclingo, a solver for epistemic logic programs under Gelfond 1991\nsemantics built upon the Answer Set Programming system clingo. The input\nlanguage of eclingo uses the syntax extension capabilities of clingo to define\nsubjective literals that, as usual in epistemic logic programs, allow for\nchecking the truth of a regular literal in all or in some of the answer sets of\na program. The eclingo solving process follows a guess and check strategy. It\nfirst generates potential truth values for subjective literals and, in a second\nstep, it checks the obtained result with respect to the cautious and brave\nconsequences of the program. This process is implemented using the multi-shot\nfunctionalities of clingo. We have also implemented some optimisations, aiming\nat reducing the search space and, therefore, increasing eclingo's efficiency in\nsome scenarios. Finally, we compare the efficiency of eclingo with two\nstate-of-the-art solvers for epistemic logic programs on a pair of benchmark\nscenarios and show that eclingo generally outperforms their obtained results.\nUnder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 09:32:05 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Garea", "Javier", ""], ["Romero", "Javier", ""], ["Schaub", "Torsten", ""]]}, {"id": "2008.02025", "submitter": "Patrick L\\\"uhne", "authors": "Jorge Fandinno, Vladimir Lifschitz, Patrick L\\\"uhne and Torsten Schaub", "title": "Verifying Tight Logic Programs with anthem and Vampire", "comments": "Paper submitted to the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages (main part), 12 pages (appendix)", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 735-750", "doi": "10.1017/S1471068420000344", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues the line of research aimed at investigating the\nrelationship between logic programs and first-order theories. We extend the\ndefinition of program completion to programs with input and output in a subset\nof the input language of the ASP grounder gringo, study the relationship\nbetween stable models and completion in this context, and describe preliminary\nexperiments with the use of two software tools, anthem and vampire, for\nverifying the correctness of programs with input and output. Proofs of theorems\nare based on a lemma that relates the semantics of programs studied in this\npaper to stable models of first-order formulas. Under consideration for\nacceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:01:33 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 23:32:54 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 21:52:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Fandinno", "Jorge", ""], ["Lifschitz", "Vladimir", ""], ["L\u00fchne", "Patrick", ""], ["Schaub", "Torsten", ""]]}, {"id": "2008.02038", "submitter": "Torsten Schaub", "authors": "Pedro Cabalar and Martin Dieguez and Torsten Schaub and Anna Schuhmann", "title": "Towards Metric Temporal Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 28 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 783-798", "doi": "10.1017/S1471068420000307", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate upon the theoretical foundations of a metric temporal extension\nof Answer Set Programming. In analogy to previous extensions of ASP with\nconstructs from Linear Temporal and Dynamic Logic, we accomplish this in the\nsetting of the logic of Here-and-There and its non-monotonic extension, called\nEquilibrium Logic. More precisely, we develop our logic on the same semantic\nunderpinnings as its predecessors and thus use a simple time domain of bounded\ntime steps. This allows us to compare all variants in a uniform framework and\nultimately combine them in a common implementation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 10:30:14 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 14:48:44 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cabalar", "Pedro", ""], ["Dieguez", "Martin", ""], ["Schaub", "Torsten", ""], ["Schuhmann", "Anna", ""]]}, {"id": "2008.02066", "submitter": "Ozsel Kilinc", "authors": "Ozsel Kilinc, Giovanni Montana", "title": "Follow the Object: Curriculum Learning for Manipulation Tasks with\n  Imagined Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot manipulation through deep reinforcement learning in\nenvironments with sparse rewards is a challenging task. In this paper we\naddress this problem by introducing a notion of imaginary object goals. For a\ngiven manipulation task, the object of interest is first trained to reach a\ndesired target position on its own, without being manipulated, through\nphysically realistic simulations. The object policy is then leveraged to build\na predictive model of plausible object trajectories providing the robot with a\ncurriculum of incrementally more difficult object goals to reach during\ntraining. The proposed algorithm, Follow the Object (FO), has been evaluated on\n7 MuJoCo environments requiring increasing degree of exploration, and has\nachieved higher success rates compared to alternative algorithms. In\nparticularly challenging learning scenarios, e.g. where the object's initial\nand target positions are far apart, our approach can still learn a policy\nwhereas competing methods currently fail.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:19:14 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kilinc", "Ozsel", ""], ["Montana", "Giovanni", ""]]}, {"id": "2008.02214", "submitter": "Jesse Russell", "authors": "Jesse Russell", "title": "Machine Learning Fairness in Justice Systems: Base Rates, False\n  Positives, and False Negatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning best practice statements have proliferated, but there is a\nlack of consensus on what the standards should be. For fairness standards in\nparticular, there is little guidance on how fairness might be achieved in\npractice. Specifically, fairness in errors (both false negatives and false\npositives) can pose a problem of how to set weights, how to make unavoidable\ntradeoffs, and how to judge models that present different kinds of errors\nacross racial groups. This paper considers the consequences of having higher\nrates of false positives for one racial group and higher rates of false\nnegatives for another racial group. The paper examines how different errors in\njustice settings can present problems for machine learning applications, the\nlimits of computation for resolving tradeoffs, and how solutions might have to\nbe crafted through courageous conversations with leadership, line workers,\nstakeholders, and impacted communities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:31:40 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Russell", "Jesse", ""]]}, {"id": "2008.02215", "submitter": "Stefan Szeider", "authors": "Johannes K. Fichte, Markus Hecher, Stefan Szeider", "title": "A Time Leap Challenge for SAT Solving", "comments": "Authors' version of a paper which is to appear in the proceedings of\n  CP'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.AR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the impact of hardware advancement and algorithm advancement for\nSAT solving over the last two decades. In particular, we compare 20-year-old\nSAT-solvers on new computer hardware with modern SAT-solvers on 20-year-old\nhardware. Our findings show that the progress on the algorithmic side has at\nleast as much impact as the progress on the hardware side.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:33:41 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Hecher", "Markus", ""], ["Szeider", "Stefan", ""]]}, {"id": "2008.02232", "submitter": "Jessica Zangari", "authors": "Alessio Fiorentino, Jessica Zangari and Marco Manna", "title": "DaRLing: A Datalog rewriter for OWL 2 RL ontological reasoning under\n  SPARQL queries", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The W3C Web Ontology Language (OWL) is a powerful knowledge representation\nformalism at the basis of many semantic-centric applications. Since its\nunrestricted usage makes reasoning undecidable already in case of very simple\ntasks, expressive yet decidable fragments have been identified. Among them, we\nfocus on OWL 2 RL, which offers a rich variety of semantic constructors, apart\nfrom supporting all RDFS datatypes. Although popular Web resources - such as\nDBpedia - fall in OWL 2 RL, only a few systems have been designed and\nimplemented for this fragment. None of them, however, fully satisfy all the\nfollowing desiderata: (i) being freely available and regularly maintained; (ii)\nsupporting query answering and SPARQL queries; (iii) properly applying the\nsameAs property without adopting the unique name assumption; (iv) dealing with\nconcrete datatypes. To fill the gap, we present DaRLing, a freely available\nDatalog rewriter for OWL 2 RL ontological reasoning under SPARQL queries. In\nparticular, we describe its architecture, the rewriting strategies it\nimplements, and the result of an experimental evaluation that demonstrates its\npractical applicability. This paper is under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:59:59 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Fiorentino", "Alessio", ""], ["Zangari", "Jessica", ""], ["Manna", "Marco", ""]]}, {"id": "2008.02254", "submitter": "Agostinho A. F. J\\'unior", "authors": "Janderson Ferreira (1), Agostinho A. F. J\\'unior (1), Yves M. Galv\\~ao\n  (1), Pablo Barros (2), Sergio Murilo Maciel Fernandes (1), Bruno J. T.\n  Fernandes (1) ((1) Universidade de Pernambuco - Escola Polit\\'ecnica de\n  Pernambuco, (2) Cognitive Architecture for Collaborative Technologies Unit -\n  Istituto Italiano di Tecnologia)", "title": "Performance Improvement of Path Planning algorithms with Deep Learning\n  Encoder Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, path planning algorithms are used in many daily tasks. They are\nrelevant to find the best route in traffic and make autonomous robots able to\nnavigate. The use of path planning presents some issues in large and dynamic\nenvironments. Large environments make these algorithms spend much time finding\nthe shortest path. On the other hand, dynamic environments request a new\nexecution of the algorithm each time a change occurs in the environment, and it\nincreases the execution time. The dimensionality reduction appears as a\nsolution to this problem, which in this context means removing useless paths\npresent in those environments. Most of the algorithms that reduce\ndimensionality are limited to the linear correlation of the input data.\nRecently, a Convolutional Neural Network (CNN) Encoder was used to overcome\nthis situation since it can use both linear and non-linear information to data\nreduction. This paper analyzes in-depth the performance to eliminate the\nuseless paths using this CNN Encoder model. To measure the mentioned model\nefficiency, we combined it with different path planning algorithms. Next, the\nfinal algorithms (combined and not combined) are checked in a database that is\ncomposed of five scenarios. Each scenario contains fixed and dynamic obstacles.\nTheir proposed model, the CNN Encoder, associated to other existent path\nplanning algorithms in the literature, was able to obtain a time decrease to\nfind the shortest path in comparison to all path planning algorithms analyzed.\nthe average decreased time was 54.43 %.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:34:31 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Ferreira", "Janderson", ""], ["J\u00fanior", "Agostinho A. F.", ""], ["Galv\u00e3o", "Yves M.", ""], ["Barros", "Pablo", ""], ["Fernandes", "Sergio Murilo Maciel", ""], ["Fernandes", "Bruno J. T.", ""]]}, {"id": "2008.02275", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and\n  Jerry Li and Dawn Song and Jacob Steinhardt", "title": "Aligning AI With Shared Human Values", "comments": "ICLR 2021; the ETHICS dataset is available at\n  https://github.com/hendrycks/ethics/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to assess a language model's knowledge of basic concepts of\nmorality. We introduce the ETHICS dataset, a new benchmark that spans concepts\nin justice, well-being, duties, virtues, and commonsense morality. Models\npredict widespread moral judgments about diverse text scenarios. This requires\nconnecting physical and social world knowledge to value judgements, a\ncapability that may enable us to steer chatbot outputs or eventually regularize\nopen-ended reinforcement learning agents. With the ETHICS dataset, we find that\ncurrent language models have a promising but incomplete ability to predict\nbasic human ethical judgements. Our work shows that progress can be made on\nmachine ethics today, and it provides a steppingstone toward AI that is aligned\nwith human values.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:59:16 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 06:02:59 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:47 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 21:47:22 GMT"}, {"version": "v5", "created": "Sat, 24 Jul 2021 04:40:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Critch", "Andrew", ""], ["Li", "Jerry", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2008.02311", "submitter": "Ranjay Krishna", "authors": "Pranav Khadpe, Ranjay Krishna, Li Fei-Fei, Jeffrey Hancock, Michael\n  Bernstein", "title": "Conceptual Metaphors Impact Perceptions of Human-AI Collaboration", "comments": "CSCW 2020", "journal-ref": "PACM HCI Volume 4 CSCW 2, 2020", "doi": "10.1145/3415234", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of conversational artificial intelligence (AI) agents, it\nis important to understand the mechanisms that influence users' experiences of\nthese agents. We study a common tool in the designer's toolkit: conceptual\nmetaphors. Metaphors can present an agent as akin to a wry teenager, a toddler,\nor an experienced butler. How might a choice of metaphor influence our\nexperience of the AI agent? Sampling metaphors along the dimensions of warmth\nand competence---defined by psychological theories as the primary axes of\nvariation for human social perception---we perform a study (N=260) where we\nmanipulate the metaphor, but not the behavior, of a Wizard-of-Oz conversational\nagent. Following the experience, participants are surveyed about their\nintention to use the agent, their desire to cooperate with the agent, and the\nagent's usability. Contrary to the current tendency of designers to use high\ncompetence metaphors to describe AI products, we find that metaphors that\nsignal low competence lead to better evaluations of the agent than metaphors\nthat signal high competence. This effect persists despite both high and low\ncompetence agents featuring human-level performance and the wizards being blind\nto condition. A second study confirms that intention to adopt decreases rapidly\nas competence projected by the metaphor increases. In a third study, we assess\neffects of metaphor choices on potential users' desire to try out the system\nand find that users are drawn to systems that project higher competence and\nwarmth. These results suggest that projecting competence may help attract new\nusers, but those users may discard the agent unless it can quickly correct with\na lower competence metaphor. We close with a retrospective analysis that finds\nsimilar patterns between metaphors and user attitudes towards past\nconversational agents such as Xiaoice, Replika, Woebot, Mitsuku, and Tay.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:39:56 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Khadpe", "Pranav", ""], ["Krishna", "Ranjay", ""], ["Fei-Fei", "Li", ""], ["Hancock", "Jeffrey", ""], ["Bernstein", "Michael", ""]]}, {"id": "2008.02312", "submitter": "Qingyong Hu", "authors": "Ruigang Fu, Qingyong Hu, Xiaohu Dong, Yulan Guo, Yinghui Gao, Biao Li", "title": "Axiom-based Grad-CAM: Towards Accurate Visualization and Explanation of\n  CNNs", "comments": "BMVC 2020 (Oral presentation). Code is avaliable at:\n  https://github.com/Fu0511/XGrad-CAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To have a better understanding and usage of Convolution Neural Networks\n(CNNs), the visualization and interpretation of CNNs has attracted increasing\nattention in recent years. In particular, several Class Activation Mapping\n(CAM) methods have been proposed to discover the connection between CNN's\ndecision and image regions. In spite of the reasonable visualization, lack of\nclear and sufficient theoretical support is the main limitation of these\nmethods. In this paper, we introduce two axioms -- Conservation and Sensitivity\n-- to the visualization paradigm of the CAM methods. Meanwhile, a dedicated\nAxiom-based Grad-CAM (XGrad-CAM) is proposed to satisfy these axioms as much as\npossible. Experiments demonstrate that XGrad-CAM is an enhanced version of\nGrad-CAM in terms of conservation and sensitivity. It is able to achieve better\nvisualization performance than Grad-CAM, while also be class-discriminative and\neasy-to-implement compared with Grad-CAM++ and Ablation-CAM. The code is\navailable at https://github.com/Fu0511/XGrad-CAM.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 18:42:33 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 10:47:39 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 06:38:53 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 06:04:28 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Fu", "Ruigang", ""], ["Hu", "Qingyong", ""], ["Dong", "Xiaohu", ""], ["Guo", "Yulan", ""], ["Gao", "Yinghui", ""], ["Li", "Biao", ""]]}, {"id": "2008.02321", "submitter": "Hongtao Wu", "authors": "Hongtao Wu, Gregory S. Chirikjian", "title": "Can I Pour into It? Robot Imagining Open Containability Affordance of\n  Previously Unseen Objects via Physical Simulations", "comments": "IEEE Robotics and Automation Letters. Video demos are available on\n  https://chirikjianlab.github.io/realcontainerimagination/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open containers, i.e., containers without covers, are an important and\nubiquitous class of objects in human life. In this letter, we propose a novel\nmethod for robots to \"imagine\" the open containability affordance of a\npreviously unseen object via physical simulations. We implement our imagination\nmethod on a UR5 manipulator. The robot autonomously scans the object with an\nRGB-D camera. The scanned 3D model is used for open containability imagination\nwhich quantifies the open containability affordance by physically simulating\ndropping particles onto the object and counting how many particles are retained\nin it. This quantification is used for open-container vs. non-open-container\nbinary classification (hereafter referred to as open container classification).\nIf the object is classified as an open container, the robot further imagines\npouring into the object, again using physical simulations, to obtain the\npouring position and orientation for real robot autonomous pouring. We evaluate\nour method on open container classification and autonomous pouring of granular\nmaterial on a dataset containing 130 previously unseen objects with 57 object\ncategories. Although our proposed method uses only 11 objects for simulation\ncalibration (training), its open container classification aligns well with\nhuman judgements. In addition, our method endows the robot with the capability\nto autonomously pour into the 55 containers in the dataset with a very high\nsuccess rate. We also compare to a deep learning method. Results show that our\nmethod achieves the same performance as the deep learning method on open\ncontainer classification and outperforms it on autonomous pouring. Moreover,\nour method is fully explainable.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 19:00:36 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:04:37 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Wu", "Hongtao", ""], ["Chirikjian", "Gregory S.", ""]]}, {"id": "2008.02347", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Anudeep Srivatsav Appe, Raghav Bali, Veera Raghavendra\n  Chikka, Arijit Ghosh Chowdhury and Vamsi M Bhandaru", "title": "An Interpretable Deep Learning System for Automatically Scoring Request\n  for Proposals", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Managed Care system within Medicaid (US Healthcare) uses Request For\nProposals (RFP) to award contracts for various healthcare and related services.\nRFP responses are very detailed documents (hundreds of pages) submitted by\ncompeting organisations to win contracts. Subject matter expertise and domain\nknowledge play an important role in preparing RFP responses along with analysis\nof historical submissions. Automated analysis of these responses through\nNatural Language Processing (NLP) systems can reduce time and effort needed to\nexplore historical responses, and assisting in writing better responses. Our\nwork draws parallels between scoring RFPs and essay scoring models, while\nhighlighting new challenges and the need for interpretability. Typical scoring\nmodels focus on word level impacts to grade essays and other short write-ups.\nWe propose a novel Bi-LSTM based regression model, and provide deeper insight\ninto phrases which latently impact scoring of responses. We contend the merits\nof our proposed methodology using extensive quantitative experiments. We also\nqualitatively asses the impact of important phrases using human evaluators.\nFinally, we introduce a novel problem statement that can be used to further\nimprove the state of the art in NLP based automatic scoring systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:21:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Maji", "Subhadip", ""], ["Appe", "Anudeep Srivatsav", ""], ["Bali", "Raghav", ""], ["Chikka", "Veera Raghavendra", ""], ["Chowdhury", "Arijit Ghosh", ""], ["Bhandaru", "Vamsi M", ""]]}, {"id": "2008.02354", "submitter": "Yukino Baba", "authors": "Yukino Baba, Jiyi Li, Hisashi Kashima", "title": "CrowDEA: Multi-view Idea Prioritization with Crowds", "comments": "Accepted in HCOMP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of ideas collected from crowds with regard to an open-ended\nquestion, how can we organize and prioritize them in order to determine the\npreferred ones based on preference comparisons by crowd evaluators? As there\nare diverse latent criteria for the value of an idea, multiple ideas can be\nconsidered as \"the best\". In addition, evaluators can have different preference\ncriteria, and their comparison results often disagree.\n  In this paper, we propose an analysis method for obtaining a subset of ideas,\nwhich we call frontier ideas, that are the best in terms of at least one latent\nevaluation criterion. We propose an approach, called CrowDEA, which estimates\nthe embeddings of the ideas in the multiple-criteria preference space, the best\nviewpoint for each idea, and preference criterion for each evaluator, to obtain\na set of frontier ideas. Experimental results using real datasets containing\nnumerous ideas or designs demonstrate that the proposed approach can\neffectively prioritize ideas from multiple viewpoints, thereby detecting\nfrontier ideas. The embeddings of ideas learned by the proposed approach\nprovide a visualization that facilitates observation of the frontier ideas. In\naddition, the proposed approach prioritizes ideas from a wider variety of\nviewpoints, whereas the baselines tend to use to the same viewpoints; it can\nalso handle various viewpoints and prioritize ideas in situations where only a\nlimited number of evaluators or labels are available.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 07:41:18 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:22:13 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Baba", "Yukino", ""], ["Li", "Jiyi", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2008.02356", "submitter": "Michael Kissner", "authors": "Michael Kissner", "title": "A Neural-Symbolic Framework for Mental Simulation", "comments": "Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural-symbolic framework for observing the environment and\ncontinuously learning visual semantics and intuitive physics to reproduce them\nin an interactive simulation. The framework consists of five parts, a\nneural-symbolic hybrid network based on capsules for inverse graphics, an\nepisodic memory to store observations, an interaction network for intuitive\nphysics, a meta-learning agent that continuously improves the framework and a\nquerying language that acts as the framework's interface for simulation. By\nmeans of lifelong meta-learning, the capsule network is expanded and trained\ncontinuously, in order to better adapt to its environment with each iteration.\nThis enables it to learn new semantics using a few-shot approach and with\nminimal input from an oracle over its lifetime. From what it learned through\nobservation, the part for intuitive physics infers all the required physical\nproperties of the objects in a scene, enabling predictions. Finally, a custom\nquery language ties all parts together, which allows to perform various mental\nsimulation tasks, such as navigation, sorting and simulation of a game\nenvironment, with which we illustrate the potential of our novel approach.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:43:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Kissner", "Michael", ""]]}, {"id": "2008.02372", "submitter": "Amit Kumar Jaiswal", "authors": "Amit Kumar Jaiswal, Haiming Liu, Ingo Frommholz", "title": "Reinforcement Learning-driven Information Seeking: A Quantum\n  Probabilistic Approach", "comments": "Accepted in Proceedings of Bridging the Gap between Information\n  Science, Information Retrieval and Data Science (BIRDS) at SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding an information forager's actions during interaction is very\nimportant for the study of interactive information retrieval. Although\ninformation spread in uncertain information space is substantially complex due\nto the high entanglement of users interacting with information objects~(text,\nimage, etc.). However, an information forager, in general, accompanies a piece\nof information (information diet) while searching (or foraging) alternative\ncontents, typically subject to decisive uncertainty. Such types of uncertainty\nare analogous to measurements in quantum mechanics which follow the uncertainty\nprinciple. In this paper, we discuss information seeking as a reinforcement\nlearning task. We then present a reinforcement learning-based framework to\nmodel forager exploration that treats the information forager as an agent to\nguide their behaviour. Also, our framework incorporates the inherent\nuncertainty of the foragers' action using the mathematical formalism of quantum\nmechanics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 21:33:51 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Jaiswal", "Amit Kumar", ""], ["Liu", "Haiming", ""], ["Frommholz", "Ingo", ""]]}, {"id": "2008.02387", "submitter": "Rupesh Kumar Srivastava", "authors": "Nihat Engin Toklu, Pawe{\\l} Liskowski, Rupesh Kumar Srivastava", "title": "ClipUp: A Simple and Powerful Optimizer for Distribution-based Policy\n  Evolution", "comments": "20 pages, 7 figures. Extended version of work appearing in PPSN 2020.\n  Code available at https://github.com/nnaisense/pgpelib", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution-based search algorithms are an effective approach for\nevolutionary reinforcement learning of neural network controllers. In these\nalgorithms, gradients of the total reward with respect to the policy parameters\nare estimated using a population of solutions drawn from a search distribution,\nand then used for policy optimization with stochastic gradient ascent. A common\nchoice in the community is to use the Adam optimization algorithm for obtaining\nan adaptive behavior during gradient ascent, due to its success in a variety of\nsupervised learning settings. As an alternative to Adam, we propose to enhance\nclassical momentum-based gradient ascent with two simple techniques: gradient\nnormalization and update clipping. We argue that the resulting optimizer called\nClipUp (short for \"clipped updates\") is a better choice for distribution-based\npolicy evolution because its working principles are simple and easy to\nunderstand and its hyperparameters can be tuned more intuitively in practice.\nMoreover, it removes the need to re-tune hyperparameters if the reward scale\nchanges. Experiments show that ClipUp is competitive with Adam despite its\nsimplicity and is effective on challenging continuous control benchmarks,\nincluding the Humanoid control task based on the Bullet physics simulator.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:46:23 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 05:45:38 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 05:32:08 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Toklu", "Nihat Engin", ""], ["Liskowski", "Pawe\u0142", ""], ["Srivastava", "Rupesh Kumar", ""]]}, {"id": "2008.02429", "submitter": "Ryan Riegel", "authors": "Ronald Fagin, Ryan Riegel, Alexander Gray", "title": "Foundations of Reasoning with Uncertainty via Real-valued Logics", "comments": "9 pages (incl. references), 9 pages supplementary. Submitted to\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-valued logics underlie an increasing number of neuro-symbolic\napproaches, though typically their logical inference capabilities are\ncharacterized only qualitatively. We provide foundations for establishing the\ncorrectness and power of such systems. For the first time, we give a sound and\ncomplete axiomatization for a broad class containing all the common real-valued\nlogics. This axiomatization allows us to derive exactly what information can be\ninferred about the combinations of real values of a collection of formulas\ngiven information about the combinations of real values of several other\ncollections of formulas. We then extend the axiomatization to deal with\nweighted subformulas. Finally, we give a decision procedure based on linear\nprogramming for deciding, under certain natural assumptions, whether a set of\nour sentences logically implies another of our sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:13:11 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 21:22:08 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Fagin", "Ronald", ""], ["Riegel", "Ryan", ""], ["Gray", "Alexander", ""]]}, {"id": "2008.02434", "submitter": "Ye Liu", "authors": "Ye Liu, Shaika Chowdhury, Chenwei Zhang, Cornelia Caragea, Philip S.\n  Yu", "title": "Interpretable Multi-Step Reasoning with Knowledge Extraction on Complex\n  Healthcare Question Answering", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare question answering assistance aims to provide customer healthcare\ninformation, which widely appears in both Web and mobile Internet. The\nquestions usually require the assistance to have proficient healthcare\nbackground knowledge as well as the reasoning ability on the knowledge.\nRecently a challenge involving complex healthcare reasoning, HeadQA dataset,\nhas been proposed, which contains multiple-choice questions authorized for the\npublic healthcare specialization exam. Unlike most other QA tasks that focus on\nlinguistic understanding, HeadQA requires deeper reasoning involving not only\nknowledge extraction, but also complex reasoning with healthcare knowledge.\nThese questions are the most challenging for current QA systems, and the\ncurrent performance of the state-of-the-art method is slightly better than a\nrandom guess. In order to solve this challenging task, we present a Multi-step\nreasoning with Knowledge extraction framework (MurKe). The proposed framework\nfirst extracts the healthcare knowledge as supporting documents from the large\ncorpus. In order to find the reasoning chain and choose the correct answer,\nMurKe iterates between selecting the supporting documents, reformulating the\nquery representation using the supporting documents and getting entailment\nscore for each choice using the entailment model. The reformulation module\nleverages selected documents for missing evidence, which maintains\ninterpretability. Moreover, we are striving to make full use of off-the-shelf\npre-trained models. With less trainable weight, the pre-trained model can\neasily adapt to healthcare tasks with limited training samples. From the\nexperimental results and ablation study, our system is able to outperform\nseveral strong baselines on the HeadQA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:47:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Ye", ""], ["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Caragea", "Cornelia", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.02550", "submitter": "Gianvincenzo Alfano", "authors": "Gianvincenzo Alfano, Sergio Greco, Francesco Parisi, Irina Trubitsyna", "title": "On the Semantics of Abstract Argumentation Frameworks: A Logic\n  Programming Approach", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increasing interest in frameworks extending Dung's\nabstract Argumentation Framework (AF). Popular extensions include bipolar AFs\nand AFs with recursive attacks and necessary supports. Although the\nrelationships between AF semantics and Partial Stable Models (PSMs) of logic\nprograms has been deeply investigated, this is not the case for more general\nframeworks extending AF.\n  In this paper we explore the relationships between AF-based frameworks and\nPSMs. We show that every AF-based framework $\\Delta$ can be translated into a\nlogic program $P_\\Delta$ so that the extensions prescribed by different\nsemantics of $\\Delta$ coincide with subsets of the PSMs of $P_\\Delta$. We\nprovide a logic programming approach that characterizes, in an elegant and\nuniform way, the semantics of several AF-based frameworks. This result allows\nalso to define the semantics for new AF-based frameworks, such as AFs with\nrecursive attacks and recursive deductive supports.\n  Under consideration for publication in Theory and Practice of Logic\nProgramming.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 10:04:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Alfano", "Gianvincenzo", ""], ["Greco", "Sergio", ""], ["Parisi", "Francesco", ""], ["Trubitsyna", "Irina", ""]]}, {"id": "2008.02577", "submitter": "Kathrin Blagec", "authors": "Kathrin Blagec, Georg Dorffner, Milad Moradi, Matthias Samwald", "title": "A critical analysis of metrics used for measuring progress in artificial\n  intelligence", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing model performances on benchmark datasets is an integral part of\nmeasuring and driving progress in artificial intelligence. A model's\nperformance on a benchmark dataset is commonly assessed based on a single or a\nsmall set of performance metrics. While this enables quick comparisons, it may\nalso entail the risk of inadequately reflecting model performance if the metric\ndoes not sufficiently cover all performance characteristics. Currently, it is\nunknown to what extent this might impact current benchmarking efforts. To\naddress this question, we analysed the current landscape of performance metrics\nbased on data covering 3867 machine learning model performance results from the\nweb-based open platform 'Papers with Code'. Our results suggest that the large\nmajority of metrics currently used to evaluate classification AI benchmark\ntasks have properties that may result in an inadequate reflection of a\nclassifiers' performance, especially when used with imbalanced datasets. While\nalternative metrics that address problematic properties have been proposed,\nthey are currently rarely applied as performance metrics in benchmarking tasks.\nFinally, we noticed that the reporting of metrics was partly inconsistent and\npartly unspecific, which may lead to ambiguities when comparing model\nperformances.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 11:14:37 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Blagec", "Kathrin", ""], ["Dorffner", "Georg", ""], ["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "2008.02595", "submitter": "Peter Harrison", "authors": "Peter M. C. Harrison, Raja Marjieh, Federico Adolfi, Pol van Rijn,\n  Manuel Anglada-Tort, Ofer Tchernichovski, Pauline Larrouy-Maestri, Nori\n  Jacoby", "title": "Gibbs Sampling with People", "comments": "Accepted for oral presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A core problem in cognitive science and machine learning is to understand how\nhumans derive semantic representations from perceptual objects, such as color\nfrom an apple, pleasantness from a musical chord, or seriousness from a face.\nMarkov Chain Monte Carlo with People (MCMCP) is a prominent method for studying\nsuch representations, in which participants are presented with binary choice\ntrials constructed such that the decisions follow a Markov Chain Monte Carlo\nacceptance rule. However, while MCMCP has strong asymptotic properties, its\nbinary choice paradigm generates relatively little information per trial, and\nits local proposal function makes it slow to explore the parameter space and\nfind the modes of the distribution. Here we therefore generalize MCMCP to a\ncontinuous-sampling paradigm, where in each iteration the participant uses a\nslider to continuously manipulate a single stimulus dimension to optimize a\ngiven criterion such as 'pleasantness'. We formulate both methods from a\nutility-theory perspective, and show that the new method can be interpreted as\n'Gibbs Sampling with People' (GSP). Further, we introduce an aggregation\nparameter to the transition step, and show that this parameter can be\nmanipulated to flexibly shift between Gibbs sampling and deterministic\noptimization. In an initial study, we show GSP clearly outperforming MCMCP; we\nthen show that GSP provides novel and interpretable results in three other\ndomains, namely musical chords, vocal emotions, and faces. We validate these\nresults through large-scale perceptual rating experiments. The final\nexperiments use GSP to navigate the latent space of a state-of-the-art image\nsynthesis network (StyleGAN), a promising approach for applying GSP to\nhigh-dimensional perceptual spaces. We conclude by discussing future cognitive\napplications and ethical implications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 11:57:07 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:55:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Harrison", "Peter M. C.", ""], ["Marjieh", "Raja", ""], ["Adolfi", "Federico", ""], ["van Rijn", "Pol", ""], ["Anglada-Tort", "Manuel", ""], ["Tchernichovski", "Ofer", ""], ["Larrouy-Maestri", "Pauline", ""], ["Jacoby", "Nori", ""]]}, {"id": "2008.02598", "submitter": "Ron Dorfman", "authors": "Ron Dorfman, Idan Shenfeld, Aviv Tamar", "title": "Offline Meta Learning of Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following instance of the Offline Meta Reinforcement Learning\n(OMRL) problem: given the complete training logs of $N$ conventional RL agents,\ntrained on $N$ different tasks, design a meta-agent that can quickly maximize\nreward in a new, unseen task from the same task distribution. In particular,\nwhile each conventional RL agent explored and exploited its own different task,\nthe meta-agent must identify regularities in the data that lead to effective\nexploration/exploitation in the unseen task. Here, we take a Bayesian RL (BRL)\nview, and seek to learn a Bayes-optimal policy from the offline data. Building\non the recent VariBAD BRL approach, we develop an off-policy BRL method that\nlearns to plan an exploration strategy based on an adaptive neural belief\nestimate. However, learning to infer such a belief from offline data brings a\nnew identifiability issue we term MDP ambiguity. We characterize the problem,\nand suggest resolutions via data collection and modification procedures.\nFinally, we evaluate our framework on a diverse set of domains, including\ndifficult sparse reward tasks, and demonstrate learning of effective\nexploration behavior that is qualitatively different from the exploration used\nby any RL agent in the data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:09:18 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 10:48:55 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 08:17:23 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Dorfman", "Ron", ""], ["Shenfeld", "Idan", ""], ["Tamar", "Aviv", ""]]}, {"id": "2008.02616", "submitter": "Jan Blumenkamp", "authors": "Jan Blumenkamp, Amanda Prorok", "title": "The Emergence of Adversarial Communication in Multi-Agent Reinforcement\n  Learning", "comments": "Accepted to Conference on Robot Learning (CoRL) 2020. Camera-ready\n  version incorporating rebuttal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems require the coordination of multiple autonomous\nagents. Recent work has shown the promise of Graph Neural Networks (GNNs) to\nlearn explicit communication strategies that enable complex multi-agent\ncoordination. These works use models of cooperative multi-agent systems whereby\nagents strive to achieve a shared global goal. When considering agents with\nself-interested local objectives, the standard design choice is to model these\nas separate learning systems (albeit sharing the same environment). Such a\ndesign choice, however, precludes the existence of a single, differentiable\ncommunication channel, and consequently prohibits the learning of inter-agent\ncommunication strategies. In this work, we address this gap by presenting a\nlearning model that accommodates individual non-shared rewards and a\ndifferentiable communication channel that is common among all agents. We focus\non the case where agents have self-interested objectives, and develop a\nlearning algorithm that elicits the emergence of adversarial communications. We\nperform experiments on multi-agent coverage and path planning problems, and\nemploy a post-hoc interpretability technique to visualize the messages that\nagents communicate to each other. We show how a single self-interested agent is\ncapable of learning highly manipulative communication strategies that allows it\nto significantly outperform a cooperative team of agents.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:48:08 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:01:46 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Blumenkamp", "Jan", ""], ["Prorok", "Amanda", ""]]}, {"id": "2008.02622", "submitter": "Wouter van Heeswijk PhD", "authors": "W.J.A. van Heeswijk", "title": "A Gentle Lecture Note on Filtrations in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This note aims to provide a basic intuition on the concept of filtrations as\nused in the context of reinforcement learning (RL). Filtrations are often used\nto formally define RL problems, yet their implications might not be eminent for\nthose without a background in measure theory. Essentially, a filtration is a\nconstruct that captures partial knowledge up to time $t$, without revealing any\nfuture information that has already been simulated, yet not revealed to the\ndecision-maker. We illustrate this with simple examples from the finance domain\non both discrete and continuous outcome spaces. Furthermore, we show that the\nnotion of filtration is not needed, as basing decisions solely on the current\nproblem state (which is possible due to the Markovian property) suffices to\neliminate future knowledge from the decision-making process.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:55:39 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["van Heeswijk", "W. J. A.", ""]]}, {"id": "2008.02637", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Pontus Stenetorp, Sebastian Riedel", "title": "Question and Answer Test-Train Overlap in Open-Domain Question Answering\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideally Open-Domain Question Answering models should exhibit a number of\ncompetencies, ranging from simply memorizing questions seen at training time,\nto answering novel question formulations with answers seen during training, to\ngeneralizing to completely novel questions with novel answers. However, single\naggregated test set scores do not show the full picture of what capabilities\nmodels truly have. In this work, we perform a detailed study of the test sets\nof three popular open-domain benchmark datasets with respect to these\ncompetencies. We find that 60-70% of test-time answers are also present\nsomewhere in the training sets. We also find that 30% of test-set questions\nhave a near-duplicate paraphrase in their corresponding training sets. Using\nthese findings, we evaluate a variety of popular open-domain models to obtain\ngreater insight into what extent they can actually generalize, and what drives\ntheir overall performance. We find that all models perform dramatically worse\non questions that cannot be memorized from training sets, with a mean absolute\nperformance difference of 63% between repeated and non-repeated data. Finally\nwe show that simple nearest-neighbor models out-perform a BART closed-book QA\nmodel, further highlighting the role that training set memorization plays in\nthese benchmarks\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:17:43 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lewis", "Patrick", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2008.02646", "submitter": "Alex Church", "authors": "Alex Church, John Lloyd, Raia Hadsell and Nathan F. Lepora", "title": "Deep Reinforcement Learning for Tactile Robotics: Learning to Type on a\n  Braille Keyboard", "comments": "Accepted in RAL and IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial touch would seem well-suited for Reinforcement Learning (RL),\nsince both paradigms rely on interaction with an environment. Here we propose a\nnew environment and set of tasks to encourage development of tactile\nreinforcement learning: learning to type on a braille keyboard. Four tasks are\nproposed, progressing in difficulty from arrow to alphabet keys and from\ndiscrete to continuous actions. A simulated counterpart is also constructed by\nsampling tactile data from the physical environment. Using state-of-the-art\ndeep RL algorithms, we show that all of these tasks can be successfully learnt\nin simulation, and 3 out of 4 tasks can be learned on the real robot. A lack of\nsample efficiency currently makes the continuous alphabet task impractical on\nthe robot. To the best of our knowledge, this work presents the first\ndemonstration of successfully training deep RL agents in the real world using\nobservations that exclusively consist of tactile images. To aid future research\nutilising this environment, the code for this project has been released along\nwith designs of the braille keycaps for 3D printing and a guide for recreating\nthe experiments. A brief video summary is also available at\nhttps://youtu.be/eNylCA2uE_E.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:29:05 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Church", "Alex", ""], ["Lloyd", "John", ""], ["Hadsell", "Raia", ""], ["Lepora", "Nathan F.", ""]]}, {"id": "2008.02663", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Hansika Hewamalage, Yuan-Hao Liu, Yanfei Kang,\n  Christoph Bergmeir", "title": "Improving the Accuracy of Global Forecasting Models using Time Series\n  Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting models that are trained across sets of many time series, known as\nGlobal Forecasting Models (GFM), have shown recently promising results in\nforecasting competitions and real-world applications, outperforming many\nstate-of-the-art univariate forecasting techniques. In most cases, GFMs are\nimplemented using deep neural networks, and in particular Recurrent Neural\nNetworks (RNN), which require a sufficient amount of time series to estimate\ntheir numerous model parameters. However, many time series databases have only\na limited number of time series. In this study, we propose a novel, data\naugmentation based forecasting framework that is capable of improving the\nbaseline accuracy of the GFM models in less data-abundant settings. We use\nthree time series augmentation techniques: GRATIS, moving block bootstrap\n(MBB), and dynamic time warping barycentric averaging (DBA) to synthetically\ngenerate a collection of time series. The knowledge acquired from these\naugmented time series is then transferred to the original dataset using two\ndifferent approaches: the pooled approach and the transfer learning approach.\nWhen building GFMs, in the pooled approach, we train a model on the augmented\ntime series alongside the original time series dataset, whereas in the transfer\nlearning approach, we adapt a pre-trained model to the new dataset. In our\nevaluation on competition and real-world time series datasets, our proposed\nvariants can significantly improve the baseline accuracy of GFM models and\noutperform state-of-the-art univariate forecasting methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:52:20 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bandara", "Kasun", ""], ["Hewamalage", "Hansika", ""], ["Liu", "Yuan-Hao", ""], ["Kang", "Yanfei", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2008.02708", "submitter": "Hrithwik Shalu", "authors": "Joseph Stember, Hrithwik Shalu", "title": "Deep reinforcement learning to detect brain lesions on MRI: a\n  proof-of-concept application of reinforcement learning to medical images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: AI in radiology is hindered chiefly by: 1) Requiring large annotated\ndata sets. 2) Non-generalizability that limits deployment to new scanners /\ninstitutions. And 3) Inadequate explainability and interpretability. We believe\nthat reinforcement learning can address all three shortcomings, with robust and\nintuitive algorithms trainable on small datasets. To the best of our knowledge,\nreinforcement learning has not been directly applied to computer vision tasks\nfor radiological images. In this proof-of-principle work, we train a deep\nreinforcement learning network to predict brain tumor location.\n  Materials and Methods: Using the BraTS brain tumor imaging database, we\ntrained a deep Q network on 70 post-contrast T1-weighted 2D image slices. We\ndid so in concert with image exploration, with rewards and punishments designed\nto localize lesions. To compare with supervised deep learning, we trained a\nkeypoint detection convolutional neural network on the same 70 images. We\napplied both approaches to a separate 30 image testing set.\n  Results: Reinforcement learning predictions consistently improved during\ntraining, whereas those of supervised deep learning quickly diverged.\nReinforcement learning predicted testing set lesion locations with 85%\naccuracy, compared to roughly 7% accuracy for the supervised deep network.\n  Conclusion: Reinforcement learning predicted lesions with high accuracy,\nwhich is unprecedented for such a small training set. We believe that\nreinforcement learning can propel radiology AI well past the inherent\nlimitations of supervised deep learning, with more clinician-driven research\nand finally toward true clinical applicability.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:26:28 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Stember", "Joseph", ""], ["Shalu", "Hrithwik", ""]]}, {"id": "2008.02735", "submitter": "Kenneth Skiba", "authors": "Kenneth Skiba and Matthias Thimm", "title": "Towards Ranking-based Semantics for Abstract Argumentation using\n  Conditional Logic Semantics", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.12020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel ranking-based semantics for Dung-style argumentation\nframeworks with the help of conditional logics. Using an intuitive translation\nfor an argumentation framework to generate conditionals, we can apply\nnonmonotonic inference systems to generate a ranking on possible worlds. With\nthis ranking we construct a ranking for our arguments. With a small extension\nto this ranking-based semantics we already satisfy some desirable properties\nfor a ranking over arguments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:34:16 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Skiba", "Kenneth", ""], ["Thimm", "Matthias", ""]]}, {"id": "2008.02742", "submitter": "Yen-Ling Kuo", "authors": "Yen-Ling Kuo, Boris Katz, Andrei Barbu", "title": "Compositional Networks Enable Systematic Generalization for Grounded\n  Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are remarkably flexible when understanding new sentences that include\ncombinations of concepts they have never encountered before. Recent work has\nshown that while deep networks can mimic some human language abilities when\npresented with novel sentences, systematic variation uncovers the limitations\nin the language-understanding abilities of networks. We demonstrate that these\nlimitations can be overcome by addressing the generalization challenges in a\nrecently-released dataset, gSCAN, which explicitly measures how well an agent\nis able to interpret novel ideas grounded in vision, e.g., novel pairings of\nadjectives and nouns. The key principle we employ is compositionality: that the\ncompositional structure of networks should reflect the compositional structure\nof the problem domain they address, while allowing other parameters and\nproperties to be learned end-to-end with weak supervision. We build a\ngeneral-purpose mechanism that enables robots to generalize their language\nunderstanding to compositional domains. Crucially, our network has the same\nstate-of-the-art performance as prior work while at the same time generalizing\nits knowledge when prior work does not. Our network also provides a level of\ninterpretability that enables users to inspect what each part of networks\nlearns. Robust language understanding without dramatic failures and without\ncorner cases is critical to building safe and fair robots; we demonstrate the\nsignificant role that compositionality can play in achieving that goal.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:17:35 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 01:02:32 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2008.02747", "submitter": "Roberta Costabile", "authors": "Roberta Costabile, Gelsomina Catalano, Bernardo Cuteri, Maria Concetta\n  Morelli, Nicola Leone, Marco Manna", "title": "A logic-based decision support system for the diagnosis of headache\n  disorders according to the ICHD-3 international classification", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support systems play an important role in medical fields as they can\naugment clinicians to deal more efficiently and effectively with complex\ndecision-making processes. In the diagnosis of headache disorders, however,\nexisting approaches and tools are still not optimal. On the one hand, to\nsupport the diagnosis of this complex and vast spectrum of disorders, the\nInternational Headache Society released in 1988 the International\nClassification of Headache Disorders (ICHD), now in its 3rd edition: a 200\npages document classifying more than 300 different kinds of headaches, where\neach is identified via a collection of specific nontrivial diagnostic criteria.\nOn the other hand, the high number of headache disorders and their complex\ncriteria make the medical history process inaccurate and not exhaustive both\nfor clinicians and existing automatic tools. To fill this gap, we present\nHEAD-ASP, a novel decision support system for the diagnosis of headache\ndisorders. Through a REST Web Service, HEAD-ASP implements a dynamic\nquestionnaire that complies with ICHD-3 by exploiting two logical modules to\nreach a complete diagnosis while trying to minimize the total number of\nquestions being posed to patients. Finally, HEAD-ASP is freely available\non-line and it is receiving very positive feedback from the group of\nneurologists that is testing it.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:26:50 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Costabile", "Roberta", ""], ["Catalano", "Gelsomina", ""], ["Cuteri", "Bernardo", ""], ["Morelli", "Maria Concetta", ""], ["Leone", "Nicola", ""], ["Manna", "Marco", ""]]}, {"id": "2008.02754", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer, Tom van Nuenen, Jose M. Such, Natalia Criado", "title": "Discovering and Categorising Language Biases in Reddit", "comments": "Author's copy of the paper accepted at the International AAAI\n  Conference on Web and Social Media (ICWSM 2021)", "journal-ref": "International AAAI Conference on Web and Social Media (ICWSM 2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven approach using word embeddings to discover and\ncategorise language biases on the discussion platform Reddit. As spaces for\nisolated user communities, platforms such as Reddit are increasingly connected\nto issues of racism, sexism and other forms of discrimination. Hence, there is\na need to monitor the language of these groups. One of the most promising AI\napproaches to trace linguistic biases in large textual datasets involves word\nembeddings, which transform text into high-dimensional dense vectors and\ncapture semantic relations between words. Yet, previous studies require\npredefined sets of potential biases to study, e.g., whether gender is more or\nless associated with particular types of jobs. This makes these approaches\nunfit to deal with smaller and community-centric datasets such as those on\nReddit, which contain smaller vocabularies and slang, as well as biases that\nmay be particular to that community. This paper proposes a data-driven approach\nto automatically discover language biases encoded in the vocabulary of online\ndiscourse communities on Reddit. In our approach, protected attributes are\nconnected to evaluative words found in the data, which are then categorised\nthrough a semantic analysis system. We verify the effectiveness of our method\nby comparing the biases we discover in the Google News dataset with those found\nin previous literature. We then successfully discover gender bias, religion\nbias, and ethnic bias in different Reddit communities. We conclude by\ndiscussing potential application scenarios and limitations of this data-driven\nbias discovery method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:42:10 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 18:38:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ferrer", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Such", "Jose M.", ""], ["Criado", "Natalia", ""]]}, {"id": "2008.02778", "submitter": "Omar Delarosa", "authors": "Omar Delarosa, Hang Dong, Mindy Ruan, Ahmed Khalifa, Julian Togelius", "title": "Mixed-Initiative Level Design with RL Brush", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces RL Brush, a level-editing tool for tile-based games\ndesigned for mixed-initiative co-creation. The tool uses\nreinforcement-learning-based models to augment manual human level-design\nthrough the addition of AI-generated suggestions. Here, we apply RL Brush to\ndesigning levels for the classic puzzle game Sokoban. We put the tool online\nand tested it in 39 different sessions. The results show that users using the\nAI suggestions stay around longer and their created levels on average are more\nplayable and more complex than without.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:25:14 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:27:39 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 20:18:28 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Delarosa", "Omar", ""], ["Dong", "Hang", ""], ["Ruan", "Mindy", ""], ["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2008.02783", "submitter": "Nicholas Kluge Corr\\^ea", "authors": "Nicholas Kluge Corr\\^ea and Nythamar De Oliveira", "title": "Modelos din\\^amicos aplicados \\`a aprendizagem de valores em\n  intelig\\^encia artificial", "comments": "in Portuguese", "journal-ref": "Veritas 65(2):1-15 (2020)", "doi": "10.15448/1984-6746.2020.2.37439", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Experts in Artificial Intelligence (AI) development predict that advances in\nthe development of intelligent systems and agents will reshape vital areas in\nour society. Nevertheless, if such an advance is not made prudently and\ncritically, reflexively, it can result in negative outcomes for humanity. For\nthis reason, several researchers in the area have developed a robust,\nbeneficial, and safe concept of AI for the preservation of humanity and the\nenvironment. Currently, several of the open problems in the field of AI\nresearch arise from the difficulty of avoiding unwanted behaviors of\nintelligent agents and systems, and at the same time specifying what we really\nwant such systems to do, especially when we look for the possibility of\nintelligent agents acting in several domains over the long term. It is of\nutmost importance that artificial intelligent agents have their values aligned\nwith human values, given the fact that we cannot expect an AI to develop human\nmoral values simply because of its intelligence, as discussed in the\nOrthogonality Thesis. Perhaps this difficulty comes from the way we are\naddressing the problem of expressing objectives, values, and ends, using\nrepresentational cognitive methods. A solution to this problem would be the\ndynamic approach proposed by Dreyfus, whose phenomenological philosophy shows\nthat the human experience of being-in-the-world in several aspects is not well\nrepresented by the symbolic or connectionist cognitive method, especially in\nregards to the question of learning values. A possible approach to this problem\nwould be to use theoretical models such as SED (situated embodied dynamics) to\naddress the values learning problem in AI.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 00:56:11 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Corr\u00eaa", "Nicholas Kluge", ""], ["De Oliveira", "Nythamar", ""]]}, {"id": "2008.02790", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Aditi Raghunathan, Percy Liang, Chelsea Finn", "title": "Decoupling Exploration and Exploitation for Meta-Reinforcement Learning\n  without Sacrifices", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of meta-reinforcement learning (meta-RL) is to build agents that can\nquickly learn new tasks by leveraging prior experience on related tasks.\nLearning a new task often requires both exploring to gather task-relevant\ninformation and exploiting this information to solve the task. In principle,\noptimal exploration and exploitation can be learned end-to-end by simply\nmaximizing task performance. However, such meta-RL approaches struggle with\nlocal optima due to a chicken-and-egg problem: learning to explore requires\ngood exploitation to gauge the exploration's utility, but learning to exploit\nrequires information gathered via exploration. Optimizing separate objectives\nfor exploration and exploitation can avoid this problem, but prior meta-RL\nexploration objectives yield suboptimal policies that gather information\nirrelevant to the task. We alleviate both concerns by constructing an\nexploitation objective that automatically identifies task-relevant information\nand an exploration objective to recover only this information. This avoids\nlocal optima in end-to-end training, without sacrificing optimal exploration.\nEmpirically, DREAM substantially outperforms existing approaches on complex\nmeta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:\nhttps://ezliu.github.io/dream/\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 17:57:36 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:54:30 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 17:53:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Raghunathan", "Aditi", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.02837", "submitter": "Preslav Nakov", "authors": "Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov", "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "comments": "propaganda, persuasion, disinformation, fake news", "journal-ref": "SemEval-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:45:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chernyavskiy", "Anton", ""], ["Ilvovsky", "Dmitry", ""], ["Nakov", "Preslav", ""]]}, {"id": "2008.02849", "submitter": "Julio Alves", "authors": "Dilson Lucas Pereira, J\\'ulio C\\'esar Alves, Mayron C\\'esar de\n  Oliveira Moreira", "title": "A Multiperiod Workforce Scheduling and Routing Problem with Dependent\n  Tasks", "comments": null, "journal-ref": "Computers & Operations Research, Volume 118, 2020, 104930, ISSN\n  0305-0548", "doi": "10.1016/j.cor.2020.104930", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a new Workforce Scheduling and Routing Problem,\ndenoted Multiperiod Workforce Scheduling and Routing Problem with Dependent\nTasks. In this problem, customers request services from a company. Each service\nis composed of dependent tasks, which are executed by teams of varying skills\nalong one or more days. Tasks belonging to a service may be executed by\ndifferent teams, and customers may be visited more than once a day, as long as\nprecedences are not violated. The objective is to schedule and route teams so\nthat the makespan is minimized, i.e., all services are completed in the minimum\nnumber of days. In order to solve this problem, we propose a Mixed-Integer\nProgramming model, a constructive algorithm and heuristic algorithms based on\nthe Ant Colony Optimization (ACO) metaheuristic. The presence of precedence\nconstraints makes it difficult to develop efficient local search algorithms.\nThis motivates the choice of the ACO metaheuristic, which is effective in\nguiding the construction process towards good solutions. Computational results\nshow that the model is capable of consistently solving problems with up to\nabout 20 customers and 60 tasks. In most cases, the best performing ACO\nalgorithm was able to match the best solution provided by the model in a\nfraction of its computational time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 19:31:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Pereira", "Dilson Lucas", ""], ["Alves", "J\u00falio C\u00e9sar", ""], ["Moreira", "Mayron C\u00e9sar de Oliveira", ""]]}, {"id": "2008.03007", "submitter": "Agostino Dovier", "authors": "Alessandro Burigana, Francesco Fabiano, Agostino Dovier, Enrico\n  Pontelli", "title": "Modelling Multi-Agent Epistemic Planning in ASP", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": "Theory and Practice of Logic Programming 20 (2020) 593-608", "doi": "10.1017/S1471068420000289", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Designing agents that reason and act upon the world has always been one of\nthe main objectives of the Artificial Intelligence community. While for\nplanning in \"simple\" domains the agents can solely rely on facts about the\nworld, in several contexts, e.g., economy, security, justice and politics, the\nmere knowledge of the world could be insufficient to reach a desired goal. In\nthese scenarios, epistemic reasoning, i.e., reasoning about agents' beliefs\nabout themselves and about other agents' beliefs, is essential to design\nwinning strategies.\n  This paper addresses the problem of reasoning in multi-agent epistemic\nsettings exploiting declarative programming techniques. In particular, the\npaper presents an actual implementation of a multi-shot Answer Set\nProgramming-based planner that can reason in multi-agent epistemic settings,\ncalled PLATO (ePistemic muLti-agent Answer seT programming sOlver). The ASP\nparadigm enables a concise and elegant design of the planner, w.r.t. other\nimperative implementations, facilitating the development of formal verification\nof correctness.\n  The paper shows how the planner, exploiting an ad-hoc epistemic state\nrepresentation and the efficiency of ASP solvers, has competitive performance\nresults on benchmarks collected from the literature. It is under consideration\nfor acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 06:35:56 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Burigana", "Alessandro", ""], ["Fabiano", "Francesco", ""], ["Dovier", "Agostino", ""], ["Pontelli", "Enrico", ""]]}, {"id": "2008.03050", "submitter": "Esra Erdem", "authors": "Esra Erdem, Muge Fidan, David Manlove, Patrick Prosser", "title": "A General Framework for Stable Roommates Problems using Answer Set\n  Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stable Roommates problem (SR) is characterized by the preferences of\nagents over other agents as roommates: each agent ranks all others in strict\norder of preference. A solution to SR is then a partition of the agents into\npairs so that each pair shares a room, and there is no pair of agents that\nwould block this matching (i.e., who prefers the other to their roommate in the\nmatching). There are interesting variations of SR that are motivated by\napplications (e.g., the preference lists may be incomplete (SRI) and involve\nties (SRTI)), and that try to find a more fair solution (e.g., Egalitarian SR).\nUnlike the Stable Marriage problem, every SR instance is not guaranteed to have\na solution. For that reason, there are also variations of SR that try to find a\ngood-enough solution (e.g., Almost SR). Most of these variations are NP-hard.\nWe introduce a formal framework, called SRTI-ASP, utilizing the logic\nprogramming paradigm Answer Set Programming, that is provable and general\nenough to solve many of such variations of SR. Our empirical analysis shows\nthat SRTI-ASP is also promising for applications. This paper is under\nconsideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 09:12:36 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Erdem", "Esra", ""], ["Fidan", "Muge", ""], ["Manlove", "David", ""], ["Prosser", "Patrick", ""]]}, {"id": "2008.03100", "submitter": "Richard Taupe", "authors": "Richard Taupe, Antonius Weinzierl, Gerhard Friedrich", "title": "Conflict Generalisation in ASP: Learning Correct and Effective\n  Non-Ground Constraints", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalising and re-using knowledge learned while solving one problem\ninstance has been neglected by state-of-the-art answer set solvers. We suggest\na new approach that generalises learned nogoods for re-use to speed-up the\nsolving of future problem instances. Our solution combines well-known ASP\nsolving techniques with deductive logic-based machine learning. Solving\nperformance can be improved by adding learned non-ground constraints to the\noriginal program. We demonstrate the effects of our method by means of\nrealistic examples, showing that our approach requires low computational cost\nto learn constraints that yield significant performance benefits in our test\ncases. These benefits can be seen with ground-and-solve systems as well as\nlazy-grounding systems. However, ground-and-solve systems suffer from\nadditional grounding overheads, induced by the additional constraints in some\ncases. By means of conflict minimization, non-minimal learned constraints can\nbe reduced. This can result in significant reductions of grounding and solving\nefforts, as our experiments show. (Under consideration for acceptance in TPLP.)\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:02:32 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Taupe", "Richard", ""], ["Weinzierl", "Antonius", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "2008.03110", "submitter": "Matthias Stierle", "authors": "Matthias Stierle, Sven Weinzierl, Maximilian Harl, Martin Matzner", "title": "A Technique for Determining Relevance Scores of Process Activities using\n  Graph-based Neural Networks", "comments": null, "journal-ref": "Decision Support Systems, 2021", "doi": "10.1016/j.dss.2021.113511", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Process models generated through process mining depict the as-is state of a\nprocess. Through annotations with metrics such as the frequency or duration of\nactivities, these models provide generic information to the process analyst. To\nimprove business processes with respect to performance measures, process\nanalysts require further guidance from the process model. In this study, we\ndesign Graph Relevance Miner (GRM), a technique based on graph neural networks,\nto determine the relevance scores for process activities with respect to\nperformance measures. Annotating process models with such relevance scores\nfacilitates a problem-focused analysis of the business process, placing these\nproblems at the centre of the analysis. We quantitatively evaluate the\npredictive quality of our technique using four datasets from different domains,\nto demonstrate the faithfulness of the relevance scores. Furthermore, we\npresent the results of a case study, which highlight the utility of the\ntechnique for organisations. Our work has important implications both for\nresearch and business applications, because process model-based analyses\nfeature shortcomings that need to be urgently addressed to realise successful\nprocess mining at an enterprise level.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:15:30 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 08:57:52 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Stierle", "Matthias", ""], ["Weinzierl", "Sven", ""], ["Harl", "Maximilian", ""], ["Matzner", "Martin", ""]]}, {"id": "2008.03172", "submitter": "Diedrich Wolter", "authors": "Mena Leemhuis and \\\"Ozg\\\"ur L. \\\"Oz\\c{c}ep and Diedrich Wolter", "title": "Orthologics for Cones", "comments": "extended version of AI2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications that use knowledge representation (KR) techniques, in\nparticular those that combine data-driven and logic methods, the domain of\nobjects is not an abstract unstructured domain, but it exhibits a dedicated,\ndeep structure of geometric objects. One example is the class of convex sets\nused to model natural concepts in conceptual spaces, which also links via\nconvex optimization techniques to machine learning. In this paper we study\nlogics for such geometric structures. Using the machinery of lattice theory, we\ndescribe an extension of minimal orthologic with a partial modularity rule that\nholds for closed convex cones. This logic combines a feasible data structure\n(exploiting convexity/conicity) with sufficient expressivity, including full\northonegation (exploiting conicity).\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:28:27 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Leemhuis", "Mena", ""], ["\u00d6z\u00e7ep", "\u00d6zg\u00fcr L.", ""], ["Wolter", "Diedrich", ""]]}, {"id": "2008.03209", "submitter": "Sina D\\\"aubener", "authors": "Sina D\\\"aubener and Asja Fischer", "title": "Investigating maximum likelihood based training of infinite mixtures for\n  uncertainty quantification", "comments": null, "journal-ref": "Presented at the uncertainty workshop of ECML PKDD 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification in neural networks gained a lot of attention in\nthe past years. The most popular approaches, Bayesian neural networks (BNNs),\nMonte Carlo dropout, and deep ensembles have one thing in common: they are all\nbased on some kind of mixture model. While the BNNs build infinite mixture\nmodels and are derived via variational inference, the latter two build finite\nmixtures trained with the maximum likelihood method. In this work we\ninvestigate the effect of training an infinite mixture distribution with the\nmaximum likelihood method instead of variational inference. We find that the\nproposed objective leads to stochastic networks with an increased predictive\nvariance, which improves uncertainty based identification of\nmiss-classification and robustness against adversarial attacks in comparison to\na standard BNN with equivalent network structure. The new model also displays\nhigher entropy on out-of-distribution data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:55:53 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:57:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["D\u00e4ubener", "Sina", ""], ["Fischer", "Asja", ""]]}, {"id": "2008.03210", "submitter": "Abhishek Kulkarni", "authors": "Abhishek N. Kulkarni and Jie Fu", "title": "A Theory of Hypergames on Graphs for Synthesizing Dynamic Cyber Defense\n  with Deception", "comments": "32 pages, 10 figures, 2 tables, Accepted Book Chapter in \"Game Theory\n  and Machine Learning for Cyber Security\" by Wiley-IEEE press, Editors:\n  Charles A. Kamhoua, Christopher D. Kiekintveld, Fei Fang, Quanyan Zhu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.GT cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present an approach using formal methods to synthesize\nreactive defense strategy in a cyber network, equipped with a set of decoy\nsystems. We first generalize formal graphical security models--attack\ngraphs--to incorporate defender's countermeasures in a game-theoretic model,\ncalled an attack-defend game on graph. This game captures the dynamic\ninteractions between the defender and the attacker and their defense/attack\nobjectives in formal logic. Then, we introduce a class of hypergames to model\nasymmetric information created by decoys in the attacker-defender interactions.\nGiven qualitative security specifications in formal logic, we show that the\nsolution concepts from hypergames and reactive synthesis in formal methods can\nbe extended to synthesize effective dynamic defense strategy using cyber\ndeception. The strategy takes the advantages of the misperception of the\nattacker to ensure security specification is satisfied, which may not be\nsatisfiable when the information is symmetric.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 14:59:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kulkarni", "Abhishek N.", ""], ["Fu", "Jie", ""]]}, {"id": "2008.03212", "submitter": "Konstantin Schekotihin", "authors": "Carmine Dodaro, Thomas Eiter, Paul Ogris, Konstantin Schekotihin", "title": "Managing caching strategies for stream reasoning with reinforcement\n  learning", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2019), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient decision-making over continuously changing data is essential for\nmany application domains such as cyber-physical systems, industry\ndigitalization, etc. Modern stream reasoning frameworks allow one to model and\nsolve various real-world problems using incremental and continuous evaluation\nof programs as new data arrives in the stream. Applied techniques use, e.g.,\nDatalog-like materialization or truth maintenance algorithms to avoid costly\nre-computations, thus ensuring low latency and high throughput of a stream\nreasoner. However, the expressiveness of existing approaches is quite limited\nand, e.g., they cannot be used to encode problems with constraints, which often\nappear in practice. In this paper, we suggest a novel approach that uses the\nConflict-Driven Constraint Learning (CDCL) to efficiently update legacy\nsolutions by using intelligent management of learned constraints. In\nparticular, we study the applicability of reinforcement learning to\ncontinuously assess the utility of learned constraints computed in previous\ninvocations of the solving algorithm for the current one. Evaluations conducted\non real-world reconfiguration problems show that providing a CDCL algorithm\nwith relevant learned constraints from previous iterations results in\nsignificant performance improvements of the algorithm in stream reasoning\nscenarios.\n  Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:01:41 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Dodaro", "Carmine", ""], ["Eiter", "Thomas", ""], ["Ogris", "Paul", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "2008.03229", "submitter": "Mingxuan Li", "authors": "Mingxuan Li, Michael L. Littman", "title": "Towards Sample Efficient Agents through Algorithmic Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose and explore Deep Graph Value Network (DeepGV) as a\npromising method to work around sample complexity in deep\nreinforcement-learning agents using a message-passing mechanism. The main idea\nis that the agent should be guided by structured non-neural-network algorithms\nlike dynamic programming. According to recent advances in algorithmic\nalignment, neural networks with structured computation procedures can be\ntrained efficiently. We demonstrate the potential of graph neural network in\nsupporting sample efficient learning by showing that Deep Graph Value Network\ncan outperform unstructured baselines by a large margin in solving the Markov\nDecision Process (MDP). We believe this would open up a new avenue for\nstructured agent design. See\nhttps://github.com/drmeerkat/Deep-Graph-Value-Network for the code.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:44:32 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:55:33 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 11:31:00 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 14:19:22 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Mingxuan", ""], ["Littman", "Michael L.", ""]]}, {"id": "2008.03301", "submitter": "Farhad Shakerin", "authors": "Farhad Shakerin, Gopal Gupta", "title": "White-box Induction From SVM Models: Explainable AI with Logic\n  Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of inducing logic programs that explain models\nlearned by the support vector machine (SVM) algorithm. The top-down sequential\ncovering inductive logic programming (ILP) algorithms (e.g., FOIL) apply\nhill-climbing search using heuristics from information theory. A major issue\nwith this class of algorithms is getting stuck in a local optimum. In our new\napproach, however, the data-dependent hill-climbing search is replaced with a\nmodel-dependent search where a globally optimal SVM model is trained first,\nthen the algorithm looks into support vectors as the most influential data\npoints in the model, and induces a clause that would cover the support vector\nand points that are most similar to that support vector. Instead of defining a\nfixed hypothesis search space, our algorithm makes use of SHAP, an\nexample-specific interpreter in explainable AI, to determine a relevant set of\nfeatures. This approach yields an algorithm that captures SVM model's\nunderlying logic and outperforms %GG: the FOIL algorithm --> other ILP\nalgorithms other ILP algorithms in terms of the number of induced clauses and\nclassification evaluation metrics. This paper is under consideration for\npublication in the journal of \"Theory and practice of logic programming\".\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 23:07:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "2008.03323", "submitter": "Xavier Amatriain", "authors": "Anitha Kannan, Richard Chen, Vignesh Venkataraman, Geoffrey J. Tso,\n  Xavier Amatriain", "title": "COVID-19 in differential diagnosis of online symptom assessments", "comments": "Accepted at the Machine Learning for Health (ML4H) at NeurIPS 2020 -\n  Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has magnified an already existing trend of people\nlooking for healthcare solutions online. One class of solutions are symptom\ncheckers, which have become very popular in the context of COVID-19.\nTraditional symptom checkers, however, are based on manually curated expert\nsystems that are inflexible and hard to modify, especially in a quickly\nchanging situation like the one we are facing today. That is why all COVID-19\nexisting solutions are manual symptom checkers that can only estimate the\nprobability of this disease and cannot contemplate alternative hypothesis or\ncome up with a differential diagnosis. While machine learning offers an\nalternative, the lack of reliable data does not make it easy to apply to\nCOVID-19 either. In this paper we present an approach that combines the\nstrengths of traditional AI expert systems and novel deep learning models. In\ndoing so we can leverage prior knowledge as well as any amount of existing data\nto quickly derive models that best adapt to the current state of the world and\nlatest scientific knowledge. We use the approach to train a COVID-19 aware\ndifferential diagnosis model that can be used for medical decision support both\nfor doctors or patients. We show that our approach is able to accurately model\nnew incoming data about COVID-19 while still preserving accuracy on conditions\nthat had been modeled in the past. While our approach shows evident and clear\nadvantages for an extreme situation like the one we are currently facing, we\nalso show that its flexibility generalizes beyond this concrete, but very\nimportant, example.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:10:42 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 22:34:44 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 22:13:39 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Kannan", "Anitha", ""], ["Chen", "Richard", ""], ["Venkataraman", "Vignesh", ""], ["Tso", "Geoffrey J.", ""], ["Amatriain", "Xavier", ""]]}, {"id": "2008.03333", "submitter": "Seyed Sajjad Fazeli", "authors": "Seyed Sajjad Fazeli, Saravanan Venkatachalam, Jonathon M. Smereka", "title": "Efficient algorithms for electric vehicles' min-max routing problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increase in greenhouse gases emission from the transportation sector has\nled companies and the government to elevate and support the production of\nelectric vehicles (EV). With recent developments in urbanization and\ne-commerce, transportation companies are replacing their conventional fleet\nwith EVs to strengthen the efforts for sustainable and environment-friendly\noperations. However, deploying a fleet of EVs asks for efficient routing and\nrecharging strategies to alleviate their limited range and mitigate the battery\ndegradation rate. In this work, a fleet of electric vehicles is considered for\ntransportation and logistic capabilities with limited battery capacity and\nscarce charging station availability. We introduce a min-max electric vehicle\nrouting problem (MEVRP) where the maximum distance traveled by any EV is\nminimized while considering charging stations for recharging. We propose an\nefficient branch and cut framework and a three-phase hybrid heuristic algorithm\nthat can efficiently solve a variety of instances. Extensive computational\nresults and sensitivity analyses are performed to corroborate the efficiency of\nthe proposed approach, both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 18:45:26 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 17:14:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Fazeli", "Seyed Sajjad", ""], ["Venkatachalam", "Saravanan", ""], ["Smereka", "Jonathon M.", ""]]}, {"id": "2008.03391", "submitter": "Pengjie Ren", "authors": "Phillip Lippe, Pengjie Ren, Hinda Haned, Bart Voorn, and Maarten de\n  Rijke", "title": "Diversifying Task-oriented Dialogue Response Generation with Prototype\n  Guided Paraphrasing", "comments": "under review at TASLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for Dialogue Response Generation (DRG) in Task-oriented\nDialogue Systems (TDSs) can be grouped into two categories: template-based and\ncorpus-based. The former prepare a collection of response templates in advance\nand fill the slots with system actions to produce system responses at runtime.\nThe latter generate system responses token by token by taking system actions\ninto account. While template-based DRG provides high precision and highly\npredictable responses, they usually lack in terms of generating diverse and\nnatural responses when compared to (neural) corpus-based approaches.\nConversely, while corpus-based DRG methods are able to generate natural\nresponses, we cannot guarantee their precision or predictability. Moreover, the\ndiversity of responses produced by today's corpus-based DRG methods is still\nlimited. We propose to combine the merits of template-based and corpus-based\nDRGs by introducing a prototype-based, paraphrasing neural network, called\nP2-Net, which aims to enhance quality of the responses in terms of both\nprecision and diversity. Instead of generating a response from scratch, P2-Net\ngenerates system responses by paraphrasing template-based responses. To\nguarantee the precision of responses, P2-Net learns to separate a response into\nits semantics, context influence, and paraphrasing noise, and to keep the\nsemantics unchanged during paraphrasing. To introduce diversity, P2-Net\nrandomly samples previous conversational utterances as prototypes, from which\nthe model can then extract speaking style information. We conduct extensive\nexperiments on the MultiWOZ dataset with both automatic and human evaluations.\nThe results show that P2-Net achieves a significant improvement in diversity\nwhile preserving the semantics of responses.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:25:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Lippe", "Phillip", ""], ["Ren", "Pengjie", ""], ["Haned", "Hinda", ""], ["Voorn", "Bart", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2008.03424", "submitter": "Xingwen Zhang", "authors": "Xingwen Zhang and Shuang Yang", "title": "Learning (Re-)Starting Solutions for Vehicle Routing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in solving a combinatorial optimization problem is how to\nguide the agent (i.e., solver) to efficiently explore the enormous search\nspace. Conventional approaches often rely on enumeration (e.g., exhaustive,\nrandom, or tabu search) or have to restrict the exploration to rather limited\nregions (e.g., a single path as in iterative algorithms). In this paper, we\nshow it is possible to use machine learning to speedup the exploration. In\nparticular, a value network is trained to evaluate solution candidates, which\nprovides a useful structure (i.e., an approximate value surface) over the\nsearch space; this value network is then used to screen solutions to help a\nblack-box optimization agent to initialize or restart so as to navigate through\nthe search space towards desirable solutions. Experiments demonstrate that the\nproposed ``Learn to Restart'' algorithm achieves promising results in solving\nCapacitated Vehicle Routing Problems (CVRPs).\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 02:53:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhang", "Xingwen", ""], ["Yang", "Shuang", ""]]}, {"id": "2008.03444", "submitter": "Xinyi Xu Mr", "authors": "Xinyi Xu and Tiancheng Huang and Pengfei Wei and Akshay Narayan and\n  Tze-Yun Leong", "title": "Hierarchical Reinforcement Learning in StarCraft II with Human Expertise\n  in Subgoals Selection", "comments": "In Submission to AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is inspired by recent advances in hierarchical reinforcement\nlearning (HRL) (Barto and Mahadevan 2003; Hengst 2010), and improvements in\nlearning efficiency from heuristic-based subgoal selection, experience replay\n(Lin 1993; Andrychowicz et al. 2017), and task-based curriculum learning\n(Bengio et al. 2009; Zaremba and Sutskever 2014). We propose a new method to\nintegrate HRL, experience replay and effective subgoal selection through an\nimplicit curriculum design based on human expertise to support sample-efficient\nlearning and enhance interpretability of the agent's behavior. Human expertise\nremains indispensable in many areas such as medicine (Buch, Ahmed, and\nMaruthappu 2018) and law (Cath 2018), where interpretability, explainability\nand transparency are crucial in the decision making process, for ethical and\nlegal reasons. Our method simplifies the complex task sets for achieving the\noverall objectives by decomposing them into subgoals at different levels of\nabstraction. Incorporating relevant subjective knowledge also significantly\nreduces the computational resources spent in exploration for RL, especially in\nhigh speed, changing, and complex environments where the transition dynamics\ncannot be effectively learned and modelled in a short time. Experimental\nresults in two StarCraft II (SC2) (Vinyals et al. 2017) minigames demonstrate\nthat our method can achieve better sample efficiency than flat and end-to-end\nRL methods, and provides an effective method for explaining the agent's\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 04:56:30 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 00:15:12 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 01:15:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Xinyi", ""], ["Huang", "Tiancheng", ""], ["Wei", "Pengfei", ""], ["Narayan", "Akshay", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2008.03496", "submitter": "Volkan Patoglu", "authors": "Momina Rizwan, Volkan Patoglu, Esra Erdem", "title": "Human Robot Collaborative Assembly Planning: An Answer Set Programming\n  Approach", "comments": "36th International Conference on Logic Programming (ICLP 2020),\n  University Of Calabria, Rende (CS), Italy, September 2020, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For planning an assembly of a product from a given set of parts, robots\nnecessitate certain cognitive skills: high-level planning is needed to decide\nthe order of actuation actions, while geometric reasoning is needed to check\nthe feasibility of these actions. For collaborative assembly tasks with humans,\nrobots require further cognitive capabilities, such as commonsense reasoning,\nsensing, and communication skills, not only to cope with the uncertainty caused\nby incomplete knowledge about the humans' behaviors but also to ensure safer\ncollaborations. We propose a novel method for collaborative assembly planning\nunder uncertainty, that utilizes hybrid conditional planning extended with\ncommonsense reasoning and a rich set of communication actions for collaborative\ntasks. Our method is based on answer set programming. We show the applicability\nof our approach in a real-world assembly domain, where a bi-manual Baxter robot\ncollaborates with a human teammate to assemble furniture. This manuscript is\nunder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 11:31:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rizwan", "Momina", ""], ["Patoglu", "Volkan", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.03518", "submitter": "Joshua Bertram", "authors": "Joshua R Bertram, Peng Wei, Joseph Zambreno", "title": "Scalable FastMDP for Pre-departure Airspace Reservation and Strategic\n  De-conflict", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-departure flight plan scheduling for Urban Air Mobility (UAM) and cargo\ndelivery drones will require on-demand scheduling of large numbers of aircraft.\nWe examine the scalability of an algorithm known as FastMDP which was shown to\nperform well in deconflicting many dozens of aircraft in a dense airspace\nenvironment with terrain. We show that the algorithm can adapted to perform\nfirst-come-first-served pre-departure flight plan scheduling where conflict\nfree flight plans are generated on demand. We demonstrate a parallelized\nimplementation of the algorithm on a Graphics Processor Unit (GPU) which we\nterm FastMDP-GPU and show the level of performance and scaling that can be\nachieved. Our results show that on commodity GPU hardware we can perform flight\nplan scheduling against 2000-3000 known flight plans and with server-class\nhardware the performance can be higher. We believe the results show promise for\nimplementing a large scale UAM scheduler capable of performing on-demand flight\nscheduling that would be suitable for both a centralized or distributed flight\nplanning system\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:25:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bertram", "Joshua R", ""], ["Wei", "Peng", ""], ["Zambreno", "Joseph", ""]]}, {"id": "2008.03519", "submitter": "Lucas Tian", "authors": "Lucas Y. Tian, Kevin Ellis, Marta Kryven, Joshua B. Tenenbaum", "title": "Learning abstract structure for drawing by efficient motor program\n  induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans flexibly solve new problems that differ qualitatively from those they\nwere trained on. This ability to generalize is supported by learned concepts\nthat capture structure common across different problems. Here we develop a\nnaturalistic drawing task to study how humans rapidly acquire structured prior\nknowledge. The task requires drawing visual objects that share underlying\nstructure, based on a set of composable geometric rules. We show that people\nspontaneously learn abstract drawing procedures that support generalization,\nand propose a model of how learners can discover these reusable drawing\nprograms. Trained in the same setting as humans, and constrained to produce\nefficient motor actions, this model discovers new drawing routines that\ntransfer to test objects and resemble learned features of human sequences.\nThese results suggest that two principles guiding motor program induction in\nthe model - abstraction (general programs that ignore object-specific details)\nand compositionality (recombining previously learned programs) - are key for\nexplaining how humans learn structured internal representations that guide\nflexible reasoning and learning.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:31:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Tian", "Lucas Y.", ""], ["Ellis", "Kevin", ""], ["Kryven", "Marta", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2008.03526", "submitter": "Antonius Weinzierl", "authors": "Antonius Weinzierl, Richard Taupe and Gerhard Friedrich", "title": "Advancing Lazy-Grounding ASP Solving Techniques -- Restarts, Phase\n  Saving, Heuristics, and More", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer-Set Programming (ASP) is a powerful and expressive knowledge\nrepresentation paradigm with a significant number of applications in\nlogic-based AI. The traditional ground-and-solve approach, however, requires\nASP programs to be grounded upfront and thus suffers from the so-called\ngrounding bottleneck (i.e., ASP programs easily exhaust all available memory\nand thus become unsolvable). As a remedy, lazy-grounding ASP solvers have been\ndeveloped, but many state-of-the-art techniques for grounded ASP solving have\nnot been available to them yet. In this work we present, for the first time,\nadaptions to the lazy-grounding setting for many important techniques, like\nrestarts, phase saving, domain-independent heuristics, and learned-clause\ndeletion. Furthermore, we investigate their effects and in general observe a\nlarge improvement in solving capabilities and also uncover negative effects in\ncertain cases, indicating the need for portfolio solving as known from other\nsolvers. Under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 13:55:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Weinzierl", "Antonius", ""], ["Taupe", "Richard", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "2008.03546", "submitter": "Anyi Rao", "authors": "Jiangyue Xia, Anyi Rao, Qingqiu Huang, Linning Xu, Jiangtao Wen, Dahua\n  Lin", "title": "Online Multi-modal Person Search in Videos", "comments": "ECCV2020. Project page:\n  http://movienet.site/projects/eccv20onlineperson.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of searching certain people in videos has seen increasing potential\nin real-world applications, such as video organization and editing. Most\nexisting approaches are devised to work in an offline manner, where identities\ncan only be inferred after an entire video is examined. This working manner\nprecludes such methods from being applied to online services or those\napplications that require real-time responses. In this paper, we propose an\nonline person search framework, which can recognize people in a video on the\nfly. This framework maintains a multimodal memory bank at its heart as the\nbasis for person recognition, and updates it dynamically with a policy obtained\nby reinforcement learning. Our experiments on a large movie dataset show that\nthe proposed method is effective, not only achieving remarkable improvements\nover online schemes but also outperforming offline methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 15:48:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xia", "Jiangyue", ""], ["Rao", "Anyi", ""], ["Huang", "Qingqiu", ""], ["Xu", "Linning", ""], ["Wen", "Jiangtao", ""], ["Lin", "Dahua", ""]]}, {"id": "2008.03573", "submitter": "Esra Erdem", "authors": "Aysu Bogatarkan and Esra Erdem", "title": "Explanation Generation for Multi-Modal Multi-Agent Path Finding with\n  Optimal Resource Utilization using Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-agent path finding (MAPF) problem is a combinatorial search problem\nthat aims at finding paths for multiple agents (e.g., robots) in an environment\n(e.g., an autonomous warehouse) such that no two agents collide with each\nother, and subject to some constraints on the lengths of paths. We consider a\ngeneral version of MAPF, called mMAPF, that involves multi-modal transportation\nmodes (e.g., due to velocity constraints) and consumption of different types of\nresources (e.g., batteries). The real-world applications of mMAPF require\nflexibility (e.g., solving variations of mMAPF) as well as explainability. Our\nearlier studies on mMAPF have focused on the former challenge of flexibility.\nIn this study, we focus on the latter challenge of explainability, and\nintroduce a method for generating explanations for queries regarding the\nfeasibility and optimality of solutions, the nonexistence of solutions, and the\nobservations about solutions. Our method is based on answer set programming.\nThis paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 18:34:34 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bogatarkan", "Aysu", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.03620", "submitter": "Javier Del Ser Dr.", "authors": "Aritz D. Martinez, Javier Del Ser, Esther Villar-Rodriguez, Eneko\n  Osaba, Javier Poyatos, Siham Tabik, Daniel Molina, Francisco Herrera", "title": "Lights and Shadows in Evolutionary Deep Learning: Taxonomy, Critical\n  Methodological Analysis, Cases of Study, Learned Lessons, Recommendations and\n  Challenges", "comments": "64 pages, 18 figures, under review for its consideration in\n  Information Fusion journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much has been said about the fusion of bio-inspired optimization algorithms\nand Deep Learning models for several purposes: from the discovery of network\ntopologies and hyper-parametric configurations with improved performance for a\ngiven task, to the optimization of the model's parameters as a replacement for\ngradient-based solvers. Indeed, the literature is rich in proposals showcasing\nthe application of assorted nature-inspired approaches for these tasks. In this\nwork we comprehensively review and critically examine contributions made so far\nbased on three axes, each addressing a fundamental question in this research\navenue: a) optimization and taxonomy (Why?), including a historical\nperspective, definitions of optimization problems in Deep Learning, and a\ntaxonomy associated with an in-depth analysis of the literature, b) critical\nmethodological analysis (How?), which together with two case studies, allows us\nto address learned lessons and recommendations for good practices following the\nanalysis of the literature, and c) challenges and new directions of research\n(What can be done, and what for?). In summary, three axes - optimization and\ntaxonomy, critical analysis, and challenges - which outline a complete vision\nof a merger of two technologies drawing up an exciting future for this area of\nfusion research.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 00:25:06 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Martinez", "Aritz D.", ""], ["Del Ser", "Javier", ""], ["Villar-Rodriguez", "Esther", ""], ["Osaba", "Eneko", ""], ["Poyatos", "Javier", ""], ["Tabik", "Siham", ""], ["Molina", "Daniel", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.03625", "submitter": "Shichao Xu", "authors": "Shichao Xu, Yixuan Wang, Yanzhi Wang, Zheng O'Neill, Qi Zhu", "title": "One for Many: Transfer Learning for Building HVAC Control", "comments": "Buildsys 2020 Accepted", "journal-ref": null, "doi": "10.1145/3408308.3427617", "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of building heating, ventilation, and air conditioning (HVAC)\nsystem is critically important, as it accounts for around half of building\nenergy consumption and directly affects occupant comfort, productivity, and\nhealth. Traditional HVAC control methods are typically based on creating\nexplicit physical models for building thermal dynamics, which often require\nsignificant effort to develop and are difficult to achieve sufficient accuracy\nand efficiency for runtime building control and scalability for field\nimplementations. Recently, deep reinforcement learning (DRL) has emerged as a\npromising data-driven method that provides good control performance without\nanalyzing physical models at runtime. However, a major challenge to DRL (and\nmany other data-driven learning methods) is the long training time it takes to\nreach the desired performance. In this work, we present a novel transfer\nlearning based approach to overcome this challenge. Our approach can\neffectively transfer a DRL-based HVAC controller trained for the source\nbuilding to a controller for the target building with minimal effort and\nimproved performance, by decomposing the design of neural network controller\ninto a transferable front-end network that captures building-agnostic behavior\nand a back-end network that can be efficiently trained for each specific\nbuilding. We conducted experiments on a variety of transfer scenarios between\nbuildings with different sizes, numbers of thermal zones, materials and\nlayouts, air conditioner types, and ambient weather conditions. The\nexperimental results demonstrated the effectiveness of our approach in\nsignificantly reducing the training time, energy cost, and temperature\nviolations.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 01:32:37 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 01:00:22 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Xu", "Shichao", ""], ["Wang", "Yixuan", ""], ["Wang", "Yanzhi", ""], ["O'Neill", "Zheng", ""], ["Zhu", "Qi", ""]]}, {"id": "2008.03641", "submitter": "Jose Frederico Simoes Bravo Ferreira", "authors": "Jose F. S. Bravo-Ferreira and David Cowburn and Yuehaw Khoo and Amit\n  Singer", "title": "NMR Assignment through Linear Programming", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear Magnetic Resonance (NMR) Spectroscopy is the second most used\ntechnique (after X-ray crystallography) for structural determination of\nproteins. A computational challenge in this technique involves solving a\ndiscrete optimization problem that assigns the resonance frequency to each atom\nin the protein. We present a novel linear programming formulation of the\nproblem which gives state-of-the-art results in simulated and experimental\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 03:46:45 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Bravo-Ferreira", "Jose F. S.", ""], ["Cowburn", "David", ""], ["Khoo", "Yuehaw", ""], ["Singer", "Amit", ""]]}, {"id": "2008.03674", "submitter": "Pierre-Alain Fayolle", "authors": "Markus Friedrich and Christoph Roch and Sebastian Feld and Carsten\n  Hahn and Pierre-Alain Fayolle", "title": "A Flexible Pipeline for the Optimization of CSG Trees", "comments": "The 28th International Conference in Central Europe on Computer\n  Graphics, Visualization and Computer Vision (WSCG) 2020, p. 79-88. Update:\n  Enlarge some of the figures and move some of the figures to the end", "journal-ref": null, "doi": "10.24132/CSRN.2020.3001.10", "report-no": null, "categories": "cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CSG trees are an intuitive, yet powerful technique for the representation of\ngeometry using a combination of Boolean set-operations and geometric\nprimitives. In general, there exists an infinite number of trees all describing\nthe same 3D solid. However, some trees are optimal regarding the number of used\noperations, their shape or other attributes, like their suitability for\nintuitive, human-controlled editing. In this paper, we present a systematic\ncomparison of newly developed and existing tree optimization methods and\npropose a flexible processing pipeline with a focus on tree editability. The\npipeline uses a redundancy removal and decomposition stage for complexity\nreduction and different (meta-)heuristics for remaining tree optimization. We\nalso introduce a new quantitative measure for CSG tree editability and show how\nit can be used as a constraint in the optimization process.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 06:45:10 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 05:43:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Friedrich", "Markus", ""], ["Roch", "Christoph", ""], ["Feld", "Sebastian", ""], ["Hahn", "Carsten", ""], ["Fayolle", "Pierre-Alain", ""]]}, {"id": "2008.03707", "submitter": "Li Xia", "authors": "Li Xia", "title": "Risk-Sensitive Markov Decision Processes with Combined Metrics of Mean\n  and Variance", "comments": "43 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the optimization problem of an infinite stage\ndiscrete time Markov decision process (MDP) with a long-run average metric\nconsidering both mean and variance of rewards together. Such performance metric\nis important since the mean indicates average returns and the variance\nindicates risk or fairness. However, the variance metric couples the rewards at\nall stages, the traditional dynamic programming is inapplicable as the\nprinciple of time consistency fails. We study this problem from a new\nperspective called the sensitivity-based optimization theory. A performance\ndifference formula is derived and it can quantify the difference of the\nmean-variance combined metrics of MDPs under any two different policies. The\ndifference formula can be utilized to generate new policies with strictly\nimproved mean-variance performance. A necessary condition of the optimal policy\nand the optimality of deterministic policies are derived. We further develop an\niterative algorithm with a form of policy iteration, which is proved to\nconverge to local optima both in the mixed and randomized policy space.\nSpecially, when the mean reward is constant in policies, the algorithm is\nguaranteed to converge to the global optimum. Finally, we apply our approach to\nstudy the fluctuation reduction of wind power in an energy storage system,\nwhich demonstrates the potential applicability of our optimization method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 10:35:35 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xia", "Li", ""]]}, {"id": "2008.03717", "submitter": "Antonios Minas Krasakis", "authors": "Antonios Minas Krasakis, Mohammad Aliannejadi, Nikos Voskarides,\n  Evangelos Kanoulas", "title": "Analysing the Effect of Clarifying Questions on Document Ranking in\n  Conversational Search", "comments": "Proceedings of the 2020 ACM SIGIR International Conference on the\n  Theory of Information Retrieval (ICTIR '20), September 14-17, 2020", "journal-ref": null, "doi": "10.1145/3409256.3409817", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on conversational search highlights the importance of\nmixed-initiative in conversations. To enable mixed-initiative, the system\nshould be able to ask clarifying questions to the user. However, the ability of\nthe underlying ranking models (which support conversational search) to account\nfor these clarifying questions and answers has not been analysed when ranking\ndocuments, at large. To this end, we analyse the performance of a lexical\nranking model on a conversational search dataset with clarifying questions. We\ninvestigate, both quantitatively and qualitatively, how different aspects of\nclarifying questions and user answers affect the quality of ranking. We argue\nthat there needs to be some fine-grained treatment of the entire conversational\nround of clarification, based on the explicit feedback which is present in such\nmixed-initiative settings. Informed by our findings, we introduce a simple\nheuristic-based lexical baseline, that significantly outperforms the existing\nnaive baselines. Our work aims to enhance our understanding of the challenges\npresent in this particular task and inform the design of more appropriate\nconversational ranking models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 12:55:16 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:21:13 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Krasakis", "Antonios Minas", ""], ["Aliannejadi", "Mohammad", ""], ["Voskarides", "Nikos", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "2008.03787", "submitter": "Ahmed Qureshi", "authors": "Ahmed H. Qureshi, Jiangeng Dong, Austin Choe, and Michael C. Yip", "title": "Neural Manipulation Planning on Constraint Manifolds", "comments": "This is the preprint version of the paper published at IEEE Robotics\n  and Automation Letters 2020", "journal-ref": "in IEEE Robotics and Automation Letters, vol. 5, no. 4, pp.\n  6089-6096, Oct. 2020", "doi": "10.1109/LRA.2020.3010220", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of task constraints imposes a significant challenge to motion\nplanning. Despite all recent advancements, existing algorithms are still\ncomputationally expensive for most planning problems. In this paper, we present\nConstrained Motion Planning Networks (CoMPNet), the first neural planner for\nmultimodal kinematic constraints. Our approach comprises the following\ncomponents: i) constraint and environment perception encoders; ii) neural robot\nconfiguration generator that outputs configurations on/near the constraint\nmanifold(s), and iii) a bidirectional planning algorithm that takes the\ngenerated configurations to create a feasible robot motion trajectory. We show\nthat CoMPNet solves practical motion planning tasks involving both\nunconstrained and constrained problems. Furthermore, it generalizes to new\nunseen locations of the objects, i.e., not seen during training, in the given\nenvironments with high success rates. When compared to the state-of-the-art\nconstrained motion planning algorithms, CoMPNet outperforms by order of\nmagnitude improvement in computational speed with a significantly lower\nvariance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 18:58:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Qureshi", "Ahmed H.", ""], ["Dong", "Jiangeng", ""], ["Choe", "Austin", ""], ["Yip", "Michael C.", ""]]}, {"id": "2008.03845", "submitter": "Svetlana Yanushkevich", "authors": "Svetlana Yanushkevich, Vlad Shmerko", "title": "On the Gap between Epidemiological Surveillance and Preparedness", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary Epidemiological Surveillance (ES) relies heavily on data\nanalytics. These analytics are critical input for pandemics preparedness\nnetworks; however, this input is not integrated into a form suitable for\ndecision makers or experts in preparedness. A decision support system (DSS)\nwith Computational Intelligence (CI) tools is required to bridge the gap\nbetween epidemiological model of evidence and expert group decision. We argue\nthat such DSS shall be a cognitive dynamic system enabling the CI and human\nexpert to work together. The core of such DSS must be based on machine\nreasoning techniques such as probabilistic inference, and shall be capable of\nestimating risks, reliability and biases in decision making.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 00:43:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yanushkevich", "Svetlana", ""], ["Shmerko", "Vlad", ""]]}, {"id": "2008.03900", "submitter": "David Martin", "authors": "David L. Martin, Peter F. Patel-Schneider", "title": "Wikidata Constraints on MARS (Extended Technical Report)", "comments": "22 pages, no figures. V2 includes a title change, revision of the\n  abstract, and a handful of minor changes in the body of the paper and the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikidata constraints, albeit useful, are represented and processed in an\nincomplete, ad hoc fashion. Constraint declarations do not fully express their\nmeaning, and thus do not provide a precise, unambiguous basis for constraint\nspecification, or a logical foundation for constraint-checking implementations.\nIn prior work we have proposed a logical framework for Wikidata as a whole,\nbased on multi-attributed relational structures (MARS) and related logical\nlanguages. In this paper we explain how constraints are handled in the proposed\nframework, and show that nearly all of Wikidata's existing property constraints\ncan be completely characterized in it, in a natural and economical fashion. We\nalso give characterizations for several proposed property constraints, and show\nthat a variety of non-property constraints can be handled in the same\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 04:49:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 02:57:00 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Martin", "David L.", ""], ["Patel-Schneider", "Peter F.", ""]]}, {"id": "2008.03920", "submitter": "Houman Owhadi", "authors": "Houman Owhadi", "title": "Do ideas have shape? Plato's theory of forms as the continuous limit of\n  artificial neural networks", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that ResNets converge, in the infinite depth limit, to a\ngeneralization of image registration algorithms. In this generalization, images\nare replaced by abstractions (ideas) living in high dimensional RKHS spaces,\nand material points are replaced by data points. Whereas computational anatomy\naligns images via deformations of the material space, this generalization\naligns ideas by via transformations of their RKHS. This identification of\nResNets as idea registration algorithms has several remarkable consequences.\nThe search for good architectures can be reduced to that of good kernels, and\nwe show that the composition of idea registration blocks with reduced\nequivariant multi-channel kernels (introduced here) recovers and generalizes\nCNNs to arbitrary spaces and groups of transformations. Minimizers of $L_2$\nregularized ResNets satisfy a discrete least action principle implying the near\npreservation of the norm of weights and biases across layers. The parameters of\ntrained ResNets can be identified as solutions of an autonomous Hamiltonian\nsystem defined by the activation function and the architecture of the ANN.\nMomenta variables provide a sparse representation of the parameters of a\nResNet. The registration regularization strategy provides a provably robust\nalternative to Dropout for ANNs. Pointwise RKHS error estimates lead to\ndeterministic error estimates for ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 15:55:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Owhadi", "Houman", ""]]}, {"id": "2008.04007", "submitter": "Ashith Babu Dr.", "authors": "RB Ashith Shyam, Zhou Hao, Umberto Montanaro, Gerhard Neumann", "title": "Imitation Learning for Autonomous Trajectory Learning of Robot Arms in\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adds on to the on-going efforts to provide more autonomy to space\nrobots. Here the concept of programming by demonstration or imitation learning\nis used for trajectory planning of manipulators mounted on small spacecraft.\nFor greater autonomy in future space missions and minimal human intervention\nthrough ground control, a robot arm having 7-Degrees of Freedom (DoF) is\nenvisaged for carrying out multiple tasks like debris removal, on-orbit\nservicing and assembly. Since actual hardware implementation of microgravity\nenvironment is extremely expensive, the demonstration data for trajectory\nlearning is generated using a model predictive controller (MPC) in a physics\nbased simulator. The data is then encoded compactly by Probabilistic Movement\nPrimitives (ProMPs). This offline trajectory learning allows faster\nreproductions and also avoids any computationally expensive optimizations after\ndeployment in a space environment. It is shown that the probabilistic\ndistribution can be used to generate trajectories to previously unseen\nsituations by conditioning the distribution. The motion of the robot (or\nmanipulator) arm induces reaction forces on the spacecraft hub and hence its\nattitude changes prompting the Attitude Determination and Control System (ADCS)\nto take large corrective action that drains energy out of the system. By having\na robot arm with redundant DoF helps in finding several possible trajectories\nfrom the same start to the same target. This allows the ProMP trajectory\ngenerator to sample out the trajectory which is obstacle free as well as having\nminimal attitudinal disturbances thereby reducing the load on ADCS.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:18:04 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Shyam", "RB Ashith", ""], ["Hao", "Zhou", ""], ["Montanaro", "Umberto", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2008.04008", "submitter": "Rafael Kiesel", "authors": "Thomas Eiter and Rafael Kiesel", "title": "ASP(AC): Answer Set Programming with Algebraic Constraints", "comments": "32 pages, 16 pages are appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted Logic is a powerful tool for the specification of calculations over\nsemirings that depend on qualitative information. Using a novel combination of\nWeighted Logic and Here-and-There (HT) Logic, in which this dependence is based\non intuitionistic grounds, we introduce Answer Set Programming with Algebraic\nConstraints (ASP(AC)), where rules may contain constraints that compare\nsemiring values to weighted formula evaluations. Such constraints provide\nstreamlined access to a manifold of constructs available in ASP, like\naggregates, choice constraints, and arithmetic operators. They extend some of\nthem and provide a generic framework for defining programs with algebraic\ncomputation, which can be fruitfully used e.g. for provenance semantics of\ndatalog programs. While undecidable in general, expressive fragments of ASP(AC)\ncan be exploited for effective problem-solving in a rich framework. This work\nis under consideration for acceptance in Theory and Practice of Logic\nProgramming.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 10:20:49 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Eiter", "Thomas", ""], ["Kiesel", "Rafael", ""]]}, {"id": "2008.04047", "submitter": "Abdelhak Loukkal", "authors": "Abdelhak Loukkal (UTC), Yves Grandvalet (Heudiasyc), Tom Drummond, You\n  Li (NRCIEA)", "title": "Driving among Flatmobiles: Bird-Eye-View occupancy grids from a\n  monocular camera for holistic trajectory planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera-based end-to-end driving neural networks bring the promise of a\nlow-cost system that maps camera images to driving control commands. These\nnetworks are appealing because they replace laborious hand engineered building\nblocks but their black-box nature makes them difficult to delve in case of\nfailure. Recent works have shown the importance of using an explicit\nintermediate representation that has the benefits of increasing both the\ninterpretability and the accuracy of networks' decisions. Nonetheless, these\ncamera-based networks reason in camera view where scale is not homogeneous and\nhence not directly suitable for motion forecasting. In this paper, we introduce\na novel monocular camera-only holistic end-to-end trajectory planning network\nwith a Bird-Eye-View (BEV) intermediate representation that comes in the form\nof binary Occupancy Grid Maps (OGMs). To ease the prediction of OGMs in BEV\nfrom camera images, we introduce a novel scheme where the OGMs are first\npredicted as semantic masks in camera view and then warped in BEV using the\nhomography between the two planes. The key element allowing this transformation\nto be applied to 3D objects such as vehicles, consists in predicting solely\ntheir footprint in camera-view, hence respecting the flat world hypothesis\nimplied by the homography.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 12:16:44 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Loukkal", "Abdelhak", "", "UTC"], ["Grandvalet", "Yves", "", "Heudiasyc"], ["Drummond", "Tom", "", "NRCIEA"], ["Li", "You", "", "NRCIEA"]]}, {"id": "2008.04057", "submitter": "Matthew Ciolino", "authors": "David Noever, Matt Ciolino and Josh Kalin", "title": "The Chess Transformer: Mastering Play using Generative Language Models", "comments": "7 Pages, 6 Figures, AAAI Format, AAAI 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that natural language transformers can support more\ngeneric strategic modeling, particularly for text-archived games. In addition\nto learning natural language skills, the abstract transformer architecture can\ngenerate meaningful moves on a chessboard. With further fine-tuning, the\ntransformer learns complex gameplay by training on 2.8 million chess games in\nPortable Game Notation. After 30,000 training steps, OpenAI's Generative\nPre-trained Transformer (GPT-2) optimizes weights for 774 million parameters.\nThis fine-tuned Chess Transformer generates plausible strategies and displays\ngame formations identifiable as classic openings, such as English or the Slav\nExchange. Finally, in live play, the novel model demonstrates a\nhuman-to-transformer interface that correctly filters illegal moves and\nprovides a novel method to challenge the transformer's chess strategies. We\nanticipate future work will build on this transformer's promise, particularly\nin other strategy games where features can capture the underlying complex rule\nsyntax from simple but expressive player annotations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 18:04:36 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 13:38:42 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 20:05:54 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 17:31:29 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 17:12:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Noever", "David", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""]]}, {"id": "2008.04068", "submitter": "Param Vir Singh", "authors": "Runshan Fu, Yan Huang and Param Vir Singh", "title": "Crowd, Lending, Machine, and Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data and machine learning (ML) algorithms are key drivers of many fintech\ninnovations. While it may be obvious that replacing humans with machine would\nincrease efficiency, it is not clear whether and where machines can make better\ndecisions than humans. We answer this question in the context of crowd lending,\nwhere decisions are traditionally made by a crowd of investors. Using data from\nProsper.com, we show that a reasonably sophisticated ML algorithm predicts\nlisting default probability more accurately than crowd investors. The dominance\nof the machine over the crowd is more pronounced for highly risky listings. We\nthen use the machine to make investment decisions, and find that the machine\nbenefits not only the lenders but also the borrowers. When machine prediction\nis used to select loans, it leads to a higher rate of return for investors and\nmore funding opportunities for borrowers with few alternative funding options.\nWe also find suggestive evidence that the machine is biased in gender and race\neven when it does not use gender and race information as input. We propose a\ngeneral and effective \"debasing\" method that can be applied to any prediction\nfocused ML applications, and demonstrate its use in our context. We show that\nthe debiased ML algorithm, which suffers from lower prediction accuracy, still\nleads to better investment decisions compared with the crowd. These results\nindicate that ML can help crowd lending platforms better fulfill the promise of\nproviding access to financial resources to otherwise underserved individuals\nand ensure fairness in the allocation of these resources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 01:26:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Fu", "Runshan", ""], ["Huang", "Yan", ""], ["Singh", "Param Vir", ""]]}, {"id": "2008.04070", "submitter": "Mark Fox", "authors": "Alanna Komisar and Mark S. Fox", "title": "An Energy Ontology for Global City Indicators (ISO 37120)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To create tomorrow's smarter cities, today's initiatives will need to create\nmeasurable improvements. However, a city is a complex system and measuring its\nperformance generates a breadth of issues. Specifically, determining what\ncriteria should be measured, how indications should be defined, and how should\nthe identified indicators be derived. This working paper is one in series that\naddresses the creation of a Semantic Web based representation of the 17\ndifferent themes of ISO 37120 indicators as part of the larger PolisGnosis\nProject (Fox, 2017). We define a standard ontology for representing general\nknowledge for the Energy Theme indicators, and for representing both the\ndefinition and data used to derive the Energy indicators.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 15:13:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Komisar", "Alanna", ""], ["Fox", "Mark S.", ""]]}, {"id": "2008.04071", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "On Controllability of AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invention of artificial general intelligence is predicted to cause a shift in\nthe trajectory of human civilization. In order to reap the benefits and avoid\npitfalls of such powerful technology it is important to be able to control it.\nHowever, possibility of controlling artificial general intelligence and its\nmore advanced version, superintelligence, has not been formally established. In\nthis paper, we present arguments as well as supporting evidence from multiple\ndomains indicating that advanced AI can't be fully controlled. Consequences of\nuncontrollability of AI are discussed with respect to future of humanity and\nresearch on AI, and AI safety and security.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 02:49:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "2008.04073", "submitter": "Sasanka Sekhar Chanda", "authors": "Debarag Narayan Banerjee and Sasanka Sekhar Chanda", "title": "AI Failures: A Review of Underlying Issues", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instances of Artificial Intelligence (AI) systems failing to deliver\nconsistent, satisfactory performance are legion. We investigate why AI failures\noccur. We address only a narrow subset of the broader field of AI Safety. We\nfocus on AI failures on account of flaws in conceptualization, design and\ndeployment. Other AI Safety issues like trade-offs between privacy and security\nor convenience, bad actors hacking into AI systems to create mayhem or bad\nactors deploying AI for purposes harmful to humanity and are out of scope of\nour discussion. We find that AI systems fail on account of omission and\ncommission errors in the design of the AI system, as well as upon failure to\ndevelop an appropriate interpretation of input information. Moreover, even when\nthere is no significant flaw in the AI software, an AI system may fail because\nthe hardware is incapable of robust performance across environments. Finally an\nAI system is quite likely to fail in situations where, in effect, it is called\nupon to deliver moral judgments -- a capability AI does not possess. We observe\ncertain trade-offs in measures to mitigate a subset of AI failures and provide\nsome recommendations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 15:31:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Banerjee", "Debarag Narayan", ""], ["Chanda", "Sasanka Sekhar", ""]]}, {"id": "2008.04088", "submitter": "Luc Le Magoarou", "authors": "Taha Yassine (IRT b-com, Hypermedia), Luc Le Magoarou (IRT b-com,\n  Hypermedia)", "title": "mpNet: variable depth unfolded neural network for massive MIMO channel\n  estimation", "comments": "arXiv admin note: text overlap with arXiv:2004.14615", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive MIMO communication systems have a huge potential both in terms of\ndata rate and energy efficiency, although channel estimation becomes\nchallenging for a large number of antennas. Using a physical model allows to\nease the problem by injecting a priori information based on the physics of\npropagation. However, such a model rests on simplifying assumptions and\nrequires to know precisely the configuration of the system, which is\nunrealistic in practice. In this paper we present mpNet, an unfolded neural\nnetwork specifically designed for massive MIMO channel estimation. It is\ntrained online in an unsupervised way. Moreover, mpNet is computationally\nefficient and automatically adapts its depth to the SNR. The method we propose\nadds flexibility to physical channel models by allowing a base station to\nautomatically correct its channel estimation algorithm based on incoming data,\nwithout the need for a separate offline training phase. It is applied to\nrealistic millimeter wave channels and shows great performance, achieving a\nchannel estimation error almost as low as one would get with a perfectly\ncalibrated system. It also allows incident detection and automatic correction,\nmaking the base station resilient and able to automatically adapt to changes in\nits environment.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:23:44 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 11:44:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yassine", "Taha", "", "IRT b-com, Hypermedia"], ["Magoarou", "Luc Le", "", "IRT b-com,\n  Hypermedia"]]}, {"id": "2008.04096", "submitter": "Amir Hosein Afshar Sedigh", "authors": "Amir Hosein Afshar Sedigh, Martin K. Purvis, Bastin Tony Roy\n  Savarimuthu, Maryam A. Purvis, and Christopher K. Frantz", "title": "Impact of meta-roles on the evolution of organisational institutions", "comments": "arXiv admin note: text overlap with arXiv:2004.11858", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of changes in agents' beliefs coupled with\ndynamics in agents' meta-roles on the evolution of institutions. The study\nembeds agents' meta-roles in the BDI architecture. In this context, the study\nscrutinises the impact of cognitive dissonance in agents due to unfairness of\ninstitutions. To showcase our model, two historical long-distance trading\nsocieties, namely Armenian merchants of New-Julfa and the English East India\nCompany are simulated. Results show how change in roles of agents coupled with\nspecific institutional characteristics leads to changes of the rules in the\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 07:00:00 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sedigh", "Amir Hosein Afshar", ""], ["Purvis", "Martin K.", ""], ["Savarimuthu", "Bastin Tony Roy", ""], ["Purvis", "Maryam A.", ""], ["Frantz", "Christopher K.", ""]]}, {"id": "2008.04105", "submitter": "Dagnachew Azene Temesgene", "authors": "Dagnachew Azene Temesgene, Marco Miozzo, Deniz G\\\"und\\\"uz and Paolo\n  Dini", "title": "Distributed Deep Reinforcement Learning for Functional Split Control in\n  Energy Harvesting Virtualized Small Cells", "comments": "Submitted to IEEE transaction on sustainable computing. arXiv admin\n  note: text overlap with arXiv:1906.05735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the growing quest for enhanced network capacity, mobile network\noperators (MNOs) are deploying dense infrastructures of small cells. This, in\nturn, increases the power consumption of mobile networks, thus impacting the\nenvironment. As a result, we have seen a recent trend of powering mobile\nnetworks with harvested ambient energy to achieve both environmental and cost\nbenefits. In this paper, we consider a network of virtualized small cells\n(vSCs) powered by energy harvesters and equipped with rechargeable batteries,\nwhich can opportunistically offload baseband (BB) functions to a grid-connected\nedge server depending on their energy availability. We formulate the\ncorresponding grid energy and traffic drop rate minimization problem, and\npropose a distributed deep reinforcement learning (DDRL) solution. Coordination\namong vSCs is enabled via the exchange of battery state information. The\nevaluation of the network performance in terms of grid energy consumption and\ntraffic drop rate confirms that enabling coordination among the vSCs via\nknowledge exchange achieves a performance close to the optimal. Numerical\nresults also confirm that the proposed DDRL solution provides higher network\nperformance, better adaptation to the changing environment, and higher cost\nsavings with respect to a tabular multi-agent reinforcement learning (MRL)\nsolution used as a benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:27:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Temesgene", "Dagnachew Azene", ""], ["Miozzo", "Marco", ""], ["G\u00fcnd\u00fcz", "Deniz", ""], ["Dini", "Paolo", ""]]}, {"id": "2008.04108", "submitter": "Jessica Zangari", "authors": "Giovambattista Ianni, Francesco Pacenza and Jessica Zangari", "title": "Incremental maintenance of overgrounded logic programs with tailored\n  simplifications", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeated execution of reasoning tasks is desirable in many applicative\nscenarios, such as stream reasoning and event processing. When using answer set\nprogramming in such contexts, one can avoid the iterative generation of ground\nprograms thus achieving a significant payoff in terms of computing time.\nHowever, this may require some additional amount of memory and/or the manual\naddition of operational directives in the declarative knowledge base at hand.\nWe introduce a new strategy for generating series of monotonically growing\npropositional programs. The proposed overgrounded programs with tailoring\n(OPTs) can be updated and reused in combination with consecutive inputs. With\nrespect to earlier approaches, our tailored simplification technique reduces\nthe size of instantiated programs. A maintained OPT slowly grows in size from\nan iteration to another while the update cost decreases, especially in later\niterations. In this paper we formally introduce tailored embeddings, a family\nof equivalence-preserving ground programs which are at the theoretical basis of\nOPTs and we describe their properties. We then illustrate an OPT update\nalgorithm and report about our implementation and its performance. This paper\nis under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:50:11 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ianni", "Giovambattista", ""], ["Pacenza", "Francesco", ""], ["Zangari", "Jessica", ""]]}, {"id": "2008.04109", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Ghulam Mohiuddin Bhat", "title": "Deep Q-Network Based Multi-agent Reinforcement Learning with Binary\n  Action Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement\nlearning (RL) use various schemes where in the agents have to learn and\ncommunicate. The learning is however specific to each agent and communication\nmay be satisfactorily designed for the agents. As more complex Deep QNetworks\ncome to the fore, the overall complexity of the multi-agent system increases\nleading to issues like difficulty in training, need for higher resources and\nmore training time, difficulty in fine-tuning, etc. To address these issues we\npropose a simple but efficient DQN based MAS for RL which uses shared state and\nrewards, but agent-specific actions, for updation of the experience replay pool\nof the DQNs, where each agent is a DQN. The benefits of the approach are\noverall simplicity, faster convergence and better performance as compared to\nconventional DQN based approaches. It should be noted that the method can be\nextended to any DQN. As such we use simple DQN and DDQN (Double Q-learning)\nrespectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment)\n, LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized\nenvironment). The proposed approach outperforms the baseline on these tasks by\ndecent margins respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 15:16:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Bhat", "Ghulam Mohiuddin", ""]]}, {"id": "2008.04116", "submitter": "Ross Dempsey", "authors": "Ross Dempsey and Charles Guinn", "title": "A Phase Transition in Minesweeper", "comments": "10 pages, 5 figures. Accepted to FUN with Algorithms 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the average-case complexity of the classic Minesweeper game in which\nplayers deduce the locations of mines on a two-dimensional lattice. Playing\nMinesweeper is known to be co-NP-complete. We show empirically that Minesweeper\nexhibits a phase transition analogous to the well-studied SAT phase transition.\nAbove the critical mine density it becomes almost impossible to play\nMinesweeper by logical inference. We use a reduction to Boolean\nunsatisfiability to characterize the hardness of Minesweeper instances, and\nshow that the hardness peaks at the phase transition. Furthermore, we\ndemonstrate algorithmic barriers at the phase transition for polynomial-time\napproaches to Minesweeper inference. Finally, we comment on expectations for\nthe asymptotic behavior of the phase transition.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:21:13 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Dempsey", "Ross", ""], ["Guinn", "Charles", ""]]}, {"id": "2008.04126", "submitter": "Esra Erdem", "authors": "Yusuf Izmirlioglu, Esra Erdem", "title": "Reasoning about Cardinal Directions between 3-Dimensional Extended\n  Objects using Answer Set Programming", "comments": "Paper presented at the 36th International Conference on Logic\n  Programming (ICLP 2020), University Of Calabria, Rende (CS), Italy, September\n  2020, 29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel formal framework (called 3D-nCDC-ASP) to represent and\nreason about cardinal directions between extended objects in 3-dimensional (3D)\nspace, using Answer Set Programming (ASP). 3D-nCDC-ASP extends Cardinal\nDirectional Calculus (CDC) with a new type of default constraints, and nCDC-ASP\nto 3D. 3D-nCDC-ASP provides a flexible platform offering different types of\nreasoning: Nonmonotonic reasoning with defaults, checking consistency of a set\nof constraints on 3D cardinal directions between objects, explaining\ninconsistencies, and inferring missing CDC relations. We prove the soundness of\n3D-nCDC-ASP, and illustrate its usefulness with applications. This paper is\nunder consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:38:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Izmirlioglu", "Yusuf", ""], ["Erdem", "Esra", ""]]}, {"id": "2008.04130", "submitter": "Longkang Li", "authors": "Longkang Li, Hui-Ling Zhen, Mingxuan Yuan, Jiawen Lu, XialiangTong,\n  Jia Zeng, Jun Wang, Dirk Schnieders", "title": "Bilevel Learning Model Towards Industrial Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic industrial scheduling, aiming at optimizing the sequence of jobs\nover limited resources, is widely needed in manufacturing industries. However,\nexisting scheduling systems heavily rely on heuristic algorithms, which either\ngenerate ineffective solutions or compute inefficiently when job scale\nincreases. Thus, it is of great importance to develop new large-scale\nalgorithms that are not only efficient and effective, but also capable of\nsatisfying complex constraints in practice. In this paper, we propose a Bilevel\nDeep reinforcement learning Scheduler, \\textit{BDS}, in which the higher level\nis responsible for exploring an initial global sequence, whereas the lower\nlevel is aiming at exploitation for partial sequence refinements, and the two\nlevels are connected by a sliding-window sampling mechanism. In the\nimplementation, a Double Deep Q Network (DDQN) is used in the upper level and\nGraph Pointer Network (GPN) lies within the lower level. After the theoretical\nguarantee for the convergence of BDS, we evaluate it in an industrial automatic\nwarehouse scenario, with job number up to $5000$ in each production line. It is\nshown that our proposed BDS significantly outperforms two most used heuristics,\nthree strong deep networks, and another bilevel baseline approach. In\nparticular, compared with the most used greedy-based heuristic algorithm in\nreal world which takes nearly an hour, our BDS can decrease the makespan by\n27.5\\%, 28.6\\% and 22.1\\% for 3 largest datasets respectively, with\ncomputational time less than 200 seconds.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:46:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Li", "Longkang", ""], ["Zhen", "Hui-Ling", ""], ["Yuan", "Mingxuan", ""], ["Lu", "Jiawen", ""], ["XialiangTong", "", ""], ["Zeng", "Jia", ""], ["Wang", "Jun", ""], ["Schnieders", "Dirk", ""]]}, {"id": "2008.04133", "submitter": "Jarrett Holtz", "authors": "Jarrett Holtz, Arjun Guha, Joydeep Biswas", "title": "Robot Action Selection Learning via Layered Dimension Informed Program\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action selection policies (ASPs), used to compose low-level robot skills into\ncomplex high-level tasks are commonly represented as neural networks (NNs) in\nthe state of the art. Such a paradigm, while very effective, suffers from a few\nkey problems: 1) NNs are opaque to the user and hence not amenable to\nverification, 2) they require significant amounts of training data, and 3) they\nare hard to repair when the domain changes. We present two key insights about\nASPs for robotics. First, ASPs need to reason about physically meaningful\nquantities derived from the state of the world, and second, there exists a\nlayered structure for composing these policies. Leveraging these insights, we\nintroduce layered dimension-informed program synthesis (LDIPS) - by reasoning\nabout the physical dimensions of state variables, and dimensional constraints\non operators, LDIPS directly synthesizes ASPs in a human-interpretable\ndomain-specific language that is amenable to program repair. We present\nempirical results to demonstrate that LDIPS 1) can synthesize effective ASPs\nfor robot soccer and autonomous driving domains, 2) requires two orders of\nmagnitude fewer training examples than a comparable NN representation, and 3)\ncan repair the synthesized ASPs with only a small number of corrections when\ntransferring from simulation to real robots.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 13:52:01 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 20:17:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Holtz", "Jarrett", ""], ["Guha", "Arjun", ""], ["Biswas", "Joydeep", ""]]}, {"id": "2008.04162", "submitter": "Philip Feldman", "authors": "Philip Feldman and Antonio Bucchiarone", "title": "Navigating Human Language Models with Synthetic Agents", "comments": "8 pages, 6 figures, 2 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern natural language models such as the GPT-2/GPT-3 contain tremendous\namounts of information about human belief in a consistently testable form. If\nthese models could be shown to accurately reflect the underlying beliefs of the\nhuman beings that produced the data used to train these models, then such\nmodels become a powerful sociological tool in ways that are distinct from\ntraditional methods, such as interviews and surveys. In this study, We train a\nversion of the GPT-2 on a corpora of historical chess games, and then \"launch\"\nclusters of synthetic agents into the model, using text strings to create\ncontext and orientation. We compare the trajectories contained in the text\ngenerated by the agents/model and compare that to the known ground truth of the\nchess board, move legality, and historical patterns of play. We find that the\npercentages of moves by piece using the model are substantially similar from\nhuman patterns. We further find that the model creates an accurate latent\nrepresentation of the chessboard, and that it is possible to plot trajectories\nof legal moves across the board using this knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:39:53 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:09:36 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 13:42:00 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 11:12:43 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 19:18:21 GMT"}, {"version": "v6", "created": "Mon, 28 Sep 2020 15:40:41 GMT"}, {"version": "v7", "created": "Tue, 29 Sep 2020 09:57:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Feldman", "Philip", ""], ["Bucchiarone", "Antonio", ""]]}, {"id": "2008.04165", "submitter": "Alasdair Hill", "authors": "Alasdair Hill, Ekaterina Komendantskaya, Ronald P. A. Petrick", "title": "Proof-Carrying Plans: a Resource Logic for AI Planning", "comments": "PPDP 2020, 13 pages, 9 figures", "journal-ref": null, "doi": "10.1145/3414080.3414094", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in AI verification and Explainable AI have raised the question\nof whether AI planning techniques can be verified. In this paper, we present a\nnovel resource logic, the Proof Carrying Plans (PCP) logic that can be used to\nverify plans produced by AI planners. The PCP logic takes inspiration from\nexisting resource logics (such as Linear logic and Separation logic) as well as\nHoare logic when it comes to modelling states and resource-aware plan\nexecution. It also capitalises on the Curry-Howard approach to logics, in its\ntreatment of plans as functions and plan pre- and post-conditions as types.\nThis paper presents two main results. From the theoretical perspective, we show\nthat the PCP logic is sound relative to the standard possible world semantics\nused in AI planning. From the practical perspective, we present a complete Agda\nformalisation of the PCP logic and of its soundness proof. Moreover, we\nshowcase the Curry-Howard, or functional, value of this implementation by\nsupplementing it with the library that parses AI plans into Agda's proofs\nautomatically. We provide evaluation of this library and the resulting Agda\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:45:52 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 03:49:19 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Hill", "Alasdair", ""], ["Komendantskaya", "Ekaterina", ""], ["Petrick", "Ronald P. A.", ""]]}, {"id": "2008.04208", "submitter": "Seyed Mohammad Mahdi Heidarpoor Yazdi", "authors": "Seyed Mohammad Mahdi Heidarpoor Yazdi, Abdolhossein Abbassian", "title": "Working Memory for Online Memory Binding Tasks: A Hybrid Model", "comments": "23 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Working Memory is the brain module that holds and manipulates information\nonline. In this work, we design a hybrid model in which a simple feed-forward\nnetwork is coupled to a balanced random network via a read-write vector called\nthe interface vector. Three cases and their results are discussed similar to\nthe n-back task called, first-order memory binding task, generalized\nfirst-order memory task, and second-order memory binding task. The important\nresult is that our dual-component model of working memory shows good\nperformance with learning restricted to the feed-forward component only. Here\nwe take advantage of the random network property without learning. Finally, a\nmore complex memory binding task called, a cue-based memory binding task, is\nintroduced in which a cue is given as input representing a binding relation\nthat prompts the network to choose the useful chunk of memory. To our\nknowledge, this is the first time that random networks as a flexible memory is\nshown to play an important role in online binding tasks. We may interpret our\nresults as a candidate model of working memory in which the feed-forward\nnetwork learns to interact with the temporary storage random network as an\nattentional-controlling executive system.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 14:06:07 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 08:33:38 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yazdi", "Seyed Mohammad Mahdi Heidarpoor", ""], ["Abbassian", "Abdolhossein", ""]]}, {"id": "2008.04212", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen", "title": "Creative AI Through Evolutionary Computation: Principles and Examples", "comments": "This is an extended version of arXiv:1901.03775", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main power of artificial intelligence is not in modeling what we already\nknow, but in creating solutions that are new. Such solutions exist in extremely\nlarge, high-dimensional, and complex search spaces. Population-based search\ntechniques, i.e. variants of evolutionary computation, are well suited to\nfinding them. These techniques make it possible to find creative solutions to\npractical problems in the real world, making creative AI through evolutionary\ncomputation the likely \"next deep learning.\"\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:53:39 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 02:16:35 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 02:10:27 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Miikkulainen", "Risto", ""]]}, {"id": "2008.04213", "submitter": "Yuan Sun", "authors": "Yuan Sun, Sheng Wang, Yunzhuang Shen, Xiaodong Li, Andreas T. Ernst,\n  and Michael Kirley", "title": "Boosting Ant Colony Optimization via Solution Prediction and Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an enhanced meta-heuristic (ML-ACO) that combines\nmachine learning (ML) and ant colony optimization (ACO) to solve combinatorial\noptimization problems. To illustrate the underlying mechanism of our enhanced\nalgorithm, we start by describing a test problem -- the orienteering problem --\nused to demonstrate the efficacy of ML-ACO. In this problem, the objective is\nto find a route that visits a subset of vertices in a graph within a time\nbudget to maximize the collected score. In the first phase of our ML-ACO\nalgorithm, an ML model is trained using a set of small problem instances where\nthe optimal solution is known. Specifically, classification models are used to\nclassify an edge as being part of the optimal route, or not, using\nproblem-specific features and statistical measures. We have tested several\nclassification models including graph neural networks, logistic regression and\nsupport vector machines. The trained model is then used to predict the\nprobability that an edge in the graph of a test problem instance belongs to the\ncorresponding optimal route. In the second phase, we incorporate the predicted\nprobabilities into the ACO component of our algorithm. Here, the probability\nvalues bias sampling towards favoring those predicted high-quality edges when\nconstructing feasible routes. We empirically show that ML-ACO generates results\nthat are significantly better than the standard ACO algorithm, especially when\nthe computational budget is limited. Furthermore, we show our algorithm is\nrobust in the sense that (a) its overall performance is not sensitive to any\nparticular classification model, and (b) it generalizes well to large and\nreal-world problem instances. Our approach integrating ML with a meta-heuristic\nis generic and can be applied to a wide range of combinatorial optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:03:37 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sun", "Yuan", ""], ["Wang", "Sheng", ""], ["Shen", "Yunzhuang", ""], ["Li", "Xiaodong", ""], ["Ernst", "Andreas T.", ""], ["Kirley", "Michael", ""]]}, {"id": "2008.04223", "submitter": "Guohua Wu", "authors": "Aijuan Song, Guohua Wu, Witold Pedrycz", "title": "Integrating Variable Reduction Strategy with Evolutionary Algorithm for\n  Solving Nonlinear Equations Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear equations systems (NESs) are widely used in real-world problems\nwhile they are also difficult to solve due to their characteristics of\nnonlinearity and multiple roots. Evolutionary algorithm (EA) is one of the\nmethods for solving NESs, given their global search capability and an ability\nto locate multiple roots of a NES simultaneously within one run. Currently, the\nmajority of research on using EAs to solve NESs focuses on transformation\ntechniques and improving the performance of the used EAs. By contrast, the\nproblem domain knowledge of NESs is particularly investigated in this study,\nusing which we propose to incorporate the variable reduction strategy (VRS)\ninto EAs to solve NESs. VRS makes full use of the systems of expressing a NES\nand uses some variables (i.e., core variable) to represent other variables\n(i.e., reduced variables) through the variable relationships existing in the\nequation systems. It enables to reduce partial variables and equations and\nshrink the decision space, thereby reducing the complexity of the problem and\nimproving the search efficiency of the EAs. To test the effectiveness of VRS in\ndealing with NESs, this paper integrates VRS into two existing state-of-the-art\nEA methods (i.e., MONES and DRJADE), respectively. Experimental results show\nthat, with the assistance of VRS, the EA methods can significantly produce\nbetter results than the original methods and other compared methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:58:31 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Song", "Aijuan", ""], ["Wu", "Guohua", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2008.04256", "submitter": "L\\^e Nguy\\^en Hoang", "authors": "L\\^e Nguy\\^en Hoang", "title": "Purely Bayesian counterfactuals versus Newcomb's paradox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a careful separation between an entity's epistemic system\nand their decision system. Crucially, Bayesian counterfactuals are estimated by\nthe epistemic system; not by the decision system. Based on this remark, I prove\nthe existence of Newcomb-like problems for which an epistemic system\nnecessarily expects the entity to make a counterfactually bad decision. I then\naddress (a slight generalization of) Newcomb's paradox. I solve the specific\ncase where the player believes that the predictor applies Bayes rule with a\nsupset of all the data available to the player. I prove that the counterfactual\noptimality of the 1-Box strategy depends on the player's prior on the\npredictor's additional data. If these additional data are not expected to\nreduce sufficiently the predictor's uncertainty on the player's decision, then\nthe player's epistemic system will counterfactually prefer to 2-Box. But if the\npredictor's data is believed to make them quasi-omniscient, then 1-Box will be\ncounterfactually preferred. Implications of the analysis are then discussed.\nMore generally, I argue that, to better understand or design an entity, it is\nuseful to clearly separate the entity's epistemic, decision, but also data\ncollection, reward and maintenance systems, whether the entity is human,\nalgorithmic or institutional.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 16:56:48 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Hoang", "L\u00ea Nguy\u00ean", ""]]}, {"id": "2008.04355", "submitter": "Maryam Abdirad", "authors": "Maryam Abdirad, Krishna Krishnan, Deepak Gupta", "title": "A Two-Stage Metaheuristic Algorithm for the Dynamic Vehicle Routing\n  Problem in Industry 4.0 approach", "comments": "22 pages, 4 figures, 1 table. Journal of Management Analytics (2020)", "journal-ref": null, "doi": "10.1080/23270012.2020.1811166", "report-no": null, "categories": "math.OC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industry 4.0 is a concept that assists companies in developing a modern\nsupply chain (MSC) system when they are faced with a dynamic process. Because\nIndustry 4.0 focuses on mobility and real-time integration, it is a good\nframework for a dynamic vehicle routing problem (DVRP). This research works on\nDVRP. The aim of this research is to minimize transportation cost without\nexceeding the capacity constraint of each vehicle while serving customer\ndemands from a common depot. Meanwhile, new orders arrive at a specific time\ninto the system while the vehicles are executing the delivery of existing\norders. This paper presents a two-stage hybrid algorithm for solving the DVRP.\nIn the first stage, construction algorithms are applied to develop the initial\nroute. In the second stage, improvement algorithms are applied. Experimental\nresults were designed for different sizes of problems. Analysis results show\nthe effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 18:39:03 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 14:26:55 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 10:14:56 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Abdirad", "Maryam", ""], ["Krishnan", "Krishna", ""], ["Gupta", "Deepak", ""]]}, {"id": "2008.04388", "submitter": "Grgur Kova\\v{c}", "authors": "Grgur Kova\\v{c}, Adrien Laversanne-Finot, Pierre-Yves Oudeyer", "title": "GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing agents, capable of learning autonomously a wide range of skills is\ncritical in order to increase the scope of reinforcement learning. It will both\nincrease the diversity of learned skills and reduce the burden of manually\ndesigning reward functions for each skill. Self-supervised agents, setting\ntheir own goals, and trying to maximize the diversity of those goals have shown\ngreat promise towards this end. However, a currently known limitation of agents\ntrying to maximize the diversity of sampled goals is that they tend to get\nattracted to noise or more generally to parts of the environments that cannot\nbe controlled (distractors). When agents have access to predefined goal\nfeatures or expert knowledge, absolute Learning Progress (ALP) provides a way\nto distinguish between regions that can be controlled and those that cannot.\nHowever, those methods often fall short when the agents are only provided with\nraw sensory inputs such as images. In this work we extend those concepts to\nunsupervised image-based goal exploration. We propose a framework that allows\nagents to autonomously identify and ignore noisy distracting regions while\nsearching for novelty in the learnable regions to both improve overall\nperformance and avoid catastrophic forgetting. Our framework can be combined\nwith any state-of-the-art novelty seeking goal exploration approaches. We\nconstruct a rich 3D image based environment with distractors. Experiments on\nthis environment show that agents using our framework successfully identify\ninteresting regions of the environment, resulting in drastically improved\nperformances. The source code is available at\nhttps://sites.google.com/view/grimgep.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:50:06 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 11:54:09 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Laversanne-Finot", "Adrien", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2008.04403", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Hamed Khorasgani, Gautam Biswas", "title": "Comparison of Model Predictive and Reinforcement Learning Methods for\n  Fault Tolerant Control", "comments": "Published in IFAC SAFEPROCESS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A desirable property in fault-tolerant controllers is adaptability to system\nchanges as they evolve during systems operations. An adaptive controller does\nnot require optimal control policies to be enumerated for possible faults.\nInstead it can approximate one in real-time. We present two adaptive\nfault-tolerant control schemes for a discrete time system based on hierarchical\nreinforcement learning. We compare their performance against a model predictive\ncontroller in presence of sensor noise and persistent faults. The controllers\nare tested on a fuel tank model of a C-130 plane. Our experiments demonstrate\nthat reinforcement learning-based controllers perform more robustly than model\npredictive controllers under faults, partially observable system models, and\nvarying sensor noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:22:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Khorasgani", "Hamed", ""], ["Biswas", "Gautam", ""]]}, {"id": "2008.04407", "submitter": "Ibrahim Ahmed", "authors": "Ibrahim Ahmed, Marcos Qui\\~nones-Grueiro, Gautam Biswas", "title": "Fault-Tolerant Control of Degrading Systems with On-Policy Reinforcement\n  Learning", "comments": "Published in IFAC World Congress 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adaptive reinforcement learning control approach for fault\ntolerant control of degrading systems that is not preceded by a fault detection\nand diagnosis step. Therefore, \\textit{a priori} knowledge of faults that may\noccur in the system is not required. The adaptive scheme combines online and\noffline learning of the on-policy control method to improve exploration and\nsample efficiency, while guaranteeing stable learning. The offline learning\nphase is performed using a data-driven model of the system, which is frequently\nupdated to track the system's operating conditions. We conduct experiments on\nan aircraft fuel transfer system to demonstrate the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 20:42:59 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ahmed", "Ibrahim", ""], ["Qui\u00f1ones-Grueiro", "Marcos", ""], ["Biswas", "Gautam", ""]]}, {"id": "2008.04448", "submitter": "Athar Kharal", "authors": "Athar Kharal", "title": "Explainable Artificial Intelligence Based Fault Diagnosis and Insight\n  Harvesting for Steel Plates Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Industry 4.0, Data Science and Explainable Artificial\nIntelligence (XAI) has received considerable intrest in recent literature.\nHowever, the entry threshold into XAI, in terms of computer coding and the\nrequisite mathematical apparatus, is really high. For fault diagnosis of steel\nplates, this work reports on a methodology of incorporating XAI based insights\ninto the Data Science process of development of high precision classifier.\nUsing Synthetic Minority Oversampling Technique (SMOTE) and notion of medoids,\ninsights from XAI tools viz. Ceteris Peribus profiles, Partial Dependence and\nBreakdown profiles have been harvested. Additionally, insights in the form of\nIF-THEN rules have also been extracted from an optimized Random Forest and\nAssociation Rule Mining. Incorporating all the insights into a single ensemble\nclassifier, a 10 fold cross validated performance of 94% has been achieved. In\nsum total, this work makes three main contributions viz.: methodology based\nupon utilization of medoids and SMOTE, of gleaning insights and incorporating\ninto model development process. Secondly the insights themselves are\ncontribution, as they benefit the human experts of steel manufacturing\nindustry, and thirdly a high precision fault diagnosis classifier has been\ndeveloped.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:04:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kharal", "Athar", ""]]}, {"id": "2008.04449", "submitter": "Rosario Cammarota", "authors": "Rosario Cammarota, Matthias Schunter, Anand Rajan, Fabian Boemer,\n  \\'Agnes Kiss, Amos Treiber, Christian Weinert, Thomas Schneider, Emmanuel\n  Stapf, Ahmad-Reza Sadeghi, Daniel Demmler, Huili Chen, Siam Umar Hussain,\n  Sadegh Riazi, Farinaz Koushanfar, Saransh Gupta, Tajan Simunic Rosing,\n  Kamalika Chaudhuri, Hamid Nejatollahi, Nikil Dutt, Mohsen Imani, Kim Laine,\n  Anuj Dubey, Aydin Aysu, Fateme Sadat Hosseini, Chengmo Yang, Eric Wallace,\n  Pamela Norton", "title": "Trustworthy AI Inference Systems: An Industry Research View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.AR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide an industry research view for approaching the\ndesign, deployment, and operation of trustworthy Artificial Intelligence (AI)\ninference systems. Such systems provide customers with timely, informed, and\ncustomized inferences to aid their decision, while at the same time utilizing\nappropriate security protection mechanisms for AI models. Additionally, such\nsystems should also use Privacy-Enhancing Technologies (PETs) to protect\ncustomers' data at any time.\n  To approach the subject, we start by introducing trends in AI inference\nsystems. We continue by elaborating on the relationship between Intellectual\nProperty (IP) and private data protection in such systems. Regarding the\nprotection mechanisms, we survey the security and privacy building blocks\ninstrumental in designing, building, deploying, and operating private AI\ninference systems. For example, we highlight opportunities and challenges in AI\nsystems using trusted execution environments combined with more recent advances\nin cryptographic techniques to protect data in use. Finally, we outline areas\nof further development that require the global collective attention of\nindustry, academia, and government researchers to sustain the operation of\ntrustworthy AI inference systems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:05:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cammarota", "Rosario", ""], ["Schunter", "Matthias", ""], ["Rajan", "Anand", ""], ["Boemer", "Fabian", ""], ["Kiss", "\u00c1gnes", ""], ["Treiber", "Amos", ""], ["Weinert", "Christian", ""], ["Schneider", "Thomas", ""], ["Stapf", "Emmanuel", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Demmler", "Daniel", ""], ["Chen", "Huili", ""], ["Hussain", "Siam Umar", ""], ["Riazi", "Sadegh", ""], ["Koushanfar", "Farinaz", ""], ["Gupta", "Saransh", ""], ["Rosing", "Tajan Simunic", ""], ["Chaudhuri", "Kamalika", ""], ["Nejatollahi", "Hamid", ""], ["Dutt", "Nikil", ""], ["Imani", "Mohsen", ""], ["Laine", "Kim", ""], ["Dubey", "Anuj", ""], ["Aysu", "Aydin", ""], ["Hosseini", "Fateme Sadat", ""], ["Yang", "Chengmo", ""], ["Wallace", "Eric", ""], ["Norton", "Pamela", ""]]}, {"id": "2008.04452", "submitter": "Erdem B{\\i}y{\\i}k", "authors": "Zheqing Zhu, Erdem B{\\i}y{\\i}k, Dorsa Sadigh", "title": "Multi-Agent Safe Planning with Gaussian Processes", "comments": "9 pages, 5 figures. Published at IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2020", "journal-ref": null, "doi": "10.1109/IROS45743.2020.9341169", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent safe systems have become an increasingly important area of study\nas we can now easily have multiple AI-powered systems operating together. In\nsuch settings, we need to ensure the safety of not only each individual agent,\nbut also the overall system. In this paper, we introduce a novel multi-agent\nsafe learning algorithm that enables decentralized safe navigation when there\nare multiple different agents in the environment. This algorithm makes mild\nassumptions about other agents and is trained in a decentralized fashion, i.e.\nwith very little prior knowledge about other agents' policies. Experiments show\nour algorithm performs well with the robots running other algorithms when\noptimizing various objectives.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 23:09:05 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhu", "Zheqing", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2008.04465", "submitter": "Rui Wang", "authors": "Rui Wang, Chaitanya Mitash, Shiyang Lu, Daniel Boehm, Kostas E. Bekris", "title": "Safe and Effective Picking Paths in Clutter given Discrete Distributions\n  of Object Poses", "comments": "8 pages. Accepted to International Conference on Intelligent Robots\n  and Systems (IROS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Picking an item in the presence of other objects can be challenging as it\ninvolves occlusions and partial views. Given object models, one approach is to\nperform object pose estimation and use the most likely candidate pose per\nobject to pick the target without collisions. This approach, however, ignores\nthe uncertainty of the perception process both regarding the target's and the\nsurrounding objects' poses. This work proposes first a perception process for\n6D pose estimation, which returns a discrete distribution of object poses in a\nscene. Then, an open-loop planning pipeline is proposed to return safe and\neffective solutions for moving a robotic arm to pick, which (a) minimizes the\nprobability of collision with the obstructing objects; and (b) maximizes the\nprobability of reaching the target item. The planning framework models the\nchallenge as a stochastic variant of the Minimum Constraint Removal (MCR)\nproblem. The effectiveness of the methodology is verified given both simulated\nand real data in different scenarios. The experiments demonstrate the\nimportance of considering the uncertainty of the perception process in terms of\nsafe execution. The results also show that the methodology is more effective\nthan conservative MCR approaches, which avoid all possible object poses\nregardless of the reported uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 00:52:03 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Wang", "Rui", ""], ["Mitash", "Chaitanya", ""], ["Lu", "Shiyang", ""], ["Boehm", "Daniel", ""], ["Bekris", "Kostas E.", ""]]}, {"id": "2008.04530", "submitter": "Abhishek Gupta", "authors": "Allison Cohen (1 and 2) and Abhishek Gupta (1 and 3) ((1) Montreal AI\n  Ethics Institute, (2) AI Global, and (3) Microsoft)", "title": "Report prepared by the Montreal AI Ethics Institute In Response to\n  Mila's Proposal for a Contact Tracing App", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contact tracing has grown in popularity as a promising solution to the\nCOVID-19 pandemic. The benefits of automated contact tracing are two-fold.\nContact tracing promises to reduce the number of infections by being able to:\n1) systematically identify all of those that have been in contact with someone\nwho has had COVID; and, 2) ensure those that have been exposed to the virus do\nnot unknowingly infect others. \"COVI\" is the name of a recent contact tracing\napp developed by Mila and was proposed to help combat COVID-19 in Canada. The\napp was designed to inform each individual of their relative risk of being\ninfected with the virus, which Mila claimed would empower citizens to make\ninformed decisions about their movement and allow for a data-driven approach to\npublic health policy; all the while ensuring data is safeguarded from\ngovernments, companies, and individuals. This article will provide a critical\nresponse to Mila's COVI White Paper. Specifically, this article will discuss:\nthe extent to which diversity has been considered in the design of the app,\nassumptions surrounding users' interaction with the app and the app's utility,\nas well as unanswered questions surrounding transparency, accountability, and\nsecurity. We see this as an opportunity to supplement the excellent risk\nanalysis done by the COVI team to surface insights that can be applied to other\ncontact- and proximity-tracing apps that are being developed and deployed\nacross the world. Our hope is that, through a meaningful dialogue, we can\nultimately help organizations develop better solutions that respect the\nfundamental rights and values of the communities these solutions are meant to\nserve.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:05:13 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Cohen", "Allison", "", "1 and 2"], ["Gupta", "Abhishek", "", "1 and 3"]]}, {"id": "2008.04548", "submitter": "Haonan Lu", "authors": "Haonan Lu, Hailin Hu", "title": "DensE: An Enhanced Non-Abelian Group Representation for Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the composition patterns of relations is a vital task in knowledge\ngraph completion. It also serves as a fundamental step towards multi-hop\nreasoning over learned knowledge. Previously, rotation-based translational\nmethods, e.g., RotatE, have been developed to model composite relations using\nthe product of a series of complex-valued diagonal matrices. However, RotatE\nmakes several oversimplified assumptions on the composition patterns, forcing\nthe relations to be commutative, independent from entities and fixed in scale.\nTo tackle this problem, we have developed a novel knowledge graph embedding\nmethod, named DensE, to provide sufficient modeling capacity for complex\ncomposition patterns. In particular, our method decomposes each relation into\nan SO(3) group-based rotation operator and a scaling operator in the three\ndimensional (3-D) Euclidean space. The advantages of our method are twofold:\n(1) For composite relations, the corresponding diagonal relation matrices can\nbe non-commutative and related with entity embeddings; (2) It extends the\nconcept of RotatE to a more expressive setting with lower model complexity and\npreserves the direct geometrical interpretations, which reveals how relations\nwith distinct patterns (i.e., symmetry/anti-symmetry, inversion and\ncomposition) are modeled. Experimental results on multiple benchmark knowledge\ngraphs show that DensE outperforms the current state-of-the-art models for\nmissing link prediction, especially on composite relations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:45:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Lu", "Haonan", ""], ["Hu", "Hailin", ""]]}, {"id": "2008.04589", "submitter": "Daniel Tanneberg", "authors": "Leon Keller, Daniel Tanneberg, Svenja Stark, Jan Peters", "title": "Model-Based Quality-Diversity Search for Efficient Robot Learning", "comments": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in robot learning, it still remains a challenge to\nprogram a robot to deal with open-ended object manipulation tasks. One approach\nthat was recently used to autonomously generate a repertoire of diverse skills\nis a novelty based Quality-Diversity~(QD) algorithm. However, as most\nevolutionary algorithms, QD suffers from sample-inefficiency and, thus, it is\nchallenging to apply it in real-world scenarios. This paper tackles this\nproblem by integrating a neural network that predicts the behavior of the\nperturbed parameters into a novelty based QD algorithm. In the proposed\nModel-based Quality-Diversity search (M-QD), the network is trained\nconcurrently to the repertoire and is used to avoid executing unpromising\nactions in the novelty search process. Furthermore, it is used to adapt the\nskills of the final repertoire in order to generalize the skills to different\nscenarios. Our experiments show that enhancing a QD algorithm with such a\nforward model improves the sample-efficiency and performance of the\nevolutionary process and the skill adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:02:18 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Keller", "Leon", ""], ["Tanneberg", "Daniel", ""], ["Stark", "Svenja", ""], ["Peters", "Jan", ""]]}, {"id": "2008.04600", "submitter": "Nir Lipovetzky", "authors": "Gang Chen, Yi Ding, Hugo Edwards, Chong Hin Chau, Sai Hou, Grace\n  Johnson, Mohammed Sharukh Syed, Haoyuan Tang, Yue Wu, Ye Yan, Gil Tidhar and\n  Nir Lipovetzky", "title": "Planimation", "comments": "Best ICAPS 19 - Systen Demo Award - technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planimation is a modular and extensible open source framework to visualise\nsequential solutions of planning problems specified in PDDL. We introduce a\npreliminary declarative PDDL-like animation profile specification, expressive\nenough to synthesise animations of arbitrary initial states and goals of a\nbenchmark with just a single profile.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 09:32:24 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Chen", "Gang", ""], ["Ding", "Yi", ""], ["Edwards", "Hugo", ""], ["Chau", "Chong Hin", ""], ["Hou", "Sai", ""], ["Johnson", "Grace", ""], ["Syed", "Mohammed Sharukh", ""], ["Tang", "Haoyuan", ""], ["Wu", "Yue", ""], ["Yan", "Ye", ""], ["Tidhar", "Gil", ""], ["Lipovetzky", "Nir", ""]]}, {"id": "2008.04774", "submitter": "Alessandro Gianola", "authors": "Paolo Felli and Alessandro Gianola and Marco Montali", "title": "SMT-based Safety Verification of Parameterised Multi-Agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the verification of parameterised multi-agent systems\n(MASs), and in particular the task of verifying whether unwanted states,\ncharacterised as a given state formula, are reachable in a given MAS, i.e.,\nwhether the MAS is unsafe. The MAS is parameterised and the model only\ndescribes the finite set of possible agent templates, while the actual number\nof concrete agent instances for each template is unbounded and cannot be\nforeseen. This makes the state-space infinite. As safety may of course depend\non the number of agent instances in the system, the verification result must be\ncorrect irrespective of such number. We solve this problem via infinite-state\nmodel checking based on satisfiability modulo theories (SMT), relying on the\ntheory of array-based systems: we present parameterised MASs as particular\narray-based systems, under two execution semantics for the MAS, which we call\nconcurrent and interleaved. We prove our decidability results under these\nassumptions and illustrate our implementation approach, called SAFE: the Swarm\nSafety Detector, based on the third-party model checker MCMT, which we evaluate\nexperimentally. Finally, we discuss how this approach lends itself to richer\nparameterised and data-aware MAS settings beyond the state-of-the-art solutions\nin the literature, which we leave as future work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:24:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 17:06:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Felli", "Paolo", ""], ["Gianola", "Alessandro", ""], ["Montali", "Marco", ""]]}, {"id": "2008.04793", "submitter": "Andrzej Cichocki", "authors": "Andrzej Cichocki and Alexander P. Kuleshov", "title": "Future Trends for Human-AI Collaboration: A Comprehensive Taxonomy of\n  AI/AGI Using Multiple Intelligences and Learning Styles", "comments": "19 Figures, 27 pages", "journal-ref": "Computational Intelligence and Neuroscience (2020)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses some trends and concepts in developing new generation\nof future Artificial General Intelligence (AGI) systems which relate to complex\nfacets and different types of human intelligence, especially social, emotional,\nattentional and ethical intelligence. We describe various aspects of multiple\nhuman intelligences and learning styles, which may impact on a variety of AI\nproblem domains. Using the concept of 'multiple intelligences' rather than a\nsingle type of intelligence, we categorize and provide working definitions of\nvarious AGI depending on their cognitive skills or capacities. Future AI\nsystems will be able not only to communicate with human users and each other,\nbut also to efficiently exchange knowledge and wisdom with abilities of\ncooperation, collaboration and even co-creating something new and valuable and\nhave meta-learning capacities. Multi-agent systems such as these can be used to\nsolve problems that would be difficult to solve by any individual intelligent\nagent.\n  Key words: Artificial General Intelligence (AGI), multiple intelligences,\nlearning styles, physical intelligence, emotional intelligence, social\nintelligence, attentional intelligence, moral-ethical intelligence, responsible\ndecision making, creative-innovative intelligence, cognitive functions,\nmeta-learning of AI systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 21:00:13 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 22:46:43 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 23:08:57 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 10:38:05 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cichocki", "Andrzej", ""], ["Kuleshov", "Alexander P.", ""]]}, {"id": "2008.04875", "submitter": "Andrew W. E. McDonald", "authors": "Andrew W.E. McDonald, Sean Grimes, David E. Breen", "title": "Ortus: an Emotion-Driven Approach to (artificial) Biological\n  Intelligence", "comments": "\\c{opyright} 2017 Massachusetts Institute of Technology Published\n  under a Creative Commons Attribution 4.0 International", "journal-ref": "European Conference on Artificial Life 2017", "doi": "10.7551/ecal_a_086", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ortus is a simple virtual organism that also serves as an initial framework\nfor investigating and developing biologically-based artificial intelligence.\nBorn from a goal to create complex virtual intelligence and an initial attempt\nto model C. elegans, Ortus implements a number of mechanisms observed in\norganic nervous systems, and attempts to fill in unknowns based upon plausible\nbiological implementations and psychological observations. Implemented\nmechanisms include excitatory and inhibitory chemical synapses, bidirectional\ngap junctions, and Hebbian learning with its Stentian extension. We present an\ninitial experiment that showcases Ortus' fundamental principles; specifically,\na cyclic respiratory circuit, and emotionally-driven associative learning with\nrespect to an input stimulus. Finally, we discuss the implications and future\ndirections for Ortus and similar systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:29:10 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 22:39:06 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["McDonald", "Andrew W. E.", ""], ["Grimes", "Sean", ""], ["Breen", "David E.", ""]]}, {"id": "2008.04891", "submitter": "Hannes Thaller", "authors": "Hannes Thaller, Lukas Linsbauer, Brent van Bladel, Alexander Egyed", "title": "Semantic Clone Detection via Probabilistic Software Modeling", "comments": "12 pages, 2 pages of references, 5 listings, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic clone detection is the process of finding program elements with\nsimilar or equal runtime behavior. For example, detecting the semantic equality\nbetween the recursive and iterative implementation of the factorial\ncomputation. Semantic clone detection is the de facto technical boundary of\nclone detectors. This boundary was tested over the last years with interesting\nnew approaches. This work contributes a semantic clone detection approach that\ndetects clones with 0% syntactic similarity. We present Semantic Clone\nDetection via Probabilistic Software Modeling (SCD-PSM) as a stable and precise\nsolution to semantic clone detection. PSM builds a probabilistic model of a\nprogram that is capable of evaluating and generating runtime data. SCD-PSM\nleverages this model and its model elements to finding behaviorally equal model\nelements. This behavioral equality is then generalized to semantic equality of\nthe original program elements. It uses the likelihood between model elements as\na distance metric. Then, it employs the likelihood ratio significance test to\ndecide whether this distance is significant, given a pre-specified and\ncontrollable false-positive rate. The output of SCD-PSM are pairs of program\nelements (i.e., methods), their distance, and a decision whether they are\nclones or not. SCD-PSM yields excellent results with a Matthews Correlation\nCoefficient greater 0.9. These results are obtained on classical semantic clone\ndetection problems such as detecting recursive and iterative versions of an\nalgorithm, but also on complex problems used in coding competitions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:54:20 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Thaller", "Hannes", ""], ["Linsbauer", "Lukas", ""], ["van Bladel", "Brent", ""], ["Egyed", "Alexander", ""]]}, {"id": "2008.04907", "submitter": "Sanskriti Singh", "authors": "Sanskriti Singh", "title": "PneumoXttention: A CNN compensating for Human Fallibility when Detecting\n  Pneumonia through CXR images with Attention", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic Chest Radiograph X-ray (CXR) interpretation by machines is an\nimportant research topic of Artificial Intelligence. As part of my journey\nthrough the California Science Fair, I have developed an algorithm that can\ndetect pneumonia from a CXR image to compensate for human fallibility. My\nalgorithm, PneumoXttention, is an ensemble of two 13 layer convolutional neural\nnetwork trained on the RSNA dataset, a dataset provided by the Radiological\nSociety of North America, containing 26,684 frontal X-ray images split into the\ncategories of pneumonia and no pneumonia. The dataset was annotated by many\nprofessional radiologists in North America. It achieved an impressive F1 score,\n0.82, on the test set (20% random split of RSNA dataset) and completely\ncompensated Human Radiologists on a random set of 25 test images drawn from\nRSNA and NIH. I don't have a direct comparison but Stanford's Chexnet has a F1\nscore of 0.435 on the NIH dataset for category Pneumonia.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 05:11:16 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Singh", "Sanskriti", ""]]}, {"id": "2008.04970", "submitter": "Amirhossein Moosavi", "authors": "Amirhossein Moosavi and Onur Ozturk", "title": "Metaheuristics for the operating theater planning and scheduling: A\n  systematic review", "comments": "30 pages, 8 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are found a vast number of papers studying the problem of operating\ntheater planning and scheduling. Different variants of this problem are\ngenerally recognized to be NP-complete; thus, several solution approaches have\nbeen utilized in the literature to confront with these complicated problems.\nThe lack of a thorough review of the main characteristics of solution\napproaches is tangible in the literature (reviewing them separately and with\nregards to the characteristics of studied problems), which can provide\npragmatic guidelines for practitioners and future research projects. This paper\naims to address this issue. Since different types of solution approaches\nusually have different characteristics, this paper focuses only on\nmetaheuristic algorithms. Through both automatic and manual search methods, we\nhave selected and reviewed 28 papers with respect to their main problem and\nsolution approach features. Finally, some directions are introduced for future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 19:13:31 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Moosavi", "Amirhossein", ""], ["Ozturk", "Onur", ""]]}, {"id": "2008.05064", "submitter": "Praveen Damacharla", "authors": "Praveen Damacharla, Parashar Dhakal, Sebastian Stumbo, Ahmad Y.\n  Javaid, Subhashini Ganapathy, David A. Malek, Douglas C. Hodge, Vijay\n  Devabhaktuni", "title": "Effects of Voice-Based Synthetic Assistant on Performance of Emergency\n  Care Provider in Training", "comments": null, "journal-ref": "Int J Artif Intell Educ, 29, 122-143, 2018", "doi": "10.1007/s40593-018-0166-3", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of a perennial project, our team is actively engaged in developing\nnew synthetic assistant (SA) technologies to assist in training combat medics\nand medical first responders. It is critical that medical first responders are\nwell trained to deal with emergencies more effectively. This would require\nreal-time monitoring and feedback for each trainee. Therefore, we introduced a\nvoice-based SA to augment the training process of medical first responders and\nenhance their performance in the field. The potential benefits of SAs include a\nreduction in training costs and enhanced monitoring mechanisms. Despite the\nincreased usage of voice-based personal assistants (PAs) in day-to-day life,\nthe associated effects are commonly neglected for a study of human factors.\nTherefore, this paper focuses on performance analysis of the developed\nvoice-based SA in emergency care provider training for a selected emergency\ntreatment scenario. The research discussed in this paper follows design science\nin developing proposed technology; at length, we discussed architecture and\ndevelopment and presented working results of voice-based SA. The empirical\ntesting was conducted on two groups as user studies using statistical analysis\ntools, one trained with conventional methods and the other with the help of SA.\nThe statistical results demonstrated the amplification in training efficacy and\nperformance of medical responders powered by SA. Furthermore, the paper also\ndiscusses the accuracy and time of task execution (t) and concludes with the\nguidelines for resolving the identified problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:55:28 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Damacharla", "Praveen", ""], ["Dhakal", "Parashar", ""], ["Stumbo", "Sebastian", ""], ["Javaid", "Ahmad Y.", ""], ["Ganapathy", "Subhashini", ""], ["Malek", "David A.", ""], ["Hodge", "Douglas C.", ""], ["Devabhaktuni", "Vijay", ""]]}, {"id": "2008.05088", "submitter": "Julie Iskander Dr", "authors": "Julie Iskander and Mohammed Hossny", "title": "An ocular biomechanics environment for reinforcement learning", "comments": "5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been applied to human movement through\nphysiologically-based biomechanical models to add insights into the neural\ncontrol of these movements; it is also useful in the design of prosthetics and\nrobotics. In this paper, we extend the use of reinforcement learning into\ncontrolling an ocular biomechanical system to perform saccades, which is one of\nthe fastest eye movement systems. We describe an ocular environment and an\nagent trained using Deep Deterministic Policy Gradients method to perform\nsaccades. The agent was able to match the desired eye position with a mean\ndeviation angle of 3:5+/-1:25 degrees. The proposed framework is a first step\ntowards using the capabilities of deep reinforcement learning to enhance our\nunderstanding of ocular biomechanics.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:39:37 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Iskander", "Julie", ""], ["Hossny", "Mohammed", ""]]}, {"id": "2008.05131", "submitter": "Deren Lei", "authors": "Yilei Zeng, Deren Lei, Beichen Li, Gangrong Jiang, Emilio Ferrara,\n  Michael Zyda", "title": "Learning to Reason in Round-based Games: Multi-task Sequence Generation\n  for Purchasing Decision Making in First-person Shooters", "comments": "16th AAAI Conference on Artificial Intelligence and Interactive\n  Digital Entertainment (AIIDE-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential reasoning is a complex human ability, with extensive previous\nresearch focusing on gaming AI in a single continuous game, round-based\ndecision makings extending to a sequence of games remain less explored.\nCounter-Strike: Global Offensive (CS:GO), as a round-based game with abundant\nexpert demonstrations, provides an excellent environment for multi-player\nround-based sequential reasoning. In this work, we propose a Sequence Reasoner\nwith Round Attribute Encoder and Multi-Task Decoder to interpret the strategies\nbehind the round-based purchasing decisions. We adopt few-shot learning to\nsample multiple rounds in a match, and modified model agnostic meta-learning\nalgorithm Reptile for the meta-learning loop. We formulate each round as a\nmulti-task sequence generation problem. Our state representations combine\naction encoder, team encoder, player features, round attribute encoder, and\neconomy encoders to help our agent learn to reason under this specific\nmulti-player round-based scenario. A complete ablation study and comparison\nwith the greedy approach certify the effectiveness of our model. Our research\nwill open doors for interpretable AI for understanding episodic and long-term\npurchasing strategies beyond the gaming community.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:29:26 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zeng", "Yilei", ""], ["Lei", "Deren", ""], ["Li", "Beichen", ""], ["Jiang", "Gangrong", ""], ["Ferrara", "Emilio", ""], ["Zyda", "Michael", ""]]}, {"id": "2008.05171", "submitter": "Erich Schubert", "authors": "Erich Schubert and Peter J. Rousseeuw", "title": "Fast and Eager k-Medoids Clustering: O(k) Runtime Improvement of the\n  PAM, CLARA, and CLARANS Algorithms", "comments": null, "journal-ref": "Information Systems, 2021", "doi": "10.1016/j.is.2021.101804", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering non-Euclidean data is difficult, and one of the most used\nalgorithms besides hierarchical clustering is the popular algorithm\nPartitioning Around Medoids (PAM), also simply referred to as k-medoids\nclustering. In Euclidean geometry the mean-as used in k-means-is a good\nestimator for the cluster center, but this does not exist for arbitrary\ndissimilarities. PAM uses the medoid instead, the object with the smallest\ndissimilarity to all others in the cluster. This notion of centrality can be\nused with any (dis-)similarity, and thus is of high relevance to many domains\nand applications. A key issue with PAM is its high run time cost. We propose\nmodifications to the PAM algorithm that achieve an O(k)-fold speedup in the\nsecond (\"SWAP\") phase of the algorithm, but will still find the same results as\nthe original PAM algorithm. If we relax the choice of swaps performed (while\nretaining comparable quality), we can further accelerate the algorithm by\neagerly performing additional swaps in each iteration. With the substantially\nfaster SWAP, we can now explore faster initialization strategies, because (i)\nthe classic (\"BUILD\") initialization now becomes the bottleneck, and (ii) our\nswap is fast enough to compensate for worse starting conditions. We also show\nhow the CLARA and CLARANS algorithms benefit from the proposed modifications.\nWhile we do not study the parallelization of our approach in this work, it can\neasily be combined with earlier approaches to use PAM and CLARA on big data\n(some of which use PAM as a subroutine, hence can immediately benefit from\nthese improvements), where the performance with high k becomes increasingly\nimportant. In experiments on real data with k=100,200, we observed a 458x\nrespectively 1191x speedup compared to the original PAM SWAP algorithm, making\nPAM applicable to larger data sets, and in particular to higher k.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:37:50 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 08:16:45 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Schubert", "Erich", ""], ["Rousseeuw", "Peter J.", ""]]}, {"id": "2008.05180", "submitter": "Christian Schulz", "authors": "Alexander Gellner, Sebastian Lamm, Christian Schulz, Darren Strash,\n  Bogd\\'an Zav\\'alnij", "title": "Boosting Data Reduction for the Maximum Weight Independent Set Problem\n  Using Increasing Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a vertex-weighted graph, the maximum weight independent set problem\nasks for a pair-wise non-adjacent set of vertices such that the sum of their\nweights is maximum. The branch-and-reduce paradigm is the de facto standard\napproach to solve the problem to optimality in practice. In this paradigm, data\nreduction rules are applied to decrease the problem size. These data reduction\nrules ensure that given an optimum solution on the new (smaller) input, one can\nquickly construct an optimum solution on the original input.\n  We introduce new generalized data reduction and transformation rules for the\nproblem. A key feature of our work is that some transformation rules can\nincrease the size of the input. Surprisingly, these so-called increasing\ntransformations can simplify the problem and also open up the reduction space\nto yield even smaller irreducible graphs later throughout the algorithm. In\nexperiments, our algorithm computes significantly smaller irreducible graphs on\nall except one instance, solves more instances to optimality than previously\npossible, is up to two orders of magnitude faster than the best\nstate-of-the-art solver, and finds higher-quality solutions than heuristic\nsolvers DynWVC and HILS on many instances. While the increasing transformations\nare only efficient enough for preprocessing at this time, we see this as a\ncritical initial step towards a new branch-and-transform paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:52:50 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 05:45:23 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gellner", "Alexander", ""], ["Lamm", "Sebastian", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""], ["Zav\u00e1lnij", "Bogd\u00e1n", ""]]}, {"id": "2008.05190", "submitter": "Isaiah Onando Mulang' Mr.", "authors": "Isaiah Onando Mulang', Kuldeep Singh, Chaitali Prabhu, Abhishek\n  Nadgeri, Johannes Hoffart, Jens Lehmann", "title": "Evaluating the Impact of Knowledge Graph Context on Entity\n  Disambiguation Models", "comments": "to appear in proceedings of CIKM 2020", "journal-ref": "CIKM 2020", "doi": "10.1145/3340531.3412159", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained Transformer models have emerged as state-of-the-art approaches\nthat learn contextual information from text to improve the performance of\nseveral NLP tasks. These models, albeit powerful, still require specialized\nknowledge in specific scenarios. In this paper, we argue that context derived\nfrom a knowledge graph (in our case: Wikidata) provides enough signals to\ninform pretrained transformer models and improve their performance for named\nentity disambiguation (NED) on Wikidata KG. We further hypothesize that our\nproposed KG context can be standardized for Wikipedia, and we evaluate the\nimpact of KG context on state-of-the-art NED model for the Wikipedia knowledge\nbase. Our empirical results validate that the proposed KG context can be\ngeneralized (for Wikipedia), and providing KG context in transformer\narchitectures considerably outperforms the existing baselines, including the\nvanilla transformer models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:12:22 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 08:44:29 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 08:58:56 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mulang'", "Isaiah Onando", ""], ["Singh", "Kuldeep", ""], ["Prabhu", "Chaitali", ""], ["Nadgeri", "Abhishek", ""], ["Hoffart", "Johannes", ""], ["Lehmann", "Jens", ""]]}, {"id": "2008.05214", "submitter": "Heechang Ryu", "authors": "Heechang Ryu, Hayong Shin, Jinkyoo Park", "title": "REMAX: Relational Representation for Multi-Agent Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a multi-agent reinforcement learning (MARL) model is generally\ndifficult because there are numerous combinations of complex interactions among\nagents that induce certain reward signals. Especially when there is a sparse\nreward signal, the training becomes more difficult. Previous studies have tried\nto resolve this issue by employing an intrinsic reward, which is a signal\nspecifically designed for inducing the interactions among agents, to boost the\nMARL model training. However, this approach requires extensive prior knowledge\nto design an intrinsic reward. To optimize the training of an MARL model, we\npropose a learning-based exploration strategy to generate the initial states of\na game. The proposed method adopts a variational graph autoencoder to represent\na state of a game such that (1) the state can be compactly encoded to the\nlatent representation by considering the relationship among agents, and (2) the\nlatent representation can be used as an effective input to the surrogate model\npredicting the exploration score. The proposed method determines the latent\nrepresentations that maximize the surrogate model and decodes these\nrepresentations to generate the initial states from which the MARL model starts\ntraining. Empirically, we demonstrate that the generated states improve the\ntraining and performance of MARL more than the existing exploration methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:23:35 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ryu", "Heechang", ""], ["Shin", "Hayong", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2008.05221", "submitter": "Manish Gupta", "authors": "Manish Gupta, Puneet Agrawal", "title": "Compression of Deep Learning Models for Text: A Survey", "comments": "Accepted at TKDD for publication. 53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:42:14 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 10:41:02 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 12:25:10 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 17:47:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gupta", "Manish", ""], ["Agrawal", "Puneet", ""]]}, {"id": "2008.05228", "submitter": "Jugoslav Stojcheski", "authors": "Jugoslav Stojcheski, Valkyrie Felso, Falk Lieder", "title": "Optimal to-do list gamification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What should I work on first? What can wait until later? Which projects should\nI prioritize and which tasks are not worth my time? These are challenging\nquestions that many people face every day. People's intuitive strategy is to\nprioritize their immediate experience over the long-term consequences. This\nleads to procrastination and the neglect of important long-term projects in\nfavor of seemingly urgent tasks that are less important. Optimal gamification\nstrives to help people overcome these problems by incentivizing each task by a\nnumber of points that communicates how valuable it is in the long-run.\nUnfortunately, computing the optimal number of points with standard dynamic\nprogramming methods quickly becomes intractable as the number of a person's\nprojects and the number of tasks required by each project increase. Here, we\nintroduce and evaluate a scalable method for identifying which tasks are most\nimportant in the long run and incentivizing each task according to its\nlong-term value. Our method makes it possible to create to-do list gamification\napps that can handle the size and complexity of people's to-do lists in the\nreal world.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:59:13 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Stojcheski", "Jugoslav", ""], ["Felso", "Valkyrie", ""], ["Lieder", "Falk", ""]]}, {"id": "2008.05239", "submitter": "Heiko Paulheim", "authors": "Niklas L\\\"udemann, Ageda Shiba, Nikolaos Thymianis, Nicolas Heist,\n  Christopher Ludwig, and Heiko Paulheim", "title": "A Knowledge Graph for Assessing Aggressive Tax Planning Strategies", "comments": "Accepted to International Semantic Web Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The taxation of multi-national companies is a complex field, since it is\ninfluenced by the legislation of several states. Laws in different states may\nhave unforeseen interaction effects, which can be exploited by allowing\nmultinational companies to minimize taxes, a concept known as tax planning. In\nthis paper, we present a knowledge graph of multinational companies and their\nrelationships, comprising almost 1.5M business entities. We show that commonly\nknown tax planning strategies can be formulated as subgraph queries to that\ngraph, which allows for identifying companies using certain strategies.\nMoreover, we demonstrate that we can identify anomalies in the graph which hint\nat potential tax planning strategies, and we show how to enhance those analyses\nby incorporating information from Wikidata using federated queries.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:19:36 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 12:01:10 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 10:56:27 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["L\u00fcdemann", "Niklas", ""], ["Shiba", "Ageda", ""], ["Thymianis", "Nikolaos", ""], ["Heist", "Nicolas", ""], ["Ludwig", "Christopher", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2008.05250", "submitter": "Anh My Vu", "authors": "Nam Hong Nguyen and My Anh Vu and Dinh Van Bui and Anh Ngoc Ta and\n  Manh Duc Hy", "title": "Optimizing fire allocation in a NCW-type model", "comments": "6 pages on NCW-type model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a non-linear Lanchester model of NCW-type and\ninvestigate an optimization problem for this model, where only the Red force is\nsupplied by several supply agents. Optimal fire allocation of the Blue force is\nsought in the form of a piece-wise constant function of time. A threatening\nrate is computed for the Red force and each of its supply agents at the\nbeginning of each stage of the combat. These rates can be used to derive the\noptimal decision for the Blue force to focus its firepower to the Red force\nitself or one of its supply agents. This optimal fire allocation is derived and\nproved by considering an optimization problem of number of Blue force troops.\nNumerical experiments are included to demonstrate the theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:55:32 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Nguyen", "Nam Hong", ""], ["Vu", "My Anh", ""], ["Van Bui", "Dinh", ""], ["Ta", "Anh Ngoc", ""], ["Hy", "Manh Duc", ""]]}, {"id": "2008.05282", "submitter": "Zhenyu Liu", "authors": "Zhenyu Liu, Chaohong Lu, Haiwei Huang, Shengfei Lyu, Zhenchao Tao", "title": "Text Classification based on Multi-granularity Attention Hybrid Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based approaches have become the driven forces for Natural\nLanguage Processing (NLP) tasks. Conventionally, there are two mainstream\nneural architectures for NLP tasks: the recurrent neural network (RNN) and the\nconvolution neural network (ConvNet). RNNs are good at modeling long-term\ndependencies over input texts, but preclude parallel computation. ConvNets do\nnot have memory capability and it has to model sequential data as un-ordered\nfeatures. Therefore, ConvNets fail to learn sequential dependencies over the\ninput texts, but it is able to carry out high-efficient parallel computation.\nAs each neural architecture, such as RNN and ConvNets, has its own pro and con,\nintegration of different architectures is assumed to be able to enrich the\nsemantic representation of texts, thus enhance the performance of NLP tasks.\nHowever, few investigation explores the reconciliation of these seemingly\nincompatible architectures. To address this issue, we propose a hybrid\narchitecture based on a novel hierarchical multi-granularity attention\nmechanism, named Multi-granularity Attention-based Hybrid Neural Network\n(MahNN). The attention mechanism is to assign different weights to different\nparts of the input sequence to increase the computation efficiency and\nperformance of neural models. In MahNN, two types of attentions are introduced:\nthe syntactical attention and the semantical attention. The syntactical\nattention computes the importance of the syntactic elements (such as words or\nsentence) at the lower symbolic level and the semantical attention is used to\ncompute the importance of the embedded space dimension corresponding to the\nupper latent semantics. We adopt the text classification as an exemplifying way\nto illustrate the ability of MahNN to understand texts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 13:02:48 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Liu", "Zhenyu", ""], ["Lu", "Chaohong", ""], ["Huang", "Haiwei", ""], ["Lyu", "Shengfei", ""], ["Tao", "Zhenchao", ""]]}, {"id": "2008.05297", "submitter": "Umberto Straccia", "authors": "Franco Alberto Cardillo and Umberto Straccia", "title": "Fuzzy OWL-BOOST: Learning Fuzzy Concept Inclusions via Real-Valued\n  Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OWL ontologies are nowadays a quite popular way to describe structured\nknowledge in terms of classes, relations among classes and class instances. In\nthis paper, given a target class T of an OWL ontology, we address the problem\nof learning fuzzy concept inclusion axioms that describe sufficient conditions\nfor being an individual instance of T. To do so, we present Fuzzy OWL-BOOST\nthat relies on the Real AdaBoost boosting algorithm adapted to the (fuzzy) OWL\ncase. We illustrate its effectiveness by means of an experimentation. An\ninteresting feature is that the learned rules can be represented directly into\nFuzzy OWL 2. As a consequence, any Fuzzy OWL 2 reasoner can then be used to\nautomatically determine/classify (and to which degree) whether an individual\nbelongs to the target class T.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 15:19:31 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 07:10:04 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Cardillo", "Franco Alberto", ""], ["Straccia", "Umberto", ""]]}, {"id": "2008.05391", "submitter": "Jing Tang", "authors": "Jing Tang, Xueyan Tang, Andrew Lim, Kai Han, Chongshou Li, Junsong\n  Yuan", "title": "Revisiting Modified Greedy Algorithm for Monotone Submodular\n  Maximization with a Knapsack Constraint", "comments": "The paper will appear in 2021 ACM SIGMETRICS conference (SIGMETRICS\n  '21), June 14-18, 2021, Beijing, China", "journal-ref": null, "doi": "10.1145/3447386", "report-no": null, "categories": "cs.DS cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotone submodular maximization with a knapsack constraint is NP-hard.\nVarious approximation algorithms have been devised to address this optimization\nproblem. In this paper, we revisit the widely known modified greedy algorithm.\nFirst, we show that this algorithm can achieve an approximation factor of\n$0.405$, which significantly improves the known factors of $0.357$ given by\nWolsey and $(1-1/\\mathrm{e})/2\\approx 0.316$ given by Khuller et al. More\nimportantly, our analysis closes a gap in Khuller et al.'s proof for the\nextensively mentioned approximation factor of $(1-1/\\sqrt{\\mathrm{e}})\\approx\n0.393$ in the literature to clarify a long-standing misconception on this\nissue. Second, we enhance the modified greedy algorithm to derive a\ndata-dependent upper bound on the optimum. We empirically demonstrate the\ntightness of our upper bound with a real-world application. The bound enables\nus to obtain a data-dependent ratio typically much higher than $0.405$ between\nthe solution value of the modified greedy algorithm and the optimum. It can\nalso be used to significantly improve the efficiency of algorithms such as\nbranch and bound.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:40:21 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 15:53:47 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Tang", "Jing", ""], ["Tang", "Xueyan", ""], ["Lim", "Andrew", ""], ["Han", "Kai", ""], ["Li", "Chongshou", ""], ["Yuan", "Junsong", ""]]}, {"id": "2008.05556", "submitter": "Gabriel Dulac-Arnold", "authors": "Arthur Argenson, Gabriel Dulac-Arnold", "title": "Model-Based Offline Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline learning is a key part of making reinforcement learning (RL) useable\nin real systems. Offline RL looks at scenarios where there is data from a\nsystem's operation, but no direct access to the system when learning a policy.\nRecent work on training RL policies from offline data has shown results both\nwith model-free policies learned directly from the data, or with planning on\ntop of learnt models of the data. Model-free policies tend to be more\nperformant, but are more opaque, harder to command externally, and less easy to\nintegrate into larger systems. We propose an offline learner that generates a\nmodel that can be used to control the system directly through planning. This\nallows us to have easily controllable policies directly from data, without ever\ninteracting with the system. We show the performance of our algorithm,\nModel-Based Offline Planning (MBOP) on a series of robotics-inspired tasks, and\ndemonstrate its ability leverage planning to respect environmental constraints.\nWe are able to find near-optimal polices for certain simulated systems from as\nlittle as 50 seconds of real-time system interaction, and create zero-shot\ngoal-conditioned policies on a series of environments. An accompanying video\ncan be found here: https://youtu.be/nxGGHdZOFts\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 20:06:52 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 16:41:47 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 17:22:51 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Argenson", "Arthur", ""], ["Dulac-Arnold", "Gabriel", ""]]}, {"id": "2008.05580", "submitter": "Richard Granger", "authors": "Richard Granger", "title": "Toward the quantification of cognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The machinery of the human brain -- analog, probabilistic, embodied -- can be\ncharacterized computationally, but what machinery confers what computational\npowers? Any such system can be abstractly cast in terms of two computational\ncomponents: a finite state machine carrying out computational steps, whether\nvia currents, chemistry, or mechanics; plus a set of allowable memory\noperations, typically formulated in terms of an information store that can be\nread from and written to, whether via synaptic change, state transition, or\nrecurrent activity. Probing these mechanisms for their information content, we\ncan capture the difference in computational power that various systems are\ncapable of. Most human cognitive abilities, from perception to action to\nmemory, are shared with other species; we seek to characterize those (few)\ncapabilities that are ubiquitously present among humans and absent from other\nspecies. Three realms of formidable constraints -- a) measurable human\ncognitive abilities, b) measurable allometric anatomic brain characteristics,\nand c) measurable features of specific automata and formal grammars --\nillustrate remarkably sharp restrictions on human abilities, unexpectedly\nconfining human cognition to a specific class of automata (\"nested stack\"),\nwhich are markedly below Turing machines.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 21:45:29 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Granger", "Richard", ""]]}, {"id": "2008.05585", "submitter": "Zhili Zhang", "authors": "Zhili Zhang and Quanyan Zhu", "title": "Deceptive Kernel Function on Observations of Discrete POMDP", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the deception applied on agent in a partially observable\nMarkov decision process. We introduce deceptive kernel function (the kernel)\napplied to agent's observations in a discrete POMDP. Based on value iteration,\nvalue function approximation and POMCP three characteristic algorithms used by\nagent, we analyze its belief being misled by falsified observations as the\nkernel's outputs and anticipate its probable threat on agent's reward and\npotentially other performance. We validate our expectation and explore more\ndetrimental effects of the deception by experimenting on two POMDP problems.\nThe result shows that the kernel applied on agent's observation can affect its\nbelief and substantially lower its resulting rewards; meantime certain\nimplementation of the kernel could induce other abnormal behaviors by the\nagent.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 21:59:42 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zhang", "Zhili", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2008.05598", "submitter": "Aske Plaat", "authors": "Aske Plaat, Walter Kosters, Mike Preuss", "title": "Deep Model-Based Reinforcement Learning for High-Dimensional Problems, a\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning has shown remarkable success in the past few\nyears. Highly complex sequential decision making problems have been solved in\ntasks such as game playing and robotics. Unfortunately, the sample complexity\nof most deep reinforcement learning methods is high, precluding their use in\nsome important applications. Model-based reinforcement learning creates an\nexplicit model of the environment dynamics to reduce the need for environment\nsamples. Current deep learning methods use high-capacity networks to solve\nhigh-dimensional problems. Unfortunately, high-capacity models typically\nrequire many samples, negating the potential benefit of lower sample complexity\nin model-based methods. A challenge for deep model-based methods is therefore\nto achieve high predictive power while maintaining low sample complexity. In\nrecent years, many model-based methods have been introduced to address this\nchallenge. In this paper, we survey the contemporary model-based landscape.\nFirst we discuss definitions and relations to other fields. We propose a\ntaxonomy based on three approaches: using explicit planning on given\ntransitions, using explicit planning on learned transitions, and end-to-end\nlearning of both planning and transitions. We use these approaches to organize\na comprehensive overview of important recent developments such as latent\nmodels. We describe methods and benchmarks, and we suggest directions for\nfuture work for each of the approaches. Among promising research directions are\ncurriculum learning, uncertainty modeling, and use of latent models for\ntransfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 08:49:04 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:40:17 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Plaat", "Aske", ""], ["Kosters", "Walter", ""], ["Preuss", "Mike", ""]]}, {"id": "2008.05607", "submitter": "Frank Emmert-Streib", "authors": "Frank Emmert-Streib, Olli Yli-Harja, Matthias Dehmer", "title": "A clarification of misconceptions, myths and desired status of\n  artificial intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field artificial intelligence (AI) has been founded over 65 years ago.\nStarting with great hopes and ambitious goals the field progressed though\nvarious stages of popularity and received recently a revival in the form of\ndeep neural networks. Some problems of AI are that so far neither\n'intelligence' nor the goals of AI are formally defined causing confusion when\ncomparing AI to other fields. In this paper, we present a perspective on the\ndesired and current status of AI in relation to machine learning and statistics\nand clarify common misconceptions and myths. Our discussion is intended to\nuncurtain the veil of vagueness surrounding AI to see its true countenance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 17:22:53 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Emmert-Streib", "Frank", ""], ["Yli-Harja", "Olli", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2008.05638", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Muhammad Najib and Giuseppe Perelli and Michael\n  Wooldridge", "title": "Automated Temporal Equilibrium Analysis: Verification and Synthesis of\n  Multi-Player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of multi-agent systems, the rational verification problem is\nconcerned with checking which temporal logic properties will hold in a system\nwhen its constituent agents are assumed to behave rationally and strategically\nin pursuit of individual objectives. Typically, those objectives are expressed\nas temporal logic formulae which the relevant agent desires to see satisfied.\nUnfortunately, rational verification is computationally complex, and requires\nspecialised techniques in order to obtain practically useable implementations.\nIn this paper, we present such a technique. This technique relies on a\nreduction of the rational verification problem to the solution of a collection\nof parity games. Our approach has been implemented in the Equilibrium\nVerification Environment (EVE) system. The EVE system takes as input a model of\na concurrent/multi-agent system represented using the Simple Reactive Modules\nLanguage (SRML), where agent goals are represented as Linear Temporal Logic\n(LTL) formulae, together with a claim about the equilibrium behaviour of the\nsystem, also expressed as an LTL formula. EVE can then check whether the LTL\nclaim holds on some (or every) computation of the system that could arise\nthrough agents choosing Nash equilibrium strategies; it can also check whether\na system has a Nash equilibrium, and synthesise individual strategies for\nplayers in the multi-player game. After presenting our basic framework, we\ndescribe our new technique and prove its correctness. We then describe our\nimplementation in the EVE system, and present experimental results which show\nthat EVE performs favourably in comparison to other existing tools that support\nrational verification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:43:31 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Najib", "Muhammad", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05640", "submitter": "Liang Pang", "authors": "Changying Hao, Liang Pang, Yanyan Lan, Fei Sun, Jiafeng Guo, Xueqi\n  Cheng", "title": "Ranking Enhanced Dialogue Generation", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411918", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to effectively utilize the dialogue history is a crucial problem in\nmulti-turn dialogue generation. Previous works usually employ various neural\nnetwork architectures (e.g., recurrent neural networks, attention mechanisms,\nand hierarchical structures) to model the history. However, a recent empirical\nstudy by Sankar et al. has shown that these architectures lack the ability of\nunderstanding and modeling the dynamics of the dialogue history. For example,\nthe widely used architectures are insensitive to perturbations of the dialogue\nhistory, such as words shuffling, utterances missing, and utterances\nreordering. To tackle this problem, we propose a Ranking Enhanced Dialogue\ngeneration framework in this paper. Despite the traditional representation\nencoder and response generation modules, an additional ranking module is\nintroduced to model the ranking relation between the former utterance and\nconsecutive utterances. Specifically, the former utterance and consecutive\nutterances are treated as query and corresponding documents, and both local and\nglobal ranking losses are designed in the learning process. In this way, the\ndynamics in the dialogue history can be explicitly captured. To evaluate our\nproposed models, we conduct extensive experiments on three public datasets,\ni.e., bAbI, PersonaChat, and JDC. Experimental results show that our models\nproduce better responses in terms of both quantitative measures and human\njudgments, as compared with the state-of-the-art dialogue generation models.\nFurthermore, we give some detailed experimental analysis to show where and how\nthe improvements come from.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:49:56 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hao", "Changying", ""], ["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Sun", "Fei", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2008.05643", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Aniello Murano and Giuseppe Perelli and Sasha\n  Rubin and Thomas Steeples and Michael Wooldridge", "title": "Equilibria for Games with Combined Qualitative and Quantitative\n  Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall aim of our research is to develop techniques to reason about the\nequilibrium properties of multi-agent systems. We model multi-agent systems as\nconcurrent games, in which each player is a process that is assumed to act\nindependently and strategically in pursuit of personal preferences. In this\narticle, we study these games in the context of finite-memory strategies, and\nwe assume players' preferences are defined by a qualitative and a quantitative\nobjective, which are related by a lexicographic order: a player first prefers\nto satisfy its qualitative objective (given as a formula of Linear Temporal\nLogic) and then prefers to minimise costs (given by a mean-payoff function).\nOur main result is that deciding the existence of a strict epsilon Nash\nequilibrium in such games is 2ExpTime-complete (and hence decidable), even if\nplayers' deviations are implemented as infinite-memory strategies.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:56:24 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Murano", "Aniello", ""], ["Perelli", "Giuseppe", ""], ["Rubin", "Sasha", ""], ["Steeples", "Thomas", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05647", "submitter": "Julian Gutierrez", "authors": "Julian Gutierrez and Giuseppe Perelli and Michael Wooldridge", "title": "Multi-Player Games with LDL Goals over Finite Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Dynamic Logic on finite traces LDLf is a powerful logic for reasoning\nabout the behaviour of concurrent and multi-agent systems.\n  In this paper, we investigate techniques for both the characterisation and\nverification of equilibria in multi-player games with goals/objectives\nexpressed using logics based on LDLf. This study builds upon a generalisation\nof Boolean games, a logic-based game model of multi-agent systems where players\nhave goals succinctly represented in a logical way.\n  Because LDLf goals are considered, in the settings we study -- Reactive\nModules games and iterated Boolean games with goals over finite traces --\nplayers' goals can be defined to be regular properties while achieved in a\nfinite, but arbitrarily large, trace.\n  In particular, using alternating automata, the paper investigates\nautomata-theoretic approaches to the characterisation and verification of (pure\nstrategy Nash) equilibria, shows that the set of Nash equilibria in\nmulti-player games with LDLf objectives is regular, and provides complexity\nresults for the associated automata constructions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:11:06 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gutierrez", "Julian", ""], ["Perelli", "Giuseppe", ""], ["Wooldridge", "Michael", ""]]}, {"id": "2008.05660", "submitter": "Nathan Gavenski", "authors": "Nathan Gavenski and Juarez Monteiro and Roger Granada and Felipe\n  Meneguzzi and Rodrigo C. Barros", "title": "Imitating Unknown Policies via Exploration", "comments": "This paper has been accepted in the British Machine Vision Virtual\n  Conference (BMVC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral cloning is an imitation learning technique that teaches an agent\nhow to behave through expert demonstrations. Recent approaches use\nself-supervision of fully-observable unlabeled snapshots of the states to\ndecode state-pairs into actions. However, the iterative learning scheme from\nthese techniques are prone to getting stuck into bad local minima. We address\nthese limitations incorporating a two-phase model into the original framework,\nwhich learns from unlabeled observations via exploration, substantially\nimproving traditional behavioral cloning by exploiting (i) a sampling mechanism\nto prevent bad local minima, (ii) a sampling mechanism to improve exploration,\nand (iii) self-attention modules to capture global features. The resulting\ntechnique outperforms the previous state-of-the-art in four different\nenvironments by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:03:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gavenski", "Nathan", ""], ["Monteiro", "Juarez", ""], ["Granada", "Roger", ""], ["Meneguzzi", "Felipe", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "2008.05789", "submitter": "Ying Cheng", "authors": "Ying Cheng, Ruize Wang, Zhihao Pan, Rui Feng, Yuejie Zhang", "title": "Look, Listen, and Attend: Co-Attention Network for Self-Supervised\n  Audio-Visual Representation Learning", "comments": "Accepted by the 28th ACM International Conference on Multimedia (ACM\n  MM 2020)", "journal-ref": null, "doi": "10.1145/3394171.3413869", "report-no": null, "categories": "cs.MM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When watching videos, the occurrence of a visual event is often accompanied\nby an audio event, e.g., the voice of lip motion, the music of playing\ninstruments. There is an underlying correlation between audio and visual\nevents, which can be utilized as free supervised information to train a neural\nnetwork by solving the pretext task of audio-visual synchronization. In this\npaper, we propose a novel self-supervised framework with co-attention mechanism\nto learn generic cross-modal representations from unlabelled videos in the\nwild, and further benefit downstream tasks. Specifically, we explore three\ndifferent co-attention modules to focus on discriminative visual regions\ncorrelated to the sounds and introduce the interactions between them.\nExperiments show that our model achieves state-of-the-art performance on the\npretext task while having fewer parameters compared with existing methods. To\nfurther evaluate the generalizability and transferability of our approach, we\napply the pre-trained model on two downstream tasks, i.e., sound source\nlocalization and action recognition. Extensive experiments demonstrate that our\nmodel provides competitive results with other self-supervised methods, and also\nindicate that our approach can tackle the challenging scenes which contain\nmultiple sound sources.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:08:12 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Cheng", "Ying", ""], ["Wang", "Ruize", ""], ["Pan", "Zhihao", ""], ["Feng", "Rui", ""], ["Zhang", "Yuejie", ""]]}, {"id": "2008.05799", "submitter": "Marcus Scheunemann", "authors": "Marcus M. Scheunemann and Raymond H. Cuijpers and Christoph Salge", "title": "Warmth and Competence to Predict Human Preference of Robot Behavior in\n  Physical Human-Robot Interaction", "comments": "8 pages, 4 figures, 29th IEEE International Conference on Robot &\n  Human Interactive Communication (RO-MAN) 2020", "journal-ref": null, "doi": "10.1109/RO-MAN47096.2020.9223478", "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.IT cs.RO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A solid methodology to understand human perception and preferences in\nhuman-robot interaction (HRI) is crucial in designing real-world HRI. Social\ncognition posits that the dimensions Warmth and Competence are central and\nuniversal dimensions characterizing other humans. The Robotic Social Attribute\nScale (RoSAS) proposes items for those dimensions suitable for HRI and\nvalidated them in a visual observation study. In this paper we complement the\nvalidation by showing the usability of these dimensions in a behavior based,\nphysical HRI study with a fully autonomous robot. We compare the findings with\nthe popular Godspeed dimensions Animacy, Anthropomorphism, Likeability,\nPerceived Intelligence and Perceived Safety. We found that Warmth and\nCompetence, among all RoSAS and Godspeed dimensions, are the most important\npredictors for human preferences between different robot behaviors. This\npredictive power holds even when there is no clear consensus preference or\nsignificant factor difference between conditions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:19:47 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Scheunemann", "Marcus M.", ""], ["Cuijpers", "Raymond H.", ""], ["Salge", "Christoph", ""]]}, {"id": "2008.05804", "submitter": "Dell Zhang", "authors": "Dell Zhang, Alexander Kuhnle, Julian Richardson, Murat Sensoy", "title": "Process Discovery for Structured Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core task in process mining is process discovery which aims to learn an\naccurate process model from event log data. In this paper, we propose to use\n(block-) structured programs directly as target process models so as to\nestablish connections to the field of program synthesis and facilitate the\ntranslation from abstract process models to executable processes, e.g., for\nrobotic process automation. Furthermore, we develop a novel bottom-up\nagglomerative approach to the discovery of such structured program process\nmodels. In comparison with the popular top-down recursive inductive miner, our\nproposed agglomerative miner enjoys the similar theoretical guarantee to\nproduce sound process models (without deadlocks and other anomalies) while\nexhibiting some advantages like avoiding silent activities and accommodating\nduplicate activities. The proposed algorithm works by iteratively applying a\nfew graph rewriting rules to the directly-follows-graph of activities. For\nreal-world (sparse) directly-follows-graphs, the algorithm has quadratic\ncomputational complexity with respect to the number of distinct activities. To\nour knowledge, this is the first process discovery algorithm that is made for\nthe purpose of program synthesis. Experiments on the BPI-Challenge 2020 dataset\nand the Karel programming dataset have demonstrated that our proposed algorithm\ncan outperform the inductive miner not only according to the traditional\nprocess discovery metrics but also in terms of the effectiveness in finding out\nthe true underlying structured program from a small number of its execution\ntraces.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 10:33:10 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zhang", "Dell", ""], ["Kuhnle", "Alexander", ""], ["Richardson", "Julian", ""], ["Sensoy", "Murat", ""]]}, {"id": "2008.05925", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Jinhang Wu, Luxin Liu and Yue Zhang", "title": "Commonsense Knowledge Graph Reasoning by Selection or Generation? Why?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge graph reasoning(CKGR) is the task of predicting a\nmissing entity given one existing and the relation in a commonsense knowledge\ngraph (CKG). Existing methods can be classified into two categories generation\nmethod and selection method. Each method has its own advantage. We\ntheoretically and empirically compare the two methods, finding the selection\nmethod is more suitable than the generation method in CKGR. Given the\nobservation, we further combine the structure of neural Text Encoder and\nKnowledge Graph Embedding models to solve the selection method's two problems,\nachieving competitive results. We provide a basic framework and baseline model\nfor subsequent CKGR tasks by selection methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:13:30 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Cunxiang", ""], ["Wu", "Jinhang", ""], ["Liu", "Luxin", ""], ["Zhang", "Yue", ""]]}, {"id": "2008.05930", "submitter": "Sergio Casas", "authors": "Abbas Sadat, Sergio Casas, Mengye Ren, Xinyu Wu, Pranaab Dhawan,\n  Raquel Urtasun", "title": "Perceive, Predict, and Plan: Safe Motion Planning Through Interpretable\n  Semantic Representations", "comments": "European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel end-to-end learnable network that performs\njoint perception, prediction and motion planning for self-driving vehicles and\nproduces interpretable intermediate representations. Unlike existing neural\nmotion planners, our motion planning costs are consistent with our perception\nand prediction estimates. This is achieved by a novel differentiable semantic\noccupancy representation that is explicitly used as cost by the motion planning\nprocess. Our network is learned end-to-end from human demonstrations. The\nexperiments in a large-scale manual-driving dataset and closed-loop simulation\nshow that the proposed model significantly outperforms state-of-the-art\nplanners in imitating the human behaviors while producing much safer\ntrajectories.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:40:46 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Sadat", "Abbas", ""], ["Casas", "Sergio", ""], ["Ren", "Mengye", ""], ["Wu", "Xinyu", ""], ["Dhawan", "Pranaab", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2008.05959", "submitter": "Philippe Esling", "authors": "Philippe Esling, Ninon Devis", "title": "Creativity in the era of artificial intelligence", "comments": "Keynote paper - JIM Conference 2020 - 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Creativity is a deeply debated topic, as this concept is arguably\nquintessential to our humanity. Across different epochs, it has been infused\nwith an extensive variety of meanings relevant to that era. Along these, the\nevolution of technology have provided a plurality of novel tools for creative\npurposes. Recently, the advent of Artificial Intelligence (AI), through deep\nlearning approaches, have seen proficient successes across various\napplications. The use of such technologies for creativity appear in a natural\ncontinuity to the artistic trend of this century. However, the aura of a\ntechnological artefact labeled as intelligent has unleashed passionate and\nsomewhat unhinged debates on its implication for creative endeavors. In this\npaper, we aim to provide a new perspective on the question of creativity at the\nera of AI, by blurring the frontier between social and computational sciences.\nTo do so, we rely on reflections from social science studies of creativity to\nview how current AI would be considered through this lens. As creativity is a\nhighly context-prone concept, we underline the limits and deficiencies of\ncurrent AI, requiring to move towards artificial creativity. We argue that the\nobjective of trying to purely mimic human creative traits towards a\nself-contained ex-nihilo generative machine would be highly counterproductive,\nputting us at risk of not harnessing the almost unlimited possibilities offered\nby the sheer computational power of artificial agents.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:07:34 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Esling", "Philippe", ""], ["Devis", "Ninon", ""]]}, {"id": "2008.05972", "submitter": "Pramod Vadiraja", "authors": "Pramod Vadiraja and Muhammad Ali Chattha", "title": "A Survey on Knowledge integration techniques with Artificial Neural\n  Networks for seq-2-seq/time series models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the advent of massive computational power and the\navailability of huge amounts of data, Deep neural networks have enabled the\nexploration of uncharted areas in several domains. But at times, they\nunder-perform due to insufficient data, poor data quality, data that might not\nbe covering the domain broadly, etc. Knowledge-based systems leverage expert\nknowledge for making decisions and suitably take actions. Such systems retain\ninterpretability in the decision-making process. This paper focuses on\nexploring techniques to integrate expert knowledge to the Deep Neural Networks\nfor sequence-to-sequence and time series models to improve their performance\nand interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:40:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Vadiraja", "Pramod", ""], ["Chattha", "Muhammad Ali", ""]]}, {"id": "2008.06035", "submitter": "Srikrishna Karanam", "authors": "Meng Zheng and Srikrishna Karanam and Terrence Chen and Richard J.\n  Radke and Ziyan Wu", "title": "Towards Visually Explaining Similarity Models", "comments": "13 pages, 10 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1911.07381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of visually explaining similarity models, i.e.,\nexplaining why a model predicts two images to be similar in addition to\nproducing a scalar score. While much recent work in visual model\ninterpretability has focused on gradient-based attention, these methods rely on\na classification module to generate visual explanations. Consequently, they\ncannot readily explain other kinds of models that do not use or need\nclassification-like loss functions (e.g., similarity models trained with a\nmetric learning loss). In this work, we bridge this crucial gap, presenting a\nmethod to generate gradient-based visual attention for image similarity\npredictors. By relying solely on the learned feature embedding, we show that\nour approach can be applied to any kind of CNN-based similarity architecture,\nan important step towards generic visual explainability. We show that our\nresulting attention maps serve more than just interpretability; they can be\ninfused into the model learning process itself with new trainable constraints.\nWe show that the resulting similarity models perform, and can be visually\nexplained, better than the corresponding baseline models trained without these\nconstraints. We demonstrate our approach using extensive experiments on three\ndifferent kinds of tasks: generic image retrieval, person re-identification,\nand low-shot semantic segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:47:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 17:00:38 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Radke", "Richard J.", ""], ["Wu", "Ziyan", ""]]}, {"id": "2008.06043", "submitter": "Eric A Mitchell", "authors": "Eric Mitchell, Rafael Rafailov, Xue Bin Peng, Sergey Levine, Chelsea\n  Finn", "title": "Offline Meta-Reinforcement Learning with Advantage Weighting", "comments": "ICML 2021; for code & project info, see\n  http://sites.google.com/view/macaw-metarl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the offline meta-reinforcement learning (offline\nmeta-RL) problem setting and proposes an algorithm that performs well in this\nsetting. Offline meta-RL is analogous to the widely successful supervised\nlearning strategy of pre-training a model on a large batch of fixed,\npre-collected data (possibly from various tasks) and fine-tuning the model to a\nnew task with relatively little data. That is, in offline meta-RL, we\nmeta-train on fixed, pre-collected data from several tasks in order to adapt to\na new task with a very small amount (less than 5 trajectories) of data from the\nnew task. By nature of being offline, algorithms for offline meta-RL can\nutilize the largest possible pool of training data available and eliminate\npotentially unsafe or costly data collection during meta-training. This setting\ninherits the challenges of offline RL, but it differs significantly because\noffline RL does not generally consider a) transfer to new tasks or b) limited\ndata from the test task, both of which we face in offline meta-RL. Targeting\nthe offline meta-RL setting, we propose Meta-Actor Critic with Advantage\nWeighting (MACAW), an optimization-based meta-learning algorithm that uses\nsimple, supervised regression objectives for both the inner and outer loop of\nmeta-training. On offline variants of common meta-RL benchmarks, we empirically\nfind that this approach enables fully offline meta-reinforcement learning and\nachieves notable gains over prior methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 17:57:14 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:35:24 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:33:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mitchell", "Eric", ""], ["Rafailov", "Rafael", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "2008.06052", "submitter": "Riccardo Franco", "authors": "Riccardo Franco", "title": "Constructed emotions and superinformation: a constructor-theoretic\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply the constructor-theoretic approach to the theory of\nconstructed emotions, showing that core affect valence and knowledge can be\nconsidered as two different observables, leading to information or\nsuperinformation conditions: this depends on subject's strategy, coherently\nwith the affect infusion model. In the second part of the article we show that\nadditional hypotheses on the structure of information allows to study emotions\nin terms of the contructor-theoretic version of phase task. Quantum algorithms\nare presented as an example of the connection between emotions and memory\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:54:38 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Franco", "Riccardo", ""]]}, {"id": "2008.06073", "submitter": "Andrey Kurenkov", "authors": "Andrey Kurenkov, Joseph Taglic, Rohun Kulkarni, Marcus\n  Dominguez-Kuhne, Animesh Garg, Roberto Mart\\'in-Mart\\'in, Silvio Savarese", "title": "Visuomotor Mechanical Search: Learning to Retrieve Target Objects in\n  Clutter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When searching for objects in cluttered environments, it is often necessary\nto perform complex interactions in order to move occluding objects out of the\nway and fully reveal the object of interest and make it graspable. Due to the\ncomplexity of the physics involved and the lack of accurate models of the\nclutter, planning and controlling precise predefined interactions with accurate\noutcome is extremely hard, when not impossible. In problems where accurate\n(forward) models are lacking, Deep Reinforcement Learning (RL) has shown to be\na viable solution to map observations (e.g. images) to good interactions in the\nform of close-loop visuomotor policies. However, Deep RL is sample inefficient\nand fails when applied directly to the problem of unoccluding objects based on\nimages. In this work we present a novel Deep RL procedure that combines i)\nteacher-aided exploration, ii) a critic with privileged information, and iii)\nmid-level representations, resulting in sample efficient and effective learning\nfor the problem of uncovering a target object occluded by a heap of unknown\nobjects. Our experiments show that our approach trains faster and converges to\nmore efficient uncovering solutions than baselines and ablations, and that our\nuncovering policies lead to an average improvement in the graspability of the\ntarget object, facilitating downstream retrieval applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:23:00 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kurenkov", "Andrey", ""], ["Taglic", "Joseph", ""], ["Kulkarni", "Rohun", ""], ["Dominguez-Kuhne", "Marcus", ""], ["Garg", "Animesh", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.06079", "submitter": "Francielle Alves Vargas", "authors": "Francielle Alves Vargas and Thiago Alexandre Salgueiro Pardo", "title": "Studying Dishonest Intentions in Brazilian Portuguese Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work in the social sciences, psychology and linguistics has show\nthat liars have some control over the content of their stories, however their\nunderlying state of mind may \"leak out\" through the way that they tell them. To\nthe best of our knowledge, no previous systematic effort exists in order to\ndescribe and model deception language for Brazilian Portuguese. To fill this\nimportant gap, we carry out an initial empirical linguistic study on false\nstatements in Brazilian news. We methodically analyze linguistic features using\na deceptive news corpus, which includes both fake and true news. The results\nshow that they present substantial lexical, syntactic and semantic variations,\nas well as punctuation and emotion distinctions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:44:52 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 21:31:47 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Vargas", "Francielle Alves", ""], ["Pardo", "Thiago Alexandre Salgueiro", ""]]}, {"id": "2008.06232", "submitter": "Jan Philipp Portisch", "authors": "Jan Portisch, Omaima Fallatah, Sebastian Neumaier, Mohamad Yaser\n  Jaradeh, Axel Polleres", "title": "Challenges of Linking Organizational Information in Open Government Data\n  to Knowledge Graphs", "comments": "to be published in the proceedings of the 22nd International\n  Conference on Knowledge Engineering and Knowledge Management (EKAW 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Government Data (OGD) is being published by various public\nadministration organizations around the globe. Within the metadata of OGD data\ncatalogs, the publishing organizations (1) are not uniquely and unambiguously\nidentifiable and, even worse, (2) change over time, by public administration\nunits being merged or restructured. In order to enable fine-grained analyses or\nsearches on Open Government Data on the level of publishing organizations,\nlinking those from OGD portals to publicly available knowledge graphs (KGs)\nsuch as Wikidata and DBpedia seems like an obvious solution. Still, as we show\nin this position paper, organization linking faces significant challenges, both\nin terms of available (portal) metadata and KGs in terms of data quality and\ncompleteness. We herein specifically highlight five main challenges, namely\nregarding (1) temporal changes in organizations and in the portal metadata, (2)\nlack of a base ontology for describing organizational structures and changes in\npublic knowledge graphs, (3) metadata and KG data quality, (4) multilinguality,\nand (5) disambiguating public sector organizations. Based on available OGD\nportal metadata from the Open Data Portal Watch, we provide an in-depth\nanalysis of these issues, make suggestions for concrete starting points on how\nto tackle them along with a call to the community to jointly work on these open\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:07:10 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Portisch", "Jan", ""], ["Fallatah", "Omaima", ""], ["Neumaier", "Sebastian", ""], ["Jaradeh", "Mohamad Yaser", ""], ["Polleres", "Axel", ""]]}, {"id": "2008.06313", "submitter": "Zelong Yang", "authors": "Zelong Yang, Zhufeng Pan, Yan Wang, Deng Cai, Xiaojiang Liu, Shuming\n  Shi, Shao-Lun Huang", "title": "Interpretable Real-Time Win Prediction for Honor of Kings, a Popular\n  Mobile MOBA Esport", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid prevalence and explosive development of MOBA esports\n(Multiplayer Online Battle Arena electronic sports), much research effort has\nbeen devoted to automatically predicting game results (win predictions). While\nthis task has great potential in various applications, such as esports live\nstreaming and game commentator AI systems, previous studies fail to investigate\nthe methods to interpret these win predictions. To mitigate this issue, we\ncollected a large-scale dataset that contains real-time game records with rich\ninput features of the popular MOBA game Honor of Kings. For interpretable\npredictions, we proposed a Two-Stage Spatial-Temporal Network (TSSTN) that can\nnot only provide accurate real-time win predictions but also attribute the\nultimate prediction results to the contributions of different features for\ninterpretability. Experiment results and applications in real-world live\nstreaming scenarios showed that the proposed TSSTN model is effective both in\nprediction accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:00:58 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:38:28 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 11:29:02 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yang", "Zelong", ""], ["Pan", "Zhufeng", ""], ["Wang", "Yan", ""], ["Cai", "Deng", ""], ["Liu", "Xiaojiang", ""], ["Shi", "Shuming", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "2008.06319", "submitter": "Christian Hubbs", "authors": "Christian D. Hubbs and Hector D. Perez and Owais Sarwar and Nikolaos\n  V. Sahinidis and Ignacio E. Grossmann and John M. Wassick", "title": "OR-Gym: A Reinforcement Learning Library for Operations Research\n  Problems", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been widely applied to game-playing and\nsurpassed the best human-level performance in many domains, yet there are few\nuse-cases in industrial or commercial settings. We introduce OR-Gym, an\nopen-source library for developing reinforcement learning algorithms to address\noperations research problems. In this paper, we apply reinforcement learning to\nthe knapsack, multi-dimensional bin packing, multi-echelon supply chain, and\nmulti-period asset allocation model problems, as well as benchmark the RL\nsolutions against MILP and heuristic models. These problems are used in\nlogistics, finance, engineering, and are common in many business operation\nsettings. We develop environments based on prototypical models in the\nliterature and implement various optimization and heuristic models in order to\nbenchmark the RL results. By re-framing a series of classic optimization\nproblems as RL tasks, we seek to provide a new tool for the operations research\ncommunity, while also opening those in the RL community to many of the problems\nand challenges in the OR field.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:21:22 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 11:58:49 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hubbs", "Christian D.", ""], ["Perez", "Hector D.", ""], ["Sarwar", "Owais", ""], ["Sahinidis", "Nikolaos V.", ""], ["Grossmann", "Ignacio E.", ""], ["Wassick", "John M.", ""]]}, {"id": "2008.06326", "submitter": "Shashank Gupta", "authors": "Shashank Gupta, Antonio Robles-Kelly and Mohamed Reda Bouadjenek", "title": "Feature Extraction Functions for Neural Logic Rule Learning", "comments": "to be published in S+SSPR 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining symbolic human knowledge with neural networks provides a rule-based\nante-hoc explanation of the output. In this paper, we propose feature\nextracting functions for integrating human knowledge abstracted as logic rules\ninto the predictive behavior of a neural network. These functions are embodied\nas programming functions, which represent the applicable domain knowledge as a\nset of logical instructions and provide a modified distribution of independent\nfeatures on input data. Unlike other existing neural logic approaches, the\nprogrammatic nature of these functions implies that they do not require any\nkind of special mathematical encoding, which makes our method very general and\nflexible in nature. We illustrate the performance of our approach for sentiment\nclassification and compare our results to those obtained using two baselines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 12:35:07 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 13:01:02 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 13:05:17 GMT"}, {"version": "v4", "created": "Sun, 11 Apr 2021 06:15:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gupta", "Shashank", ""], ["Robles-Kelly", "Antonio", ""], ["Bouadjenek", "Mohamed Reda", ""]]}, {"id": "2008.06359", "submitter": "Debangshu Banerjee", "authors": "Debangshu Banerjee", "title": "HEX and Neurodynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hex is a complex game with a high branching factor. For the first time Hex is\nbeing attempted to be solved without the use of game tree structures and\nassociated methods of pruning. We also are abstaining from any heuristic\ninformation about Virtual Connections or Semi Virtual Connections which were\npreviously used in all previous known computer versions of the game. The\nH-search algorithm which was the basis of finding such connections and had been\nused with success in previous Hex playing agents has been forgone. Instead what\nwe use is reinforcement learning through self play and approximations through\nneural networks to by pass the problem of high branching factor and maintaining\nlarge tables for state-action evaluations. Our code is based primarily on\nNeuroHex. The inspiration is drawn from the recent success of AlphaGo Zero.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:36:50 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Banerjee", "Debangshu", ""]]}, {"id": "2008.06457", "submitter": "Avinash Kori", "authors": "Avinash Kori, Parth Natekar, Ganapathy Krishnamurthi, Balaji\n  Srinivasan", "title": "Abstracting Deep Neural Networks into Concept Graphs for Concept Level\n  Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The black-box nature of deep learning models prevents them from being\ncompletely trusted in domains like biomedicine. Most explainability techniques\ndo not capture the concept-based reasoning that human beings follow. In this\nwork, we attempt to understand the behavior of trained models that perform\nimage processing tasks in the medical domain by building a graphical\nrepresentation of the concepts they learn. Extracting such a graphical\nrepresentation of the model's behavior on an abstract, higher conceptual level\nwould unravel the learnings of these models and would help us to evaluate the\nsteps taken by the model for predictions. We show the application of our\nproposed implementation on two biomedical problems - brain tumor segmentation\nand fundus image classification. We provide an alternative graphical\nrepresentation of the model by formulating a concept level graph as discussed\nabove, which makes the problem of intervention to find active inference trails\nmore tractable. Understanding these trails would provide an understanding of\nthe hierarchy of the decision-making process followed by the model. [As well as\noverall nature of model]. Our framework is available at\nhttps://github.com/koriavinash1/BioExp\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:34:32 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 07:12:01 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kori", "Avinash", ""], ["Natekar", "Parth", ""], ["Krishnamurthi", "Ganapathy", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "2008.06464", "submitter": "Shilin Xu", "authors": "Shilin Xu, Caili Guo, Rose Qingyang Hu and Yi Qian", "title": "Multi-Agent Deep Reinforcement Learning enabled Computation Resource\n  Allocation in a Vehicular Cloud Network", "comments": "I have update this paper, and a new version will be resubmitted later", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the computational resource allocation problem\nin a distributed Ad-Hoc vehicular network with no centralized infrastructure\nsupport. To support the ever increasing computational needs in such a vehicular\nnetwork, the distributed virtual cloud network (VCN) is formed, based on which\na computational resource sharing scheme through offloading among nearby\nvehicles is proposed. In view of the time-varying computational resource in\nVCN, the statistical distribution characteristics for computational resource\nare analyzed in detail. Thereby, a resource-aware combinatorial optimization\nobjective mechanism is proposed. To alleviate the non-stationary environment\ncaused by the typically multi-agent environment in VCN, we adopt a centralized\ntraining and decentralized execution framework. In addition, for the objective\noptimization problem, we model it as a Markov game and propose a DRL based\nmulti-agent deep deterministic reinforcement learning (MADDPG) algorithm to\nsolve it. Interestingly, to overcome the dilemma of lacking a real central\ncontrol unit in VCN, the allocation is actually completed on the vehicles in a\ndistributed manner. The simulation results are presented to demonstrate our\nscheme's effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:02:24 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:26:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Shilin", ""], ["Guo", "Caili", ""], ["Hu", "Rose Qingyang", ""], ["Qian", "Yi", ""]]}, {"id": "2008.06495", "submitter": "Yuandong Tian", "authors": "Yuandong Tian, Qucheng Gong, Tina Jiang", "title": "Joint Policy Search for Multi-agent Collaboration with Imperfect\n  Information", "comments": "Minor fix of the algorithm block", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn good joint policies for multi-agent collaboration with imperfect\ninformation remains a fundamental challenge. While for two-player zero-sum\ngames, coordinate-ascent approaches (optimizing one agent's policy at a time,\ne.g., self-play) work with guarantees, in multi-agent cooperative setting they\noften converge to sub-optimal Nash equilibrium. On the other hand, directly\nmodeling joint policy changes in imperfect information game is nontrivial due\nto complicated interplay of policies (e.g., upstream updates affect downstream\nstate reachability). In this paper, we show global changes of game values can\nbe decomposed to policy changes localized at each information set, with a novel\nterm named policy-change density. Based on this, we propose Joint Policy\nSearch(JPS) that iteratively improves joint policies of collaborative agents in\nimperfect information games, without re-evaluating the entire game. On\nmulti-agent collaborative tabular games, JPS is proven to never worsen\nperformance and can improve solutions provided by unilateral approaches (e.g,\nCFR), outperforming algorithms designed for collaborative policy learning (e.g.\nBAD). Furthermore, for real-world games, JPS has an online form that naturally\nlinks with gradient updates. We test it to Contract Bridge, a 4-player\nimperfect-information game where a team of $2$ collaborates to compete against\nthe other. In its bidding phase, players bid in turn to find a good contract\nthrough a limited information channel. Based on a strong baseline agent that\nbids competitive bridge purely through domain-agnostic self-play, JPS improves\ncollaboration of team players and outperforms WBridge5, a championship-winning\nsoftware, by $+0.63$ IMPs (International Matching Points) per board over 1k\ngames, substantially better than previous SoTA ($+0.41$ IMPs/b) under\nDouble-Dummy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 17:58:47 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 02:35:56 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 17:14:14 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 20:09:48 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 01:10:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tian", "Yuandong", ""], ["Gong", "Qucheng", ""], ["Jiang", "Tina", ""]]}, {"id": "2008.06529", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, and\n  Lalitha Sankar", "title": "Three Variants of Differential Privacy: Lossless Conversion and\n  Applications", "comments": "To appear in IEEE Journal on Selected Areas in Information Theory,\n  Special Issue on Privacy and Security of Information Systems. arXiv admin\n  note: text overlap with arXiv:2001.05990", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.CR math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three different variants of differential privacy (DP), namely\napproximate DP, R\\'enyi DP (RDP), and hypothesis test DP. In the first part, we\ndevelop a machinery for optimally relating approximate DP to RDP based on the\njoint range of two $f$-divergences that underlie the approximate DP and RDP. In\nparticular, this enables us to derive the optimal approximate DP parameters of\na mechanism that satisfies a given level of RDP. As an application, we apply\nour result to the moments accountant framework for characterizing privacy\nguarantees of noisy stochastic gradient descent (SGD). When compared to the\nstate-of-the-art, our bounds may lead to about 100 more stochastic gradient\ndescent iterations for training deep learning models for the same privacy\nbudget. In the second part, we establish a relationship between RDP and\nhypothesis test DP which allows us to translate the RDP constraint into a\ntradeoff between type I and type II error probabilities of a certain binary\nhypothesis test. We then demonstrate that for noisy SGD our result leads to\ntighter privacy guarantees compared to the recently proposed $f$-DP framework\nfor some range of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 18:23:50 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 19:34:51 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Liao", "Jiachun", ""], ["Calmon", "Flavio P.", ""], ["Kosut", "Oliver", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2008.06595", "submitter": "Teng Liu", "authors": "Teng Liu, Xingyu Mu, Bing Huang, Xiaolin Tang, Fuqing Zhao, Xiao Wang,\n  Dongpu Cao", "title": "Decision-making at Unsignalized Intersection for Autonomous Vehicles:\n  Left-turn Maneuver with Deep Reinforcement Learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making module enables autonomous vehicles to reach appropriate\nmaneuvers in the complex urban environments, especially the intersection\nsituations. This work proposes a deep reinforcement learning (DRL) based\nleft-turn decision-making framework at unsignalized intersection for autonomous\nvehicles. The objective of the studied automated vehicle is to make an\nefficient and safe left-turn maneuver at a four-way unsignalized intersection.\nThe exploited DRL methods include deep Q-learning (DQL) and double DQL.\nSimulation results indicate that the presented decision-making strategy could\nefficaciously reduce the collision rate and improve transport efficiency. This\nwork also reveals that the constructed left-turn control structure has a great\npotential to be applied in real-time.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:44:26 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Liu", "Teng", ""], ["Mu", "Xingyu", ""], ["Huang", "Bing", ""], ["Tang", "Xiaolin", ""], ["Zhao", "Fuqing", ""], ["Wang", "Xiao", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.06599", "submitter": "Peter Patel-Schneider", "authors": "Peter F. Patel-Schneider and David Martin", "title": "Wikidata on MARS", "comments": "arXiv admin note: text overlap with arXiv:2008.03900", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-attributed relational structures (MARSs) have been proposed as a formal\ndata model for generalized property graphs, along with multi-attributed\nrule-based predicate logic (MARPL) as a useful rule-based logic in which to\nwrite inference rules over property graphs. Wikidata can be modelled in an\nextended MARS that adds the (imprecise) datatypes of Wikidata. The rules of\ninference for the Wikidata ontology can be modelled as a MARPL ontology, with\nextensions to handle the Wikidata datatypes and functions over these datatypes.\nBecause many Wikidata qualifiers should participate in most inference rules in\nWikidata a method of implicitly handling qualifier values on a per-qualifier\nbasis is needed to make this modelling useful. The meaning of Wikidata is then\nthe extended MARS that is the closure of running these rules on the Wikidata\ndata model. Wikidata constraints can be modelled as multi-attributed predicate\nlogic (MAPL) formulae, again extended with datatypes, that are evaluated over\nthis extended MARS. The result models Wikidata in a way that fixes several of\nits major problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 22:58:04 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Patel-Schneider", "Peter F.", ""], ["Martin", "David", ""]]}, {"id": "2008.06601", "submitter": "Omid Halimi Milani", "authors": "Omid Halimi Milani, S. Ahmad Motamedi and Saeed Sharifian", "title": "Intelligent Service Selection in a Multi-dimensional Environment of\n  Cloud Providers for IoT stream Data through cloudlets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expansion of the Internet of Things(IoT) services and a huge amount of\ndata generated by different sensors, signify the importance of cloud computing\nservices like Storage as a Service more than ever. IoT traffic imposes such\nextra constraints on the cloud storage service as sensor data preprocessing\ncapability and load-balancing between data centers and servers in each data\ncenter. Also, it should be allegiant to the Quality of Service (QoS). The\nhybrid MWG algorithm has been proposed in this work, which considers different\nobjectives such as energy, processing time, transmission time, and load\nbalancing in both Fog and Cloud Layer. The MATLAB script is used to simulate\nand implement our algorithms, and services of different servers, e.g. Amazon,\nDropbox, Google Drive, etc. have been considered. The MWG has 7%, 13%, and 25%\nimprovement in comparison with MOWCA, KGA, and NSGAII in metric of spacing,\nrespectively. Moreover, the MWG has 4%, 4.7%, and 7.3% optimization in metric\nof quality in comparison to MOWCA, KGA, and NSGAII, respectively. The overall\noptimization shows that the MWG algorithm has 7.8%, 17%, and 21.6% better\nperformance in comparison with MOWCA, KGA, and NSGAII in the obtained best\nresult by considering different objectives, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 23:15:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 22:22:42 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Milani", "Omid Halimi", ""], ["Motamedi", "S. Ahmad", ""], ["Sharifian", "Saeed", ""]]}, {"id": "2008.06626", "submitter": "Akifumi Wachi", "authors": "Akifumi Wachi and Yanan Sui", "title": "Safe Reinforcement Learning in Constrained Markov Decision Processes", "comments": "10 pages, 6 figures, Accepted to ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe reinforcement learning has been a promising approach for optimizing the\npolicy of an agent that operates in safety-critical applications. In this\npaper, we propose an algorithm, SNO-MDP, that explores and optimizes Markov\ndecision processes under unknown safety constraints. Specifically, we take a\nstepwise approach for optimizing safety and cumulative reward. In our method,\nthe agent first learns safety constraints by expanding the safe region, and\nthen optimizes the cumulative reward in the certified safe region. We provide\ntheoretical guarantees on both the satisfaction of the safety constraint and\nthe near-optimality of the cumulative reward under proper regularity\nassumptions. In our experiments, we demonstrate the effectiveness of SNO-MDP\nthrough two experiments: one uses a synthetic data in a new, openly-available\nenvironment named GP-SAFETY-GYM, and the other simulates Mars surface\nexploration by using real observation data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 02:20:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wachi", "Akifumi", ""], ["Sui", "Yanan", ""]]}, {"id": "2008.06662", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou", "title": "Compositional Generalization via Neural-Symbolic Stack Machines", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving tremendous success, existing deep learning models have\nexposed limitations in compositional generalization, the capability to learn\ncompositional rules and apply them to unseen cases in a systematic manner. To\ntackle this issue, we propose the Neural-Symbolic Stack Machine (NeSS). It\ncontains a neural network to generate traces, which are then executed by a\nsymbolic stack machine enhanced with sequence manipulation operations. NeSS\ncombines the expressive power of neural sequence models with the recursion\nsupported by the symbolic stack machine. Without training supervision on\nexecution traces, NeSS achieves 100% generalization performance in four\ndomains: the SCAN benchmark of language-driven navigation tasks, the task of\nfew-shot learning of compositional instructions, the compositional machine\ntranslation benchmark, and context-free grammar parsing tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 06:23:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:16:10 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Xinyun", ""], ["Liang", "Chen", ""], ["Yu", "Adams Wei", ""], ["Song", "Dawn", ""], ["Zhou", "Denny", ""]]}, {"id": "2008.06692", "submitter": "Torsten Schaub", "authors": "Roland Kaminski and Javier Romero and Torsten Schaub and Philipp Wanko", "title": "How to build your own ASP-based system?!", "comments": "69 pages, submitted to TPLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) has become a popular and quite sophisticated\napproach to declarative problem solving. This is arguably due to its attractive\nmodeling-grounding-solving workflow that provides an easy approach to problem\nsolving, even for laypersons outside computer science. Unlike this, the high\ndegree of sophistication of the underlying technology makes it increasingly\nhard for ASP experts to put ideas into practice.\n  For addressing this issue, this tutorial aims at enabling users to build\ntheir own ASP-based systems. More precisely, we show how the ASP system CLINGO\ncan be used for extending ASP and for implementing customized special-purpose\nsystems. To this end, we propose two alternatives. We begin with a traditional\nAI technique and show how meta programming can be used for extending ASP. This\nis a rather light approach that relies on CLINGO's reification feature to use\nASP itself for expressing new functionalities. Unlike this, the major part of\nthis tutorial uses traditional programming (in PYTHON) for manipulating CLINGO\nvia its application programming interface. This approach allows for changing\nand controlling the entire model-ground-solve workflow of ASP. Central to this\nis CLINGO's new Application class that allows us to draw on CLINGO's\ninfrastructure by customizing processes similar to the one in CLINGO. For\ninstance, we may engage manipulations to programs' abstract syntax trees,\ncontrol various forms of multi-shot solving, and set up theory propagators for\nforeign inferences. Another cross-sectional structure, spanning meta as well as\napplication programming, is CLINGO's intermediate format, ASPIF, that specifies\nthe interface among the underlying grounder and solver. We illustrate the\naforementioned concepts and techniques throughout this tutorial by means of\nexamples and several non-trivial case-studies.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:08:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kaminski", "Roland", ""], ["Romero", "Javier", ""], ["Schaub", "Torsten", ""], ["Wanko", "Philipp", ""]]}, {"id": "2008.06693", "submitter": "Alexandre Heuillet", "authors": "Alexandre Heuillet, Fabien Couthouis and Natalia D\\'iaz-Rodr\\'iguez", "title": "Explainability in Deep Reinforcement Learning", "comments": "Article accepted at Knowledge-Based Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A large set of the explainable Artificial Intelligence (XAI) literature is\nemerging on feature relevance techniques to explain a deep neural network (DNN)\noutput or explaining models that ingest image source data. However, assessing\nhow XAI techniques can help understand models beyond classification tasks, e.g.\nfor reinforcement learning (RL), has not been extensively studied. We review\nrecent works in the direction to attain Explainable Reinforcement Learning\n(XRL), a relatively new subfield of Explainable Artificial Intelligence,\nintended to be used in general public applications, with diverse audiences,\nrequiring ethical, responsible and trustable algorithms. In critical situations\nwhere it is essential to justify and explain the agent's behaviour, better\nexplainability and interpretability of RL models could help gain scientific\ninsight on the inner workings of what is still considered a black box. We\nevaluate mainly studies directly linking explainability to RL, and split these\ninto two categories according to the way the explanations are generated:\ntransparent algorithms and post-hoc explainaility. We also review the most\nprominent XAI works from the lenses of how they could potentially enlighten the\nfurther deployment of the latest advances in RL, in the demanding present and\nfuture of everyday problems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:11:42 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 09:15:07 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 17:14:08 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 10:08:51 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Heuillet", "Alexandre", ""], ["Couthouis", "Fabien", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""]]}, {"id": "2008.06696", "submitter": "Varshit Dubey", "authors": "Varshit S. Dubey, Ruhshad Kasad and Karan Agrawal", "title": "Autonomous Braking and Throttle System: A Deep Reinforcement Learning\n  Approach for Naturalistic Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Braking and Throttle control is key in developing safe driving\nsystems for the future. There exists a need for autonomous vehicles to\nnegotiate a multi-agent environment while ensuring safety and comfort. A Deep\nReinforcement Learning based autonomous throttle and braking system is\npresented. For each time step, the proposed system makes a decision to apply\nthe brake or throttle. The throttle and brake are modelled as continuous action\nspace values. We demonstrate 2 scenarios where there is a need for a\nsophisticated braking and throttle system, i.e when there is a static obstacle\nin front of our agent like a car, stop sign. The second scenario consists of 2\nvehicles approaching an intersection. The policies for brake and throttle\ncontrol are learned through computer simulation using Deep deterministic policy\ngradients. The experiment shows that the system not only avoids a collision,\nbut also it ensures that there is smooth change in the values of throttle/brake\nas it gets out of the emergency situation and abides by the speed regulations,\ni.e the system resembles human driving.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:37:07 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dubey", "Varshit S.", ""], ["Kasad", "Ruhshad", ""], ["Agrawal", "Karan", ""]]}, {"id": "2008.06723", "submitter": "Lionel Robert", "authors": "Connor Esterwood, Lionel P. Robert", "title": "Personality in Healthcare Human Robot Interaction (H-HRI): A Literature\n  Review and Brief Critique", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": "10.1145/3406499.3415075", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are becoming an important way to deliver health care, and personality\nis vital to understanding their effectiveness. Despite this, there is a lack of\na systematic overarching understanding of personality in health care human\nrobot interaction (H-HRI). To address this, the authors conducted a review that\nidentified 18 studies on personality in H-HRI. This paper presents the results\nof that systematic literature review. Insights are derived from this review\nregarding the methodologies, outcomes, and samples utilized. The authors of\nthis review discuss findings across this literature while identifying several\ngaps worthy of attention. Overall, this paper is an important starting point in\nunderstanding personality in H-HRI.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 14:14:56 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Esterwood", "Connor", ""], ["Robert", "Lionel P.", ""]]}, {"id": "2008.06727", "submitter": "Md Mostafizur Rahman Komol", "authors": "Md Mostafizur Rahman Komol, Mohammed Elhenawy, Shamsunnahar Yasmin,\n  Mahmoud Masoud and Andry Rakotonirainy", "title": "A Review on Drivers Red Light Running and Turning Behaviour Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drivers behaviour prediction has been an unceasing concern for transportation\nsafety divisions all over the world. A massive amount of lives and properties\nlosses due to the adversities at intersections and pedestrian crossings.\nEspecially for countries with poor road safety technologies, this toll knows no\nbounds. A myriad of research and studies have been mastered for technological\nevaluation and model representation over this issue. Instead, little\ncomprehensive review has been made on the drivers behaviour prediction at\nsignalised intersections on red-light running and turning. This Paper aims at\nincorporating previous researches on drivers behaviour prediction and the\nprediction parameters leading to traffic violation like red-light running and\nturning at intersection and pedestrian crossing. The review also covers the\nprobable crash scenarios by red-light running and turning and analyses the\ninnovation of counter-crash technologies with future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 14:57:43 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Komol", "Md Mostafizur Rahman", ""], ["Elhenawy", "Mohammed", ""], ["Yasmin", "Shamsunnahar", ""], ["Masoud", "Mahmoud", ""], ["Rakotonirainy", "Andry", ""]]}, {"id": "2008.06738", "submitter": "Brahma Pavse", "authors": "Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone", "title": "Reducing Sampling Error in Batch Temporal Difference Learning", "comments": "Accepted to International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is one of the main foundations of modern\nreinforcement learning. This paper studies the use of TD(0), a canonical TD\nalgorithm, to estimate the value function of a given policy from a batch of\ndata. In this batch setting, we show that TD(0) may converge to an inaccurate\nvalue function because the update following an action is weighted according to\nthe number of times that action occurred in the batch -- not the true\nprobability of the action under the given policy. To address this limitation,\nwe introduce \\textit{policy sampling error corrected}-TD(0) (PSEC-TD(0)).\nPSEC-TD(0) first estimates the empirical distribution of actions in each state\nin the batch and then uses importance sampling to correct for the mismatch\nbetween the empirical weighting and the correct weighting for updates following\neach action. We refine the concept of a certainty-equivalence estimate and\nargue that PSEC-TD(0) is a more data efficient estimator than TD(0) for a fixed\nbatch of data. Finally, we conduct an empirical evaluation of PSEC-TD(0) on\nthree batch value function learning tasks, with a hyperparameter sensitivity\nanalysis, and show that PSEC-TD(0) produces value function estimates with lower\nmean squared error than TD(0).\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 15:30:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pavse", "Brahma", ""], ["Durugkar", "Ishan", ""], ["Hanna", "Josiah", ""], ["Stone", "Peter", ""]]}, {"id": "2008.06759", "submitter": "Xiaowei Liu", "authors": "Xiaowei Liu, Weiwei Guo, Huiji Gao, Bo Long", "title": "Deep Search Query Intent Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a user's query intent behind a search is critical for modern\nsearch engine success. Accurate query intent prediction allows the search\nengine to better serve the user's need by rendering results from more relevant\ncategories. This paper aims to provide a comprehensive learning framework for\nmodeling query intent under different stages of a search. We focus on the\ndesign for 1) predicting users' intents as they type in queries on-the-fly in\ntypeahead search using character-level models; and 2) accurate word-level\nintent prediction models for complete queries. Various deep learning components\nfor query text understanding are experimented. Offline evaluation and online\nA/B test experiments show that the proposed methods are effective in\nunderstanding query intent and efficient to scale for online search systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 18:19:56 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 04:59:27 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Liu", "Xiaowei", ""], ["Guo", "Weiwei", ""], ["Gao", "Huiji", ""], ["Long", "Bo", ""]]}, {"id": "2008.06775", "submitter": "Karan Goel", "authors": "Karan Goel, Albert Gu, Yixuan Li and Christopher R\\'e", "title": "Model Patching: Closing the Subgroup Performance Gap with Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers in machine learning are often brittle when deployed. Particularly\nconcerning are models with inconsistent performance on specific subgroups of a\nclass, e.g., exhibiting disparities in skin cancer classification in the\npresence or absence of a spurious bandage. To mitigate these performance\ndifferences, we introduce model patching, a two-stage framework for improving\nrobustness that encourages the model to be invariant to subgroup differences,\nand focus on class information shared by subgroups. Model patching first models\nsubgroup features within a class and learns semantic transformations between\nthem, and then trains a classifier with data augmentations that deliberately\nmanipulate subgroup features. We instantiate model patching with CAMEL, which\n(1) uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and\n(2) balances subgroup performance using a theoretically-motivated subgroup\nconsistency regularizer, accompanied by a new robust objective. We demonstrate\nCAMEL's effectiveness on 3 benchmark datasets, with reductions in robust error\nof up to 33% relative to the best baseline. Lastly, CAMEL successfully patches\na model that fails due to spurious features on a real-world skin cancer\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 20:01:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goel", "Karan", ""], ["Gu", "Albert", ""], ["Li", "Yixuan", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2008.06799", "submitter": "Divyanshu Marwah", "authors": "Divyanshu Marwah, Sneha Srivastava, Anusha Gupta, Shruti Verma", "title": "Chrome Dino Run using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning is one of the most advanced set of algorithms known to\nmankind which can compete in games and perform at par or even better than\nhumans. In this paper we study most popular model free reinforcement learning\nalgorithms along with convolutional neural network to train the agent for\nplaying the game of Chrome Dino Run. We have used two of the popular temporal\ndifference approaches namely Deep Q-Learning, and Expected SARSA and also\nimplemented Double DQN model to train the agent and finally compare the scores\nwith respect to the episodes and convergence of algorithms with respect to\ntimesteps.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 22:18:20 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Marwah", "Divyanshu", ""], ["Srivastava", "Sneha", ""], ["Gupta", "Anusha", ""], ["Verma", "Shruti", ""]]}, {"id": "2008.06824", "submitter": "Balder ten Cate", "authors": "Balder ten Cate and Victor Dalmau", "title": "Conjunctive Queries: Unique Characterizations and Exact Learnability", "comments": null, "journal-ref": "Proceedings of the 24th International Conference on Database\n  Theory (ICDT 2021), pp. 7:1-7:35", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We answer the question which conjunctive queries are uniquely characterized\nby polynomially many positive and negative examples, and how to construct such\nexamples efficiently. As a consequence, we obtain a new efficient exact\nlearning algorithm for a class of conjunctive queries. At the core of our\ncontributions lie two new polynomial-time algorithms for constructing frontiers\nin the homomorphism lattice of finite structures. We also discuss implications\nfor the unique characterizability and learnability of schema mappings and of\ndescription logic concepts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 02:54:56 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 06:52:51 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Cate", "Balder ten", ""], ["Dalmau", "Victor", ""]]}, {"id": "2008.06832", "submitter": "Dayong Ye", "authors": "Dayong Ye and Tianqing Zhu and Sheng Shen and Wanlei Zhou and Philip\n  S. Yu", "title": "Differentially Private Multi-Agent Planning for Logistic-like Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is one of the main approaches used to improve agents' working\nefficiency by making plans beforehand. However, during planning, agents face\nthe risk of having their private information leaked. This paper proposes a\nnovel strong privacy-preserving planning approach for logistic-like problems.\nThis approach outperforms existing approaches by addressing two challenges: 1)\nsimultaneously achieving strong privacy, completeness and efficiency, and 2)\naddressing communication constraints. These two challenges are prevalent in\nmany real-world applications including logistics in military environments and\npacket routing in networks. To tackle these two challenges, our approach adopts\nthe differential privacy technique, which can both guarantee strong privacy and\ncontrol communication overhead. To the best of our knowledge, this paper is the\nfirst to apply differential privacy to the field of multi-agent planning as a\nmeans of preserving the privacy of agents for logistic-like problems. We\ntheoretically prove the strong privacy and completeness of our approach and\nempirically demonstrate its efficiency. We also theoretically analyze the\ncommunication overhead of our approach and illustrate how differential privacy\ncan be used to control it.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 03:43:09 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ye", "Dayong", ""], ["Zhu", "Tianqing", ""], ["Shen", "Sheng", ""], ["Zhou", "Wanlei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2008.06869", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "SECODA: Segmentation- and Combination-Based Detection of Anomalies", "comments": "12 pages (including DSAA conference poster), 9 figures, 3 tables.\n  Presented at DSAA 2017, the IEEE International Conference on Data Science and\n  Advanced Analytics", "journal-ref": null, "doi": "10.1109/DSAA.2017.35", "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study introduces SECODA, a novel general-purpose unsupervised\nnon-parametric anomaly detection algorithm for datasets containing continuous\nand categorical attributes. The method is guaranteed to identify cases with\nunique or sparse combinations of attribute values. Continuous attributes are\ndiscretized repeatedly in order to correctly determine the frequency of such\nvalue combinations. The concept of constellations, exponentially increasing\nweights and discretization cut points, as well as a pruning heuristic are used\nto detect anomalies with an optimal number of iterations. Moreover, the\nalgorithm has a low memory imprint and its runtime performance scales linearly\nwith the size of the dataset. An evaluation with simulated and real-life\ndatasets shows that this algorithm is able to identify many different types of\nanomalies, including complex multidimensional instances. An evaluation in terms\nof a data quality use case with a real dataset demonstrates that SECODA can\nbring relevant and practical value to real-world settings.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 10:03:14 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2008.06924", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Inverse Reinforcement Learning with Natural Language Goals", "comments": "To appear in Proceedings of the 35th AAAI Conference on Artificial\n  Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans generally use natural language to communicate task requirements to\neach other. Ideally, natural language should also be usable for communicating\ngoals to autonomous machines (e.g., robots) to minimize friction in task\nspecification. However, understanding and mapping natural language goals to\nsequences of states and actions is challenging. Specifically, existing work\nalong these lines has encountered difficulty in generalizing learned policies\nto new natural language goals and environments. In this paper, we propose a\nnovel adversarial inverse reinforcement learning algorithm to learn a\nlanguage-conditioned policy and reward function. To improve generalization of\nthe learned policy and reward function, we use a variational goal generator to\nrelabel trajectories and sample diverse goals during training. Our algorithm\noutperforms multiple baselines by a large margin on a vision-based natural\nlanguage instruction following dataset (Room-2-Room), demonstrating a promising\nadvance in enabling the use of natural language instructions in specifying\nagent goals.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:43:49 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 02:44:41 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 04:40:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "2008.06979", "submitter": "Jos\\'e Ribeiro MSc.", "authors": "Jos\\'e Ribeiro, Lair Meneses, Denis Costa, Wando Miranda, Ronnie Alves", "title": "Prediction of Homicides in Urban Centers: A Machine Learning Approach", "comments": "17 pages, 4 tables and 3 figures, Accepted in IntelliSys 2021", "journal-ref": "IntelliSys 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relevant research has been highlighted in the computing community to develop\nmachine learning models capable of predicting the occurrence of crimes,\nanalyzing contexts of crimes, extracting profiles of individuals linked to\ncrime, and analyzing crimes over time. However, models capable of predicting\nspecific crimes, such as homicide, are not commonly found in the current\nliterature. This research presents a machine learning model to predict homicide\ncrimes, using a dataset that uses generic data (without study location\ndependencies) based on incident report records for 34 different types of\ncrimes, along with time and space data from crime reports. Experimentally, data\nfrom the city of Bel\\'em - Par\\'a, Brazil was used. These data were transformed\nto make the problem generic, enabling the replication of this model to other\nlocations. In the research, analyses were performed with simple and robust\nalgorithms on the created dataset. With this, statistical tests were performed\nwith 11 different classification methods and the results are related to the\nprediction's occurrence and non-occurrence of homicide crimes in the month\nsubsequent to the occurrence of other registered crimes, with 76% assertiveness\nfor both classes of the problem, using Random Forest. Results are considered as\na baseline for the proposed problem.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 19:13:53 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 20:01:54 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 15:59:59 GMT"}, {"version": "v4", "created": "Sun, 21 Mar 2021 18:35:10 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ribeiro", "Jos\u00e9", ""], ["Meneses", "Lair", ""], ["Costa", "Denis", ""], ["Miranda", "Wando", ""], ["Alves", "Ronnie", ""]]}, {"id": "2008.06995", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Fenglong Ma, Jing Gao", "title": "Efficient Knowledge Graph Validation via Cross-Graph Representation\n  Learning", "comments": "CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in information extraction have motivated the automatic\nconstruction of huge Knowledge Graphs (KGs) by mining from large-scale text\ncorpus. However, noisy facts are unavoidably introduced into KGs that could be\ncaused by automatic extraction. To validate the correctness of facts (i.e.,\ntriplets) inside a KG, one possible approach is to map the triplets into vector\nrepresentations by capturing the semantic meanings of facts. Although many\nrepresentation learning approaches have been developed for knowledge graphs,\nthese methods are not effective for validation. They usually assume that facts\nare correct, and thus may overfit noisy facts and fail to detect such facts.\nTowards effective KG validation, we propose to leverage an external\nhuman-curated KG as auxiliary information source to help detect the errors in a\ntarget KG. The external KG is built upon human-curated knowledge repositories\nand tends to have high precision. On the other hand, although the target KG\nbuilt by information extraction from texts has low precision, it can cover new\nor domain-specific facts that are not in any human-curated repositories. To\ntackle this challenging task, we propose a cross-graph representation learning\nframework, i.e., CrossVal, which can leverage an external KG to validate the\nfacts in the target KG efficiently. This is achieved by embedding triplets\nbased on their semantic meanings, drawing cross-KG negative samples and\nestimating a confidence score for each triplet based on its degree of\ncorrectness. We evaluate the proposed framework on datasets across different\ndomains. Experimental results show that the proposed framework achieves the\nbest performance compared with the state-of-the-art methods on large-scale KGs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 20:51:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Yaqing", ""], ["Ma", "Fenglong", ""], ["Gao", "Jing", ""]]}, {"id": "2008.07007", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "Towards Faithful and Meaningful Interpretable Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable representations are the backbone of many black-box explainers.\nThey translate the low-level data representation necessary for good predictive\nperformance into high-level human-intelligible concepts used to convey the\nexplanation. Notably, the explanation type and its cognitive complexity are\ndirectly controlled by the interpretable representation, allowing to target a\nparticular audience and use case. However, many explainers that rely on\ninterpretable representations overlook their merit and fall back on default\nsolutions, which may introduce implicit assumptions, thereby degrading the\nexplanatory power of such techniques. To address this problem, we study\nproperties of interpretable representations that encode presence and absence of\nhuman-comprehensible concepts. We show how they are operationalised for\ntabular, image and text data, discussing their strengths and weaknesses.\nFinally, we analyse their explanatory properties in the context of tabular\ndata, where a linear model is used to quantify the importance of interpretable\nconcepts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:44:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2008.07079", "submitter": "Quentin Gendre", "authors": "Quentin Gendre, Tomoyuki Kaneko", "title": "Playing Catan with Cross-dimensional Neural Network", "comments": "12 pages, 5 tables and 10 figures; submitted to the ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catan is a strategic board game having interesting properties, including\nmulti-player, imperfect information, stochastic, complex state space structure\n(hexagonal board where each vertex, edge and face has its own features, cards\nfor each player, etc), and a large action space (including negotiation).\nTherefore, it is challenging to build AI agents by Reinforcement Learning (RL\nfor short), without domain knowledge nor heuristics. In this paper, we\nintroduce cross-dimensional neural networks to handle a mixture of information\nsources and a wide variety of outputs, and empirically demonstrate that the\nnetwork dramatically improves RL in Catan. We also show that, for the first\ntime, a RL agent can outperform jsettler, the best heuristic agent available.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:09:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gendre", "Quentin", ""], ["Kaneko", "Tomoyuki", ""]]}, {"id": "2008.07087", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Yuke Zhu, Jure Leskovec, Anima Anandkumar, Animesh Garg", "title": "OCEAN: Online Task Inference for Compositional Tasks with Context\n  Adaptation", "comments": "UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world tasks often exhibit a compositional structure that contains a\nsequence of simpler sub-tasks. For instance, opening a door requires reaching,\ngrasping, rotating, and pulling the door knob. Such compositional tasks require\nan agent to reason about the sub-task at hand while orchestrating global\nbehavior accordingly. This can be cast as an online task inference problem,\nwhere the current task identity, represented by a context variable, is\nestimated from the agent's past experiences with probabilistic inference.\nPrevious approaches have employed simple latent distributions, e.g., Gaussian,\nto model a single context for the entire task. However, this formulation lacks\nthe expressiveness to capture the composition and transition of the sub-tasks.\nWe propose a variational inference framework OCEAN to perform online task\ninference for compositional tasks. OCEAN models global and local context\nvariables in a joint latent space, where the global variables represent a\nmixture of sub-tasks required for the task, while the local variables capture\nthe transitions between the sub-tasks. Our framework supports flexible latent\ndistributions based on prior knowledge of the task structure and can be trained\nin an unsupervised manner. Experimental results show that OCEAN provides more\neffective task inference with sequential context adaptation and thus leads to a\nperformance boost on complex, multi-stage tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 04:50:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ren", "Hongyu", ""], ["Zhu", "Yuke", ""], ["Leskovec", "Jure", ""], ["Anandkumar", "Anima", ""], ["Garg", "Animesh", ""]]}, {"id": "2008.07273", "submitter": "C. Maria Keet", "authors": "C. Maria Keet", "title": "Why a computer program is a functional whole", "comments": "25 pages, 5 figures, extended technical report of the accepted FOIS\n  2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing, downloading, and reusing software is common-place, some of which is\ncarried out legally with open source software. When it is not legal, it is\nunclear just how many copyright infringements and trade secret violations have\ntaken place: does an infringement count for the artefact as a whole or perhaps\nfor each file of the program? To answer this question, it must first be\nestablished whether a program should be considered as an integral whole, a\ncollection, or a mere set of distinct files, and why. We argue that a program\nis a functional whole, availing of, and combining, arguments from mereology,\ngranularity, modularity, unity, and function to substantiate the claim. The\nargumentation and answer contributes to the ontology of software artefacts, may\nassist industry in litigation cases, and demonstrates that the notion of\nunifying relation is operationalisable. Indirectly, it provides support for\ncontinued modular design of artefacts following established engineering\npractices.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 10:47:58 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Keet", "C. Maria", ""]]}, {"id": "2008.07283", "submitter": "Sergio Garrido", "authors": "Sergio Garrido, Stanislav S. Borysov, Jeppe Rich, Francisco C. Pereira", "title": "Estimating Causal Effects with the Neural Autoregressive Density\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of causal effects is fundamental in situations were the underlying\nsystem will be subject to active interventions. Part of building a causal\ninference engine is defining how variables relate to each other, that is,\ndefining the functional relationship between variables given conditional\ndependencies. In this paper, we deviate from the common assumption of linear\nrelationships in causal models by making use of neural autoregressive density\nestimators and use them to estimate causal effects within the Pearl's\ndo-calculus framework. Using synthetic data, we show that the approach can\nretrieve causal effects from non-linear systems without explicitly modeling the\ninteractions between the variables.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:38 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 13:03:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Garrido", "Sergio", ""], ["Borysov", "Stanislav S.", ""], ["Rich", "Jeppe", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2008.07284", "submitter": "Eiji Uchibe", "authors": "Eiji Uchibe and Kenji Doya", "title": "Imitation learning based on entropy-regularized forward and inverse\n  reinforcement learning", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Entropy-Regularized Imitation Learning (ERIL), which is a\ncombination of forward and inverse reinforcement learning under the framework\nof the entropy-regularized Markov decision process. ERIL minimizes the reverse\nKullback-Leibler (KL) divergence between two probability distributions induced\nby a learner and an expert. Inverse reinforcement learning (RL) in ERIL\nevaluates the log-ratio between two distributions using the density ratio\ntrick, which is widely used in generative adversarial networks. More\nspecifically, the log-ratio is estimated by building two binary discriminators.\nThe first discriminator is a state-only function, and it tries to distinguish\nthe state generated by the forward RL step from the expert's state. The second\ndiscriminator is a function of current state, action, and transitioned state,\nand it distinguishes the generated experiences from the ones provided by the\nexpert. Since the second discriminator has the same hyperparameters of the\nforward RL step, it can be used to control the discriminator's ability. The\nforward RL minimizes the reverse KL estimated by the inverse RL. We show that\nminimizing the reverse KL divergence is equivalent to finding an optimal policy\nunder entropy regularization. Consequently, a new policy is derived from an\nalgorithm that resembles Dynamic Policy Programming and Soft Actor-Critic. Our\nexperimental results on MuJoCo-simulated environments show that ERIL is more\nsample-efficient than such previous methods. We further apply the method to\nhuman behaviors in performing a pole-balancing task and show that the estimated\nreward functions show how every subject achieves the goal.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:12:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Uchibe", "Eiji", ""], ["Doya", "Kenji", ""]]}, {"id": "2008.07303", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Christoph-Nikolas Straehle", "title": "Learning game-theoretic models of multiagent trajectories using implicit\n  layers", "comments": "Accepted at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For prediction of interacting agents' trajectories, we propose an end-to-end\ntrainable architecture that hybridizes neural nets with game-theoretic\nreasoning, has interpretable intermediate representations, and transfers to\ndownstream decision making. It uses a net that reveals preferences from the\nagents' past joint trajectory, and a differentiable implicit layer that maps\nthese preferences to local Nash equilibria, forming the modes of the predicted\nfuture trajectory. Additionally, it learns an equilibrium refinement concept.\nFor tractability, we introduce a new class of continuous potential games and an\nequilibrium-separating partition of the action space. We provide theoretical\nresults for explicit gradients and soundness. In experiments, we evaluate our\napproach on two real-world data sets, where we predict highway driver merging\ntrajectories, and on a simple decision-making transfer task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:34:12 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 15:09:02 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 14:43:04 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 21:07:22 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 14:16:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Geiger", "Philipp", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "2008.07318", "submitter": "Suining He", "authors": "Xi Yang and Suining He", "title": "Towards Dynamic Urban Bike Usage Prediction for Station Network\n  Reconfiguration", "comments": "9 pages, UrbComp 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bike sharing has become one of the major choices of transportation for\nresidents in metropolitan cities worldwide. A station-based bike sharing system\nis usually operated in the way that a user picks up a bike from one station,\nand drops it off at another. Bike stations are, however, not static, as the\nbike stations are often reconfigured to accommodate changing demands or city\nurbanization over time. One of the key operations is to evaluate candidate\nlocations and install new stations to expand the bike sharing station network.\nConventional practices have been studied to predict existing station usage,\nwhile evaluating new stations is highly challenging due to the lack of the\nhistorical bike usage.\n  To fill this gap, in this work we propose a novel and efficient bike\nstation-level prediction algorithm called AtCoR, which can predict the bike\nusage at both existing and new stations (candidate locations during\nreconfiguration). In order to address the lack of historical data issues,\nvirtual historical usage of new stations is generated according to their\ncorrelations with the surrounding existing stations, for AtCoR model\ninitialization. We have designed novel station-centered heatmaps which\ncharacterize for each target station centered at the heatmap the trend that\nriders travel between it and the station's neighboring regions, enabling the\nmodel to capture the learnable features of the bike station network. The\ncaptured features are further applied to the prediction of bike usage for new\nstations. Our extensive experiment study on more than 23 million trips from\nthree major bike sharing systems in US, including New York City, Chicago and\nLos Angeles, shows that AtCoR outperforms baselines and state-of-art models in\nprediction of both existing and future stations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 23:41:29 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yang", "Xi", ""], ["He", "Suining", ""]]}, {"id": "2008.07324", "submitter": "Karl Fezer", "authors": "Karl Fezer and Andrew Sloss", "title": "Intelligence Primer", "comments": "34 pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This primer explores the exciting subject of intelligence. Intelligence is a\nfundamental component of all living things, as well as Artificial\nIntelligence(AI). Artificial Intelligence has the potential to affect all of\nour lives and a new era for modern humans. This paper is an attempt to explore\nthe ideas associated with intelligence, and by doing so understand the\nimplications, constraints, and potentially the capabilities of future\nArtificial Intelligence. As an exploration, we journey into different parts of\nintelligence that appear essential. We hope that people find this useful in\ndetermining where Artificial Intelligence may be headed. Also, during the\nexploration, we hope to create new thought-provoking questions. Intelligence is\nnot a single weighable quantity but a subject that spans Biology, Physics,\nPhilosophy, Cognitive Science, Neuroscience, Psychology, and Computer Science.\nHistorian Yuval Noah Harari pointed out that engineers and scientists in the\nfuture will have to broaden their understandings to include disciplines such as\nPsychology, Philosophy, and Ethics. Fiction writers have long portrayed\nengineers and scientists as deficient in these areas. Today, modern society,\nthe emergence of Artificial Intelligence, and legal requirements all act as\nforcing functions to push these broader subjects into the foreground. We start\nwith an introduction to intelligence and move quickly onto more profound\nthoughts and ideas. We call this a Life, the Universe and Everything primer,\nafter the famous science fiction book by Douglas Adams. Forty-two may very well\nbe the right answer, but what are the questions?\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:47:04 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 17:04:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Fezer", "Karl", ""], ["Sloss", "Andrew", ""]]}, {"id": "2008.07328", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "An Ontological AI-and-Law Framework for the Autonomous Levels of AI\n  Legal Reasoning", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is proposed that seeks to identify and establish a set of robust\nautonomous levels articulating the realm of Artificial Intelligence and Legal\nReasoning (AILR). Doing so provides a sound and parsimonious basis for being\nable to assess progress in the application of AI to the law, and can be\nutilized by scholars in academic pursuits of AI legal reasoning, along with\nbeing used by law practitioners and legal professionals in gauging how advances\nin AI are aiding the practice of law and the realization of aspirational versus\nachieved results. A set of seven levels of autonomy for AI and Legal Reasoning\nare meticulously proffered and mindfully discussed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 16:12:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2008.07331", "submitter": "Shuby Deshpande", "authors": "Shuby Deshpande, Benjamin Eysenbach, Jeff Schneider", "title": "Interactive Visualization for Debugging RL", "comments": "Builds on preliminary work presented at ICML 2020 (WHI)\n  arXiv:2007.05577. An interactive demo of the system can be at\n  https://tinyurl.com/y5gv5t4m", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization tools for supervised learning allow users to interpret,\nintrospect, and gain an intuition for the successes and failures of their\nmodels. While reinforcement learning practitioners ask many of the same\nquestions, existing tools are not applicable to the RL setting as these tools\naddress challenges typically found in the supervised learning regime. In this\nwork, we design and implement an interactive visualization tool for debugging\nand interpreting RL algorithms. Our system addresses many features missing from\nprevious tools such as (1) tools for supervised learning often are not\ninteractive; (2) while debugging RL policies researchers use state\nrepresentations that are different from those seen by the agent; (3) a\nframework designed to make the debugging RL policies more conducive. We provide\nan example workflow of how this system could be used, along with ideas for\nfuture extensions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 15:28:18 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 22:27:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Deshpande", "Shuby", ""], ["Eysenbach", "Benjamin", ""], ["Schneider", "Jeff", ""]]}, {"id": "2008.07343", "submitter": "Thanh Thi Nguyen", "authors": "Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Edbert B.\n  Hsu, Samuel Yang, Peter Eklund", "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A\n  Survey and Future Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) has been applied widely in our daily lives in a\nvariety of ways with numerous successful stories. AI has also contributed to\ndealing with the coronavirus disease (COVID-19) pandemic, which has been\nhappening around the globe. This paper presents a survey of AI methods being\nused in various applications in the fight against the COVID-19 outbreak and\noutlines the crucial roles of AI research in this unprecedented battle. We\ntouch on a number of areas where AI plays as an essential component, from\nmedical image processing, data analytics, text mining and natural language\nprocessing, the Internet of Things, to computational biology and medicine. A\nsummary of COVID-19 related data sources that are available for research\npurposes is also presented. Research directions on exploring the potentials of\nAI and enhancing its capabilities and power in the battle are thoroughly\ndiscussed. We highlight 13 groups of problems related to the COVID-19 pandemic\nand point out promising AI methods and tools that can be used to solve those\nproblems. It is envisaged that this study will provide AI researchers and the\nwider community an overview of the current status of AI applications and\nmotivate researchers in harnessing AI potentials in the fight against COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 11:11:55 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 03:20:18 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nguyen", "Thanh Thi", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Nguyen", "Dung Tien", ""], ["Hsu", "Edbert B.", ""], ["Yang", "Samuel", ""], ["Eklund", "Peter", ""]]}, {"id": "2008.07346", "submitter": "Federico Ruggeri", "authors": "Federico Ruggeri, Francesca Lagioia, Marco Lippi, Paolo Torroni", "title": "Memory networks for consumer protection:unfairness exposed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated how data-driven AI methods can leverage consumer\nprotection by supporting the automated analysis of legal documents. However, a\nshortcoming of data-driven approaches is poor explainability. We posit that in\nthis domain useful explanations of classifier outcomes can be provided by\nresorting to legal rationales. We thus consider several configurations of\nmemory-augmented neural networks where rationales are given a special role in\nthe modeling of context knowledge. Our results show that rationales not only\ncontribute to improve the classification accuracy, but are also able to offer\nmeaningful, natural language explanations of otherwise opaque classifier\noutcomes.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 14:25:54 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ruggeri", "Federico", ""], ["Lagioia", "Francesca", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "2008.07353", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Zheng Wen, Xi Chen", "title": "On the Sample Complexity of Reinforcement Learning with Policy Space\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimal sample complexity in large-scale Reinforcement Learning\n(RL) problems with policy space generalization, i.e. the agent has a prior\nknowledge that the optimal policy lies in a known policy space. Existing\nresults show that without a generalization model, the sample complexity of an\nRL algorithm will inevitably depend on the cardinalities of state space and\naction space, which are intractably large in many practical problems.\n  To avoid such undesirable dependence on the state and action space sizes,\nthis paper proposes a new notion of eluder dimension for the policy space,\nwhich characterizes the intrinsic complexity of policy learning in an arbitrary\nMarkov Decision Process (MDP). Using a simulator oracle, we prove a\nnear-optimal sample complexity upper bound that only depends linearly on the\neluder dimension. We further prove a similar regret bound in deterministic\nsystems without the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:26:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mou", "Wenlong", ""], ["Wen", "Zheng", ""], ["Chen", "Xi", ""]]}, {"id": "2008.07356", "submitter": "Marcelo Teixeira", "authors": "Darlan Felipe Klotz and Richardson Ribeiro and Fabr\\'icio Enembreck\n  and Gustavo Denardin and Marco Barbosa and Dalcimar Casanova and Marcelo\n  Teixeira", "title": "Estimating action plans for smart poultry houses", "comments": "To be submitted to the journal Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In poultry farming, the systematic choice, update, and implementation of\nperiodic (t) action plans define the feed conversion rate (FCR[t]), which is an\nacceptable measure for successful production. Appropriate action plans provide\ntailored resources for broilers, allowing them to grow within the so-called\nthermal comfort zone, without wast or lack of resources. Although the\nimplementation of an action plan is automatic, its configuration depends on the\nknowledge of the specialist, tending to be inefficient and error-prone, besides\nto result in different FCR[t] for each poultry house. In this article, we claim\nthat the specialist's perception can be reproduced, to some extent, by\ncomputational intelligence. By combining deep learning and genetic algorithm\ntechniques, we show how action plans can adapt their performance over the time,\nbased on previous well succeeded plans. We also implement a distributed network\ninfrastructure that allows to replicate our method over distributed poultry\nhouses, for their smart, interconnected, and adaptive control. A supervision\nsystem is provided as interface to users. Experiments conducted over real data\nshow that our method improves 5% on the performance of the most productive\nspecialist, staying very close to the optimal FCR[t].\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:28:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Klotz", "Darlan Felipe", ""], ["Ribeiro", "Richardson", ""], ["Enembreck", "Fabr\u00edcio", ""], ["Denardin", "Gustavo", ""], ["Barbosa", "Marco", ""], ["Casanova", "Dalcimar", ""], ["Teixeira", "Marcelo", ""]]}, {"id": "2008.07371", "submitter": "John Bishop Prof", "authors": "John Mark Bishop", "title": "Artificial Intelligence is stupid and causal reasoning won't fix it", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks have reached Grandmaster and even super-human\nperformance across a variety of games: from those involving perfect-information\n(such as Go) to those involving imperfect-information (such as Starcraft). Such\ntechnological developments from AI-labs have ushered concomitant applications\nacross the world of business - where an AI brand tag is fast becoming\nubiquitous. A corollary of such widespread commercial deployment is that when\nAI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist\nbehaviour; automated credit scoring processes discriminate on gender etc. -\nthere are often significant financial, legal and brand consequences and the\nincident becomes major news. As Judea Pearl sees it, the underlying reason for\nsuch mistakes is that, 'all the impressive achievements of deep learning amount\nto just curve fitting'. The key, Judea Pearl suggests, is to replace reasoning\nby association with causal-reasoning - the ability to infer causes from\nobserved phenomena. It is a point that was echoed by Gary Marcus and Ernest\nDavis in a recent piece for the New York Times: 'we need to stop building\ncomputer systems that merely get better and better at detecting statistical\npatterns in data sets - often using an approach known as Deep Learning - and\nstart building computer systems that from the moment of their assembly innately\ngrasp three basic concepts: time, space and causality'. In this paper,\nforegrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer\nan alternative explanation for AI errors: it is not so much that AI machinery\ncannot grasp causality, but that AI machinery - qua computation - cannot\nunderstand anything at all.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 22:23:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bishop", "John Mark", ""]]}, {"id": "2008.07372", "submitter": "Welverton Silva", "authors": "Welverton R. Silva and Rafael C. S. Schouery", "title": "Maximum Customers' Satisfaction in One-way Car-sharing: Modeling, Exact\n  and Heuristic Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-way car-sharing systems are transportation systems that allow customers\nto rent cars at stations scattered around the city, use them for a short\njourney, and return them at any station. The maximum customers' satisfaction\nproblem concerns the task of assigning the cars, initially located at given\nstations, to maximize the number of satisfied customers. We consider the\nproblem with two stations where each customer has exactly two demands in\nopposite directions between both stations, and a customer is satisfied only if\nboth their demands are fulfilled. For solving this problem, we propose\nmixed-integer programming (MIP) models and matheuristics based on local search.\nWe created a benchmark of instances used to test the exact and heuristic\napproaches. Additionally, we proposed a preprocessing procedure to reduce the\nsize of the instance. Our MIP models can solve to optimality 85% of the\nproposed instances with 1000 customers in 10 minutes, with an average gap\nsmaller than 0.1% for all these instances. For larger instances (2500 and 5000\ncustomers), except for some particular cases, they presented an average gap\nsmaller than 0.8%. Also, our local-based matheuristics presented small average\ngaps which are better than the MIP models in some larger instances.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:27:44 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Silva", "Welverton R.", ""], ["Schouery", "Rafael C. S.", ""]]}, {"id": "2008.07408", "submitter": "Thomas Rood", "authors": "Thomas Rood and Marcel van Gerven and Pablo Lanillos", "title": "A deep active inference model of the rubber-hand illusion", "comments": "8 pages, 3 figures, Accepted in 1st International Workshop on Active\n  Inference, in Conjunction with European Conference of Machine Learning 2020.\n  The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-64919-7_10", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_10", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how perception and action deal with sensorimotor conflicts,\nsuch as the rubber-hand illusion (RHI), is essential to understand how the body\nadapts to uncertain situations. Recent results in humans have shown that the\nRHI not only produces a change in the perceived arm location, but also causes\ninvoluntary forces. Here, we describe a deep active inference agent in a\nvirtual environment, which we subjected to the RHI, that is able to account for\nthese results. We show that our model, which deals with visual high-dimensional\ninputs, produces similar perceptual and force patterns to those found in\nhumans.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 15:28:57 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 13:48:59 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Rood", "Thomas", ""], ["van Gerven", "Marcel", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2008.07433", "submitter": "Sriram Vasudevan", "authors": "Sriram Vasudevan, Krishnaram Kenthapadi", "title": "LiFT: A Scalable Framework for Measuring Fairness in ML Applications", "comments": "Accepted for publication in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412705", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many internet applications are powered by machine learned models, which are\nusually trained on labeled datasets obtained through either implicit / explicit\nuser feedback signals or human judgments. Since societal biases may be present\nin the generation of such datasets, it is possible for the trained models to be\nbiased, thereby resulting in potential discrimination and harms for\ndisadvantaged groups. Motivated by the need for understanding and addressing\nalgorithmic bias in web-scale ML systems and the limitations of existing\nfairness toolkits, we present the LinkedIn Fairness Toolkit (LiFT), a framework\nfor scalable computation of fairness metrics as part of large ML systems. We\nhighlight the key requirements in deployed settings, and present the design of\nour fairness measurement system. We discuss the challenges encountered in\nincorporating fairness tools in practice and the lessons learned during\ndeployment at LinkedIn. Finally, we provide open problems based on practical\nexperience.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:55:31 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Vasudevan", "Sriram", ""], ["Kenthapadi", "Krishnaram", ""]]}, {"id": "2008.07434", "submitter": "Michael Allen", "authors": "Michael Allen, and Thomas Monks", "title": "Integrating Deep Reinforcement Learning Networks with Health System\n  Simulations", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and motivation: Combining Deep Reinforcement Learning (Deep RL)\nand Health Systems Simulations has significant potential, for both research\ninto improving Deep RL performance and safety, and in operational practice.\nWhile individual toolkits exist for Deep RL and Health Systems Simulations, no\nframework to integrate the two has been established.\n  Aim: Provide a framework for integrating Deep RL Networks with Health System\nSimulations, and to ensure this framework is compatible with Deep RL agents\nthat have been developed and tested using OpenAI Gym.\n  Methods: We developed our framework based on the OpenAI Gym framework, and\ndemonstrate its use on a simple hospital bed capacity model. We built the Deep\nRL agents using PyTorch, and the Hospital Simulatation using SimPy.\n  Results: We demonstrate example models using a Double Deep Q Network or a\nDuelling Double Deep Q Network as the Deep RL agent.\n  Conclusion: SimPy may be used to create Health System Simulations that are\ncompatible with agents developed and tested on OpenAI Gym environments.\n  GitHub repository of code:\nhttps://github.com/MichaelAllen1966/learninghospital\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 07:44:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Allen", "Michael", ""], ["Monks", "Thomas", ""]]}, {"id": "2008.07449", "submitter": "Toki Inan", "authors": "Muhammad Nazrul Islam, Toki Tahmid Inan, Suzzana Rafi, Syeda Sabrina\n  Akter, Iqbal H. Sarker, A. K. M. Najmul Islam", "title": "A Survey on the Use of AI and ML for Fighting the COVID-19 Pandemic", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) have made a paradigm\nshift in health care which, eventually can be used for decision support and\nforecasting by exploring the medical data. Recent studies showed that AI and ML\ncan be used to fight against the COVID-19 pandemic. Therefore, the objective of\nthis review study is to summarize the recent AI and ML based studies that have\nfocused to fight against COVID-19 pandemic. From an initial set of 634\narticles, a total of 35 articles were finally selected through an extensive\ninclusion-exclusion process. In our review, we have explored the\nobjectives/aims of the existing studies (i.e., the role of AI/ML in fighting\nCOVID-19 pandemic); context of the study (i.e., study focused to a specific\ncountry-context or with a global perspective); type and volume of dataset;\nmethodology, algorithms or techniques adopted in the prediction or diagnosis\nprocesses; and mapping the algorithms/techniques with the data type\nhighlighting their prediction/classification accuracy. We particularly focused\non the uses of AI/ML in analyzing the pandemic data in order to depict the most\nrecent progress of AI for fighting against COVID-19 and pointed out the\npotential scope of further research.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 16:49:04 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Islam", "Muhammad Nazrul", ""], ["Inan", "Toki Tahmid", ""], ["Rafi", "Suzzana", ""], ["Akter", "Syeda Sabrina", ""], ["Sarker", "Iqbal H.", ""], ["Islam", "A. K. M. Najmul", ""]]}, {"id": "2008.07456", "submitter": "Lauren Pusey-Nazzaro", "authors": "Lauren Pusey-Nazzaro, Prasanna Date", "title": "Adiabatic Quantum Optimization Fails to Solve the Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we attempt to solve the integer-weight knapsack problem using\nthe D-Wave 2000Q adiabatic quantum computer. The knapsack problem is a\nwell-known NP-complete problem in computer science, with applications in\neconomics, business, finance, etc. We attempt to solve a number of small\nknapsack problems whose optimal solutions are known; we find that adiabatic\nquantum optimization fails to produce solutions corresponding to optimal\nfilling of the knapsack in all problem instances. We compare results obtained\non the quantum hardware to the classical simulated annealing algorithm and two\nsolvers employing a hybrid branch-and-bound algorithm. The simulated annealing\nalgorithm also fails to produce the optimal filling of the knapsack, though\nsolutions obtained by simulated and quantum annealing are no more similar to\neach other than to the correct solution. We discuss potential causes for this\nobserved failure of adiabatic quantum optimization.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:29:34 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pusey-Nazzaro", "Lauren", ""], ["Date", "Prasanna", ""]]}, {"id": "2008.07463", "submitter": "Alessandro Artale", "authors": "Sabiha Tahrat, German Braun, Alessandro Artale, Marco Gario, and Ana\n  Ozaki", "title": "Automated Reasoning in Temporal DL-Lite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the feasibility of automated reasoning over temporal\nDL-Lite (TDL-Lite) knowledge bases (KBs). We test the usage of off-the-shelf\nLTL reasoners to check satisfiability of TDL-Lite KBs. In particular, we test\nthe robustness and the scalability of reasoners when dealing with TDL-Lite\nTBoxes paired with a temporal ABox. We conduct various experiments to analyse\nthe performance of different reasoners by randomly generating TDL-Lite KBs and\nthen measuring the running time and the size of the translations. Furthermore,\nin an effort to make the usage of TDL-Lite KBs a reality, we present a fully\nfledged tool with a graphical interface to design them. Our interface is based\non conceptual modelling principles and it is integrated with our translation\ntool and a temporal reasoner.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:40:27 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tahrat", "Sabiha", ""], ["Braun", "German", ""], ["Artale", "Alessandro", ""], ["Gario", "Marco", ""], ["Ozaki", "Ana", ""]]}, {"id": "2008.07491", "submitter": "Andrea Mazza", "authors": "Gianfranco Chicco and Andrea Mazza", "title": "Metaheuristic optimization of power and energy systems: underlying\n  principles and main issues of the 'rush to heuristics'", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the power and energy systems area, a progressive increase of literature\ncontributions containing applications of metaheuristic algorithms is occurring.\nIn many cases, these applications are merely aimed at proposing the testing of\nan existing metaheuristic algorithm on a specific problem, claiming that the\nproposed method is better than other methods based on weak comparisons. This\n'rush to heuristics' does not happen in the evolutionary computation domain,\nwhere the rules for setting up rigorous comparisons are stricter, but are\ntypical of the domains of application of the metaheuristics. This paper\nconsiders the applications to power and energy systems, and aims at providing a\ncomprehensive view of the main issues concerning the use of metaheuristics for\nglobal optimization problems. A set of underlying principles that characterize\nthe metaheuristic algorithms is presented. The customization of metaheuristic\nalgorithms to fit the constraints of specific problems is discussed. Some\nweaknesses and pitfalls found in literature contributions are identified, and\nspecific guidelines are provided on how to prepare sound contributions on the\napplication of metaheuristic algorithms to specific problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:33:51 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Chicco", "Gianfranco", ""], ["Mazza", "Andrea", ""]]}, {"id": "2008.07559", "submitter": "Kaustubh Dhole", "authors": "Kaustubh D. Dhole", "title": "Resolving Intent Ambiguities by Retrieving Discriminative Clarifying\n  Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented Dialogue Systems generally employ intent detection systems in\norder to map user queries to a set of pre-defined intents. However, user\nqueries appearing in natural language can be easily ambiguous and hence such a\ndirect mapping might not be straightforward harming intent detection and\neventually the overall performance of a dialogue system. Moreover, acquiring\ndomain-specific clarification questions is costly. In order to disambiguate\nqueries which are ambiguous between two intents, we propose a novel method of\ngenerating discriminative questions using a simple rule based system which can\ntake advantage of any question generation system without requiring annotated\ndata of clarification questions. Our approach aims at discrimination between\ntwo intents but can be easily extended to clarification over multiple intents.\nSeeking clarification from the user to classify user intents not only helps\nunderstand the user intent effectively, but also reduces the roboticity of the\nconversation and makes the interaction considerably natural.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:11:13 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dhole", "Kaustubh D.", ""]]}, {"id": "2008.07644", "submitter": "Peleg Harel", "authors": "Peleg Harel and Ohad Ben-Shahar", "title": "Lazy caterer jigsaw puzzles: Models, properties, and a mechanical\n  system-based solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jigsaw puzzle solving, the problem of constructing a coherent whole from a\nset of non-overlapping unordered fragments, is fundamental to numerous\napplications, and yet most of the literature has focused thus far on less\nrealistic puzzles whose pieces are identical squares. Here we formalize a new\ntype of jigsaw puzzle where the pieces are general convex polygons generated by\ncutting through a global polygonal shape with an arbitrary number of straight\ncuts, a generation model inspired by the celebrated Lazy caterer's sequence. We\nanalyze the theoretical properties of such puzzles, including the inherent\nchallenges in solving them once pieces are contaminated with geometrical noise.\nTo cope with such difficulties and obtain tractable solutions, we abstract the\nproblem as a multi-body spring-mass dynamical system endowed with hierarchical\nloop constraints and a layered reconstruction process. We define evaluation\nmetrics and present experimental results to indicate that such puzzles are\nsolvable completely automatically.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 22:07:40 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Harel", "Peleg", ""], ["Ben-Shahar", "Ohad", ""]]}, {"id": "2008.07667", "submitter": "Weichao Zhou", "authors": "Weichao Zhou, Ruihan Gao, BaekGyu Kim, Eunsuk Kang, Wenchao Li", "title": "Runtime-Safety-Guided Policy Repair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of policy repair for learning-based control policies in\nsafety-critical settings. We consider an architecture where a high-performance\nlearning-based control policy (e.g. one trained as a neural network) is paired\nwith a model-based safety controller. The safety controller is endowed with the\nabilities to predict whether the trained policy will lead the system to an\nunsafe state, and take over control when necessary. While this architecture can\nprovide added safety assurances, intermittent and frequent switching between\nthe trained policy and the safety controller can result in undesirable\nbehaviors and reduced performance. We propose to reduce or even eliminate\ncontrol switching by `repairing' the trained policy based on runtime data\nproduced by the safety controller in a way that deviates minimally from the\noriginal policy. The key idea behind our approach is the formulation of a\ntrajectory optimization problem that allows the joint reasoning of policy\nupdate and safety constraints. Experimental results demonstrate that our\napproach is effective even when the system model in the safety controller is\nunknown and only approximated.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 23:31:48 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhou", "Weichao", ""], ["Gao", "Ruihan", ""], ["Kim", "BaekGyu", ""], ["Kang", "Eunsuk", ""], ["Li", "Wenchao", ""]]}, {"id": "2008.07682", "submitter": "Todor Davchev", "authors": "Todor Davchev, Kevin Sebastian Luck, Michael Burke, Franziska Meier,\n  Stefan Schaal, Subramanian Ramamoorthy", "title": "Residual Learning from Demonstration: Adapting Dynamic Movement\n  Primitives for Contact-rich Insertion Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contacts and friction are inherent to nearly all robotic manipulation tasks.\nThrough the motor skill of insertion, we study how robots can learn to cope\nwhen these attributes play a salient role. In this work we study ways for\nadapting dynamic movement primitives (DMP) to improve their performance in the\ncontext of contact rich insertion. We propose a framework we refer to as\nresidual learning from demonstration (rLfD) that combines dynamic movement\nprimitives (DMP) that rely on behavioural cloning with a reinforcement learning\n(RL) based residual correction policy. Our evaluation suggests that applying\nresidual learning directly in task space and operating on the full pose of the\nrobot can significantly improve the overall performance of DMPs. We show that\nrLfD outperforms alternatives and improves the generalisation abilities of\nDMPs. We evaluate this approach by training an agent to successfully perform\nboth simulated and real world insertions of pegs, gears and plugs into\nrespective sockets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 00:33:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:24:59 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Davchev", "Todor", ""], ["Luck", "Kevin Sebastian", ""], ["Burke", "Michael", ""], ["Meier", "Franziska", ""], ["Schaal", "Stefan", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2008.07683", "submitter": "Karthik Gopalakrishnan", "authors": "Karthik Gopalakrishnan, Behnam Hedayatnia, Longshaokan Wang, Yang Liu,\n  Dilek Hakkani-Tur", "title": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition\n  Errors in the Dialog History? An Empirical Study", "comments": "Accepted at INTERSPEECH 2020. For dataset, see\n  https://github.com/alexa/Topical-Chat/tree/master/TopicalChatASR/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large end-to-end neural open-domain chatbots are becoming increasingly\npopular. However, research on building such chatbots has typically assumed that\nthe user input is written in nature and it is not clear whether these chatbots\nwould seamlessly integrate with automatic speech recognition (ASR) models to\nserve the speech modality. We aim to bring attention to this important question\nby empirically studying the effects of various types of synthetic and actual\nASR hypotheses in the dialog history on TransferTransfo, a state-of-the-art\nGenerative Pre-trained Transformer (GPT) based neural open-domain dialog system\nfrom the NeurIPS ConvAI2 challenge. We observe that TransferTransfo trained on\nwritten data is very sensitive to such hypotheses introduced to the dialog\nhistory during inference time. As a baseline mitigation strategy, we introduce\nsynthetic ASR hypotheses to the dialog history during training and observe\nmarginal improvements, demonstrating the need for further research into\ntechniques to make end-to-end open-domain chatbots fully speech-robust. To the\nbest of our knowledge, this is the first study to evaluate the effects of\nsynthetic and actual ASR hypotheses on a state-of-the-art neural open-domain\ndialog system and we hope it promotes speech-robustness as an evaluation\ncriterion in open-domain dialog.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 00:36:57 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gopalakrishnan", "Karthik", ""], ["Hedayatnia", "Behnam", ""], ["Wang", "Longshaokan", ""], ["Liu", "Yang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2008.07688", "submitter": "Vaibhav Kumar", "authors": "Vaibhav Kumar and Vikas Raunak and Jamie Callan", "title": "Ranking Clarification Questions via Natural Language Inference", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412137", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given a natural language query, teaching machines to ask clarifying questions\nis of immense utility in practical natural language processing systems. Such\ninteractions could help in filling information gaps for better machine\ncomprehension of the query. For the task of ranking clarification questions, we\nhypothesize that determining whether a clarification question pertains to a\nmissing entry in a given post (on QA forums such as StackExchange) could be\nconsidered as a special case of Natural Language Inference (NLI), where both\nthe post and the most relevant clarification question point to a shared latent\npiece of information or context. We validate this hypothesis by incorporating\nrepresentations from a Siamese BERT model fine-tuned on NLI and Multi-NLI\ndatasets into our models and demonstrate that our best performing model obtains\na relative performance improvement of 40 percent and 60 percent respectively\n(on the key metric of Precision@1), over the state-of-the-art baseline(s) on\nthe two evaluation sets of the StackExchange dataset, thereby, significantly\nsurpassing the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 01:32:29 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Raunak", "Vikas", ""], ["Callan", "Jamie", ""]]}, {"id": "2008.07709", "submitter": "Shusuke Kobayashi", "authors": "Shusuke Kobayashi, Susumu Shirayama", "title": "Selecting Data Adaptive Learner from Multiple Deep Learners using\n  Bayesian Networks", "comments": "14 pages, 12 tables and 4 figures, Submitted to Neural Computing and\n  Applications", "journal-ref": null, "doi": "10.1007/s00521-020-05234-6", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to predict time-series using multiple deep learners and a Bayesian\nnetwork is proposed. In this study, the input explanatory variables are\nBayesian network nodes that are associated with learners. Training data are\ndivided using K-means clustering, and multiple deep learners are trained\ndepending on the cluster. A Bayesian network is used to determine which deep\nlearner is in charge of predicting a time-series. We determine a threshold\nvalue and select learners with a posterior probability equal to or greater than\nthe threshold value, which could facilitate more robust prediction. The\nproposed method is applied to financial time-series data, and the predicted\nresults for the Nikkei 225 index are demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:48:43 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kobayashi", "Shusuke", ""], ["Shirayama", "Susumu", ""]]}, {"id": "2008.07734", "submitter": "Thomas P Quinn", "authors": "Thomas P. Quinn, Manisha Senadeera, Stephan Jacobs, Simon Coghlan, and\n  Vuong Le", "title": "Trust and Medical AI: The challenges we face and the expertise needed to\n  overcome them", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence (AI) is increasingly of tremendous interest in the\nmedical field. However, failures of medical AI could have serious consequences\nfor both clinical outcomes and the patient experience. These consequences could\nerode public trust in AI, which could in turn undermine trust in our healthcare\ninstitutions. This article makes two contributions. First, it describes the\nmajor conceptual, technical, and humanistic challenges in medical AI. Second,\nit proposes a solution that hinges on the education and accreditation of new\nexpert groups who specialize in the development, verification, and operation of\nmedical AI technologies. These groups will be required to maintain trust in our\nhealthcare institutions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:17:58 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Quinn", "Thomas P.", ""], ["Senadeera", "Manisha", ""], ["Jacobs", "Stephan", ""], ["Coghlan", "Simon", ""], ["Le", "Vuong", ""]]}, {"id": "2008.07743", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Turing Test and the Practice of Law: The Role of Autonomous Levels of AI\n  Legal Reasoning", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is increasingly being applied to law and a\nmyriad of legal tasks amid attempts to bolster AI Legal Reasoning (AILR)\nautonomous capabilities. A major question that has generally been unaddressed\ninvolves how we will know when AILR has achieved autonomous capacities. The\nfield of AI has grappled with similar quandaries over how to assess the\nattainment of Artificial General Intelligence (AGI), a persistently discussed\nissue among scholars since the inception of AI, with the Turing Test communally\nbeing considered as the bellwether for ascertaining such matters. This paper\nproposes a variant of the Turing Test that is customized for specific use in\nthe AILR realm, including depicting how this famous gold standard of AI\nfulfillment can be robustly applied across the autonomous levels of AI Legal\nReasoning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 04:50:23 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2008.07773", "submitter": "Muhammad Umer Siddique", "authors": "Umer Siddique, Paul Weng, Matthieu Zimmer", "title": "Learning Fair Policies in Multiobjective (Deep) Reinforcement Learning\n  with Average and Discounted Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the operations of autonomous systems generally affect simultaneously\nseveral users, it is crucial that their designs account for fairness\nconsiderations. In contrast to standard (deep) reinforcement learning (RL), we\ninvestigate the problem of learning a policy that treats its users equitably.\nIn this paper, we formulate this novel RL problem, in which an objective\nfunction, which encodes a notion of fairness that we formally define, is\noptimized. For this problem, we provide a theoretical discussion where we\nexamine the case of discounted rewards and that of average rewards. During this\nanalysis, we notably derive a new result in the standard RL setting, which is\nof independent interest: it states a novel bound on the approximation error\nwith respect to the optimal average reward of that of a policy optimal for the\ndiscounted reward. Since learning with discounted rewards is generally easier,\nthis discussion further justifies finding a fair policy for the average reward\nby learning a fair policy for the discounted reward. Thus, we describe how\nseveral classic deep RL algorithms can be adapted to our fair optimization\nproblem, and we validate our approach with extensive experiments in three\ndifferent domains.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:17:53 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Siddique", "Umer", ""], ["Weng", "Paul", ""], ["Zimmer", "Matthieu", ""]]}, {"id": "2008.07792", "submitter": "Chengshu Li", "authors": "Fei Xia, Chengshu Li, Roberto Mart\\'in-Mart\\'in, Or Litany, Alexander\n  Toshev, Silvio Savarese", "title": "ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for\n  Mobile Manipulation", "comments": "First two authors contributed equally. Access project website at\n  http://svl.stanford.edu/projects/relmogen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Reinforcement Learning (RL) approaches use joint control signals\n(positions, velocities, torques) as action space for continuous control tasks.\nWe propose to lift the action space to a higher level in the form of subgoals\nfor a motion generator (a combination of motion planner and trajectory\nexecutor). We argue that, by lifting the action space and by leveraging\nsampling-based motion planners, we can efficiently use RL to solve complex,\nlong-horizon tasks that could not be solved with existing RL methods in the\noriginal action space. We propose ReLMoGen -- a framework that combines a\nlearned policy to predict subgoals and a motion generator to plan and execute\nthe motion needed to reach these subgoals. To validate our method, we apply\nReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation\nproblems where interactions with the environment are required to reach the\ndestination, and 2) Mobile Manipulation tasks, manipulation tasks that require\nmoving the robot base. These problems are challenging because they are usually\nlong-horizon, hard to explore during training, and comprise alternating phases\nof navigation and interaction. Our method is benchmarked on a diverse set of\nseven robotics tasks in photo-realistic simulation environments. In all\nsettings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and\nHierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding\ntransferability between different motion generators at test time, indicating a\ngreat potential to transfer to real robots.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 08:05:15 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:44:22 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Xia", "Fei", ""], ["Li", "Chengshu", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""], ["Litany", "Or", ""], ["Toshev", "Alexander", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.07796", "submitter": "Xintao Ren", "authors": "Hao Guo, Xintao Ren, Rongrong Wang, Zhun Cai, Kai Shuang and Yue Sun", "title": "A Hierarchical User Intention-Habit Extract Network for Credit Loan\n  Overdue Risk Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More personal consumer loan products are emerging in mobile banking APP. For\nease of use, application process is always simple, which means that few\napplication information is requested for user to fill when applying for a loan,\nwhich is not conducive to construct users' credit profile. Thus, the simple\napplication process brings huge challenges to the overdue risk detection, as\nhigher overdue rate will result in greater economic losses to the bank. In this\npaper, we propose a model named HUIHEN (Hierarchical User Intention-Habit\nExtract Network) that leverages the users' behavior information in mobile\nbanking APP. Due to the diversity of users' behaviors, we divide behavior\nsequences into sessions according to the time interval, and use the field-aware\nmethod to extract the intra-field information of behaviors. Then, we propose a\nhierarchical network composed of time-aware GRU and user-item-aware GRU to\ncapture users' short-term intentions and users' long-term habits, which can be\nregarded as a supplement to user profile. The proposed model can improve the\naccuracy without increasing the complexity of the original online application\nprocess. Experimental results demonstrate the superiority of HUIHEN and show\nthat HUIHEN outperforms other state-of-art models on all datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 08:13:49 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Guo", "Hao", ""], ["Ren", "Xintao", ""], ["Wang", "Rongrong", ""], ["Cai", "Zhun", ""], ["Shuang", "Kai", ""], ["Sun", "Yue", ""]]}, {"id": "2008.07901", "submitter": "Yanhong Annie Liu", "authors": "David S. Warren and Yanhong A. Liu", "title": "LPOP: Challenges and Advances in Logic and Practice of Programming", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.10247 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the work presented at the first Logic and Practice of\nProgramming (LPOP) Workshop, which was held in Oxford, UK, on July 18, 2018, in\nconjunction with the Federated Logic Conference (FLoC) 2018. Its focus is\nchallenges and advances in logic and practice of programming. The workshop was\norganized around a challenge problem that specifies issues in role-based access\ncontrol (RBAC), with many participants proposing combined imperative and\ndeclarative solutions expressed in the languages of their choice.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 14:28:46 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Warren", "David S.", ""], ["Liu", "Yanhong A.", ""]]}, {"id": "2008.07912", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sebastijan Duman\\v{c}i\\'c", "title": "Inductive logic programming at 30: a new introduction", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive logic programming (ILP) is a form of machine learning. The goal of\nILP is to induce a hypothesis (a set of logical rules) that generalises given\ntraining examples. In contrast to most forms of machine learning, ILP can learn\nhuman-readable hypotheses from small amounts of data. As ILP approaches 30, we\nprovide a new introduction to the field. We introduce the necessary logical\nnotation and the main ILP learning settings. We describe the main building\nblocks of an ILP system. We compare several ILP systems on several dimensions.\nWe describe in detail four systems (Aleph, TILDE, ASPAL, and Metagol). We\ndocument some of the main application areas of ILP. Finally, we summarise the\ncurrent limitations and outline promising directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:09:25 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 12:52:09 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 16:35:41 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""]]}, {"id": "2008.07965", "submitter": "Agostinho A. F. J\\'unior", "authors": "Janderson Ferreira (1), Agostinho A. F. J\\'unior (1), Let\\'icia Castro\n  (1), Yves M. Galv\\~ao (1), Pablo Barros (2), Bruno J. T. Fernandes (1) ((1)\n  Universidade de Pernambuco - Escola Polit\\'ecnica de Pernambuco, (2)\n  Cognitive Architecture for Collaborative Technologies Unit - Istituto\n  Italiano di Tecnologia)", "title": "Analysis of Social Robotic Navigation approaches: CNN Encoder and\n  Incremental Learning as an alternative to Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with social tasks in robotic scenarios is difficult, as having humans\nin the learning loop is incompatible with most of the state-of-the-art machine\nlearning algorithms. This is the case when exploring Incremental learning\nmodels, in particular the ones involving reinforcement learning. In this work,\nwe discuss this problem and possible solutions by analysing a previous study on\nadaptive convolutional encoders for a social navigation task.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:54:24 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 15:11:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ferreira", "Janderson", ""], ["J\u00fanior", "Agostinho A. F.", ""], ["Castro", "Let\u00edcia", ""], ["Galv\u00e3o", "Yves M.", ""], ["Barros", "Pablo", ""], ["Fernandes", "Bruno J. T.", ""]]}, {"id": "2008.07971", "submitter": "Yunlong Song", "authors": "Florian Fuchs, Yunlong Song, Elia Kaufmann, Davide Scaramuzza, Peter\n  Duerr", "title": "Super-Human Performance in Gran Turismo Sport Using Deep Reinforcement\n  Learning", "comments": "Accepted for Publication at the IEEE Robotics and Automation Letters\n  (RA-L) 2021, and International Conference on Robots and Automation (ICRA)\n  2021", "journal-ref": "IEEE Robotics and Automation Letters (RAL) 2021", "doi": "10.1109/LRA.2021.3064284", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous car racing is a major challenge in robotics. It raises fundamental\nproblems for classical approaches such as planning minimum-time trajectories\nunder uncertain dynamics and controlling the car at the limits of its handling.\nBesides, the requirement of minimizing the lap time, which is a sparse\nobjective, and the difficulty of collecting training data from human experts\nhave also hindered researchers from directly applying learning-based approaches\nto solve the problem. In the present work, we propose a learning-based system\nfor autonomous car racing by leveraging a high-fidelity physical car\nsimulation, a course-progress proxy reward, and deep reinforcement learning. We\ndeploy our system in Gran Turismo Sport, a world-leading car simulator known\nfor its realistic physics simulation of different race cars and tracks, which\nis even used to recruit human race car drivers. Our trained policy achieves\nautonomous racing performance that goes beyond what had been achieved so far by\nthe built-in AI, and, at the same time, outperforms the fastest driver in a\ndataset of over 50,000 human players.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:06:44 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 16:03:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fuchs", "Florian", ""], ["Song", "Yunlong", ""], ["Kaufmann", "Elia", ""], ["Scaramuzza", "Davide", ""], ["Duerr", "Peter", ""]]}, {"id": "2008.07993", "submitter": "Sven Weinzierl", "authors": "Sven Weinzierl and Sandra Zilker and Jens Brunk and Kate Revoredo and\n  Martin Matzner and J\\\"org Becker", "title": "XNAP: Making LSTM-based Next Activity Predictions Explainable by Using\n  LRP", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66498-5_10", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring (PBPM) is a class of techniques\ndesigned to predict behaviour, such as next activities, in running traces. PBPM\ntechniques aim to improve process performance by providing predictions to\nprocess analysts, supporting them in their decision making. However, the PBPM\ntechniques` limited predictive quality was considered as the essential obstacle\nfor establishing such techniques in practice. With the use of deep neural\nnetworks (DNNs), the techniques` predictive quality could be improved for tasks\nlike the next activity prediction. While DNNs achieve a promising predictive\nquality, they still lack comprehensibility due to their hierarchical approach\nof learning representations. Nevertheless, process analysts need to comprehend\nthe cause of a prediction to identify intervention mechanisms that might affect\nthe decision making to secure process performance. In this paper, we propose\nXNAP, the first explainable, DNN-based PBPM technique for the next activity\nprediction. XNAP integrates a layer-wise relevance propagation method from the\nfield of explainable artificial intelligence to make predictions of a long\nshort-term memory DNN explainable by providing relevance values for activities.\nWe show the benefit of our approach through two real-life event logs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 15:40:07 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:40:56 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 19:03:05 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Weinzierl", "Sven", ""], ["Zilker", "Sandra", ""], ["Brunk", "Jens", ""], ["Revoredo", "Kate", ""], ["Matzner", "Martin", ""], ["Becker", "J\u00f6rg", ""]]}, {"id": "2008.08076", "submitter": "Jason  Weston", "authors": "Kurt Shuster, Jack Urbanek, Emily Dinan, Arthur Szlam, Jason Weston", "title": "Deploying Lifelong Open-Domain Dialogue Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of NLP research has focused on crowdsourced static datasets and the\nsupervised learning paradigm of training once and then evaluating test\nperformance. As argued in de Vries et al. (2020), crowdsourced data has the\nissues of lack of naturalness and relevance to real-world use cases, while the\nstatic dataset paradigm does not allow for a model to learn from its\nexperiences of using language (Silver et al., 2013). In contrast, one might\nhope for machine learning systems that become more useful as they interact with\npeople. In this work, we build and deploy a role-playing game, whereby human\nplayers converse with learning agents situated in an open-domain fantasy world.\nWe show that by training models on the conversations they have with humans in\nthe game the models progressively improve, as measured by automatic metrics and\nonline engagement scores. This learning is shown to be more efficient than\ncrowdsourced data when applied to conversations with real users, as well as\nbeing far cheaper to collect.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:57:26 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:03:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shuster", "Kurt", ""], ["Urbanek", "Jack", ""], ["Dinan", "Emily", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "2008.08114", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Pedro Szekely, and Daniel Schwabe", "title": "Commonsense Knowledge in Wikidata", "comments": "WikiData Workshop at ISWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikidata and Wikipedia have been proven useful for reason-ing in natural\nlanguage applications, like question answering or entitylinking. Yet, no\nexisting work has studied the potential of Wikidata for commonsense reasoning.\nThis paper investigates whether Wikidata con-tains commonsense knowledge which\nis complementary to existing commonsense sources. Starting from a definition of\ncommon sense, we devise three guiding principles, and apply them to generate a\ncommonsense subgraph of Wikidata (Wikidata-CS). Within our approach, we map the\nrelations of Wikidata to ConceptNet, which we also leverage to integrate\nWikidata-CS into an existing consolidated commonsense graph. Our experiments\nreveal that: 1) albeit Wikidata-CS represents a small portion of Wikidata, it\nis an indicator that Wikidata contains relevant commonsense knowledge, which\ncan be mapped to 15 ConceptNet relations; 2) the overlap between Wikidata-CS\nand other commonsense sources is low, motivating the value of knowledge\nintegration; 3) Wikidata-CS has been evolving over time at a slightly slower\nrate compared to the overall Wikidata, indicating a possible lack of focus on\ncommonsense knowledge. Based on these findings, we propose three recommended\nactions to improve the coverage and quality of Wikidata-CS further.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 18:23:06 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 23:04:31 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ilievski", "Filip", ""], ["Szekely", "Pedro", ""], ["Schwabe", "Daniel", ""]]}, {"id": "2008.08165", "submitter": "Bahareh Sarrafzadeh", "authors": "Bahareh Sarrafzadeh, Sujay Kumar Jauhar, Michael Gamon, Edward Lank,\n  and Ryen White", "title": "Characterizing Stage-Aware Writing Assistance in Collaborative Document\n  Authoring", "comments": "Accepted for publication at CSCW 2020", "journal-ref": "CSCW 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing is a complex non-linear process that begins with a mental model of\nintent, and progresses through an outline of ideas, to words on paper (and\ntheir subsequent refinement). Despite past research in understanding writing,\nWeb-scale consumer and enterprise collaborative digital writing environments\nare yet to greatly benefit from intelligent systems that understand the stages\nof document evolution, providing opportune assistance based on authors'\nsituated actions and context. In this paper, we present three studies that\nexplore temporal stages of document authoring. We first survey information\nworkers at a large technology company about their writing habits and\npreferences, concluding that writers do in fact conceptually progress through\nseveral distinct phases while authoring documents. We also explore,\nqualitatively, how writing stages are linked to document lifespan. We\nsupplement these qualitative findings with an analysis of the longitudinal user\ninteraction logs of a popular digital writing platform over several million\ndocuments. Finally, as a first step towards facilitating an intelligent digital\nwriting assistant, we conduct a preliminary investigation into the utility of\nuser interaction log data for predicting the temporal stage of a document. Our\nresults support the benefit of tools tailored to writing stages, identify\nprimary tasks associated with these stages, and show that it is possible to\npredict stages from anonymous interaction logs. Together, these results argue\nfor the benefit and feasibility of more tailored digital writing assistance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 21:48:04 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sarrafzadeh", "Bahareh", ""], ["Jauhar", "Sujay Kumar", ""], ["Gamon", "Michael", ""], ["Lank", "Edward", ""], ["White", "Ryen", ""]]}, {"id": "2008.08202", "submitter": "Yubo Kou", "authors": "Yubo Kou and Xinning Gui", "title": "Mediating Community-AI Interaction through Situated Explanation: The\n  Case of AI-Led Moderation", "comments": null, "journal-ref": "PACMHCI, Vol 4, No. CSCW2, Article 102 (October 2020). 27 pages", "doi": "10.1145/3415173", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has become prevalent in our everyday\ntechnologies and impacts both individuals and communities. The explainable AI\n(XAI) scholarship has explored the philosophical nature of explanation and\ntechnical explanations, which are usually driven by experts in lab settings and\ncan be challenging for laypersons to understand. In addition, existing XAI\nresearch tends to focus on the individual level. Little is known about how\npeople understand and explain AI-led decisions in the community context.\nDrawing from XAI and activity theory, a foundational HCI theory, we theorize\nhow explanation is situated in a community's shared values, norms, knowledge,\nand practices, and how situated explanation mediates community-AI interaction.\nWe then present a case study of AI-led moderation, where community members\ncollectively develop explanations of AI-led decisions, most of which are\nautomated punishments. Lastly, we discuss the implications of this framework at\nthe intersection of CSCW, HCI, and XAI.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 00:13:12 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Kou", "Yubo", ""], ["Gui", "Xinning", ""]]}, {"id": "2008.08236", "submitter": "Lu Cheng", "authors": "Lu Cheng, Ruocheng Guo, Huan Liu", "title": "Long-Term Effect Estimation with Surrogate Representation", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many scenarios where short- and long-term causal effects of an\nintervention are different. For example, low-quality ads may increase\nshort-term ad clicks but decrease the long-term revenue via reduced clicks.\nThis work, therefore, studies the problem of long-term effect where the outcome\nof primary interest, or primary outcome, takes months or even years to\naccumulate. The observational study of long-term effect presents unique\nchallenges. First, the confounding bias causes large estimation error and\nvariance, which can further accumulate towards the prediction of primary\noutcomes. Second, short-term outcomes are often directly used as the proxy of\nthe primary outcome, i.e., the surrogate. Nevertheless, this method entails the\nstrong surrogacy assumption that is often impractical. To tackle these\nchallenges, we propose to build connections between long-term causal inference\nand sequential models in machine learning. This enables us to learn surrogate\nrepresentations that account for the temporal unconfoundedness and circumvent\nthe stringent surrogacy assumption by conditioning on the inferred time-varying\nconfounders. Experimental results show that the proposed framework outperforms\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:16:18 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:52:05 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cheng", "Lu", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""]]}, {"id": "2008.08247", "submitter": "Kun Zhou", "authors": "Kun Zhou, Wayne Xin Zhao, Hui Wang, Sirui Wang, Fuzheng Zhang,\n  Zhongyuan Wang and Ji-Rong Wen", "title": "Leveraging Historical Interaction Data for Improving Conversational\n  Recommender System", "comments": "Accepted as CIKM short paper", "journal-ref": null, "doi": "10.1145/3340531.3412098", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, conversational recommender system (CRS) has become an emerging and\npractical research topic. Most of the existing CRS methods focus on learning\neffective preference representations for users from conversation data alone.\nWhile, we take a new perspective to leverage historical interaction data for\nimproving CRS. For this purpose, we propose a novel pre-training approach to\nintegrating both item-based preference sequence (from historical interaction\ndata) and attribute-based preference sequence (from conversation data) via\npre-training methods. We carefully design two pre-training tasks to enhance\ninformation fusion between item- and attribute-based preference. To improve the\nlearning performance, we further develop an effective negative sample generator\nwhich can produce high-quality negative samples. Experiment results on two\nreal-world datasets have demonstrated the effectiveness of our approach for\nimproving CRS.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:43:50 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhou", "Kun", ""], ["Zhao", "Wayne Xin", ""], ["Wang", "Hui", ""], ["Wang", "Sirui", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Zhongyuan", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2008.08264", "submitter": "Quoc-Viet Pham", "authors": "Quoc-Viet Pham and Nhan Thanh Nguyen and Thien Huynh-The and Long Bao\n  Le and Kyungchun Lee and Won-Joo Hwang", "title": "Intelligent Radio Signal Processing: A Survey", "comments": "Accepted for publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent signal processing for wireless communications is a vital task in\nmodern wireless systems, but it faces new challenges because of network\nheterogeneity, diverse service requirements, a massive number of connections,\nand various radio characteristics. Owing to recent advancements in big data and\ncomputing technologies, artificial intelligence (AI) has become a useful tool\nfor radio signal processing and has enabled the realization of intelligent\nradio signal processing. This survey covers four intelligent signal processing\ntopics for the wireless physical layer, including modulation classification,\nsignal detection, beamforming, and channel estimation. In particular, each\ntheme is presented in a dedicated section, starting with the most fundamental\nprinciples, followed by a review of up-to-date studies and a summary. To\nprovide the necessary background, we first present a brief overview of AI\ntechniques such as machine learning, deep learning, and federated learning.\nFinally, we highlight a number of research challenges and future directions in\nthe area of intelligent radio signal processing. We expect this survey to be a\ngood source of information for anyone interested in intelligent radio signal\nprocessing, and the perspectives we provide therein will stimulate many more\nnovel ideas and contributions in the future.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:06:31 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 12:15:29 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 00:48:27 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Pham", "Quoc-Viet", ""], ["Nguyen", "Nhan Thanh", ""], ["Huynh-The", "Thien", ""], ["Le", "Long Bao", ""], ["Lee", "Kyungchun", ""], ["Hwang", "Won-Joo", ""]]}, {"id": "2008.08300", "submitter": "Zhichao Xu", "authors": "Zhichao Xu, Shuhong Chen", "title": "Using Sampling Strategy to Assist Consensus Sequence Analysis", "comments": "under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus Sequences of event logs are often used in process mining to quickly\ngrasp the core sequence of events to be performed in a process, or to represent\nthe backbone of the process for doing other analyses. However, it is still not\nclear how many traces are enough to properly represent the underlying process.\nIn this paper, we propose a novel sampling strategy to determine the number of\ntraces necessary to produce a representative consensus sequence. We show how to\nestimate the difference between the predefined Expert Model and the real\nprocesses carried out. This difference level can be used as reference for\ndomain experts to adjust the Expert Model. In addition, we apply this strategy\nto several real-world workflow activity datasets as a case study. We show a\nsample curve fitting task to help readers better understand our proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 07:12:09 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 23:03:06 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Xu", "Zhichao", ""], ["Chen", "Shuhong", ""]]}, {"id": "2008.08316", "submitter": "Margarita Osadchy", "authors": "Ben Mussay, Daniel Feldman, Samson Zhou, Vladimir Braverman, Margarita\n  Osadchy", "title": "Data-Independent Structured Pruning of Neural Networks via Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is crucial for deployment of neural networks on devices\nwith limited computational and memory resources. Many different methods show\ncomparable accuracy of the compressed model and similar compression rates.\nHowever, the majority of the compression methods are based on heuristics and\noffer no worst-case guarantees on the trade-off between the compression rate\nand the approximation error for an arbitrarily new sample. We propose the first\nefficient structured pruning algorithm with a provable trade-off between its\ncompression rate and the approximation error for any future test sample. Our\nmethod is based on the coreset framework and it approximates the output of a\nlayer of neurons/filters by a coreset of neurons/filters in the previous layer\nand discards the rest. We apply this framework in a layer-by-layer fashion from\nthe bottom to the top. Unlike previous works, our coreset is data independent,\nmeaning that it provably guarantees the accuracy of the function for any input\n$x\\in \\mathbb{R}^d$, including an adversarial one.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:03:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mussay", "Ben", ""], ["Feldman", "Daniel", ""], ["Zhou", "Samson", ""], ["Braverman", "Vladimir", ""], ["Osadchy", "Margarita", ""]]}, {"id": "2008.08444", "submitter": "Scott Stoller", "authors": "Thang Bui and Scott D. Stoller", "title": "Learning Attribute-Based and Relationship-Based Access Control Policies\n  with Unknown Values", "comments": "arXiv admin note: text overlap with arXiv:1909.12095", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute-Based Access Control (ABAC) and Relationship-based access control\n(ReBAC) provide a high level of expressiveness and flexibility that promote\nsecurity and information sharing, by allowing policies to be expressed in terms\nof attributes of and chains of relationships between entities. Algorithms for\nlearning ABAC and ReBAC policies from legacy access control information have\nthe potential to significantly reduce the cost of migration to ABAC or ReBAC.\n  This paper presents the first algorithms for mining ABAC and ReBAC policies\nfrom access control lists (ACLs) and incomplete information about entities,\nwhere the values of some attributes of some entities are unknown. We show that\nthe core of this problem can be viewed as learning a concise three-valued logic\nformula from a set of labeled feature vectors containing unknowns, and we give\nthe first algorithm (to the best of our knowledge) for that problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:56:29 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 14:59:55 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 19:27:26 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 18:45:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bui", "Thang", ""], ["Stoller", "Scott D.", ""]]}, {"id": "2008.08446", "submitter": "Duncan Eddy", "authors": "Duncan Eddy and Mykel J. Kochenderfer", "title": "A Maximum Independent Set Method for Scheduling Earth Observing\n  Satellite Constellations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating Earth observing satellites requires efficient planning methods that\ncoordinate activities of multiple spacecraft. The satellite task planning\nproblem entails selecting actions that best satisfy mission objectives for\nautonomous execution. Task scheduling is often performed by human operators\nassisted by heuristic or rule-based planning tools. This approach does not\nefficiently scale to multiple assets as heuristics frequently fail to properly\ncoordinate actions of multiple vehicles over long horizons. Additionally, the\nproblem becomes more difficult to solve for large constellations as the\ncomplexity of the problem scales exponentially in the number of requested\nobservations and linearly in the number of spacecraft. It is expected that new\ncommercial optical and radar imaging constellations will require automated\nplanning methods to meet stated responsiveness and throughput objectives. This\npaper introduces a new approach for solving the satellite scheduling problem by\ngenerating an infeasibility-based graph representation of the problem and\nfinding a maximal independent set of vertices for the graph. The approach is\ntested on a scenarios of up to 10,000 requested imaging locations for the\nSkysat constellation of optical satellites as well as simulated constellations\nof up to 24 satellites. Performance is compared with contemporary\ngraph-traversal and mixed-integer linear programming approaches. Empirical\nresults demonstrate improvements in both the solution time along with the\nnumber of scheduled collections beyond baseline methods. For large problems,\nthe maximum independent set approach is able find a feasible schedule with 8%\nmore collections in 75% less time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 19:32:21 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Eddy", "Duncan", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2008.08501", "submitter": "Lorenzo Federici Mr.", "authors": "Alessandro Zavoli and Lorenzo Federici", "title": "Reinforcement Learning for Low-Thrust Trajectory Design of\n  Interplanetary Missions", "comments": "2020 AAS/AIAA Astrodynamics Specialist Virtual Lake Tahoe Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Reinforcement Learning for the robust\ndesign of low-thrust interplanetary trajectories in presence of severe\ndisturbances, modeled alternatively as Gaussian additive process noise,\nobservation noise, control actuation errors on thrust magnitude and direction,\nand possibly multiple missed thrust events. The optimal control problem is\nrecast as a time-discrete Markov Decision Process to comply with the standard\nformulation of reinforcement learning. An open-source implementation of the\nstate-of-the-art algorithm Proximal Policy Optimization is adopted to carry out\nthe training process of a deep neural network, used to map the spacecraft\n(observed) states to the optimal control policy. The resulting Guidance and\nControl Network provides both a robust nominal trajectory and the associated\nclosed-loop guidance law. Numerical results are presented for a typical\nEarth-Mars mission. First, in order to validate the proposed approach, the\nsolution found in a (deterministic) unperturbed scenario is compared with the\noptimal one provided by an indirect technique. Then, the robustness and\noptimality of the obtained closed-loop guidance laws is assessed by means of\nMonte Carlo campaigns performed in the considered uncertain scenarios. These\npreliminary results open up new horizons for the use of reinforcement learning\nin the robust design of interplanetary missions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 15:22:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zavoli", "Alessandro", ""], ["Federici", "Lorenzo", ""]]}, {"id": "2008.08524", "submitter": "Lilith Mattei", "authors": "Lilith Mattei, Alessandro Antonucci, Denis Deratani Mau\\'a, Alessandro\n  Facchini, Julissa Villanueva Llerena", "title": "Tractable Inference in Credal Sentential Decision Diagrams", "comments": "To appear in the International Journal of Approximate Reasoning (IJAR\n  Volume 125)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic sentential decision diagrams are logic circuits where the\ninputs of disjunctive gates are annotated by probability values. They allow for\na compact representation of joint probability mass functions defined over sets\nof Boolean variables, that are also consistent with the logical constraints\ndefined by the circuit. The probabilities in such a model are usually learned\nfrom a set of observations. This leads to overconfident and prior-dependent\ninferences when data are scarce, unreliable or conflicting. In this work, we\ndevelop the credal sentential decision diagrams, a generalisation of their\nprobabilistic counterpart that allows for replacing the local probabilities\nwith (so-called credal) sets of mass functions. These models induce a joint\ncredal set over the set of Boolean variables, that sharply assigns probability\nzero to states inconsistent with the logical constraints. Three inference\nalgorithms are derived for these models, these allow to compute: (i) the lower\nand upper probabilities of an observation for an arbitrary number of variables;\n(ii) the lower and upper conditional probabilities for the state of a single\nvariable given an observation; (iii) whether or not all the probabilistic\nsentential decision diagrams compatible with the credal specification have the\nsame most probable explanation of a given set of variables given an observation\nof the other variables. These inferences are tractable, as all the three\nalgorithms, based on bottom-up traversal with local linear programming tasks on\nthe disjunctive gates, can be solved in polynomial time with respect to the\ncircuit size. For a first empirical validation, we consider a simple\napplication based on noisy seven-segment display images. The credal models are\nobserved to properly distinguish between easy and hard-to-detect instances and\noutperform other generative models not able to cope with logical constraints.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:04:34 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Mattei", "Lilith", ""], ["Antonucci", "Alessandro", ""], ["Mau\u00e1", "Denis Deratani", ""], ["Facchini", "Alessandro", ""], ["Llerena", "Julissa Villanueva", ""]]}, {"id": "2008.08548", "submitter": "Shiqi Zhang", "authors": "Shiqi Zhang and Mohan Sridharan", "title": "A Survey of Knowledge-based Sequential Decision Making under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with declarative knowledge (RDK) and sequential decision-making\n(SDM) are two key research areas in artificial intelligence. RDK methods reason\nwith declarative domain knowledge, including commonsense knowledge, that is\neither provided a priori or acquired over time, while SDM methods\n(probabilistic planning and reinforcement learning) seek to compute action\npolicies that maximize the expected cumulative utility over a time horizon;\nboth classes of methods reason in the presence of uncertainty. Despite the rich\nliterature in these two areas, researchers have not fully explored their\ncomplementary strengths. In this paper, we survey algorithms that leverage RDK\nmethods while making sequential decisions under uncertainty. We discuss\nsignificant developments, open problems, and directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:48:03 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:54:38 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Shiqi", ""], ["Sridharan", "Mohan", ""]]}, {"id": "2008.08665", "submitter": "Hyunsung Lee", "authors": "Hyunsung Lee", "title": "Intelligent Replication Management for HDFS Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage systems for cloud computing merge a large number of commodity\ncomputers into a single large storage pool. It provides high-performance\nstorage over an unreliable, and dynamic network at a lower cost than purchasing\nand maintaining large mainframe. In this paper, we examine whether it is\nfeasible to apply Reinforcement Learning(RL) to system domain problems. Our\nexperiments show that the RL model is comparable, even outperform other\nheuristics for block management problem. However, our experiments are limited\nin terms of scalability and fidelity. Even though our formulation is not very\npractical,applying Reinforcement Learning to system domain could offer good\nalternatives to existing heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:53:13 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Lee", "Hyunsung", ""]]}, {"id": "2008.08693", "submitter": "Sven Weinzierl", "authors": "Sven Weinzierl and Sebastian Dunzer and Sandra Zilker and Martin\n  Matzner", "title": "Prescriptive Business Process Monitoring for Recommending Next Best\n  Actions", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58638-6_12", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring (PBPM) techniques predict future\nprocess behaviour based on historical event log data to improve operational\nbusiness processes. Concerning the next activity prediction, recent PBPM\ntechniques use state-of-the-art deep neural networks (DNNs) to learn predictive\nmodels for producing more accurate predictions in running process instances.\nEven though organisations measure process performance by key performance\nindicators (KPIs), the DNN`s learning procedure is not directly affected by\nthem. Therefore, the resulting next most likely activity predictions can be\nless beneficial in practice. Prescriptive business process monitoring (PrBPM)\napproaches assess predictions regarding their impact on the process performance\n(typically measured by KPIs) to prevent undesired process activities by raising\nalarms or recommending actions. However, none of these approaches recommends\nactual process activities as actions that are optimised according to a given\nKPI. We present a PrBPM technique that transforms the next most likely\nactivities into the next best actions regarding a given KPI. Thereby, our\ntechnique uses business process simulation to ensure the control-flow\nconformance of the recommended actions. Based on our evaluation with two\nreal-life event logs, we show that our technique`s next best actions can\noutperform next activity predictions regarding the optimisation of a KPI and\nthe distance from the actual process instances.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 22:33:54 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Weinzierl", "Sven", ""], ["Dunzer", "Sebastian", ""], ["Zilker", "Sandra", ""], ["Matzner", "Martin", ""]]}, {"id": "2008.08748", "submitter": "Vu Hoang Nguyen Phan", "authors": "Jeffrey M. Dudek, Vu H. N. Phan, Moshe Y. Vardi", "title": "DPMC: Weighted Model Counting by Dynamic Programming on Project-Join\n  Trees", "comments": "Full version of paper at CP 2020 (26th International Conference on\n  Principles and Practice of Constraint Programming)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unifying dynamic-programming framework to compute exact\nliteral-weighted model counts of formulas in conjunctive normal form. At the\ncenter of our framework are project-join trees, which specify efficient\nproject-join orders to apply additive projections (variable eliminations) and\njoins (clause multiplications). In this framework, model counting is performed\nin two phases. First, the planning phase constructs a project-join tree from a\nformula. Second, the execution phase computes the model count of the formula,\nemploying dynamic programming as guided by the project-join tree. We\nempirically evaluate various methods for the planning phase and compare\nconstraint-satisfaction heuristics with tree-decomposition tools. We also\ninvestigate the performance of different data structures for the execution\nphase and compare algebraic decision diagrams with tensors. We show that our\ndynamic-programming model-counting framework DPMC is competitive with the\nstate-of-the-art exact weighted model counters cachet, c2d, d4, and miniC2D.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 03:09:09 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dudek", "Jeffrey M.", ""], ["Phan", "Vu H. N.", ""], ["Vardi", "Moshe Y.", ""]]}, {"id": "2008.08808", "submitter": "Zhou Tianze", "authors": "Tianze Zhou, Fubiao Zhang, Pan Tang, Chenfei Wang", "title": "BGC: Multi-Agent Group Belief with Graph Clustering", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances have witnessed that value decomposed-based multi-agent\nreinforcement learning methods make an efficient performance in coordination\ntasks. Most current methods assume that agents can make communication to assist\ndecisions, which is impractical in some situations. In this paper, we propose a\nsemi-communication method to enable agents can exchange information without\ncommunication. Specifically, we introduce a group concept to help agents\nlearning a belief which is a type of consensus. With this consensus, adjacent\nagents tend to accomplish similar sub-tasks to achieve cooperation. We design a\nnovel agent structure named Belief in Graph Clustering(BGC), composed of an\nagent characteristic module, a belief module, and a fusion module. To represent\neach agent characteristic, we use an MLP-based characteristic module to\ngenerate agent unique features. Inspired by the neighborhood cognitive\nconsistency, we propose a group-based module to divide adjacent agents into a\nsmall group and minimize in-group agents' beliefs to accomplish similar\nsub-tasks. Finally, we use a hyper-network to merge these features and produce\nagent actions. To overcome the agent consistent problem brought by GAT, a split\nloss is introduced to distinguish different agents. Results reveal that the\nproposed method achieves a significant improvement in the SMAC benchmark.\nBecause of the group concept, our approach maintains excellent performance with\nan increase in the number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:07:20 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 02:34:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 06:46:08 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 09:21:33 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhou", "Tianze", ""], ["Zhang", "Fubiao", ""], ["Tang", "Pan", ""], ["Wang", "Chenfei", ""]]}, {"id": "2008.08812", "submitter": "Zheng Wu", "authors": "Liting Sun, Zheng Wu, Hengbo Ma, Masayoshi Tomizuka", "title": "Expressing Diverse Human Driving Behavior with Probabilistic Rewards and\n  Online Inference", "comments": "7 pages, 9 figures, 2020 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human-robot interaction (HRI) systems, such as autonomous vehicles,\nunderstanding and representing human behavior are important. Human behavior is\nnaturally rich and diverse. Cost/reward learning, as an efficient way to learn\nand represent human behavior, has been successfully applied in many domains.\nMost of traditional inverse reinforcement learning (IRL) algorithms, however,\ncannot adequately capture the diversity of human behavior since they assume\nthat all behavior in a given dataset is generated by a single cost function.In\nthis paper, we propose a probabilistic IRL framework that directly learns a\ndistribution of cost functions in continuous domain. Evaluations on both\nsynthetic data and real human driving data are conducted. Both the quantitative\nand subjective results show that our proposed framework can better express\ndiverse human driving behaviors, as well as extracting different driving styles\nthat match what human participants interpret in our user study.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:32:45 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 01:14:04 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Sun", "Liting", ""], ["Wu", "Zheng", ""], ["Ma", "Hengbo", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2008.08919", "submitter": "Wissam Maamar Kouadri", "authors": "Wissam Maamar Kouadri, Salima Benbernou, Mourad Ouziri, Themis\n  Palpanas, Iheb Ben Amor", "title": "SentiQ: A Probabilistic Logic Approach to Enhance Sentiment Analysis\n  Tool Quality", "comments": "In Proceedings of the 9th KDD Workshop on Issues of Sentiment\n  Discovery and Opinion Mining (WISDOM 20). San Diego, CA, USA, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The opinion expressed in various Web sites and social-media is an essential\ncontributor to the decision making process of several organizations. Existing\nsentiment analysis tools aim to extract the polarity (i.e., positive, negative,\nneutral) from these opinionated contents. Despite the advance of the research\nin the field, sentiment analysis tools give \\textit{inconsistent} polarities,\nwhich is harmful to business decisions. In this paper, we propose SentiQ, an\nunsupervised Markov logic Network-based approach that injects the semantic\ndimension in the tools through rules. It allows to detect and solve\ninconsistencies and then improves the overall accuracy of the tools.\nPreliminary experimental results demonstrate the usefulness of SentiQ.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 14:30:00 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Kouadri", "Wissam Maamar", ""], ["Benbernou", "Salima", ""], ["Ouziri", "Mourad", ""], ["Palpanas", "Themis", ""], ["Amor", "Iheb Ben", ""]]}, {"id": "2008.08932", "submitter": "Justin Terry", "authors": "Justin K. Terry, Benjamin Black, Ananth Hari", "title": "SuperSuit: Simple Microwrappers for Reinforcement Learning Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, wrappers are universally used to transform the\ninformation that passes between a model and an environment. Despite their\nubiquity, no library exists with reasonable implementations of all popular\npreprocessing methods. This leads to unnecessary bugs, code inefficiencies, and\nwasted developer time. Accordingly we introduce SuperSuit, a Python library\nthat includes all popular wrappers, and wrappers that can easily apply lambda\nfunctions to the observations/actions/reward. It's compatible with the standard\nGym environment specification, as well as the PettingZoo specification for\nmulti-agent environments. The library is available at\nhttps://github.com/PettingZoo-Team/SuperSuit,and can be installed via pip.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 00:30:06 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Terry", "Justin K.", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""]]}, {"id": "2008.08937", "submitter": "Christopher Frantz", "authors": "Christopher K. Frantz and Saba N. Siddiki", "title": "Institutional Grammar 2.0 Codebook", "comments": "120 pages, 16 figures, 14 tables", "journal-ref": null, "doi": "10.1111/padm.12719", "report-no": "IG-001", "categories": "cs.MA cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the concluding section of\nthe codebook.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:55 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 21:15:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 13:12:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Frantz", "Christopher K.", ""], ["Siddiki", "Saba N.", ""]]}, {"id": "2008.08957", "submitter": "Jinhe Shi", "authors": "Jinhe Shi, Xiangyu Gao, Chenyu Ha, Yage Wang, Guodong Gao, Yi Chen", "title": "Patient ADE Risk Prediction through Hierarchical Time-Aware Neural\n  Network Using Claim Codes", "comments": null, "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378336", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug events (ADEs) are a serious health problem that can be\nlife-threatening. While a lot of studies have been performed on detect\ncorrelation between a drug and an AE, limited studies have been conducted on\npersonalized ADE risk prediction. Among treatment alternatives, avoiding the\ndrug that has high likelihood of causing severe AE can help physicians to\nprovide safer treatment to patients. Existing work on personalized ADE risk\nprediction uses the information obtained in the current medical visit. However,\non the other hand, medical history reveals each patient's unique\ncharacteristics and comprehensive medical information. The goal of this study\nis to assess personalized ADE risks that a target drug may induce on a target\npatient, based on patient medical history recorded in claims codes, which\nprovide information about diagnosis, drugs taken, related medical supplies\nbesides billing information. We developed a HTNNR model (Hierarchical\nTime-aware Neural Network for ADE Risk) that capture characteristics of claim\ncodes and their relationship. The empirical evaluation show that the proposed\nHTNNR model substantially outperforms the comparison methods, especially for\nrare drugs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 13:24:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Shi", "Jinhe", ""], ["Gao", "Xiangyu", ""], ["Ha", "Chenyu", ""], ["Wang", "Yage", ""], ["Gao", "Guodong", ""], ["Chen", "Yi", ""]]}, {"id": "2008.09018", "submitter": "Lu Duan", "authors": "Lu Duan, Haoyuan Hu, Zili Wu, Guozheng Li, Xinhang Zhang, Yu Gong,\n  Yinghui Xu", "title": "Balanced Order Batching with Task-Oriented Graph Clustering", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3394486.3403355", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balanced order batching problem (BOBP) arises from the process of warehouse\npicking in Cainiao, the largest logistics platform in China. Batching orders\ntogether in the picking process to form a single picking route, reduces travel\ndistance. The reason for its importance is that order picking is a labor\nintensive process and, by using good batching methods, substantial savings can\nbe obtained. The BOBP is a NP-hard combinational optimization problem and\ndesigning a good problem-specific heuristic under the quasi-real-time system\nresponse requirement is non-trivial. In this paper, rather than designing\nheuristics, we propose an end-to-end learning and optimization framework named\nBalanced Task-orientated Graph Clustering Network (BTOGCN) to solve the BOBP by\nreducing it to balanced graph clustering optimization problem. In BTOGCN, a\ntask-oriented estimator network is introduced to guide the type-aware\nheterogeneous graph clustering networks to find a better clustering result\nrelated to the BOBP objective. Through comprehensive experiments on\nsingle-graph and multi-graphs, we show: 1) our balanced task-oriented graph\nclustering network can directly utilize the guidance of target signal and\noutperforms the two-stage deep embedding and deep clustering method; 2) our\nmethod obtains an average 4.57m and 0.13m picking distance (\"m\" is the\nabbreviation of the meter (the SI base unit of length)) reduction than the\nexpert-designed algorithm on single and multi-graph set and has a good\ngeneralization ability to apply in practical scenario.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 08:42:50 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Duan", "Lu", ""], ["Hu", "Haoyuan", ""], ["Wu", "Zili", ""], ["Li", "Guozheng", ""], ["Zhang", "Xinhang", ""], ["Gong", "Yu", ""], ["Xu", "Yinghui", ""]]}, {"id": "2008.09043", "submitter": "Joseph Bullock", "authors": "Alexandra Luccioni and Joseph Bullock and Katherine Hoffmann Pham and\n  Cynthia Sin Nga Lam and Miguel Luengo-Oroz", "title": "Considerations, Good Practices, Risks and Pitfalls in Developing AI\n  Solutions Against COVID-19", "comments": "4 pages, 1 figure", "journal-ref": "Harvard CRCS Workshop on AI for Social Good, United States, 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has been a major challenge to humanity, with 12.7\nmillion confirmed cases as of July 13th, 2020 [1]. In previous work, we\ndescribed how Artificial Intelligence can be used to tackle the pandemic with\napplications at the molecular, clinical, and societal scales [2]. In the\npresent follow-up article, we review these three research directions, and\nassess the level of maturity and feasibility of the approaches used, as well as\ntheir potential for operationalization. We also summarize some commonly\nencountered risks and practical pitfalls, as well as guidelines and best\npractices for formulating and deploying AI applications at different scales.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 12:37:37 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Bullock", "Joseph", ""], ["Pham", "Katherine Hoffmann", ""], ["Lam", "Cynthia Sin Nga", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2008.09067", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Adventures in Mathematical Reasoning", "comments": "To appear in \"DReaM On: 45 years of Automated Reasoning\", a\n  festschrift for Alan Bundy published by Springer-Verlag", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Mathematics is not a careful march down a well-cleared highway, but a\njourney into a strange wilderness, where the explorers often get lost. Rigour\nshould be a signal to the historian that the maps have been made, and the real\nexplorers have gone elsewhere.\" W.S. Anglin, the Mathematical Intelligencer, 4\n(4), 1982.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:41:18 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2008.09072", "submitter": "Muhammad Sabih", "authors": "Muhammad Sabih, Frank Hannig and Juergen Teich", "title": "Utilizing Explainable AI for Quantization and Pruning of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, utilizing DNNs (Deep Neural Networks) requires their\nimplementation on a target architecture in an optimized manner concerning\nenergy consumption, memory requirement, throughput, etc. DNN compression is\nused to reduce the memory footprint and complexity of a DNN before its\ndeployment on hardware. Recent efforts to understand and explain AI (Artificial\nIntelligence) methods have led to a new research area, termed as explainable\nAI. Explainable AI methods allow us to understand better the inner working of\nDNNs, such as the importance of different neurons and features. The concepts\nfrom explainable AI provide an opportunity to improve DNN compression methods\nsuch as quantization and pruning in several ways that have not been\nsufficiently explored so far. In this paper, we utilize explainable AI methods:\nmainly DeepLIFT method. We use these methods for (1) pruning of DNNs; this\nincludes structured and unstructured pruning of \\ac{CNN} filters pruning as\nwell as pruning weights of fully connected layers, (2) non-uniform quantization\nof DNN weights using clustering algorithm; this is also referred to as Weight\nSharing, and (3) integer-based mixed-precision quantization; this is where each\nlayer of a DNN may use a different number of integer bits. We use typical image\nclassification datasets with common deep learning image classification models\nfor evaluation. In all these three cases, we demonstrate significant\nimprovements as well as new insights and opportunities from the use of\nexplainable AI in DNN compression.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:52:58 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Sabih", "Muhammad", ""], ["Hannig", "Frank", ""], ["Teich", "Juergen", ""]]}, {"id": "2008.09075", "submitter": "Prakhar Gupta", "authors": "Prakhar Gupta, Jeffrey P. Bigham, Yulia Tsvetkov and Amy Pavel", "title": "Controlling Dialogue Generation with Semantic Exemplars", "comments": "Accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems pretrained with large language models generate locally\ncoherent responses, but lack the fine-grained control over responses necessary\nto achieve specific goals. A promising method to control response generation is\nexemplar-based generation, in which models edit exemplar responses that are\nretrieved from training data, or hand-written to strategically address\ndiscourse-level goals, to fit new dialogue contexts. But, current\nexemplar-based approaches often excessively copy words from the exemplar\nresponses, leading to incoherent replies. We present an Exemplar-based Dialogue\nGeneration model, EDGE, that uses the semantic frames present in exemplar\nresponses to guide generation. We show that controlling dialogue generation\nbased on the semantic frames of exemplars, rather than words in the exemplar\nitself, improves the coherence of generated responses, while preserving\nsemantic meaning and conversation goals present in exemplar responses.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:02:37 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 17:30:46 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Gupta", "Prakhar", ""], ["Bigham", "Jeffrey P.", ""], ["Tsvetkov", "Yulia", ""], ["Pavel", "Amy", ""]]}, {"id": "2008.09100", "submitter": "Mahsan Nourani", "authors": "Mahsan Nourani, Joanie T. King, Eric D. Ragan", "title": "The Role of Domain Expertise in User Trust and the Impact of First\n  Impressions with Intelligent Systems", "comments": "Accepted and to appear in the Proceedings of the AAAI Conference on\n  Human Computation and Crowdsourcing (HCOMP) 2020", "journal-ref": null, "doi": null, "report-no": "https://www.aaai.org/ojs/index.php/HCOMP/article/view/7469", "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific intelligent systems are meant to help system users in their\ndecision-making process. Many systems aim to simultaneously support different\nusers with varying levels of domain expertise, but prior domain knowledge can\naffect user trust and confidence in detecting system errors. While it is also\nknown that user trust can be influenced by first impressions with intelligent\nsystems, our research explores the relationship between ordering bias and\ndomain expertise when encountering errors in intelligent systems. In this\npaper, we present a controlled user study to explore the role of domain\nknowledge in establishing trust and susceptibility to the influence of first\nimpressions on user trust. Participants reviewed an explainable image\nclassifier with a constant accuracy and two different orders of observing\nsystem errors (observing errors in the beginning of usage vs. in the end). Our\nfindings indicate that encountering errors early-on can cause negative first\nimpressions for domain experts, negatively impacting their trust over the\ncourse of interactions. However, encountering correct outputs early helps more\nknowledgable users to dynamically adjust their trust based on their\nobservations of system performance. In contrast, novice users suffer from\nover-reliance due to their lack of proper knowledge to detect errors.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:41:02 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nourani", "Mahsan", ""], ["King", "Joanie T.", ""], ["Ragan", "Eric D.", ""]]}, {"id": "2008.09150", "submitter": "Iacer Calixto", "authors": "Houda Alberts, Teresa Huang, Yash Deshpande, Yibo Liu, Kyunghyun Cho,\n  Clara Vania, Iacer Calixto", "title": "VisualSem: a high-quality knowledge graph for vision and language", "comments": "11 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the next frontier in natural language understanding (NLU) and\ngeneration (NLG) will include models that can efficiently access external\nstructured knowledge repositories. In order to support the development of such\nmodels, we release the VisualSem knowledge graph (KG) which includes nodes with\nmultilingual glosses and multiple illustrative images and visually relevant\nrelations. We also release a neural multi-modal retrieval model that can use\nimages or sentences as inputs and retrieves entities in the KG. This\nmulti-modal retrieval model can be integrated into any (neural network) model\npipeline and we encourage the research community to use VisualSem for data\naugmentation and/or as a source of grounding, among other possible uses.\nVisualSem as well as the multi-modal retrieval model are publicly available and\ncan be downloaded in: https://github.com/iacercalixto/visualsem.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:20:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Alberts", "Houda", ""], ["Huang", "Teresa", ""], ["Deshpande", "Yash", ""], ["Liu", "Yibo", ""], ["Cho", "Kyunghyun", ""], ["Vania", "Clara", ""], ["Calixto", "Iacer", ""]]}, {"id": "2008.09154", "submitter": "Athanasios Vlontzos", "authors": "Athanasios Vlontzos, Henrique Bergallo Rocha, Daniel Rueckert,\n  Bernhard Kainz", "title": "Causal Future Prediction in a Minkowski Space-Time", "comments": "Includes supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating future events is a difficult task. Unlike humans, machine learning\napproaches are not regularized by a natural understanding of physics. In the\nwild, a plausible succession of events is governed by the rules of causality,\nwhich cannot easily be derived from a finite training set. In this paper we\npropose a novel theoretical framework to perform causal future prediction by\nembedding spatiotemporal information on a Minkowski space-time. We utilize the\nconcept of a light cone from special relativity to restrict and traverse the\nlatent space of an arbitrary model. We demonstrate successful applications in\ncausal image synthesis and future video frame prediction on a dataset of\nimages. Our framework is architecture- and task-independent and comes with\nstrong theoretical guarantees of causal capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:45:55 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 17:08:17 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Vlontzos", "Athanasios", ""], ["Rocha", "Henrique Bergallo", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2008.09209", "submitter": "Massimiliano Morrelli", "authors": "Massimiliano Morrelli", "title": "Addestramento con Dataset Sbilanciati", "comments": "in Italian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  English. The following document pursues the objective of comparing some\nuseful methods to balance a dataset and obtain a trained model. The dataset\nused for training is made up of short and medium length sentences, such as\nsimple phrases or extracts from conversations that took place on web channels.\nThe training of the models will take place with the help of the structures made\navailable by the Apache Spark framework, the models may subsequently be useful\nfor a possible implementation of a solution capable of classifying sentences\nusing the distributed environment, as described in \"New frontier of textual\nclassification: Big data and distributed calculation\" by Massimiliano Morrelli\net al.\n  Italiano. Il seguente documento persegue l'obiettivo di mettere a confronto\nalcuni metodi utili a bilanciare un dataset e ottenere un modello addestrato.\nIl dataset utilizzato per l'addestramento \\`e composto da frasi di lunghezza\nbreve e media, come frasi semplici o estratte da conversazioni avvenute su\ncanali web. L'addestramento dei modelli avverr\\`a con l'ausilio delle strutture\nmesse a disposizione dal framework Apache Spark, i modelli successivamente\npotranno essere utili a un eventuale implementazione di una soluzione in grado\ndi classificare frasi sfruttando l'ambiente distribuito, come descritto in\n\"Nuova frontiera della classificazione testuale: Big data e calcolo\ndistribuito\" di Massimiliano Morrelli et al.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:47:38 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Morrelli", "Massimiliano", ""]]}, {"id": "2008.09237", "submitter": "Zuohui Fu", "authors": "Zuohui Fu, Yikun Xian, Yaxin Zhu, Yongfeng Zhang, Gerard de Melo", "title": "COOKIE: A Dataset for Conversational Recommendation over Knowledge\n  Graphs in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new dataset for conversational recommendation over\nknowledge graphs in e-commerce platforms called COOKIE. The dataset is\nconstructed from an Amazon review corpus by integrating both user-agent\ndialogue and custom knowledge graphs for recommendation. Specifically, we first\nconstruct a unified knowledge graph and extract key entities between\nuser--product pairs, which serve as the skeleton of a conversation. Then we\nsimulate conversations mirroring the human coarse-to-fine process of choosing\npreferred items. The proposed baselines and experiments demonstrate that our\ndataset is able to provide innovative opportunities for conversational\nrecommendation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:11:31 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Fu", "Zuohui", ""], ["Xian", "Yikun", ""], ["Zhu", "Yaxin", ""], ["Zhang", "Yongfeng", ""], ["de Melo", "Gerard", ""]]}, {"id": "2008.09283", "submitter": "Param Vir Singh", "authors": "Qiaochu Wang, Yan Huang, Stefanus Jasin, Param Vir Singh", "title": "Algorithmic Transparency with Strategic Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Should firms that apply machine learning algorithms in their decision-making\nmake their algorithms transparent to the users they affect? Despite growing\ncalls for algorithmic transparency, most firms have kept their algorithms\nopaque, citing potential gaming by users that may negatively affect the\nalgorithm's predictive power. We develop an analytical model to compare firm\nand user surplus with and without algorithmic transparency in the presence of\nstrategic users and present novel insights. We identify a broad set of\nconditions under which making the algorithm transparent benefits the firm. We\nshow that, in some cases, even the predictive power of machine learning\nalgorithms may increase if the firm makes them transparent. By contrast, users\nmay not always be better off under algorithmic transparency. The results hold\neven when the predictive power of the opaque algorithm comes largely from\ncorrelational features and the cost for users to improve on them is close to\nzero. Overall, our results show that firms should not view manipulation by\nusers as bad. Rather, they should use algorithmic transparency as a lever to\nmotivate users to invest in more desirable features.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:10:42 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wang", "Qiaochu", ""], ["Huang", "Yan", ""], ["Jasin", "Stefanus", ""], ["Singh", "Param Vir", ""]]}, {"id": "2008.09293", "submitter": "Kishor Jothimurugan", "authors": "Kishor Jothimurugan, Rajeev Alur and Osbert Bastani", "title": "A Composable Specification Language for Reinforcement Learning Tasks", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems, pp.\n  13041-13051. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a promising approach for learning control policies\nfor robot tasks. However, specifying complex tasks (e.g., with multiple\nobjectives and safety constraints) can be challenging, since the user must\ndesign a reward function that encodes the entire task. Furthermore, the user\noften needs to manually shape the reward to ensure convergence of the learning\nalgorithm. We propose a language for specifying complex control tasks, along\nwith an algorithm that compiles specifications in our language into a reward\nfunction and automatically performs reward shaping. We implement our approach\nin a tool called SPECTRL, and show that it outperforms several state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:40:57 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:02:43 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Jothimurugan", "Kishor", ""], ["Alur", "Rajeev", ""], ["Bastani", "Osbert", ""]]}, {"id": "2008.09307", "submitter": "Jingzhou Liu Mr", "authors": "Ethan L. Childerhose, Jingzhou Liu", "title": "A Heuristic Approach to Two Level Boolean Minimization Derived from\n  Karnaugh Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following paper presents a heuristic method by which sum-of-product\nBoolean expressions can be simplified with a specific focus on the removal of\nredundant and selective prime implicants. Existing methods, such as the\nKarnaugh map and the Quine-McCluskey method [1, 2], fail to scale since they\nincrease exponentially in complexity as the quantity of literals increases,\ndoing as such to ensure the solution is algorithmically obtained. By employing\na heuristic model, nearly all expressions can be simplified at an overall\nreduction in computational complexity. This new method was derived from the\nfundamental Boolean laws, Karnaugh mapping, as well as truth tables.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:10:10 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 15:05:21 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 05:27:47 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Childerhose", "Ethan L.", ""], ["Liu", "Jingzhou", ""]]}, {"id": "2008.09369", "submitter": "Xu He", "authors": "Xu He, Bo An, Yanghua Li, Haikai Chen, Rundong Wang, Xinrun Wang,\n  Runsheng Yu, Xin Li, and Zhirong Wang", "title": "Learning to Collaborate in Multi-Module Recommendation via Multi-Agent\n  Reinforcement Learning without Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of online e-commerce platforms, more and more customers prefer\nto shop online. To sell more products, online platforms introduce various\nmodules to recommend items with different properties such as huge discounts. A\nweb page often consists of different independent modules. The ranking policies\nof these modules are decided by different teams and optimized individually\nwithout cooperation, which might result in competition between modules. Thus,\nthe global policy of the whole page could be sub-optimal. In this paper, we\npropose a novel multi-agent cooperative reinforcement learning approach with\nthe restriction that different modules cannot communicate. Our contributions\nare three-fold. Firstly, inspired by a solution concept in game theory named\ncorrelated equilibrium, we design a signal network to promote cooperation of\nall modules by generating signals (vectors) for different modules. Secondly, an\nentropy-regularized version of the signal network is proposed to coordinate\nagents' exploration of the optimal global policy. Furthermore, experiments\nbased on real-world e-commerce data demonstrate that our algorithm obtains\nsuperior performance over baselines.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:23:33 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 10:34:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["He", "Xu", ""], ["An", "Bo", ""], ["Li", "Yanghua", ""], ["Chen", "Haikai", ""], ["Wang", "Rundong", ""], ["Wang", "Xinrun", ""], ["Yu", "Runsheng", ""], ["Li", "Xin", ""], ["Wang", "Zhirong", ""]]}, {"id": "2008.09377", "submitter": "Binyamin Manela", "authors": "Binyamin Manela, Armin Biess", "title": "Curriculum Learning with Hindsight Experience Replay for Sequential\n  Object Manipulation Tasks", "comments": "arXiv admin note: text overlap with arXiv:2001.03877", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning complex tasks from scratch is challenging and often impossible for\nhumans as well as for artificial agents. A curriculum can be used instead,\nwhich decomposes a complex task (target task) into a sequence of source tasks\n(the curriculum). Each source task is a simplified version of the next source\ntask with increasing complexity. Learning then occurs gradually by training on\neach source task while using knowledge from the curriculum's prior source\ntasks. In this study, we present a new algorithm that combines curriculum\nlearning with Hindsight Experience Replay (HER), to learn sequential object\nmanipulation tasks for multiple goals and sparse feedback. The algorithm\nexploits the recurrent structure inherent in many object manipulation tasks and\nimplements the entire learning process in the original simulation without\nadjusting it to each source task. We have tested our algorithm on three\nchallenging throwing tasks and show vast improvements compared to vanilla-HER.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:59:28 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Manela", "Binyamin", ""], ["Biess", "Armin", ""]]}, {"id": "2008.09384", "submitter": "Florian Schaefer", "authors": "Florian Schaefer, Jan-Hendrik Menke, Martin Braun", "title": "Evaluating Machine Learning Models for the Fast Identification of\n  Contingency Cases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast approximations of power flow results are beneficial in power system\nplanning and live operation. In planning, millions of power flow calculations\nare necessary if multiple years, different control strategies or contingency\npolicies are to be considered. In live operation, grid operators must assess if\ngrid states comply with contingency requirements in a short time. In this\npaper, we compare regression and classification methods to either predict\nmulti-variable results, e.g. bus voltage magnitudes and line loadings, or\nbinary classifications of time steps to identify critical loading situations.\nWe test the methods on three realistic power systems based on time series in 15\nmin and 5 min resolution of one year. We compare different machine learning\nmodels, such as multilayer perceptrons (MLPs), decision trees, k-nearest\nneighbours, gradient boosting, and evaluate the required training time and\nprediction times as well as the prediction errors. We additionally determine\nthe amount of training data needed for each method and show results, including\nthe approximation of untrained curtailment of generation. Regarding the\ncompared methods, we identified the MLPs as most suitable for the task. The\nMLP-based models can predict critical situations with an accuracy of 97-98 %\nand a very low number of false negative predictions of 0.0-0.64 %.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:24:57 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Schaefer", "Florian", ""], ["Menke", "Jan-Hendrik", ""], ["Braun", "Martin", ""]]}, {"id": "2008.09507", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Authorized and Unauthorized Practices of Law: The Role of Autonomous\n  Levels of AI Legal Reasoning", "comments": "22 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2008.07743", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Artificial Intelligence (AI) and Machine Learning (ML) that are\nbeing applied to legal efforts have raised controversial questions about the\nexistent restrictions imposed on the practice-of-law. Generally, the legal\nfield has sought to define Authorized Practices of Law (APL) versus\nUnauthorized Practices of Law (UPL), though the boundaries are at times\namorphous and some contend capricious and self-serving, rather than being\ndevised holistically for the benefit of society all told. A missing ingredient\nin these arguments is the realization that impending legal profession\ndisruptions due to AI can be more robustly discerned by examining the matter\nthrough the lens of a framework utilizing the autonomous levels of AI Legal\nReasoning (AILR). This paper explores a newly derived instrumental grid\ndepicting the key characteristics underlying APL and UPL as they apply to the\nAILR autonomous levels and offers key insights for the furtherance of these\ncrucial practice-of-law debates.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:35:58 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2008.09510", "submitter": "Xingyu Zhao", "authors": "Xingyu Zhao, Kizito Salako, Lorenzo Strigini, Valentin Robu, David\n  Flynn", "title": "Assessing Safety-Critical Systems from Operational Testing: A Study on\n  Autonomous Vehicles", "comments": "Accepted by Information and Software Technology. arXiv admin note:\n  substantial text overlap with arXiv:1908.06540", "journal-ref": null, "doi": "10.1016/j.infsof.2020.106393", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Demonstrating high reliability and safety for safety-critical\nsystems (SCSs) remains a hard problem. Diverse evidence needs to be combined in\na rigorous way: in particular, results of operational testing with other\nevidence from design and verification. Growing use of machine learning in SCSs,\nby precluding most established methods for gaining assurance, makes operational\ntesting even more important for supporting safety and reliability claims.\nObjective: We use Autonomous Vehicles (AVs) as a current example to revisit the\nproblem of demonstrating high reliability. AVs are making their debut on public\nroads: methods for assessing whether an AV is safe enough are urgently needed.\nWe demonstrate how to answer 5 questions that would arise in assessing an AV\ntype, starting with those proposed by a highly-cited study. Method: We apply\nnew theorems extending Conservative Bayesian Inference (CBI), which exploit the\nrigour of Bayesian methods while reducing the risk of involuntary misuse\nassociated with now-common applications of Bayesian inference; we define\nadditional conditions needed for applying these methods to AVs. Results: Prior\nknowledge can bring substantial advantages if the AV design allows strong\nexpectations of safety before road testing. We also show how naive attempts at\nconservative assessment may lead to over-optimism instead; why extrapolating\nthe trend of disengagements is not suitable for safety claims; use of knowledge\nthat an AV has moved to a less stressful environment. Conclusion: While some\nreliability targets will remain too high to be practically verifiable, CBI\nremoves a major source of doubt: it allows use of prior knowledge without\ninducing dangerously optimistic biases. For certain ranges of required\nreliability and prior beliefs, CBI thus supports feasible, sound arguments.\nUseful conservative claims can be derived from limited prior knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:50:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhao", "Xingyu", ""], ["Salako", "Kizito", ""], ["Strigini", "Lorenzo", ""], ["Robu", "Valentin", ""], ["Flynn", "David", ""]]}, {"id": "2008.09514", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Weizhi Ma, Jiaxin Mao, Min Zhang, Yongfeng\n  Zhang", "title": "Neural Logic Reasoning", "comments": "Accepted to ACM CIKM 2020. arXiv admin note: substantial text overlap\n  with arXiv:1910.08629", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of cognitive reasoning. However, the concrete ability of\nreasoning is critical to many theoretical and practical problems. On the other\nhand, traditional symbolic reasoning methods do well in making logical\ninference, but they are mostly hard rule-based reasoning, which limits their\ngeneralization ability to different tasks since difference tasks may require\ndifferent rules. Both reasoning and generalization ability are important for\nprediction tasks such as recommender systems, where reasoning provides strong\nconnection between user history and target items for accurate prediction, and\ngeneralization helps the model to draw a robust user portrait over noisy\ninputs.\n  In this paper, we propose Logic-Integrated Neural Network (LINN) to integrate\nthe power of deep learning and logic reasoning. LINN is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations such as AND, OR, NOT as neural\nmodules, and conducts propositional logical reasoning through the network for\ninference. Experiments on theoretical task show that LINN achieves significant\nperformance on solving logical equations and variables. Furthermore, we test\nour approach on the practical task of recommendation by formulating the task\ninto a logical inference problem. Experiments show that LINN significantly\noutperforms state-of-the-art recommendation models in Top-K recommendation,\nwhich verifies the potential of LINN in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:53:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Ma", "Weizhi", ""], ["Mao", "Jiaxin", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2008.09535", "submitter": "Aaron Julian Gutknecht", "authors": "Aaron J. Gutknecht, Michael Wibral, Abdullah Makkeh", "title": "Bits and Pieces: Understanding Information Decomposition from Part-whole\n  Relationships and Formal Logic", "comments": "25 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT math.LO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial information decomposition (PID) seeks to decompose the multivariate\nmutual information that a set of source variables contains about a target\nvariable into basic pieces, the so called \"atoms of information\". Each atom\ndescribes a distinct way in which the sources may contain information about the\ntarget. In this paper we show, first, that the entire theory of partial\ninformation decomposition can be derived from considerations of elementary\nparthood relationships between information contributions. This way of\napproaching the problem has the advantage of directly characterizing the atoms\nof information, instead of taking an indirect approach via the concept of\nredundancy. Secondly, we describe several intriguing links between PID and\nformal logic. In particular, we show how to define a measure of PID based on\nthe information provided by certain statements about source realizations.\nFurthermore, we show how the mathematical lattice structure underlying PID\ntheory can be translated into an isomorphic structure of logical statements\nwith a particularly simple ordering relation: logical implication. The\nconclusion to be drawn from these considerations is that there are three\nisomorphic \"worlds\" of partial information decomposition, i.e. three equivalent\nways to mathematically describe the decomposition of the information carried by\na set of sources about a target: the world of parthood relationships, the world\nof logical statements, and the world of antichains that was utilized by\nWilliams and Beer in their original exposition of PID theory. We additionally\nshow how the parthood perspective provides a systematic way to answer a type of\nquestion that has been much discussed in the PID field: whether a partial\ninformation decomposition can be uniquely determined based on concepts other\nthan redundant information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:26:10 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Gutknecht", "Aaron J.", ""], ["Wibral", "Michael", ""], ["Makkeh", "Abdullah", ""]]}, {"id": "2008.09558", "submitter": "Artem Polyvyanyy", "authors": "Artem Polyvyanyy, Hanan Alkhammash, Claudio Di Ciccio, Luciano\n  Garc\\'ia-Ba\\~nuelos, Anna Kalenkova, Sander J. J. Leemans, Jan Mendling,\n  Alistair Moffat, Matthias Weidlich", "title": "Entropia: A Family of Entropy-Based Conformance Checking Measures for\n  Process Mining", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.FL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a command-line tool, called Entropia, that implements a\nfamily of conformance checking measures for process mining founded on the\nnotion of entropy from information theory. The measures allow quantifying\nclassical non-deterministic and stochastic precision and recall quality\ncriteria for process models automatically discovered from traces executed by\nIT-systems and recorded in their event logs. A process model has \"good\"\nprecision with respect to the log it was discovered from if it does not encode\nmany traces that are not part of the log, and has \"good\" recall if it encodes\nmost of the traces from the log. By definition, the measures possess useful\nproperties and can often be computed quickly.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:54:47 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 03:26:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Polyvyanyy", "Artem", ""], ["Alkhammash", "Hanan", ""], ["Di Ciccio", "Claudio", ""], ["Garc\u00eda-Ba\u00f1uelos", "Luciano", ""], ["Kalenkova", "Anna", ""], ["Leemans", "Sander J. J.", ""], ["Mendling", "Jan", ""], ["Moffat", "Alistair", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2008.09566", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth and Franz Pernkopf", "title": "Differentiable TAN Structure Learning for Bayesian Network Classifiers", "comments": "Accepted at PGM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Bayesian networks is a difficult combinatorial\noptimization problem. In this paper, we consider learning of tree-augmented\nnaive Bayes (TAN) structures for Bayesian network classifiers with discrete\ninput features. Instead of performing a combinatorial optimization over the\nspace of possible graph structures, the proposed method learns a distribution\nover graph structures. After training, we select the most probable structure of\nthis distribution. This allows for a joint training of the Bayesian network\nparameters along with its TAN structure using gradient-based optimization. The\nproposed method is agnostic to the specific loss and only requires that it is\ndifferentiable. We perform extensive experiments using a hybrid\ngenerative-discriminative loss based on the discriminative probabilistic\nmargin. Our method consistently outperforms random TAN structures and Chow-Liu\nTAN structures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 16:22:47 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Roth", "Wolfgang", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2008.09590", "submitter": "Majid Raeis", "authors": "Majid Raeis, Ali Tizghadam and Alberto Leon-Garcia", "title": "Reinforcement Learning-based Admission Control in Delay-sensitive\n  Service Systems", "comments": "7 pages, to be presented at IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring quality of service (QoS) guarantees in service systems is a\nchallenging task, particularly when the system is composed of more fine-grained\nservices, such as service function chains. An important QoS metric in service\nsystems is the end-to-end delay, which becomes even more important in\ndelay-sensitive applications, where the jobs must be completed within a time\ndeadline. Admission control is one way of providing end-to-end delay guarantee,\nwhere the controller accepts a job only if it has a high probability of meeting\nthe deadline. In this paper, we propose a reinforcement learning-based\nadmission controller that guarantees a probabilistic upper-bound on the\nend-to-end delay of the service system, while minimizes the probability of\nunnecessary rejections. Our controller only uses the queue length information\nof the network and requires no knowledge about the network topology or system\nparameters. Since long-term performance metrics are of great importance in\nservice systems, we take an average-reward reinforcement learning approach,\nwhich is well suited to infinite horizon problems. Our evaluations verify that\nthe proposed RL-based admission controller is capable of providing\nprobabilistic bounds on the end-to-end delay of the network, without using\nsystem model information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:33:55 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Raeis", "Majid", ""], ["Tizghadam", "Ali", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2008.09622", "submitter": "Changan Chen", "authors": "Changan Chen, Sagnik Majumder, Ziad Al-Halah, Ruohan Gao, Santhosh\n  Kumar Ramakrishnan, Kristen Grauman", "title": "Learning to Set Waypoints for Audio-Visual Navigation", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In audio-visual navigation, an agent intelligently travels through a complex,\nunmapped 3D environment using both sights and sounds to find a sound source\n(e.g., a phone ringing in another room). Existing models learn to act at a\nfixed granularity of agent motion and rely on simple recurrent aggregations of\nthe audio observations. We introduce a reinforcement learning approach to\naudio-visual navigation with two key novel elements: 1) waypoints that are\ndynamically set and learned end-to-end within the navigation policy, and 2) an\nacoustic memory that provides a structured, spatially grounded record of what\nthe agent has heard as it moves. Both new ideas capitalize on the synergy of\naudio and visual data for revealing the geometry of an unmapped space. We\ndemonstrate our approach on two challenging datasets of real-world 3D scenes,\nReplica and Matterport3D. Our model improves the state of the art by a\nsubstantial margin, and our experiments reveal that learning the links between\nsights, sounds, and space is essential for audio-visual navigation. Project:\nhttp://vision.cs.utexas.edu/projects/audio_visual_waypoints.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:00:33 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:47:31 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 18:36:45 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Chen", "Changan", ""], ["Majumder", "Sagnik", ""], ["Al-Halah", "Ziad", ""], ["Gao", "Ruohan", ""], ["Ramakrishnan", "Santhosh Kumar", ""], ["Grauman", "Kristen", ""]]}, {"id": "2008.09643", "submitter": "Rachel Luo", "authors": "Rachel Luo, Shengjia Zhao, Jiaming Song, Jonathan Kuck, Stefano Ermon,\n  Silvio Savarese", "title": "Privacy Preserving Recalibration under Domain Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers deployed in high-stakes real-world applications must output\ncalibrated confidence scores, i.e. their predicted probabilities should reflect\nempirical frequencies. Recalibration algorithms can greatly improve a model's\nprobability estimates; however, existing algorithms are not applicable in\nreal-world situations where the test data follows a different distribution from\nthe training data, and privacy preservation is paramount (e.g. protecting\npatient records). We introduce a framework that abstracts out the properties of\nrecalibration problems under differential privacy constraints. This framework\nallows us to adapt existing recalibration algorithms to satisfy differential\nprivacy while remaining effective for domain-shift situations. Guided by our\nframework, we also design a novel recalibration algorithm, accuracy temperature\nscaling, that outperforms prior work on private datasets. In an extensive\nempirical study, we find that our algorithm improves calibration on\ndomain-shift benchmarks under the constraints of differential privacy. On the\n15 highest severity perturbations of the ImageNet-C dataset, our method\nachieves a median ECE of 0.029, over 2x better than the next best recalibration\nmethod and almost 5x better than without recalibration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:43:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luo", "Rachel", ""], ["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Kuck", "Jonathan", ""], ["Ermon", "Stefano", ""], ["Savarese", "Silvio", ""]]}, {"id": "2008.09645", "submitter": "Sheng Liu", "authors": "Sheng Liu, Zuo-Jun Max Shen, Xiang Ji", "title": "Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and\n  a Real-World Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an urban bike lane planning problem based on the fine-grained bike\ntrajectory data, which is made available by smart city infrastructure such as\nbike-sharing systems. The key decision is where to build bike lanes in the\nexisting road network. As bike-sharing systems become widespread in the\nmetropolitan areas over the world, bike lanes are being planned and constructed\nby many municipal governments to promote cycling and protect cyclists.\nTraditional bike lane planning approaches often rely on surveys and heuristics.\nWe develop a general and novel optimization framework to guide the bike lane\nplanning from bike trajectories. We formalize the bike lane planning problem in\nview of the cyclists' utility functions and derive an integer optimization\nmodel to maximize the utility. To capture cyclists' route choices, we develop a\nbilevel program based on the Multinomial Logit model. We derive structural\nproperties about the base model and prove that the Lagrangian dual of the bike\nlane planning model is polynomial-time solvable. Furthermore, we reformulate\nthe route choice based planning model as a mixed integer linear program using a\nlinear approximation scheme. We develop tractable formulations and efficient\nalgorithms to solve the large-scale optimization problem. Via a real-world case\nstudy with a city government, we demonstrate the efficiency of the proposed\nalgorithms and quantify the trade-off between the coverage of bike trips and\ncontinuity of bike lanes. We show how the network topology evolves according to\nthe utility functions and highlight the importance of understanding cyclists'\nroute choices. The proposed framework drives the data-driven urban planning\nscheme in smart city operations management.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 18:46:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Sheng", ""], ["Shen", "Zuo-Jun Max", ""], ["Ji", "Xiang", ""]]}, {"id": "2008.09670", "submitter": "Anna Solovyova", "authors": "Anna Solovyova, Sergiy Danylov, Shpenkov Oleksii, Aleksandr Kravchenko", "title": "Early Autism Spectrum Disorders Diagnosis Using Eye-Tracking Technology", "comments": "11 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the number of children with diagnosed autism spectrum disorder (ASD)\ncontinues to rise from year to year, there is still no universal approach to\nautism diagnosis and treatment. A great variety of different tools and\napproaches for the on-site diagnostic are available right now, however, a big\npercent of parents have no access to them and they tend to search for the\navailable tools and correction programs on the Internet. Lack of money, absence\nof qualified specialists, and low level of trust to the correction methods are\nthe main issues that affect the in-time diagnoses of ASD and which need to be\nsolved to get the early treatment for the little patients. Understanding the\nimportance of this issue our team decided to investigate new methods of the\nonline autism diagnoses and develop the algorithm that will be able to predict\nthe chances of ASD according to the information from the gaze activity of the\nchild. The results that we got during the experiments show supported our idea\nthat eye-tracking technology is one of the most promising tools for the early\ndetection of the eye-movement features that can be markers of the ASD.\nMoreover, we have conducted a series of experiments to ensure that our approach\nhas a reliable result on the cheap webcam systems. Thus, this approach can be\nused as an additional first screening tool for the home monitoring of the early\nchild development and ASD connected disorders monitoring. The further\ndevelopment of eye-tracking based autism diagnosis has a big potential of usage\nand can be further implemented in the daily practice for practical specialists\nand parents.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:22:55 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Solovyova", "Anna", ""], ["Danylov", "Sergiy", ""], ["Oleksii", "Shpenkov", ""], ["Kravchenko", "Aleksandr", ""]]}, {"id": "2008.09676", "submitter": "Alexandra Savelieva", "authors": "Alexandra Savelieva, Bryan Au-Yeung, and Vasanth Ramani", "title": "Abstractive Summarization of Spoken and Written Instructions with BERT", "comments": "Accepted for KDD Converse 2020\n  (https://conversekdd20.github.io/accepted-papers.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarization of speech is a difficult problem due to the spontaneity of the\nflow, disfluencies, and other issues that are not usually encountered in\nwritten texts. Our work presents the first application of the BERTSum model to\nconversational language. We generate abstractive summaries of narrated\ninstructional videos across a wide variety of topics, from gardening and\ncooking to software configuration and sports. In order to enrich the\nvocabulary, we use transfer learning and pretrain the model on a few large\ncross-domain datasets in both written and spoken English. We also do\npreprocessing of transcripts to restore sentence segmentation and punctuation\nin the output of an ASR system. The results are evaluated with ROUGE and\nContent-F1 scoring for the How2 and WikiHow datasets. We engage human judges to\nscore a set of summaries randomly selected from a dataset curated from\nHowTo100M and YouTube. Based on blind evaluation, we achieve a level of textual\nfluency and utility close to that of summaries written by human content\ncreators. The model beats current SOTA when applied to WikiHow articles that\nvary widely in style and topic, while showing no performance regression on the\ncanonical CNN/DailyMail dataset. Due to the high generalizability of the model\nacross different styles and domains, it has great potential to improve\naccessibility and discoverability of internet content. We envision this\nintegrated as a feature in intelligent virtual assistants, enabling them to\nsummarize both written and spoken instructional content upon request.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:59:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 14:36:29 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 20:46:23 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Savelieva", "Alexandra", ""], ["Au-Yeung", "Bryan", ""], ["Ramani", "Vasanth", ""]]}, {"id": "2008.09680", "submitter": "Ryan Bernstein", "authors": "Ryan Bernstein, Matthijs V\\'ak\\'ar, Jeannette Wing", "title": "Transforming Probabilistic Programs for Model Checking", "comments": "To be published in Proceedings of the 2020 ACM-IMS Foundations of\n  Data Science Conference", "journal-ref": null, "doi": "10.1145/3412815.3416896", "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming is perfectly suited to reliable and transparent\ndata science, as it allows the user to specify their models in a high-level\nlanguage without worrying about the complexities of how to fit the models.\nStatic analysis of probabilistic programs presents even further opportunities\nfor enabling a high-level style of programming, by automating time-consuming\nand error-prone tasks. We apply static analysis to probabilistic programs to\nautomate large parts of two crucial model checking methods: Prior Predictive\nChecks and Simulation-Based Calibration. Our method transforms a probabilistic\nprogram specifying a density function into an efficient forward-sampling form.\nTo achieve this transformation, we extract a factor graph from a probabilistic\nprogram using static analysis, generate a set of proposal directed acyclic\ngraphs using a SAT solver, select a graph which will produce provably correct\nsampling code, then generate one or more sampling programs. We allow minimal\nuser interaction to broaden the scope of application beyond what is possible\nwith static analysis alone. We present an implementation targeting the popular\nStan probabilistic programming language, automating large parts of a robust\nBayesian workflow for a wide community of probabilistic programming users.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:06:34 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bernstein", "Ryan", ""], ["V\u00e1k\u00e1r", "Matthijs", ""], ["Wing", "Jeannette", ""]]}, {"id": "2008.09685", "submitter": "Rafael Pinto", "authors": "Rafael Pinto", "title": "Model-Free Episodic Control with State Aggregation", "comments": "8 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic control provides a highly sample-efficient method for reinforcement\nlearning while enforcing high memory and computational requirements. This work\nproposes a simple heuristic for reducing these requirements, and an application\nto Model-Free Episodic Control (MFEC) is presented. Experiments on Atari games\nshow that this heuristic successfully reduces MFEC computational demands while\nproducing no significant loss of performance when conservative choices of\nhyperparameters are used. Consequently, episodic control becomes a more\nfeasible option when dealing with reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:20:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pinto", "Rafael", ""]]}, {"id": "2008.09695", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, and Xia Hu", "title": "A Unified Taylor Framework for Revisiting Attribution Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been developed to understand the decision-making\nprocess of machine learning models, especially deep neural networks, by\nassigning importance scores to individual features. Existing attribution\nmethods often built upon empirical intuitions and heuristics. There still lacks\na general and theoretical framework that not only can unify these attribution\nmethods, but also theoretically reveal their rationales, fidelity, and\nlimitations. To bridge the gap, in this paper, we propose a Taylor attribution\nframework and reformulate seven mainstream attribution methods into the\nframework. Based on reformulations, we analyze the attribution methods in terms\nof rationale, fidelity, and limitation. Moreover, We establish three principles\nfor a good attribution in the Taylor attribution framework, i.e., low\napproximation error, correct contribution assignment, and unbiased baseline\nselection. Finally, we empirically validate the Taylor reformulations and\nreveal a positive correlation between the attribution performance and the\nnumber of principles followed by the attribution method via benchmarking on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:07:06 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 11:38:08 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 09:00:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Du", "Mengnan", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Hu", "Xia", ""]]}, {"id": "2008.09707", "submitter": "Hazem Torfah", "authors": "Sumukh Shivakumar, Hazem Torfah, Ankush Desai, Sanjit A. Seshia", "title": "SOTER on ROS: A Run-Time Assurance Framework on the Robot Operating\n  System", "comments": "20th International Conference on Runtime Verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of SOTER, a run-time assurance framework for\nbuilding safe distributed mobile robotic (DMR) systems, on top of the Robot\nOperating System (ROS). The safety of DMR systems cannot always be guaranteed\nat design time, especially when complex, off-the-shelf components are used that\ncannot be verified easily. SOTER addresses this by providing a language-based\napproach for run-time assurance for DMR systems. SOTER implements the reactive\nrobotic software using the language P, a domain-specific language designed for\nimplementing asynchronous event-driven systems, along with an integrated\nrun-time assurance system that allows programmers to use unfortified components\nbut still provide safety guarantees. We describe an implementation of SOTER for\nROS and demonstrate its efficacy using a multi-robot surveillance case study,\nwith multiple run-time assurance modules. Through rigorous simulation, we show\nthat SOTER enabled systems ensure safety, even when using unknown and untrusted\ncomponents.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:48:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Shivakumar", "Sumukh", ""], ["Torfah", "Hazem", ""], ["Desai", "Ankush", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2008.09721", "submitter": "Huan Ling", "authors": "Bowen Chen, Huan Ling, Xiaohui Zeng, Gao Jun, Ziyue Xu, Sanja Fidler", "title": "ScribbleBox: Interactive Annotation Framework for Video Object\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Manually labeling video datasets for segmentation tasks is extremely time\nconsuming. In this paper, we introduce ScribbleBox, a novel interactive\nframework for annotating object instances with masks in videos. In particular,\nwe split annotation into two steps: annotating objects with tracked boxes, and\nlabeling masks inside these tracks. We introduce automation and interaction in\nboth steps. Box tracks are annotated efficiently by approximating the\ntrajectory using a parametric curve with a small number of control points which\nthe annotator can interactively correct. Our approach tolerates a modest amount\nof noise in the box placements, thus typically only a few clicks are needed to\nannotate tracked boxes to a sufficient accuracy. Segmentation masks are\ncorrected via scribbles which are efficiently propagated through time. We show\nsignificant performance gains in annotation efficiency over past work. We show\nthat our ScribbleBox approach reaches 88.92% J&F on DAVIS2017 with 9.14 clicks\nper box track, and 4 frames of scribble annotation.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 00:33:10 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chen", "Bowen", ""], ["Ling", "Huan", ""], ["Zeng", "Xiaohui", ""], ["Jun", "Gao", ""], ["Xu", "Ziyue", ""], ["Fidler", "Sanja", ""]]}, {"id": "2008.09728", "submitter": "Sumit Mandal", "authors": "Sumit K. Mandal, Umit Y. Ogras, Janardhan Rao Doppa, Raid Z. Ayoub,\n  Michael Kishinevsky, Partha P. Pande", "title": "Online Adaptive Learning for Runtime Resource Management of\n  Heterogeneous SoCs", "comments": "This paper appeared in the Proceedings of Design Automation\n  Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic resource management has become one of the major areas of research in\nmodern computer and communication system design due to lower power consumption\nand higher performance demands. The number of integrated cores, level of\nheterogeneity and amount of control knobs increase steadily. As a result, the\nsystem complexity is increasing faster than our ability to optimize and\ndynamically manage the resources. Moreover, offline approaches are sub-optimal\ndue to workload variations and large volume of new applications unknown at\ndesign time. This paper first reviews recent online learning techniques for\npredicting system performance, power, and temperature. Then, we describe the\nuse of predictive models for online control using two modern approaches:\nimitation learning (IL) and an explicit nonlinear model predictive control\n(NMPC). Evaluations on a commercial mobile platform with 16 benchmarks show\nthat the IL approach successfully adapts the control policy to unknown\napplications. The explicit NMPC provides 25% energy savings compared to a\nstate-of-the-art algorithm for multi-variable power management of modern GPU\nsub-systems.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 01:39:32 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mandal", "Sumit K.", ""], ["Ogras", "Umit Y.", ""], ["Doppa", "Janardhan Rao", ""], ["Ayoub", "Raid Z.", ""], ["Kishinevsky", "Michael", ""], ["Pande", "Partha P.", ""]]}, {"id": "2008.09747", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad and Naimul Khan", "title": "Towards Improved Human Action Recognition Using Convolutional Neural\n  Networks and Multimodal Fusion of Depth and Inertial Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper attempts at improving the accuracy of Human Action Recognition\n(HAR) by fusion of depth and inertial sensor data. Firstly, we transform the\ndepth data into Sequential Front view Images(SFI) and fine-tune the pre-trained\nAlexNet on these images. Then, inertial data is converted into Signal Images\n(SI) and another convolutional neural network (CNN) is trained on these images.\nFinally, learned features are extracted from both CNN, fused together to make a\nshared feature layer, and these features are fed to the classifier. We\nexperiment with two classifiers, namely Support Vector Machines (SVM) and\nsoftmax classifier and compare their performances. The recognition accuracies\nof each modality, depth data alone and sensor data alone are also calculated\nand compared with fusion based accuracies to highlight the fact that fusion of\nmodalities yields better results than individual modalities. Experimental\nresults on UTD-MHAD and Kinect 2D datasets show that proposed method achieves\nstate of the art results when compared to other recently proposed\nvisual-inertial action recognition methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 03:41:34 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.09748", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad and Naimul Khan", "title": "Multidomain Multimodal Fusion For Human Action Recognition Using\n  Inertial Sensors", "comments": null, "journal-ref": null, "doi": "10.1109/BigMM.2019.00074", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the major reasons for misclassification of multiplex actions during\naction recognition is the unavailability of complementary features that provide\nthe semantic information about the actions. In different domains these features\nare present with different scales and intensities. In existing literature,\nfeatures are extracted independently in different domains, but the benefits\nfrom fusing these multidomain features are not realized. To address this\nchallenge and to extract complete set of complementary information, in this\npaper, we propose a novel multidomain multimodal fusion framework that extracts\ncomplementary and distinct features from different domains of the input\nmodality. We transform input inertial data into signal images, and then make\nthe input modality multidomain and multimodal by transforming spatial domain\ninformation into frequency and time-spectrum domain using Discrete Fourier\nTransform (DFT) and Gabor wavelet transform (GWT) respectively. Features in\ndifferent domains are extracted by Convolutional Neural networks (CNNs) and\nthen fused by Canonical Correlation based Fusion (CCF) for improving the\naccuracy of human action recognition. Experimental results on three inertial\ndatasets show the superiority of the proposed method when compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 03:46:12 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Khan", "Naimul", ""]]}, {"id": "2008.09858", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee,\n  Lovekesh Vig, Gautam Shroff", "title": "Hi-CI: Deep Causal Inference in High Dimensions", "comments": "23 pages, 5 figures, Accepted in Causal Discovery Workshop - KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of counterfactual regression using causal inference\n(CI) in observational studies consisting of high dimensional covariates and\nhigh cardinality treatments. Confounding bias, which leads to inaccurate\ntreatment effect estimation, is attributed to covariates that affect both\ntreatments and outcome. The presence of high-dimensional co-variates\nexacerbates the impact of bias as it is harder to isolate and measure the\nimpact of these confounders. In the presence of high-cardinality treatment\nvariables, CI is rendered ill-posed due to the increase in the number of\ncounterfactual outcomes to be predicted. We propose Hi-CI, a deep neural\nnetwork (DNN) based framework for estimating causal effects in the presence of\nlarge number of covariates, and high-cardinal and continuous treatment\nvariables. The proposed architecture comprises of a decorrelation network and\nan outcome prediction network. In the decorrelation network, we learn a data\nrepresentation in lower dimensions as compared to the original covariates and\naddresses confounding bias alongside. Subsequently, in the outcome prediction\nnetwork, we learn an embedding of high-cardinality and continuous treatments,\njointly with the data representation. We demonstrate the efficacy of causal\neffect prediction of the proposed Hi-CI network using synthetic and real-world\nNEWS datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:41:59 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 10:52:23 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 11:56:02 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Sharma", "Ankit", ""], ["Gupta", "Garima", ""], ["Prasad", "Ranjitha", ""], ["Chatterjee", "Arnab", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "2008.09879", "submitter": "Vasilis Margonis", "authors": "Vasilis Margonis, Athanasios Davvetas, Iraklis A. Klampanos", "title": "WeLa-VAE: Learning Alternative Disentangled Representations Using Weak\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning disentangled representations without supervision or inductive\nbiases, often leads to non-interpretable or undesirable representations. On the\nother hand, strict supervision requires detailed knowledge of the true\ngenerative factors, which is not always possible. In this paper, we consider\nweak supervision by means of high-level labels that are not assumed to be\nexplicitly related to the ground truth factors. Such labels, while being easier\nto acquire, can also be used as inductive biases for algorithms to learn more\ninterpretable or alternative disentangled representations. To this end, we\npropose WeLa-VAE, a variational inference framework where observations and\nlabels share the same latent variables, which involves the maximization of a\nmodified variational lower bound and total correlation regularization. Our\nmethod is a generalization of TCVAE, adding only one extra hyperparameter. We\nexperiment on a dataset generated by Cartesian coordinates and we show that,\nwhile a TCVAE learns a factorized Cartesian representation, given weak labels\nof distance and angle, WeLa-VAE is able to learn and disentangle a polar\nrepresentation. This is achieved without the need of refined labels or having\nto adjust the number of layers, the optimization parameters, or the total\ncorrelation hyperparameter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 17:13:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Margonis", "Vasilis", ""], ["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "2008.09912", "submitter": "Dongjie Wang", "authors": "Dongjie Wang, Yanjie Fu, Pengyang Wang, Bo Huang, Chang-Tien Lu", "title": "Reimagining City Configuration: Automated Urban Planning via Adversarial\n  Learning", "comments": "Proceedings of the 28th International Conference on Advances in\n  Geographic Information Systems (2020)", "journal-ref": "SIGSPATIAL/GIS 2020: 497-506", "doi": "10.1145/3397536.3422268", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban planning refers to the efforts of designing land-use configurations.\nEffective urban planning can help to mitigate the operational and social\nvulnerability of a urban system, such as high tax, crimes, traffic congestion\nand accidents, pollution, depression, and anxiety. Due to the high complexity\nof urban systems, such tasks are mostly completed by professional planners.\nBut, human planners take longer time. The recent advance of deep learning\nmotivates us to ask: can machines learn at a human capability to automatically\nand quickly calculate land-use configuration, so human planners can finally\nadjust machine-generated plans for specific needs? To this end, we formulate\nthe automated urban planning problem into a task of learning to configure\nland-uses, given the surrounding spatial contexts. To set up the task, we\ndefine a land-use configuration as a longitude-latitude-channel tensor, where\neach channel is a category of POIs and the value of an entry is the number of\nPOIs. The objective is then to propose an adversarial learning framework that\ncan automatically generate such tensor for an unplanned area. In particular, we\nfirst characterize the contexts of surrounding areas of an unplanned area by\nlearning representations from spatial graphs using geographic and human\nmobility data. Second, we combine each unplanned area and its surrounding\ncontext representation as a tuple, and categorize all the tuples into positive\n(well-planned areas) and negative samples (poorly-planned areas). Third, we\ndevelop an adversarial land-use configuration approach, where the surrounding\ncontext representation is fed into a generator to generate a land-use\nconfiguration, and a discriminator learns to distinguish among positive and\nnegative samples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 21:15:39 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 16:52:19 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Wang", "Dongjie", ""], ["Fu", "Yanjie", ""], ["Wang", "Pengyang", ""], ["Huang", "Bo", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2008.09926", "submitter": "Anuraganand Sharma Dr", "authors": "Anuraganand Sharma", "title": "Optimistic variants of single-objective bilevel optimization for\n  evolutionary algorithms", "comments": "preprint: 15 pages, published: 20 pages", "journal-ref": "IJCIA, 2020, pp. 2050020-1 to 2050020-20", "doi": "10.1142/S1469026820500200", "report-no": "Vol. 19", "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-objective bilevel optimization is a specialized form of constraint\noptimization problems where one of the constraints is an optimization problem\nitself. These problems are typically non-convex and strongly NP-Hard. Recently,\nthere has been an increased interest from the evolutionary computation\ncommunity to model bilevel problems due to its applicability in the real-world\napplications for decision-making problems. In this work, a partial nested\nevolutionary approach with a local heuristic search has been proposed to solve\nthe benchmark problems and have outstanding results. This approach relies on\nthe concept of intermarriage-crossover in search of feasible regions by\nexploiting information from the constraints. A new variant has also been\nproposed to the commonly used convergence approaches, i.e., optimistic and\npessimistic. It is called extreme optimistic approach. The experimental results\ndemonstrate the algorithm converges differently to known optimum solutions with\nthe optimistic variants. Optimistic approach also outperforms pessimistic\napproach. Comparative statistical analysis of our approach with other recently\npublished partial to complete evolutionary approaches demonstrates very\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 23:12:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sharma", "Anuraganand", ""]]}, {"id": "2008.09942", "submitter": "Guizhong Liu", "authors": "Jianyi Li and Guizhong Liu", "title": "Few-Shot Image Classification via Contrastive Self-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous few-shot learning algorithms are based on meta-training with\nfake few-shot tasks as training samples, where large labeled base classes are\nrequired. The trained model is also limited by the type of tasks. In this paper\nwe propose a new paradigm of unsupervised few-shot learning to repair the\ndeficiencies. We solve the few-shot tasks in two phases: meta-training a\ntransferable feature extractor via contrastive self-supervised learning and\ntraining a classifier using graph aggregation, self-distillation and manifold\naugmentation. Once meta-trained, the model can be used in any type of tasks\nwith a task-dependent classifier training. Our method achieves state of-the-art\nperformance in a variety of established few-shot tasks on the standard few-shot\nvisual classification datasets, with an 8- 28% increase compared to the\navailable unsupervised few-shot learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 02:24:31 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Jianyi", ""], ["Liu", "Guizhong", ""]]}, {"id": "2008.09943", "submitter": "Chen Yiwei", "authors": "Yiwei Chen, Yu Pan, Daoyi Dong", "title": "Quantum Language Model with Entanglement Embedding for Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Language Models (QLMs) in which words are modelled as quantum\nsuperposition of sememes have demonstrated a high level of model transparency\nand good post-hoc interpretability. Nevertheless, in the current literature\nword sequences are basically modelled as a classical mixture of word states,\nwhich cannot fully exploit the potential of a quantum probabilistic\ndescription. A full quantum model is yet to be developed to explicitly capture\nthe non-classical correlations within the word sequences. We propose a neural\nnetwork model with a novel Entanglement Embedding (EE) module, whose function\nis to transform the word sequences into entangled pure states of many-body\nquantum systems. Strong quantum entanglement, which is the central concept of\nquantum information and an indication of parallelized correlations among the\nwords, is observed within the word sequences. Numerical experiments show that\nthe proposed QLM with EE (QLM-EE) achieves superior performance compared with\nthe classical deep neural network models and other QLMs on Question Answering\n(QA) datasets. In addition, the post-hoc interpretability of the model can be\nimproved by quantizing the degree of entanglement among the words.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 02:34:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chen", "Yiwei", ""], ["Pan", "Yu", ""], ["Dong", "Daoyi", ""]]}, {"id": "2008.09958", "submitter": "Kaiyu Yue", "authors": "Kaiyu Yue, Jiangfan Deng, Feng Zhou", "title": "Matching Guided Distillation", "comments": "ECCV 2020 Camera-Ready. Project: http://kaiyuyue.com/mgd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature distillation is an effective way to improve the performance for a\nsmaller student model, which has fewer parameters and lower computation cost\ncompared to the larger teacher model. Unfortunately, there is a common obstacle\n- the gap in semantic feature structure between the intermediate features of\nteacher and student. The classic scheme prefers to transform intermediate\nfeatures by adding the adaptation module, such as naive convolutional,\nattention-based or more complicated one. However, this introduces two problems:\na) The adaptation module brings more parameters into training. b) The\nadaptation module with random initialization or special transformation isn't\nfriendly for distilling a pre-trained student. In this paper, we present\nMatching Guided Distillation (MGD) as an efficient and parameter-free manner to\nsolve these problems. The key idea of MGD is to pose matching the teacher\nchannels with students' as an assignment problem. We compare three solutions of\nthe assignment problem to reduce channels from teacher features with partial\ndistillation loss. The overall training takes a coordinate-descent approach\nbetween two optimization objects - assignments update and parameters update.\nSince MGD only contains normalization or pooling operations with negligible\ncomputation cost, it is flexible to plug into network with other distillation\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 04:57:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 02:58:25 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yue", "Kaiyu", ""], ["Deng", "Jiangfan", ""], ["Zhou", "Feng", ""]]}, {"id": "2008.09982", "submitter": "Liangwei Li", "authors": "Liangwei Li, Liucheng Sun, Chenwei Weng, Chengfu Huo, Weijun Ren", "title": "Spending Money Wisely: Online Electronic Coupon Allocation based on\n  Real-Time User Intent Detection", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412745", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online electronic coupon (e-coupon) is becoming a primary tool for e-commerce\nplatforms to attract users to place orders. E-coupons are the digital\nequivalent of traditional paper coupons which provide customers with discounts\nor gifts. One of the fundamental problems related is how to deliver e-coupons\nwith minimal cost while users' willingness to place an order is maximized. We\ncall this problem the coupon allocation problem. This is a non-trivial problem\nsince the number of regular users on a mature e-platform often reaches hundreds\nof millions and the types of e-coupons to be allocated are often multiple. The\npolicy space is extremely large and the online allocation has to satisfy a\nbudget constraint. Besides, one can never observe the responses of one user\nunder different policies which increases the uncertainty of the policy making\nprocess. Previous work fails to deal with these challenges. In this paper, we\ndecompose the coupon allocation task into two subtasks: the user intent\ndetection task and the allocation task. Accordingly, we propose a two-stage\nsolution: at the first stage (detection stage), we put forward a novel\nInstantaneous Intent Detection Network (IIDN) which takes the user-coupon\nfeatures as input and predicts user real-time intents; at the second stage\n(allocation stage), we model the allocation problem as a Multiple-Choice\nKnapsack Problem (MCKP) and provide a computational efficient allocation method\nusing the intents predicted at the detection stage. We conduct extensive online\nand offline experiments and the results show the superiority of our proposed\nframework, which has brought great profits to the platform and continues to\nfunction online.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 07:19:25 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Liangwei", ""], ["Sun", "Liucheng", ""], ["Weng", "Chenwei", ""], ["Huo", "Chengfu", ""], ["Ren", "Weijun", ""]]}, {"id": "2008.10054", "submitter": "Behzad Khamidehi", "authors": "Behzad Khamidehi and Elvino S. Sousa", "title": "Federated Learning for Cellular-connected UAVs: Radio Mapping and Path\n  Planning", "comments": "to appear in IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prolong the lifetime of the unmanned aerial vehicles (UAVs), the UAVs need\nto fulfill their missions in the shortest possible time. In addition to this\nrequirement, in many applications, the UAVs require a reliable internet\nconnection during their flights. In this paper, we minimize the travel time of\nthe UAVs, ensuring that a probabilistic connectivity constraint is satisfied.\nTo solve this problem, we need a global model of the outage probability in the\nenvironment. Since the UAVs have different missions and fly over different\nareas, their collected data carry local information on the network's\nconnectivity. As a result, the UAVs can not rely on their own experiences to\nbuild the global model. This issue affects the path planning of the UAVs. To\naddress this concern, we utilize a two-step approach. In the first step, by\nusing Federated Learning (FL), the UAVs collaboratively build a global model of\nthe outage probability in the environment. In the second step, by using the\nglobal model obtained in the first step and rapidly-exploring random trees\n(RRTs), we propose an algorithm to optimize UAVs' paths. Simulation results\nshow the effectiveness of this two-step approach for UAV networks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 14:55:37 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khamidehi", "Behzad", ""], ["Sousa", "Elvino S.", ""]]}, {"id": "2008.10066", "submitter": "Harshit Sikchi", "authors": "Harshit Sikchi, Wenxuan Zhou, David Held", "title": "Learning Off-Policy with Online Planning", "comments": "In submission. Previously presented in ICML BIG workshop, July 18\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in low-data and risk-sensitive domains requires\nperformant and flexible deployment policies that can readily incorporate\nconstraints during deployment. One such class of policies are the\nsemi-parametric H-step lookahead policies, which select actions using\ntrajectory optimization over a dynamics model for a fixed horizon with a\nterminal value function. In this work, we investigate a novel instantiation of\nH-step lookahead with a learned model and a terminal value function learned by\na model-free off-policy algorithm, named Learning Off-Policy with Online\nPlanning (LOOP). We provide a theoretical analysis of this method, suggesting a\ntradeoff between model errors and value function errors and empirically\ndemonstrate this tradeoff to be beneficial in deep reinforcement learning.\nFurthermore, we identify the \"Actor Divergence\" issue in this framework and\npropose Actor Regularized Control (ARC), a modified trajectory optimization\nprocedure. We evaluate our method on a set of robotic tasks for Offline and\nOnline RL and demonstrate improved performance. We also show the flexibility of\nLOOP to incorporate safety constraints during deployment with a set of\nnavigation environments. We demonstrate that LOOP is a desirable framework for\nrobotics applications based on its strong performance in various important RL\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 16:18:44 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 19:11:59 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 17:37:00 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sikchi", "Harshit", ""], ["Zhou", "Wenxuan", ""], ["Held", "David", ""]]}, {"id": "2008.10073", "submitter": "Chayan Sarkar", "authors": "Pradip Pramanick, Chayan Sarkar, Balamuralidhar P, Ajay Kattepur,\n  Indrajit Bhattacharya, Arpan Pal", "title": "Enabling human-like task identification from natural conversation", "comments": null, "journal-ref": "Published in: 2019 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "doi": "10.1109/IROS40897.2019.8968120", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot as a coworker or a cohabitant is becoming mainstream day-by-day with\nthe development of low-cost sophisticated hardware. However, an accompanying\nsoftware stack that can aid the usability of the robotic hardware remains the\nbottleneck of the process, especially if the robot is not dedicated to a single\njob. Programming a multi-purpose robot requires an on the fly mission\nscheduling capability that involves task identification and plan generation.\nThe problem dimension increases if the robot accepts tasks from a human in\nnatural language. Though recent advances in NLP and planner development can\nsolve a variety of complex problems, their amalgamation for a dynamic robotic\ntask handler is used in a limited scope. Specifically, the problem of\nformulating a planning problem from natural language instructions is not\nstudied in details. In this work, we provide a non-trivial method to combine an\nNLP engine and a planner such that a robot can successfully identify tasks and\nall the relevant parameters and generate an accurate plan for the task.\nAdditionally, some mechanism is required to resolve the ambiguity or missing\npieces of information in natural language instruction. Thus, we also develop a\ndialogue strategy that aims to gather additional information with minimal\nquestion-answer iterations and only when it is necessary. This work makes a\nsignificant stride towards enabling a human-like task understanding capability\nin a robot.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:19:23 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 04:54:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Pramanick", "Pradip", ""], ["Sarkar", "Chayan", ""], ["P", "Balamuralidhar", ""], ["Kattepur", "Ajay", ""], ["Bhattacharya", "Indrajit", ""], ["Pal", "Arpan", ""]]}, {"id": "2008.10077", "submitter": "Qing Sun", "authors": "Qing Sun and James Cross", "title": "Learn to Talk via Proactive Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer has been applied in solving a wide variety of problems.\nFor example, knowledge can be transferred between tasks (e.g., learning to\nhandle novel situations by leveraging prior knowledge) or between agents (e.g.,\nlearning from others without direct experience). Without loss of generality, we\nrelate knowledge transfer to KL-divergence minimization, i.e., matching the\n(belief) distributions of learners and teachers. The equivalence gives us a new\nperspective in understanding variants of the KL-divergence by looking at how\nlearners structure their interaction with teachers in order to acquire\nknowledge. In this paper, we provide an in-depth analysis of KL-divergence\nminimization in Forward and Backward orders, which shows that learners are\nreinforced via on-policy learning in Backward. In contrast, learners are\nsupervised in Forward. Moreover, our analysis is gradient-based, so it can be\ngeneralized to arbitrary tasks and help to decide which order to minimize given\nthe property of the task. By replacing Forward with Backward in Knowledge\nDistillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15\nTh-En machine translation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:46:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sun", "Qing", ""], ["Cross", "James", ""]]}, {"id": "2008.10078", "submitter": "Chayan Sarkar", "authors": "Hrishav Bakul Barua, Pradip Pramanick, Chayan Sarkar, Theint Haythi Mg", "title": "Let me join you! Real-time F-formation recognition by a socially aware\n  robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel architecture to detect social groups in real-time\nfrom a continuous image stream of an ego-vision camera. F-formation defines\nsocial orientations in space where two or more person tends to communicate in a\nsocial place. Thus, essentially, we detect F-formations in social gatherings\nsuch as meetings, discussions, etc. and predict the robot's approach angle if\nit wants to join the social group. Additionally, we also detect outliers, i.e.,\nthe persons who are not part of the group under consideration. Our proposed\npipeline consists of -- a) a skeletal key points estimator (a total of 17) for\nthe detected human in the scene, b) a learning model (using a feature vector\nbased on the skeletal points) using CRF to detect groups of people and outlier\nperson in a scene, and c) a separate learning model using a multi-class Support\nVector Machine (SVM) to predict the exact F-formation of the group of people in\nthe current scene and the angle of approach for the viewing robot. The system\nis evaluated using two data-sets. The results show that the group and outlier\ndetection in a scene using our method establishes an accuracy of 91%. We have\nmade rigorous comparisons of our systems with a state-of-the-art F-formation\ndetection system and found that it outperforms the state-of-the-art by 29% for\nformation detection and 55% for combined detection of the formation and\napproach angle.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:46:08 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Barua", "Hrishav Bakul", ""], ["Pramanick", "Pradip", ""], ["Sarkar", "Chayan", ""], ["Mg", "Theint Haythi", ""]]}, {"id": "2008.10080", "submitter": "Tristan Cazenave", "authors": "Tristan Cazenave", "title": "Mobile Networks for Computer Go", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of the neural networks used in Deep Reinforcement Learning\nprograms such as Alpha Zero or Polygames has been shown to have a great impact\non the performances of the resulting playing engines. For example the use of\nresidual networks gave a 600 ELO increase in the strength of Alpha Go. This\npaper proposes to evaluate the interest of Mobile Network for the game of Go\nusing supervised learning as well as the use of a policy head and a value head\ndifferent from the Alpha Zero heads. The accuracy of the policy, the mean\nsquared error of the value, the efficiency of the networks with the number of\nparameters, the playing speed and strength of the trained networks are\nevaluated.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:57:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Cazenave", "Tristan", ""]]}, {"id": "2008.10084", "submitter": "Chayan Sarkar", "authors": "Pradip Pramanick, Hrishav Bakul Barua, Chayan Sarkar", "title": "DeComplex: Task planning from complex natural instructions by a\n  collocating robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of robots in our daily surroundings like home, office,\nrestaurants, factory floors, etc. are increasing rapidly, the development of\nnatural human-robot interaction mechanism becomes more vital as it dictates the\nusability and acceptability of the robots. One of the valued features of such a\ncohabitant robot is that it performs tasks that are instructed in natural\nlanguage. However, it is not trivial to execute the human intended tasks as\nnatural language expressions can have large linguistic variations. Existing\nworks assume either single task instruction is given to the robot at a time or\nthere are multiple independent tasks in an instruction. However, complex task\ninstructions composed of multiple inter-dependent tasks are not handled\nefficiently in the literature. There can be ordering dependency among the\ntasks, i.e., the tasks have to be executed in a certain order or there can be\nexecution dependency, i.e., input parameter or execution of a task depends on\nthe outcome of another task. Understanding such dependencies in a complex\ninstruction is not trivial if an unconstrained natural language is allowed. In\nthis work, we propose a method to find the intended order of execution of\nmultiple inter-dependent tasks given in natural language instruction. Based on\nour experiment, we show that our system is very accurate in generating a viable\nexecution plan from a complex instruction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:10:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Pramanick", "Pradip", ""], ["Barua", "Hrishav Bakul", ""], ["Sarkar", "Chayan", ""]]}, {"id": "2008.10086", "submitter": "Reid McIlroy-Young", "authors": "Reid McIlroy-Young, Russell Wang, Siddhartha Sen, Jon Kleinberg,\n  Ashton Anderson", "title": "Learning Personalized Models of Human Behavior in Chess", "comments": "The current version of the paper corrects data processing problems\n  present in the previous version. 21 pages, 13 figures, 7 tables (one very\n  long)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even when machine learning systems surpass human ability in a domain, there\nare many reasons why AI systems that capture human-like behavior would be\ndesirable: humans may want to learn from them, they may need to collaborate\nwith them, or they may expect them to serve as partners in an extended\ninteraction. Motivated by this goal of human-like AI systems, the problem of\npredicting human actions -- as opposed to predicting optimal actions -- has\nbecome an increasingly useful task. We extend this line of work by developing\nhighly accurate personalized models of human behavior in the context of chess.\nChess is a rich domain for exploring these questions, since it combines a set\nof appealing features: AI systems have achieved superhuman performance but\nstill interact closely with human chess players both as opponents and\npreparation tools, and there is an enormous amount of recorded data on\nindividual players. Starting with an open-source version of AlphaZero trained\non a population of human players, we demonstrate that we can significantly\nimprove prediction of a particular player's moves by applying a series of\nfine-tuning adjustments. Furthermore, we can accurately perform stylometry --\npredicting who made a given set of actions -- indicating that our personalized\nmodels capture human decision-making at an individual level.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 18:24:21 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 20:10:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["McIlroy-Young", "Reid", ""], ["Wang", "Russell", ""], ["Sen", "Siddhartha", ""], ["Kleinberg", "Jon", ""], ["Anderson", "Ashton", ""]]}, {"id": "2008.10114", "submitter": "Roohallah Alizadehsani", "authors": "Roohallah Alizadehsani, Mohamad Roshanzamir, Sadiq Hussain, Abbas\n  Khosravi, Afsaneh Koohestani, Mohammad Hossein Zangooei, Moloud Abdar, Adham\n  Beykikhoshk, Afshin Shoeibi, Assef Zare, Maryam Panahiazar, Saeid Nahavandi,\n  Dipti Srinivasan, Amir F. Atiya, U. Rajendra Acharya", "title": "Handling of uncertainty in medical data using machine learning and\n  probability theory techniques: A review of 30 years (1991-2020)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding data and reaching valid conclusions are of paramount importance\nin the present era of big data. Machine learning and probability theory methods\nhave widespread application for this purpose in different fields. One\ncritically important yet less explored aspect is how data and model\nuncertainties are captured and analyzed. Proper quantification of uncertainty\nprovides valuable information for optimal decision making. This paper reviewed\nrelated studies conducted in the last 30 years (from 1991 to 2020) in handling\nuncertainties in medical data using probability theory and machine learning\ntechniques. Medical data is more prone to uncertainty due to the presence of\nnoise in the data. So, it is very important to have clean medical data without\nany noise to get accurate diagnosis. The sources of noise in the medical data\nneed to be known to address this issue. Based on the medical data obtained by\nthe physician, diagnosis of disease, and treatment plan are prescribed. Hence,\nthe uncertainty is growing in healthcare and there is limited knowledge to\naddress these problems. We have little knowledge about the optimal treatment\nmethods as there are many sources of uncertainty in medical science. Our\nfindings indicate that there are few challenges to be addressed in handling the\nuncertainty in medical raw data and new models. In this work, we have\nsummarized various methods employed to overcome this problem. Nowadays,\napplication of novel deep learning techniques to deal such uncertainties have\nsignificantly increased.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:54:27 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Alizadehsani", "Roohallah", ""], ["Roshanzamir", "Mohamad", ""], ["Hussain", "Sadiq", ""], ["Khosravi", "Abbas", ""], ["Koohestani", "Afsaneh", ""], ["Zangooei", "Mohammad Hossein", ""], ["Abdar", "Moloud", ""], ["Beykikhoshk", "Adham", ""], ["Shoeibi", "Afshin", ""], ["Zare", "Assef", ""], ["Panahiazar", "Maryam", ""], ["Nahavandi", "Saeid", ""], ["Srinivasan", "Dipti", ""], ["Atiya", "Amir F.", ""], ["Acharya", "U. Rajendra", ""]]}, {"id": "2008.10134", "submitter": "Salman Maqbool", "authors": "Salman Maqbool, Aqsa Riaz, Hasan Sajid, Osman Hasan", "title": "m2caiSeg: Semantic Segmentation of Laparoscopic Images using\n  Convolutional Neural Networks", "comments": "16 pages, 5 figures, Code available at:\n  https://github.com/salmanmaq/segmentationNetworks, Dataset available at:\n  https://www.kaggle.com/salmanmaq/m2caiseg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous surgical procedures, in particular minimal invasive surgeries, are\nthe next frontier for Artificial Intelligence research. However, the existing\nchallenges include precise identification of the human anatomy and the surgical\nsettings, and modeling the environment for training of an autonomous agent. To\naddress the identification of human anatomy and the surgical settings, we\npropose a deep learning based semantic segmentation algorithm to identify and\nlabel the tissues and organs in the endoscopic video feed of the human torso\nregion. We present an annotated dataset, m2caiSeg, created from endoscopic\nvideo feeds of real-world surgical procedures. Overall, the data consists of\n307 images, each of which is annotated for the organs and different surgical\ninstruments present in the scene. We propose and train a deep convolutional\nneural network for the semantic segmentation task. To cater for the low\nquantity of annotated data, we use unsupervised pre-training and data\naugmentation. The trained model is evaluated on an independent test set of the\nproposed dataset. We obtained a F1 score of 0.33 while using all the labeled\ncategories for the semantic segmentation task. Secondly, we labeled all\ninstruments into an 'Instruments' superclass to evaluate the model's\nperformance on discerning the various organs and obtained a F1 score of 0.57.\nWe propose a new dataset and a deep learning method for pixel level\nidentification of various organs and instruments in a endoscopic surgical\nscene. Surgical scene understanding is one of the first steps towards\nautomating surgical procedures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 23:30:15 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 21:34:59 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Maqbool", "Salman", ""], ["Riaz", "Aqsa", ""], ["Sajid", "Hasan", ""], ["Hasan", "Osman", ""]]}, {"id": "2008.10148", "submitter": "Md. Shirajum Munir", "authors": "Md. Shirajum Munir, Sarder Fakhrul Abedin, Ki Tae Kim, Do Hyeon Kim,\n  Md. Golam Rabiul Alam, and Choong Seon Hong", "title": "Drive Safe: Cognitive-Behavioral Mining for Intelligent Transportation\n  Cyber-Physical System", "comments": "Submitted to IEEE Transactions on Intelligent Transportation Systems,\n  Special Issue on Technologies for risk mitigation and support of impaired\n  drivers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a cognitive behavioral-based driver mood repairment\nplatform in intelligent transportation cyber-physical systems (IT-CPS) for road\nsafety. In particular, we propose a driving safety platform for distracted\ndrivers, namely \\emph{drive safe}, in IT-CPS. The proposed platform recognizes\nthe distracting activities of the drivers as well as their emotions for mood\nrepair. Further, we develop a prototype of the proposed drive safe platform to\nestablish proof-of-concept (PoC) for the road safety in IT-CPS. In the\ndeveloped driving safety platform, we employ five AI and statistical-based\nmodels to infer a vehicle driver's cognitive-behavioral mining to ensure safe\ndriving during the drive. Especially, capsule network (CN), maximum likelihood\n(ML), convolutional neural network (CNN), Apriori algorithm, and Bayesian\nnetwork (BN) are deployed for driver activity recognition, environmental\nfeature extraction, mood recognition, sequential pattern mining, and content\nrecommendation for affective mood repairment of the driver, respectively.\nBesides, we develop a communication module to interact with the systems in\nIT-CPS asynchronously. Thus, the developed drive safe PoC can guide the vehicle\ndrivers when they are distracted from driving due to the cognitive-behavioral\nfactors. Finally, we have performed a qualitative evaluation to measure the\nusability and effectiveness of the developed drive safe platform. We observe\nthat the P-value is 0.0041 (i.e., < 0.05) in the ANOVA test. Moreover, the\nconfidence interval analysis also shows significant gains in prevalence value\nwhich is around 0.93 for a 95% confidence level. The aforementioned statistical\nresults indicate high reliability in terms of driver's safety and mental state.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 01:19:40 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Munir", "Md. Shirajum", ""], ["Abedin", "Sarder Fakhrul", ""], ["Kim", "Ki Tae", ""], ["Kim", "Do Hyeon", ""], ["Alam", "Md. Golam Rabiul", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2008.10244", "submitter": "Marc Aubreville", "authors": "Marc Aubreville, Christof A. Bertram, Taryn A. Donovan, Christian\n  Marzahl, Andreas Maier, and Robert Klopfleisch", "title": "A completely annotated whole slide image dataset of canine breast cancer\n  to aid human breast cancer research", "comments": "12 pages, 5 figures", "journal-ref": "Sci Data 7, 417 (2020)", "doi": "10.1038/s41597-020-00756-z", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Canine mammary carcinoma (CMC) has been used as a model to investigate the\npathogenesis of human breast cancer and the same grading scheme is commonly\nused to assess tumor malignancy in both. One key component of this grading\nscheme is the density of mitotic figures (MF). Current publicly available\ndatasets on human breast cancer only provide annotations for small subsets of\nwhole slide images (WSIs). We present a novel dataset of 21 WSIs of CMC\ncompletely annotated for MF. For this, a pathologist screened all WSIs for\npotential MF and structures with a similar appearance. A second expert blindly\nassigned labels, and for non-matching labels, a third expert assigned the final\nlabels. Additionally, we used machine learning to identify previously\nundetected MF. Finally, we performed representation learning and\ntwo-dimensional projection to further increase the consistency of the\nannotations. Our dataset consists of 13,907 MF and 36,379 hard negatives. We\nachieved a mean F1-score of 0.791 on the test set and of up to 0.696 on a human\nbreast cancer dataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 08:06:55 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 11:49:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Aubreville", "Marc", ""], ["Bertram", "Christof A.", ""], ["Donovan", "Taryn A.", ""], ["Marzahl", "Christian", ""], ["Maier", "Andreas", ""], ["Klopfleisch", "Robert", ""]]}, {"id": "2008.10293", "submitter": "Dimitrios Bariamis", "authors": "Armin Runge (1) and Thomas Wenzel (2) and Dimitrios Bariamis (2) and\n  Benedikt Sebastian Staffler (3) and Lucas Rego Drumond (2) and Michael\n  Pfeiffer (3) ((1) Department of Advanced Digital Technologies, Bosch\n  Corporate Research, Renningen, Germany, (2) Computer Vision Lab, Bosch\n  Corporate Research, Hildesheim, Germany, (3) Bosch Center for Artificial\n  Intelligence, Renningen, Germany)", "title": "Bosch Deep Learning Hardware Benchmark", "comments": "Presented in MLBench: Workshop on Benchmarking Machine Learning\n  Workloads (https://sites.google.com/g.harvard.edu/mlbench/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of Deep Learning (DL) applications in science and industry\nhas created a large demand for efficient inference systems. This has resulted\nin a rapid increase of available Hardware Accelerators (HWAs) making comparison\nchallenging and laborious. To address this, several DL hardware benchmarks have\nbeen proposed aiming at a comprehensive comparison for many models, tasks, and\nhardware platforms. Here, we present our DL hardware benchmark which has been\nspecifically developed for inference on embedded HWAs and tasks required for\nautonomous driving. In addition to previous benchmarks, we propose a new\ngranularity level to evaluate common submodules of DL models, a twofold\nbenchmark procedure that accounts for hardware and model optimizations done by\nHWA manufacturers, and an extended set of performance indicators that can help\nto identify a mismatch between a HWA and the DL models used in our benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:50:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Runge", "Armin", ""], ["Wenzel", "Thomas", ""], ["Bariamis", "Dimitrios", ""], ["Staffler", "Benedikt Sebastian", ""], ["Drumond", "Lucas Rego", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "2008.10298", "submitter": "Robin Kips", "authors": "Robin Kips, Pietro Gori, Matthieu Perrot, Isabelle Bloch", "title": "CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup\n  Transfer", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-67070-2_17", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing makeup style transfer models perform an image synthesis whose\nresults cannot be explicitly controlled, the ability to modify makeup color\ncontinuously is a desirable property for virtual try-on applications. We\npropose a new formulation for the makeup style transfer task, with the\nobjective to learn a color controllable makeup style synthesis. We introduce\nCA-GAN, a generative model that learns to modify the color of specific objects\n(e.g. lips or eyes) in the image to an arbitrary target color while preserving\nbackground. Since color labels are rare and costly to acquire, our method\nleverages weakly supervised learning for conditional GANs. This enables to\nlearn a controllable synthesis of complex objects, and only requires a weak\nproxy of the image attribute that we desire to modify. Finally, we present for\nthe first time a quantitative analysis of makeup style transfer and color\ncontrol performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 10:11:17 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Kips", "Robin", ""], ["Gori", "Pietro", ""], ["Perrot", "Matthieu", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2008.10309", "submitter": "Guohao Li", "authors": "Guohao Li, Mengmeng Xu, Silvio Giancola, Ali Thabet, Bernard Ghanem", "title": "LC-NAS: Latency Constrained Neural Architecture Search for Point Cloud\n  Networks", "comments": "Originally submitted to ECCV'2020 but rejected. This work was filed\n  with the United States Patent and Trademark Office (USPTO) on May 19, 2020\n  and assigned Serial No. 63/027,241", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud architecture design has become a crucial problem for 3D deep\nlearning. Several efforts exist to manually design architectures with high\naccuracy in point cloud tasks such as classification, segmentation, and\ndetection. Recent progress in automatic Neural Architecture Search (NAS)\nminimizes the human effort in network design and optimizes high performing\narchitectures. However, these efforts fail to consider important factors such\nas latency during inference. Latency is of high importance in time critical\napplications like self-driving cars, robot navigation, and mobile applications,\nthat are generally bound by the available hardware. In this paper, we introduce\na new NAS framework, dubbed LC-NAS, where we search for point cloud\narchitectures that are constrained to a target latency. We implement a novel\nlatency constraint formulation to trade-off between accuracy and latency in our\narchitecture search. Contrary to previous works, our latency loss guarantees\nthat the final network achieves latency under a specified target value. This is\ncrucial when the end task is to be deployed in a limited hardware setting.\nExtensive experiments show that LC-NAS is able to find state-of-the-art\narchitectures for point cloud classification in ModelNet40 with minimal\ncomputational cost. We also show how our searched architectures achieve any\ndesired latency with a reasonably low drop in accuracy. Finally, we show how\nour searched architectures easily transfer to a different task, part\nsegmentation on PartNet, where we achieve state-of-the-art results while\nlowering latency by a factor of 10.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 10:30:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Guohao", ""], ["Xu", "Mengmeng", ""], ["Giancola", "Silvio", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2008.10320", "submitter": "Fanhua Shang", "authors": "Hongying Liu, Zhubo Ruan, Chaowei Fang, Peng Zhao, Fanhua Shang,\n  Yuanyuan Liu, Lijun Wang", "title": "A Single Frame and Multi-Frame Joint Network for 360-degree Panorama\n  Video Super-Resolution", "comments": "10 pages, 5 figures, submitted to an international peer-review\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical videos, also known as \\ang{360} (panorama) videos, can be viewed\nwith various virtual reality devices such as computers and head-mounted\ndisplays. They attract large amount of interest since awesome immersion can be\nexperienced when watching spherical videos. However, capturing, storing and\ntransmitting high-resolution spherical videos are extremely expensive. In this\npaper, we propose a novel single frame and multi-frame joint network (SMFN) for\nrecovering high-resolution spherical videos from low-resolution inputs. To take\nadvantage of pixel-level inter-frame consistency, deformable convolutions are\nused to eliminate the motion difference between feature maps of the target\nframe and its neighboring frames. A mixed attention mechanism is devised to\nenhance the feature representation capability. The dual learning strategy is\nexerted to constrain the space of solution so that a better solution can be\nfound. A novel loss function based on the weighted mean square error is\nproposed to emphasize on the super-resolution of the equatorial regions. This\nis the first attempt to settle the super-resolution of spherical videos, and we\ncollect a novel dataset from the Internet, MiG Panorama Video, which includes\n204 videos. Experimental results on 4 representative video clips demonstrate\nthe efficacy of the proposed method. The dataset and code are available at\nhttps://github.com/lovepiano/SMFN_For_360VSR.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:09:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Hongying", ""], ["Ruan", "Zhubo", ""], ["Fang", "Chaowei", ""], ["Zhao", "Peng", ""], ["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Wang", "Lijun", ""]]}, {"id": "2008.10327", "submitter": "Chengyu Wang", "authors": "Taolin Zhang, Chengyu Wang, Minghui Qiu, Bite Yang, Xiaofeng He, Jun\n  Huang", "title": "Knowledge-Empowered Representation Learning for Chinese Medical Reading\n  Comprehension: Task, Model and Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) aims to extract answers to questions\ngiven a passage. It has been widely studied recently, especially in open\ndomains. However, few efforts have been made on closed-domain MRC, mainly due\nto the lack of large-scale training data. In this paper, we introduce a\nmulti-target MRC task for the medical domain, whose goal is to predict answers\nto medical questions and the corresponding support sentences from medical\ninformation sources simultaneously, in order to ensure the high reliability of\nmedical knowledge serving. A high-quality dataset is manually constructed for\nthe purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with\ndetailed analysis conducted. We further propose the Chinese medical BERT model\nfor the task (CMedBERT), which fuses medical knowledge into pre-trained\nlanguage models by the dynamic fusion mechanism of heterogeneous features and\nthe multi-task learning strategy. Experiments show that CMedBERT consistently\noutperforms strong baselines by fusing context-aware and knowledge-aware token\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:23:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Taolin", ""], ["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Yang", "Bite", ""], ["He", "Xiaofeng", ""], ["Huang", "Jun", ""]]}, {"id": "2008.10356", "submitter": "Shengjun Liu", "authors": "Shengjun Liu, Ningkang Jiang, Yuanbin Wu", "title": "Visual Attack and Defense on Text", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modifying characters of a piece of text to their visual similar ones often\nap-pear in spam in order to fool inspection systems and other conditions, which\nwe regard as a kind of adversarial attack to neural models. We pro-pose a way\nof generating such visual text attack and show that the attacked text are\nreadable by humans but mislead a neural classifier greatly. We ap-ply a\nvision-based model and adversarial training to defense the attack without\nlosing the ability to understand normal text. Our results also show that visual\nattack is extremely sophisticated and diverse, more work needs to be done to\nsolve this.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:44:58 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Liu", "Shengjun", ""], ["Jiang", "Ningkang", ""], ["Wu", "Yuanbin", ""]]}, {"id": "2008.10365", "submitter": "Ravi Vadlamani", "authors": "Sarveswararao Vangala, Ravi Vadlamani", "title": "ATM Cash demand forecasting in an Indian Bank with chaos and deep\n  learning", "comments": "20 pages; 6 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes to model chaos in the ATM cash withdrawal time series of\na big Indian bank and forecast the withdrawals using deep learning methods. It\nalso considers the importance of day-of-the-week and includes it as a dummy\nexogenous variable. We first modelled the chaos present in the withdrawal time\nseries by reconstructing the state space of each series using the lag, and\nembedding dimension found using an auto-correlation function and Cao's method.\nThis process converts the uni-variate time series into multi variate time\nseries. The \"day-of-the-week\" is converted into seven features with the help of\none-hot encoding. Then these seven features are augmented to the multivariate\ntime series. For forecasting the future cash withdrawals, using algorithms\nnamely ARIMA, random forest (RF), support vector regressor (SVR), multi-layer\nperceptron (MLP), group method of data handling (GMDH), general regression\nneural network (GRNN), long short term memory neural network and 1-dimensional\nconvolutional neural network. We considered a daily cash withdrawals data set\nfrom an Indian commercial bank. After modelling chaos and adding exogenous\nfeatures to the data set, we observed improvements in the forecasting for all\nmodels. Even though the random forest (RF) yielded better Symmetric Mean\nAbsolute Percentage Error (SMAPE) value, deep learning algorithms, namely LSTM\nand 1D CNN, showed similar performance compared to RF, based on t-test.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:23:07 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Vangala", "Sarveswararao", ""], ["Vadlamani", "Ravi", ""]]}, {"id": "2008.10383", "submitter": "Kazi Zainab Khanam", "authors": "Kazi Zainab Khanam, Gautam Srivastava, Vijay Mago", "title": "The Homophily Principle in Social Network Analysis", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, social media has become a ubiquitous and integral part of\nsocial networking. One of the major attentions made by social researchers is\nthe tendency of like-minded people to interact with one another in social\ngroups, a concept which is known as Homophily. The study of homophily can\nprovide eminent insights into the flow of information and behaviors within a\nsociety and this has been extremely useful in analyzing the formations of\nonline communities. In this paper, we review and survey the effect of homophily\nin social networks and summarize the state of art methods that has been\nproposed in the past years to identify and measure the effect of homophily in\nmultiple types of social networks and we conclude with a critical discussion of\nopen challenges and directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:43:59 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Khanam", "Kazi Zainab", ""], ["Srivastava", "Gautam", ""], ["Mago", "Vijay", ""]]}, {"id": "2008.10386", "submitter": "Evgenii Safronov", "authors": "Evgenii Safronov, Michele Colledanchise and Lorenzo Natale", "title": "Compact Belief State Representation for Task Planning", "comments": "Accepted to CASE 2020 16th IEEE International Conference on\n  Automation Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task planning in a probabilistic belief state domains allows generating\ncomplex and robust execution policies in those domains affected by state\nuncertainty. The performance of a task planner relies on the belief state\nrepresentation. However, current belief state representation becomes easily\nintractable as the number of variables and execution time grows. To address\nthis problem, we developed a novel belief state representation based on\ncartesian product and union operations over belief substates. These two\noperations and single variable assignment nodes form And-Or directed acyclic\ngraph of Belief State (AOBS). We show how to apply actions with probabilistic\noutcomes and measure the probability of conditions holding over belief state.\nWe evaluated AOBS performance in simulated forward state space exploration. We\ncompared the size of AOBS with the size of Binary Decision Diagrams (BDD) that\nwere previously used to represent belief state. We show that AOBS\nrepresentation is not only much more compact than a full belief state but it\nalso scales better than BDD for most of the cases.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:38:36 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Safronov", "Evgenii", ""], ["Colledanchise", "Michele", ""], ["Natale", "Lorenzo", ""]]}, {"id": "2008.10401", "submitter": "Mark Dukes Dr", "authors": "Mark Dukes, Anthony A. Casey", "title": "Combinatorial diversity metrics for the analysis of policy processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several completely general diversity metrics to quantify the\nproblem-solving capacity of any public policy decision making process. This is\nperformed by modelling the policy process using a declarative process paradigm\nin conjunction with constraints modelled by expressions in linear temporal\nlogic. We introduce a class of traces, called first-passage traces, to\nrepresent the different executions of the declarative processes. Heuristics of\nwhat properties a diversity measure of such processes ought to satisfy are used\nto derive two different metrics for these processes in terms of the set of\nfirst-passage traces. These metrics turn out to have formulations in terms of\nthe entropies of two different random variables on the set of traces of the\nprocesses. In addition, we introduce a measure of `goodness' whereby a trace is\ntermed {\\it good} if it satisfies some prescribed linear temporal logic\nexpression. This allows for comparisons of policy processes with respect to the\nprescribed notion of `goodness'.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 19:46:29 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Dukes", "Mark", ""], ["Casey", "Anthony A.", ""]]}, {"id": "2008.10417", "submitter": "Kehua Chen", "authors": "Kehua Chen, Hongcheng Wang, Borja Valverde-Perezc, Siyuan Zhai, Luca\n  Vezzaro, Aijie Wang", "title": "Optimal control towards sustainable wastewater treatment plants based on\n  multi-agent reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.chemosphere.2021.130498", "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wastewater treatment plants are designed to eliminate pollutants and\nalleviate environmental pollution. However, the construction and operation of\nWWTPs consume resources, emit greenhouse gases (GHGs) and produce residual\nsludge, thus require further optimization. WWTPs are complex to control and\noptimize because of high nonlinearity and variation. This study used a novel\ntechnique, multi-agent deep reinforcement learning, to simultaneously optimize\ndissolved oxygen and chemical dosage in a WWTP. The reward function was\nspecially designed from life cycle perspective to achieve sustainable\noptimization. Five scenarios were considered: baseline, three different\neffluent quality and cost-oriented scenarios. The result shows that\noptimization based on LCA has lower environmental impacts compared to baseline\nscenario, as cost, energy consumption and greenhouse gas emissions reduce to\n0.890 CNY/m3-ww, 0.530 kWh/m3-ww, 2.491 kg CO2-eq/m3-ww respectively. The\ncost-oriented control strategy exhibits comparable overall performance to the\nLCA driven strategy since it sacrifices environmental bene ts but has lower\ncost as 0.873 CNY/m3-ww. It is worth mentioning that the retrofitting of WWTPs\nbased on resources should be implemented with the consideration of impact\ntransfer. Specifically, LCA SW scenario decreases 10 kg PO4-eq in\neutrophication potential compared to the baseline within 10 days, while\nsignificantly increases other indicators. The major contributors of each\nindicator are identified for future study and improvement. Last, the author\ndiscussed that novel dynamic control strategies required advanced sensors or a\nlarge amount of data, so the selection of control strategies should also\nconsider economic and ecological conditions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 05:34:47 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 13:17:42 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 08:04:28 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Chen", "Kehua", ""], ["Wang", "Hongcheng", ""], ["Valverde-Perezc", "Borja", ""], ["Zhai", "Siyuan", ""], ["Vezzaro", "Luca", ""], ["Wang", "Aijie", ""]]}, {"id": "2008.10422", "submitter": "Hongchang Gao", "authors": "Hongchang Gao, Heng Huang", "title": "Adaptive Serverless Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of distributed data, training machine learning models in\nthe serverless manner has attracted increasing attention in recent years.\nNumerous training approaches have been proposed in this regime, such as\ndecentralized SGD. However, all existing decentralized algorithms only focus on\nstandard SGD. It might not be suitable for some applications, such as deep\nfactorization machine in which the feature is highly sparse and categorical so\nthat the adaptive training algorithm is needed. In this paper, we propose a\nnovel adaptive decentralized training approach, which can compute the learning\nrate from data dynamically. To the best of our knowledge, this is the first\nadaptive decentralized training approach. Our theoretical results reveal that\nthe proposed algorithm can achieve linear speedup with respect to the number of\nworkers. Moreover, to reduce the communication-efficient overhead, we further\npropose a communication-efficient adaptive decentralized training approach,\nwhich can also achieve linear speedup with respect to the number of workers. At\nlast, extensive experiments on different tasks have confirmed the effectiveness\nof our proposed two approaches.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:23:02 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gao", "Hongchang", ""], ["Huang", "Heng", ""]]}, {"id": "2008.10427", "submitter": "Prasanna Parthasarathi", "authors": "Prasanna Parthasarathi and Joelle Pineau and Sarath Chandar", "title": "How To Evaluate Your Dialogue System: Probe Tasks as an Alternative for\n  Token-level Evaluation Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though generative dialogue modeling is widely seen as a language modeling\ntask, the task demands an agent to have a complex natural language\nunderstanding of its input text to carry a meaningful interaction with an user.\nThe automatic metrics used evaluate the quality of the generated text as a\nproxy to the holistic interaction of the agent. Such metrics were earlier shown\nto not correlate with the human judgement. In this work, we observe that human\nevaluation of dialogue agents can be inconclusive due to the lack of sufficient\ninformation for appropriate evaluation. The automatic metrics are deterministic\nyet shallow and human evaluation can be relevant yet inconclusive. To bridge\nthis gap in evaluation, we propose designing a set of probing tasks to evaluate\ndialogue models. The hand-crafted tasks are aimed at quantitatively evaluating\na generative dialogue model's understanding beyond the token-level evaluation\non the generated text. The probing tasks are deterministic like automatic\nmetrics and requires human judgement in their designing; benefiting from the\nbest of both worlds. With experiments on probe tasks we observe that, unlike\nRNN based architectures, transformer model may not be learning to comprehend\nthe input text despite its generated text having higher overlap with the target\ntext.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:28:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Parthasarathi", "Prasanna", ""], ["Pineau", "Joelle", ""], ["Chandar", "Sarath", ""]]}, {"id": "2008.10492", "submitter": "Brent Biseda", "authors": "Brent Biseda, Gaurav Desai, Haifeng Lin, and Anish Philip", "title": "Prediction of ICD Codes with Clinical BERT Embeddings and Text\n  Augmentation with Label Balancing using MIMIC-III", "comments": "5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper achieves state of the art results for the ICD code prediction task\nusing the MIMIC-III dataset. This was achieved through the use of Clinical BERT\n(Alsentzer et al., 2019). embeddings and text augmentation and label balancing\nto improve F1 scores for both ICD Chapter as well as ICD disease codes. We\nattribute the improved performance mainly to the use of novel text augmentation\nto shuffle the order of sentences during training. In comparison to the Top-32\nICD code prediction (Keyang Xu, et. al.) with an F1 score of 0.76, we achieve a\nfinal F1 score of 0.75 but on a total of the top 50 ICD codes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:53:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Biseda", "Brent", ""], ["Desai", "Gaurav", ""], ["Lin", "Haifeng", ""], ["Philip", "Anish", ""]]}, {"id": "2008.10518", "submitter": "Ajinkya Jain", "authors": "Ajinkya Jain and Rudolf Lioutikov and Caleb Chuck and Scott Niekum", "title": "ScrewNet: Category-Independent Articulation Model Estimation From Depth\n  Images Using Screw Theory", "comments": "Presented at ICRA'21. Project webpage:\n  https://pearl-utexas.github.io/ScrewNet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots in human environments will need to interact with a wide variety of\narticulated objects such as cabinets, drawers, and dishwashers while assisting\nhumans in performing day-to-day tasks. Existing methods either require objects\nto be textured or need to know the articulation model category a priori for\nestimating the model parameters for an articulated object. We propose ScrewNet,\na novel approach that estimates an object's articulation model directly from\ndepth images without requiring a priori knowledge of the articulation model\ncategory. ScrewNet uses screw theory to unify the representation of different\narticulation types and perform category-independent articulation model\nestimation. We evaluate our approach on two benchmarking datasets and compare\nits performance with a current state-of-the-art method. Results demonstrate\nthat ScrewNet can successfully estimate the articulation models and their\nparameters for novel objects across articulation model categories with better\non average accuracy than the prior state-of-the-art method. Project webpage:\nhttps://pearl-utexas.github.io/ScrewNet/\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:41:23 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 21:01:42 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 22:55:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jain", "Ajinkya", ""], ["Lioutikov", "Rudolf", ""], ["Chuck", "Caleb", ""], ["Niekum", "Scott", ""]]}, {"id": "2008.10522", "submitter": "Peter beim Graben", "authors": "Peter Klimczak, G\\\"unther Wirsching and Peter beim Graben", "title": "Machine Semiotics", "comments": "37 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their satisfactory speech recognition capabilities, current speech\nassistive devices still lack suitable automatic semantic analysis capabilities\nas well as useful representation of pragmatic world knowledge. Instead, current\ntechnologies require users to learn keywords necessary to effectively operate\nand work with a machine. Such a machine-centered approach can be frustrating\nfor users. However, recognizing a basic difference between the semiotics of\nhumans and machines presents a possibility to overcome this shortcoming: For\nthe machine, the meaning of a (human) utterance is defined by its own scope of\nactions. Machines, thus, do not need to understand the meanings of individual\nwords, nor the meaning of phrasal and sentence semantics that combine\nindividual word meanings with additional implicit world knowledge. For speech\nassistive devices, the learning of machine specific meanings of human\nutterances by trial and error should be sufficient. Using the trivial example\nof a cognitive heating device, we show that -- based on dynamic semantics --\nthis process can be formalized as the learning of utterance-meaning pairs\n(UMP). This is followed by a detailed semiotic contextualization of the\npreviously generated signs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:49:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Klimczak", "Peter", ""], ["Wirsching", "G\u00fcnther", ""], ["Graben", "Peter beim", ""]]}, {"id": "2008.10546", "submitter": "Lingkai Kong", "authors": "Lingkai Kong, Jimeng Sun and Chao Zhang", "title": "SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates", "comments": "ICML2020. Code is available through\n  https://github.com/Lingkai-Kong/SDE-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is a fundamental yet unsolved problem for deep\nlearning. The Bayesian framework provides a principled way of uncertainty\nestimation but is often not scalable to modern deep neural nets (DNNs) that\nhave a large number of parameters. Non-Bayesian methods are simple to implement\nbut often conflate different sources of uncertainties and require huge\ncomputing resources. We propose a new method for quantifying uncertainties of\nDNNs from a dynamical system perspective. The core of our method is to view DNN\ntransformations as state evolution of a stochastic dynamical system and\nintroduce a Brownian motion term for capturing epistemic uncertainty. Based on\nthis perspective, we propose a neural stochastic differential equation model\n(SDE-Net) which consists of (1) a drift net that controls the system to fit the\npredictive function; and (2) a diffusion net that captures epistemic\nuncertainty. We theoretically analyze the existence and uniqueness of the\nsolution to SDE-Net. Our experiments demonstrate that the SDE-Net model can\noutperform existing uncertainty estimation methods across a series of tasks\nwhere uncertainty plays a fundamental role.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:33:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kong", "Lingkai", ""], ["Sun", "Jimeng", ""], ["Zhang", "Chao", ""]]}, {"id": "2008.10575", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Multidimensionality of Legal Singularity: Parametric Analysis and the\n  Autonomous Levels of AI Legal Reasoning", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal scholars have in the last several years embarked upon an ongoing\ndiscussion and debate over a potential Legal Singularity that might someday\noccur, involving a variant or law-domain offshoot leveraged from the Artificial\nIntelligence (AI) realm amid its many decades of deliberations about an\noverarching and generalized technological singularity (referred to classically\nas The Singularity). This paper examines the postulated Legal Singularity and\nproffers that such AI and Law cogitations can be enriched by these three facets\naddressed herein: (1) dovetail additionally salient considerations of The\nSingularity into the Legal Singularity, (2) make use of an in-depth and\ninnovative multidimensional parametric analysis of the Legal Singularity as\nposited in this paper, and (3) align and unify the Legal Singularity with the\nLevels of Autonomy (LoA) associated with AI Legal Reasoning (AILR) as\npropounded in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:28:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2008.10592", "submitter": "Benjamin Wilson", "authors": "Benjamin Wilson, Zsolt Kira, James Hays", "title": "3D for Free: Crossmodal Transfer Learning using HD Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object detection is a core perceptual challenge for robotics and\nautonomous driving. However, the class-taxonomies in modern autonomous driving\ndatasets are significantly smaller than many influential 2D detection datasets.\nIn this work, we address the long-tail problem by leveraging both the large\nclass-taxonomies of modern 2D datasets and the robustness of state-of-the-art\n2D detection methods. We proceed to mine a large, unlabeled dataset of images\nand LiDAR, and estimate 3D object bounding cuboids, seeded from an\noff-the-shelf 2D instance segmentation model. Critically, we constrain this\nill-posed 2D-to-3D mapping by using high-definition maps and object size\npriors. The result of the mining process is 3D cuboids with varying confidence.\nThis mining process is itself a 3D object detector, although not especially\naccurate when evaluated as such. However, we then train a 3D object detection\nmodel on these cuboids, consistent with other recent observations in the deep\nlearning literature, we find that the resulting model is fairly robust to the\nnoisy supervision that our mining process provides. We mine a collection of\n1151 unlabeled, multimodal driving logs from an autonomous vehicle and use the\ndiscovered objects to train a LiDAR-based object detector. We show that\ndetector performance increases as we mine more unlabeled data. With our full,\nunlabeled dataset, our method performs competitively with fully supervised\nmethods, even exceeding the performance for certain object categories, without\nany human 3D annotations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:54:51 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wilson", "Benjamin", ""], ["Kira", "Zsolt", ""], ["Hays", "James", ""]]}, {"id": "2008.10713", "submitter": "Shuai Zheng", "authors": "Chi Zhang, Philip Odonkor, Shuai Zheng, Hamed Khorasgani, Susumu\n  Serita, Chetan Gupta", "title": "Dynamic Dispatching for Large-Scale Heterogeneous Fleet via Multi-agent\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic dispatching is one of the core problems for operation optimization in\ntraditional industries such as mining, as it is about how to smartly allocate\nthe right resources to the right place at the right time. Conventionally, the\nindustry relies on heuristics or even human intuitions which are often\nshort-sighted and sub-optimal solutions. Leveraging the power of AI and\nInternet of Things (IoT), data-driven automation is reshaping this area.\nHowever, facing its own challenges such as large-scale and heterogenous trucks\nrunning in a highly dynamic environment, it can barely adopt methods developed\nin other domains (e.g., ride-sharing). In this paper, we propose a novel Deep\nReinforcement Learning approach to solve the dynamic dispatching problem in\nmining. We first develop an event-based mining simulator with parameters\ncalibrated in real mines. Then we propose an experience-sharing Deep Q Network\nwith a novel abstract state/action representation to learn memories from\nheterogeneous agents altogether and realizes learning in a centralized way. We\ndemonstrate that the proposed methods significantly outperform the most widely\nadopted approaches in the industry by $5.56\\%$ in terms of productivity. The\nproposed approach has great potential in a broader range of industries (e.g.,\nmanufacturing, logistics) which have a large-scale of heterogenous equipment\nworking in a highly dynamic environment, as a general framework for dynamic\nresource allocation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 21:29:56 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Chi", ""], ["Odonkor", "Philip", ""], ["Zheng", "Shuai", ""], ["Khorasgani", "Hamed", ""], ["Serita", "Susumu", ""], ["Gupta", "Chetan", ""]]}, {"id": "2008.10733", "submitter": "Chandra Thapa", "authors": "Chandra Thapa and Seyit Camtepe", "title": "Precision Health Data: Requirements, Challenges and Existing Techniques\n  for Data Security and Privacy", "comments": "35 pages, 3 figures, 7 tables", "journal-ref": "Computers in Biology and Medicine 129 (2021) 104130", "doi": "10.1016/j.compbiomed.2020.104130", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision health leverages information from various sources, including omics,\nlifestyle, environment, social media, medical records, and medical insurance\nclaims to enable personalized care, prevent and predict illness, and precise\ntreatments. It extensively uses sensing technologies (e.g., electronic health\nmonitoring devices), computations (e.g., machine learning), and communication\n(e.g., interaction between the health data centers). As health data contain\nsensitive private information, including the identity of patient and carer and\nmedical conditions of the patient, proper care is required at all times.\nLeakage of these private information affects the personal life, including\nbullying, high insurance premium, and loss of job due to the medical history.\nThus, the security, privacy of and trust on the information are of utmost\nimportance. Moreover, government legislation and ethics committees demand the\nsecurity and privacy of healthcare data. Herein, in the light of precision\nhealth data security, privacy, ethical and regulatory requirements, finding the\nbest methods and techniques for the utilization of the health data, and thus\nprecision health is essential. In this regard, firstly, this paper explores the\nregulations, ethical guidelines around the world, and domain-specific needs.\nThen it presents the requirements and investigates the associated challenges.\nSecondly, this paper investigates secure and privacy-preserving machine\nlearning methods suitable for the computation of precision health data along\nwith their usage in relevant health projects. Finally, it illustrates the best\navailable techniques for precision health data security and privacy with a\nconceptual system model that enables compliance, ethics clearance, consent\nmanagement, medical innovations, and developments in the health domain.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 22:17:32 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Thapa", "Chandra", ""], ["Camtepe", "Seyit", ""]]}, {"id": "2008.10766", "submitter": "Dong Lao", "authors": "Dong Lao, Peihao Zhu, Peter Wonka, Ganesh Sundaramoorthi", "title": "Channel-Directed Gradients for Optimization of Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce optimization methods for convolutional neural networks that can\nbe used to improve existing gradient-based optimization in terms of\ngeneralization error. The method requires only simple processing of existing\nstochastic gradients, can be used in conjunction with any optimizer, and has\nonly a linear overhead (in the number of parameters) compared to computation of\nthe stochastic gradient. The method works by computing the gradient of the loss\nfunction with respect to output-channel directed re-weighted L2 or Sobolev\nmetrics, which has the effect of smoothing components of the gradient across a\ncertain direction of the parameter tensor. We show that defining the gradients\nalong the output channel direction leads to a performance boost, while other\ndirections can be detrimental. We present the continuum theory of such\ngradients, its discretization, and application to deep networks. Experiments on\nbenchmark datasets, several networks and baseline optimizers show that\noptimizers can be improved in generalization error by simply computing the\nstochastic gradient with respect to output-channel directed metrics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:44:09 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lao", "Dong", ""], ["Zhu", "Peihao", ""], ["Wonka", "Peter", ""], ["Sundaramoorthi", "Ganesh", ""]]}, {"id": "2008.10774", "submitter": "Saeed Anwar", "authors": "Saeed Anwar, Muhammad Tahir, Chongyi Li, Ajmal Mian, Fahad Shahbaz\n  Khan, Abdul Wahab Muzaffar", "title": "Image Colorization: A Survey and Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image colorization is an essential image processing and computer vision\nbranch to colorize images and videos. Recently, deep learning techniques\nprogressed notably for image colorization. This article presents a\ncomprehensive survey of recent state-of-the-art colorization using deep\nlearning algorithms, describing their fundamental block architectures in terms\nof skip connections, input etc. as well as optimizers, loss functions, training\nprotocols, and training data etc. Generally, we can roughly categorize the\nexisting colorization techniques into seven classes. Besides, we also provide\nsome additional essential issues, such as benchmark datasets and evaluation\nmetrics. We also introduce a new dataset specific to colorization and perform\nan experimental evaluation of the publicly available methods. In the last\nsection, we discuss the limitations, possible solutions, and future research\ndirections of the rapidly evolving topic of deep image colorization that the\ncommunity should further address. Dataset and Codes for evaluation will be\npublicly available at https://github.com/saeed-anwar/ColorSurvey\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 01:22:52 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 11:44:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Anwar", "Saeed", ""], ["Tahir", "Muhammad", ""], ["Li", "Chongyi", ""], ["Mian", "Ajmal", ""], ["Khan", "Fahad Shahbaz", ""], ["Muzaffar", "Abdul Wahab", ""]]}, {"id": "2008.10781", "submitter": "Burak Aksar", "authors": "Emre Ates, Burak Aksar, Vitus J. Leung, Ayse K. Coskun", "title": "Counterfactual Explanations for Machine Learning on Multivariate Time\n  Series Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying machine learning (ML) on multivariate time series data has growing\npopularity in many application domains, including in computer system\nmanagement. For example, recent high performance computing (HPC) research\nproposes a variety of ML frameworks that use system telemetry data in the form\nof multivariate time series so as to detect performance variations, perform\nintelligent scheduling or node allocation, and improve system security. Common\nbarriers for adoption for these ML frameworks include the lack of user trust\nand the difficulty of debugging. These barriers need to be overcome to enable\nthe widespread adoption of ML frameworks in production systems. To address this\nchallenge, this paper proposes a novel explainability technique for providing\ncounterfactual explanations for supervised ML frameworks that use multivariate\ntime series data. The proposed method outperforms state-of-the-art\nexplainability methods on several different ML frameworks and data sets in\nmetrics such as faithfulness and robustness. The paper also demonstrates how\nthe proposed method can be used to debug ML frameworks and gain a better\nunderstanding of HPC system telemetry data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 02:04:59 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ates", "Emre", ""], ["Aksar", "Burak", ""], ["Leung", "Vitus J.", ""], ["Coskun", "Ayse K.", ""]]}, {"id": "2008.10806", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu and Takamitsu Matsubara", "title": "Ensuring Monotonic Policy Improvement in Entropy-regularized Value-based\n  Reinforcement Learning", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to establish an entropy-regularized value-based reinforcement\nlearning method that can ensure the monotonic improvement of policies at each\npolicy update. Unlike previously proposed lower-bounds on policy improvement in\ngeneral infinite-horizon MDPs, we derive an entropy-regularization aware lower\nbound. Since our bound only requires the expected policy advantage function to\nbe estimated, it is scalable to large-scale (continuous) state-space problems.\nWe propose a novel reinforcement learning algorithm that exploits this\nlower-bound as a criterion for adjusting the degree of a policy update for\nalleviating policy oscillation. We demonstrate the effectiveness of our\napproach in both discrete-state maze and continuous-state inverted pendulum\ntasks using a linear function approximator for value estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:09:18 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhu", "Lingwei", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2008.10808", "submitter": "Hao Li", "authors": "Mingkai Huang, Hao Li, Bing Bai, Chang Wang, Kun Bai, Fei Wang", "title": "A Federated Multi-View Deep Learning Framework for Privacy-Preserving\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving recommendations are recently gaining momentum, since the\ndecentralized user data is increasingly harder to collect, by recommendation\nservice providers, due to the serious concerns over user privacy and data\nsecurity. This situation is further exacerbated by the strict government\nregulations such as Europe's General Data Privacy Regulations(GDPR). Federated\nLearning(FL) is a newly developed privacy-preserving machine learning paradigm\nto bridge data repositories without compromising data security and privacy.\nThus many federated recommendation(FedRec) algorithms have been proposed to\nrealize personalized privacy-preserving recommendations. However, existing\nFedRec algorithms, mostly extended from traditional collaborative filtering(CF)\nmethod, cannot address cold-start problem well. In addition, their performance\noverhead w.r.t. model accuracy, trained in a federated setting, is often\nnon-negligible comparing to centralized recommendations. This paper studies\nthis issue and presents FL-MV-DSSM, a generic content-based federated\nmulti-view recommendation framework that not only addresses the cold-start\nproblem, but also significantly boosts the recommendation performance by\nlearning a federated model from multiple data source for capturing richer\nuser-level features. The new federated multi-view setting, proposed by\nFL-MV-DSSM, opens new usage models and brings in new security challenges to FL\nin recommendation scenarios. We prove the security guarantees of \\xxx, and\nempirical evaluations on FL-MV-DSSM and its variations with public datasets\ndemonstrate its effectiveness. Our codes will be released if this paper is\naccepted.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:19:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Huang", "Mingkai", ""], ["Li", "Hao", ""], ["Bai", "Bing", ""], ["Wang", "Chang", ""], ["Bai", "Kun", ""], ["Wang", "Fei", ""]]}, {"id": "2008.10845", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "CnGAN: Generative Adversarial Networks for Cross-network user preference\n  generation for non-overlapped users", "comments": null, "journal-ref": "The World Wide Web Conference, 2019 (WWW'19)", "doi": "10.1145/3308558.3313733", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major drawback of cross-network recommender solutions is that they can only\nbe applied to users that are overlapped across networks. Thus, the\nnon-overlapped users, which form the majority of users are ignored. As a\nsolution, we propose CnGAN, a novel multi-task learning based,\nencoder-GAN-recommender architecture. The proposed model synthetically\ngenerates source network user preferences for non-overlapped users by learning\nthe mapping from target to source network preference manifolds. The resultant\nuser preferences are used in a Siamese network based neural recommender\narchitecture. Furthermore, we propose a novel user based pairwise loss function\nfor recommendations using implicit interactions to better guide the generation\nprocess in the multi-task learning environment.We illustrate our solution by\ngenerating user preferences on the Twitter source network for recommendations\non the YouTube target network. Extensive experiments show that the generated\npreferences can be used to improve recommendations for non-overlapped users.\nThe resultant recommendations achieve superior performance compared to the\nstate-of-the-art cross-network recommender solutions in terms of accuracy,\nnovelty and diversity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:47:44 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10849", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "LSTM Networks for Online Cross-Network Recommendations", "comments": null, "journal-ref": "International Joint Conference on Artificial Intelligence, 2018\n  (IJCAI-18)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-network recommender systems use auxiliary information from multiple\nsource networks to create holistic user profiles and improve recommendations in\na target network. However, we find two major limitations in existing\ncross-network solutions that reduce overall recommender performance. Existing\nmodels (1) fail to capture complex non-linear relationships in user\ninteractions, and (2) are designed for offline settings hence, not updated\nonline with incoming interactions to capture the dynamics in the recommender\nenvironment. We propose a novel multi-layered Long Short-Term Memory (LSTM)\nnetwork based online solution to mitigate these issues. The proposed model\ncontains three main extensions to the standard LSTM: First, an attention gated\nmechanism to capture long-term user preference changes. Second, a higher order\ninteraction layer to alleviate data sparsity. Third, time aware LSTM cell gates\nto capture irregular time intervals between user interactions. We illustrate\nour solution using auxiliary information from Twitter and Google Plus to\nimprove recommendations on YouTube. Extensive experiments show that the\nproposed model consistently outperforms state-of-the-art in terms of accuracy,\ndiversity and novelty.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:10:24 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 09:34:10 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.10869", "submitter": "David Fern\\'andez-Llorca", "authors": "David Fern\\'andez-Llorca, Mahdi Biparva, Rub\\'en Izquierdo-Gonzalo and\n  John K. Tsotsos", "title": "Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles", "comments": "This work has been accepted at the IEEE Intelligent Transportation\n  Systems Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In highway scenarios, an alert human driver will typically anticipate early\ncut-in and cut-out maneuvers of surrounding vehicles using only visual cues. An\nautomated system must anticipate these situations at an early stage too, to\nincrease the safety and the efficiency of its performance. To deal with\nlane-change recognition and prediction of surrounding vehicles, we pose the\nproblem as an action recognition/prediction problem by stacking visual cues\nfrom video cameras. Two video action recognition approaches are analyzed:\ntwo-stream convolutional networks and spatiotemporal multiplier networks.\nDifferent sizes of the regions around the vehicles are analyzed, evaluating the\nimportance of the interaction between vehicles and the context information in\nthe performance. In addition, different prediction horizons are evaluated. The\nobtained results demonstrate the potential of these methodologies to serve as\nrobust predictors of future lane-changes of surrounding vehicles in time\nhorizons between 1 and 2 seconds.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:59:15 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Fern\u00e1ndez-Llorca", "David", ""], ["Biparva", "Mahdi", ""], ["Izquierdo-Gonzalo", "Rub\u00e9n", ""], ["Tsotsos", "John K.", ""]]}, {"id": "2008.10870", "submitter": "Arunselvan Ramaswamy Dr.", "authors": "Arunselvan Ramaswamy, Eyke H\\\"ullermeier", "title": "Deep Q-Learning: Theoretical Insights from an Asymptotic Analysis", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q-Learning is an important reinforcement learning algorithm, which\ninvolves training a deep neural network, called Deep Q-Network (DQN), to\napproximate the well-known Q-function. Although wildly successful under\nlaboratory conditions, serious gaps between theory and practice as well as a\nlack of formal guarantees prevent its use in the real world. Adopting a\ndynamical systems perspective, we provide a theoretical analysis of a popular\nversion of Deep Q-Learning under realistic and verifiable assumptions. More\nspecifically, we prove an important result on the convergence of the algorithm,\ncharacterizing the asymptotic behavior of the learning process. Our result\nsheds light on hitherto unexplained properties of the algorithm and helps\nunderstand empirical observations, such as performance inconsistencies even\nafter training. Unlike previous theories, our analysis accommodates state\nMarkov processes with multiple stationary distributions. In spite of the focus\non Deep Q-Learning, we believe that our theory may be applied to understand\nother deep learning algorithms\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:59:20 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:53:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ramaswamy", "Arunselvan", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.10880", "submitter": "Rik Helwegen MSc", "authors": "Rik Helwegen, Christos Louizos and Patrick Forr\\'e", "title": "Improving Fair Predictions Using Variational Inference In Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of algorithmic fairness grows with the increasing impact\nmachine learning has on people's lives. Recent work on fairness metrics shows\nthe need for causal reasoning in fairness constraints. In this work, a\npractical method named FairTrade is proposed for creating flexible prediction\nmodels which integrate fairness constraints on sensitive causal paths. The\nmethod uses recent advances in variational inference in order to account for\nunobserved confounders. Further, a method outline is proposed which uses the\ncausal mechanism estimates to audit black box models. Experiments are conducted\non simulated data and on a real dataset in the context of detecting unlawful\nsocial welfare. This research aims to contribute to machine learning techniques\nwhich honour our ethical and legal boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:27:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Helwegen", "Rik", ""], ["Louizos", "Christos", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2008.10898", "submitter": "Zhize Li", "authors": "Zhize Li, Hongyan Bao, Xiangliang Zhang, Peter Richt\\'arik", "title": "PAGE: A Simple and Optimal Probabilistic Gradient Estimator for\n  Nonconvex Optimization", "comments": "25 pages; accepted by ICML 2021 (long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel stochastic gradient estimator --\nProbAbilistic Gradient Estimator (PAGE) -- for nonconvex optimization. PAGE is\neasy to implement as it is designed via a small adjustment to vanilla SGD: in\neach iteration, PAGE uses the vanilla minibatch SGD update with probability\n$p_t$ or reuses the previous gradient with a small adjustment, at a much lower\ncomputational cost, with probability $1-p_t$. We give a simple formula for the\noptimal choice of $p_t$. Moreover, we prove the first tight lower bound\n$\\Omega(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ for nonconvex finite-sum problems,\nwhich also leads to a tight lower bound $\\Omega(b+\\frac{\\sqrt{b}}{\\epsilon^2})$\nfor nonconvex online problems, where $b:= \\min\\{\\frac{\\sigma^2}{\\epsilon^2},\nn\\}$. Then, we show that PAGE obtains the optimal convergence results\n$O(n+\\frac{\\sqrt{n}}{\\epsilon^2})$ (finite-sum) and\n$O(b+\\frac{\\sqrt{b}}{\\epsilon^2})$ (online) matching our lower bounds for both\nnonconvex finite-sum and online problems. Besides, we also show that for\nnonconvex functions satisfying the Polyak-\\L{}ojasiewicz (PL) condition, PAGE\ncan automatically switch to a faster linear convergence rate $O(\\cdot\\log\n\\frac{1}{\\epsilon})$. Finally, we conduct several deep learning experiments\n(e.g., LeNet, VGG, ResNet) on real datasets in PyTorch showing that PAGE not\nonly converges much faster than SGD in training but also achieves the higher\ntest accuracy, validating the optimal theoretical results and confirming the\npractical superiority of PAGE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:11:31 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 18:25:41 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 21:37:35 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhize", ""], ["Bao", "Hongyan", ""], ["Zhang", "Xiangliang", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2008.10916", "submitter": "Shuxin Qin", "authors": "Shuxin Qin and Sijiang Liu", "title": "Towards End-to-end Car License Plate Location and Recognition in\n  Unconstrained Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from the rapid development of convolutional neural networks, the\nperformance of car license plate detection and recognition has been largely\nimproved. Nonetheless, challenges still exist especially for real-world\napplications. In this paper, we present an efficient and accurate framework to\nsolve the license plate detection and recognition tasks simultaneously. It is a\nlightweight and unified deep neural network, that can be optimized end-to-end\nand work in real-time. Specifically, for unconstrained scenarios, an\nanchor-free method is adopted to efficiently detect the bounding box and four\ncorners of a license plate, which are used to extract and rectify the target\nregion features. Then, a novel convolutional neural network branch is designed\nto further extract features of characters without segmentation. Finally,\nrecognition task is treated as sequence labelling problems, which are solved by\nConnectionist Temporal Classification (CTC) directly. Several public datasets\nincluding images collected from different scenarios under various conditions\nare chosen for evaluation. A large number of experiments indicate that the\nproposed method significantly outperforms the previous state-of-the-art methods\nin both speed and precision.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:51:33 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Qin", "Shuxin", ""], ["Liu", "Sijiang", ""]]}, {"id": "2008.10960", "submitter": "Julien Despois", "authors": "Julien Despois, Frederic Flament, Matthieu Perrot", "title": "AgingMapGAN (AMGAN): High-Resolution Controllable Face Aging with\n  Spatially-Aware Conditional GANs", "comments": "Project page: https://despoisj.github.io/AgingMapGAN/", "journal-ref": null, "doi": "10.1007/978-3-030-67070-2_37", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches and datasets for face aging produce results skewed\ntowards the mean, with individual variations and expression wrinkles often\ninvisible or overlooked in favor of global patterns such as the fattening of\nthe face. Moreover, they offer little to no control over the way the faces are\naged and can difficultly be scaled to large images, thus preventing their usage\nin many real-world applications. To address these limitations, we present an\napproach to change the appearance of a high-resolution image using\nethnicity-specific aging information and weak spatial supervision to guide the\naging process. We demonstrate the advantage of our proposed method in terms of\nquality, control, and how it can be used on high-definition images while\nlimiting the computational overhead.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 12:35:48 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 09:51:12 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Despois", "Julien", ""], ["Flament", "Frederic", ""], ["Perrot", "Matthieu", ""]]}, {"id": "2008.11003", "submitter": "Christoph Salge", "authors": "Christoph Salge, Emily Short, Mike Preuss, Spyridion Samothrakis and\n  Pieter Spronck", "title": "Applications of Artificial Intelligence in Live Action Role-Playing\n  Games (LARP)", "comments": "8 pages, 2 figures. Published at IEEE Conference on Games, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live Action Role-Playing (LARP) games and similar experiences are becoming a\npopular game genre. Here, we discuss how artificial intelligence techniques,\nparticularly those commonly used in AI for Games, could be applied to LARP. We\ndiscuss the specific properties of LARP that make it a surprisingly suitable\napplication field, and provide a brief overview of some existing approaches. We\nthen outline several directions where utilizing AI seems beneficial, by both\nmaking LARPs easier to organize, and by enhancing the player experience with\nelements not possible without AI.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 13:41:35 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Salge", "Christoph", ""], ["Short", "Emily", ""], ["Preuss", "Mike", ""], ["Samothrakis", "Spyridion", ""], ["Spronck", "Pieter", ""]]}, {"id": "2008.11092", "submitter": "Damien Garreau", "authors": "Damien Garreau, Ulrike von Luxburg", "title": "Looking Deeper into Tabular LIME", "comments": "63 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of machine learning algorithms is an urgent need. Numerous\nmethods appeared in recent years, but do their explanations make sense? In this\npaper, we present a thorough theoretical analysis of one of these methods,\nLIME, in the case of tabular data. We prove that in the large sample limit, the\ninterpretable coefficients provided by Tabular LIME can be computed in an\nexplicit way as a function of the algorithm parameters and some expectation\ncomputations related to the black-box model. When the function to explain has\nsome nice algebraic structure (linear, multiplicative, or sparsely depending on\na subset of the coordinates), our analysis provides interesting insights into\nthe explanations provided by LIME. These can be applied to a range of machine\nlearning models including Gaussian kernels or CART random forests. As an\nexample, for linear functions we show that LIME has the desirable property to\nprovide explanations that are proportional to the coefficients of the function\nto explain and to ignore coordinates that are not used by the function to\nexplain. For partition-based regressors, on the other side, we show that LIME\nproduces undesired artifacts that may provide misleading explanations.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 15:10:57 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 09:35:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garreau", "Damien", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "2008.11149", "submitter": "Akshat Gupta", "authors": "Akshat Gupta, Milan Desai, Wusheng Liang, Magesh Kannan", "title": "Spatiotemporal Action Recognition in Restaurant Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal action recognition is the task of locating and classifying\nactions in videos. Our project applies this task to analyzing video footage of\nrestaurant workers preparing food, for which potential applications include\nautomated checkout and inventory management. Such videos are quite different\nfrom the standardized datasets that researchers are used to, as they involve\nsmall objects, rapid actions, and notoriously unbalanced data classes. We\nexplore two approaches. The first approach involves the familiar object\ndetector You Only Look Once, and another applying a recently proposed analogue\nfor action recognition, You Only Watch Once. In the first, we design and\nimplement a novel, recurrent modification of YOLO using convolutional LSTMs and\nexplore the various subtleties in the training of such a network. In the\nsecond, we study the ability of YOWOs three dimensional convolutions to capture\nthe spatiotemporal features of our unique dataset\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 16:30:01 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Gupta", "Akshat", ""], ["Desai", "Milan", ""], ["Liang", "Wusheng", ""], ["Kannan", "Magesh", ""]]}, {"id": "2008.11174", "submitter": "Robin Strudel", "authors": "Robin Strudel, Ricardo Garcia, Justin Carpentier, Jean-Paul Laumond,\n  Ivan Laptev, Cordelia Schmid", "title": "Learning Obstacle Representations for Neural Motion Planning", "comments": "CoRL 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/nmp_repr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motion planning and obstacle avoidance is a key challenge in robotics\napplications. While previous work succeeds to provide excellent solutions for\nknown environments, sensor-based motion planning in new and dynamic\nenvironments remains difficult. In this work we address sensor-based motion\nplanning from a learning perspective. Motivated by recent advances in visual\nrecognition, we argue the importance of learning appropriate representations\nfor motion planning. We propose a new obstacle representation based on the\nPointNet architecture and train it jointly with policies for obstacle\navoidance. We experimentally evaluate our approach for rigid body motion\nplanning in challenging environments and demonstrate significant improvements\nof the state of the art in terms of accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:12:32 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 16:51:26 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 15:58:40 GMT"}, {"version": "v4", "created": "Sat, 7 Nov 2020 11:30:09 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Strudel", "Robin", ""], ["Garcia", "Ricardo", ""], ["Carpentier", "Justin", ""], ["Laumond", "Jean-Paul", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2008.11229", "submitter": "Olumide Leshi", "authors": "Olumide Leshi", "title": "Uncovering Soccer Teams Passing Strategies Using Implication Rules", "comments": "10 pages with sbc-template.sty used, 3 PNG figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal Concept Analysis FCA has seen application in different knowledge\nareas, including Social Network Analysis SNA. In turn, research has also shown\nthe applicability of SNA in assessing team sports. In this project, to uncover\nfrequent passing sequences of a soccer team, an FCA based approach is\nintroduced. The approach relies on a minimum cover of implications, the\nDuquenne Guigues DG basis and the notion that a soccer teams passes describe a\nsocial network.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:34:21 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Leshi", "Olumide", ""]]}, {"id": "2008.11258", "submitter": "Megan Charity", "authors": "Megan Charity, Dipika Rajesh, Rachel Ombok, L. B. Soros", "title": "Say \"Sul Sul!\" to SimSim, A Sims-Inspired Platform for Sandbox Game AI", "comments": "7 pages, Accepted as poster to AIIDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes environment design in the life simulation game The Sims\nas a novel platform and challenge for testing divergent search algorithms. In\nthis domain, which includes a minimal viability criterion, the goal is to\nfurnish a house with objects that satisfy the physical needs of a simulated\nagent. Importantly, the large number of objects available to the player\n(whether human or automated) affords a wide variety of solutions to the\nunderlying design problem. Empirical studies in a novel open source simulator\ncalled SimSim investigate the ability of novelty-based evolutionary algorithms\nto effectively generate viable environment designs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:31:26 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Charity", "Megan", ""], ["Rajesh", "Dipika", ""], ["Ombok", "Rachel", ""], ["Soros", "L. B.", ""]]}, {"id": "2008.11281", "submitter": "Dimitris Stripelis", "authors": "Dimitris Stripelis and Jose Luis Ambite", "title": "Accelerating Federated Learning in Heterogeneous Data and Computational\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are situations where data relevant to a machine learning problem are\ndistributed among multiple locations that cannot share the data due to\nregulatory, competitiveness, or privacy reasons. For example, data present in\nusers' cellphones, manufacturing data of companies in a given industrial\nsector, or medical records located at different hospitals. Moreover,\nparticipating sites often have different data distributions and computational\ncapabilities. Federated Learning provides an approach to learn a joint model\nover all the available data in these environments. In this paper, we introduce\na novel distributed validation weighting scheme (DVW), which evaluates the\nperformance of a learner in the federation against a distributed validation\nset. Each learner reserves a small portion (e.g., 5%) of its local training\nexamples as a validation dataset and allows other learners models to be\nevaluated against it. We empirically show that DVW results in better\nperformance compared to established methods, such as FedAvg, both under\nsynchronous and asynchronous communication protocols in data and\ncomputationally heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 21:28:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Stripelis", "Dimitris", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "2008.11329", "submitter": "Alan Chan", "authors": "Alan Chan, Kris de Asis, Richard S. Sutton", "title": "Inverse Policy Evaluation for Value-based Sequential Decision-making", "comments": "Submitted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-based methods for reinforcement learning lack generally applicable ways\nto derive behavior from a value function. Many approaches involve approximate\nvalue iteration (e.g., $Q$-learning), and acting greedily with respect to the\nestimates with an arbitrary degree of entropy to ensure that the state-space is\nsufficiently explored. Behavior based on explicit greedification assumes that\nthe values reflect those of \\textit{some} policy, over which the greedy policy\nwill be an improvement. However, value-iteration can produce value functions\nthat do not correspond to \\textit{any} policy. This is especially relevant in\nthe function-approximation regime, when the true value function can't be\nperfectly represented. In this work, we explore the use of \\textit{inverse\npolicy evaluation}, the process of solving for a likely policy given a value\nfunction, for deriving behavior from a value function. We provide theoretical\nand empirical results to show that inverse policy evaluation, combined with an\napproximate value iteration algorithm, is a feasible method for value-based\ncontrol.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 01:31:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Chan", "Alan", ""], ["de Asis", "Kris", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2008.11355", "submitter": "Fatemeh Ganji", "authors": "Fatemeh Ganji and Shahin Tajik", "title": "Physically Unclonable Functions and AI: Two Decades of Marriage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The current chapter aims at establishing a relationship between artificial\nintelligence (AI) and hardware security. Such a connection between AI and\nsoftware security has been confirmed and well-reviewed in the relevant\nliterature. The main focus here is to explore the methods borrowed from AI to\nassess the security of a hardware primitive, namely physically unclonable\nfunctions (PUFs), which has found applications in cryptographic protocols,\ne.g., authentication and key generation. Metrics and procedures devised for\nthis are further discussed. Moreover, By reviewing PUFs designed by applying AI\ntechniques, we give insight into future research directions in this area.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 02:53:40 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 16:32:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Ganji", "Fatemeh", ""], ["Tajik", "Shahin", ""]]}, {"id": "2008.11463", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Ethical behavior in humans and machines -- Evaluating training data\n  quality for beneficial machine learning", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine behavior that is based on learning algorithms can be significantly\ninfluenced by the exposure to data of different qualities. Up to now, those\nqualities are solely measured in technical terms, but not in ethical ones,\ndespite the significant role of training and annotation data in supervised\nmachine learning. This is the first study to fill this gap by describing new\ndimensions of data quality for supervised machine learning applications. Based\non the rationale that different social and psychological backgrounds of\nindividuals correlate in practice with different modes of\nhuman-computer-interaction, the paper describes from an ethical perspective how\nvarying qualities of behavioral data that individuals leave behind while using\ndigital technologies have socially relevant ramification for the development of\nmachine learning applications. The specific objective of this study is to\ndescribe how training data can be selected according to ethical assessments of\nthe behavior it originates from, establishing an innovative filter regime to\ntransition from the big data rationale n = all to a more selective way of\nprocessing data for training sets in machine learning. The overarching aim of\nthis research is to promote methods for achieving beneficial machine learning\napplications that could be widely useful for industry as well as academia.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 09:48:38 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "2008.11545", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "The Effects of Quantum Randomness on a System Exhibiting Computational\n  Creativity", "comments": "4 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present experimental results on the effects of using quantum or 'truly'\nrandom numbers, as opposed to pseudorandom numbers, in a system that exhibits\ncomputational creativity (given its ability to compose original chess\nproblems). The results indicate that using quantum random numbers too often or\ntoo seldom in the composing process does not have any positive effect on the\noutput generated. Interestingly, there is a 'sweet spot' of using quantum\nrandom numbers 15% of the time that results in fewer statistical outliers.\nOverall, it would appear that there may indeed be a slight advantage to using\nquantum random numbers in such a system and this may also be true in other\nsystems that exhibit computational creativity. The benefits of doing so should,\nhowever, be weighed against the overhead of obtaining quantum random numbers in\ncontrast to a pseudorandom number generator that is likely more convenient to\nincorporate.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 04:34:17 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 03:35:11 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "2008.11592", "submitter": "Bo Pang", "authors": "Bo Pang and Zhong-Ping Jiang", "title": "Robust Reinforcement Learning: A Case Study in Linear Quadratic\n  Regulation", "comments": "arXiv admin note: text overlap with arXiv:2005.09528", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the robustness of reinforcement learning algorithms to\nerrors in the learning process. Specifically, we revisit the benchmark problem\nof discrete-time linear quadratic regulation (LQR) and study the long-standing\nopen question: Under what conditions is the policy iteration method robustly\nstable from a dynamical systems perspective? Using advanced stability results\nin control theory, it is shown that policy iteration for LQR is inherently\nrobust to small errors in the learning process and enjoys small-disturbance\ninput-to-state stability: whenever the error in each iteration is bounded and\nsmall, the solutions of the policy iteration algorithm are also bounded, and,\nmoreover, enter and stay in a small neighbourhood of the optimal LQR solution.\nAs an application, a novel off-policy optimistic least-squares policy iteration\nfor the LQR problem is proposed, when the system dynamics are subjected to\nadditive stochastic disturbances. The proposed new results in robust\nreinforcement learning are validated by a numerical example.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 11:11:28 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 02:42:10 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 04:57:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Pang", "Bo", ""], ["Jiang", "Zhong-Ping", ""]]}, {"id": "2008.11634", "submitter": "Alvaro Cabrejas Egea", "authors": "Alvaro Cabrejas-Egea, Shaun Howell, Maksis Knutins and Colm\n  Connaughton", "title": "Assessment of Reward Functions for Reinforcement Learning Traffic Signal\n  Control under Real-World Limitations", "comments": "Conference paper, 13 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1109/SMC42975.2020.9283498", "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive traffic signal control is one key avenue for mitigating the growing\nconsequences of traffic congestion. Incumbent solutions such as SCOOT and SCATS\nrequire regular and time-consuming calibration, can't optimise well for\nmultiple road use modalities, and require the manual curation of many\nimplementation plans. A recent alternative to these approaches are deep\nreinforcement learning algorithms, in which an agent learns how to take the\nmost appropriate action for a given state of the system. This is guided by\nneural networks approximating a reward function that provides feedback to the\nagent regarding the performance of the actions taken, making it sensitive to\nthe specific reward function chosen. Several authors have surveyed the reward\nfunctions used in the literature, but attributing outcome differences to reward\nfunction choice across works is problematic as there are many uncontrolled\ndifferences, as well as different outcome metrics. This paper compares the\nperformance of agents using different reward functions in a simulation of a\njunction in Greater Manchester, UK, across various demand profiles, subject to\nreal world constraints: realistic sensor inputs, controllers, calibrated\ndemand, intergreen times and stage sequencing. The reward metrics considered\nare based on the time spent stopped, lost time, change in lost time, average\nspeed, queue length, junction throughput and variations of these magnitudes.\nThe performance of these reward functions is compared in terms of total waiting\ntime. We find that speed maximisation resulted in the lowest average waiting\ntimes across all demand levels, displaying significantly better performance\nthan other rewards previously introduced in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:47:15 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:00:15 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Cabrejas-Egea", "Alvaro", ""], ["Howell", "Shaun", ""], ["Knutins", "Maksis", ""], ["Connaughton", "Colm", ""]]}, {"id": "2008.11649", "submitter": "Masataro Asai", "authors": "Masataro Asai, Zilu Tang", "title": "Discrete Word Embedding for Logical Natural Language Understanding", "comments": "equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised neural model for learning a discrete embedding of\nwords. Unlike existing discrete embeddings, our binary embedding supports\nvector arithmetic operations similar to continuous embeddings. Our embedding\nrepresents each word as a set of propositional statements describing a\ntransition rule in classical/STRIPS planning formalism. This makes the\nembedding directly compatible with symbolic, state of the art classical\nplanning solvers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:15:18 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 14:37:59 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Asai", "Masataro", ""], ["Tang", "Zilu", ""]]}, {"id": "2008.11675", "submitter": "Karthee Sivalingam", "authors": "Nina Mujkanovic and Karthee Sivalingam and Alfio Lazzaro", "title": "Optimising AI Training Deployments using Graph Compilers and Containers", "comments": "HPEC IEEE, 6 pages, 5 figues, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) applications based on Deep Neural Networks (DNN)\nor Deep Learning (DL) have become popular due to their success in solving\nproblems likeimage analysis and speech recognition. Training a DNN is\ncomputationally intensive and High Performance Computing(HPC) has been a key\ndriver in AI growth. Virtualisation and container technology have led to the\nconvergence of cloud and HPC infrastructure. These infrastructures with diverse\nhardware increase the complexity of deploying and optimising AI training\nworkloads. AI training deployments in HPC or cloud can be optimised with\ntarget-specific libraries, graph compilers, andby improving data movement or\nIO. Graph compilers aim to optimise the execution of a DNN graph by generating\nan optimised code for a target hardware/backend. As part of SODALITE (a Horizon\n2020 project), MODAK tool is developed to optimise application deployment in\nsoftware defined infrastructures. Using input from the data scientist and\nperformance modelling, MODAK maps optimal application parameters to a target\ninfrastructure and builds an optimised container. In this paper, we introduce\nMODAK and review container technologies and graph compilers for AI. We\nillustrate optimisation of AI training deployments using graph compilers and\nSingularity containers. Evaluation using MNIST-CNN and ResNet50 training\nworkloads shows that custom built optimised containers outperform the official\nimages from DockerHub. We also found that the performance of graph compilers\ndepends on the target hardware and the complexity of the neural network.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:58:32 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 09:23:06 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mujkanovic", "Nina", ""], ["Sivalingam", "Karthee", ""], ["Lazzaro", "Alfio", ""]]}, {"id": "2008.11707", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Zhiwei Steven Wu, Rayid Ghani, Fei Fang", "title": "Bandit Data-driven Optimization: AI for Social Good and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning (ML) systems in real-world applications entails\nmore than just a prediction algorithm. AI for social good applications, and\nmany real-world ML tasks in general, feature an iterative process which joins\nprediction, optimization, and data acquisition happen in a loop. We introduce\nbandit data-driven optimization, the first iterative prediction-prescription\nframework to formally analyze this practical routine. Bandit data-driven\noptimization combines the advantages of online bandit learning and offline\npredictive analytics in an integrated framework. It offers a flexible setup to\nreason about unmodeled policy objectives and unforeseen consequences. We\npropose PROOF, the first algorithm for this framework and show that it achieves\nno-regret. Using numerical simulations, we show that PROOF achieves superior\nperformance over existing baseline.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:50:49 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Wu", "Zhiwei Steven", ""], ["Ghani", "Rayid", ""], ["Fang", "Fei", ""]]}, {"id": "2008.11719", "submitter": "Maryam Abdirad", "authors": "Maryam Abdirad, Krishna Krishnan, Deepak Gupta", "title": "A Three-Stage Algorithm for the Large Scale Dynamic Vehicle Routing\n  Problem with an Industry 4.0 Approach", "comments": "It previously appeared as arXiv:2008.04355v2. arXiv admin note: text\n  overlap with arXiv:2008.04355v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industry 4.0 is a concept which helps companies to have a smart supply chain\nsystem when they are faced with a dynamic process. As Industry 4.0 focuses on\nmobility and real-time integration, it is a good framework for a Dynamic\nVehicle Routing problem (DVRP). The main objective of this research is to solve\nthe DVRP on a large-scale size. The aim of this study is to show that the\ndelivery vehicles must serve customer demands from a common depot to have a\nminimum transit cost without exceeding the capacity constraint of each vehicle.\nIn VRP, to reach an exact solution is quite difficult, and in large-size real\nworld problems it is often impossible. Also, the computational time complexity\nof this type of problem grows exponentially. In order to find optimal answers\nfor this problem in medium and large dimensions, using a heuristic approach is\nrecommended as the best approach. A hierarchical approach consisting of three\nstages as cluster-first, route-construction second, route-improvement third is\nproposed. In the first stage, customers are clustered based on the number of\nvehicles with different clustering algorithms (i.e., K-mean, GMM, and BIRCH\nalgorithms). In the second stage, the DVRP is solved using construction\nalgorithms and in the third stage improvement algorithms are applied. The\nsecond stage is solved using construction algorithms (i.e. Savings algorithm,\npath cheapest arc algorithm, etc.). In the third stage, improvement algorithms\nsuch as Guided Local Search, Simulated Annealing and Tabu Search are applied.\nOne of the main contributions of this paper is that the proposed approach can\ndeal with large-size real world problems to decrease the computational time\ncomplexity. The results of this approach confirmed that the proposed\nmethodology is applicable.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 10:39:36 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:52:13 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Abdirad", "Maryam", ""], ["Krishnan", "Krishna", ""], ["Gupta", "Deepak", ""]]}, {"id": "2008.11721", "submitter": "Hua Shen", "authors": "Hua Shen and Ting-Hao Kenneth Huang", "title": "How Useful Are the Machine-Generated Interpretations to General Users? A\n  Human Evaluation on Guessing the Incorrectly Predicted Labels", "comments": "Accepted by The 8th AAAI Conference on Human Computation and\n  Crowdsourcing (HCOMP 2020) https://github.com/huashen218/GuessWrongLabel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining to users why automated systems make certain mistakes is important\nand challenging. Researchers have proposed ways to automatically produce\ninterpretations for deep neural network models. However, it is unclear how\nuseful these interpretations are in helping users figure out why they are\ngetting an error. If an interpretation effectively explains to users how the\nunderlying deep neural network model works, people who were presented with the\ninterpretation should be better at predicting the model's outputs than those\nwho were not. This paper presents an investigation on whether or not showing\nmachine-generated visual interpretations helps users understand the incorrectly\npredicted labels produced by image classifiers. We showed the images and the\ncorrect labels to 150 online crowd workers and asked them to select the\nincorrectly predicted labels with or without showing them the machine-generated\nvisual interpretations. The results demonstrated that displaying the visual\ninterpretations did not increase, but rather decreased, the average guessing\naccuracy by roughly 10%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:02:05 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 02:42:23 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Shen", "Hua", ""], ["Huang", "Ting-Hao Kenneth", ""]]}, {"id": "2008.11783", "submitter": "Taesup Kim", "authors": "Taesup Kim, Sungwoong Kim, Yoshua Bengio", "title": "Visual Concept Reasoning Networks", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A split-transform-merge strategy has been broadly used as an architectural\nconstraint in convolutional neural networks for visual recognition tasks. It\napproximates sparsely connected networks by explicitly defining multiple\nbranches to simultaneously learn representations with different visual concepts\nor properties. Dependencies or interactions between these representations are\ntypically defined by dense and local operations, however, without any\nadaptiveness or high-level reasoning. In this work, we propose to exploit this\nstrategy and combine it with our Visual Concept Reasoning Networks (VCRNet) to\nenable reasoning between high-level visual concepts. We associate each branch\nwith a visual concept and derive a compact concept state by selecting a few\nlocal descriptors through an attention module. These concept states are then\nupdated by graph-based interaction and used to adaptively modulate the local\ndescriptors. We describe our proposed model by\nsplit-transform-attend-interact-modulate-merge stages, which are implemented by\nopting for a highly modularized architecture. Extensive experiments on visual\nrecognition tasks such as image classification, semantic segmentation, object\ndetection, scene recognition, and action recognition show that our proposed\nmodel, VCRNet, consistently improves the performance by increasing the number\nof parameters by less than 1%.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:02:40 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kim", "Taesup", ""], ["Kim", "Sungwoong", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2008.11785", "submitter": "Guy Marshall", "authors": "Guy Clarke Marshall, Caroline Jay and Andr\\'e Freitas", "title": "Understanding scholarly Natural Language Processing system diagrams\n  through application of the Richards-Engelhardt framework", "comments": "16 pages, 5 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilise Richards-Engelhardt framework as a tool for understanding Natural\nLanguage Processing systems diagrams. Through four examples from scholarly\nproceedings, we find that the application of the framework to this ecological\nand complex domain is effective for reflecting on these diagrams. We argue for\nvocabulary to describe multiple-codings, semiotic variability, and\ninconsistency or misuse of visual encoding principles in diagrams. Further, for\napplication to scholarly Natural Language Processing systems, and perhaps\nsystems diagrams more broadly, we propose the addition of \"Grouping by Object\"\nas a new visual encoding principle, and \"Emphasising\" as a new visual encoding\ntype.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:06:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Marshall", "Guy Clarke", ""], ["Jay", "Caroline", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2008.11791", "submitter": "David Maoujoud", "authors": "David Maoujoud and Gavin Rens", "title": "Reputation-driven Decision-making in Networks of Stochastic Agents", "comments": "19 pages, including bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies multi-agent systems that involve networks of\nself-interested agents. We propose a Markov Decision Process-derived framework,\ncalled RepNet-MDP, tailored to domains in which agent reputation is a key\ndriver of the interactions between agents. The fundamentals are based on the\nprinciples of RepNet-POMDP, a framework developed by Rens et al. in 2018, but\naddresses its mathematical inconsistencies and alleviates its intractability by\nonly considering fully observable environments. We furthermore use an online\nlearning algorithm for finding approximate solutions to RepNet-MDPs. In a\nseries of experiments, RepNet agents are shown to be able to adapt their own\nbehavior to the past behavior and reliability of the remaining agents of the\nnetwork. Finally, our work identifies a limitation of the framework in its\ncurrent formulation that prevents its agents from learning in circumstances in\nwhich they are not a primary actor.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:21:04 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 07:57:32 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Maoujoud", "David", ""], ["Rens", "Gavin", ""]]}, {"id": "2008.11804", "submitter": "Brighter Agyemang", "authors": "Brighter Agyemang, Wei-Ping Wu, Daniel Addo, Michael Y. Kpiebaareh,\n  Ebenezer Nanor, Charles Roland Haruna", "title": "Deep Inverse Reinforcement Learning for Structural Evolution of Small\n  Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size and quality of chemical libraries to the drug discovery pipeline are\ncrucial for developing new drugs or repurposing existing drugs. Existing\ntechniques such as combinatorial organic synthesis and High-Throughput\nScreening usually make the process extraordinarily tough and complicated since\nthe search space of synthetically feasible drugs is exorbitantly huge. While\nreinforcement learning has been mostly exploited in the literature for\ngenerating novel compounds, the requirement of designing a reward function that\nsuccinctly represents the learning objective could prove daunting in certain\ncomplex domains. Generative Adversarial Network-based methods also mostly\ndiscard the discriminator after training and could be hard to train. In this\nstudy, we propose a framework for training a compound generator and learning a\ntransferable reward function based on the entropy maximization inverse\nreinforcement learning paradigm. We show from our experiments that the inverse\nreinforcement learning route offers a rational alternative for generating\nchemical compounds in domains where reward function engineering may be less\nappealing or impossible while data exhibiting the desired objective is readily\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 17:21:59 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 11:20:01 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Agyemang", "Brighter", ""], ["Wu", "Wei-Ping", ""], ["Addo", "Daniel", ""], ["Kpiebaareh", "Michael Y.", ""], ["Nanor", "Ebenezer", ""], ["Haruna", "Charles Roland", ""]]}, {"id": "2008.11817", "submitter": "Kien Nguyen", "authors": "Kien Nguyen, John Krumm, Cyrus Shahabi", "title": "Spatial Privacy Pricing: The Interplay between Privacy, Utility and\n  Price in Geo-Marketplaces", "comments": "10 pages, SIGSPATIAL'20", "journal-ref": null, "doi": "10.1145/3397536.3422213", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A geo-marketplace allows users to be paid for their location data. Users\nconcerned about privacy may want to charge more for data that pinpoints their\nlocation accurately, but may charge less for data that is more vague. A buyer\nwould prefer to minimize data costs, but may have to spend more to get the\nnecessary level of accuracy. We call this interplay between privacy, utility,\nand price \\emph{spatial privacy pricing}. We formalize the issues\nmathematically with an example problem of a buyer deciding whether or not to\nopen a restaurant by purchasing location data to determine if the potential\nnumber of customers is sufficient to open. The problem is expressed as a\nsequential decision making problem, where the buyer first makes a series of\ndecisions about which data to buy and concludes with a decision about opening\nthe restaurant or not. We present two algorithms to solve this problem,\nincluding experiments that show they perform better than baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:28:02 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 01:11:07 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Nguyen", "Kien", ""], ["Krumm", "John", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "2008.11830", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Xin Yang, Partha S. Roop, Marc Katzef, T\\'orur\n  Biskopst{\\o} Str{\\o}m", "title": "Designing Neural Networks for Real-Time Systems", "comments": "4 pages, 2 figures. IEEE Embedded Systems Letters, 2020", "journal-ref": null, "doi": "10.1109/LES.2020.3009910", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) are increasingly being used within\nsafety-critical Cyber-Physical Systems (CPSs). They are often co-located with\ntraditional embedded software, and may perform advisory or control-based roles.\nIt is important to validate both the timing and functional correctness of these\nsystems. However, most approaches in the literature consider guaranteeing only\nthe functionality of ANN based controllers. This issue stems largely from the\nimplementation strategies used within common neural network frameworks -- their\nunderlying source code is often simply unsuitable for formal techniques such as\nstatic timing analysis. As a result, developers of safety-critical CPS must\nrely on informal techniques such as measurement based approaches to prove\ncorrectness, techniques that provide weak guarantees at best. In this work we\naddress this challenge. We propose a design pipeline whereby neural networks\ntrained using the popular deep learning framework Keras are compiled to\nfunctionally equivalent C code. This C code is restricted to simple constructs\nthat may be analysed by existing static timing analysis tools. As a result, if\ncompiled to a suitable time-predictable platform all execution bounds may be\nstatically derived. To demonstrate the benefits of our approach we execute an\nANN trained to drive an autonomous vehicle around a race track. We compile the\nANN to the Patmos time-predictable controller, and show that we can derive\nworst case execution timings.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:41:37 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Pearce", "Hammond", ""], ["Yang", "Xin", ""], ["Roop", "Partha S.", ""], ["Katzef", "Marc", ""], ["Str\u00f8m", "T\u00f3rur Biskopst\u00f8", ""]]}, {"id": "2008.11852", "submitter": "Teng Liu", "authors": "Teng Liu, Hong Wang, Bing Lu, Jun Li, Dongpu Cao", "title": "Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement\n  Learning with Continuous Action Horizon", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making strategy for autonomous vehicles de-scribes a sequence of\ndriving maneuvers to achieve a certain navigational mission. This paper\nutilizes the deep reinforcement learning (DRL) method to address the\ncontinuous-horizon decision-making problem on the highway. First, the vehicle\nkinematics and driving scenario on the freeway are introduced. The running\nobjective of the ego automated vehicle is to execute an efficient and smooth\npolicy without collision. Then, the particular algorithm named proximal policy\noptimization (PPO)-enhanced DRL is illustrated. To overcome the challenges in\ntardy training efficiency and sample inefficiency, this applied algorithm could\nrealize high learning efficiency and excellent control performance. Finally,\nthe PPO-DRL-based decision-making strategy is estimated from multiple\nperspectives, including the optimality, learning efficiency, and adaptability.\nIts potential for online application is discussed by applying it to similar\ndriving scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:49:27 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Liu", "Teng", ""], ["Wang", "Hong", ""], ["Lu", "Bing", ""], ["Li", "Jun", ""], ["Cao", "Dongpu", ""]]}, {"id": "2008.11906", "submitter": "Oliver Biggar", "authors": "Oliver Biggar (1), Mohammad Zamani (1), Iman Shames (2) ((1) Defence\n  Science and Technology Group, Australia, (2) The Australian National\n  University, Australia)", "title": "A principled analysis of Behavior Trees and their generalisations", "comments": "13 pages, 11 figures. The content of the previous version is now\n  split between this and arXiv:2104.07919, which have both been significantly\n  updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As complex autonomous robotic systems become more widespread, the need for\ntransparent and reusable Artificial Intelligence (AI) designs becomes more\napparent. In this paper we analyse how the principles behind Behavior Trees\n(BTs), an increasingly popular tree-structured control architecture, are\napplicable to these goals. Using structured programming as a guide, we analyse\nthe BT principles of reactiveness and modularity in a formal framework of\naction selection. Proceeding from these principles, we review a number of\nchallenging use cases of BTs in the literature, and show that reasoning via\nthese principles leads to compatible solutions. Extending these arguments, we\nintroduce a new class of control architectures we call generalised BTs or\n$k$-BTs and show how they can extend the applicability of BTs to some of the\naforementioned challenging BT use cases while preserving the BT principles.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 04:09:31 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 05:42:14 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Biggar", "Oliver", ""], ["Zamani", "Mohammad", ""], ["Shames", "Iman", ""]]}, {"id": "2008.12001", "submitter": "Wei Fan", "authors": "Wei Fan, Kunpeng Liu, Hao Liu, Pengyang Wang, Yong Ge and Yanjie Fu", "title": "AutoFS: Automated Feature Selection via Diversity-aware Interactive\n  Reinforcement Learning", "comments": "Accepted by ICDM 2020. In this version, we revised some typos or\n  mistakes for camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of balancing effectiveness and efficiency\nin automated feature selection. Feature selection is a fundamental intelligence\nfor machine learning and predictive analysis. After exploring many feature\nselection methods, we observe a computational dilemma: 1) traditional feature\nselection methods (e.g., mRMR) are mostly efficient, but difficult to identify\nthe best subset; 2) the emerging reinforced feature selection methods\nautomatically navigate feature space to explore the best subset, but are\nusually inefficient. Are automation and efficiency always apart from each\nother? Can we bridge the gap between effectiveness and efficiency under\nautomation? Motivated by such a computational dilemma, this study is to develop\na novel feature space navigation method. To that end, we propose an Interactive\nReinforced Feature Selection (IRFS) framework that guides agents by not just\nself-exploration experience, but also diverse external skilled trainers to\naccelerate learning for feature exploration. Specifically, we formulate the\nfeature selection problem into an interactive reinforcement learning framework.\nIn this framework, we first model two trainers skilled at different searching\nstrategies: (1) KBest based trainer; (2) Decision Tree based trainer. We then\ndevelop two strategies: (1) to identify assertive and hesitant agents to\ndiversify agent training, and (2) to enable the two trainers to take the\nteaching role in different stages to fuse the experiences of the trainers and\ndiversify teaching process. Such a hybrid teaching strategy can help agents to\nlearn broader knowledge, and, thereafter, be more effective. Finally, we\npresent extensive experiments on real-world datasets to demonstrate the\nimproved performances of our method: more efficient than existing reinforced\nselection and more effective than classic selection.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:11:30 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 05:15:32 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 08:12:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fan", "Wei", ""], ["Liu", "Kunpeng", ""], ["Liu", "Hao", ""], ["Wang", "Pengyang", ""], ["Ge", "Yong", ""], ["Fu", "Yanjie", ""]]}, {"id": "2008.12003", "submitter": "Nikolaos Tziortziotis", "authors": "Yang Qiu, Nikolaos Tziortziotis, Martial Hue, Michalis Vazirgiannis", "title": "Predicting conversions in display advertising based on URL embeddings", "comments": "Accepted at AdKDD 2020 workshop at KDD'20 conference, San Diego, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online display advertising is growing rapidly in recent years thanks to the\nautomation of the ad buying process. Real-time bidding (RTB) allows the\nautomated trading of ad impressions between advertisers and publishers through\nreal-time auctions. In order to increase the effectiveness of their campaigns,\nadvertisers should deliver ads to the users who are highly likely to be\nconverted (i.e., purchase, registration, website visit, etc.) in the near\nfuture. In this study, we introduce and examine different models for estimating\nthe probability of a user converting, given their history of visited URLs.\nInspired by natural language processing, we introduce three URL embedding\nmodels to compute semantically meaningful URL representations. To demonstrate\nthe effectiveness of the different proposed representation and conversion\nprediction models, we have conducted experiments on real logged events\ncollected from an advertising platform.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:14:28 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 09:09:26 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Qiu", "Yang", ""], ["Tziortziotis", "Nikolaos", ""], ["Hue", "Martial", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2008.12065", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Astin-Walmsley Kieren, Heath Kerina, Richi Nayak", "title": "Propensity-to-Pay: Machine Learning for Estimating Prediction\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting a customer's propensity-to-pay at an early point in the revenue\ncycle can provide organisations many opportunities to improve the customer\nexperience, reduce hardship and reduce the risk of impaired cash flow and\noccurrence of bad debt. With the advancements in data science; machine learning\ntechniques can be used to build models to accurately predict a customer's\npropensity-to-pay. Creating effective machine learning models without access to\nlarge and detailed datasets presents some significant challenges. This paper\npresents a case-study, conducted on a dataset from an energy organisation, to\nexplore the uncertainty around the creation of machine learning models that are\nable to predict residential customers entering financial hardship which then\nreduces their ability to pay energy bills. Incorrect predictions can result in\ninefficient resource allocation and vulnerable customers not being proactively\nidentified. This study investigates machine learning models' ability to\nconsider different contexts and estimate the uncertainty in the prediction.\nSeven models from four families of machine learning algorithms are investigated\nfor their novel utilisation. A novel concept of utilising a Baysian Neural\nNetwork to the binary classification problem of propensity-to-pay energy bills\nis proposed and explored for deployment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 11:49:25 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Bashar", "Md Abul", ""], ["Kieren", "Astin-Walmsley", ""], ["Kerina", "Heath", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.12095", "submitter": "Katya Kudashkina", "authors": "Katya Kudashkina, Patrick M. Pilarski, Richard S. Sutton", "title": "Document-editing Assistants and Model-based Reinforcement Learning as a\n  Path to Conversational AI", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent assistants that follow commands or answer simple questions, such\nas Siri and Google search, are among the most economically important\napplications of AI. Future conversational AI assistants promise even greater\ncapabilities and a better user experience through a deeper understanding of the\ndomain, the user, or the user's purposes. But what domain and what methods are\nbest suited to researching and realizing this promise? In this article we argue\nfor the domain of voice document editing and for the methods of model-based\nreinforcement learning. The primary advantages of voice document editing are\nthat the domain is tightly scoped and that it provides something for the\nconversation to be about (the document) that is delimited and fully accessible\nto the intelligent assistant. The advantages of reinforcement learning in\ngeneral are that its methods are designed to learn from interaction without\nexplicit instruction and that it formalizes the purposes of the assistant.\nModel-based reinforcement learning is needed in order to genuinely understand\nthe domain of discourse and thereby work efficiently with the user to achieve\ntheir goals. Together, voice document editing and model-based reinforcement\nlearning comprise a promising research direction for achieving conversational\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 13:05:51 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Kudashkina", "Katya", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "2008.12096", "submitter": "Bernd Dudzik", "authors": "Bernd Dudzik, Joost Broekens, Mark Neerincx, Hayley Hung", "title": "A Blast From the Past: Personalizing Predictions of Video-Induced\n  Emotions using Personal Memories as Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in the accurate prediction of viewers' emotional responses to\nvideo stimuli in real-world applications is accounting for person- and\nsituation-specific variation. An important contextual influence shaping\nindividuals' subjective experience of a video is the personal memories that it\ntriggers in them. Prior research has found that this memory influence explains\nmore variation in video-induced emotions than other contextual variables\ncommonly used for personalizing predictions, such as viewers' demographics or\npersonality. In this article, we show that (1) automatic analysis of text\ndescribing their video-triggered memories can account for variation in viewers'\nemotional responses, and (2) that combining such an analysis with that of a\nvideo's audiovisual content enhances the accuracy of automatic predictions. We\ndiscuss the relevance of these findings for improving on state of the art\napproaches to automated affective video analysis in personalized contexts.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 13:06:10 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Dudzik", "Bernd", ""], ["Broekens", "Joost", ""], ["Neerincx", "Mark", ""], ["Hung", "Hayley", ""]]}, {"id": "2008.12097", "submitter": "Marcos Baez", "authors": "Pietro Chitt\\`o and Marcos Baez and Florian Daniel and Boualem\n  Benatallah", "title": "Automatic Generation of Chatbots for Conversational Web Browsing", "comments": "typos corrected, metadata fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the foundations for generating a chatbot out of a\nwebsite equipped with simple, bot-specific HTML annotations. The approach is\npart of what we call conversational web browsing, i.e., a dialog-based, natural\nlanguage interaction with websites. The goal is to enable users to use content\nand functionality accessible through rendered UIs by \"talking to websites\"\ninstead of by operating the graphical UI using keyboard and mouse. The chatbot\nmediates between the user and the website, operates its graphical UI on behalf\nof the user, and informs the user about the state of interaction. We describe\nthe conceptual vocabulary and annotation format, the supporting conversational\nmiddleware and techniques, and the implementation of a demo able to deliver\nconversational web browsing experiences through Amazon Alexa.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:10:28 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 10:15:47 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chitt\u00f2", "Pietro", ""], ["Baez", "Marcos", ""], ["Daniel", "Florian", ""], ["Benatallah", "Boualem", ""]]}, {"id": "2008.12114", "submitter": "Rafael Morales Gamboa", "authors": "Rafael Morales-Gamboa, L. Enrique Sucar", "title": "Competence-Based Student Modelling with Dynamic Bayesian Networks", "comments": "Artificial Intelligence Applied to Education. 22 pages, 9 tables, 9\n  figures. Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for using a competences map, created by defining\ngeneralization/specialization and inclusion/part-of relationships between\ncompetences, in order to build an overlay student model in the form of a\ndynamic Bayesian network in which conditional probability distributions are\ndefined per relationship type. We have created a competences map for a subset\nof the transversal competences defined as educational goals for the Mexican\nhigh school system, then we have built a dynamic Bayesian student model as said\nbefore, and we have use it to trace the development of the corresponding\ncompetences by some hypothetical students exhibiting representative\nperformances along an online course (low to medium performance, medium to high\nperformance but with low final score, and two terms medium to high\nperformance). The results obtained suggest that the proposed way for\nconstructing dynamic Bayesian student models on the basis of competences maps\ncould be useful to monitor competence development by real students in online\ncourse.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:08:04 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Morales-Gamboa", "Rafael", ""], ["Sucar", "L. Enrique", ""]]}, {"id": "2008.12146", "submitter": "Sandhya Saisubramanian", "authors": "Sandhya Saisubramanian and Shlomo Zilberstein and Ece Kamar", "title": "Avoiding Negative Side Effects due to Incomplete Knowledge of AI Systems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents acting in the real-world often operate based on models that\nignore certain aspects of the environment. The incompleteness of any given\nmodel---handcrafted or machine acquired---is inevitable due to practical\nlimitations of any modeling technique for complex real-world settings. Due to\nthe limited fidelity of its model, an agent's actions may have unexpected,\nundesirable consequences during execution. Learning to recognize and avoid such\nnegative side effects of the agent's actions is critical to improving the\nsafety and reliability of autonomous systems. This emerging research topic is\nattracting increased attention due to the increased deployment of AI systems\nand their broad societal impacts. This article provides a comprehensive\noverview of different forms of negative side effects and the recent research\nefforts to address them. We identify key characteristics of negative side\neffects, highlight the challenges in avoiding negative side effects, and\ndiscuss recently developed approaches, contrasting their benefits and\nlimitations. We conclude with a discussion of open questions and suggestions\nfor future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 16:48:46 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 15:36:04 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""], ["Kamar", "Ece", ""]]}, {"id": "2008.12210", "submitter": "Mo Hossny", "authors": "Mohammed Hossny and Julie Iskander", "title": "Biomechanic Posture Stabilisation via Iterative Training of Multi-policy\n  Deep Reinforcement Learning Agents", "comments": "Content: 12 pages, 6 figures. \\c{opyright} 2020. This manuscript\n  version is made available under the CC-BY-NC-ND 4.0 license\n  http://creativecommons.org/licenses/by- nc-nd/4.0/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not until we become senior citizens do we recognise how much we took\nmaintaining a simple standing posture for granted. It is truly fascinating to\nobserve the magnitude of control the human brain exercises, in real time, to\nactivate and deactivate the lower body muscles and solve a multi-link 3D\ninverted pendulum problem in order to maintain a stable standing posture. This\nrealisation is even more apparent when training an artificial intelligence (AI)\nagent to maintain a standing posture of a digital musculoskeletal avatar due to\nthe error propagation problem. In this work we address the error propagation\nproblem by introducing an iterative training procedure for deep reinforcement\nlearning which allows the agent to learn a finite set of actions and how to\ncoordinate between them in order to achieve a stable standing posture. The\nproposed training approach allowed the agent to increase standing duration from\n4 seconds using the traditional training method to 348 seconds using the\nproposed method. The proposed training method allowed the agent to generalise\nand accommodate perception and actuation noise for almost 108 seconds.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 05:58:10 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hossny", "Mohammed", ""], ["Iskander", "Julie", ""]]}, {"id": "2008.12219", "submitter": "Sergei Nechaev", "authors": "O.V. Valba, A.S. Gorsky, S.K. Nechaev, and M.V. Tamm", "title": "Analysis of English free association network reveals mechanisms of\n  efficient solution of Remote Association Tests", "comments": "16 pages, 4 figures, 3 tables (article is substantially revised)", "journal-ref": null, "doi": "10.1371/journal.pone.0248986", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study correlations between the structure and properties of a free\nassociation network of the English language, and solutions of psycholinguistic\nRemote Association Tests (RATs). We show that average hardness of individual\nRATs is largely determined by relative positions of test words (stimuli and\nresponse) on the free association network. We argue that the solution of RATs\ncan be interpreted as a first passage search problem on a network whose\nvertices are words and links are associations between words. We propose\ndifferent heuristic search algorithms and demonstrate that in \"easily-solving\"\nRATs (those that are solved in 15 seconds by more than 64\\% subjects) the\nsolution is governed by \"strong\" network links (i.e. strong associations)\ndirectly connecting stimuli and response, and thus the efficient strategy\nconsist in activating such strong links. In turn, the most efficient mechanism\nof solving medium and hard RATs consists of preferentially following sequence\nof \"moderately weak\" associations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:17:38 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 17:30:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Valba", "O. V.", ""], ["Gorsky", "A. S.", ""], ["Nechaev", "S. K.", ""], ["Tamm", "M. V.", ""]]}, {"id": "2008.12228", "submitter": "Tim Hertweck", "authors": "Roland Hafner, Tim Hertweck, Philipp Kl\\\"oppner, Michael Bloesch,\n  Michael Neunert, Markus Wulfmeier, Saran Tunyasuvunakool, Nicolas Heess,\n  Martin Riedmiller", "title": "Towards General and Autonomous Learning of Core Skills: A Case Study in\n  Locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Reinforcement Learning (RL) algorithms promise to solve difficult\nmotor control problems directly from raw sensory inputs. Their attraction is\ndue in part to the fact that they can represent a general class of methods that\nallow to learn a solution with a reasonably set reward and minimal prior\nknowledge, even in situations where it is difficult or expensive for a human\nexpert. For RL to truly make good on this promise, however, we need algorithms\nand learning setups that can work across a broad range of problems with minimal\nproblem specific adjustments or engineering. In this paper, we study this idea\nof generality in the locomotion domain. We develop a learning framework that\ncan learn sophisticated locomotion behavior for a wide spectrum of legged\nrobots, such as bipeds, tripeds, quadrupeds and hexapods, including wheeled\nvariants. Our learning framework relies on a data-efficient, off-policy\nmulti-task RL algorithm and a small set of reward functions that are\nsemantically identical across robots. To underline the general applicability of\nthe method, we keep the hyper-parameter settings and reward definitions\nconstant across experiments and rely exclusively on on-board sensing. For nine\ndifferent types of robots, including a real-world quadruped robot, we\ndemonstrate that the same algorithm can rapidly learn diverse and reusable\nlocomotion skills without any platform specific adjustments or additional\ninstrumentation of the learning setup.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:23:55 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Hafner", "Roland", ""], ["Hertweck", "Tim", ""], ["Kl\u00f6ppner", "Philipp", ""], ["Bloesch", "Michael", ""], ["Neunert", "Michael", ""], ["Wulfmeier", "Markus", ""], ["Tunyasuvunakool", "Saran", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2008.12234", "submitter": "Audrunas Gruslys", "authors": "Audr\\=unas Gruslys, Marc Lanctot, R\\'emi Munos, Finbarr Timbers,\n  Martin Schmid, Julien Perolat, Dustin Morrill, Vinicius Zambaldi,\n  Jean-Baptiste Lespiau, John Schultz, Mohammad Gheshlaghi Azar, Michael\n  Bowling, and Karl Tuyls", "title": "The Advantage Regret-Matching Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization has played a key role in online learning, equilibrium\ncomputation in games, and reinforcement learning (RL). In this paper, we\ndescribe a general model-free RL method for no-regret learning based on\nrepeated reconsideration of past behavior. We propose a model-free RL\nalgorithm, the AdvantageRegret-Matching Actor-Critic (ARMAC): rather than\nsaving past state-action data, ARMAC saves a buffer of past policies, replaying\nthrough them to reconstruct hindsight assessments of past behavior. These\nretrospective value estimates are used to predict conditional advantages which,\ncombined with regret matching, produces a new policy. In particular, ARMAC\nlearns from sampled trajectories in a centralized training setting, without\nrequiring the application of importance sampling commonly used in Monte Carlo\ncounterfactual regret (CFR) minimization; hence, it does not suffer from\nexcessive variance in large environments. In the single-agent setting, ARMAC\nshows an interesting form of exploration by keeping past policies intact. In\nthe multiagent setting, ARMAC in self-play approaches Nash equilibria on some\npartially-observable zero-sum benchmarks. We provide exploitability estimates\nin the significantly larger game of betting-abstracted no-limit Texas Hold'em.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 16:30:17 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Gruslys", "Audr\u016bnas", ""], ["Lanctot", "Marc", ""], ["Munos", "R\u00e9mi", ""], ["Timbers", "Finbarr", ""], ["Schmid", "Martin", ""], ["Perolat", "Julien", ""], ["Morrill", "Dustin", ""], ["Zambaldi", "Vinicius", ""], ["Lespiau", "Jean-Baptiste", ""], ["Schultz", "John", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Bowling", "Michael", ""], ["Tuyls", "Karl", ""]]}, {"id": "2008.12330", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "The Impact of Discretization Method on the Detection of Six Types of\n  Anomalies in Datasets", "comments": "16 pages, 5 figures, 2 tables. Presented at the 30th Benelux\n  Conference on Artificial Intelligence (BNAIC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is the process of identifying cases, or groups of cases,\nthat are in some way unusual and do not fit the general patterns present in the\ndataset. Numerous algorithms use discretization of numerical data in their\ndetection processes. This study investigates the effect of the discretization\nmethod on the unsupervised detection of each of the six anomaly types\nacknowledged in a recent typology of data anomalies. To this end, experiments\nare conducted with various datasets and SECODA, a general-purpose algorithm for\nunsupervised non-parametric anomaly detection in datasets with numerical and\ncategorical attributes. This algorithm employs discretization of continuous\nattributes, exponentially increasing weights and discretization cut points, and\na pruning heuristic to detect anomalies with an optimal number of iterations.\nThe results demonstrate that standard SECODA can detect all six types, but that\ndifferent discretization methods favor the discovery of certain anomaly types.\nThe main findings also hold for other detection techniques using\ndiscretization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:43:55 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2008.12333", "submitter": "Marcus Badgeley", "authors": "Gabe Schamberg, Marcus Badgeley, and Emery N. Brown", "title": "Controlling Level of Unconsciousness by Titrating Propofol with Deep\n  Reinforcement Learning", "comments": "International Conference on Artificial Intelligence in Medicine 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) can be used to fit a mapping from patient state\nto a medication regimen. Prior studies have used deterministic and value-based\ntabular learning to learn a propofol dose from an observed anesthetic state.\nDeep RL replaces the table with a deep neural network and has been used to\nlearn medication regimens from registry databases. Here we perform the first\napplication of deep RL to closed-loop control of anesthetic dosing in a\nsimulated environment. We use the cross-entropy method to train a deep neural\nnetwork to map an observed anesthetic state to a probability of infusing a\nfixed propofol dosage. During testing, we implement a deterministic policy that\ntransforms the probability of infusion to a continuous infusion rate. The model\nis trained and tested on simulated pharmacokinetic/pharmacodynamic models with\nrandomized parameters to ensure robustness to patient variability. The deep RL\nagent significantly outperformed a proportional-integral-derivative controller\n(median absolute performance error 1.7% +/- 0.6 and 3.4% +/- 1.2). Modeling\ncontinuous input variables instead of a table affords more robust pattern\nrecognition and utilizes our prior domain knowledge. Deep RL learned a smooth\npolicy with a natural interpretation to data scientists and anesthesia care\nproviders alike.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 18:47:08 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:24:47 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Schamberg", "Gabe", ""], ["Badgeley", "Marcus", ""], ["Brown", "Emery N.", ""]]}, {"id": "2008.12342", "submitter": "Jakob Kotas", "authors": "Jakob Kotas, Peter Pham, Sam Koellmann", "title": "Optimal minimal-perturbation university timetabling with faculty\n  preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the university timetabling problem, sometimes additions or cancellations\nof course sections occur shortly before the beginning of the academic term,\nnecessitating last-minute teaching staffing changes. We present a\ndecision-making framework that both minimizes the number of course swaps, which\nare inconvenient to faculty members, and maximizes faculty members' preferences\nfor times they wish to teach. The model is formulated as an integer linear\nprogram (ILP). Numerical simulations for a hypothetical mid-sized academic\ndepartment are presented.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:11:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kotas", "Jakob", ""], ["Pham", "Peter", ""], ["Koellmann", "Sam", ""]]}, {"id": "2008.12348", "submitter": "Abigail See", "authors": "Ashwin Paranjape, Abigail See, Kathleen Kenealy, Haojun Li, Amelia\n  Hardy, Peng Qi, Kaushik Ram Sadagopan, Nguyet Minh Phu, Dilara Soylu,\n  Christopher D. Manning", "title": "Neural Generation Meets Real People: Towards Emotionally Engaging\n  Mixed-Initiative Conversations", "comments": "Published in 3rd Proceedings of Alexa Prize (Alexa Prize 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Chirpy Cardinal, an open-domain dialogue agent, as a research\nplatform for the 2019 Alexa Prize competition. Building an open-domain\nsocialbot that talks to real people is challenging - such a system must meet\nmultiple user expectations such as broad world knowledge, conversational style,\nand emotional connection. Our socialbot engages users on their terms -\nprioritizing their interests, feelings and autonomy. As a result, our socialbot\nprovides a responsive, personalized user experience, capable of talking\nknowledgeably about a wide variety of topics, as well as chatting\nempathetically about ordinary life. Neural generation plays a key role in\nachieving these goals, providing the backbone for our conversational and\nemotional tone. At the end of the competition, Chirpy Cardinal progressed to\nthe finals with an average rating of 3.6/5.0, a median conversation duration of\n2 minutes 16 seconds, and a 90th percentile duration of over 12 minutes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:37:27 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 17:14:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Paranjape", "Ashwin", ""], ["See", "Abigail", ""], ["Kenealy", "Kathleen", ""], ["Li", "Haojun", ""], ["Hardy", "Amelia", ""], ["Qi", "Peng", ""], ["Sadagopan", "Kaushik Ram", ""], ["Phu", "Nguyet Minh", ""], ["Soylu", "Dilara", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2008.12401", "submitter": "John Thomson", "authors": "Sizhe Yuen, John D. Thomson, Oliver Don", "title": "Automatic Player Identification in Dota 2", "comments": "11 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dota 2 is a popular, multiplayer online video game. Like many online games,\nplayers are mostly anonymous, being tied only to online accounts which can be\nreadily obtained, sold and shared between multiple people. This makes it\ndifficult to track or ban players who exhibit unwanted behavior online. In this\npaper, we present a machine learning approach to identify players based a\n`digital fingerprint' of how they play the game, rather than by account. We use\ndata on mouse movements, in-game statistics and game strategy extracted from\nmatch replays and show that for best results, all of these are necessary. We\nare able to obtain an accuracy of prediction of 95\\% for the problem of\npredicting if two different matches were played by the same player.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 22:58:01 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Yuen", "Sizhe", ""], ["Thomson", "John D.", ""], ["Don", "Oliver", ""]]}, {"id": "2008.12429", "submitter": "Seyedali Meghdadi Mr", "authors": "Seyedali Meghdadi, Guido Tack, Ariel Liebman", "title": "Data-Driven Security Assessment of the Electric Power System", "comments": null, "journal-ref": "2019 9th International Conference on Power and Energy Systems\n  (ICPES), Perth, Australia, 2019, pp. 1-6", "doi": "10.1109/ICPES47639.2019.9105621", "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transition to a new low emission energy future results in a changing mix\nof generation and load types due to significant growth in renewable energy\npenetration and reduction in system inertia due to the exit of ageing fossil\nfuel power plants. This increases technical challenges for electrical grid\nplanning and operation. This study introduces a new decomposition approach to\naccount for the system security for short term planning using conventional\nmachine learning tools. The immediate value of this work is that it provides\nextendable and computationally efficient guidelines for using supervised\nlearning tools to assess first swing transient stability status. To provide an\nunbiased evaluation of the final model fit on the training dataset, the\nproposed approach was examined on a previously unseen test set. It\ndistinguished stable and unstable cases in the test set accurately, with only\n0.57% error, and showed a high precision in predicting the time of instability,\nwith 6.8% error and mean absolute error as small as 0.0145.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 01:37:21 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Meghdadi", "Seyedali", ""], ["Tack", "Guido", ""], ["Liebman", "Ariel", ""]]}, {"id": "2008.12515", "submitter": "Oliver Biggar", "authors": "Oliver Biggar (1), Mohammad Zamani (1), Iman Shames (2) ((1) Defence\n  Science and Technology Group, Australia, (2) University of Melbourne)", "title": "On modularity in reactive control architectures, with an application to\n  formal verification", "comments": "Submitted to ACM Transactions on Cyber-Physical Systems. 26 pages, 9\n  figures. Version 2 changes: minor corrections, particularly Definition 6.19\n  and the proof of Lemma 6.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modularity is a central principle throughout the design process for\ncyber-physical systems. Modularity reduces complexity and increases reuse of\nbehavior. In this paper we pose and answer the following question: how can we\nidentify independent `modules' within the structure of reactive control\narchitectures? To this end, we propose a graph-structured control architecture\nwe call a decision structure, and show how it generalises some reactive control\narchitectures which are popular in Artificial Intelligence (AI) and robotics,\nspecifically Teleo-Reactive programs (TRs), Decision Trees (DTs), Behavior\nTrees (BTs) and Generalised Behavior Trees ($k$-BTs). Inspired by the\ndefinition of a module in graph theory, we define modules in decision\nstructures and show how each decision structure possesses a canonical\ndecomposition into its modules. We can naturally characterise each of the BTs,\n$k$-BTs, DTs and TRs by properties of their module decomposition. This allows\nus to recognise which decision structures are equivalent to each of these\narchitectures in quadratic time. Our proposed concept of modules extends to\nformal verification, under any verification scheme capable of verifying a\ndecision structure. Namely, we prove that a modification to a module within a\ndecision structure has no greater flow-on effects than a modification to an\nindividual action within that structure. This enables verification on modules\nto be done locally and hierarchically, where structures can be verified and\nthen repeatedly locally modified, with modules replaced by modules while\npreserving correctness. To illustrate the findings, we present an example of a\nsolar-powered drone controlled by a decision structure. We use a Linear\nTemporal Logic-based verification scheme to verify the correctness of this\nstructure, and then show how one can modify modules while preserving its\ncorrectness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:25:38 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 07:22:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Biggar", "Oliver", ""], ["Zamani", "Mohammad", ""], ["Shames", "Iman", ""]]}, {"id": "2008.12566", "submitter": "Guy Marshall", "authors": "Guy Clarke Marshall, Andr\\'e Freitas, Caroline Jay", "title": "How Researchers Use Diagrams in Communicating Neural Network Systems", "comments": "19 pages, 6 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a prevalent and effective machine learning component, and\ntheir application is leading to significant scientific progress in many\ndomains. As the field of neural network systems is fast growing, it is\nimportant to understand how advances are communicated. Diagrams are key to\nthis, appearing in almost all papers describing novel systems. This paper\nreports on a study into the use of neural network system diagrams, through\ninterviews, card sorting, and qualitative feedback structured around\necologically-derived examples. We find high diversity of usage, perception and\npreference in both creation and interpretation of diagrams, examining this in\nthe context of existing design, information visualisation, and user experience\nguidelines. Considering the interview data alongside existing guidance, we\npropose guidelines aiming to improve the way in which neural network system\ndiagrams are constructed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:21:03 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 09:59:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Marshall", "Guy Clarke", ""], ["Freitas", "Andr\u00e9", ""], ["Jay", "Caroline", ""]]}, {"id": "2008.12568", "submitter": "Pedro Mediano", "authors": "Fernando E. Rosas, Pedro A.M. Mediano, Martin Biehl, Shamil Chandaria,\n  Daniel Polani", "title": "Causal blankets: Theory and algorithmic framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework to identify perception-action loops (PALOs)\ndirectly from data based on the principles of computational mechanics. Our\napproach is based on the notion of causal blanket, which captures sensory and\nactive variables as dynamical sufficient statistics -- i.e. as the \"differences\nthat make a difference.\" Moreover, our theory provides a broadly applicable\nprocedure to construct PALOs that requires neither a steady-state nor Markovian\ndynamics. Using our theory, we show that every bipartite stochastic process has\na causal blanket, but the extent to which this leads to an effective PALO\nformulation varies depending on the integrated information of the bipartition.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:26:17 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 10:11:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Rosas", "Fernando E.", ""], ["Mediano", "Pedro A. M.", ""], ["Biehl", "Martin", ""], ["Chandaria", "Shamil", ""], ["Polani", "Daniel", ""]]}, {"id": "2008.12579", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Yejin Bang, Pascale Fung", "title": "The Adapter-Bot: All-In-One Controllable Conversational Model", "comments": "Andrea Madotto and Zhaojiang Lin contributed equally to this work.\n  Video demo: https://www.youtube.com/watch?v=Jz8KWE_gKH0&feature=youtu.be", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable progress has been made towards conversational models that\ngenerate coherent and fluent responses by training large language models on\nlarge dialogue datasets. These models have little or no control of the\ngenerated responses and miss two important features: continuous dialogue skills\nintegration and seamlessly leveraging diverse knowledge sources. In this paper,\nwe propose the Adapter-Bot, a dialogue model that uses a fixed backbone\nconversational model such as DialGPT (Zhang et al., 2019) and triggers\non-demand dialogue skills (e.g., emphatic response, weather information, movie\nrecommendation) via different adapters (Houlsby et al., 2019). Each adapter can\nbe trained independently, thus allowing a continual integration of skills\nwithout retraining the entire model. Depending on the skills, the model is able\nto process multiple knowledge types, such as text, tables, and graphs, in a\nseamless manner. The dialogue skills can be triggered automatically via a\ndialogue manager, or manually, thus allowing high-level control of the\ngenerated responses. At the current stage, we have implemented 12 response\nstyles (e.g., positive, negative etc.), 8 goal-oriented skills (e.g. weather\ninformation, movie recommendation, etc.), and personalized and emphatic\nresponses. We evaluate our model using automatic evaluation by comparing it\nwith existing state-of-the-art conversational models, and we have released an\ninteractive system at adapter.bot.ust.hk.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:59:31 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 02:44:30 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Bang", "Yejin", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.12613", "submitter": "Kiara Grouwstra", "authors": "Kiara Grouwstra", "title": "Type-driven Neural Programming by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this thesis we look into programming by example (PBE), which is about\nfinding a program mapping given inputs to given outputs. PBE has traditionally\nseen a split between formal versus neural approaches, where formal approaches\ntypically involve deductive techniques such as SAT solvers and types, while the\nneural approaches involve training on sample input-outputs with their\ncorresponding program, typically using sequence-based machine learning\ntechniques such as LSTMs [41]. As a result of this split, programming types had\nyet to be used in neural program synthesis techniques.\n  We propose a way to incorporate programming types into a neural program\nsynthesis approach for PBE. We introduce the Typed Neuro-Symbolic Program\nSynthesis (TNSPS) method based on this idea, and test it in the functional\nprogramming context to empirically verify type information may help improve\ngeneralization in neural synthesizers on limited-size datasets.\n  Our TNSPS model builds upon the existing Neuro-Symbolic Program Synthesis\n(NSPS), a tree-based neural synthesizer combining info from input-output\nexamples plus the current program, by further exposing information on types of\nthose input-output examples, of the grammar production rules, as well as of the\nhole that we wish to expand in the program.\n  We further explain how we generated a dataset within our domain, which uses a\nlimited subset of Haskell as the synthesis language. Finally we discuss several\ntopics of interest that may help take these ideas further. For reproducibility,\nwe release our code publicly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 12:30:05 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 17:42:54 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 11:00:05 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 17:58:09 GMT"}, {"version": "v5", "created": "Thu, 17 Sep 2020 09:51:08 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Grouwstra", "Kiara", ""]]}, {"id": "2008.12615", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "An Impact Model of AI on the Principles of Justice: Encompassing the\n  Autonomous Levels of AI Legal Reasoning", "comments": "19 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2008.10575, arXiv:2008.09507, arXiv:2008.07743", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts furthering the advancement of Artificial Intelligence (AI) will\nincreasingly encompass AI Legal Reasoning (AILR) as a crucial element in the\npractice of law. It is argued in this research paper that the infusion of AI\ninto existing and future legal activities and the judicial structure needs to\nbe undertaken by mindfully observing an alignment with the core principles of\njustice. As such, the adoption of AI has a profound twofold possibility of\neither usurping the principles of justice, doing so in a Dystopian manner, and\nyet also capable to bolster the principles of justice, doing so in a Utopian\nway. By examining the principles of justice across the Levels of Autonomy (LoA)\nof AI Legal Reasoning, the case is made that there is an ongoing tension\nunderlying the efforts to develop and deploy AI that can demonstrably determine\nthe impacts and sway upon each core principle of justice and the collective\nset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 22:56:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2008.12624", "submitter": "Pedro Braga", "authors": "Hansenclever F. Bassani, Renie A. Delgado, Jos\\'e Nilton de O. Lima\n  Junior, Heitor R. Medeiros, Pedro H. M. Braga, Mateus G. Machado, Lucas H. C.\n  Santos and Alain Tapp", "title": "A Framework for Studying Reinforcement Learning and Sim-to-Real in Robot\n  Soccer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article introduces an open framework, called VSSS-RL, for studying\nReinforcement Learning (RL) and sim-to-real in robot soccer, focusing on the\nIEEE Very Small Size Soccer (VSSS) league. We propose a simulated environment\nin which continuous or discrete control policies can be trained to control the\ncomplete behavior of soccer agents and a sim-to-real method based on domain\nadaptation to adapt the obtained policies to real robots. Our results show that\nthe trained policies learned a broad repertoire of behaviors that are difficult\nto implement with handcrafted control policies. With VSSS-RL, we were able to\nbeat human-designed policies in the 2019 Latin American Robotics Competition\n(LARC), achieving 4th place out of 21 teams, being the first to apply\nReinforcement Learning (RL) successfully in this competition. Both environment\nand hardware specifications are available open-source to allow reproducibility\nof our results and further studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 23:52:32 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bassani", "Hansenclever F.", ""], ["Delgado", "Renie A.", ""], ["Junior", "Jos\u00e9 Nilton de O. Lima", ""], ["Medeiros", "Heitor R.", ""], ["Braga", "Pedro H. M.", ""], ["Machado", "Mateus G.", ""], ["Santos", "Lucas H. C.", ""], ["Tapp", "Alain", ""]]}, {"id": "2008.12639", "submitter": "Hussein Abbass A", "authors": "Saber Elsayed, Hemant Singh, Essam Debie, Anthony Perry, Benjamin\n  Campbell, Robert Hunjet, Hussein Abbass", "title": "Path Planning for Shepherding a Swarm in a Cluttered Environment using\n  Differential Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shepherding involves herding a swarm of agents (\\emph{sheep}) by another a\ncontrol agent (\\emph{sheepdog}) towards a goal. Multiple approaches have been\ndocumented in the literature to model this behaviour. In this paper, we present\na modification to a well-known shepherding approach, and show, via simulation,\nthat this modification improves shepherding efficacy. We then argue that given\ncomplexity arising from obstacles laden environments, path planning approaches\ncould further enhance this model. To validate this hypothesis, we present a\n2-stage evolutionary-based path planning algorithm for shepherding a swarm of\nagents in 2D environments. In the first stage, the algorithm attempts to find\nthe best path for the sheepdog to move from its initial location to a strategic\ndriving location behind the sheep. In the second stage, it calculates and\noptimises a path for the sheep. It does so by using \\emph{way points} on that\npath as the sequential sub-goals for the sheepdog to aim towards. The proposed\nalgorithm is evaluated in obstacle laden environments via simulation with\nfurther improvements achieved.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 13:17:59 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Elsayed", "Saber", ""], ["Singh", "Hemant", ""], ["Debie", "Essam", ""], ["Perry", "Anthony", ""], ["Campbell", "Benjamin", ""], ["Hunjet", "Robert", ""], ["Abbass", "Hussein", ""]]}, {"id": "2008.12647", "submitter": "Yiren Lu", "authors": "Yiren Lu, Jonathan Tompson", "title": "ADAIL: Adaptive Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the ADaptive Adversarial Imitation Learning (ADAIL) algorithm for\nlearning adaptive policies that can be transferred between environments of\nvarying dynamics, by imitating a small number of demonstrations collected from\na single source domain. This is an important problem in robotic learning\nbecause in real world scenarios 1) reward functions are hard to obtain, 2)\nlearned policies from one domain are difficult to deploy in another due to\nvarying source to target domain statistics, 3) collecting expert demonstrations\nin multiple environments where the dynamics are known and controlled is often\ninfeasible. We address these constraints by building upon recent advances in\nadversarial imitation learning; we condition our policy on a learned dynamics\nembedding and we employ a domain-adversarial loss to learn a dynamics-invariant\ndiscriminator. The effectiveness of our method is demonstrated on simulated\ncontrol tasks with varying environment dynamics and the learned adaptive agent\noutperforms several recent baselines.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 06:11:00 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lu", "Yiren", ""], ["Tompson", "Jonathan", ""]]}, {"id": "2008.12693", "submitter": "Trevor McInroe", "authors": "Trevor A. McInroe", "title": "Sample Efficiency in Sparse Reinforcement Learning: Or Your Money Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse rewards present a difficult problem in reinforcement learning and may\nbe inevitable in certain domains with complex dynamics such as real-world\nrobotics. Hindsight Experience Replay (HER) is a recent replay memory\ndevelopment that allows agents to learn in sparse settings by altering memories\nto show them as successful even though they may not be. While, empirically, HER\nhas shown some success, it does not provide guarantees around the makeup of\nsamples drawn from an agent's replay memory. This may result in minibatches\nthat contain only memories with zero-valued rewards or agents learning an\nundesirable policy that completes HER-adjusted goals instead of the actual\ngoal.\n  In this paper, we introduce Or Your Money Back (OYMB), a replay memory\nsampler designed to work with HER. OYMB improves training efficiency in sparse\nsettings by providing a direct interface to the agent's replay memory that\nallows for control over minibatch makeup, as well as a preferential lookup\nscheme that prioritizes real-goal memories before HER-adjusted memories. We\ntest our approach on five tasks across three unique environments. Our results\nshow that using HER in combination with OYMB outperforms using HER alone and\nleads to agents that learn to complete the real goal more quickly.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 14:48:48 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["McInroe", "Trevor A.", ""]]}, {"id": "2008.12708", "submitter": "Hung Nguyen", "authors": "Hung The Nguyen, Matthew Garratt, Lam Thu Bui, and Hussein Abbass", "title": "Disturbances in Influence of a Shepherding Agent is More Impactful than\n  Sensorial Noise During Swarm Guidance", "comments": null, "journal-ref": null, "doi": "10.1109/MCI.2020.2998307", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The guidance of a large swarm is a challenging control problem. Shepherding\noffers one approach to guide a large swarm using a few shepherding agents\n(sheepdogs). While noise is an inherent characteristic in many real-world\nproblems, the impact of noise on shepherding is not a well-studied problem. We\nstudy two forms of noise. First, we evaluate noise in the sensorial information\nreceived by the shepherd about the location of sheep. Second, we evaluate noise\nin the ability of the sheepdog to influence sheep due to disturbance forces\noccurring during actuation. We study both types of noise in this paper, and\ninvestigate the performance of Str\\\"{o}mbom's approach under these actuation\nand perception noises. To ensure that the parameterisation of the algorithm\ncreates a stable performance, we need to run a large number of simulations,\nwhile increasing the number of random episodes until stability is achieved. We\nthen systematically study the impact of sensorial and actuation noise on\nperformance. Str\\\"{o}mbom's approach is found to be more sensitive to actuation\nnoise than perception noise. This implies that it is more important for the\nshepherding agent to influence the sheep more accurately by reducing actuation\nnoise than attempting to reduce noise in its sensors. Moreover, different\nlevels of noise required different parameterisation for the shepherding agent,\nwhere the threshold needed by an agent to decide whether or not to collect\nastray sheep is different for different noise levels.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:40:40 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 05:33:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Hung The", ""], ["Garratt", "Matthew", ""], ["Bui", "Lam Thu", ""], ["Abbass", "Hussein", ""]]}, {"id": "2008.12735", "submitter": "Donald Honeycutt", "authors": "Donald R. Honeycutt, Mahsan Nourani, Eric D. Ragan", "title": "Soliciting Human-in-the-Loop User Feedback for Interactive Machine\n  Learning Reduces User Trust and Impressions of Model Accuracy", "comments": "Accepted and to appear in the Proceedings of the AAAI Conference on\n  Human Computation and Crowdsourcing (HCOMP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-initiative systems allow users to interactively provide feedback to\npotentially improve system performance. Human feedback can correct model errors\nand update model parameters to dynamically adapt to changing data.\nAdditionally, many users desire the ability to have a greater level of control\nand fix perceived flaws in systems they rely on. However, how the ability to\nprovide feedback to autonomous systems influences user trust is a largely\nunexplored area of research. Our research investigates how the act of providing\nfeedback can affect user understanding of an intelligent system and its\naccuracy. We present a controlled experiment using a simulated object detection\nsystem with image data to study the effects of interactive feedback collection\non user impressions. The results show that providing human-in-the-loop feedback\nlowered both participants' trust in the system and their perception of system\naccuracy, regardless of whether the system accuracy improved in response to\ntheir feedback. These results highlight the importance of considering the\neffects of allowing end-user feedback on user trust when designing intelligent\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:46:41 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Honeycutt", "Donald R.", ""], ["Nourani", "Mahsan", ""], ["Ragan", "Eric D.", ""]]}, {"id": "2008.12736", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, Jaideep Srivastava", "title": "RKT : Relation-Aware Self-Attention for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3411994", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has transitioned into a new phase of online learning in response to\nthe recent Covid19 pandemic. Now more than ever, it has become paramount to\npush the limits of online learning in every manner to keep flourishing the\neducation system. One crucial component of online learning is Knowledge Tracing\n(KT). The aim of KT is to model student's knowledge level based on their\nanswers to a sequence of exercises referred as interactions. Students acquire\ntheir skills while solving exercises and each such interaction has a distinct\nimpact on student ability to solve a future exercise. This \\textit{impact} is\ncharacterized by 1) the relation between exercises involved in the interactions\nand 2) student forget behavior. Traditional studies on knowledge tracing do not\nexplicitly model both the components jointly to estimate the impact of these\ninteractions. In this paper, we propose a novel Relation-aware self-attention\nmodel for Knowledge Tracing (RKT). We introduce a relation-aware self-attention\nlayer that incorporates the contextual information. This contextual information\nintegrates both the exercise relation information through their textual content\nas well as student performance data and the forget behavior information through\nmodeling an exponentially decaying kernel function. Extensive experiments on\nthree real-world datasets, among which two new collections are released to the\npublic, show that our model outperforms state-of-the-art knowledge tracing\nmethods. Furthermore, the interpretable attention weights help visualize the\nrelation between interactions and temporal patterns in the human learning\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:47:03 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Pandey", "Shalini", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2008.12742", "submitter": "Jose Manuel Gomez-Perez", "authors": "Ronald Denaux and Jose Manuel Gomez-Perez", "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "comments": "Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:55:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Denaux", "Ronald", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "2008.12760", "submitter": "Roozbeh Mottaghi", "authors": "Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng,\n  Roozbeh Mottaghi, Aniruddha Kembhavi", "title": "AllenAct: A Framework for Embodied AI Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domain of Embodied AI, in which agents learn to complete tasks through\ninteraction with their environment from egocentric observations, has\nexperienced substantial growth with the advent of deep reinforcement learning\nand increased interest from the computer vision, NLP, and robotics communities.\nThis growth has been facilitated by the creation of a large number of simulated\nenvironments (such as AI2-THOR, Habitat and CARLA), tasks (like point\nnavigation, instruction following, and embodied question answering), and\nassociated leaderboards. While this diversity has been beneficial and organic,\nit has also fragmented the community: a huge amount of effort is required to do\nsomething as simple as taking a model trained in one environment and testing it\nin another. This discourages good science. We introduce AllenAct, a modular and\nflexible learning framework designed with a focus on the unique requirements of\nEmbodied AI research. AllenAct provides first-class support for a growing\ncollection of embodied environments, tasks and algorithms, provides\nreproductions of state-of-the-art models and includes extensive documentation,\ntutorials, start-up code, and pre-trained models. We hope that our framework\nmakes Embodied AI more accessible and encourages new researchers to join this\nexciting area. The framework can be accessed at: https://allenact.org/\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:35:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Weihs", "Luca", ""], ["Salvador", "Jordi", ""], ["Kotar", "Klemen", ""], ["Jain", "Unnat", ""], ["Zeng", "Kuo-Hao", ""], ["Mottaghi", "Roozbeh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2008.12763", "submitter": "Ju Fan", "authors": "Ju Fan, Tongyu Liu, Guoliang Li, Junyou Chen, Yuwei Shen, Xiaoyong Du", "title": "Relational Data Synthesis using Generative Adversarial Networks: A\n  Design Space Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of big data has brought an urgent demand for\nprivacy-preserving data publishing. Traditional solutions to this demand have\nlimitations on effectively balancing the tradeoff between privacy and utility\nof the released data. Thus, the database community and machine learning\ncommunity have recently studied a new problem of relational data synthesis\nusing generative adversarial networks (GAN) and proposed various algorithms.\nHowever, these algorithms are not compared under the same framework and thus it\nis hard for practitioners to understand GAN's benefits and limitations. To\nbridge the gaps, we conduct so far the most comprehensive experimental study\nthat investigates applying GAN to relational data synthesis. We introduce a\nunified GAN-based framework and define a space of design solutions for each\ncomponent in the framework, including neural network architectures and training\nstrategies. We conduct extensive experiments to explore the design space and\ncompare with traditional data synthesis approaches. Through extensive\nexperiments, we find that GAN is very promising for relational data synthesis,\nand provide guidance for selecting appropriate design solutions. We also point\nout limitations of GAN and identify future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:41:11 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Fan", "Ju", ""], ["Liu", "Tongyu", ""], ["Li", "Guoliang", ""], ["Chen", "Junyou", ""], ["Shen", "Yuwei", ""], ["Du", "Xiaoyong", ""]]}, {"id": "2008.12775", "submitter": "Brandon Amos", "authors": "Brandon Amos, Samuel Stanton, Denis Yarats, Andrew Gordon Wilson", "title": "On the model-based stochastic value gradient for continuous\n  reinforcement learning", "comments": "L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade, model-based reinforcement learning has been seen as a way\nto leverage control-based domain knowledge to improve the sample-efficiency of\nreinforcement learning agents. While model-based agents are conceptually\nappealing, their policies tend to lag behind those of model-free agents in\nterms of final reward, especially in non-trivial environments. In response,\nresearchers have proposed model-based agents with increasingly complex\ncomponents, from ensembles of probabilistic dynamics models, to heuristics for\nmitigating model error. In a reversal of this trend, we show that simple\nmodel-based agents can be derived from existing ideas that not only match, but\noutperform state-of-the-art model-free agents in terms of both\nsample-efficiency and final reward. We find that a model-free soft value\nestimate for policy evaluation and a model-based stochastic value gradient for\npolicy improvement is an effective combination, achieving state-of-the-art\nresults on a high-dimensional humanoid control task, which most model-based\nagents are unable to solve. Our findings suggest that model-based policy\nevaluation deserves closer attention.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:58:29 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:28:25 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 17:59:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Amos", "Brandon", ""], ["Stanton", "Samuel", ""], ["Yarats", "Denis", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2008.12800", "submitter": "Mohd Hafiz Hasan", "authors": "Mohd. Hafiz Hasan and Pascal Van Hentenryck", "title": "The Benefits of Autonomous Vehicles for Community-Based Trip Sharing", "comments": "43 pages, 32 figures, submitted to Transportation Research: Part C", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work reconsiders the concept of community-based trip sharing proposed by\nHasan et al. (2018) that leverages the structure of commuting patterns and\nurban communities to optimize trip sharing. It aims at quantifying the benefits\nof autonomous vehicles for community-based trip sharing, compared to a\ncar-pooling platform where vehicles are driven by their owners. In the\nconsidered problem, each rider specifies a desired arrival time for her inbound\ntrip (commuting to work) and a departure time for her outbound trip (commuting\nback home). In addition, her commute time cannot deviate too much from the\nduration of a direct trip. Prior work motivated by reducing parking pressure\nand congestion in the city of Ann Arbor, Michigan, showed that a car-pooling\nplatform for community-based trip sharing could reduce the number of vehicles\nby close to 60%.\n  This paper studies the potential benefits of autonomous vehicles in further\nreducing the number of vehicles needed to serve all these commuting trips. It\nproposes a column-generation procedure that generates and assembles mini routes\nto serve inbound and outbound trips, using a lexicographic objective that first\nminimizes the required vehicle count and then the total travel distance. The\noptimization algorithm is evaluated on a large-scale, real-world dataset of\ncommute trips from the city of Ann Arbor, Michigan. The results of the\noptimization show that it can leverage autonomous vehicles to reduce the daily\nvehicle usage by 92%, improving upon the results of the original Commute Trip\nSharing Problem by 34%, while also reducing daily vehicle miles traveled by\napproximately 30%. These results demonstrate the significant potential of\nautonomous vehicles for the shared commuting of a community to a common work\ndestination.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:12:13 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 17:00:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hasan", "Mohd. Hafiz", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2008.12804", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Josef Jon, Pavel Smrz", "title": "Rethinking the Objectives of Extractive Question Answering", "comments": "final preprint version (added manual analysis, code & results,\n  experiments with MLP similarity, complexity analysis, conditional objective)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that, contrary to a common belief, using the objective\nwith independence assumption for modelling the span probability $P(a_s,a_e) =\nP(a_s)P(a_e)$ of span starting at position $a_s$ and ending at position $a_e$\nhas adverse effects. Therefore we propose multiple approaches to modelling\njoint probability $P(a_s,a_e)$ directly. Among those, we propose a compound\nobjective, composed from the joint probability while still keeping the\nobjective with independence assumption as an auxiliary objective. We find that\nthe compound objective is consistently superior or equal to other assumptions\nin exact match. Additionally, we identified common errors caused by the\nassumption of independence and manually checked the counterpart predictions,\ndemonstrating the impact of the compound objective on the real examples. Our\nfindings are supported via experiments with three extractive QA models (BIDAF,\nBERT, ALBERT) over six datasets and our code, individual results and manual\nanalysis are available online.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:22:19 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 15:04:42 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 13:24:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fajcik", "Martin", ""], ["Jon", "Josef", ""], ["Smrz", "Pavel", ""]]}, {"id": "2008.12833", "submitter": "Gabriel Spadon", "authors": "Gabriel Spadon, Shenda Hong, Bruno Brandoli, Stan Matwin, Jose F.\n  Rodrigues-Jr, and Jimeng Sun", "title": "Pay Attention to Evolution: Time Series Forecasting with Deep\n  Graph-Evolution Learning", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3076155", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is one of the most active research topics in\nartificial intelligence. Applications in real-world time series should consider\ntwo factors for achieving reliable predictions: modeling dynamic dependencies\namong multiple variables and adjusting the model's intrinsic hyperparameters. A\nstill open gap in that literature is that statistical and ensemble learning\napproaches systematically present lower predictive performance than deep\nlearning methods. They generally disregard the data sequence aspect entangled\nwith multivariate data represented in more than one time series. Conversely,\nthis work presents a novel neural network architecture for time-series\nforecasting that combines the power of graph evolution with deep recurrent\nlearning on distinct data distributions; we named our method Recurrent Graph\nEvolution Neural Network (ReGENN). The idea is to infer multiple multivariate\nrelationships between co-occurring time-series by assuming that the temporal\ndata depends not only on inner variables and intra-temporal relationships\n(i.e., observations from itself) but also on outer variables and inter-temporal\nrelationships (i.e., observations from other-selves). An extensive set of\nexperiments was conducted comparing ReGENN with dozens of ensemble methods and\nclassical statistical ones, showing sound improvement of up to 64.87% over the\ncompeting algorithms. Furthermore, we present an analysis of the intermediate\nweights arising from ReGENN, showing that by looking at inter and\nintra-temporal relationships simultaneously, time-series forecasting is majorly\nimproved if paying attention to how multiple multivariate data synchronously\nevolve.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 20:10:07 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 11:10:35 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 15:46:00 GMT"}, {"version": "v4", "created": "Wed, 26 May 2021 19:58:48 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Spadon", "Gabriel", ""], ["Hong", "Shenda", ""], ["Brandoli", "Bruno", ""], ["Matwin", "Stan", ""], ["Rodrigues-Jr", "Jose F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2008.12858", "submitter": "Hongzi Mao", "authors": "Hongzi Mao, Shannon Chen, Drew Dimmery, Shaun Singh, Drew Blaisdell,\n  Yuandong Tian, Mohammad Alizadeh, Eytan Bakshy", "title": "Real-world Video Adaptation with Reinforcement Learning", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  36th International Conference on Machine Learning, Long Beach, California,\n  USA, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client-side video players employ adaptive bitrate (ABR) algorithms to\noptimize user quality of experience (QoE). We evaluate recently proposed\nRL-based ABR methods in Facebook's web-based video streaming platform.\nReal-world ABR contains several challenges that requires customized designs\nbeyond off-the-shelf RL algorithms -- we implement a scalable neural network\narchitecture that supports videos with arbitrary bitrate encodings; we design a\ntraining method to cope with the variance resulting from the stochasticity in\nnetwork conditions; and we leverage constrained Bayesian optimization for\nreward shaping in order to optimize the conflicting QoE objectives. In a\nweek-long worldwide deployment with more than 30 million video streaming\nsessions, our RL approach outperforms the existing human-engineered ABR\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:44:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mao", "Hongzi", ""], ["Chen", "Shannon", ""], ["Dimmery", "Drew", ""], ["Singh", "Shaun", ""], ["Blaisdell", "Drew", ""], ["Tian", "Yuandong", ""], ["Alizadeh", "Mohammad", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2008.12879", "submitter": "Ozkan Kilic", "authors": "Hugo Latapie and Ozkan Kilic", "title": "A Metamodel and Framework for AGI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can artificial intelligence systems exhibit superhuman performance, but in\ncritical ways, lack the intelligence of even a single-celled organism? The\nanswer is clearly 'yes' for narrow AI systems. Animals, plants, and even\nsingle-celled organisms learn to reliably avoid danger and move towards food.\nThis is accomplished via a physical knowledge preserving metamodel that\nautonomously generates useful models of the world. We posit that preserving the\nstructure of knowledge is critical for higher intelligences that manage\nincreasingly higher levels of abstraction, be they human or artificial. This is\nthe key lesson learned from applying AGI subsystems to complex real-world\nproblems that require continuous learning and adaptation. In this paper, we\nintroduce the Deep Fusion Reasoning Engine (DFRE), which implements a\nknowledge-preserving metamodel and framework for constructing applied AGI\nsystems. The DFRE metamodel exhibits some important fundamental knowledge\npreserving properties such as clear distinctions between symmetric and\nantisymmetric relations, and the ability to create a hierarchical knowledge\nrepresentation that clearly delineates between levels of abstraction. The DFRE\nmetamodel, which incorporates these capabilities, demonstrates how this\napproach benefits AGI in specific ways such as managing combinatorial explosion\nand enabling cumulative, distributed and federated learning. Our experiments\nshow that the proposed framework achieves 94% accuracy on average on\nunsupervised object detection and recognition. This work is inspired by the\nstate-of-the-art approaches to AGI, recent AGI-aspiring work, the granular\ncomputing community, as well as Alfred Korzybski's general semantics.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 23:34:21 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 23:36:32 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Latapie", "Hugo", ""], ["Kilic", "Ozkan", ""]]}, {"id": "2008.12884", "submitter": "Josimar Chire Saire", "authors": "Josimar E. Chire-Saire", "title": "New feature for Complex Network based on Ant Colony Optimization for\n  High Level Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low level classification extracts features from the elements, i.e. physical\nto use them to train a model for a later classification. High level\nclassification uses high level features, the existent patterns, relationship\nbetween the data and combines low and high level features for classification.\nHigh Level features can be got from Complex Network created over the data.\nLocal and global features are used to describe the structure of a Complex\nNetwork, i.e. Average Neighbor Degree, Average Clustering. The present work\nproposed a novel feature to describe the architecture of the Network following\na Ant Colony System approach. The experiments shows the advantage of using this\nfeature because the sensibility with data of different classes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 00:22:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chire-Saire", "Josimar E.", ""]]}, {"id": "2008.12894", "submitter": "Junaid Malik", "authors": "Junaid Malik, Serkan Kiranyaz, Moncef Gabbouj", "title": "Self-Organized Operational Neural Networks for Severe Image Restoration\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Discriminative learning based on convolutional neural networks (CNNs) aims to\nperform image restoration by learning from training examples of noisy-clean\nimage pairs. It has become the go-to methodology for tackling image restoration\nand has outperformed the traditional non-local class of methods. However, the\ntop-performing networks are generally composed of many convolutional layers and\nhundreds of neurons, with trainable parameters in excess of several millions.\nWe claim that this is due to the inherent linear nature of convolution-based\ntransformation, which is inadequate for handling severe restoration problems.\nRecently, a non-linear generalization of CNNs, called the operational neural\nnetworks (ONN), has been shown to outperform CNN on AWGN denoising. However,\nits formulation is burdened by a fixed collection of well-known nonlinear\noperators and an exhaustive search to find the best possible configuration for\na given architecture, whose efficacy is further limited by a fixed output layer\noperator assignment. In this study, we leverage the Taylor series-based\nfunction approximation to propose a self-organizing variant of ONNs, Self-ONNs,\nfor image restoration, which synthesizes novel nodal transformations onthe-fly\nas part of the learning process, thus eliminating the need for redundant\ntraining runs for operator search. In addition, it enables a finer level of\noperator heterogeneity by diversifying individual connections of the receptive\nfields and weights. We perform a series of extensive ablation experiments\nacross three severe image restoration tasks. Even when a strict equivalence of\nlearnable parameters is imposed, Self-ONNs surpass CNNs by a considerable\nmargin across all problems, improving the generalization performance by up to 3\ndB in terms of PSNR.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 02:19:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Malik", "Junaid", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2008.12937", "submitter": "Shaghayegh Roohi", "authors": "Shaghayegh Roohi (1), Asko Relas (2), Jari Takatalo (2), Henri\n  Heiskanen (2), Perttu H\\\"am\\\"al\\\"ainen (1) ((1) Aalto University, Espoo,\n  Finland, (2) Rovio Entertainment, Espoo, Finland)", "title": "Predicting Game Difficulty and Churn Without Players", "comments": "9 pages, 9 figures, In Proceedings of the Annual Symposium on\n  Computer-Human Interaction in Play (CHI PLAY '20)", "journal-ref": null, "doi": "10.1145/3410404.3414235", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel simulation model that is able to predict the per-level\nchurn and pass rates of Angry Birds Dream Blast, a popular mobile free-to-play\ngame. Our primary contribution is to combine AI gameplay using Deep\nReinforcement Learning (DRL) with a simulation of how the player population\nevolves over the levels. The AI players predict level difficulty, which is used\nto drive a player population model with simulated skill, persistence, and\nboredom. This allows us to model, e.g., how less persistent and skilled players\nare more sensitive to high difficulty, and how such players churn early, which\nmakes the player population and the relation between difficulty and churn\nevolve level by level. Our work demonstrates that player behavior predictions\nproduced by DRL gameplay can be significantly improved by even a very simple\npopulation-level simulation of individual player differences, without requiring\ncostly retraining of agents or collecting new DRL gameplay data for each\nsimulated player.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 08:37:47 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Roohi", "Shaghayegh", ""], ["Relas", "Asko", ""], ["Takatalo", "Jari", ""], ["Heiskanen", "Henri", ""], ["H\u00e4m\u00e4l\u00e4inen", "Perttu", ""]]}, {"id": "2008.12997", "submitter": "Pengfei Xia", "authors": "Pengfei Xia and Bin Li", "title": "Improving Resistance to Adversarial Deformations by Regularizing\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the resistance of deep neural networks against adversarial attacks\nis important for deploying models to realistic applications. However, most\ndefense methods are designed to defend against intensity perturbations and\nignore location perturbations, which should be equally important for deep model\nsecurity. In this paper, we focus on adversarial deformations, a typical class\nof location perturbations, and propose a flow gradient regularization to\nimprove the resistance of models. Theoretically, we prove that, compared with\ninput gradient regularization, regularizing flow gradients is able to get a\ntighter bound. Over multiple datasets, architectures, and adversarial\ndeformations, our empirical results indicate that models trained with flow\ngradients can acquire a better resistance than trained with input gradients\nwith a large margin, and also better than adversarial training. Moreover,\ncompared with directly training with adversarial deformations, our method can\nachieve better results in unseen attacks, and combining these two methods can\nimprove the resistance further.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 15:28:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 05:58:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Xia", "Pengfei", ""], ["Li", "Bin", ""]]}, {"id": "2008.13006", "submitter": "Cong Guo", "authors": "Cong Guo and Bo Yang Hsueh and Jingwen Leng and Yuxian Qiu and Yue\n  Guan and Zehuan Wang and Xiaoying Jia and Xipeng Li and Minyi Guo and Yuhao\n  Zhu", "title": "Accelerating Sparse DNN Models without Hardware-Support via Tile-Wise\n  Sparsity", "comments": "12pages, ACM/IEEE Proceedings of the International Conference for\n  High Performance Computing, Networking, Storage and Analysis (SC20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network pruning can reduce the high computation cost of deep neural network\n(DNN) models. However, to maintain their accuracies, sparse models often carry\nrandomly-distributed weights, leading to irregular computations. Consequently,\nsparse models cannot achieve meaningful speedup on commodity hardware (e.g.,\nGPU) built for dense matrix computations. As such, prior works usually modify\nor design completely new sparsity-optimized architectures for exploiting\nsparsity. We propose an algorithm-software co-designed pruning method that\nachieves latency speedups on existing dense architectures. Our work builds upon\nthe insight that the matrix multiplication generally breaks the large matrix\ninto multiple smaller tiles for parallel execution. We propose a\ntiling-friendly \"tile-wise\" sparsity pattern, which maintains a regular pattern\nat the tile level for efficient execution but allows for irregular, arbitrary\npruning at the global scale to maintain the high accuracy. We implement and\nevaluate the sparsity pattern on GPU tensor core, achieving a 1.95x speedup\nover the dense model.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 16:27:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guo", "Cong", ""], ["Hsueh", "Bo Yang", ""], ["Leng", "Jingwen", ""], ["Qiu", "Yuxian", ""], ["Guan", "Yue", ""], ["Wang", "Zehuan", ""], ["Jia", "Xiaoying", ""], ["Li", "Xipeng", ""], ["Guo", "Minyi", ""], ["Zhu", "Yuhao", ""]]}, {"id": "2008.13015", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Hossein Ghanei-Yakhdan, and Shohreh\n  Kasaei", "title": "Adaptive Exploitation of Pre-trained Deep Convolutional Neural Networks\n  for Robust Visual Tracking", "comments": "Accepted Manuscript in Multimedia Tools and Applications (MTAP),\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the automatic feature extraction procedure via multi-layer nonlinear\ntransformations, the deep learning-based visual trackers have recently achieved\ngreat success in challenging scenarios for visual tracking purposes. Although\nmany of those trackers utilize the feature maps from pre-trained convolutional\nneural networks (CNNs), the effects of selecting different models and\nexploiting various combinations of their feature maps are still not compared\ncompletely. To the best of our knowledge, all those methods use a fixed number\nof convolutional feature maps without considering the scene attributes (e.g.,\nocclusion, deformation, and fast motion) that might occur during tracking. As a\npre-requisition, this paper proposes adaptive discriminative correlation\nfilters (DCF) based on the methods that can exploit CNN models with different\ntopologies. First, the paper provides a comprehensive analysis of four commonly\nused CNN models to determine the best feature maps of each model. Second, with\nthe aid of analysis results as attribute dictionaries, adaptive exploitation of\ndeep features is proposed to improve the accuracy and robustness of visual\ntrackers regarding video characteristics. Third, the generalization of the\nproposed method is validated on various tracking datasets as well as CNN models\nwith similar architectures. Finally, extensive experimental results demonstrate\nthe effectiveness of the proposed adaptive method compared with\nstate-of-the-art visual tracking methods.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:09:43 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 06:57:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2008.13024", "submitter": "Hao Tang", "authors": "Hao Tang, Song Bai, Nicu Sebe", "title": "Dual Attention GANs for Semantic Image Synthesis", "comments": "Accepted to ACM MM 2020, camera ready (9 pages) + supplementary (10\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the semantic image synthesis task that aims at\ntransferring semantic label maps to photo-realistic images. Existing methods\nlack effective semantic constraints to preserve the semantic information and\nignore the structural correlations in both spatial and channel dimensions,\nleading to unsatisfactory blurry and artifact-prone results. To address these\nlimitations, we propose a novel Dual Attention GAN (DAGAN) to synthesize\nphoto-realistic and semantically-consistent images with fine details from the\ninput layouts without imposing extra training overhead or modifying the network\narchitectures of existing methods. We also propose two novel modules, i.e.,\nposition-wise Spatial Attention Module (SAM) and scale-wise Channel Attention\nModule (CAM), to capture semantic structure attention in spatial and channel\ndimensions, respectively. Specifically, SAM selectively correlates the pixels\nat each position by a spatial attention map, leading to pixels with the same\nsemantic label being related to each other regardless of their spatial\ndistances. Meanwhile, CAM selectively emphasizes the scale-wise features at\neach channel by a channel attention map, which integrates associated features\namong all channel maps regardless of their scales. We finally sum the outputs\nof SAM and CAM to further improve feature representation. Extensive experiments\non four challenging datasets show that DAGAN achieves remarkably better results\nthan state-of-the-art methods, while using fewer model parameters. The source\ncode and trained models are available at https://github.com/Ha0Tang/DAGAN.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 17:49:01 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tang", "Hao", ""], ["Bai", "Song", ""], ["Sebe", "Nicu", ""]]}, {"id": "2008.13041", "submitter": "Shalabh Gupta", "authors": "Zongyuan Shen and James P. Wilson and Shalabh Gupta", "title": "$\\epsilon^*$+: An Online Coverage Path Planning Algorithm for\n  Energy-constrained Autonomous Vehicles", "comments": null, "journal-ref": "IEEE/MTS Global Oceans 2020, Singapore-US Gulf Coast", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel algorithm, called $\\epsilon^*$+, for online\ncoverage path planning of unknown environments using energy-constrained\nautonomous vehicles. Due to limited battery size, the energy-constrained\nvehicles have limited duration of operation time. Therefore, while executing a\ncoverage trajectory, the vehicle has to return to the charging station for a\nrecharge before the battery runs out. In this regard, the $\\epsilon^*$+\nalgorithm enables the vehicle to retreat back to the charging station based on\nthe remaining energy which is monitored throughout the coverage process. This\nis followed by an advance trajectory that takes the vehicle to a near by\nunexplored waypoint to restart the coverage process, instead of taking it back\nto the previous left over point of the retreat trajectory; thus reducing the\noverall coverage time. The proposed $\\epsilon^*$+ algorithm is an extension of\nthe $\\epsilon^*$ algorithm, which utilizes an Exploratory Turing Machine (ETM)\nas a supervisor to navigate the vehicle with back and forth trajectory for\ncomplete coverage. The performance of the $\\epsilon^*$+ algorithm is validated\non complex scenarios using Player/Stage which is a high-fidelity robotic\nsimulator.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 19:24:54 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Shen", "Zongyuan", ""], ["Wilson", "James P.", ""], ["Gupta", "Shalabh", ""]]}, {"id": "2008.13044", "submitter": "Stephen Chung", "authors": "Stephen Chung, Robert Kozma", "title": "Reinforcement Learning with Feedback-modulated TD-STDP", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neuron networks have been used successfully to solve simple\nreinforcement learning tasks with continuous action set applying learning rules\nbased on spike-timing-dependent plasticity (STDP). However, most of these\nmodels cannot be applied to reinforcement learning tasks with discrete action\nset since they assume that the selected action is a deterministic function of\nfiring rate of neurons, which is continuous. In this paper, we propose a new\nSTDP-based learning rule for spiking neuron networks which contains feedback\nmodulation. We show that the STDP-based learning rule can be used to solve\nreinforcement learning tasks with discrete action set at a speed similar to\nstandard reinforcement learning algorithms when applied to the CartPole and\nLunarLander tasks. Moreover, we demonstrate that the agent is unable to solve\nthese tasks if feedback modulation is omitted from the learning rule. We\nconclude that feedback modulation allows better credit assignment when only the\nunits contributing to the executed action and TD error participate in learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 20:08:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chung", "Stephen", ""], ["Kozma", "Robert", ""]]}, {"id": "2008.13048", "submitter": "Shalabh Gupta", "authors": "James P. Wilson and Zongyuan Shen and Shalabh Gupta and Thomas A.\n  Wettergren", "title": "T$^{\\star}$-Lite: A Fast Time-Risk Optimal Motion Planning Algorithm for\n  Multi-Speed Autonomous Vehicles", "comments": null, "journal-ref": "IEEE/MTS Global Oceans 2020, Singapore-US Gulf Coast", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new algorithm, called T$^{\\star}$-Lite, that\nenables fast time-risk optimal motion planning for variable-speed autonomous\nvehicles. The T$^{\\star}$-Lite algorithm is a significantly faster version of\nthe previously developed T$^{\\star}$ algorithm. T$^{\\star}$-Lite uses the novel\ntime-risk cost function of T$^{\\star}$; however, instead of a grid-based\napproach, it uses an asymptotically optimal sampling-based motion planner.\nFurthermore, it utilizes the recently developed Generalized Multi-speed Dubins\nMotion-model (GMDM) for sample-to-sample kinodynamic motion planning. The\nsample-based approach and GMDM significantly reduce the computational burden of\nT$^{\\star}$ while providing reasonable solution quality. The sample points are\ndrawn from a four-dimensional configuration space consisting of two position\ncoordinates plus vehicle heading and speed. Specifically, T$^{\\star}$-Lite\nenables the motion planner to select the vehicle speed and direction based on\nits proximity to the obstacle to generate faster and safer paths. In this\npaper, T$^{\\star}$-Lite is developed using the RRT$^{\\star}$ motion planner,\nbut adaptation to other motion planners is straightforward and depends on the\nneeds of the planner\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 20:25:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wilson", "James P.", ""], ["Shen", "Zongyuan", ""], ["Gupta", "Shalabh", ""], ["Wettergren", "Thomas A.", ""]]}, {"id": "2008.13115", "submitter": "Michael Maher", "authors": "Michael J. Maher", "title": "Corruption and Audit in Strategic Argumentation", "comments": "Reasoning Research Institute technical report, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strategic argumentation provides a simple model of disputation and\nnegotiation among agents. Although agents might be expected to act in our best\ninterests, there is little that enforces such behaviour. (Maher, 2016)\nintroduced a model of corruption and resistance to corruption within strategic\nargumentation. In this paper we identify corrupt behaviours that are not\ndetected in that formulation. We strengthen the model to detect such\nbehaviours, and show that, under the strengthened model, all the strategic aims\nin (Maher, 2016) are resistant to corruption.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 08:08:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Maher", "Michael J.", ""]]}, {"id": "2008.13122", "submitter": "Vincent Grari", "authors": "Vincent Grari, Sylvain Lamprier, Marcin Detyniecki", "title": "Adversarial Learning for Counterfactual Fairness", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, fairness has become an important topic in the machine\nlearning research community. In particular, counterfactual fairness aims at\nbuilding prediction models which ensure fairness at the most individual level.\nRather than globally considering equity over the entire population, the idea is\nto imagine what any individual would look like with a variation of a given\nattribute of interest, such as a different gender or race for instance.\nExisting approaches rely on Variational Auto-encoding of individuals, using\nMaximum Mean Discrepancy (MMD) penalization to limit the statistical dependence\nof inferred representations with their corresponding sensitive attributes. This\nenables the simulation of counterfactual samples used for training the target\nfair model, the goal being to produce similar outcomes for every alternate\nversion of any individual. In this work, we propose to rely on an adversarial\nneural learning approach, that enables more powerful inference than with MMD\npenalties, and is particularly better fitted for the continuous setting, where\nvalues of sensitive attributes cannot be exhaustively enumerated. Experiments\nshow significant improvements in term of counterfactual fairness for both the\ndiscrete and the continuous settings.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:06:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Grari", "Vincent", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2008.13141", "submitter": "Hyunsung Lee", "authors": "Hyunsung Lee, Yeongjae Jang, Jaekwang Kim and Honguk Woo", "title": "A Differentiable Ranking Metric Using Relaxed Sorting Operation for\n  Top-K Recommender Systems", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recommender system generates personalized recommendations for a user by\ncomputing the preference score of items, sorting the items according to the\nscore, and filtering top-K items with high scores. While sorting and ranking\nitems are integral for this recommendation procedure, it is nontrivial to\nincorporate them in the process of end-to-end model training since sorting is\nnondifferentiable and hard to optimize with gradient descent. This incurs the\ninconsistency issue between existing learning objectives and ranking metrics of\nrecommenders. In this work, we present DRM (differentiable ranking metric) that\nmitigates the inconsistency and improves recommendation performance by\nemploying the differentiable relaxation of ranking metrics. Via experiments\nwith several real-world datasets, we demonstrate that the joint learning of the\nDRM objective upon existing factor based recommenders significantly improves\nthe quality of recommendations, in comparison with other state-of-the-art\nrecommendation methods.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 10:57:33 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 13:53:24 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 01:42:09 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 10:44:49 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Lee", "Hyunsung", ""], ["Jang", "Yeongjae", ""], ["Kim", "Jaekwang", ""], ["Woo", "Honguk", ""]]}, {"id": "2008.13146", "submitter": "Arvind  Kiwelekar", "authors": "Arvind W. Kiwelekar, Geetanjali S. Mahamunkar, Laxman D. Netak, Valmik\n  B Nikam", "title": "Deep Learning Techniques for Geospatial Data Analysis", "comments": "This is a pre-print of the following chapter: Arvind W. Kiwelekar,\n  Geetanjali S. Mahamunkar, Laxman D. Netak, Valmik B Nikam, {\\em Deep Learning\n  Techniques for Geospatial Data Analysis}, published in {\\bf Machine Learning\n  Paradigms}, edited by George A. TsihrintzisLakhmi C. Jain, 2020, publisher\n  Springer, Cham reproduced with permission of publisher Springer, Cham", "journal-ref": "In Machine Learning Paradigms, pp. 63-81. Springer, Cham, 2020", "doi": "10.1007/978-3-030-49724-8_3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumer electronic devices such as mobile handsets, goods tagged with RFID\nlabels, location and position sensors are continuously generating a vast amount\nof location enriched data called geospatial data. Conventionally such\ngeospatial data is used for military applications. In recent times, many useful\ncivilian applications have been designed and deployed around such geospatial\ndata. For example, a recommendation system to suggest restaurants or places of\nattraction to a tourist visiting a particular locality. At the same time, civic\nbodies are harnessing geospatial data generated through remote sensing devices\nto provide better services to citizens such as traffic monitoring, pothole\nidentification, and weather reporting. Typically such applications are\nleveraged upon non-hierarchical machine learning techniques such as Naive-Bayes\nClassifiers, Support Vector Machines, and decision trees. Recent advances in\nthe field of deep-learning showed that Neural Network-based techniques\noutperform conventional techniques and provide effective solutions for many\ngeospatial data analysis tasks such as object recognition, image\nclassification, and scene understanding. The chapter presents a survey on the\ncurrent state of the applications of deep learning techniques for analyzing\ngeospatial data.\n  The chapter is organized as below: (i) A brief overview of deep learning\nalgorithms. (ii)Geospatial Analysis: a Data Science Perspective (iii)\nDeep-learning techniques for Remote Sensing data analytics tasks (iv)\nDeep-learning techniques for GPS data analytics(iv) Deep-learning techniques\nfor RFID data analytics.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 11:51:10 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kiwelekar", "Arvind W.", ""], ["Mahamunkar", "Geetanjali S.", ""], ["Netak", "Laxman D.", ""], ["Nikam", "Valmik B", ""]]}, {"id": "2008.13173", "submitter": "Somnath Banerjee", "authors": "Somnath Banerjee, Sahar Ghannay, Sophie Rosset, Anne Vilnat and Paolo\n  Rosso", "title": "LIMSI_UPV at SemEval-2020 Task 9: Recurrent Convolutional Neural Network\n  for Code-mixed Sentiment Analysis", "comments": "To be published in the Proceedings of the 14th International Workshop\n  on Semantic Evaluation (SemEval-2020), Barcelona, Spain, Sep. Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the participation of LIMSI UPV team in SemEval-2020 Task\n9: Sentiment Analysis for Code-Mixed Social Media Text. The proposed approach\ncompeted in SentiMix Hindi-English subtask, that addresses the problem of\npredicting the sentiment of a given Hindi-English code-mixed tweet. We propose\nRecurrent Convolutional Neural Network that combines both the recurrent neural\nnetwork and the convolutional network to better capture the semantics of the\ntext, for code-mixed sentiment analysis. The proposed system obtained 0.69\n(best run) in terms of F1 score on the given test data and achieved the 9th\nplace (Codalab username: somban) in the SentiMix Hindi-English subtask.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:52:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Banerjee", "Somnath", ""], ["Ghannay", "Sahar", ""], ["Rosset", "Sophie", ""], ["Vilnat", "Anne", ""], ["Rosso", "Paolo", ""]]}, {"id": "2008.13187", "submitter": "Yanan Sun", "authors": "Yanan Sun and Xian Sun and Yuhan Fang and Gary Yen", "title": "A Novel Training Protocol for Performance Predictors of Evolutionary\n  Neural Architecture Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Neural Architecture Search (ENAS) can automatically design the\narchitectures of Deep Neural Networks (DNNs) using evolutionary computation\nalgorithms. However, most ENAS algorithms require intensive computational\nresource, which is not necessarily available to the users interested.\nPerformance predictors are a type of regression models which can assist to\naccomplish the search, while without exerting much computational resource.\nDespite various performance predictors have been designed, they employ the same\ntraining protocol to build the regression models: 1) sampling a set of DNNs\nwith performance as the training dataset, 2) training the model with the mean\nsquare error criterion, and 3) predicting the performance of DNNs newly\ngenerated during the ENAS. In this paper, we point out that the three steps\nconstituting the training protocol are not well though-out through intuitive\nand illustrative examples. Furthermore, we propose a new training protocol to\naddress these issues, consisting of designing a pairwise ranking indicator to\nconstruct the training target, proposing to use the logistic regression to fit\nthe training samples, and developing a differential method to building the\ntraining instances. To verify the effectiveness of the proposed training\nprotocol, four widely used regression models in the field of machine learning\nhave been chosen to perform the comparisons on two benchmark datasets. The\nexperimental results of all the comparisons demonstrate that the proposed\ntraining protocol can significantly improve the performance prediction accuracy\nagainst the traditional training protocols.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 14:39:28 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 06:22:28 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sun", "Yanan", ""], ["Sun", "Xian", ""], ["Fang", "Yuhan", ""], ["Yen", "Gary", ""]]}, {"id": "2008.13221", "submitter": "Vinicius G. Goecks", "authors": "Vinicius G. Goecks", "title": "Human-in-the-Loop Methods for Data-Driven and Reinforcement Learning\n  Systems", "comments": "PhD thesis, Aerospace Engineering, Texas A&M (2020). For more\n  information, see https://vggoecks.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes combine reinforcement learning algorithms and deep neural\nnetworks, despite reinforcement learning not being widely applied to robotics\nand real world scenarios. This can be attributed to the fact that current\nstate-of-the-art, end-to-end reinforcement learning approaches still require\nthousands or millions of data samples to converge to a satisfactory policy and\nare subject to catastrophic failures during training. Conversely, in real world\nscenarios and after just a few data samples, humans are able to either provide\ndemonstrations of the task, intervene to prevent catastrophic actions, or\nsimply evaluate if the policy is performing correctly. This research\ninvestigates how to integrate these human interaction modalities to the\nreinforcement learning loop, increasing sample efficiency and enabling\nreal-time reinforcement learning in robotics and real world scenarios. This\nnovel theoretical foundation is called Cycle-of-Learning, a reference to how\ndifferent human interaction modalities, namely, task demonstration,\nintervention, and evaluation, are cycled and combined to reinforcement learning\nalgorithms. Results presented in this work show that the reward signal that is\nlearned based upon human interaction accelerates the rate of learning of\nreinforcement learning algorithms and that learning from a combination of human\ndemonstrations and interventions is faster and more sample efficient when\ncompared to traditional supervised learning algorithms. Finally,\nCycle-of-Learning develops an effective transition between policies learned\nusing human demonstrations and interventions to reinforcement learning. The\ntheoretical foundation developed by this research opens new research paths to\nhuman-agent teaming scenarios where autonomous agents are able to learn from\nhuman teammates and adapt to mission performance metrics in real-time and in\nreal world scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:28:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Goecks", "Vinicius G.", ""]]}, {"id": "2008.13225", "submitter": "Tharun Kumar Reddy Medini", "authors": "Tharun Medini, Beidi Chen, Anshumali Shrivastava", "title": "SOLAR: Sparse Orthogonal Learned and Random Embeddings", "comments": "Under review at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense embedding models are commonly deployed in commercial search engines,\nwherein all the document vectors are pre-computed, and near-neighbor search\n(NNS) is performed with the query vector to find relevant documents. However,\nthe bottleneck of indexing a large number of dense vectors and performing an\nNNS hurts the query time and accuracy of these models. In this paper, we argue\nthat high-dimensional and ultra-sparse embedding is a significantly superior\nalternative to dense low-dimensional embedding for both query efficiency and\naccuracy. Extreme sparsity eliminates the need for NNS by replacing them with\nsimple lookups, while its high dimensionality ensures that the embeddings are\ninformative even when sparse. However, learning extremely high dimensional\nembeddings leads to blow up in the model size. To make the training feasible,\nwe propose a partitioning algorithm that learns such high dimensional\nembeddings across multiple GPUs without any communication. This is facilitated\nby our novel asymmetric mixture of Sparse, Orthogonal, Learned and Random\n(SOLAR) Embeddings. The label vectors are random, sparse, and near-orthogonal\nby design, while the query vectors are learned and sparse. We theoretically\nprove that our way of one-sided learning is equivalent to learning both query\nand label embeddings. With these unique properties, we can successfully train\n500K dimensional SOLAR embeddings for the tasks of searching through 1.6M books\nand multi-label classification on the three largest public datasets. We achieve\nsuperior precision and recall compared to the respective state-of-the-art\nbaselines for each of the tasks with up to 10 times faster speed.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:35:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Medini", "Tharun", ""], ["Chen", "Beidi", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2008.13229", "submitter": "Ernest Greene", "authors": "Ernest Greene", "title": "An evolutionary perspective on the design of neuromorphic shape filters", "comments": null, "journal-ref": "IEEE Access, 2020, 8, 114228-114238", "doi": "10.1109/ACCESS.2020_3004412", "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A substantial amount of time and energy has been invested to develop machine\nvision using connectionist (neural network) principles. Most of that work has\nbeen inspired by theories advanced by neuroscientists and behaviorists for how\ncortical systems store stimulus information. Those theories call for\ninformation flow through connections among several neuron populations, with the\ninitial connections being random (or at least non-functional). Then the\nstrength or location of connections are modified through training trials to\nachieve an effective output, such as the ability to identify an object. Those\ntheories ignored the fact that animals that have no cortex, e.g., fish, can\ndemonstrate visual skills that outpace the best neural network models. Neural\ncircuits that allow for immediate effective vision and quick learning have been\npreprogrammed by hundreds of millions of years of evolution and the visual\nskills are available shortly after hatching. Cortical systems may be providing\nadvanced image processing, but most likely are using design principles that had\nbeen proven effective in simpler systems. The present article provides a brief\noverview of retinal and cortical mechanisms for registering shape information,\nwith the hope that it might contribute to the design of shape-encoding circuits\nthat more closely match the mechanisms of biological vision.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:53:44 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Greene", "Ernest", ""]]}, {"id": "2008.13255", "submitter": "Anas Blasi", "authors": "Mohammed Alsuwaiket, Anas H. Blasi, Ra'Fat Al-Msie'deen", "title": "Formulating Module Assessment for Improved Academic Performance\n  Predictability in Higher Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various studies have shown that students tend to get higher marks when\nassessed through coursework based assessment methods which include either\nmodules that are fully assessed through coursework or a mixture of coursework\nand examinations than assessed by examination alone. There are a large number\nof educational data mining studies that preprocess data through conventional\ndata mining processes including data preparation process, but they are using\ntranscript data as they stand without looking at examination and coursework\nresults weighting which could affect prediction accuracy. This paper proposes a\ndifferent data preparation process through investigating more than 230000\nstudent records in order to prepare students marks based on the assessment\nmethods of enrolled modules. The data have been processed through different\nstages in order to extract a categorical factor through which students module\nmarks are refined during the data preparation process. The results of this work\nshow that students final marks should not be isolated from the nature of the\nenrolled modules assessment methods. They must rather be investigated\nthoroughly and considered during EDMs data preprocessing phases. More\ngenerally, it is concluded that educational data should not be prepared in the\nsame way as other data types due to differences as data sources, applications,\nand types of errors in them. Therefore, an attribute, coursework assessment\nratio, is proposed to be used in order to take the different modules assessment\nmethods into account while preparing student transcript data. The effect of CAR\non prediction process using the random forest classification technique has been\ninvestigated. It is shown that considering CAR as an attribute increases the\naccuracy of predicting students second year averages based on their first year\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 19:42:31 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Alsuwaiket", "Mohammed", ""], ["Blasi", "Anas H.", ""], ["Al-Msie'deen", "Ra'Fat", ""]]}, {"id": "2008.13261", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed", "title": "Benchmarking adversarial attacks and defenses for time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The adversarial vulnerability of deep networks has spurred the interest of\nresearchers worldwide. Unsurprisingly, like images, adversarial examples also\ntranslate to time-series data as they are an inherent weakness of the model\nitself rather than the modality. Several attempts have been made to defend\nagainst these adversarial attacks, particularly for the visual modality. In\nthis paper, we perform detailed benchmarking of well-proven adversarial defense\nmethodologies on time-series data. We restrict ourselves to the $L_{\\infty}$\nthreat model. We also explore the trade-off between smoothness and clean\naccuracy for regularization-based defenses to better understand the trade-offs\nthat they offer. Our analysis shows that the explored adversarial defenses\noffer robustness against both strong white-box as well as black-box attacks.\nThis paves the way for future research in the direction of adversarial attacks\nand defenses, particularly for time-series data.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:03:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2008.13265", "submitter": "Deepan Muthirayan", "authors": "Deepan Muthirayan and Pramod Khargonekar", "title": "A Meta-Learning Control Algorithm with Provable Finite-Time Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide provable regret guarantees for an online\nmeta-learning control algorithm in an iterative control setting, where in each\niteration the system to be controlled is a linear deterministic system that is\ndifferent and unknown, the cost for the controller in an iteration is a general\nadditive cost function and the control input is required to be constrained,\nwhich if violated incurs an additional cost. We prove (i) that the algorithm\nachieves a regret for the controller cost and constraint violation that are\n$O(T^{3/4})$ for an episode of duration $T$ with respect to the best policy\nthat satisfies the control input control constraints and (ii) that the average\nof the regret for the controller cost and constraint violation with respect to\nthe same policy vary as $O((1+\\log(N)/N)T^{3/4})$ with the number of iterations\n$N$, showing that the worst regret for the learning within an iteration\ncontinuously improves with experience of more iterations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 20:30:40 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 21:04:18 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 01:32:32 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 22:18:33 GMT"}, {"version": "v5", "created": "Thu, 8 Oct 2020 20:47:57 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Muthirayan", "Deepan", ""], ["Khargonekar", "Pramod", ""]]}, {"id": "2008.13278", "submitter": "Laura Giordano", "authors": "Laura Giordano, Valentina Gliozzi, Daniele Theseider Dupr\\'e", "title": "On a plausible concept-wise multipreference semantics and its relations\n  with self-organising maps", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": "TR-INF-2020-09-02-UNIPMN", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inthispaperwedescribeaconcept-wisemulti-preferencesemantics for description\nlogic which has its root in the preferential approach for modeling defeasible\nreasoning in knowledge representation. We argue that this proposal, beside\nsatisfying some desired properties, such as KLM postulates, and avoiding the\ndrowning problem, also defines a plausible notion of semantics. We motivate the\nplausibility of the concept-wise multi-preference semantics by developing a\nlogical semantics of self-organising maps, which have been proposed as possible\ncandidates to explain the psychological mechanisms underlying category\ngeneralisation, in terms of multi-preference interpretations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 21:06:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2008.13335", "submitter": "Thanh Tran", "authors": "Thanh Tran, Di You, Kyumin Lee", "title": "Quaternion-Based Self-Attentive Long Short-Term User Preference Encoding\n  for Recommendation", "comments": null, "journal-ref": "CIKM 2020", "doi": "10.1145/3340531.3411926", "report-no": null, "categories": "cs.IR cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quaternion space has brought several benefits over the traditional Euclidean\nspace: Quaternions (i) consist of a real and three imaginary components,\nencouraging richer representations; (ii) utilize Hamilton product which better\nencodes the inter-latent interactions across multiple Quaternion components;\nand (iii) result in a model with smaller degrees of freedom and less prone to\noverfitting. Unfortunately, most of the current recommender systems rely on\nreal-valued representations in Euclidean space to model either user's long-term\nor short-term interests. In this paper, we fully utilize Quaternion space to\nmodel both user's long-term and short-term preferences. We first propose a\nQUaternion-based self-Attentive Long term user Encoding (QUALE) to study the\nuser's long-term intents. Then, we propose a QUaternion-based self-Attentive\nShort term user Encoding (QUASE) to learn the user's short-term interests. To\nenhance our models' capability, we propose to fuse QUALE and QUASE into one\nmodel, namely QUALSE, by using a Quaternion-based gating mechanism. We further\ndevelop Quaternion-based Adversarial learning along with the Bayesian\nPersonalized Ranking (QABPR) to improve our model's robustness. Extensive\nexperiments on six real-world datasets show that our fused QUALSE model\noutperformed 11 state-of-the-art baselines, improving 8.43% at HIT@1 and 10.27%\nat NDCG@1 on average compared with the best baseline.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:22:14 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Tran", "Thanh", ""], ["You", "Di", ""], ["Lee", "Kyumin", ""]]}, {"id": "2008.13336", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "Shape Defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans rely heavily on shape information to recognize objects. Conversely,\nconvolutional neural networks (CNNs) are biased more towards texture. This is\nperhaps the main reason why CNNs are vulnerable to adversarial examples. Here,\nwe explore how shape bias can be incorporated into CNNs to improve their\nrobustness. Two algorithms are proposed, based on the observation that edges\nare invariant to moderate imperceptible perturbations. In the first one, a\nclassifier is adversarially trained on images with the edge map as an\nadditional channel. At inference time, the edge map is recomputed and\nconcatenated to the image. In the second algorithm, a conditional GAN is\ntrained to translate the edge maps, from clean and/or perturbed images, into\nclean images. Inference is done over the generated image corresponding to the\ninput's edge map. Extensive experiments over 10 datasets demonstrate the\neffectiveness of the proposed algorithms against FGSM and $\\ell_\\infty$ PGD-40\nattacks. Further, we show that a) edge information can also benefit other\nadversarial training methods, and b) CNNs trained on edge-augmented inputs are\nmore robust against natural image corruptions such as motion blur, impulse\nnoise and JPEG compression, than CNNs trained solely on RGB images. From a\nbroader perspective, our study suggests that CNNs do not adequately account for\nimage structures that are crucial for robustness. Code is available\nat:~\\url{https://github.com/aliborji/Shapedefence.git}.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:23:59 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2008.13351", "submitter": "Yang Yang", "authors": "Yang Yang, Zhen-Qiang Sun, HengShu Zhu, Yanjie Fu, Hui Xiong, Jian\n  Yang", "title": "Learning Adaptive Embedding Considering Incremental Class", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-Incremental Learning (CIL) aims to train a reliable model with the\nstreaming data, which emerges unknown classes sequentially. Different from\ntraditional closed set learning, CIL has two main challenges: 1) Novel class\ndetection. The initial training data only contains incomplete classes, and\nstreaming test data will accept unknown classes. Therefore, the model needs to\nnot only accurately classify known classes, but also effectively detect unknown\nclasses; 2) Model expansion. After the novel classes are detected, the model\nneeds to be updated without re-training using entire previous data. However,\ntraditional CIL methods have not fully considered these two challenges, first,\nthey are always restricted to single novel class detection each phase and\nembedding confusion caused by unknown classes. Besides, they also ignore the\ncatastrophic forgetting of known categories in model update. To this end, we\npropose a Class-Incremental Learning without Forgetting (CILF) framework, which\naims to learn adaptive embedding for processing novel class detection and model\nupdate in a unified framework. In detail, CILF designs to regularize\nclassification with decoupled prototype based loss, which can improve the\nintra-class and inter-class structure significantly, and acquire a compact\nembedding representation for novel class detection in result. Then, CILF\nemploys a learnable curriculum clustering operator to estimate the number of\nsemantic clusters via fine-tuning the learned network, in which curriculum\noperator can adaptively learn the embedding in self-taught form. Therefore,\nCILF can detect multiple novel classes and mitigate the embedding confusion\nproblem. Last, with the labeled streaming test data, CILF can update the\nnetwork with robust regularization to mitigate the catastrophic forgetting.\nConsequently, CILF is able to iteratively perform novel class detection and\nmodel update.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 04:11:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Yang", "Yang", ""], ["Sun", "Zhen-Qiang", ""], ["Zhu", "HengShu", ""], ["Fu", "Yanjie", ""], ["Xiong", "Hui", ""], ["Yang", "Jian", ""]]}, {"id": "2008.13377", "submitter": "Zahra Anvari", "authors": "Zahra Anvari, Vassilis Athitsos", "title": "Evaluating Single Image Dehazing Methods Under Realistic Sunlight Haze", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haze can degrade the visibility and the image quality drastically, thus\ndegrading the performance of computer vision tasks such as object detection.\nSingle image dehazing is a challenging and ill-posed problem, despite being\nwidely studied. Most existing methods assume that haze has a\nuniform/homogeneous distribution and haze can have a single color, i.e. grayish\nwhite color similar to smoke, while in reality haze can be distributed\nnon-uniformly with different patterns and colors. In this paper, we focus on\nhaze created by sunlight as it is one of the most prevalent type of haze in the\nwild. Sunlight can generate non-uniformly distributed haze with drastic density\nchanges due to sun rays and also a spectrum of haze color due to sunlight color\nchanges during the day. This presents a new challenge to image dehazing\nmethods. For these methods to be practical, this problem needs to be addressed.\nTo quantify the challenges and assess the performance of these methods, we\npresent a sunlight haze benchmark dataset, Sun-Haze, containing 107 hazy images\nwith different types of haze created by sunlight having a variety of intensity\nand color. We evaluate a representative set of state-of-the-art image dehazing\nmethods on this benchmark dataset in terms of standard metrics such as PSNR,\nSSIM, CIEDE2000, PI and NIQE. This uncovers the limitation of the current\nmethods, and questions their underlying assumptions as well as their\npracticality.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:53:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Anvari", "Zahra", ""], ["Athitsos", "Vassilis", ""]]}, {"id": "2008.13429", "submitter": "Zhao Kang", "authors": "Zhao Kang and Chong Peng and Qiang Cheng and Xinwang Liu and Xi Peng\n  and Zenglin Xu and Ling Tian", "title": "Structured Graph Learning for Clustering and Semi-supervised\n  Classification", "comments": "Appear in Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs have become increasingly popular in modeling structures and\ninteractions in a wide variety of problems during the last decade. Graph-based\nclustering and semi-supervised classification techniques have shown impressive\nperformance. This paper proposes a graph learning framework to preserve both\nthe local and global structure of data. Specifically, our method uses the\nself-expressiveness of samples to capture the global structure and adaptive\nneighbor approach to respect the local structure. Furthermore, most existing\ngraph-based methods conduct clustering and semi-supervised classification on\nthe graph learned from the original data matrix, which doesn't have explicit\ncluster structure, thus they might not achieve the optimal performance. By\nconsidering rank constraint, the achieved graph will have exactly $c$ connected\ncomponents if there are $c$ clusters or classes. As a byproduct of this, graph\nlearning and label inference are jointly and iteratively implemented in a\nprincipled way. Theoretically, we show that our model is equivalent to a\ncombination of kernel k-means and k-means methods under certain condition.\nExtensive experiments on clustering and semi-supervised classification\ndemonstrate that the proposed method outperforms other state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 08:41:20 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""], ["Liu", "Xinwang", ""], ["Peng", "Xi", ""], ["Xu", "Zenglin", ""], ["Tian", "Ling", ""]]}, {"id": "2008.13503", "submitter": "Barbora Hudcova", "authors": "Barbora Hudcova, Tomas Mikolov", "title": "Classification of Complex Systems Based on Transients", "comments": "9 pages", "journal-ref": "Artificial Life Conference Proceedings 32 (2020), 367-375", "doi": "10.1162/isal_a_00260", "report-no": null, "categories": "nlin.CG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to develop systems capable of modeling artificial life, we need to\nidentify, which systems can produce complex behavior. We present a novel\nclassification method applicable to any class of deterministic discrete space\nand time dynamical systems. The method distinguishes between different\nasymptotic behaviors of a system's average computation time before entering a\nloop. When applied to elementary cellular automata, we obtain classification\nresults, which correlate very well with Wolfram's manual classification.\nFurther, we use it to classify 2D cellular automata to show that our technique\ncan easily be applied to more complex models of computation. We believe this\nclassification method can help to develop systems, in which complex structures\nemerge.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 11:47:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hudcova", "Barbora", ""], ["Mikolov", "Tomas", ""]]}, {"id": "2008.13507", "submitter": "Manuel Marin-Jimenez", "authors": "Zihao Mu and Francisco M. Castro and Manuel J. Marin-Jimenez and\n  Nicolas Guil and Yan-ran Li and Shiqi Yu", "title": "iLGaCo: Incremental Learning of Gait Covariate Factors", "comments": "Accepted for presentation at IJCB'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gait is a popular biometric pattern used for identifying people based on\ntheir way of walking. Traditionally, gait recognition approaches based on deep\nlearning are trained using the whole training dataset. In fact, if new data\n(classes, view-points, walking conditions, etc.) need to be included, it is\nnecessary to re-train again the model with old and new data samples.\n  In this paper, we propose iLGaCo, the first incremental learning approach of\ncovariate factors for gait recognition, where the deep model can be updated\nwith new information without re-training it from scratch by using the whole\ndataset. Instead, our approach performs a shorter training process with the new\ndata and a small subset of previous samples. This way, our model learns new\ninformation while retaining previous knowledge.\n  We evaluate iLGaCo on CASIA-B dataset in two incremental ways: adding new\nview-points and adding new walking conditions. In both cases, our results are\nclose to the classical `training-from-scratch' approach, obtaining a marginal\ndrop in accuracy ranging from 0.2% to 1.2%, what shows the efficacy of our\napproach. In addition, the comparison of iLGaCo with other incremental learning\nmethods, such as LwF and iCarl, shows a significant improvement in accuracy,\nbetween 6% and 15% depending on the experiment.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 11:52:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mu", "Zihao", ""], ["Castro", "Francisco M.", ""], ["Marin-Jimenez", "Manuel J.", ""], ["Guil", "Nicolas", ""], ["Li", "Yan-ran", ""], ["Yu", "Shiqi", ""]]}, {"id": "2008.13516", "submitter": "Dilruk Perera", "authors": "Dilruk Perera and Roger Zimmermann", "title": "Towards Comprehensive Recommender Systems: Time-Aware\n  UnifiedcRecommendations Based on Listwise Ranking of Implicit Cross-Network\n  Data", "comments": null, "journal-ref": "Association for the Advancement of Artificial Intelligence, 2020\n  (AAAI'20)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of information in web applications make recommendation\nessential for users as well as applications. Despite the effectiveness of\nexisting recommender systems, we find two major limitations that reduce their\noverall performance: (1) inability to provide timely recommendations for both\nnew and existing users by considering the dynamic nature of user preferences,\nand (2) not fully optimized for the ranking task when using implicit feedback.\nTherefore, we propose a novel deep learning based unified cross-network\nsolution to mitigate cold-start and data sparsity issues and provide timely\nrecommendations for new and existing users.Furthermore, we consider the ranking\nproblem under implicit feedback as a classification task, and propose a generic\npersonalized listwise optimization criterion for implicit data to effectively\nrank a list of items. We illustrate our cross-network model using Twitter\nauxiliary information for recommendations on YouTube target network. Extensive\ncomparisons against multiple time aware and cross-network base-lines show that\nthe proposed solution is superior in terms of accuracy, novelty and diversity.\nFurthermore, experiments conducted on the popular MovieLens dataset suggest\nthat the proposed listwise ranking method outperforms existing state-of-the-art\nranking techniques.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:08:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Perera", "Dilruk", ""], ["Zimmermann", "Roger", ""]]}, {"id": "2008.13526", "submitter": "Sami Khenissi", "authors": "Sami Khenissi and Mariem Boujelbene and Olfa Nasraoui", "title": "Theoretical Modeling of the Iterative Properties of User Discovery in a\n  Collaborative Filtering Recommender System", "comments": "Accepted in Recsys2020. Code available at:\n  https://github.com/samikhenissi/TheoretUserModeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The closed feedback loop in recommender systems is a common setting that can\nlead to different types of biases. Several studies have dealt with these biases\nby designing methods to mitigate their effect on the recommendations. However,\nmost existing studies do not consider the iterative behavior of the system\nwhere the closed feedback loop plays a crucial role in incorporating different\nbiases into several parts of the recommendation steps.\n  We present a theoretical framework to model the asymptotic evolution of the\ndifferent components of a recommender system operating within a feedback loop\nsetting, and derive theoretical bounds and convergence properties on\nquantifiable measures of the user discovery and blind spots. We also validate\nour theoretical findings empirically using a real-life dataset and empirically\ntest the efficiency of a basic exploration strategy within our theoretical\nframework.\n  Our findings lay the theoretical basis for quantifying the effect of feedback\nloops and for designing Artificial Intelligence and machine learning algorithms\nthat explicitly incorporate the iterative nature of feedback loops in the\nmachine learning and recommendation process.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:30:39 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Khenissi", "Sami", ""], ["Boujelbene", "Mariem", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2008.13544", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera, Rricha Jalota, Mohamed A. Sherif, Axel N. Ngomo", "title": "I-AID: Identifying Actionable Information from Disaster-related Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media plays a significant role in disaster management by providing\nvaluable data about affected people, donations and help requests. Recent\nstudies highlight the need to filter information on social media into\nfine-grained content labels. However, identifying useful information from\nmassive amounts of social media posts during a crisis is a challenging task. In\nthis paper, we propose I-AID, a multimodel approach to automatically categorize\ntweets into multi-label information types and filter critical information from\nthe enormous volume of social media data. I-AID incorporates three main\ncomponents: i) a BERT-based encoder to capture the semantics of a tweet and\nrepresent as a low-dimensional vector, ii) a graph attention network (GAT) to\napprehend correlations between tweets' words/entities and the corresponding\ninformation types, and iii) a Relation Network as a learnable distance metric\nto compute the similarity between tweets and their corresponding information\ntypes in a supervised way. We conducted several experiments on two real\npublicly-available datasets. Our results indicate that I-AID outperforms\nstate-of-the-art approaches in terms of weighted average F1 score by +6% and\n+4% on the TREC-IS dataset and COVID-19 Tweets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:07:50 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:32:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Jalota", "Rricha", ""], ["Sherif", "Mohamed A.", ""], ["Ngomo", "Axel N.", ""]]}, {"id": "2008.13548", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Seth Cooper", "title": "Towards Game Design via Creative Machine Learning (GDCML)", "comments": "6 pages, 4 figures, IEEE Conference on Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning (ML) systems have been increasingly applied\nfor performing creative tasks. Such creative ML approaches have seen wide use\nin the domains of visual art and music for applications such as image and music\ngeneration and style transfer. However, similar creative ML techniques have not\nbeen as widely adopted in the domain of game design despite the emergence of\nML-based methods for generating game content. In this paper, we argue for\nleveraging and repurposing such creative techniques for designing content for\ngames, referring to these as approaches for Game Design via Creative ML\n(GDCML). We highlight existing systems that enable GDCML and illustrate how\ncreative ML can inform new systems via example applications and a proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 21:15:55 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Sarkar", "Anurag", ""], ["Cooper", "Seth", ""]]}, {"id": "2008.13559", "submitter": "Shatrughan Modi", "authors": "Shatrughan Modi, Jhilik Bhattacharya, Prasenjit Basak", "title": "Convolutional Neural Network-Bagged Decision Tree: A hybrid approach to\n  reduce electric vehicle's driver's range anxiety by estimating energy\n  consumption in real-time", "comments": null, "journal-ref": "Soft Computing, October 2020", "doi": "10.1007/s00500-020-05310-y", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome range anxiety problem of Electric Vehicles (EVs), an accurate\nreal-time energy consumption estimation is necessary, which can be used to\nprovide the EV's driver with information about the remaining range in\nreal-time. A hybrid CNN-BDT approach has been developed, in which Convolutional\nNeural Network (CNN) is used to provide an energy consumption estimate\nconsidering the effect of temperature, wind speed, battery's SOC, auxiliary\nloads, road elevation, vehicle speed and acceleration. Further, Bagged Decision\nTree (BDT) is used to fine tune the estimate. Unlike existing techniques, the\nproposed approach doesn't require internal vehicle parameters from manufacturer\nand can easily learn complex patterns even from noisy data. Comparison results\nwith existing techniques show that the developed approach provides better\nestimates with least mean absolute energy deviation of 0.14.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 12:45:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Modi", "Shatrughan", ""], ["Bhattacharya", "Jhilik", ""], ["Basak", "Prasenjit", ""]]}, {"id": "2008.13597", "submitter": "Somnath Banerjee", "authors": "Somnath Banerjee, Sudip Kumar Naskar, Paolo Rosso and Sivaji\n  Bandyopadhyay", "title": "Classifier Combination Approach for Question Classification for Bengali\n  Question Answering System", "comments": "16 pages, to be published in Sadhana", "journal-ref": "Sadhana, Springer, 2019", "doi": "10.1007/s12046-019-1224-8", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question classification (QC) is a prime constituent of automated question\nanswering system. The work presented here demonstrates that the combination of\nmultiple models achieve better classification performance than those obtained\nwith existing individual models for the question classification task in\nBengali. We have exploited state-of-the-art multiple model combination\ntechniques, i.e., ensemble, stacking and voting, to increase QC accuracy.\nLexical, syntactic and semantic features of Bengali questions are used for four\nwell-known classifiers, namely Na\\\"{\\i}ve Bayes, kernel Na\\\"{\\i}ve Bayes, Rule\nInduction, and Decision Tree, which serve as our base learners. Single-layer\nquestion-class taxonomy with 8 coarse-grained classes is extended to two-layer\ntaxonomy by adding 69 fine-grained classes. We carried out the experiments both\non single-layer and two-layer taxonomies. Experimental results confirmed that\nclassifier combination approaches outperform single classifier classification\napproaches by 4.02% for coarse-grained question classes. Overall, the stacking\napproach produces the best results for fine-grained classification and achieves\n87.79% of accuracy. The approach presented here could be used in other\nIndo-Aryan or Indic languages to develop a question answering system.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:39:04 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 14:47:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Banerjee", "Somnath", ""], ["Naskar", "Sudip Kumar", ""], ["Rosso", "Paolo", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2008.13600", "submitter": "Dionysis Manousakas", "authors": "Dionysis Manousakas and Cecilia Mascolo", "title": "$\\beta$-Cores: Robust Large-Scale Bayesian Data Summarization in the\n  Presence of Outliers", "comments": "25 pages, 5 figures, Accepted at the 14th ACM International\n  Conference on Web Search and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning applications should be able to address the intrinsic\nchallenges arising over inference on massive real-world datasets, including\nscalability and robustness to outliers. Despite the multiple benefits of\nBayesian methods (such as uncertainty-aware predictions, incorporation of\nexperts knowledge, and hierarchical modeling), the quality of classic Bayesian\ninference depends critically on whether observations conform with the assumed\ndata generating model, which is impossible to guarantee in practice. In this\nwork, we propose a variational inference method that, in a principled way, can\nsimultaneously scale to large datasets, and robustify the inferred posterior\nwith respect to the existence of outliers in the observed data. Reformulating\nBayes theorem via the $\\beta$-divergence, we posit a robustified\npseudo-Bayesian posterior as the target of inference. Moreover, relying on the\nrecent formulations of Riemannian coresets for scalable Bayesian inference, we\npropose a sparse variational approximation of the robustified posterior and an\nefficient stochastic black-box algorithm to construct it. Overall our method\nallows releasing cleansed data summaries that can be applied broadly in\nscenarios including structured data corruption. We illustrate the applicability\nof our approach in diverse simulated and real datasets, and various statistical\nmodels, including Gaussian mean inference, logistic and neural linear\nregression, demonstrating its superiority to existing Bayesian summarization\nmethods in the presence of outliers.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:47:12 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 10:25:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Manousakas", "Dionysis", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2008.13618", "submitter": "Zhenyu A. Liao", "authors": "Zhenyu A. Liao, Charupriya Sharma, James Cussens, Peter van Beek", "title": "Learning All Credible Bayesian Network Structures for Model Averaging", "comments": "under review by JMLR. arXiv admin note: substantial text overlap with\n  arXiv:1811.05039", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a widely used probabilistic graphical model with\napplications in knowledge discovery and prediction. Learning a Bayesian network\n(BN) from data can be cast as an optimization problem using the well-known\nscore-and-search approach. However, selecting a single model (i.e., the best\nscoring BN) can be misleading or may not achieve the best possible accuracy. An\nalternative to committing to a single model is to perform some form of Bayesian\nor frequentist model averaging, where the space of possible BNs is sampled or\nenumerated in some fashion. Unfortunately, existing approaches for model\naveraging either severely restrict the structure of the Bayesian network or\nhave only been shown to scale to networks with fewer than 30 random variables.\nIn this paper, we propose a novel approach to model averaging inspired by\nperformance guarantees in approximation algorithms. Our approach has two\nprimary advantages. First, our approach only considers credible models in that\nthey are optimal or near-optimal in score. Second, our approach is more\nefficient and scales to significantly larger Bayesian networks than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:56:27 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Liao", "Zhenyu A.", ""], ["Sharma", "Charupriya", ""], ["Cussens", "James", ""], ["van Beek", "Peter", ""]]}, {"id": "2008.13671", "submitter": "Ajaya Adhikari", "authors": "Ajaya Adhikari, Richard den Hollander, Ioannis Tolios, Michael van\n  Bekkum, Anneloes Bal, Stijn Hendriks, Maarten Kruithof, Dennis Gross, Nils\n  Jansen, Guillermo P\\'erez, Kit Buurman, Stephan Raaijmakers", "title": "Adversarial Patch Camouflage against Aerial Detection", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of military assets on the ground can be performed by applying deep\nlearning-based object detectors on drone surveillance footage. The traditional\nway of hiding military assets from sight is camouflage, for example by using\ncamouflage nets. However, large assets like planes or vessels are difficult to\nconceal by means of traditional camouflage nets. An alternative type of\ncamouflage is the direct misleading of automatic object detectors. Recently, it\nhas been observed that small adversarial changes applied to images of the\nobject can produce erroneous output by deep learning-based detectors. In\nparticular, adversarial attacks have been successfully demonstrated to prohibit\nperson detections in images, requiring a patch with a specific pattern held up\nin front of the person, thereby essentially camouflaging the person for the\ndetector. Research into this type of patch attacks is still limited and several\nquestions related to the optimal patch configuration remain open.\n  This work makes two contributions. First, we apply patch-based adversarial\nattacks for the use case of unmanned aerial surveillance, where the patch is\nlaid on top of large military assets, camouflaging them from automatic\ndetectors running over the imagery. The patch can prevent automatic detection\nof the whole object while only covering a small part of it. Second, we perform\nseveral experiments with different patch configurations, varying their size,\nposition, number and saliency. Our results show that adversarial patch attacks\nform a realistic alternative to traditional camouflage activities, and should\ntherefore be considered in the automated analysis of aerial surveillance\nimagery.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:21:50 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Adhikari", "Ajaya", ""], ["Hollander", "Richard den", ""], ["Tolios", "Ioannis", ""], ["van Bekkum", "Michael", ""], ["Bal", "Anneloes", ""], ["Hendriks", "Stijn", ""], ["Kruithof", "Maarten", ""], ["Gross", "Dennis", ""], ["Jansen", "Nils", ""], ["P\u00e9rez", "Guillermo", ""], ["Buurman", "Kit", ""], ["Raaijmakers", "Stephan", ""]]}, {"id": "2008.13712", "submitter": "Rohitkumar Arasanipalai", "authors": "Aakriti Agrawal, V S Rajashekhar, Rohitkumar Arasanipalai and Debasish\n  Ghose", "title": "Control of a Nature-inspired Scorpion using Reinforcement Learning", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A terrestrial robot that can maneuver rough terrain and scout places is very\nuseful in mapping out unknown areas. It can also be used explore dangerous\nareas in place of humans. A terrestrial robot modeled after a scorpion will be\nable to traverse undetected and can be used for surveillance purposes.\nTherefore, this paper proposes modelling of a scorpion inspired robot and a\nreinforcement learning (RL) based controller for navigation. The robot scorpion\nuses serial four bar mechanisms for the legs movements. It also has an active\ntail and a movable claw. The controller is trained to navigate the robot\nscorpion to the target waypoint. The simulation results demonstrate efficient\nnavigation of the robot scorpion.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 16:24:58 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Agrawal", "Aakriti", ""], ["Rajashekhar", "V S", ""], ["Arasanipalai", "Rohitkumar", ""], ["Ghose", "Debasish", ""]]}, {"id": "2008.13759", "submitter": "Gurkirt Singh", "authors": "Gurkirt Singh", "title": "Online Spatiotemporal Action Detection and Prediction via Causal\n  Representations", "comments": "PhD thesis, Oxford Brookes University, Examiners: Dr. Andrea Vedaldi\n  and Dr. Fridolin Wild, 172 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we focus on video action understanding problems from an\nonline and real-time processing point of view. We start with the conversion of\nthe traditional offline spatiotemporal action detection pipeline into an online\nspatiotemporal action tube detection system. An action tube is a set of\nbounding connected over time, which bounds an action instance in space and\ntime. Next, we explore the future prediction capabilities of such detection\nmethods by extending an existing action tube into the future by regression.\nLater, we seek to establish that online/causal representations can achieve\nsimilar performance to that of offline three dimensional (3D) convolutional\nneural networks (CNNs) on various tasks, including action recognition, temporal\naction segmentation and early prediction.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:28:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Singh", "Gurkirt", ""]]}, {"id": "2008.13769", "submitter": "Maitree Leekha", "authors": "Shahid Nawaz Khan, Maitree Leekha, Jainendra Shukla, Rajiv Ratn Shah", "title": "Vyaktitv: A Multimodal Peer-to-Peer Hindi Conversations based Dataset\n  for Personality Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically detecting personality traits can aid several applications, such\nas mental health recognition and human resource management. Most datasets\nintroduced for personality detection so far have analyzed these traits for each\nindividual in isolation. However, personality is intimately linked to our\nsocial behavior. Furthermore, surprisingly little research has focused on\npersonality analysis using low resource languages. To this end, we present a\nnovel peer-to-peer Hindi conversation dataset- Vyaktitv. It consists of\nhigh-quality audio and video recordings of the participants, with Hinglish\ntextual transcriptions for each conversation. The dataset also contains a rich\nset of socio-demographic features, like income, cultural orientation, amongst\nseveral others, for all the participants. We release the dataset for public\nuse, as well as perform preliminary statistical analysis along the different\ndimensions. Finally, we also discuss various other applications and tasks for\nwhich the dataset can be employed.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 17:44:28 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Khan", "Shahid Nawaz", ""], ["Leekha", "Maitree", ""], ["Shukla", "Jainendra", ""], ["Shah", "Rajiv Ratn", ""]]}]