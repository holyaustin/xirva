[{"id": "1902.00014", "submitter": "Carsten Lutz", "authors": "Elena Botoeva and Carsten Lutz and Vladislav Ryzhikov and Frank Wolter\n  and Michael Zakharyaschev", "title": "Query Inseparability for ALC Ontologies", "comments": "arXiv admin note: text overlap with arXiv:1604.04164", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem whether two ALC ontologies are indistinguishable\n(or inseparable) by means of queries in a given signature, which is fundamental\nfor ontology engineering tasks such as ontology versioning, modularisation,\nupdate, and forgetting. We consider both knowledge base (KB) and TBox\ninseparability. For KBs, we give model-theoretic criteria in terms of (finite\npartial) homomorphisms and products and prove that this problem is undecidable\nfor conjunctive queries (CQs), but 2ExpTime-complete for unions of CQs (UCQs).\nThe same results hold if (U)CQs are replaced by rooted (U)CQs, where every\nvariable is connected to an answer variable. We also show that inseparability\nby CQs is still undecidable if one KB is given in the lightweight DL EL and if\nno restrictions are imposed on the signature of the CQs. We also consider the\nproblem whether two ALC TBoxes give the same answers to any query over any ABox\nin a given signature and show that, for CQs, this problem is undecidable, too.\nWe then develop model-theoretic criteria for Horn-ALC TBoxes and show using\ntree automata that, in contrast, inseparability becomes decidable and\n2ExpTime-complete, even ExpTime-complete when restricted to (unions of) rooted\nCQs.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 13:58:48 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Botoeva", "Elena", ""], ["Lutz", "Carsten", ""], ["Ryzhikov", "Vladislav", ""], ["Wolter", "Frank", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1902.00016", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razdehi, Slava Voloshynovskiy", "title": "Network Parameter Learning Using Nonlinear Transforms, Local\n  Representation Goals and Local Propagation Constraints", "comments": "arXiv admin note: text overlap with arXiv:1805.07802", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel concept for learning of the parameters in\na neural network. Our idea is grounded on modeling a learning problem that\naddresses a trade-off between (i) satisfying local objectives at each node and\n(ii) achieving desired data propagation through the network under (iii) local\npropagation constraints. We consider two types of nonlinear transforms which\ndescribe the network representations. One of the nonlinear transforms serves as\nactivation function. The other one enables a locally adjusted, deviation\ncorrective components to be included in the update of the network weights in\norder to enable attaining target specific representations at the last network\nnode. Our learning principle not only provides insight into the understanding\nand the interpretation of the learning dynamics, but it offers theoretical\nguarantees over decoupled and parallel parameter estimation strategy that\nenables learning in synchronous and asynchronous mode. Numerical experiments\nvalidate the potential of our approach on image recognition task. The\npreliminary results show advantages in comparison to the state-of-the-art\nmethods, w.r.t. the learning time and the network size while having competitive\nrecognition accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 14:43:55 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razdehi", "Behrooz", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1902.00040", "submitter": "David Melhart", "authors": "David Melhart, Ahmad Azadvar, Alessandro Canossa, Antonios Liapis,\n  Georgios N. Yannakakis", "title": "Your Gameplay Says It All: Modelling Motivation in Tom Clancy's The\n  Division", "comments": "Version accepted for IEEE Conference on Games, 2019", "journal-ref": "Proceedings of the 2019 International IEEE Conference on Games\n  (CoG 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to predict the motivation of players just by observing their\ngameplay data? Even if so, how should we measure motivation in the first place?\nTo address the above questions, on the one end, we collect a large dataset of\ngameplay data from players of the popular game Tom Clancy's The Division. On\nthe other end, we ask them to report their levels of competence, autonomy,\nrelatedness and presence using the Ubisoft Perceived Experience Questionnaire.\nAfter processing the survey responses in an ordinal fashion we employ\npreference learning methods based on support vector machines to infer the\nmapping between gameplay and the reported four motivation factors. Our key\nfindings suggest that gameplay features are strong predictors of player\nmotivation as the best obtained models reach accuracies of near certainty, from\n92% up to 94% on unseen players.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:15:04 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 09:04:06 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Melhart", "David", ""], ["Azadvar", "Ahmad", ""], ["Canossa", "Alessandro", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "1902.00045", "submitter": "Andrija Petrovic", "authors": "Andrija Petrovi\\'c and Mladen Nikoli\\'c and Milo\\v{s} Jovanovi\\'c and\n  Boris Deliba\\v{s}i\\'c", "title": "Gaussian Conditional Random Fields for Classification", "comments": "Draft paper without experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian conditional random fields (GCRF) are a well-known used structured\nmodel for continuous outputs that uses multiple unstructured predictors to form\nits features and at the same time exploits dependence structure among outputs,\nwhich is provided by a similarity measure. In this paper, a Gaussian\nconditional random fields model for structured binary classification (GCRFBC)\nis proposed. The model is applicable to classification problems with undirected\ngraphs, intractable for standard classification CRFs. The model representation\nof GCRFBC is extended by latent variables which yield some appealing\nproperties. Thanks to the GCRF latent structure, the model becomes tractable,\nefficient and open to improvements previously applied to GCRF regression\nmodels. In addition, the model allows for reduction of noise, that might appear\nif structures were defined directly between discrete outputs. Additionally, two\ndifferent forms of the algorithm are presented: GCRFBCb (GCRGBC - Bayesian) and\nGCRFBCnb (GCRFBC - non Bayesian). The extended method of local variational\napproximation of sigmoid function is used for solving empirical Bayes in\nBayesian GCRFBCb variant, whereas MAP value of latent variables is the basis\nfor learning and inference in the GCRFBCnb variant. The inference in GCRFBCb is\nsolved by Newton-Cotes formulas for one-dimensional integration. Both models\nare evaluated on synthetic data and real-world data. It was shown that both\nmodels achieve better prediction performance than unstructured predictors.\nFurthermore, computational and memory complexity is evaluated. Advantages and\ndisadvantages of the proposed GCRFBCb and GCRFBCnb are discussed in detail.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 19:33:13 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Petrovi\u0107", "Andrija", ""], ["Nikoli\u0107", "Mladen", ""], ["Jovanovi\u0107", "Milo\u0161", ""], ["Deliba\u0161i\u0107", "Boris", ""]]}, {"id": "1902.00089", "submitter": "Meixin Zhu", "authors": "Meixin Zhu, Yinhai Wang, Ziyuan Pu, Jingyun Hu, Xuesong Wang, Ruimin\n  Ke", "title": "Safe, Efficient, and Comfortable Velocity Control based on Reinforcement\n  Learning for Autonomous Driving", "comments": "Under the first-round revision for transportation research part c", "journal-ref": "Transportation Research Part C: Emerging Technologies 2020", "doi": "10.1016/j.trc.2020.102662", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model used for velocity control during car following was proposed based on\ndeep reinforcement learning (RL). To fulfil the multi-objectives of car\nfollowing, a reward function reflecting driving safety, efficiency, and comfort\nwas constructed. With the reward function, the RL agent learns to control\nvehicle speed in a fashion that maximizes cumulative rewards, through trials\nand errors in the simulation environment. A total of 1,341 car-following events\nextracted from the Next Generation Simulation (NGSIM) dataset were used to\ntrain the model. Car-following behavior produced by the model were compared\nwith that observed in the empirical NGSIM data, to demonstrate the model's\nability to follow a lead vehicle safely, efficiently, and comfortably. Results\nshow that the model demonstrates the capability of safe, efficient, and\ncomfortable velocity control in that it 1) has small percentages (8\\%) of\ndangerous minimum time to collision values (\\textless\\ 5s) than human drivers\nin the NGSIM data (35\\%); 2) can maintain efficient and safe headways in the\nrange of 1s to 2s; and 3) can follow the lead vehicle comfortably with smooth\nacceleration. The results indicate that reinforcement learning methods could\ncontribute to the development of autonomous driving systems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 20:04:40 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 03:57:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhu", "Meixin", ""], ["Wang", "Yinhai", ""], ["Pu", "Ziyuan", ""], ["Hu", "Jingyun", ""], ["Wang", "Xuesong", ""], ["Ke", "Ruimin", ""]]}, {"id": "1902.00098", "submitter": "Emily Dinan", "authors": "Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander Miller,\n  Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan\n  Lowe, Shrimai Prabhumoye, Alan W Black, Alexander Rudnicky, Jason Williams,\n  Joelle Pineau, Mikhail Burtsev, Jason Weston", "title": "The Second Conversational Intelligence Challenge (ConvAI2)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the setting and results of the ConvAI2 NeurIPS competition that\naims to further the state-of-the-art in open-domain chatbots. Some key\ntakeaways from the competition are: (i) pretrained Transformer variants are\ncurrently the best performing models on this task, (ii) but to improve\nperformance on multi-turn conversations with humans, future systems must go\nbeyond single word metrics like perplexity to measure the performance across\nsequences of utterances (conversations) -- in terms of repetition, consistency\nand balance of dialogue acts (e.g. how many questions asked vs. answered).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:14:34 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Dinan", "Emily", ""], ["Logacheva", "Varvara", ""], ["Malykh", "Valentin", ""], ["Miller", "Alexander", ""], ["Shuster", "Kurt", ""], ["Urbanek", "Jack", ""], ["Kiela", "Douwe", ""], ["Szlam", "Arthur", ""], ["Serban", "Iulian", ""], ["Lowe", "Ryan", ""], ["Prabhumoye", "Shrimai", ""], ["Black", "Alan W", ""], ["Rudnicky", "Alexander", ""], ["Williams", "Jason", ""], ["Pineau", "Joelle", ""], ["Burtsev", "Mikhail", ""], ["Weston", "Jason", ""]]}, {"id": "1902.00120", "submitter": "Felix Hill Mr", "authors": "Felix Hill, Adam Santoro, David G.T. Barrett, Ari S. Morcos and\n  Timothy Lillicrap", "title": "Learning to Make Analogies by Contrasting Abstract Relational Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogical reasoning has been a principal focus of various waves of AI\nresearch. Analogy is particularly challenging for machines because it requires\nrelational structures to be represented such that they can be flexibly applied\nacross diverse domains of experience. Here, we study how analogical reasoning\ncan be induced in neural networks that learn to perceive and reason about raw\nvisual data. We find that the critical factor for inducing such a capacity is\nnot an elaborate architecture, but rather, careful attention to the choice of\ndata and the manner in which it is presented to the model. The most robust\ncapacity for analogical reasoning is induced when networks learn analogies by\ncontrasting abstract relational structures in their input domains, a training\nmethod that uses only the input data to force models to learn about important\nabstract features. Using this technique we demonstrate capacities for complex,\nvisual and symbolic analogy making and generalisation in even the simplest\nneural network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:10:31 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Hill", "Felix", ""], ["Santoro", "Adam", ""], ["Barrett", "David G. T.", ""], ["Morcos", "Ari S.", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1902.00137", "submitter": "Kyungjae Lee", "authors": "Kyungjae Lee and Sungyub Kim and Sungbin Lim and Sungjoon Choi and\n  Songhwai Oh", "title": "Tsallis Reinforcement Learning: A Unified Framework for Maximum Entropy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new class of Markov decision processes (MDPs),\ncalled Tsallis MDPs, with Tsallis entropy maximization, which generalizes\nexisting maximum entropy reinforcement learning (RL). A Tsallis MDP provides a\nunified framework for the original RL problem and RL with various types of\nentropy, including the well-known standard Shannon-Gibbs (SG) entropy, using an\nadditional real-valued parameter, called an entropic index. By controlling the\nentropic index, we can generate various types of entropy, including the SG\nentropy, and a different entropy results in a different class of the optimal\npolicy in Tsallis MDPs. We also provide a full mathematical analysis of Tsallis\nMDPs, including the optimality condition, performance error bounds, and\nconvergence. Our theoretical result enables us to use any positive entropic\nindex in RL. To handle complex and large-scale problems, we propose a\nmodel-free actor-critic RL method using Tsallis entropy maximization. We\nevaluate the regularization effect of the Tsallis entropy with various values\nof entropic indices and show that the entropic index controls the exploration\ntendency of the proposed method. For a different type of RL problems, we find\nthat a different value of the entropic index is desirable. The proposed method\nis evaluated using the MuJoCo simulator and achieves the state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:59:34 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 00:27:53 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Lee", "Kyungjae", ""], ["Kim", "Sungyub", ""], ["Lim", "Sungbin", ""], ["Choi", "Sungjoon", ""], ["Oh", "Songhwai", ""]]}, {"id": "1902.00163", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Claire Tseng, Karla Montejo, Joseph Kwon, Gabriel\n  Kreiman", "title": "Lift-the-flap: what, where and when for context reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context reasoning is critical in a wide variety of applications where current\ninputs need to be interpreted in the light of previous experience and\nknowledge. Both spatial and temporal contextual information play a critical\nrole in the domain of visual recognition. Here we investigate spatial\nconstraints (what image features provide contextual information and where they\nare located), and temporal constraints (when different contextual cues matter)\nfor visual recognition. The task is to reason about the scene context and infer\nwhat a target object hidden behind a flap is in a natural image. To tackle this\nproblem, we first describe an online human psychophysics experiment recording\nactive sampling via mouse clicks in lift-the-flap games and identify clicking\npatterns and features which are diagnostic for high contextual reasoning\naccuracy. As a proof of the usefulness of these clicking patterns and visual\nfeatures, we extend a state-of-the-art recurrent model capable of attending to\nsalient context regions, dynamically integrating useful information, making\ninferences, and predicting class label for the target object over multiple\nclicks. The proposed model achieves human-level contextual reasoning accuracy,\nshares human-like sampling behavior and learns interpretable features for\ncontextual reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 03:37:17 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 01:34:56 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Zhang", "Mengmi", ""], ["Tseng", "Claire", ""], ["Montejo", "Karla", ""], ["Kwon", "Joseph", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1902.00175", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth, Shib Sankar Dasgupta, Swayambhu Nath Ray, Partha\n  Talukdar", "title": "Dating Documents using Graph Convolution Networks", "comments": "Accepted at ACL 2018", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document date is essential for many important tasks, such as document\nretrieval, summarization, event detection, etc. While existing approaches for\nthese tasks assume accurate knowledge of the document date, this is not always\navailable, especially for arbitrary documents from the Web. Document Dating is\na challenging problem which requires inference over the temporal structure of\nthe document. Prior document dating systems have largely relied on handcrafted\nfeatures while ignoring such document internal structures. In this paper, we\npropose NeuralDater, a Graph Convolutional Network (GCN) based document dating\napproach which jointly exploits syntactic and temporal graph structures of\ndocument in a principled way. To the best of our knowledge, this is the first\napplication of deep learning for the problem of document dating. Through\nextensive experiments on real-world datasets, we find that NeuralDater\nsignificantly outperforms state-of-the-art baseline by 19% absolute (45%\nrelative) accuracy points.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 04:30:42 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Vashishth", "Shikhar", ""], ["Dasgupta", "Shib Sankar", ""], ["Ray", "Swayambhu Nath", ""], ["Talukdar", "Partha", ""]]}, {"id": "1902.00287", "submitter": "Jeroen Berrevoets", "authors": "Jeroen Berrevoets and Wouter Verbeke", "title": "Causal Simulations for Uplift Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling requires experimental data, preferably collected in random\nfashion. This places a logistical and financial burden upon any organisation\naspiring such models. Once deployed, uplift models are subject to effects from\nconcept drift. Hence, methods are being developed that are able to learn from\nnewly gained experience, as well as handle drifting environments. As these new\nmethods attempt to eliminate the need for experimental data, another approach\nto test such methods must be formulated. Therefore, we propose a method to\nsimulate environments that offer causal relationships in their parameters.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 11:46:36 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Berrevoets", "Jeroen", ""], ["Verbeke", "Wouter", ""]]}, {"id": "1902.00358", "submitter": "Li Xiao", "authors": "Li Xiao, Yijie Peng, Jeff Hong, Zewu Ke, Shuhuai Yang", "title": "Training Artificial Neural Networks by Generalized Likelihood Ratio\n  Method: Exploring Brain-like Learning to Improve Robustness", "comments": "12 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a generalized likelihood ratio method capable of\ntraining the artificial neural networks with some biological brain-like\nmechanisms,.e.g., (a) learning by the loss value, (b) learning via neurons with\ndiscontinuous activation and loss functions. The traditional back propagation\nmethod cannot train the artificial neural networks with aforementioned\nbrain-like learning mechanisms. Numerical results show that the robustness of\nvarious artificial neural networks trained by the new method is significantly\nimproved when the input data is affected by both the natural noises and\nadversarial attacks. Code is available:\n\\url{https://github.com/LX-doctorAI/GLR_ADV} .\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 09:14:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 06:58:45 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Xiao", "Li", ""], ["Peng", "Yijie", ""], ["Hong", "Jeff", ""], ["Ke", "Zewu", ""], ["Yang", "Shuhuai", ""]]}, {"id": "1902.00363", "submitter": "Luiz Pessoa", "authors": "Luiz Pessoa", "title": "Intelligent architectures for robotics: The merging of cognition and\n  emotion", "comments": "7 figures", "journal-ref": null, "doi": "10.1016/j.plrev.2019.04.009", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What is the place of emotion in intelligent robots? In the past two decades,\nresearchers have advocated for the inclusion of some emotion-related components\nin the general information processing architecture of autonomous agents, say,\nfor better communication with humans, or to instill a sense of urgency to\naction. The framework advanced here goes beyond these approaches and proposes\nthat emotion and motivation need to be integrated with all aspects of the\narchitecture. Thus, cognitive-emotional integration is a key design principle.\nEmotion is not an \"add on\" that endows a robot with \"feelings\" (for instance,\nreporting or expressing its internal state). It allows the significance of\npercepts, plans, and actions to be an integral part of all its computations. It\nis hypothesized that a sophisticated artificial intelligence cannot be built\nfrom separate cognitive and emotional modules. A hypothetical test inspired by\nthe Turing test, called the Dolores test, is proposed to test this assertion.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:30:50 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pessoa", "Luiz", ""]]}, {"id": "1902.00465", "submitter": "David Budden", "authors": "Peter Buchlovsky, David Budden, Dominik Grewe, Chris Jones, John\n  Aslanides, Frederic Besse, Andy Brock, Aidan Clark, Sergio G\\'omez\n  Colmenarejo, Aedan Pope, Fabio Viola and Dan Belov", "title": "TF-Replicator: Distributed Machine Learning for Researchers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe TF-Replicator, a framework for distributed machine learning\ndesigned for DeepMind researchers and implemented as an abstraction over\nTensorFlow. TF-Replicator simplifies writing data-parallel and model-parallel\nresearch code. The same models can be effortlessly deployed to different\ncluster architectures (i.e. one or many machines containing CPUs, GPUs or TPU\naccelerators) using synchronous or asynchronous training regimes. To\ndemonstrate the generality and scalability of TF-Replicator, we implement and\nbenchmark three very different models: (1) A ResNet-50 for ImageNet\nclassification, (2) a SN-GAN for class-conditional ImageNet image generation,\nand (3) a D4PG reinforcement learning agent for continuous control. Our results\nshow strong scalability performance without demanding any distributed systems\nexpertise of the user. The TF-Replicator programming model will be open-sourced\nas part of TensorFlow 2.0 (see\nhttps://github.com/tensorflow/community/pull/25).\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:26:07 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Buchlovsky", "Peter", ""], ["Budden", "David", ""], ["Grewe", "Dominik", ""], ["Jones", "Chris", ""], ["Aslanides", "John", ""], ["Besse", "Frederic", ""], ["Brock", "Andy", ""], ["Clark", "Aidan", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Pope", "Aedan", ""], ["Viola", "Fabio", ""], ["Belov", "Dan", ""]]}, {"id": "1902.00506", "submitter": "Nolan Bard", "authors": "Nolan Bard, Jakob N. Foerster, Sarath Chandar, Neil Burch, Marc\n  Lanctot, H. Francis Song, Emilio Parisotto, Vincent Dumoulin, Subhodeep\n  Moitra, Edward Hughes, Iain Dunning, Shibl Mourad, Hugo Larochelle, Marc G.\n  Bellemare, Michael Bowling", "title": "The Hanabi Challenge: A New Frontier for AI Research", "comments": "32 pages, 5 figures, In Press (Artificial Intelligence)", "journal-ref": null, "doi": "10.1016/j.artint.2019.103216", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the early days of computing, games have been important testbeds for\nstudying how well machines can do sophisticated decision making. In recent\nyears, machine learning has made dramatic advances with artificial agents\nreaching superhuman performance in challenge domains like Go, Atari, and some\nvariants of poker. As with their predecessors of chess, checkers, and\nbackgammon, these game domains have driven research by providing sophisticated\nyet well-defined challenges for artificial intelligence practitioners. We\ncontinue this tradition by proposing the game of Hanabi as a new challenge\ndomain with novel problems that arise from its combination of purely\ncooperative gameplay with two to five players and imperfect information. In\nparticular, we argue that Hanabi elevates reasoning about the beliefs and\nintentions of other agents to the foreground. We believe developing novel\ntechniques for such theory of mind reasoning will not only be crucial for\nsuccess in Hanabi, but also in broader collaborative efforts, especially those\nwith human partners. To facilitate future research, we introduce the\nopen-source Hanabi Learning Environment, propose an experimental framework for\nthe research community to evaluate algorithmic advances, and assess the\nperformance of current state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 18:59:07 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 22:15:35 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bard", "Nolan", ""], ["Foerster", "Jakob N.", ""], ["Chandar", "Sarath", ""], ["Burch", "Neil", ""], ["Lanctot", "Marc", ""], ["Song", "H. Francis", ""], ["Parisotto", "Emilio", ""], ["Dumoulin", "Vincent", ""], ["Moitra", "Subhodeep", ""], ["Hughes", "Edward", ""], ["Dunning", "Iain", ""], ["Mourad", "Shibl", ""], ["Larochelle", "Hugo", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1902.00541", "submitter": "Cory Cornelius", "authors": "Cory Cornelius, Nilaksh Das, Shang-Tse Chen, Li Chen, Michael E.\n  Kounavis, Duen Horng Chau", "title": "The Efficacy of SHIELD under Different Threat Models", "comments": "Appraisal paper of existing method accepted for oral presentation at\n  KDD LEMINCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this appraisal paper, we evaluate the efficacy of SHIELD, a\ncompression-based defense framework for countering adversarial attacks on image\nclassification models, which was published at KDD 2018. Here, we consider\nalternative threat models not studied in the original work, where we assume\nthat an adaptive adversary is aware of the ensemble defense approach, the\ndefensive pre-processing, and the architecture and weights of the models used\nin the ensemble. We define scenarios with varying levels of threat and\nempirically analyze the proposed defense by varying the degree of information\navailable to the attacker, spanning from a full white-box attack to the\ngray-box threat model described in the original work. To evaluate the\nrobustness of the defense against an adaptive attacker, we consider the\ntargeted-attack success rate of the Projected Gradient Descent (PGD) attack,\nwhich is a strong gradient-based adversarial attack proposed in adversarial\nmachine learning research. We also experiment with training the SHIELD ensemble\nfrom scratch, which is different from re-training using a pre-trained model as\ndone in the original work. We find that the targeted PGD attack has a success\nrate of 64.3% against the original SHIELD ensemble in the full white box\nscenario, but this drops to 48.9% if the models used in the ensemble are\ntrained from scratch instead of being retrained. Our experiments further reveal\nthat an ensemble whose models are re-trained indeed have higher correlation in\nthe cosine similarity space, and models that are trained from scratch are less\nvulnerable to targeted attacks in the white-box and gray-box scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 20:10:12 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 20:48:26 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Cornelius", "Cory", ""], ["Das", "Nilaksh", ""], ["Chen", "Shang-Tse", ""], ["Chen", "Li", ""], ["Kounavis", "Michael E.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1902.00577", "submitter": "Sascha Saralajew", "authors": "Sascha Saralajew and Lars Holdijk and Maike Rees and Thomas Villmann", "title": "Robustness of Generalized Learning Vector Quantization Models against\n  Adversarial Attacks", "comments": "to be published in 13th International Workshop on Self-Organizing\n  Maps and Learning Vector Quantization, Clustering and Data Visualization", "journal-ref": null, "doi": "10.1007/978-3-030-19642-4_19", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks and the development of (deep) neural networks robust\nagainst them are currently two widely researched topics. The robustness of\nLearning Vector Quantization (LVQ) models against adversarial attacks has\nhowever not yet been studied to the same extent. We therefore present an\nextensive evaluation of three LVQ models: Generalized LVQ, Generalized Matrix\nLVQ and Generalized Tangent LVQ. The evaluation suggests that both Generalized\nLVQ and Generalized Tangent LVQ have a high base robustness, on par with the\ncurrent state-of-the-art in robust neural network methods. In contrast to this,\nGeneralized Matrix LVQ shows a high susceptibility to adversarial attacks,\nscoring consistently behind all other models. Additionally, our numerical\nevaluation indicates that increasing the number of prototypes per class\nimproves the robustness of the models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 22:28:56 GMT"}, {"version": "v2", "created": "Sat, 9 Mar 2019 23:29:01 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Saralajew", "Sascha", ""], ["Holdijk", "Lars", ""], ["Rees", "Maike", ""], ["Villmann", "Thomas", ""]]}, {"id": "1902.00604", "submitter": "Yu Zhang", "authors": "Yu Zhang and Mehrdad Zakershahrak", "title": "Progressive Explanation Generation for Human-robot Teaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating explanation to explain its behavior is an essential capability for\na robotic teammate. Explanations help human partners better understand the\nsituation and maintain trust of their teammates. Prior work on robot generating\nexplanations focuses on providing the reasoning behind its decision making.\nThese approaches, however, fail to heed the cognitive requirement of\nunderstanding an explanation. In other words, while they provide the right\nexplanations from the explainer's perspective, the explainee part of the\nequation is ignored. In this work, we address an important aspect along this\ndirection that contributes to a better understanding of a given explanation,\nwhich we refer to as the progressiveness of explanations. A progressive\nexplanation improves understanding by limiting the cognitive effort required at\neach step of making the explanation. As a result, such explanations are\nexpected to be smoother and hence easier to understand. A general formulation\nof progressive explanation is presented. Algorithms are provided based on\nseveral alternative quantifications of cognitive effort as an explanation is\nbeing made, which are evaluated in a standard planning competition domain.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 01:02:59 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Zhang", "Yu", ""], ["Zakershahrak", "Mehrdad", ""]]}, {"id": "1902.00624", "submitter": "Wahyudi Wahyudi", "authors": "Wahyudi, Masayu Leylia Khodra, Ary Setijadi Prihatmanto, Carmadi\n  Machbub", "title": "A Question Answering System Using Graph-Pattern Association Rules\n  (QAGPAR) On YAGO Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A question answering system (QA System) was developed that uses graph-pattern\nassociation rules on the YAGO knowledge base. The answer as output of the\nsystem is provided based on a user question as input. If the answer is missing\nor unavailable in the database, then graph-pattern association rules are used\nto get the answer. The architecture of this question answering system is as\nfollows: question classification, graph component generation, query generation,\nand query processing. The question answering system uses association graph\npatterns in a waterfall model. In this paper, the architecture of the system is\ndescribed, specifically discussing its reasoning and performance capabilities.\nThe results of this research is that rules with high confidence and correct\nlogic produce correct answers, and vice versa\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 02:24:08 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wahyudi", "", ""], ["Khodra", "Masayu Leylia", ""], ["Prihatmanto", "Ary Setijadi", ""], ["Machbub", "Carmadi", ""]]}, {"id": "1902.00655", "submitter": "Chuzhe Tang", "authors": "Chuzhe Tang, Zhiyuan Dong, Minjie Wang, Zhaoguo Wang, Haibo Chen", "title": "Learned Indexes for Dynamic Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proposal of learned index structures opens up a new perspective on\nhow traditional range indexes can be optimized. However, the current learned\nindexes assume the data distribution is relatively static and the access\npattern is uniform, while real-world scenarios consist of skew query\ndistribution and evolving data. In this paper, we demonstrate that the missing\nconsideration of access patterns and dynamic data distribution notably hinders\nthe applicability of learned indexes. To this end, we propose solutions for\nlearned indexes for dynamic workloads (called Doraemon). To improve the latency\nfor skew queries, Doraemon augments the training data with access frequencies.\nTo address the slow model re-training when data distribution shifts, Doraemon\ncaches the previously-trained models and incrementally fine-tunes them for\nsimilar access patterns and data distribution. Our preliminary result shows\nthat, Doraemon improves the query latency by 45.1% and reduces the model\nre-training time to 1/20.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:03:00 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tang", "Chuzhe", ""], ["Dong", "Zhiyuan", ""], ["Wang", "Minjie", ""], ["Wang", "Zhaoguo", ""], ["Chen", "Haibo", ""]]}, {"id": "1902.00659", "submitter": "M. Hanefi Calp", "authors": "Muhammed Hanefi Calp, Muhammet Ali Akcayol", "title": "Optimization of Project Scheduling Activities in Dynamic CPM and PERT\n  Networks Using Genetic Algorithms", "comments": "13 pages", "journal-ref": null, "doi": "10.19113/sdufbed.35437", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projects consist of interconnected dimensions such as objective, time,\nresource and environment. Use of these dimensions in a controlled way and their\neffective scheduling brings the project success. Project scheduling process\nincludes defining project activities, and estimation of time and resources to\nbe used for the activities. At this point, the project resource-scheduling\nproblems have begun to attract more attention after Program Evaluation and\nReview Technique (PERT) and Critical Path Method (CPM) are developed one after\nthe other. However, complexity and difficulty of CPM and PERT processes led to\nthe use of these techniques through artificial intelligence methods such as\nGenetic Algorithm (GA). In this study, an algorithm was proposed and developed,\nwhich determines critical path, critical activities and project completion\nduration by using GA, instead of CPM and PERT techniques used for network\nanalysis within the scope of project management. The purpose of using GA was\nthat these algorithms are an effective method for solution of complex\noptimization problems. Therefore, correct decisions can be made for implemented\nproject activities by using obtained results. Thus, optimum results were\nobtained in a shorter time than the CPM and PERT techniques by using the model\nbased on the dynamic algorithm. It is expected that this study will contribute\nto the performance field (time, speed, low error etc.) of other studies.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 07:22:07 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Calp", "Muhammed Hanefi", ""], ["Akcayol", "Muhammet Ali", ""]]}, {"id": "1902.00672", "submitter": "Hadrien Van Lierde", "authors": "Hadrien Van Lierde and Tommy W. S. Chow", "title": "Query-oriented text summarization based on hypergraph transversals", "comments": "This is the unrefereed Author's Original Version (or pre-print\n  Version) of the article", "journal-ref": "Information Processing & Management, Volume 56, Issue 4, July\n  2019, Pages 1317-1338", "doi": "10.1016/j.ipm.2019.03.003", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph- and hypergraph-based algorithms for document summarization\nrepresent the sentences of a corpus as the nodes of a graph or a hypergraph in\nwhich the edges represent relationships of lexical similarities between\nsentences. Each sentence of the corpus is then scored individually, using\npopular node ranking algorithms, and a summary is produced by extracting highly\nscored sentences. This approach fails to select a subset of jointly relevant\nsentences and it may produce redundant summaries that are missing important\ntopics of the corpus. To alleviate this issue, a new hypergraph-based\nsummarizer is proposed in this paper, in which each node is a sentence and each\nhyperedge is a theme, namely a group of sentences sharing a topic. Themes are\nweighted in terms of their prominence in the corpus and their relevance to a\nuser-defined query. It is further shown that the problem of identifying a\nsubset of sentences covering the relevant themes of the corpus is equivalent to\nthat of finding a hypergraph transversal in our theme-based hypergraph. Two\nextensions of the notion of hypergraph transversal are proposed for the purpose\nof summarization, and polynomial time algorithms building on the theory of\nsubmodular functions are proposed for solving the associated discrete\noptimization problems. The worst-case time complexity of the proposed\nalgorithms is squared in the number of terms, which makes it cheaper than the\nexisting hypergraph-based methods. A thorough comparative analysis with related\nmodels on DUC benchmark datasets demonstrates the effectiveness of our\napproach, which outperforms existing graph- or hypergraph-based methods by at\nleast 6% of ROUGE-SU4 score.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 08:52:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Van Lierde", "Hadrien", ""], ["Chow", "Tommy W. S.", ""]]}, {"id": "1902.00673", "submitter": "Arun Kumar", "authors": "Arun Kumar, Zhengwei Wu, Xaq Pitkow, Paul Schrater", "title": "Belief dynamics extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal behavior is not driven simply by its current observations, but is\nstrongly influenced by internal states. Estimating the structure of these\ninternal states is crucial for understanding the neural basis of behavior. In\nprinciple, internal states can be estimated by inverting behavior models, as in\ninverse model-based Reinforcement Learning. However, this requires careful\nparameterization and risks model-mismatch to the animal. Here we take a\ndata-driven approach to infer latent states directly from observations of\nbehavior, using a partially observable switching semi-Markov process. This\nprocess has two elements critical for capturing animal behavior: it captures\nnon-exponential distribution of times between observations, and transitions\nbetween latent states depend on the animal's actions, features that require\nmore complex non-markovian models to represent. To demonstrate the utility of\nour approach, we apply it to the observations of a simulated optimal agent\nperforming a foraging task, and find that latent dynamics extracted by the\nmodel has correspondences with the belief dynamics of the agent. Finally, we\napply our model to identify latent states in the behaviors of monkey performing\na foraging task, and find clusters of latent states that identify periods of\ntime consistent with expectant waiting. This data-driven behavioral model will\nbe valuable for inferring latent cognitive states, and thereby for measuring\nneural representations of those states.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 09:05:46 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Kumar", "Arun", ""], ["Wu", "Zhengwei", ""], ["Pitkow", "Xaq", ""], ["Schrater", "Paul", ""]]}, {"id": "1902.00685", "submitter": "M. Hanefi Calp", "authors": "M. Hanefi Calp", "title": "Medical Diagnosis with a Novel SVM-CoDOA Based Hybrid Approach", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning is an important sub-field of the Artificial Intelligence and\nit has been become a very critical task to train Machine Learning techniques\nvia effective method or techniques. Recently, researchers try to use\nalternative techniques to improve ability of Machine Learning techniques.\nMoving from the explanations, objective of this study is to introduce a novel\nSVM-CoDOA (Cognitive Development Optimization Algorithm trained Support Vector\nMachines) system for general medical diagnosis. In detail, the system consists\nof a SVM, which is trained by CoDOA, a newly developed optimization algorithm.\nAs it is known, use of optimization algorithms is an essential task to train\nand improve Machine Learning techniques. In this sense, the study has provided\na medical diagnosis oriented problem scope in order to show effectiveness of\nthe SVM-CoDOA hybrid formation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 10:32:50 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Calp", "M. Hanefi", ""]]}, {"id": "1902.00719", "submitter": "Miguel Alonso Jr", "authors": "Miguel Alonso Jr", "title": "Learning User Preferences via Reinforcement Learning with Spatial\n  Interface Valuing", "comments": "Submitted to HCI International 2019 Parallel Session on Spatial\n  Interaction for Universal Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Machine Learning is concerned with creating systems that operate\nin environments alongside humans to achieve a task. A typical use is to extend\nor amplify the capabilities of a human in cognitive or physical ways, requiring\nthe machine to adapt to the users' intentions and preferences. Often, this\ntakes the form of a human operator providing some type of feedback to the user,\nwhich can be explicit feedback, implicit feedback, or a combination of both.\nExplicit feedback, such as through a mouse click, carries a high cognitive\nload. The focus of this study is to extend the current state of the art in\ninteractive machine learning by demonstrating that agents can learn a human\nuser's behavior and adapt to preferences with a reduced amount of explicit\nhuman feedback in a mixed feedback setting. The learning agent perceives a\nvalue of its own behavior from hand gestures given via a spatial interface.\nThis feedback mechanism is termed Spatial Interface Valuing. This method is\nevaluated experimentally in a simulated environment for a grasping task using a\nrobotic arm with variable grip settings. Preliminary results indicate that\nlearning agents using spatial interface valuing can learn a value function\nmapping spatial gestures to expected future rewards much more quickly as\ncompared to those same agents just receiving explicit feedback, demonstrating\nthat an agent perceiving feedback from a human user via a spatial interface can\nserve as an effective complement to existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:45:20 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Alonso", "Miguel", "Jr"]]}, {"id": "1902.00741", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Distinction Graphs and Graphtropy: A Formalized Phenomenological Layer\n  Underlying Classical and Quantum Entropy, Observational Semantics and\n  Cognitive Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new conceptual foundation for the notion of \"information\" is proposed,\nbased on the concept of a \"distinction graph\": a graph in which two nodes are\nconnected iff they cannot be distinguished by a particular observer. The\n\"graphtropy\" of a distinction graph is defined as the average connection\nprobability of two nodes; in the case where the distinction graph is a composed\nof disconnected components that are fully connected subgraphs, this is\nequivalent to Ellerman's logical entropy, which has straightforward\nrelationships to Shannon entropy. Probabilistic distinction graphs and\nprobabilistic graphtropy are also considered, as well as connections between\ngraphtropy and thermodynamic and quantum entropy. The semantics of the Second\nLaw of Thermodynamics and the Maximum Entropy Production Principle are unfolded\nin a novel way, via analysis of the cognitive processes underlying the making\nof distinction graphs This evokes an interpretation in which complex\nintelligence is seen to correspond to states of consciousness with intermediate\ngraphtropy, which are associated with memory imperfections that violate the\nassumptions leading to derivation of the Second Law. In the case where nodes of\na distinction graph are labeled by computable entities, graphtropy is shown to\nbe monotonically related to the average algorithmic information of the nodes\n(relative to to the algorithmic information of the observer). A\nquantum-mechanical version of distinction graphs is considered, in which\ndistinctions can exist in a superposed state; this yields to graphtropy as a\nmeasure of the impurity of a mixed state, and to a concept of \"quangraphtropy.\"\nFinally, a novel computational model called Dynamic Distinction Graphs (DDGs)\nis formulated, via enhancing distinction graphs with additional links\nexpressing causal implications, enabling a distinction-based model of\n\"observers.\"\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 15:59:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "1902.00771", "submitter": "Adi Botea", "authors": "Adi Botea, Christian Muise, Shubham Agarwal, Oznur Alkan, Ondrej\n  Bajgar, Elizabeth Daly, Akihiro Kishimoto, Luis Lastras, Radu Marinescu,\n  Josef Ondrej, Pablo Pedemonte, Miroslav Vodolan", "title": "Generating Dialogue Agents via Automated Planning", "comments": "Accepted at the AAAI-2019 DEEP-DIAL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems have many applications such as customer support or question\nanswering. Typically they have been limited to shallow single turn\ninteractions. However more advanced applications such as career coaching or\nplanning a trip require a much more complex multi-turn dialogue. Current\nlimitations of conversational systems have made it difficult to support\napplications that require personalization, customization and context dependent\ninteractions. We tackle this challenging problem by using domain-independent AI\nplanning to automatically create dialogue plans, customized to guide a dialogue\ntowards achieving a given goal. The input includes a library of atomic dialogue\nactions, an initial state of the dialogue, and a goal. Dialogue plans are\nplugged into a dialogue system capable to orchestrate their execution. Use\ncases demonstrate the viability of the approach. Our work on dialogue planning\nhas been integrated into a product, and it is in the process of being deployed\ninto another.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 19:23:30 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Botea", "Adi", ""], ["Muise", "Christian", ""], ["Agarwal", "Shubham", ""], ["Alkan", "Oznur", ""], ["Bajgar", "Ondrej", ""], ["Daly", "Elizabeth", ""], ["Kishimoto", "Akihiro", ""], ["Lastras", "Luis", ""], ["Marinescu", "Radu", ""], ["Ondrej", "Josef", ""], ["Pedemonte", "Pablo", ""], ["Vodolan", "Miroslav", ""]]}, {"id": "1902.00916", "submitter": "Tom Hanika", "authors": "Tom Hanika and Maximilian Marx and Gerd Stumme", "title": "Discovering Implicational Knowledge in Wikidata", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-21462-3_21", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have recently become the state-of-the-art tool for\nrepresenting the diverse and complex knowledge of the world. Examples include\nthe proprietary knowledge graphs of companies such as Google, Facebook, IBM, or\nMicrosoft, but also freely available ones such as YAGO, DBpedia, and Wikidata.\nA distinguishing feature of Wikidata is that the knowledge is collaboratively\nedited and curated. While this greatly enhances the scope of Wikidata, it also\nmakes it impossible for a single individual to grasp complex connections\nbetween properties or understand the global impact of edits in the graph. We\napply Formal Concept Analysis to efficiently identify comprehensible\nimplications that are implicitly present in the data. Although the complex\nstructure of data modelling in Wikidata is not amenable to a direct approach,\nwe overcome this limitation by extracting contextual representations of parts\nof Wikidata in a systematic fashion. We demonstrate the practical feasibility\nof our approach through several experiments and show that the results may lead\nto the discovery of interesting implicational knowledge. Besides providing a\nmethod for obtaining large real-world data sets for FCA, we sketch potential\napplications in offering semantic assistance for editing and curating Wikidata.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:13:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hanika", "Tom", ""], ["Marx", "Maximilian", ""], ["Stumme", "Gerd", ""]]}, {"id": "1902.01030", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Ming Tan, Mo Yu, Shiyu Chang, Dakuo Wang, Kun Xu, Xiaoxiao\n  Guo, Saloni Potdar", "title": "Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to extraction multiple relations from a paragraph require\nmultiple passes over the paragraph. In practice, multiple passes are\ncomputationally expensive and this makes difficult to scale to longer\nparagraphs and larger text corpora. In this work, we focus on the task of\nmultiple relation extraction by encoding the paragraph only once (one-pass). We\nbuild our solution on the pre-trained self-attentive (Transformer) models,\nwhere we first add a structured prediction layer to handle extraction between\nmultiple entity pairs, then enhance the paragraph embedding to capture multiple\nrelational information associated with each entity with an entity-aware\nattention technique. We show that our approach is not only scalable but can\nalso perform state-of-the-art on the standard benchmark ACE 2005.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 04:42:08 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 14:43:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Wang", "Haoyu", ""], ["Tan", "Ming", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Wang", "Dakuo", ""], ["Xu", "Kun", ""], ["Guo", "Xiaoxiao", ""], ["Potdar", "Saloni", ""]]}, {"id": "1902.01073", "submitter": "Santtu Tikka", "authors": "Santtu Tikka, Antti Hyttinen, Juha Karvanen", "title": "Causal Effect Identification from Multiple Incomplete Data Sources: A\n  General Search-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal effect identification considers whether an interventional probability\ndistribution can be uniquely determined without parametric assumptions from\nmeasured source distributions and structural knowledge on the generating\nsystem. While complete graphical criteria and procedures exist for many\nidentification problems, there are still challenging but important extensions\nthat have not been considered in the literature. To tackle these new settings,\nwe present a search algorithm directly over the rules of do-calculus. Due to\ngenerality of do-calculus, the search is capable of taking more advanced\ndata-generating mechanisms into account along with an arbitrary type of both\nobservational and experimental source distributions. The search is enhanced via\na heuristic and search space reduction techniques. The approach, called\ndo-search, is provably sound, and it is complete with respect to\nidentifiability problems that have been shown to be completely characterized by\ndo-calculus. When extended with additional rules, the search is capable of\nhandling missing data problems as well. With the versatile search, we are able\nto approach new problems such as combined transportability and selection bias,\nor multiple sources of selection bias. We perform a systematic analysis of\nbivariate missing data problems and study causal inference under case-control\ndesign. We also present the R package dosearch that provides an interface for a\nC++ implementation of the search.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:12:04 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 08:19:27 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 13:36:36 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 10:00:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Tikka", "Santtu", ""], ["Hyttinen", "Antti", ""], ["Karvanen", "Juha", ""]]}, {"id": "1902.01080", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi, Sina D\\\"aubener, Asja Fischer", "title": "Predictive Uncertainty Quantification with Compound Density Networks", "comments": "Bayesian deep learning workshop, NeuRIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the huge success of deep neural networks (NNs), finding good\nmechanisms for quantifying their prediction uncertainty is still an open\nproblem. Bayesian neural networks are one of the most popular approaches to\nuncertainty quantification. On the other hand, it was recently shown that\nensembles of NNs, which belong to the class of mixture models, can be used to\nquantify prediction uncertainty. In this paper, we build upon these two\napproaches. First, we increase the mixture model's flexibility by replacing the\nfixed mixing weights by an adaptive, input-dependent distribution (specifying\nthe probability of each component) represented by NNs, and by considering\nuncountably many mixture components. The resulting class of models can be seen\nas the continuous counterpart to mixture density networks and is therefore\nreferred to as compound density networks (CDNs). We employ both maximum\nlikelihood and variational Bayesian inference to train CDNs, and empirically\nshow that they yield better uncertainty estimates on out-of-distribution data\nand are more robust to adversarial examples than the previous approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 08:39:06 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 12:59:03 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["D\u00e4ubener", "Sina", ""], ["Fischer", "Asja", ""]]}, {"id": "1902.01119", "submitter": "Guy Tennenholtz", "authors": "Guy Tennenholtz, Shie Mannor", "title": "The Natural Language of Actions", "comments": "Published in the proceedings of the 36th International Conference on\n  Machine Learning (ICML 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Act2Vec, a general framework for learning context-based action\nrepresentation for Reinforcement Learning. Representing actions in a vector\nspace help reinforcement learning algorithms achieve better performance by\ngrouping similar actions and utilizing relations between different actions. We\nshow how prior knowledge of an environment can be extracted from demonstrations\nand injected into action vector representations that encode natural compatible\nbehavior. We then use these for augmenting state representations as well as\nimproving function approximation of Q-values. We visualize and test action\nembeddings in three domains including a drawing task, a high dimensional\nnavigation task, and the large action space domain of StarCraft II.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 10:46:53 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 07:35:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Tennenholtz", "Guy", ""], ["Mannor", "Shie", ""]]}, {"id": "1902.01128", "submitter": "Kui Zhao", "authors": "Kui Zhao, Junhao Hua, Ling Yan, Qi Zhang, Huan Xu, Cheng Yang", "title": "A Unified Framework for Marketing Budget Allocation", "comments": "KDD'19, 11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While marketing budget allocation has been studied for decades in traditional\nbusiness, nowadays online business brings much more challenges due to the\ndynamic environment and complex decision-making process. In this paper, we\npresent a novel unified framework for marketing budget allocation. By\nleveraging abundant data, the proposed data-driven approach can help us to\novercome the challenges and make more informed decisions. In our approach, a\nsemi-black-box model is built to forecast the dynamic market response and an\nefficient optimization method is proposed to solve the complex allocation task.\nFirst, the response in each market-segment is forecasted by exploring\nhistorical data through a semi-black-box model, where the capability of logit\ndemand curve is enhanced by neural networks. The response model reveals\nrelationship between sales and marketing cost. Based on the learned model,\nbudget allocation is then formulated as an optimization problem, and we design\nefficient algorithms to solve it in both continuous and discrete settings.\nSeveral kinds of business constraints are supported in one unified optimization\nparadigm, including cost upper bound, profit lower bound, or ROI lower bound.\nThe proposed framework is easy to implement and readily to handle large-scale\nproblems. It has been successfully applied to many scenarios in Alibaba Group.\nThe results of both offline experiments and online A/B testing demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 11:27:11 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 03:29:12 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 04:36:22 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Zhao", "Kui", ""], ["Hua", "Junhao", ""], ["Yan", "Ling", ""], ["Zhang", "Qi", ""], ["Xu", "Huan", ""], ["Yang", "Cheng", ""]]}, {"id": "1902.01182", "submitter": "Jalil Taghia", "authors": "Jalil Taghia, Maria B\\r{a}nkestad, Fredrik Lindsten, Thomas B. Sch\\\"on", "title": "Constructing the Matrix Multilayer Perceptron and its Application to the\n  VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like most learning algorithms, the multilayer perceptrons (MLP) is designed\nto learn a vector of parameters from data. However, in certain scenarios we are\ninterested in learning structured parameters (predictions) in the form of\nsymmetric positive definite matrices. Here, we introduce a variant of the MLP,\nreferred to as the matrix MLP, that is specialized at learning symmetric\npositive definite matrices. We also present an application of the model within\nthe context of the variational autoencoder (VAE). Our formulation of the VAE\nextends the vanilla formulation to the cases where the recognition and the\ngenerative networks can be from the parametric family of distributions with\ndense covariance matrices. Two specific examples are discussed in more detail:\nthe dense covariance Gaussian and its generalization, the power exponential\ndistribution. Our new developments are illustrated using both synthetic and\nreal data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 13:51:03 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Taghia", "Jalil", ""], ["B\u00e5nkestad", "Maria", ""], ["Lindsten", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1902.01193", "submitter": "Akeem Amusat", "authors": "O.M. Alade, A.O. Amusat", "title": "Solving Nurse Scheduling Problem Using Constraint Programming Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Staff scheduling is a universal problem that can be encountered in many\norganizations, such as call centers, educational institution, industry,\nhospital, and any other public services. It is one of the most important\naspects of workforce management strategy and the one that is most prone to\nerrors or issues as there are many entities should be considered, such as the\nstaff turnover, employee availability, time between rotations, unusual periods\nof activity, and even the last-minute shift changes. The nurse scheduling\nproblem is a variant of staff scheduling problems which appoints nurses to\nshifts as well as rooms per day taking both hard constraints, i.e., hospital\nrequirements, and soft constraints, i.e., nurse preferences, into account. Most\nalgorithms used for scheduling problems fall short when it comes to the number\nof inputs they can handle. In this paper, constraint programming was developed\nto solve the nurse scheduling problem. The developed constraint programming\nmodel was then implemented using python programming language.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 14:09:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Alade", "O. M.", ""], ["Amusat", "A. O.", ""]]}, {"id": "1902.01240", "submitter": "Paavo Parmas", "authors": "Paavo Parmas, Carl Edward Rasmussen, Jan Peters, Kenji Doya", "title": "PIPPS: Flexible Model-Based Policy Search Robust to the Curse of Chaos", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, the exploding gradient problem has been explained to be central\nin deep learning and model-based reinforcement learning, because it causes\nnumerical issues and instability in optimization. Our experiments in\nmodel-based reinforcement learning imply that the problem is not just a\nnumerical issue, but it may be caused by a fundamental chaos-like nature of\nlong chains of nonlinear computations. Not only do the magnitudes of the\ngradients become large, the direction of the gradients becomes essentially\nrandom. We show that reparameterization gradients suffer from the problem,\nwhile likelihood ratio gradients are robust. Using our insights, we develop a\nmodel-based policy search framework, Probabilistic Inference for Particle-Based\nPolicy Search (PIPPS), which is easily extensible, and allows for almost\narbitrary models and policies, while simultaneously matching the performance of\nprevious data-efficient learning algorithms. Finally, we invent the total\npropagation algorithm, which efficiently computes a union over all pathwise\nderivative depths during a single backwards pass, automatically giving greater\nweight to estimators with lower variance, sometimes improving over\nreparameterization gradients by $10^6$ times.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 15:12:55 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Parmas", "Paavo", ""], ["Rasmussen", "Carl Edward", ""], ["Peters", "Jan", ""], ["Doya", "Kenji", ""]]}, {"id": "1902.01286", "submitter": "Yang Hao", "authors": "Zhongliang Yang, Hao Yang, Yuting Hu, Yongfeng Huang, Yu-Jin Zhang", "title": "Real-Time Steganalysis for Stream Media Based on Multi-channel\n  Convolutional Sliding Windows", "comments": "13 pages, summit to ieee transactions on information forensics and\n  security (tifs)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous VoIP steganalysis methods face great challenges in detecting speech\nsignals at low embedding rates, and they are also generally difficult to\nperform real-time detection, making them hard to truly maintain cyberspace\nsecurity. To solve these two challenges, in this paper, combined with the\nsliding window detection algorithm and Convolution Neural Network we propose a\nreal-time VoIP steganalysis method which based on multi-channel convolution\nsliding windows. In order to analyze the correlations between frames and\ndifferent neighborhood frames in a VoIP signal, we define multi channel sliding\ndetection windows. Within each sliding window, we design two feature extraction\nchannels which contain multiple convolution layers with multiple convolution\nkernels each layer to extract correlation features of the input signal. Then\nbased on these extracted features, we use a forward fully connected network for\nfeature fusion. Finally, by analyzing the statistical distribution of these\nfeatures, the discriminator will determine whether the input speech signal\ncontains covert information or not.We designed several experiments to test the\nproposed model's detection ability under various conditions, including\ndifferent embedding rates, different speech length, etc. Experimental results\nshowed that the proposed model outperforms all the previous methods, especially\nin the case of low embedding rate, which showed state-of-the-art performance.\nIn addition, we also tested the detection efficiency of the proposed model, and\nthe results showed that it can achieve almost real-time detection of VoIP\nspeech signals.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 16:23:56 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Yang", "Zhongliang", ""], ["Yang", "Hao", ""], ["Hu", "Yuting", ""], ["Huang", "Yongfeng", ""], ["Zhang", "Yu-Jin", ""]]}, {"id": "1902.01313", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "An Effective Approach to Unsupervised Machine Translation", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine translation has traditionally relied on large amounts of\nparallel corpora, a recent research line has managed to train both Neural\nMachine Translation (NMT) and Statistical Machine Translation (SMT) systems\nusing monolingual corpora only. In this paper, we identify and address several\ndeficiencies of existing unsupervised SMT approaches by exploiting subword\ninformation, developing a theoretically well founded unsupervised tuning\nmethod, and incorporating a joint refinement procedure. Moreover, we use our\nimproved SMT system to initialize a dual NMT model, which is further fine-tuned\nthrough on-the-fly back-translation. Together, we obtain large improvements\nover the previous state-of-the-art in unsupervised machine translation. For\ninstance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points\nmore than the previous best unsupervised system, and 0.5 points more than the\n(supervised) shared task winner back in 2014.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:08:32 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 22:23:38 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1902.01360", "submitter": "M. Hanefi Calp", "authors": "Murat Dener, M. Hanefi Calp", "title": "Solving The Exam Scheduling Problems in Central Exams With Genetic\n  Algorithms", "comments": "14 pages", "journal-ref": null, "doi": "10.22531/muglajsci.423185", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is the efficient use of resources expected from an exam scheduling\napplication. There are various criteria for efficient use of resources and for\nall tests to be carried out at minimum cost in the shortest possible time. It\nis aimed that educational institutions with such criteria successfully carry\nout central examination organizations. In the study, a two-stage genetic\nalgorithm was developed. In the first stage, the assignment of courses to\nsessions was carried out. In the second stage, the students who participated in\nthe test session were assigned to examination rooms. Purposes of the study are\nincreasing the number of joint students participating in sessions, using the\nminimum number of buildings in the same session, and reducing the number of\nsupervisors using the minimum number of classrooms possible. In this study, a\ngeneral purpose exam scheduling solution for educational institutions was\npresented. The developed system can be used in different central examinations\nto create originality. Given the results of the sample application, it is seen\nthat the proposed genetic algorithm gives successful results.1\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:21:37 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Dener", "Murat", ""], ["Calp", "M. Hanefi", ""]]}, {"id": "1902.01362", "submitter": "M. Hanefi Calp", "authors": "M. H. Calp", "title": "Evaluation of Multidisciplinary Effects of Artificial Intelligence with\n  Optimization Perspective", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence has an important place in the scientific community as\na result of its successful outputs in terms of different fields. In time, the\nfield of Artificial Intelligence has been divided into many sub-fields because\nof increasing number of different solution approaches, methods, and techniques.\nMachine Learning has the most remarkable role with its functions to learn from\nsamples from the environment. On the other hand, intelligent optimization done\nby inspiring from nature and swarms had its own unique scientific literature,\nwith effective solutions provided for optimization problems from different\nfields. Because intelligent optimization can be applied in different fields\neffectively, this study aims to provide a general discussion on\nmultidisciplinary effects of Artificial Intelligence by considering its\noptimization oriented solutions. The study briefly focuses on background of the\nintelligent optimization briefly and then gives application examples of\nintelligent optimization from a multidisciplinary perspective.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:26:12 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Calp", "M. H.", ""]]}, {"id": "1902.01378", "submitter": "Arthur Juliani", "authors": "Arthur Juliani, Ahmed Khalifa, Vincent-Pierre Berges, Jonathan Harper,\n  Ervin Teng, Hunter Henry, Adam Crespi, Julian Togelius, Danny Lange", "title": "Obstacle Tower: A Generalization Challenge in Vision, Control, and\n  Planning", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid pace of recent research in AI has been driven in part by the\npresence of fast and challenging simulation environments. These environments\noften take the form of games; with tasks ranging from simple board games, to\ncompetitive video games. We propose a new benchmark - Obstacle Tower: a high\nfidelity, 3D, 3rd person, procedurally generated environment. An agent playing\nObstacle Tower must learn to solve both low-level control and high-level\nplanning problems in tandem while learning from pixels and a sparse reward\nsignal. Unlike other benchmarks such as the Arcade Learning Environment,\nevaluation of agent performance in Obstacle Tower is based on an agent's\nability to perform well on unseen instances of the environment. In this paper\nwe outline the environment and provide a set of baseline results produced by\ncurrent state-of-the-art Deep RL methods as well as human players. These\nalgorithms fail to produce agents capable of performing near human level.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:45:46 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 20:58:01 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Juliani", "Arthur", ""], ["Khalifa", "Ahmed", ""], ["Berges", "Vincent-Pierre", ""], ["Harper", "Jonathan", ""], ["Teng", "Ervin", ""], ["Henry", "Hunter", ""], ["Crespi", "Adam", ""], ["Togelius", "Julian", ""], ["Lange", "Danny", ""]]}, {"id": "1902.01385", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Lisa Lee, Ruslan Salakhutdinov, Devi Parikh,\n  Dhruv Batra", "title": "Embodied Multimodal Multitask Learning", "comments": "See https://devendrachaplot.github.io/projects/EMML for demo videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts on training visual navigation agents conditioned on language\nusing deep reinforcement learning have been successful in learning policies for\ndifferent multimodal tasks, such as semantic goal navigation and embodied\nquestion answering. In this paper, we propose a multitask model capable of\njointly learning these multimodal tasks, and transferring knowledge of words\nand their grounding in visual objects across the tasks. The proposed model uses\na novel Dual-Attention unit to disentangle the knowledge of words in the\ntextual representations and visual concepts in the visual representations, and\nalign them with each other. This disentangled task-invariant alignment of\nrepresentations facilitates grounding and knowledge transfer across both tasks.\nWe show that the proposed model outperforms a range of baselines on both tasks\nin simulated 3D environments. We also show that this disentanglement of\nrepresentations makes our model modular, interpretable, and allows for transfer\nto instructions containing new words by leveraging object detectors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 18:53:14 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Lee", "Lisa", ""], ["Salakhutdinov", "Ruslan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.01437", "submitter": "Junhao Li", "authors": "Junhao Li, Hang Zhang", "title": "Blaze: Simplified High Performance Cluster Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  MapReduce and its variants have significantly simplified and accelerated the\nprocess of developing parallel programs. However, most MapReduce\nimplementations focus on data-intensive tasks while many real-world tasks are\ncompute intensive and their data can fit distributedly into the memory. For\nthese tasks, the speed of MapReduce programs can be much slower than those\nhand-optimized ones. We present Blaze, a C++ library that makes it easy to\ndevelop high performance parallel programs for such compute intensive tasks. At\nthe core of Blaze is a highly-optimized in-memory MapReduce function, which has\nthree main improvements over conventional MapReduce implementations: eager\nreduction, fast serialization, and special treatment for a small fixed key\nrange. We also offer additional conveniences that make developing parallel\nprograms similar to developing serial programs. These improvements make Blaze\nan easy-to-use cluster computing library that approaches the speed of\nhand-optimized parallel code. We apply Blaze to some common data mining tasks,\nincluding word frequency count, PageRank, k-means, expectation maximization\n(Gaussian mixture model), and k-nearest neighbors. Blaze outperforms Apache\nSpark by more than 10 times on average for these tasks, and the speed of Blaze\nscales almost linearly with the number of nodes. In addition, Blaze uses only\nthe MapReduce function and 3 utility functions in its implementation while\nSpark uses almost 30 different parallel primitives in its official\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:28:15 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 02:59:19 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Li", "Junhao", ""], ["Zhang", "Hang", ""]]}, {"id": "1902.01453", "submitter": "Johan Mathe", "authors": "Johan Mathe, Nina Miolane, Nicolas Sebastien, Jeremie Lequeux", "title": "PVNet: A LRCN Architecture for Spatio-Temporal Photovoltaic\n  PowerForecasting from Numerical Weather Prediction", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photovoltaic (PV) power generation has emerged as one of the lead renewable\nenergy sources. Yet, its production is characterized by high uncertainty, being\ndependent on weather conditions like solar irradiance and temperature.\nPredicting PV production, even in the 24-hour forecast, remains a challenge and\nleads energy providers to left idling - often carbon emitting - plants. In this\npaper, we introduce a Long-Term Recurrent Convolutional Network using Numerical\nWeather Predictions (NWP) to predict, in turn, PV production in the 24-hour and\n48-hour forecast horizons. This network architecture fully leverages both\ntemporal and spatial weather data, sampled over the whole geographical area of\ninterest. We train our model on an NWP dataset from the National Oceanic and\nAtmospheric Administration (NOAA) to predict spatially aggregated PV production\nin Germany. We compare its performance to the persistence model and\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 20:30:24 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 20:02:30 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 00:57:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Mathe", "Johan", ""], ["Miolane", "Nina", ""], ["Sebastien", "Nicolas", ""], ["Lequeux", "Jeremie", ""]]}, {"id": "1902.01529", "submitter": "Ryota Tanaka", "authors": "Ryota Tanaka, Akihide Ozeki, Shugo Kato, Akinobu Lee", "title": "An Ensemble Dialogue System for Facts-Based Sentence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aims to generate responses based on real-world facts by\nconditioning context and external facts extracted from information websites.\nOur system is an ensemble system that combines three modules: generated-based\nmodule, retrieval-based module, and reranking module. Therefore, this system\ncan return diverse and meaningful responses from various perspectives. The\nexperiments and evaluations are conducted with the sentence generation task in\nDialog System Technology Challenges 7 (DSTC7-Task2). As a result, the proposed\nsystem performed significantly better than sole modules, and worked fine at the\nDSTC7-Task2, specifically on the objective evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 03:25:24 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Tanaka", "Ryota", ""], ["Ozeki", "Akihide", ""], ["Kato", "Shugo", ""], ["Lee", "Akinobu", ""]]}, {"id": "1902.01554", "submitter": "Daewoo Kim", "authors": "Daewoo Kim, Sangwoo Moon, David Hostallero, Wan Ju Kang, Taeyoung Lee,\n  Kyunghwan Son, Yung Yi", "title": "Learning to Schedule Communication in Multi-agent Reinforcement Learning", "comments": "Accepted in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world reinforcement learning tasks require multiple agents to make\nsequential decisions under the agents' interaction, where well-coordinated\nactions among the agents are crucial to achieve the target goal better at these\ntasks. One way to accelerate the coordination effect is to enable multiple\nagents to communicate with each other in a distributed manner and behave as a\ngroup. In this paper, we study a practical scenario when (i) the communication\nbandwidth is limited and (ii) the agents share the communication medium so that\nonly a restricted number of agents are able to simultaneously use the medium,\nas in the state-of-the-art wireless networking standards. This calls for a\ncertain form of communication scheduling. In that regard, we propose a\nmulti-agent deep reinforcement learning framework, called SchedNet, in which\nagents learn how to schedule themselves, how to encode the messages, and how to\nselect actions based on received messages. SchedNet is capable of deciding\nwhich agents should be entitled to broadcasting their (encoded) messages, by\nlearning the importance of each agent's partially observed information. We\nevaluate SchedNet against multiple baselines under two different applications,\nnamely, cooperative communication and navigation, and predator-prey. Our\nexperiments show a non-negligible performance gap between SchedNet and other\nmechanisms such as the ones without communication and with vanilla scheduling\nmethods, e.g., round robin, ranging from 32% to 43%.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 05:51:36 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Kim", "Daewoo", ""], ["Moon", "Sangwoo", ""], ["Hostallero", "David", ""], ["Kang", "Wan Ju", ""], ["Lee", "Taeyoung", ""], ["Son", "Kyunghwan", ""], ["Yi", "Yung", ""]]}, {"id": "1902.01560", "submitter": "Shushman Choudhury", "authors": "Shushman Choudhury and Jacob P. Knickerbocker and Mykel J.\n  Kochenderfer", "title": "Dynamic Real-time Multimodal Routing with Hierarchical Hybrid Planning", "comments": "8 pages, 8 figures, Accepted to Intelligent Vehicles (IV) Symposium\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of Dynamic Real-time Multimodal Routing (DREAMR),\nwhich requires planning and executing routes under uncertainty for an\nautonomous agent. The agent has access to a time-varying transit vehicle\nnetwork in which it can use multiple modes of transportation. For instance, a\ndrone can either fly or ride on terrain vehicles for segments of their routes.\nDREAMR is a difficult problem of sequential decision making under uncertainty\nwith both discrete and continuous variables. We design a novel hierarchical\nhybrid planning framework to solve the DREAMR problem that exploits its\nstructural decomposability. Our framework consists of a global open-loop\nplanning layer that invokes and monitors a local closed-loop execution layer.\nAdditional abstractions allow efficient and seamless interleaving of planning\nand execution. We create a large-scale simulation for DREAMR problems, with\neach scenario having hundreds of transportation routes and thousands of\nconnection points. Our algorithmic framework significantly outperforms a\nreceding horizon control baseline, in terms of elapsed time to reach the\ndestination and energy expended by the agent.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 06:03:18 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 06:08:22 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Choudhury", "Shushman", ""], ["Knickerbocker", "Jacob P.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1902.01569", "submitter": "Ervin Teng", "authors": "Ervin Teng, Bob Iannucci", "title": "Learning to Learn in Simulation", "comments": "AAAI-19 Workshop on Games and Simulations for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning often requires the manual collection and annotation of a\ntraining set. On robotic platforms, can we partially automate this task by\ntraining the robot to be curious, i.e., to seek out beneficial training\ninformation in the environment? In this work, we address the problem of\ncuriosity as it relates to online, real-time, human-in-the-loop training of an\nobject detection algorithm onboard a drone, where motion is constrained to two\ndimensions. We use a 3D simulation environment and deep reinforcement learning\nto train a curiosity agent to, in turn, train the object detection model. This\nagent could have one of two conflicting objectives: train as quickly as\npossible, or train with minimal human input. We outline a reward function that\nallows the curiosity agent to learn either of these objectives, while taking\ninto account some of the physical characteristics of the drone platform on\nwhich it is meant to run. In addition, We show that we can weigh the importance\nof achieving these objectives by adjusting a parameter in the reward function.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 07:05:41 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Teng", "Ervin", ""], ["Iannucci", "Bob", ""]]}, {"id": "1902.01580", "submitter": "Saurabh Srivastava", "authors": "Saurabh Srivastava, Vinay P. Namboodiri, T.V. Prabhakar", "title": "PUTWorkbench: Analysing Privacy in AI-intensive Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI intensive systems that operate upon user data face the challenge of\nbalancing data utility with privacy concerns. We propose the idea and present\nthe prototype of an open-source tool called Privacy Utility Trade-off (PUT)\nWorkbench which seeks to aid software practitioners to take such crucial\ndecisions. We pick a simple privacy model that doesn't require any background\nknowledge in Data Science and show how even that can achieve significant\nresults over standard and real-life datasets. The tool and the source code is\nmade freely available for extensions and usage.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 08:09:33 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Srivastava", "Saurabh", ""], ["Namboodiri", "Vinay P.", ""], ["Prabhakar", "T. V.", ""]]}, {"id": "1902.01722", "submitter": "Paavo Parmas", "authors": "Paavo Parmas", "title": "Total stochastic gradient algorithms and applications in reinforcement\n  learning", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation and the chain rule of derivatives have been prominent;\nhowever, the total derivative rule has not enjoyed the same amount of\nattention. In this work we show how the total derivative rule leads to an\nintuitive visual framework for creating gradient estimators on graphical\nmodels. In particular, previous \"policy gradient theorems\" are easily derived.\nWe derive new gradient estimators based on density estimation, as well as a\nlikelihood ratio gradient, which \"jumps\" to an intermediate node, not directly\nto the objective function. We evaluate our methods on model-based policy\ngradient algorithms, achieve good performance, and present evidence towards\ndemystifying the success of the popular PILCO algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:54:05 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Parmas", "Paavo", ""]]}, {"id": "1902.01724", "submitter": "Kai Arulkumaran", "authors": "Kai Arulkumaran, Antoine Cully, Julian Togelius", "title": "AlphaStar: An Evolutionary Computation Perspective", "comments": "Genetic and EvolutionaryComputation Conference Companion 2019", "journal-ref": null, "doi": "10.1145/3319619.3321894", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In January 2019, DeepMind revealed AlphaStar to the world-the first\nartificial intelligence (AI) system to beat a professional player at the game\nof StarCraft II-representing a milestone in the progress of AI. AlphaStar draws\non many areas of AI research, including deep learning, reinforcement learning,\ngame theory, and evolutionary computation (EC). In this paper we analyze\nAlphaStar primarily through the lens of EC, presenting a new look at the system\nand relating it to many concepts in the field. We highlight some of its most\ninteresting aspects-the use of Lamarckian evolution, competitive co-evolution,\nand quality diversity. In doing so, we hope to provide a bridge between the\nwider EC community and one of the most significant AI systems developed in\nrecent times.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:57:15 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 15:05:35 GMT"}, {"version": "v3", "created": "Sun, 14 Jul 2019 16:16:44 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Arulkumaran", "Kai", ""], ["Cully", "Antoine", ""], ["Togelius", "Julian", ""]]}, {"id": "1902.01769", "submitter": "Dustin Dannenhauer", "authors": "Dustin Dannenhauer, Michael W. Floyd, Jonathan Decker, David W. Aha", "title": "Dungeon Crawl Stone Soup as an Evaluation Domain for Artificial\n  Intelligence", "comments": "AAAI-19 Workshop on Games and Simulations for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dungeon Crawl Stone Soup is a popular, single-player, free and open-source\nrogue-like video game with a sufficiently complex decision space that makes it\nan ideal testbed for research in cognitive systems and, more generally,\nartificial intelligence. This paper describes the properties of Dungeon Crawl\nStone Soup that are conducive to evaluating new approaches of AI systems. We\nalso highlight an ongoing effort to build an API for AI researchers in the\nspirit of recent game APIs such as MALMO, ELF, and the Starcraft II API.\nDungeon Crawl Stone Soup's complexity offers significant opportunities for\nevaluating AI and cognitive systems, including human user studies. In this\npaper we provide (1) a description of the state space of Dungeon Crawl Stone\nSoup, (2) a description of the components for our API, and (3) the potential\nbenefits of evaluating AI agents in the Dungeon Crawl Stone Soup video game.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:26:56 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Dannenhauer", "Dustin", ""], ["Floyd", "Michael W.", ""], ["Decker", "Jonathan", ""], ["Aha", "David W.", ""]]}, {"id": "1902.01780", "submitter": "Stephan Alaniz", "authors": "Stephan Alaniz, Diego Marcos, Bernt Schiele, Zeynep Akata", "title": "Learning Decision Trees Recurrently Through Communication", "comments": "Accepted in IEEE CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated interpretability without sacrificing the prediction accuracy of\ndecision making algorithms has the potential of greatly improving their value\nto the user. Instead of assigning a label to an image directly, we propose to\nlearn iterative binary sub-decisions, inducing sparsity and transparency in the\ndecision making process. The key aspect of our model is its ability to build a\ndecision tree whose structure is encoded into the memory representation of a\nRecurrent Neural Network jointly learned by two models communicating through\nmessage passing. In addition, our model assigns a semantic meaning to each\ndecision in the form of binary attributes, providing concise, semantic and\nrelevant rationalizations to the user. On three benchmark image classification\ndatasets, including the large-scale ImageNet, our model generates human\ninterpretable binary decision sequences explaining the predictions of the\nnetwork while maintaining state-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 16:40:34 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 12:00:07 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 19:26:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Alaniz", "Stephan", ""], ["Marcos", "Diego", ""], ["Schiele", "Bernt", ""], ["Akata", "Zeynep", ""]]}, {"id": "1902.01838", "submitter": "Amritanshu Agrawal", "authors": "Amritanshu Agrawal, Wei Fu, Di Chen, Xipeng Shen, Tim Menzies", "title": "How to \"DODGE\" Complex Software Analytics?", "comments": "13 Pages, Accepted to IEEE Transactions in Software Engineering, 2019", "journal-ref": null, "doi": "10.1109/TSE.2019.2945020", "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques applied to software engineering tasks can be\nimproved by hyperparameter optimization, i.e., automatic tools that find good\nsettings for a learner's control parameters.\n  We show that such hyperparameter optimization can be unnecessarily slow,\nparticularly when the optimizers waste time exploring \"redundant tunings\"',\ni.e., pairs of tunings which lead to indistinguishable results. By ignoring\nredundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while\nalso generating learners with more accurate predictions than seen in prior\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 18:16:56 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 23:45:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Agrawal", "Amritanshu", ""], ["Fu", "Wei", ""], ["Chen", "Di", ""], ["Shen", "Xipeng", ""], ["Menzies", "Tim", ""]]}, {"id": "1902.01876", "submitter": "Shane Mueller", "authors": "Shane T. Mueller, Robert R. Hoffman, William Clancey, Abigail Emrey,\n  Gary Klein", "title": "Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of\n  Key Ideas and Publications, and Bibliography for Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an integrative review that address the question, \"What makes for a\ngood explanation?\" with reference to AI systems. Pertinent literatures are\nvast. Thus, this review is necessarily selective. That said, most of the key\nconcepts and issues are expressed in this Report. The Report encapsulates the\nhistory of computer science efforts to create systems that explain and instruct\n(intelligent tutoring systems and expert systems). The Report expresses the\nexplainability issues and challenges in modern AI, and presents capsule views\nof the leading psychological theories of explanation. Certain articles stand\nout by virtue of their particular relevance to XAI, and their methods, results,\nand key points are highlighted. It is recommended that AI/XAI researchers be\nencouraged to include in their research reports fuller details on their\nempirical or experimental methods, in the fashion of experimental psychology\nresearch reports: details on Participants, Instructions, Procedures, Tasks,\nDependent Variables (operational definitions of the measures and metrics),\nIndependent Variables (conditions), and Control Conditions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:16:17 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Mueller", "Shane T.", ""], ["Hoffman", "Robert R.", ""], ["Clancey", "William", ""], ["Emrey", "Abigail", ""], ["Klein", "Gary", ""]]}, {"id": "1902.01883", "submitter": "Peter Henderson", "authors": "Joshua Romoff, Peter Henderson, Ahmed Touati, Emma Brunskill, Joelle\n  Pineau, Yann Ollivier", "title": "Separating value functions across time-scales", "comments": "Full version accepted to ICML 2019. Extended abstract also to be\n  presented at RLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many finite horizon episodic reinforcement learning (RL) settings, it is\ndesirable to optimize for the undiscounted return - in settings like Atari, for\ninstance, the goal is to collect the most points while staying alive in the\nlong run. Yet, it may be difficult (or even intractable) mathematically to\nlearn with this target. As such, temporal discounting is often applied to\noptimize over a shorter effective planning horizon. This comes at the risk of\npotentially biasing the optimization target away from the undiscounted goal. In\nsettings where this bias is unacceptable - where the system must optimize for\nlonger horizons at higher discounts - the target of the value function\napproximator may increase in variance leading to difficulties in learning. We\npresent an extension of temporal difference (TD) learning, which we call\nTD($\\Delta$), that breaks down a value function into a series of components\nbased on the differences between value functions with smaller discount factors.\nThe separation of a longer horizon value function into these components has\nuseful properties in scalability and performance. We discuss these properties\nand show theoretic and empirical improvements over standard TD learning in\ncertain settings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:45:08 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 05:49:34 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 20:12:47 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Romoff", "Joshua", ""], ["Henderson", "Peter", ""], ["Touati", "Ahmed", ""], ["Brunskill", "Emma", ""], ["Pineau", "Joelle", ""], ["Ollivier", "Yann", ""]]}, {"id": "1902.01886", "submitter": "Nikhil Krishnaswamy", "authors": "James Pustejovsky and Nikhil Krishnaswamy", "title": "Situational Grounding within Multimodal Simulations", "comments": "AAAI-19 Workshop on Games and Simulations for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we argue that simulation platforms enable a novel type of\nembodied spatial reasoning, one facilitated by a formal model of object and\nevent semantics that renders the continuous quantitative search space of an\nopen-world, real-time environment tractable. We provide examples for how a\nsemantically-informed AI system can exploit the precise, numerical information\nprovided by a game engine to perform qualitative reasoning about objects and\nevents, facilitate learning novel concepts from data, and communicate with a\nhuman to improve its models and demonstrate its understanding. We argue that\nsimulation environments, and game engines in particular, bring together many\ndifferent notions of \"simulation\" and many different technologies to provide a\nhighly-effective platform for developing both AI systems and tools to\nexperiment in both machine and human intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:49:56 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Pustejovsky", "James", ""], ["Krishnaswamy", "Nikhil", ""]]}, {"id": "1902.01894", "submitter": "Ang Li", "authors": "Ang Li, Ola Spyra, Sagi Perel, Valentin Dalibard, Max Jaderberg,\n  Chenjie Gu, David Budden, Tim Harley, Pramod Gupta", "title": "A Generalized Framework for Population Based Training", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population Based Training (PBT) is a recent approach that jointly optimizes\nneural network weights and hyperparameters which periodically copies weights of\nthe best performers and mutates hyperparameters during training. Previous PBT\nimplementations have been synchronized glass-box systems. We propose a general,\nblack-box PBT framework that distributes many asynchronous \"trials\" (a small\nnumber of training steps with warm-starting) across a cluster, coordinated by\nthe PBT controller. The black-box design does not make assumptions on model\narchitectures, loss functions or training procedures. Our system supports\ndynamic hyperparameter schedules to optimize both differentiable and\nnon-differentiable metrics. We apply our system to train a state-of-the-art\nWaveNet generative model for human voice synthesis. We show that our PBT system\nachieves better accuracy, less sensitivity and faster convergence compared to\nexisting methods, given the same computational resource.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 20:11:17 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Li", "Ang", ""], ["Spyra", "Ola", ""], ["Perel", "Sagi", ""], ["Dalibard", "Valentin", ""], ["Jaderberg", "Max", ""], ["Gu", "Chenjie", ""], ["Budden", "David", ""], ["Harley", "Tim", ""], ["Gupta", "Pramod", ""]]}, {"id": "1902.01909", "submitter": "Mark Koren", "authors": "Mark Koren, Saud Alsaif, Ritchie Lee, and Mykel J. Kochenderfer", "title": "Adaptive Stress Testing for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for testing the decision making systems of\nautonomous vehicles. Our approach involves perturbing stochastic elements in\nthe vehicle's environment until the vehicle is involved in a collision. Instead\nof applying direct Monte Carlo sampling to find collision scenarios, we\nformulate the problem as a Markov decision process and use reinforcement\nlearning algorithms to find the most likely failure scenarios. This paper\npresents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL)\nsolutions that can scale to large environments. We show that DRL can find more\nlikely failure scenarios than MCTS with fewer calls to the simulator. A\nsimulation scenario involving a vehicle approaching a crosswalk is used to\nvalidate the framework. Our proposed approach is very general and can be easily\napplied to other scenarios given the appropriate models of the vehicle and the\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 21:10:37 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Koren", "Mark", ""], ["Alsaif", "Saud", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1902.01950", "submitter": "Kristy Choi", "authors": "Mike Wu, Kristy Choi, Noah Goodman, Stefano Ermon", "title": "Meta-Amortized Variational Inference and Learning", "comments": "First 2 authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success in probabilistic modeling and their applications,\ngenerative models trained using traditional inference techniques struggle to\nadapt to new distributions, even when the target distribution may be closely\nrelated to the ones seen during training. In this work, we present a\ndoubly-amortized variational inference procedure as a way to address this\nchallenge. By sharing computation across not only a set of query inputs, but\nalso a set of different, related probabilistic models, we learn transferable\nlatent representations that generalize across several related distributions. In\nparticular, given a set of distributions over images, we find the learned\nrepresentations to transfer to different data transformations. We empirically\ndemonstrate the effectiveness of our method by introducing the MetaVAE, and\nshow that it significantly outperforms baselines on downstream image\nclassification tasks on MNIST (10-50%) and NORB (10-35%).\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:06:25 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 06:09:30 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wu", "Mike", ""], ["Choi", "Kristy", ""], ["Goodman", "Noah", ""], ["Ermon", "Stefano", ""]]}, {"id": "1902.01958", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila, Francis Bach, Alessandro Rudi", "title": "A General Theory for Structured Prediction with Smooth Convex Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide a theoretical framework for structured prediction\nthat generalizes the existing theory of surrogate methods for binary and\nmulticlass classification based on estimating conditional probabilities with\nsmooth convex surrogates (e.g. logistic regression). The theory relies on a\nnatural characterization of structural properties of the task loss and allows\nto derive statistical guarantees for many widely used methods in the context of\nmultilabeling, ranking, ordinal regression and graph matching. In particular,\nwe characterize the smooth convex surrogates compatible with a given task loss\nin terms of a suitable Bregman divergence composed with a link function. This\nallows to derive tight bounds for the calibration function and to obtain novel\nresults on existing surrogate frameworks for structured prediction such as\nconditional random fields and quadratic surrogates.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 22:27:24 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 17:19:29 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Nowak-Vila", "Alex", ""], ["Bach", "Francis", ""], ["Rudi", "Alessandro", ""]]}, {"id": "1902.01996", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Samy Bengio and Yoram Singer", "title": "Are All Layers Created Equal?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding deep neural networks has been a major research objective in\nrecent years with notable theoretical progress. A focal point of those studies\nstems from the success of excessively large networks which defy the classical\nwisdom of uniform convergence and learnability. We study empirically the\nlayer-wise functional structure of overparameterized deep models. We provide\nevidence for the heterogeneous characteristic of layers. To do so, we introduce\nthe notion of robustness to post-training re-initialization and\nre-randomization. We show that the layers can be categorized as either\n``ambient'' or ``critical''. Resetting the ambient layers to their initial\nvalues has no negative consequence, and in many cases they barely change\nthroughout training. On the contrary, resetting the critical layers completely\ndestroys the predictor and the performance drops to chanceh. Our study provides\nfurther evidence that mere parameter counting or norm accounting is too coarse\nin studying generalization of deep models, and flatness or robustness analysis\nof the models needs to respect the network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 01:29:01 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 18:56:11 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 21:21:09 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Bengio", "Samy", ""], ["Singer", "Yoram", ""]]}, {"id": "1902.02037", "submitter": "Hao Wang", "authors": "Hao Wang, Chengzhi Mao, Hao He, Mingmin Zhao, Tommi S. Jaakkola, Dina\n  Katabi", "title": "Bidirectional Inference Networks: A Class of Deep Bayesian Networks for\n  Health Profiling", "comments": "Appeared at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the values of an arbitrary set of\nvariables (e.g., risk of diseases) given other observed variables (e.g.,\nsymptoms and diagnosed diseases) and high-dimensional signals (e.g., MRI images\nor EEG). This is a common problem in healthcare since variables of interest\noften differ for different patients. Existing methods including Bayesian\nnetworks and structured prediction either do not incorporate high-dimensional\nsignals or fail to model conditional dependencies among variables. To address\nthese issues, we propose bidirectional inference networks (BIN), which stich\ntogether multiple probabilistic neural networks, each modeling a conditional\ndependency. Predictions are then made via iteratively updating variables using\nbackpropagation (BP) to maximize corresponding posterior probability.\nFurthermore, we extend BIN to composite BIN (CBIN), which involves the\niterative prediction process in the training stage and improves both accuracy\nand computational efficiency by adaptively smoothing the optimization\nlandscape. Experiments on synthetic and real-world datasets (a sleep study and\na dermatology dataset) show that CBIN is a single model that can achieve\nstate-of-the-art performance and obtain better accuracy in most inference tasks\nthan multiple models each specifically trained for a different task.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 06:10:46 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Wang", "Hao", ""], ["Mao", "Chengzhi", ""], ["He", "Hao", ""], ["Zhao", "Mingmin", ""], ["Jaakkola", "Tommi S.", ""], ["Katabi", "Dina", ""]]}, {"id": "1902.02041", "submitter": "Sunghwan Joo", "authors": "Juyeon Heo, Sunghwan Joo, Taesup Moon", "title": "Fooling Neural Network Interpretations via Adversarial Model\n  Manipulation", "comments": null, "journal-ref": "NeurIPS 2019, ICCV workshop 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ask whether the neural network interpretation methods can be fooled via\nadversarial model manipulation, which is defined as a model fine-tuning step\nthat aims to radically alter the explanations without hurting the accuracy of\nthe original models, e.g., VGG19, ResNet50, and DenseNet121. By incorporating\nthe interpretation results directly in the penalty term of the objective\nfunction for fine-tuning, we show that the state-of-the-art saliency map based\ninterpreters, e.g., LRP, Grad-CAM, and SimpleGrad, can be easily fooled with\nour model manipulation. We propose two types of fooling, Passive and Active,\nand demonstrate such foolings generalize well to the entire validation set as\nwell as transfer to other interpretation methods. Our results are validated by\nboth visually showing the fooled explanations and reporting quantitative\nmetrics that measure the deviations from the original explanations. We claim\nthat the stability of neural network interpretation method with respect to our\nadversarial model manipulation is an important criterion to check for\ndeveloping robust and reliable neural network interpretation method.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 06:28:09 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 08:31:14 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 00:16:17 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Heo", "Juyeon", ""], ["Joo", "Sunghwan", ""], ["Moon", "Taesup", ""]]}, {"id": "1902.02113", "submitter": "Max Frenzel", "authors": "Max F. Frenzel, Bogdan Teleaga, Asahi Ushio", "title": "Latent Space Cartography: Generalised Metric-Inspired Measures and\n  Measure-Based Transformations for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are universal tools for learning data distributions on\nhigh dimensional data spaces via a mapping to lower dimensional latent spaces.\nWe provide a study of latent space geometries and extend and build upon\nprevious results on Riemannian metrics. We show how a class of heuristic\nmeasures gives more flexibility in finding meaningful, problem-specific\ndistances, and how it can be applied to diverse generator types such as\nautoregressive generators commonly used in e.g. language and other sequence\nmodeling. We further demonstrate how a diffusion-inspired transformation\npreviously studied in cartography can be used to smooth out latent spaces,\nstretching them according to a chosen measure. In addition to providing more\nmeaningful distances directly in latent space, this also provides a unique tool\nfor novel kinds of data visualizations. We believe that the proposed methods\ncan be a valuable tool for studying the structure of latent spaces and learned\ndata distributions of generative models.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 11:15:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Frenzel", "Max F.", ""], ["Teleaga", "Bogdan", ""], ["Ushio", "Asahi", ""]]}, {"id": "1902.02132", "submitter": "Felix Diaz Hermida", "authors": "F\\'elix D\\'iaz-Hermida, Marcos Matabuena, Juan C. Vidal", "title": "The FA Quantifier Fuzzification Mechanism: analysis of convergence and\n  efficient implementations", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fuzzy quantification model FA has been identified as one of the best\nbehaved quantification models in several revisions of the field of fuzzy\nquantification. This model is, to our knowledge, the unique one fulfilling the\nstrict Determiner Fuzzification Scheme axiomatic framework that does not induce\nthe standard min and max operators. The main contribution of this paper is the\nproof of a convergence result that links this quantification model with the\nZadeh's model when the size of the input sets tends to infinite. The\nconvergence proof is, in any case, more general than the convergence to the\nZadeh's model, being applicable to any quantitative quantifier. In addition,\nrecent revisions papers have presented some doubts about the existence of\nsuitable computational implementations to evaluate the FA model in practical\napplications. In order to prove that this model is not only a theoretical\napproach, we show exact algorithmic solutions for the most common linguistic\nquantifiers as well as an approximate implementation by means of Monte Carlo.\nAdditionally, we will also give a general overview of the main properties\nfulfilled by the FA model, as a single compendium integrating the whole set of\nproperties fulfilled by it has not been previously published.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 12:17:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["D\u00edaz-Hermida", "F\u00e9lix", ""], ["Matabuena", "Marcos", ""], ["Vidal", "Juan C.", ""]]}, {"id": "1902.02162", "submitter": "Anupiya Nugaliyadde Mr", "authors": "M.R, Akram, C.P, Singhabahu, M.S.M Saad, P, Deleepa, Anupiya,\n  Nugaliyadde and Yashas, Mallawarachchi", "title": "Adaptive Artificial Intelligent Q&A Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an approach to build a question and answer system that is\ncapable of processing the information in a large dataset and allows the user to\ngain knowledge from this dataset by asking questions in natural language form.\nKey content of this research covers four dimensions which are; Corpus\nPreprocessing, Question Preprocessing, Deep Neural Network for Answer\nExtraction and Answer Generation. The system is capable of understanding the\nquestion, responds to the user's query in natural language form as well. The\ngoal is to make the user feel as if they were interacting with a person than a\nmachine.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 17:40:08 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["R", "M.", ""], ["Akram", "", ""], ["P", "C.", ""], ["Singhabahu", "", ""], ["Saad", "M. S. M", ""], ["P", "", ""], ["Deleepa", "", ""], ["Anupiya", "", ""], ["Nugaliyadde", "", ""], ["Yashas", "", ""], ["Mallawarachchi", "", ""]]}, {"id": "1902.02169", "submitter": "Lukas Schmelzeisen", "authors": "Lukas Schmelzeisen and Steffen Staab", "title": "Learning Taxonomies of Concepts and not Words using Contextualized Word\n  Representations: A Position Paper", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Taxonomies are semantic hierarchies of concepts. One limitation of current\ntaxonomy learning systems is that they define concepts as single words. This\nposition paper argues that contextualized word representations, which recently\nachieved state-of-the-art results on many competitive NLP tasks, are a\npromising method to address this limitation. We outline a novel approach for\ntaxonomy learning that (1) defines concepts as synsets, (2) learns\ndensity-based approximations of contextualized word representations, and (3)\ncan measure similarity and hypernymy among them.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 17:18:42 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Schmelzeisen", "Lukas", ""], ["Staab", "Steffen", ""]]}, {"id": "1902.02181", "submitter": "Andrea Galassi", "authors": "Andrea Galassi, Marco Lippi, Paolo Torroni", "title": "Attention in Natural Language Processing", "comments": "18 pages, 8 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2020)", "doi": "10.1109/TNNLS.2020.3019893", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is an increasingly popular mechanism used in a wide range of neural\narchitectures. The mechanism itself has been realized in a variety of formats.\nHowever, because of the fast-paced advances in this domain, a systematic\noverview of attention is still missing. In this article, we define a unified\nmodel for attention architectures in natural language processing, with a focus\non those designed to work with vector representations of the textual data. We\npropose a taxonomy of attention models according to four dimensions: the\nrepresentation of the input, the compatibility function, the distribution\nfunction, and the multiplicity of the input and/or output. We present the\nexamples of how prior information can be exploited in attention models and\ndiscuss ongoing research efforts and open challenges in the area, providing the\nfirst extensive categorization of the vast body of literature in this exciting\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 16:09:50 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 10:52:29 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Galassi", "Andrea", ""], ["Lippi", "Marco", ""], ["Torroni", "Paolo", ""]]}, {"id": "1902.02186", "submitter": "Razvan Pascanu", "authors": "Wojciech Marian Czarnecki, Razvan Pascanu, Simon Osindero, Siddhant M.\n  Jayakumar, Grzegorz Swirszcz, Max Jaderberg", "title": "Distilling Policy Distillation", "comments": "Accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transfer of knowledge from one policy to another is an important tool in\nDeep Reinforcement Learning. This process, referred to as distillation, has\nbeen used to great success, for example, by enhancing the optimisation of\nagents, leading to stronger performance faster, on harder domains [26, 32, 5,\n8]. Despite the widespread use and conceptual simplicity of distillation, many\ndifferent formulations are used in practice, and the subtle variations between\nthem can often drastically change the performance and the resulting objective\nthat is being optimised. In this work, we rigorously explore the entire\nlandscape of policy distillation, comparing the motivations and strengths of\neach variant through theoretical and empirical analysis. Our results point to\nthree distillation techniques, that are preferred depending on specifics of the\ntask. Specifically a newly proposed expected entropy regularised distillation\nallows for quicker learning in a wide range of situations, while still\nguaranteeing convergence.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 14:01:34 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["Pascanu", "Razvan", ""], ["Osindero", "Simon", ""], ["Jayakumar", "Siddhant M.", ""], ["Swirszcz", "Grzegorz", ""], ["Jaderberg", "Max", ""]]}, {"id": "1902.02194", "submitter": "Romain Edelmann", "authors": "Romain Edelmann, Viktor Kun\\v{c}ak", "title": "Neural-Network Guided Expression Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing compilers, as well as other translator systems, often work by\nrewriting expressions according to equivalence preserving rules. Given an input\nexpression and its optimized form, finding the sequence of rules that were\napplied is a non-trivial task. Most of the time, the tools provide no proof, of\nany kind, of the equivalence between the original expression and its optimized\nform. In this work, we propose to reconstruct proofs of equivalence of simple\nmathematical expressions, after the fact, by finding paths of equivalence\npreserving transformations between expressions. We propose to find those\nsequences of transformations using a search algorithm, guided by a neural\nnetwork heuristic. Using a Tree-LSTM recursive neural network, we learn a\ndistributed representation of expressions where the Manhattan distance between\nvectors approximately corresponds to the rewrite distance between expressions.\nWe then show how the neural network can be efficiently used to search for\ntransformation paths, leading to substantial gain in speed compared to an\nuninformed exhaustive search. In one of our experiments, our neural-network\nguided search algorithm is able to solve more instances with a 2 seconds\ntimeout per instance than breadth-first search does with a 5 minutes timeout\nper instance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 14:17:47 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Edelmann", "Romain", ""], ["Kun\u010dak", "Viktor", ""]]}, {"id": "1902.02279", "submitter": "Mauricio Gonzalez-Soto", "authors": "M. Gonzalez-Soto, L.E. Sucar, H.J. Escalante", "title": "A Guiding Principle for Causal Decision Problems", "comments": "Submitted to AAAI Spring Symposium Beyond Curve Fitting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a Causal Decision Problem as a Decision Problem where the available\nactions, the family of uncertain events and the set of outcomes are related\nthrough the variables of a Causal Graphical Model $\\mathcal{G}$. A solution\ncriteria based on Pearl's Do-Calculus and the Expected Utility criteria for\nrational preferences is proposed. The implementation of this criteria leads to\nan on-line decision making procedure that has been shown to have similar\nperformance to classic Reinforcement Learning algorithms while allowing for a\ncausal model of an environment to be learned. Thus, we aim to provide the\ntheoretical guarantees of the usefulness and optimality of a decision making\nprocedure based on causal information.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 17:15:28 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Gonzalez-Soto", "M.", ""], ["Sucar", "L. E.", ""], ["Escalante", "H. J.", ""]]}, {"id": "1902.02311", "submitter": "Alex Tong Lin", "authors": "Alex Tong Lin, Mark J. Debord, Katia Estabridis, Gary Hewer, Guido\n  Montufar, Stanley Osher", "title": "Decentralized Multi-Agents by Imitation of a Centralized Controller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-agent reinforcement learning problem where each agent\nseeks to maximize a shared reward while interacting with other agents, and they\nmay or may not be able to communicate. Typically the agents do not have access\nto other agent policies and thus each agent is situated in a non-stationary and\npartially-observable environment. In order to obtain multi-agents that act in a\ndecentralized manner, we introduce a novel algorithm under the popular\nframework of centralized training, but decentralized execution. This training\nframework first obtains solutions to a multi-agent problem with a single\ncentralized joint-space learner, which is then used to guide imitation learning\nfor independent decentralized multi-agents. This framework has the flexibility\nto use any reinforcement learning algorithm to obtain the expert as well as any\nimitation learning algorithm to obtain the decentralized agents. This is in\ncontrast to other multi-agent learning algorithms that, for example, can\nrequire more specific structures. We present some theoretical bounds for our\nmethod, and we show that one can obtain decentralized solutions to a\nmulti-agent problem through imitation learning.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:14:31 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 14:48:32 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 01:39:00 GMT"}, {"version": "v4", "created": "Thu, 22 Apr 2021 18:59:26 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Lin", "Alex Tong", ""], ["Debord", "Mark J.", ""], ["Estabridis", "Katia", ""], ["Hewer", "Gary", ""], ["Montufar", "Guido", ""], ["Osher", "Stanley", ""]]}, {"id": "1902.02322", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini", "title": "Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:38:02 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Carlini", "Nicholas", ""]]}, {"id": "1902.02354", "submitter": "Zohar Ringel", "authors": "Oded Ben-David, Zohar Ringel", "title": "The role of a layer in deep neural networks: a Gaussian Process\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in deep learning concerns the role played by\nindividual layers in a deep neural network (DNN) and the transferable\nproperties of the data representations which they learn. To the extent that\nlayers have clear roles, one should be able to optimize them separately using\nlayer-wise loss functions. Such loss functions would describe what is the set\nof good data representations at each depth of the network and provide a target\nfor layer-wise greedy optimization (LEGO). Here we derive a novel\ncorrespondence between Gaussian Processes and SGD trained deep neural networks.\nLeveraging this correspondence, we derive the Deep Gaussian Layer-wise loss\nfunctions (DGLs) which, we believe, are the first supervised layer-wise loss\nfunctions which are both explicit and competitive in terms of accuracy. Being\nhighly structured and symmetric, the DGLs provide a promising analytic route to\nunderstanding the internal representations generated by DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:00:03 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 14:19:01 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 11:59:02 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ben-David", "Oded", ""], ["Ringel", "Zohar", ""]]}, {"id": "1902.02384", "submitter": "Mark Ibrahim", "authors": "Mark Ibrahim, Melissa Louie, Ceena Modarres, John Paisley", "title": "Global Explanations of Neural Networks: Mapping the Landscape of\n  Predictions", "comments": "published at ACM/AAAI AIES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A barrier to the wider adoption of neural networks is their lack of\ninterpretability. While local explanation methods exist for one prediction,\nmost global attributions still reduce neural network decisions to a single set\nof features. In response, we present an approach for generating global\nattributions called GAM, which explains the landscape of neural network\npredictions across subpopulations. GAM augments global explanations with the\nproportion of samples that each attribution best explains and specifies which\nsamples are described by each attribution. Global explanations also have\ntunable granularity to detect more or fewer subpopulations. We demonstrate that\nGAM's global explanations 1) yield the known feature importances of simulated\ndata, 2) match feature weights of interpretable statistical models on real\ndata, and 3) are intuitive to practitioners through user studies. With more\ntransparent predictions, GAM can help ensure neural network decisions are\ngenerated for the right reasons.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 19:58:48 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Ibrahim", "Mark", ""], ["Louie", "Melissa", ""], ["Modarres", "Ceena", ""], ["Paisley", "John", ""]]}, {"id": "1902.02390", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ahmed Ahmed Elsaid, Travis Desell", "title": "Investigating Recurrent Neural Network Memory Structures using\n  Neuro-Evolution", "comments": "Some corrections to language, title fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm, Evolutionary eXploration of Augmenting\nMemory Models (EXAMM), which is capable of evolving recurrent neural networks\n(RNNs) using a wide variety of memory structures, such as Delta-RNN, GRU, LSTM,\nMGU and UGRNN cells. EXAMM evolved RNNs to perform prediction of large-scale,\nreal world time series data from the aviation and power industries. These data\nsets consist of very long time series (thousands of readings), each with a\nlarge number of potentially correlated and dependent parameters. Four different\nparameters were selected for prediction and EXAMM runs were performed using\neach memory cell type alone, each cell type with feed forward nodes, and with\nall possible memory cell types. Evolved RNN performance was measured using\nrepeated k-fold cross validation, resulting in 1210 EXAMM runs which evolved\n2,420,000 RNNs in 12,100 CPU hours on a high performance computing cluster.\nGeneralization of the evolved RNNs was examined statistically, providing\ninteresting findings that can help refine the RNN memory cell design as well as\ninform future neuro-evolution algorithms development.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 20:33:12 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 20:23:06 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ororbia", "Alexander", ""], ["Elsaid", "Ahmed Ahmed", ""], ["Desell", "Travis", ""]]}, {"id": "1902.02393", "submitter": "Sudarshanan Bharadwaj", "authors": "Suda Bharadwaj, Rayna Dimitrova, Ufuk Topcu", "title": "Distributed Synthesis of Surveillance Strategies for Mobile Sensors", "comments": null, "journal-ref": "2018 IEEE Conference on Decision and Control (CDC), FL, USA, 2018,\n  pp. 3335-3342", "doi": "10.1109/CDC.2018.8619145", "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of synthesizing strategies for a mobile sensor network\nto conduct surveillance in partnership with static alarm triggers. We formulate\nthe problem as a multi-agent reactive synthesis problem with surveillance\nobjectives specified as temporal logic formulas. In order to avoid the state\nspace blow-up arising from a centralized strategy computation, we propose a\nmethod to decentralize the surveillance strategy synthesis by decomposing the\nmulti-agent game into subgames that can be solved independently. We also\ndecompose the global surveillance specification into local specifications for\neach sensor, and show that if the sensors satisfy their local surveillance\nspecifications, then the sensor network as a whole will satisfy the global\nsurveillance objective. Thus, our method is able to guarantee global\nsurveillance properties in a mobile sensor network while synthesizing\ncompletely decentralized strategies with no need for coordination between the\nsensors. We also present a case study in which we demonstrate an application of\ndecentralized surveillance strategy synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 20:41:51 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Bharadwaj", "Suda", ""], ["Dimitrova", "Rayna", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1902.02399", "submitter": "Jae-Wook Ahn", "authors": "Payel Das, Brian Quanz, Pin-Yu Chen, Jae-wook Ahn, Dhruv Shah", "title": "Toward A Neuro-inspired Creative Decoder", "comments": "Accepted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity, a process that generates novel and meaningful ideas, involves\nincreased association between task-positive (control) and task-negative\n(default) networks in the human brain. Inspired by this seminal finding, in\nthis study we propose a creative decoder within a deep generative framework,\nwhich involves direct modulation of the neuronal activation pattern after\nsampling from the learned latent space. The proposed approach is fully\nunsupervised and can be used off-the-shelf. Several novelty metrics and human\nevaluation were used to evaluate the creative capacity of the deep decoder. Our\nexperiments on different image datasets (MNIST, FMNIST, MNIST+FMNIST, WikiArt\nand CelebA) reveal that atypical co-activation of highly activated and weakly\nactivated neurons in a deep decoder promotes generation of novel and meaningful\nartifacts.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 21:06:58 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 17:09:42 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 18:24:27 GMT"}, {"version": "v4", "created": "Thu, 23 Apr 2020 02:42:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Das", "Payel", ""], ["Quanz", "Brian", ""], ["Chen", "Pin-Yu", ""], ["Ahn", "Jae-wook", ""], ["Shah", "Dhruv", ""]]}, {"id": "1902.02432", "submitter": "Abhishek Dubey", "authors": "Shreyas Ramakrishna and Charles Hartsell and Matthew P Burruss and\n  Gabor Karsai and Abhishek Dubey", "title": "Dynamic-Weighted Simplex Strategy for Learning Enabled Cyber Physical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber Physical Systems (CPS) have increasingly started using Learning Enabled\nComponents (LECs) for performing perception-based control tasks. The simple\ndesign approach, and their capability to continuously learn has led to their\nwidespread use in different autonomous applications. Despite their simplicity\nand impressive capabilities, these models are difficult to assure, which makes\ntheir use challenging. The problem of assuring CPS with untrusted controllers\nhas been achieved using the Simplex Architecture. This architecture integrates\nthe system to be assured with a safe controller and provides a decision logic\nto switch between the decisions of these controllers. However, the key\nchallenges in using the Simplex Architecture are: (1) designing an effective\ndecision logic, and (2) sudden transitions between controller decisions lead to\ninconsistent system performance. To address these research challenges, we make\nthree key contributions: (1) \\textit{dynamic-weighted simplex strategy} -- we\nintroduce ``weighted simplex strategy\" as the weighted ensemble extension of\nthe classical Simplex Architecture. We then provide a reinforcement learning\nbased mechanism to find dynamic ensemble weights, (2) \\textit{middleware\nframework} -- we design a framework that allows the use of the dynamic-weighted\nsimplex strategy, and provides a resource manager to monitor the computational\nresources, and (3) \\textit{hardware testbed} -- we design a remote-controlled\ncar testbed called DeepNNCar to test and demonstrate the aforementioned key\nconcepts. Using the hardware, we show that the dynamic-weighted simplex\nstrategy has 60\\% fewer out-of-track occurrences (soft constraint violations),\nwhile demonstrating higher optimized speed (performance) of 0.4 m/s during\nindoor driving than the original LEC driven system.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 23:39:22 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 22:28:11 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 17:27:28 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Ramakrishna", "Shreyas", ""], ["Hartsell", "Charles", ""], ["Burruss", "Matthew P", ""], ["Karsai", "Gabor", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1902.02443", "submitter": "Sunil Mallya", "authors": "Sunil Mallya, Marc Overhage, Navneet Srivastava, Tatsuya Arai, Cole\n  Erdman", "title": "Effectiveness of LSTMs in Predicting Congestive Heart Failure Onset", "comments": "LSTMs, Electronic Health Records", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a Recurrent neural networks (RNN) based architecture\nthat achieves an AUCROC of 0.9147 for predicting the onset of Congestive Heart\nFailure (CHF) 15 months in advance using a 12-month observation window on a\nlarge cohort of 216,394 patients. We believe this to be the largest study in\nCHF onset prediction with respect to the number of CHF case patients in the\ncohort and the test set (3,332 CHF patients) on which the AUC metrics are\nreported. We explore the extent to which LSTM (Long Short Term Memory) based\nmodel, a variant of RNNs, can accurately predict the onset of CHF when compared\nto known linear baselines like Logistic Regression, Random Forests and deep\nlearning based models such as Multi-Layer Perceptron and Convolutional Neural\nNetworks. We utilize demographics, medical diagnosis and procedure data from\n21,405 CHF and 194,989 control patients to as our features. We describe our\nfeature embedding strategy for medical diagnosis codes that accommodates the\nsparse, irregular, longitudinal, and high-dimensional characteristics of EHR\ndata. We empirically show that LSTMs can capture the longitudinal aspects of\nEHR data better than the proposed baselines. As an attempt to interpret the\nmodel, we present a temporal data analysis-based technique on false positives\nto attribute feature importance. A model capable of predicting the onset of\ncongestive heart failure months in the future with this level of accuracy and\nprecision can support efforts of practitioners to implement risk factor\nreduction strategies and researchers to begin to systematically evaluate\ninterventions to potentially delay or avert development of the disease with\nhigh mortality, morbidity and significant costs.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 01:47:28 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 06:13:02 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Mallya", "Sunil", ""], ["Overhage", "Marc", ""], ["Srivastava", "Navneet", ""], ["Arai", "Tatsuya", ""], ["Erdman", "Cole", ""]]}, {"id": "1902.02476", "submitter": "Andrew Wilson", "authors": "Wesley Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, Andrew\n  Gordon Wilson", "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose\napproach for uncertainty representation and calibration in deep learning.\nStochastic Weight Averaging (SWA), which computes the first moment of\nstochastic gradient descent (SGD) iterates with a modified learning rate\nschedule, has recently been shown to improve generalization in deep learning.\nWith SWAG, we fit a Gaussian using the SWA solution as the first moment and a\nlow rank plus diagonal covariance also derived from the SGD iterates, forming\nan approximate posterior distribution over neural network weights; we then\nsample from this Gaussian distribution to perform Bayesian model averaging. We\nempirically find that SWAG approximates the shape of the true posterior, in\naccordance with results describing the stationary distribution of SGD iterates.\nMoreover, we demonstrate that SWAG performs well on a wide variety of tasks,\nincluding out of sample detection, calibration, and transfer learning, in\ncomparison to many popular alternatives including MC dropout, KFAC Laplace,\nSGLD, and temperature scaling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 05:15:46 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 08:28:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Maddox", "Wesley", ""], ["Garipov", "Timur", ""], ["Izmailov", "Pavel", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1902.02518", "submitter": "Matthew Stephenson", "authors": "Matthew Stephenson, Jochen Renz", "title": "Agent-Based Adaptive Level Generation for Dynamic Difficulty Adjustment\n  in Angry Birds", "comments": "AAAI-19 Workshop on Games and Simulations for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive level generation algorithm for the\nphysics-based puzzle game Angry Birds. The proposed algorithm is based on a\npre-existing level generator for this game, but where the difficulty of the\ngenerated levels can be adjusted based on the player's performance. This allows\nfor the creation of personalised levels tailored specifically to the player's\nown abilities. The effectiveness of our proposed method is evaluated using\nseveral agents with differing strategies and AI techniques. By using these\nagents as models / representations of real human player's characteristics, we\ncan optimise level properties efficiently over a large number of generations.\nAs a secondary investigation, we also demonstrate that by combining the\nperformance of several agents together it is possible to generate levels that\nare especially challenging for certain players but not others.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 08:36:34 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Stephenson", "Matthew", ""], ["Renz", "Jochen", ""]]}, {"id": "1902.02556", "submitter": "H\\'el\\`ene Plisnier", "authors": "H\\'el\\`ene Plisnier, Denis Steckelmacher, Diederik M. Roijers, Ann\n  Now\\'e", "title": "The Actor-Advisor: Policy Gradient With Off-Policy Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor-critic algorithms learn an explicit policy (actor), and an accompanying\nvalue function (critic). The actor performs actions in the environment, while\nthe critic evaluates the actor's current policy. However, despite their\nstability and promising convergence properties, current actor-critic algorithms\ndo not outperform critic-only ones in practice. We believe that the fact that\nthe critic learns Q^pi, instead of the optimal Q-function Q*, prevents\nstate-of-the-art robust and sample-efficient off-policy learning algorithms\nfrom being used. In this paper, we propose an elegant solution, the\nActor-Advisor architecture, in which a Policy Gradient actor learns from\nunbiased Monte-Carlo returns, while being shaped (or advised) by the Softmax\npolicy arising from an off-policy critic. The critic can be learned\nindependently from the actor, using any state-of-the-art algorithm. Being\nadvised by a high-quality critic, the actor quickly and robustly learns the\ntask, while its use of the Monte-Carlo return helps overcome any bias the\ncritic may have. In addition to a new Actor-Critic formulation, the\nActor-Advisor, a method that allows an external advisory policy to shape a\nPolicy Gradient actor, can be applied to many other domains. By varying the\nsource of advice, we demonstrate the wide applicability of the Actor-Advisor to\nthree other important subfields of RL: safe RL with backup policies, efficient\nleverage of domain knowledge, and transfer learning in RL. Our experimental\nresults demonstrate the benefits of the Actor-Advisor compared to\nstate-of-the-art actor-critic methods, illustrate its applicability to the\nthree other application scenarios listed above, and show that many important\nchallenges of RL can now be solved using a single elegant solution.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 10:30:40 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Plisnier", "H\u00e9l\u00e8ne", ""], ["Steckelmacher", "Denis", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1902.02661", "submitter": "Divya Grover", "authors": "Divya Grover, Debabrota Basu, Christos Dimitrakakis", "title": "Bayesian Reinforcement Learning via Deep, Sparse Sampling", "comments": "Published in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of Bayesian reinforcement learning using efficient\nmodel-based online planning. We propose an optimism-free Bayes-adaptive\nalgorithm to induce deeper and sparser exploration with a theoretical bound on\nits performance relative to the Bayes optimal policy, with a lower\ncomputational complexity. The main novelty is the use of a candidate policy\ngenerator, to generate long-term options in the planning tree (over beliefs),\nwhich allows us to create much sparser and deeper trees. Experimental results\non different environments show that in comparison to the state-of-the-art, our\nalgorithm is both computationally more efficient, and obtains significantly\nhigher reward in discrete environments.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 14:52:37 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 15:20:51 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 10:32:19 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 16:31:26 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Grover", "Divya", ""], ["Basu", "Debabrota", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1902.02752", "submitter": "Alexandre Kaspar", "authors": "Alexandre Kaspar, Tae-Hyun Oh, Liane Makatura, Petr Kellnhofer,\n  Jacqueline Aslarus and Wojciech Matusik", "title": "Neural Inverse Knitting: From Images to Manufacturing Instructions", "comments": "Project page: http://deepknitting.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent potential of mass customization brought by\nwhole-garment knitting machines, we introduce the new problem of automatic\nmachine instruction generation using a single image of the desired physical\nproduct, which we apply to machine knitting. We propose to tackle this problem\nby directly learning to synthesize regular machine instructions from real\nimages. We create a cured dataset of real samples with their instruction\ncounterpart and propose to use synthetic images to augment it in a novel way.\nWe theoretically motivate our data mixing framework and show empirical results\nsuggesting that making real images look more synthetic is beneficial in our\nproblem setup.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 18:05:17 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 19:32:16 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Kaspar", "Alexandre", ""], ["Oh", "Tae-Hyun", ""], ["Makatura", "Liane", ""], ["Kellnhofer", "Petr", ""], ["Aslarus", "Jacqueline", ""], ["Matusik", "Wojciech", ""]]}, {"id": "1902.02834", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti, Jilles Vreeken", "title": "The Long and the Short of It: Summarising Event Sequences with Serial\n  Episodes", "comments": null, "journal-ref": null, "doi": "10.1145/2339530.2339606", "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ideal outcome of pattern mining is a small set of informative patterns,\ncontaining no redundancy or noise, that identifies the key structure of the\ndata at hand. Standard frequent pattern miners do not achieve this goal, as due\nto the pattern explosion typically very large numbers of highly redundant\npatterns are returned.\n  We pursue the ideal for sequential data, by employing a pattern set mining\napproach-an approach where, instead of ranking patterns individually, we\nconsider results as a whole. Pattern set mining has been successfully applied\nto transactional data, but has been surprisingly under studied for sequential\ndata.\n  In this paper, we employ the MDL principle to identify the set of sequential\npatterns that summarises the data best. In particular, we formalise how to\nencode sequential data using sets of serial episodes, and use the encoded\nlength as a quality score. As search strategy, we propose two approaches: the\nfirst algorithm selects a good pattern set from a large candidate set, while\nthe second is a parameter-free any-time algorithm that mines pattern sets\ndirectly from the data. Experimentation on synthetic and real data demonstrates\nwe efficiently discover small sets of informative patterns.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 20:25:50 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Tatti", "Nikolaj", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1902.02870", "submitter": "Valsamis Ntouskos", "authors": "Lorenzo Mauro, Francesco Puja, Simone Grazioso, Valsamis Ntouskos,\n  Marta Sanzari, Edoardo Alati, Fiora Pirri", "title": "Visual search and recognition for robot task execution and monitoring", "comments": null, "journal-ref": "Frontiers in Artificial Intelligence and Applications 310 (2018)\n  94-109", "doi": "10.3233/978-1-61499-929-4-94", "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual search of relevant targets in the environment is a crucial robot\nskill. We propose a preliminary framework for the execution monitor of a robot\ntask, taking care of the robot attitude to visually searching the environment\nfor targets involved in the task. Visual search is also relevant to recover\nfrom a failure. The framework exploits deep reinforcement learning to acquire a\n\"common sense\" scene structure and it takes advantage of a deep convolutional\nnetwork to detect objects and relevant relations holding between them. The\nframework builds on these methods to introduce a vision-based execution\nmonitoring, which uses classical planning as a backbone for task execution.\nExperiments show that with the proposed vision-based execution monitor the\nrobot can complete simple tasks and can recover from failures in autonomy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 22:35:51 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Mauro", "Lorenzo", ""], ["Puja", "Francesco", ""], ["Grazioso", "Simone", ""], ["Ntouskos", "Valsamis", ""], ["Sanzari", "Marta", ""], ["Alati", "Edoardo", ""], ["Pirri", "Fiora", ""]]}, {"id": "1902.02877", "submitter": "Valsamis Ntouskos", "authors": "Lorenzo Mauro, Edoardo Alati, Marta Sanzari, Valsamis Ntouskos,\n  Gianluca Massimiani, Fiora Pirri", "title": "Deep execution monitor for robot assistive tasks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-11024-6_11", "report-no": null, "categories": "cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel approach to high-level robot task execution for a robot\nassistive task. In this work we explore the problem of learning to predict the\nnext subtask by introducing a deep model for both sequencing goals and for\nvisually evaluating the state of a task. We show that deep learning for\nmonitoring robot tasks execution very well supports the interconnection between\ntask-level planning and robot operations. These solutions can also cope with\nthe natural non-determinism of the execution monitor. We show that a deep\nexecution monitor leverages robot performance. We measure the improvement\ntaking into account some robot helping tasks performed at a warehouse.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 23:02:47 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Mauro", "Lorenzo", ""], ["Alati", "Edoardo", ""], ["Sanzari", "Marta", ""], ["Ntouskos", "Valsamis", ""], ["Massimiani", "Gianluca", ""], ["Pirri", "Fiora", ""]]}, {"id": "1902.02893", "submitter": "Silviu Pitis", "authors": "Silviu Pitis", "title": "Rethinking the Discount Factor in Reinforcement Learning: A Decision\n  Theoretic Approach", "comments": "8 pages + 1 page supplement. In proceedings of AAAI 2019. Slides,\n  poster and bibtex available at\n  https://silviupitis.com/#rethinking-the-discount-factor-in-reinforcement-learning-a-decision-theoretic-approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents have traditionally been tasked with\nmaximizing the value function of a Markov decision process (MDP), either in\ncontinuous settings, with fixed discount factor $\\gamma < 1$, or in episodic\nsettings, with $\\gamma = 1$. While this has proven effective for specific tasks\nwith well-defined objectives (e.g., games), it has never been established that\nfixed discounting is suitable for general purpose use (e.g., as a model of\nhuman preferences). This paper characterizes rationality in sequential decision\nmaking using a set of seven axioms and arrives at a form of discounting that\ngeneralizes traditional fixed discounting. In particular, our framework admits\na state-action dependent \"discount\" factor that is not constrained to be less\nthan 1, so long as there is eventual long run discounting. Although this\nbroadens the range of possible preference structures in continuous settings, we\nshow that there exists a unique \"optimizing MDP\" with fixed $\\gamma < 1$ whose\noptimal value function matches the true utility of the optimal policy, and we\nquantify the difference between value and utility for suboptimal policies. Our\nwork can be seen as providing a normative justification for (a slight\ngeneralization of) Martha White's RL task formalism (2017) and other recent\ndepartures from the traditional RL, and is relevant to task specification in\nRL, inverse RL and preference-based RL.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 00:30:53 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pitis", "Silviu", ""]]}, {"id": "1902.02904", "submitter": "Xilei Zhao", "authors": "Xilei Zhao, Xiang Yan, Pascal Van Hentenryck", "title": "Modeling Heterogeneity in Mode-Switching Behavior Under a\n  Mobility-on-Demand Transit System: An Interpretable Machine Learning Approach", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increased focus on interpretability and the\nuse of machine learning to inform policy analysis and decision making. This\npaper applies machine learning to examine travel behavior and, in particular,\non modeling changes in travel modes when individuals are presented with a novel\n(on-demand) mobility option. It addresses the following question: Can machine\nlearning be applied to model individual taste heterogeneity (preference\nheterogeneity for travel modes and response heterogeneity to travel attributes)\nin travel mode choice? This paper first develops a high-accuracy classifier to\npredict mode-switching behavior under a hypothetical Mobility-on-Demand Transit\nsystem (i.e., stated-preference data), which represents the case study\nunderlying this research. We show that this classifier naturally captures\nindividual heterogeneity available in the data. Moreover, the paper derives\ninsights on heterogeneous switching behaviors through the generation of\nmarginal effects and elasticities by current travel mode, partial dependence\nplots, and individual conditional expectation plots. The paper also proposes\ntwo new model-agnostic interpretation tools for machine learning, i.e.,\nconditional partial dependence plots and conditional individual partial\ndependence plots, specifically designed to examine response heterogeneity. The\nresults on the case study show that the machine-learning classifier, together\nwith model-agnostic interpretation tools, provides valuable insights on travel\nmode switching behavior for different individuals and population segments. For\nexample, the existing drivers are more sensitive to additional pickups than\npeople using other travel modes, and current transit users are generally\nwilling to share rides but reluctant to take any additional transfers.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:15:09 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Zhao", "Xilei", ""], ["Yan", "Xiang", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "1902.02905", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo, Mikelson MomPremier, Richard Y. Hwang, Salman J.\n  Yousuf, Steven L. Williams, Joshua Grant", "title": "Mobile Artificial Intelligence Technology for Detecting Macula Edema and\n  Subretinal Fluid on OCT Scans: Initial Results from the DATUM alpha Study", "comments": "Initial results of the DATUM alpha Study were initially presented on\n  August 13th 2018 in the Keynote Address at the 116th National Medical\n  Association Annual Meeting & Scientific Assembly's New Innovations in\n  Ophthalmology Session. The results were also presented on September 21st 2018\n  in a Podium Lecture during Alumni Day at the University of Michigan--Ann\n  Arbor Kellogg Eye Center", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is necessary to address the large and growing\ndeficit in retina and healthcare access globally. And mobile AI diagnostic\nplatforms running in the Cloud may effectively and efficiently distribute such\nAI capability. Here we sought to evaluate the feasibility of Cloud-based mobile\nartificial intelligence for detection of retinal disease. And to evaluate the\naccuracy of a particular such system for detection of subretinal fluid (SRF)\nand macula edema (ME) on OCT scans. A multicenter retrospective image analysis\nwas conducted in which board-certified ophthalmologists with fellowship\ntraining in retina evaluated OCT images of the macula. They noted the presence\nor absence of ME or SRF, then compared their assessment to that obtained from\nFluid Intelligence, a mobile AI app that detects SRF and ME on OCT scans.\nInvestigators consecutively selected retinal OCTs, while making effort to\nbalance the number of scans with retinal fluid and scans without. Exclusion\ncriteria included poor scan quality, ambiguous features, macula holes,\nretinoschisis, and dense epiretinal membranes. Accuracy in the form of\nsensitivity and specificity of the AI mobile App was determined by comparing\nits assessments to those of the retina specialists. At the time of this\nsubmission, five centers have completed their initial studies. This consists of\na total of 283 OCT scans of which 155 had either ME or SRF (\"wet\") and 128 did\nnot (\"dry\"). The sensitivity ranged from 82.5% to 97% with a weighted average\nof 89.3%. The specificity ranged from 52% to 100% with a weighted average of\n81.23%. CONCLUSION: Cloud-based Mobile AI technology is feasible for the\ndetection retinal disease. In particular, Fluid Intelligence (alpha version),\nis sufficiently accurate as a screening tool for SRF and ME, especially in\nunderserved areas. Further studies and technology development is needed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:15:23 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 23:50:23 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Odaibo", "Stephen G.", ""], ["MomPremier", "Mikelson", ""], ["Hwang", "Richard Y.", ""], ["Yousuf", "Salman J.", ""], ["Williams", "Steven L.", ""], ["Grant", "Joshua", ""]]}, {"id": "1902.02907", "submitter": "Silviu Pitis", "authors": "Silviu Pitis", "title": "Source Traces for Temporal Difference Learning", "comments": "8 pages. In proceedings of AAAI 2018. Slides and bibtex available at\n  https://silviupitis.com/#source-traces-for-temporal-difference-learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper motivates and develops source traces for temporal difference (TD)\nlearning in the tabular setting. Source traces are like eligibility traces, but\nmodel potential histories rather than immediate ones. This allows TD errors to\nbe propagated to potential causal states and leads to faster generalization.\nSource traces can be thought of as the model-based, backward view of successor\nrepresentations (SR), and share many of the same benefits. This view, however,\nsuggests several new ideas. First, a TD($\\lambda$)-like source learning\nalgorithm is proposed and its convergence is proven. Then, a novel algorithm\nfor learning the source map (or SR matrix) is developed and shown to outperform\nthe previous algorithm. Finally, various approaches to using the source/SR\nmodel are explored, and it is shown that source traces can be effectively\ncombined with other model-based methods like Dyna and experience replay.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 01:21:17 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Pitis", "Silviu", ""]]}, {"id": "1902.02935", "submitter": "Rodrigo Velez", "authors": "Rodrigo A. Velez", "title": "Expressive mechanisms for equitable rent division on a budget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the incentive properties of envy-free mechanisms for the allocation\nof rooms and payments of rent among financially constrained roommates. Each\nagent reports her values for rooms, her housing earmark (soft budget), and an\nindex that reflects the difficulty the agent experiences from having to pay\nover this amount. Then an envy-free allocation for these reports is\nrecommended. The complete information non-cooperative outcomes of each of these\nmechanisms are exactly the envy-free allocations with respect to true\npreferences if and only if the admissible budget violation indices have a\nbound.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 04:35:33 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:25:08 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 16:51:47 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Velez", "Rodrigo A.", ""]]}, {"id": "1902.03046", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (PSL, SIERRA), Dmitrii Ostrovskii (PSL, SIERRA),\n  Francis Bach (PSL, SIERRA), Alessandro Rudi (PSL, SIERRA)", "title": "Beyond Least-Squares: Fast Rates for Regularized Empirical Risk\n  Minimization through Self-Concordance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning methods based on the regularization of a convex\nempirical risk by a squared Hilbertian norm, a setting that includes linear\npredictors and non-linear predictors through positive-definite kernels. In\norder to go beyond the generic analysis leading to convergence rates of the\nexcess risk as $O(1/\\sqrt{n})$ from $n$ observations, we assume that the\nindividual losses are self-concordant, that is, their third-order derivatives\nare bounded by their second-order derivatives. This setting includes\nleast-squares, as well as all generalized linear models such as logistic and\nsoftmax regression. For this class of losses, we provide a bias-variance\ndecomposition and show that the assumptions commonly made in least-squares\nregression, such as the source and capacity conditions, can be adapted to\nobtain fast non-asymptotic rates of convergence by improving the bias terms,\nthe variance terms or both.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:18:05 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 13:37:59 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 14:40:41 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "PSL, SIERRA"], ["Ostrovskii", "Dmitrii", "", "PSL, SIERRA"], ["Bach", "Francis", "", "PSL, SIERRA"], ["Rudi", "Alessandro", "", "PSL, SIERRA"]]}, {"id": "1902.03092", "submitter": "Lin Xie", "authors": "Lin Xie, Nils Thieme, Ruslan Krenzler, Hanyi Li", "title": "Efficient order picking methods in robotic mobile fulfillment systems", "comments": null, "journal-ref": "European Journal of Operational Research 2021", "doi": "10.1016/j.ejor.2020.05.032", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic mobile fulfillment systems (RMFSs) are a new type of warehousing\nsystem, which has received more attention recently, due to increasing growth in\nthe e-commerce sector. Instead of sending pickers to the inventory area to\nsearch for and pick the ordered items, robots carry shelves (called \"pods\")\nincluding ordered items from the inventory area to picking stations. In the\npicking stations, human pickers put ordered items into totes; then these items\nare transported by a conveyor to the packing stations. This type of warehousing\nsystem relieves the human pickers and improves the picking process. In this\npaper, we concentrate on decisions about the assignment of pods to stations and\norders to stations to fulfill picking for each incoming customer's order. In\nprevious research for an RMFS with multiple picking stations, these decisions\nare made sequentially. Instead, we present a new integrated model. To improve\nthe system performance even more, we extend our model by splitting orders. This\nmeans parts of an order are allowed to be picked at different stations. To the\nbest of the authors' knowledge, this is the first publication on split orders\nin an RMFS. We analyze different performance metrics, such as pile-on,\npod-station visits, robot moving distance and order turn-over time. We compare\nthe results of our models in different instances with the sequential method in\nour open-source simulation framework RAWSim-O.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 22:26:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Xie", "Lin", ""], ["Thieme", "Nils", ""], ["Krenzler", "Ruslan", ""], ["Li", "Hanyi", ""]]}, {"id": "1902.03096", "submitter": "Maximilian K\\\"ohl", "authors": "Dimitri Bohlender, Maximilian A. K\\\"ohl", "title": "Towards a Characterization of Explainable Systems", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building software-driven systems that are easily understood becomes a\nchallenge, with their ever-increasing complexity and autonomy. Accordingly,\nrecent research efforts strive to aid in designing explainable systems.\nNevertheless, a common notion of what it takes for a system to be explainable\nis still missing. To address this problem, we propose a characterization of\nexplainable systems that consolidates existing research. By providing a unified\nterminology, we lay a basis for the classification of both existing and future\nresearch, and the formulation of precise requirements towards such systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 01:00:11 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Bohlender", "Dimitri", ""], ["K\u00f6hl", "Maximilian A.", ""]]}, {"id": "1902.03109", "submitter": "Mohamed-Hamza Ibrahim", "authors": "Mohamed-Hamza Ibrahim, Rokia Missaoui, Abir Messaoudi", "title": "Detecting Local Community Structures in Social Networks Using Concept\n  Interestingness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key challenge in Social Network Analysis is to design an efficient and\naccurate community detection procedure as a means to discover intrinsic\nstructures and extract relevant information. In this paper, we introduce a\nnovel strategy called (COIN), which exploits COncept INterestingness measures\nto detect communities based on the concept lattice construction of the network.\nThus, unlike off-the-shelf community detection algorithms, COIN leverages\nrelevant conceptual characteristics inherited from Formal Concept Analysis to\ndiscover substantial local structures. On the first stage of COIN, we extract\nthe formal concepts that capture all the cliques and bridges in the social\nnetwork. On the second stage, we use the stability index to remove noisy\nbridges between communities and then percolate relevant adjacent cliques. Our\nexperiments on several real-world social networks show that COIN can quickly\ndetect communities more accurately than existing prominent algorithms such as\nEdge betweenness, Fast greedy modularity, and Infomap.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 14:46:20 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Ibrahim", "Mohamed-Hamza", ""], ["Missaoui", "Rokia", ""], ["Messaoudi", "Abir", ""]]}, {"id": "1902.03127", "submitter": "Hossein Yazdani", "authors": "Hossein Yazdani", "title": "Bounded Fuzzy Possibilistic Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Bounded Fuzzy Possibilistic Method (BFPM) by addressing\nseveral issues that previous clustering/classification methods have not\nconsidered. In fuzzy clustering, object's membership values should sum to 1.\nHence, any object may obtain full membership in at most one cluster.\nPossibilistic clustering methods remove this restriction. However, BFPM differs\nfrom previous fuzzy and possibilistic clustering approaches by allowing the\nmembership function to take larger values with respect to all clusters.\nFurthermore, in BFPM, a data object can have full membership in multiple\nclusters or even in all clusters. BFPM relaxes the boundary conditions\n(restrictions) in membership assignment. The proposed methodology satisfies the\nnecessity of obtaining full memberships and overcomes the issues with\nconventional methods on dealing with overlapping. Analysing the objects'\nmovements from their own cluster to another (mutation) is also proposed in this\npaper. BFPM has been applied in different domains in geometry, set theory,\nanomaly detection, risk management, diagnosis diseases, and other disciplines.\nValidity and comparison indexes have been also used to evaluate the accuracy of\nBFPM. BFPM has been evaluated in terms of accuracy, fuzzification constant\n(different norms), objects' movement analysis, and covering diversity. The\npromising results prove the importance of considering the proposed methodology\nin learning methods to track the behaviour of data objects, in addition to\nobtain accurate results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 14:53:59 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Yazdani", "Hossein", ""]]}, {"id": "1902.03142", "submitter": "Ethan C Jackson", "authors": "Ethan C. Jackson and Mark Daley", "title": "Novelty Search for Deep Reinforcement Learning Policy Network Weights by\n  Action Sequence Edit Metric Distance", "comments": "Submitted to GECCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) problems often feature deceptive local optima,\nand learning methods that optimize purely for reward signal often fail to learn\nstrategies for overcoming them. Deep neuroevolution and novelty search have\nbeen proposed as effective alternatives to gradient-based methods for learning\nRL policies directly from pixels. In this paper, we introduce and evaluate the\nuse of novelty search over agent action sequences by string edit metric\ndistance as a means for promoting innovation. We also introduce a method for\nstagnation detection and population resampling inspired by recent developments\nin the RL community that uses the same mechanisms as novelty search to promote\nand develop innovative policies. Our methods extend a state-of-the-art method\nfor deep neuroevolution using a simple-yet-effective genetic algorithm (GA)\ndesigned to efficiently learn deep RL policy network weights. Experiments using\nfour games from the Atari 2600 benchmark were conducted. Results provide\nfurther evidence that GAs are competitive with gradient-based algorithms for\ndeep RL. Results also demonstrate that novelty search over action sequences is\nan effective source of selection pressure that can be integrated into existing\nevolutionary algorithms for deep RL.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 15:14:09 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Jackson", "Ethan C.", ""], ["Daley", "Mark", ""]]}, {"id": "1902.03155", "submitter": "Timo Nolle", "authors": "Timo Nolle and Stefan Luettgen and Alexander Seeliger and Max\n  M\\\"uhlh\\\"auser", "title": "BINet: Multi-perspective Business Process Anomaly Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.is.2019.101458", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce BINet, a neural network architecture for\nreal-time multi-perspective anomaly detection in business process event logs.\nBINet is designed to handle both the control flow and the data perspective of a\nbusiness process. Additionally, we propose a set of heuristics for setting the\nthreshold of an anomaly detection algorithm automatically. We demonstrate that\nBINet can be used to detect anomalies in event logs not only on a case level\nbut also on event attribute level. Finally, we demonstrate that a simple set of\nrules can be used to utilize the output of BINet for anomaly classification. We\ncompare BINet to eight other state-of-the-art anomaly detection algorithms and\nevaluate their performance on an elaborate data corpus of 29 synthetic and 15\nreal-life event logs. BINet outperforms all other methods both on the synthetic\nas well as on the real-life datasets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 15:48:29 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nolle", "Timo", ""], ["Luettgen", "Stefan", ""], ["Seeliger", "Alexander", ""], ["M\u00fchlh\u00e4user", "Max", ""]]}, {"id": "1902.03185", "submitter": "Nicolas Anastassacos", "authors": "Nicolas Anastassacos, Stephen Hailes, Mirco Musolesi", "title": "Partner Selection for the Emergence of Cooperation in Multi-Agent\n  Systems Using Reinforcement Learning", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social dilemmas have been widely studied to explain how humans are able to\ncooperate in society. Considerable effort has been invested in designing\nartificial agents for social dilemmas that incorporate explicit agent\nmotivations that are chosen to favor coordinated or cooperative responses. The\nprevalence of this general approach points towards the importance of achieving\nan understanding of both an agent's internal design and external environment\ndynamics that facilitate cooperative behavior. In this paper, we investigate\nhow partner selection can promote cooperative behavior between agents who are\ntrained to maximize a purely selfish objective function. Our experiments reveal\nthat agents trained with this dynamic learn a strategy that retaliates against\ndefectors while promoting cooperation with other agents resulting in a\nprosocial society.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:47:00 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 15:54:26 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 12:18:00 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 14:59:18 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Anastassacos", "Nicolas", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1902.03245", "submitter": "Chenhao Tan", "authors": "Brian Lubars and Chenhao Tan", "title": "Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of\n  Task Delegability", "comments": "19 pages, 3 figures, 5 tables, NeurIPS 2019, dataset available at\n  https://delegability.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While artificial intelligence (AI) holds promise for addressing societal\nchallenges, issues of exactly which tasks to automate and to what extent to do\nso remain understudied. We approach this problem of task delegability from a\nhuman-centered perspective by developing a framework on human perception of\ntask delegation to AI. We consider four high-level factors that can contribute\nto a delegation decision: motivation, difficulty, risk, and trust. To obtain an\nempirical understanding of human preferences in different tasks, we build a\ndataset of 100 tasks from academic papers, popular media portrayal of AI, and\neveryday life, and administer a survey based on our proposed framework. We find\nlittle preference for full AI control and a strong preference for\nmachine-in-the-loop designs, in which humans play the leading role. Among the\nfour factors, trust is the most correlated with human preferences of optimal\nhuman-machine delegation. This framework represents a first step towards\ncharacterizing human preferences of AI automation across tasks. We hope this\nwork encourages future efforts towards understanding such individual attitudes;\nour goal is to inform the public and the AI research community rather than\ndictating any direction in technology development.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:00:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 18:00:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lubars", "Brian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1902.03251", "submitter": "Ilya Feige", "authors": "Ilya Feige", "title": "Invariant-equivariant representation learning for multi-class data", "comments": "8 pages, 5 figures, 2 tables, 2 appendices", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations learnt through deep neural networks tend to be highly\ninformative, but opaque in terms of what information they learn to encode. We\nintroduce an approach to probabilistic modelling that learns to represent data\nwith two separate deep representations: an invariant representation that\nencodes the information of the class from which the data belongs, and an\nequivariant representation that encodes the symmetry transformation defining\nthe particular data point within the class manifold (equivariant in the sense\nthat the representation varies naturally with symmetry transformations). This\napproach is based primarily on the strategic routing of data through the two\nlatent variables, and thus is conceptually transparent, easy to implement, and\nin-principle generally applicable to any data comprised of discrete classes of\ncontinuous distributions (e.g. objects in images, topics in language,\nindividuals in behavioural data). We demonstrate qualitatively compelling\nrepresentation learning and competitive quantitative performance, in both\nsupervised and semi-supervised settings, versus comparable modelling approaches\nin the literature with little fine tuning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:01:13 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:03:14 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Feige", "Ilya", ""]]}, {"id": "1902.03264", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Jiahui Yu, Nebojsa Jojic, Jun Huan, Thomas S. Huang", "title": "FSNet: Compression of Deep Convolutional Neural Networks by Filter\n  Summary", "comments": "published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method of compression of deep Convolutional Neural\nNetworks (CNNs) by weight sharing through a new representation of convolutional\nfilters. The proposed method reduces the number of parameters of each\nconvolutional layer by learning a 1D vector termed Filter Summary (FS). The\nconvolutional filters are located in FS as overlapping 1D segments, and nearby\nfilters in FS share weights in their overlapping regions in a natural way. The\nresultant neural network based on such weight sharing scheme, termed Filter\nSummary CNNs or FSNet, has a FS in each convolution layer instead of a set of\nindependent filters in the conventional convolution layer. FSNet has the same\narchitecture as that of the baseline CNN to be compressed, and each convolution\nlayer of FSNet has the same number of filters from FS as that of the basline\nCNN in the forward process. With compelling computational acceleration ratio,\nthe parameter space of FSNet is much smaller than that of the baseline CNN. In\naddition, FSNet is quantization friendly. FSNet with weight quantization leads\nto even higher compression ratio without noticeable performance loss. We\nfurther propose Differentiable FSNet where the way filters share weights is\nlearned in a differentiable and end-to-end manner. Experiments demonstrate the\neffectiveness of FSNet in compression of CNNs for computer vision tasks\nincluding image classification and object detection, and the effectiveness of\nDFSNet is evidenced by the task of Neural Architecture Search.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:26:46 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 21:20:09 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 08:35:40 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Yang", "Yingzhen", ""], ["Yu", "Jiahui", ""], ["Jojic", "Nebojsa", ""], ["Huan", "Jun", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1902.03271", "submitter": "Supreeth Prajwal Shashikumar", "authors": "Russell Jeter, Christopher Josef, Supreeth Shashikumar and Shamim\n  Nemati", "title": "Does the \"Artificial Intelligence Clinician\" learn optimal treatment\n  strategies for sepsis in intensive care?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  From 2017 to 2018 the number of scientific publications found via PubMed\nsearch using the keyword \"Machine Learning\" increased by 46% (4,317 to 6,307).\nThe results of studies involving machine learning, artificial intelligence\n(AI), and big data have captured the attention of healthcare practitioners,\nhealthcare managers, and the public at a time when Western medicine grapples\nwith unmitigated cost increases and public demands for accountability. The\ncomplexity involved in healthcare applications of machine learning and the size\nof the associated data sets has afforded many researchers an uncontested\nopportunity to satisfy these demands with relatively little oversight. In a\nrecent Nature Medicine article, \"The Artificial Intelligence Clinician learns\noptimal treatment strategies for sepsis in intensive care,\" Komorowski and his\ncoauthors propose methods to train an artificial intelligence clinician to\ntreat sepsis patients with vasopressors and IV fluids. In this post, we will\nclosely examine the claims laid out in this paper. In particular, we will study\nthe individual treatment profiles suggested by their AI Clinician to gain\ninsight into how their AI Clinician intends to treat patients on an individual\nlevel.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:54:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Jeter", "Russell", ""], ["Josef", "Christopher", ""], ["Shashikumar", "Supreeth", ""], ["Nemati", "Shamim", ""]]}, {"id": "1902.03273", "submitter": "Nicolas Troquard", "authors": "Ana Ozaki and Nicolas Troquard", "title": "Learning Ontologies with Epistemic Reasoning: The EL Case", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning description logic ontologies from\nentailments via queries, using epistemic reasoning. We introduce a new learning\nmodel consisting of epistemic membership and example queries and show that\npolynomial learnability in this model coincides with polynomial learnability in\nAngluin's exact learning model with membership and equivalence queries. We then\ninstantiate our learning framework to EL and show some complexity results for\nan epistemic extension of EL where epistemic operators can be applied over the\naxioms. Finally, we transfer known results for EL ontologies and its fragments\nto our learning model based on epistemic reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 20:06:36 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Ozaki", "Ana", ""], ["Troquard", "Nicolas", ""]]}, {"id": "1902.03334", "submitter": "Tomas Hodan", "authors": "Tomas Hodan, Vibhav Vineet, Ran Gal, Emanuel Shalev, Jon Hanzelka,\n  Treb Connell, Pedro Urbina, Sudipta N. Sinha, Brian Guenter", "title": "Photorealistic Image Synthesis for Object Instance Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to synthesize highly photorealistic images of 3D\nobject models, which we use to train a convolutional neural network for\ndetecting the objects in real images. The proposed approach has three key\ningredients: (1) 3D object models are rendered in 3D models of complete scenes\nwith realistic materials and lighting, (2) plausible geometric configuration of\nobjects and cameras in a scene is generated using physics simulations, and (3)\nhigh photorealism of the synthesized images achieved by physically based\nrendering. When trained on images synthesized by the proposed approach, the\nFaster R-CNN object detector achieves a 24% absolute improvement of mAP@.75IoU\non Rutgers APC and 11% on LineMod-Occluded datasets, compared to a baseline\nwhere the training images are synthesized by rendering object models on top of\nrandom photographs. This work is a step towards being able to effectively train\nobject detectors without capturing or annotating any real images. A dataset of\n600K synthetic images with ground truth annotations for various computer vision\ntasks will be released on the project website: thodan.github.io/objectsynth.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 00:14:46 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Hodan", "Tomas", ""], ["Vineet", "Vibhav", ""], ["Gal", "Ran", ""], ["Shalev", "Emanuel", ""], ["Hanzelka", "Jon", ""], ["Connell", "Treb", ""], ["Urbina", "Pedro", ""], ["Sinha", "Sudipta N.", ""], ["Guenter", "Brian", ""]]}, {"id": "1902.03376", "submitter": "Yu Cheng", "authors": "Zihao Zhu, Changchang Yin, Buyue Qian, Yu Cheng, Jishang Wei, Fei Wang", "title": "Measuring Patient Similarities via a Deep Architecture with Medical\n  Concept Embedding", "comments": "Published in ICDM 2016, arXiv version. Code link is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the clinical similarities between pairwise patients is a\nfundamental problem in healthcare informatics. A proper patient similarity\nmeasure enables various downstream applications, such as cohort study and\ntreatment comparative effectiveness research. One major carrier for conducting\npatient similarity research is Electronic Health Records(EHRs), which are\nusually heterogeneous, longitudinal, and sparse. Though existing studies on\nlearning patient similarity from EHRs have shown being useful in solving real\nclinical problems, their applicability is limited due to the lack of medical\ninterpretations. Moreover, most previous methods assume a vector-based\nrepresentation for patients, which typically requires aggregation of medical\nevents over a certain time period. As a consequence, temporal information will\nbe lost. In this paper, we propose a patient similarity evaluation framework\nbased on the temporal matching of longitudinal patient EHRs. Two efficient\nmethods are presented, unsupervised and supervised, both of which preserve the\ntemporal properties in EHRs. The supervised scheme takes a convolutional neural\nnetwork architecture and learns an optimal representation of patient clinical\nrecords with medical concept embedding. The empirical results on real-world\nclinical data demonstrate substantial improvement over the baselines. We make\nour code and sample data available for further study.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 05:36:18 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Zhu", "Zihao", ""], ["Yin", "Changchang", ""], ["Qian", "Buyue", ""], ["Cheng", "Yu", ""], ["Wei", "Jishang", ""], ["Wang", "Fei", ""]]}, {"id": "1902.03380", "submitter": "C. H. Huck Yang", "authors": "Chao-Han Huck Yang, Yi-Chieh Liu, Pin-Yu Chen, Xiaoli Ma, Yi-Chang\n  James Tsai", "title": "When Causal Intervention Meets Adversarial Examples and Image Masking\n  for Deep Neural Networks", "comments": "Noted our camera-ready version has changed the title. \"When Causal\n  Intervention Meets Adversarial Examples and Image Masking for Deep Neural\n  Networks\" as the v3 official paper title in IEEE Proceeding. Please use it in\n  your formal reference. Accepted at IEEE ICIP 2019. Pytorch code has released\n  on https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg", "journal-ref": "2019 26th IEEE International Conference on Image Processing\n  (ICIP). IEEE", "doi": null, "report-no": "pages={3811--3815}", "categories": "cs.CV cs.AI cs.LG cs.SC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Discovering and exploiting the causality in deep neural networks (DNNs) are\ncrucial challenges for understanding and reasoning causal effects (CE) on an\nexplainable visual model. \"Intervention\" has been widely used for recognizing a\ncausal relation ontologically. In this paper, we propose a causal inference\nframework for visual reasoning via do-calculus. To study the intervention\neffects on pixel-level features for causal reasoning, we introduce pixel-wise\nmasking and adversarial perturbation. In our framework, CE is calculated using\nfeatures in a latent space and perturbed prediction from a DNN-based model. We\nfurther provide the first look into the characteristics of discovered CE of\nadversarially perturbed images generated by gradient-based methods\n\\footnote{~~https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg}.\nExperimental results show that CE is a competitive and robust index for\nunderstanding DNNs when compared with conventional methods such as\nclass-activation mappings (CAMs) on the Chest X-Ray-14 dataset for\nhuman-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds\npromises for detecting adversarial examples as it possesses distinct\ncharacteristics in the presence of adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 06:44:13 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 19:11:24 GMT"}, {"version": "v3", "created": "Tue, 25 Jun 2019 15:07:42 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Liu", "Yi-Chieh", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Tsai", "Yi-Chang James", ""]]}, {"id": "1902.03389", "submitter": "Yuki Saito", "authors": "Hiroki Tamaru, Yuki Saito, Shinnosuke Takamichi, Tomoki Koriyama,\n  Hiroshi Saruwatari", "title": "Generative Moment Matching Network-based Random Modulation Post-filter\n  for DNN-based Singing Voice Synthesis and Neural Double-tracking", "comments": "5 pages, to appear in IEEE ICASSP 2019 (Paper Code: SLP-P22.11,\n  Session: Speech Synthesis III)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.MM cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generative moment matching network (GMMN)-based\npost-filter that provides inter-utterance pitch variation for deep neural\nnetwork (DNN)-based singing voice synthesis. The natural pitch variation of a\nhuman singing voice leads to a richer musical experience and is used in\ndouble-tracking, a recording method in which two performances of the same\nphrase are recorded and mixed to create a richer, layered sound. However,\nsinging voices synthesized using conventional DNN-based methods never vary\nbecause the synthesis process is deterministic and only one waveform is\nsynthesized from one musical score. To address this problem, we use a GMMN to\nmodel the variation of the modulation spectrum of the pitch contour of natural\nsinging voices and add a randomized inter-utterance variation to the pitch\ncontour generated by conventional DNN-based singing voice synthesis.\nExperimental evaluations suggest that 1) our approach can provide perceptible\ninter-utterance pitch variation while preserving speech quality. We extend our\napproach to double-tracking, and the evaluation demonstrates that 2) GMMN-based\nneural double-tracking is perceptually closer to natural double-tracking than\nconventional signal processing-based artificial double-tracking is.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 07:49:42 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Tamaru", "Hiroki", ""], ["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Koriyama", "Tomoki", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1902.03393", "submitter": "Mehrdad Farajtabar", "authors": "Seyed-Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro\n  Matsukawa, Hassan Ghasemzadeh", "title": "Improved Knowledge Distillation via Teacher Assistant", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that deep neural networks are powerful models and achieve\nappealing results on many tasks, they are too large to be deployed on edge\ndevices like smartphones or embedded sensor nodes. There have been efforts to\ncompress these networks, and a popular method is knowledge distillation, where\na large (teacher) pre-trained network is used to train a smaller (student)\nnetwork. However, in this paper, we show that the student network performance\ndegrades when the gap between student and teacher is large. Given a fixed\nstudent network, one cannot employ an arbitrarily large teacher, or in other\nwords, a teacher can effectively transfer its knowledge to students up to a\ncertain size, not smaller. To alleviate this shortcoming, we introduce\nmulti-step knowledge distillation, which employs an intermediate-sized network\n(teacher assistant) to bridge the gap between the student and the teacher.\nMoreover, we study the effect of teacher assistant size and extend the\nframework to multi-step distillation. Theoretical analysis and extensive\nexperiments on CIFAR-10,100 and ImageNet datasets and on CNN and ResNet\narchitectures substantiate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 09:06:01 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 01:11:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mirzadeh", "Seyed-Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Li", "Ang", ""], ["Levine", "Nir", ""], ["Matsukawa", "Akihiro", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1902.03440", "submitter": "James Tan", "authors": "James P.L. Tan", "title": "Simulating extrapolated dynamics with parameterization networks", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An artificial neural network architecture, parameterization networks, is\nproposed for simulating extrapolated dynamics beyond observed data in dynamical\nsystems. Parameterization networks are used to ensure the long term integrity\nof extrapolated dynamics, while careful tuning of model hyperparameters against\nvalidation errors controls overfitting. A parameterization network is\ndemonstrated on the logistic map, where chaos and other nonlinear phenomena\nconsistent with the underlying model can be extrapolated from non-chaotic\ntraining time series with good fidelity. The stated results are a lot less\nfantastical than they appear to be because the neural network is only\nextrapolating between quadratic return maps. Nonetheless, the results do\nsuggest that successful extrapolation of qualitatively different behaviors\nrequires learning to occur on a level of abstraction where the corresponding\nbehaviors are more similar in nature.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 16:37:34 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Tan", "James P. L.", ""]]}, {"id": "1902.03442", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, Pavel Krizek, David Hurych, Ibrahim Sobh, Senthil\n  Yogamani and Patrick Denny", "title": "Yes, we GAN: Applying Adversarial Techniques for Autonomous Driving", "comments": "Accepted for publication in Electronic Imaging, Autonomous Vehicles\n  and Machines 2019. arXiv admin note: text overlap with arXiv:1606.05908 by\n  other authors", "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2019.15.AVM-048", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have gained a lot of popularity from\ntheir introduction in 2014 till present. Research on GAN is rapidly growing and\nthere are many variants of the original GAN focusing on various aspects of deep\nlearning. GAN are perceived as the most impactful direction of machine learning\nin the last decade. This paper focuses on the application of GAN in autonomous\ndriving including topics such as advanced data augmentation, loss function\nlearning, semi-supervised learning, etc. We formalize and review key\napplications of adversarial techniques and discuss challenges and open problems\nto be addressed.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 16:42:47 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 18:22:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Uricar", "Michal", ""], ["Krizek", "Pavel", ""], ["Hurych", "David", ""], ["Sobh", "Ibrahim", ""], ["Yogamani", "Senthil", ""], ["Denny", "Patrick", ""]]}, {"id": "1902.03451", "submitter": "Adnane Boukhayma", "authors": "Adnane Boukhayma, Rodrigo de Bem, Philip H.S. Torr", "title": "3D Hand Shape and Pose from Images in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this work the first end-to-end deep learning based method that\npredicts both 3D hand shape and pose from RGB images in the wild. Our network\nconsists of the concatenation of a deep convolutional encoder, and a fixed\nmodel-based decoder. Given an input image, and optionally 2D joint detections\nobtained from an independent CNN, the encoder predicts a set of hand and view\nparameters. The decoder has two components: A pre-computed articulated mesh\ndeformation hand model that generates a 3D mesh from the hand parameters, and a\nre-projection module controlled by the view parameters that projects the\ngenerated hand into the image domain. We show that using the shape and pose\nprior knowledge encoded in the hand model within a deep learning framework\nyields state-of-the-art performance in 3D pose prediction from images on\nstandard benchmarks, and produces geometrically valid and plausible 3D\nreconstructions. Additionally, we show that training with weak supervision in\nthe form of 2D joint annotations on datasets of images in the wild, in\nconjunction with full supervision in the form of 3D joint annotations on\nlimited available datasets allows for good generalization to 3D shape and pose\npredictions on images in the wild.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 17:30:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Boukhayma", "Adnane", ""], ["de Bem", "Rodrigo", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1902.03477", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Ruslan Salakhutdinov, Joshua B. Tenenbaum", "title": "The Omniglot challenge: a 3-year progress report", "comments": "In press at Current Opinion in Behavioral Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three years ago, we released the Omniglot dataset for one-shot learning,\nalong with five challenge tasks and a computational model that addresses these\ntasks. The model was not meant to be the final word on Omniglot; we hoped that\nthe community would build on our work and develop new approaches. In the time\nsince, we have been pleased to see wide adoption of the dataset. There has been\nnotable progress on one-shot classification, but researchers have adopted new\nsplits and procedures that make the task easier. There has been less progress\non the other four tasks. We conclude that recent approaches are still far from\nhuman-like concept learning on Omniglot, a challenge that requires performing\nmany tasks with a single model.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 19:13:31 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 20:01:27 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Lake", "Brenden M.", ""], ["Salakhutdinov", "Ruslan", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1902.03545", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran,\n  Subhransu Maji, Charless Fowlkes, Stefano Soatto, Pietro Perona", "title": "Task2Vec: Task Embedding for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to provide vectorial representations of visual\nclassification tasks which can be used to reason about the nature of those\ntasks and their relations. Given a dataset with ground-truth labels and a loss\nfunction defined over those labels, we process images through a \"probe network\"\nand compute an embedding based on estimates of the Fisher information matrix\nassociated with the probe network parameters. This provides a fixed-dimensional\nembedding of the task that is independent of details such as the number of\nclasses and does not require any understanding of the class label semantics. We\ndemonstrate that this embedding is capable of predicting task similarities that\nmatch our intuition about semantic and taxonomic relations between different\nvisual tasks (e.g., tasks based on classifying different types of plants are\nsimilar) We also demonstrate the practical value of this framework for the\nmeta-task of selecting a pre-trained feature extractor for a new task. We\npresent a simple meta-learning framework for learning a metric on embeddings\nthat is capable of predicting which feature extractors will perform well.\nSelecting a feature extractor with task embedding obtains a performance close\nto the best available feature extractor, while costing substantially less than\nexhaustively training and evaluating on all available feature extractors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 06:27:25 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Achille", "Alessandro", ""], ["Lam", "Michael", ""], ["Tewari", "Rahul", ""], ["Ravichandran", "Avinash", ""], ["Maji", "Subhransu", ""], ["Fowlkes", "Charless", ""], ["Soatto", "Stefano", ""], ["Perona", "Pietro", ""]]}, {"id": "1902.03570", "submitter": "Deshraj Yadav", "authors": "Deshraj Yadav, Rishabh Jain, Harsh Agrawal, Prithvijit Chattopadhyay,\n  Taranjeet Singh, Akash Jain, Shiv Baran Singh, Stefan Lee, Dhruv Batra", "title": "EvalAI: Towards Better Evaluation Systems for AI Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EvalAI, an open source platform for evaluating and comparing\nmachine learning (ML) and artificial intelligence algorithms (AI) at scale.\nEvalAI is built to provide a scalable solution to the research community to\nfulfill the critical need of evaluating machine learning models and agents\nacting in an environment against annotations or with a human-in-the-loop. This\nwill help researchers, students, and data scientists to create, collaborate,\nand participate in AI challenges organized around the globe. By simplifying and\nstandardizing the process of benchmarking these models, EvalAI seeks to lower\nthe barrier to entry for participating in the global scientific effort to push\nthe frontiers of machine learning and artificial intelligence, thereby\nincreasing the rate of measurable progress in this domain.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 10:34:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Yadav", "Deshraj", ""], ["Jain", "Rishabh", ""], ["Agrawal", "Harsh", ""], ["Chattopadhyay", "Prithvijit", ""], ["Singh", "Taranjeet", ""], ["Jain", "Akash", ""], ["Singh", "Shiv Baran", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1902.03588", "submitter": "Stavros Gerakaris", "authors": "Stavros Gerakaris and Subramanian Ramamoorthy", "title": "Learning Best Response Strategies for Agents in Ad Exchanges", "comments": null, "journal-ref": "EUMAS 2018, LNAI 11450, pp. 1-17, 2019", "doi": "10.1007/978-3-030-14174-5_6", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ad exchanges are widely used in platforms for online display advertising.\nAutonomous agents operating in these exchanges must learn policies for\ninteracting profitably with a diverse, continually changing, but unknown\nmarket. We consider this problem from the perspective of a publisher,\nstrategically interacting with an advertiser through a posted price mechanism.\nThe learning problem for this agent is made difficult by the fact that\ninformation is censored, i.e., the publisher knows if an impression is sold but\nno other quantitative information. We address this problem using the\nHarsanyi-Bellman Ad Hoc Coordination (HBA) algorithm, which conceptualises this\ninteraction in terms of a Stochastic Bayesian Game and arrives at optimal\nactions by best responding with respect to probabilistic beliefs maintained\nover a candidate set of opponent behaviour profiles. We adapt and apply HBA to\nthe censored information setting of ad exchanges. Also, addressing the case of\nstochastic opponents, we devise a strategy based on a Kaplan-Meier estimator\nfor opponent modelling. We evaluate the proposed method using simulations\nwherein we show that HBA-KM achieves substantially better competitive ratio and\nlower variance of return than baselines, including a Q-learning agent and a\nUCB-based online learning agent, and comparable to the offline optimal\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 12:44:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Gerakaris", "Stavros", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1902.03731", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, Cass R. Sunstein", "title": "Discrimination in the Age of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The law forbids discrimination. But the ambiguity of human decision-making\noften makes it extraordinarily hard for the legal system to know whether anyone\nhas actually discriminated. To understand how algorithms affect discrimination,\nwe must therefore also understand how they affect the problem of detecting\ndiscrimination. By one measure, algorithms are fundamentally opaque, not just\ncognitively but even mathematically. Yet for the task of proving\ndiscrimination, processes involving algorithms can provide crucial forms of\ntransparency that are otherwise unavailable. These benefits do not happen\nautomatically. But with appropriate requirements in place, the use of\nalgorithms will make it possible to more easily examine and interrogate the\nentire decision process, thereby making it far easier to know whether\ndiscrimination has occurred. By forcing a new level of specificity, the use of\nalgorithms also highlights, and makes transparent, central tradeoffs among\ncompeting values. Algorithms are not only a threat to be regulated; with the\nright safeguards in place, they have the potential to be a positive force for\nequity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 04:58:11 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kleinberg", "Jon", ""], ["Ludwig", "Jens", ""], ["Mullainathan", "Sendhil", ""], ["Sunstein", "Cass R.", ""]]}, {"id": "1902.03765", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Latent Space Reinforcement Learning for Steering Angle Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning has recently been shown to successfully\nlearn navigation policies from raw sensor data. In this work, we address the\nproblem of learning driving policies for an autonomous agent in a high-fidelity\nsimulator. Building upon recent research that applies deep reinforcement\nlearning to navigation problems, we present a modular deep reinforcement\nlearning approach to predict the steering angle of the car from raw images. The\nfirst module extracts a low-dimensional latent semantic representation of the\nimage. The control module trained with reinforcement learning takes the latent\nvector as input to predict the correct steering angle. The experimental results\nhave showed that our method is capable of learning to maneuver the car without\nany human control signals.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 08:14:34 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.03777", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Semantic Label Reduction Techniques for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation maps can be used as input to models for maneuvering the\ncontrols of a car. However, not all labels may be necessary for making the\ncontrol decision. One would expect that certain labels such as road lanes or\nsidewalks would be more critical in comparison with labels for vegetation or\nbuildings which may not have a direct influence on the car's driving decision.\nIn this appendix, we evaluate and quantify how sensitive and important the\ndifferent semantic labels are for controlling the car. Labels that do not\ninfluence the driving decision are remapped to other classes, thereby\nsimplifying the task by reducing to only labels critical for driving of the\nvehicle.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 08:38:26 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.03833", "submitter": "Ga\\\"el Beck", "authors": "Ga\\\"el Beck, Tarn Duong, Mustapha Lebbah, Hanane Azzag, Christophe\n  C\\'erin", "title": "A Distributed and Approximated Nearest Neighbors Algorithm for an\n  Efficient Large Scale Mean Shift Clustering", "comments": "Algorithms are available at\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we target the class of modal clustering methods where clusters\nare defined in terms of the local modes of the probability density function\nwhich generates the data. The most well-known modal clustering method is the\nk-means clustering. Mean Shift clustering is a generalization of the k-means\nclustering which computes arbitrarily shaped clusters as defined as the basins\nof attraction to the local modes created by the density gradient ascent paths.\nDespite its potential, the Mean Shift approach is a computationally expensive\nmethod for unsupervised learning. Thus, we introduce two contributions aiming\nto provide clustering algorithms with a linear time complexity, as opposed to\nthe quadratic time complexity for the exact Mean Shift clustering. Firstly we\npropose a scalable procedure to approximate the density gradient ascent.\nSecond, our proposed scalable cluster labeling technique is presented. Both\npropositions are based on Locality Sensitive Hashing (LSH) to approximate\nnearest neighbors. These two techniques may be used for moderate sized\ndatasets. Furthermore, we show that using our proposed approximations of the\ndensity gradient ascent as a pre-processing step in other clustering methods\ncan also improve dedicated classification metrics. For the latter, a\ndistributed implementation, written for the Spark/Scala ecosystem is proposed.\nFor all these considered clustering methods, we present experimental results\nillustrating their labeling accuracy and their potential to solve concrete\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 12:00:06 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Beck", "Ga\u00ebl", ""], ["Duong", "Tarn", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["C\u00e9rin", "Christophe", ""]]}, {"id": "1902.03930", "submitter": "Michael Saint-Guillain", "authors": "Michael Saint-Guillain, Christine Solnon, Yves Deville", "title": "Progressive Focus Search for the Static and Stochastic VRPTW with both\n  Random Customers and Reveal Times", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.03151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static stochastic VRPs aim at modeling real-life VRPs by considering\nuncertainty on data. In particular, the SS-VRPTW-CR considers stochastic\ncustomers with time windows and does not make any assumption on their reveal\ntimes, which are stochastic as well. Based on customer request probabilities,\nwe look for an a priori solution composed preventive vehicle routes, minimizing\nthe expected number of unsatisfied customer requests at the end of the day. A\nroute describes a sequence of strategic vehicle relocations, from which nearby\nrequests can be rapidly reached. Instead of reoptimizing online, a so-called\nrecourse strategy defines the way the requests are handled, whenever they\nappear. In this paper, we describe a new recourse strategy for the SS-VRPTW-CR,\nimproving vehicle routes by skipping useless parts. We show how to compute the\nexpected cost of a priori solutions, in pseudo-polynomial time, for this\nrecourse strategy. We introduce a new meta-heuristic, called Progressive Focus\nSearch (PFS), which may be combined with any local-search based algorithm for\nsolving static stochastic optimization problems. PFS accelerates the search by\nusing approximation factors: from an initial rough simplified problem, the\nsearch progressively focuses to the actual problem description. We evaluate our\ncontributions on a new, real-world based, public benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 12:48:32 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Saint-Guillain", "Michael", ""], ["Solnon", "Christine", ""], ["Deville", "Yves", ""]]}, {"id": "1902.03932", "submitter": "Andrew Wilson", "authors": "Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, Andrew Gordon\n  Wilson", "title": "Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posteriors over neural network weights are high dimensional and\nmultimodal. Each mode typically characterizes a meaningfully different\nrepresentation of the data. We develop Cyclical Stochastic Gradient MCMC\n(SG-MCMC) to automatically explore such distributions. In particular, we\npropose a cyclical stepsize schedule, where larger steps discover new modes,\nand smaller steps characterize each mode. We also prove non-asymptotic\nconvergence of our proposed algorithm. Moreover, we provide extensive\nexperimental results, including ImageNet, to demonstrate the scalability and\neffectiveness of cyclical SG-MCMC in learning complex multimodal distributions,\nespecially for fully Bayesian inference with modern deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:03:30 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 20:49:28 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Zhang", "Ruqi", ""], ["Li", "Chunyuan", ""], ["Zhang", "Jianyi", ""], ["Chen", "Changyou", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1902.03984", "submitter": "Thanh-Tung Hoang", "authors": "Hoang Thanh-Tung, Truyen Tran, Svetha Venkatesh", "title": "Improving Generalization and Stability of Generative Adversarial\n  Networks", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are one of the most popular tools for\nlearning complex high dimensional distributions. However, generalization\nproperties of GANs have not been well understood. In this paper, we analyze the\ngeneralization of GANs in practical settings. We show that discriminators\ntrained on discrete datasets with the original GAN loss have poor\ngeneralization capability and do not approximate the theoretically optimal\ndiscriminator. We propose a zero-centered gradient penalty for improving the\ngeneralization of the discriminator by pushing it toward the optimal\ndiscriminator. The penalty guarantees the generalization and convergence of\nGANs. Experiments on synthetic and large scale datasets verify our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:44:16 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Thanh-Tung", "Hoang", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1902.04147", "submitter": "C. H. Huck Yang", "authors": "Yi-Chieh Liu, Hao-Hsiang Yang, Chao-Han Huck Yang, Jia-Hong Huang,\n  Meng Tian, Hiromasa Morikawa, Yi-Chang James Tsai, Jesper Tegner", "title": "Synthesizing New Retinal Symptom Images by Multiple Generative Models", "comments": null, "journal-ref": "AI for Retinal Image Analysis Workshop ACCV 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Age-Related Macular Degeneration (AMD) is an asymptomatic retinal disease\nwhich may result in loss of vision. There is limited access to high-quality\nrelevant retinal images and poor understanding of the features defining\nsub-classes of this disease. Motivated by recent advances in machine learning\nwe specifically explore the potential of generative modeling, using Generative\nAdversarial Networks (GANs) and style transferring, to facilitate clinical\ndiagnosis and disease understanding by feature extraction. We design an\nanalytic pipeline which first generates synthetic retinal images from clinical\nimages; a subsequent verification step is applied. In the synthesizing step we\nmerge GANs (DCGANs and WGANs architectures) and style transferring for the\nimage generation, whereas the verified step controls the accuracy of the\ngenerated images. We find that the generated images contain sufficient\npathological details to facilitate ophthalmologists' task of disease\nclassification and in discovery of disease relevant features. In particular,\nour system predicts the drusen and geographic atrophy sub-classes of AMD.\nFurthermore, the performance using CFP images for GANs outperforms the\nclassification based on using only the original clinical dataset. Our results\nare evaluated using existing classifier of retinal diseases and class activated\nmaps, supporting the predictive power of the synthetic images and their utility\nfor feature extraction. Our code examples are available online.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 21:07:14 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Liu", "Yi-Chieh", ""], ["Yang", "Hao-Hsiang", ""], ["Yang", "Chao-Han Huck", ""], ["Huang", "Jia-Hong", ""], ["Tian", "Meng", ""], ["Morikawa", "Hiromasa", ""], ["Tsai", "Yi-Chang James", ""], ["Tegner", "Jesper", ""]]}, {"id": "1902.04178", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang, Clement H. C. Leung, and Vienne W. K. Sung", "title": "Stochastic Reinforcement Learning", "comments": "AIKE 2018", "journal-ref": null, "doi": "10.1109/AIKE.2018.00055", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning episodes, the rewards and punishments are often\nnon-deterministic, and there are invariably stochastic elements governing the\nunderlying situation. Such stochastic elements are often numerous and cannot be\nknown in advance, and they have a tendency to obscure the underlying rewards\nand punishments patterns. Indeed, if stochastic elements were absent, the same\noutcome would occur every time and the learning problems involved could be\ngreatly simplified. In addition, in most practical situations, the cost of an\nobservation to receive either a reward or punishment can be significant, and\none would wish to arrive at the correct learning conclusion by incurring\nminimum cost. In this paper, we present a stochastic approach to reinforcement\nlearning which explicitly models the variability present in the learning\nenvironment and the cost of observation. Criteria and rules for learning\nsuccess are quantitatively analyzed, and probabilities of exceeding the\nobservation cost bounds are also obtained.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:13:32 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""], ["Sung", "Vienne W. K.", ""]]}, {"id": "1902.04179", "submitter": "Nikki Lijing Kuang", "authors": "Nikki Lijing Kuang, Clement H. C. Leung", "title": "Performance Dynamics and Termination Errors in Reinforcement Learning: A\n  Unifying Perspective", "comments": "Short Paper in AIKE 2018", "journal-ref": null, "doi": "10.1109/AIKE.2018.00028", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, a decision needs to be made at some point as to\nwhether it is worthwhile to carry on with the learning process or to terminate\nit. In many such situations, stochastic elements are often present which govern\nthe occurrence of rewards, with the sequential occurrences of positive rewards\nrandomly interleaved with negative rewards. For most practical learners, the\nlearning is considered useful if the number of positive rewards always exceeds\nthe negative ones. A situation that often calls for learning termination is\nwhen the number of negative rewards exceeds the number of positive rewards.\nHowever, while this seems reasonable, the error of premature termination,\nwhereby termination is enacted along with the conclusion of learning failure\ndespite the positive rewards eventually far outnumber the negative ones, can be\nsignificant. In this paper, using combinatorial analysis we study the error\nprobability in wrongly terminating a reinforcement learning activity which\nundermines the effectiveness of an optimal policy, and we show that the\nresultant error can be quite high. Whilst we demonstrate mathematically that\nsuch errors can never be eliminated, we propose some practical mechanisms that\ncan effectively reduce such errors. Simulation experiments have been carried\nout, the results of which are in close agreement with our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:13:50 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kuang", "Nikki Lijing", ""], ["Leung", "Clement H. C.", ""]]}, {"id": "1902.04181", "submitter": "Ga\\\"el Beck", "authors": "Ga\\\"el Beck, Tarn Duong, Mustapha Lebbah, Hanane Azzag", "title": "Nearest Neighbor Median Shift Clustering for Binary Data", "comments": "Algorithms are available at\n  https://github.com/Clustering4Ever/Clustering4Ever", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe in this paper the theory and practice behind a new modal\nclustering method for binary data. Our approach (BinNNMS) is based on the\nnearest neighbor median shift. The median shift is an extension of the\nwell-known mean shift, which was designed for continuous data, to handle binary\ndata. We demonstrate that BinNNMS can discover accurately the location of\nclusters in binary data with theoretical and experimental analyses.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:34:21 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Beck", "Ga\u00ebl", ""], ["Duong", "Tarn", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""]]}, {"id": "1902.04186", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai and Bamdev Mishra", "title": "Riemannian joint dimensionality reduction and dictionary learning on\n  symmetric positive definite manifold", "comments": "European Signal Processing Conference (EUSIPCO 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary leaning (DL) and dimensionality reduction (DR) are powerful tools\nto analyze high-dimensional noisy signals. This paper presents a proposal of a\nnovel Riemannian joint dimensionality reduction and dictionary learning\n(R-JDRDL) on symmetric positive definite (SPD) manifolds for classification\ntasks. The joint learning considers the interaction between dimensionality\nreduction and dictionary learning procedures by connecting them into a unified\nframework. We exploit a Riemannian optimization framework for solving DL and DR\nproblems jointly. Finally, we demonstrate that the proposed R-JDRDL outperforms\nexisting state-of-the-arts algorithms when used for image classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:49:03 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1902.04187", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Michael I. Jordan", "title": "LS-Tree: Model Interpretation When the Data Are Linguistic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of interpreting trained classification models in the\nsetting of linguistic data sets. Leveraging a parse tree, we propose to assign\nleast-squares based importance scores to each word of an instance by exploiting\nsyntactic constituency structure. We establish an axiomatic characterization of\nthese importance scores by relating them to the Banzhaf value in coalitional\ngame theory. Based on these importance scores, we develop a principled method\nfor detecting and quantifying interactions between words in a sentence. We\ndemonstrate that the proposed method can aid in interpretability and\ndiagnostics for several widely-used language models.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 23:58:22 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chen", "Jianbo", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1902.04198", "submitter": "Rohin Shah", "authors": "Rohin Shah, Dmitrii Krasheninnikov, Jordan Alexander, Pieter Abbeel,\n  Anca Dragan", "title": "Preferences Implicit in the State of the World", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents optimize only the features specified in a\nreward function and are indifferent to anything left out inadvertently. This\nmeans that we must not only specify what to do, but also the much larger space\nof what not to do. It is easy to forget these preferences, since these\npreferences are already satisfied in our environment. This motivates our key\ninsight: when a robot is deployed in an environment that humans act in, the\nstate of the environment is already optimized for what humans want. We can\ntherefore use this implicit preference information from the state to fill in\nthe blanks. We develop an algorithm based on Maximum Causal Entropy IRL and use\nit to evaluate the idea in a suite of proof-of-concept environments designed to\nshow its properties. We find that information from the initial state can be\nused to infer both side effects that should be avoided as well as preferences\nfor how the environment should be organized. Our code can be found at\nhttps://github.com/HumanCompatibleAI/rlsp.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 00:50:56 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 22:15:37 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Shah", "Rohin", ""], ["Krasheninnikov", "Dmitrii", ""], ["Alexander", "Jordan", ""], ["Abbeel", "Pieter", ""], ["Dragan", "Anca", ""]]}, {"id": "1902.04208", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Xiang Kong, Shanghang Zhang, Eduard Hovy", "title": "MaCow: Masked Convolutional Generative Flow", "comments": "In Proceedings of Thirty-third Conference on Neural Information\n  Processing Systems (NeurIPS-2019)", "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models, conceptually attractive due to tractability of\nboth the exact log-likelihood computation and latent-variable inference, and\nefficiency of both training and sampling, has led to a number of impressive\nempirical successes and spawned many advanced variants and theoretical\ninvestigations. Despite their computational efficiency, the density estimation\nperformance of flow-based generative models significantly falls behind those of\nstate-of-the-art autoregressive models. In this work, we introduce masked\nconvolutional generative flow (MaCow), a simple yet effective architecture of\ngenerative flow using masked convolution. By restricting the local connectivity\nin a small kernel, MaCow enjoys the properties of fast and stable training, and\nefficient sampling, while achieving significant improvements over Glow for\ndensity estimation on standard image benchmarks, considerably narrowing the gap\nto autoregressive models.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:31:06 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 18:34:51 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 18:46:40 GMT"}, {"version": "v4", "created": "Sat, 15 Jun 2019 15:33:07 GMT"}, {"version": "v5", "created": "Sun, 27 Oct 2019 00:45:11 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ma", "Xuezhe", ""], ["Kong", "Xiang", ""], ["Zhang", "Shanghang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1902.04228", "submitter": "Majid Abdolshah", "authors": "Majid Abdolshah, Alistair Shilton, Santu Rana, Sunil Gupta, Svetha\n  Venkatesh", "title": "Multi-objective Bayesian optimisation with preferences over objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-objective Bayesian optimisation algorithm that allows the\nuser to express preference-order constraints on the objectives of the type\n\"objective A is more important than objective B\". These preferences are defined\nbased on the stability of the obtained solutions with respect to preferred\nobjective functions. Rather than attempting to find a representative subset of\nthe complete Pareto front, our algorithm selects those Pareto-optimal points\nthat satisfy these constraints. We formulate a new acquisition function based\non expected improvement in dominated hypervolume (EHI) to ensure that the\nsubset of Pareto front satisfying the constraints is thoroughly explored. The\nhypervolume calculation is weighted by the probability of a point satisfying\nthe constraints from a gradient Gaussian Process model. We demonstrate our\nalgorithm on both synthetic and real-world problems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 03:47:16 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:21:54 GMT"}, {"version": "v3", "created": "Wed, 13 Nov 2019 04:24:25 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Abdolshah", "Majid", ""], ["Shilton", "Alistair", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1902.04237", "submitter": "Alexis Kirke", "authors": "Alexis Kirke", "title": "Applying Quantum Hardware to non-Scientific Problems: Grover's Algorithm\n  and Rule-based Algorithmic Music Composition", "comments": "Accepted by 'International Journal of Unconventional Computing' 18\n  July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of all novel computing methods, quantum computation (QC) is currently the\nmost likely to move from the realm of the unconventional into the conventional.\nAs a result some initial work has been done on applications of QC outside of\nscience: for example music. The small amount of arts research done in hardware\nor with actual physical systems has not utilized any of the advantages of\nquantum computation (QC): the main advantage being the potential speed increase\nof quantum algorithms. This paper introduces a way of utilizing Grover's\nalgorithm - which has been shown to provide a quadratic speed-up over its\nclassical equivalent - in algorithmic rule-based music composition. The system\nintroduced - qgMuse - is simple but scalable. Example melodies are composed\nusing qgMuse using the ibmqx4 quantum hardware. The paper concludes with\ndiscussion on how such an approach can grow with the improvement of quantum\ncomputer hardware and software.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:19:05 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:23:34 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 10:08:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kirke", "Alexis", ""]]}, {"id": "1902.04245", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Daniel J. Fremont, Shromona Ghosh, Edward Kim, Hadi\n  Ravanbakhsh, Marcell Vazquez-Chanlatte, and Sanjit A. Seshia", "title": "VERIFAI: A Toolkit for the Design and Analysis of Artificial\n  Intelligence-Based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VERIFAI, a software toolkit for the formal design and analysis of\nsystems that include artificial intelligence (AI) and machine learning (ML)\ncomponents. VERIFAI particularly seeks to address challenges with applying\nformal methods to perception and ML components, including those based on neural\nnetworks, and to model and analyze system behavior in the presence of\nenvironment uncertainty. We describe the initial version of VERIFAI which\ncenters on simulation guided by formal models and specifications. Several use\ncases are illustrated with examples, including temporal-logic falsification,\nmodel-based systematic fuzz testing, parameter synthesis, counterexample\nanalysis, and data set augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 05:38:14 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 17:30:49 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Fremont", "Daniel J.", ""], ["Ghosh", "Shromona", ""], ["Kim", "Edward", ""], ["Ravanbakhsh", "Hadi", ""], ["Vazquez-Chanlatte", "Marcell", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1902.04259", "submitter": "Matthew Hausknecht", "authors": "Matthew Hausknecht, Ricky Loynd, Greg Yang, Adith Swaminathan, Jason\n  D. Williams", "title": "NAIL: A General Interactive Fiction Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction (IF) games are complex textual decision making problems.\nThis paper introduces NAIL, an autonomous agent for general parser-based IF\ngames. NAIL won the 2018 Text Adventure AI Competition, where it was evaluated\non twenty unseen games. This paper describes the architecture, development, and\ninsights underpinning NAIL's performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 06:58:31 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 19:45:43 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Hausknecht", "Matthew", ""], ["Loynd", "Ricky", ""], ["Yang", "Greg", ""], ["Swaminathan", "Adith", ""], ["Williams", "Jason D.", ""]]}, {"id": "1902.04272", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Torsten Sch\\\"on, Patrick Wenzel", "title": "Towards Self-Supervised High Level Sensor Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a framework to control a self-driving car by fusing\nraw information from RGB images and depth maps. A deep neural network\narchitecture is used for mapping the vision and depth information,\nrespectively, to steering commands. This fusion of information from two sensor\nsources allows to provide redundancy and fault tolerance in the presence of\nsensor failures. Even if one of the input sensors fails to produce the correct\noutput, the other functioning sensor would still be able to maneuver the car.\nSuch redundancy is crucial in the critical application of self-driving cars.\nThe experimental results have showed that our method is capable of learning to\nuse the relevant sensor information even when one of the sensors fail without\nany explicit signal.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 07:53:55 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Khan", "Qadeer", ""], ["Sch\u00f6n", "Torsten", ""], ["Wenzel", "Patrick", ""]]}, {"id": "1902.04346", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen, Joost Huizinga and Jim Torresen", "title": "Guiding Neuroevolution with Structural Objectives", "comments": null, "journal-ref": null, "doi": "10.1162/evco_a_00250", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure and performance of neural networks are intimately connected,\nand by use of evolutionary algorithms, neural network structures optimally\nadapted to a given task can be explored. Guiding such neuroevolution with\nadditional objectives related to network structure has been shown to improve\nperformance in some cases, especially when modular neural networks are\nbeneficial. However, apart from objectives aiming to make networks more\nmodular, such structural objectives have not been widely explored. We propose\ntwo new structural objectives and test their ability to guide evolving neural\nnetworks on two problems which can benefit from decomposition into subtasks.\nThe first structural objective guides evolution to align neural networks with a\nuser-recommended decomposition pattern. Intuitively, this should be a powerful\nguiding target for problems where human users can easily identify a structure.\nThe second structural objective guides evolution towards a population with a\nhigh diversity in decomposition patterns. This results in exploration of many\ndifferent ways to decompose a problem, allowing evolution to find good\ndecompositions faster. Tests on our target problems reveal that both methods\nperform well on a problem with a very clear and decomposable structure.\nHowever, on a problem where the optimal decomposition is less obvious, the\nstructural diversity objective is found to outcompete other structural\nobjectives -- and this technique can even increase performance on problems\nwithout any decomposable structure at all.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 11:54:23 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 09:31:24 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 06:52:22 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Huizinga", "Joost", ""], ["Torresen", "Jim", ""]]}, {"id": "1902.04393", "submitter": "Libby Ferland", "authors": "Libby Ferland and Thomas Huffstutler and Jacob Rice and Joan Zheng and\n  Shi Ni and Maria Gini", "title": "Evaluating Older Users' Experiences with Commercial Dialogue Systems:\n  Implications for Future Design and Development", "comments": "In DEEP-DIAL19 workshop at AAAI-19, Honolulu, HI, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the needs of a variety of distinct user groups is vital in\ndesigning effective, desirable dialogue systems that will be adopted by the\nlargest possible segment of the population. Despite the increasing popularity\nof dialogue systems in both mobile and home formats, user studies remain\nrelatively infrequent and often sample a segment of the user population that is\nnot representative of the needs of the potential user population as a whole.\nThis is especially the case for users who may be more reluctant adopters, such\nas older adults.\n  In this paper we discuss the results of a recent user study performed over a\nlarge population of age 50 and over adults in the Midwestern United States that\nhave experience using a variety of commercial dialogue systems. We show the\ncommon preferences, use cases, and feature gaps identified by older adult users\nin interacting with these systems. Based on these results, we propose a new,\nrobust user modeling framework that addresses common issues facing older adult\nusers, which can then be generalized to the wider user population.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 00:21:30 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Ferland", "Libby", ""], ["Huffstutler", "Thomas", ""], ["Rice", "Jacob", ""], ["Zheng", "Joan", ""], ["Ni", "Shi", ""], ["Gini", "Maria", ""]]}, {"id": "1902.04416", "submitter": "Aminollah Khormali", "authors": "Ahmed Abusnaina, Aminollah Khormali, Hisham Alasmary, Jeman Park,\n  Afsah Anwar, Ulku Meteriz, and Aziz Mohaisen", "title": "Examining Adversarial Learning against Graph-based IoT Malware Detection\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this study is to investigate the robustness of graph-based\nDeep Learning (DL) models used for Internet of Things (IoT) malware\nclassification against Adversarial Learning (AL). We designed two approaches to\ncraft adversarial IoT software, including Off-the-Shelf Adversarial Attack\n(OSAA) methods, using six different AL attack approaches, and Graph Embedding\nand Augmentation (GEA). The GEA approach aims to preserve the functionality and\npracticality of the generated adversarial sample through a careful embedding of\na benign sample to a malicious one. Our evaluations demonstrate that OSAAs are\nable to achieve a misclassification rate (MR) of 100%. Moreover, we observed\nthat the GEA approach is able to misclassify all IoT malware samples as benign.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 14:49:08 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 22:41:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Abusnaina", "Ahmed", ""], ["Khormali", "Aminollah", ""], ["Alasmary", "Hisham", ""], ["Park", "Jeman", ""], ["Anwar", "Afsah", ""], ["Meteriz", "Ulku", ""], ["Mohaisen", "Aziz", ""]]}, {"id": "1902.04506", "submitter": "Stefano Cresci", "authors": "Michele Mazza, Stefano Cresci, Marco Avvenuti, Walter Quattrociocchi,\n  Maurizio Tesconi", "title": "RTbust: Exploiting Temporal Patterns for Botnet Detection on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within OSNs, many of our supposedly online friends may instead be fake\naccounts called social bots, part of large groups that purposely re-share\ntargeted content. Here, we study retweeting behaviors on Twitter, with the\nultimate goal of detecting retweeting social bots. We collect a dataset of 10M\nretweets. We design a novel visualization that we leverage to highlight benign\nand malicious patterns of retweeting activity. In this way, we uncover a\n'normal' retweeting pattern that is peculiar of human-operated accounts, and 3\nsuspicious patterns related to bot activities. Then, we propose a bot detection\ntechnique that stems from the previous exploration of retweeting behaviors. Our\ntechnique, called Retweet-Buster (RTbust), leverages unsupervised feature\nextraction and clustering. An LSTM autoencoder converts the retweet time series\ninto compact and informative latent feature vectors, which are then clustered\nwith a hierarchical density-based algorithm. Accounts belonging to large\nclusters characterized by malicious retweeting patterns are labeled as bots.\nRTbust obtains excellent detection results, with F1 = 0.87, whereas competitors\nachieve F1 < 0.76. Finally, we apply RTbust to a large dataset of retweets,\nuncovering 2 previously unknown active botnets with hundreds of accounts.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:15:17 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Mazza", "Michele", ""], ["Cresci", "Stefano", ""], ["Avvenuti", "Marco", ""], ["Quattrociocchi", "Walter", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1902.04522", "submitter": "Jerry Ma", "authors": "Yuandong Tian, Jerry Ma, Qucheng Gong, Shubho Sengupta, Zhuoyuan Chen,\n  James Pinkerton, C. Lawrence Zitnick", "title": "ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero", "comments": "Published as a conference paper at ICML 2019. This version contains\n  supplementary appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The AlphaGo, AlphaGo Zero, and AlphaZero series of algorithms are remarkable\ndemonstrations of deep reinforcement learning's capabilities, achieving\nsuperhuman performance in the complex game of Go with progressively increasing\nautonomy. However, many obstacles remain in the understanding of and usability\nof these promising approaches by the research community. Toward elucidating\nunresolved mysteries and facilitating future research, we propose ELF OpenGo,\nan open-source reimplementation of the AlphaZero algorithm. ELF OpenGo is the\nfirst open-source Go AI to convincingly demonstrate superhuman performance with\na perfect (20:0) record against global top professionals. We apply ELF OpenGo\nto conduct extensive ablation studies, and to identify and analyze numerous\ninteresting phenomena in both the model training and in the gameplay inference\nprocedures. Our code, models, selfplay datasets, and auxiliary data are\npublicly available.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:59:38 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 14:54:44 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 00:01:31 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 18:24:50 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Tian", "Yuandong", ""], ["Ma", "Jerry", ""], ["Gong", "Qucheng", ""], ["Sengupta", "Shubho", ""], ["Chen", "Zhuoyuan", ""], ["Pinkerton", "James", ""], ["Zitnick", "C. Lawrence", ""]]}, {"id": "1902.04546", "submitter": "Harris Chan", "authors": "Harris Chan, Yuhuai Wu, Jamie Kiros, Sanja Fidler, Jimmy Ba", "title": "ACTRCE: Augmenting Experience via Teacher's Advice For Multi-Goal\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse reward is one of the most challenging problems in reinforcement\nlearning (RL). Hindsight Experience Replay (HER) attempts to address this issue\nby converting a failed experience to a successful one by relabeling the goals.\nDespite its effectiveness, HER has limited applicability because it lacks a\ncompact and universal goal representation. We present Augmenting experienCe via\nTeacheR's adviCE (ACTRCE), an efficient reinforcement learning technique that\nextends the HER framework using natural language as the goal representation. We\nfirst analyze the differences among goal representation, and show that ACTRCE\ncan efficiently solve difficult reinforcement learning problems in challenging\n3D navigation tasks, whereas HER with non-language goal representation failed\nto learn. We also show that with language goal representations, the agent can\ngeneralize to unseen instructions, and even generalize to instructions with\nunseen lexicons. We further demonstrate it is crucial to use hindsight advice\nto solve challenging tasks, and even small amount of advice is sufficient for\nthe agent to achieve good performance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:43:56 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Chan", "Harris", ""], ["Wu", "Yuhuai", ""], ["Kiros", "Jamie", ""], ["Fidler", "Sanja", ""], ["Ba", "Jimmy", ""]]}, {"id": "1902.04627", "submitter": "Helge Spieker", "authors": "Morten Mossige, Arnaud Gotlieb, Helge Spieker, Hein Meling, Mats\n  Carlsson", "title": "Time-aware Test Case Execution Scheduling for Cyber-Physical Systems", "comments": "Published in the 23rd International Conference on Principles and\n  Practice of Constraint Programming (CP 2017)", "journal-ref": "In: Beck J. (eds) Principles and Practice of Constraint\n  Programming. CP 2017. Lecture Notes in Computer Science, vol 10416. Springer,\n  Cham", "doi": "10.1007/978-3-319-66158-2_25", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing cyber-physical systems involves the execution of test cases on\ntarget-machines equipped with the latest release of a software control system.\nWhen testing industrial robots, it is common that the target machines need to\nshare some common resources, e.g., costly hardware devices, and so there is a\nneed to schedule test case execution on the target machines, accounting for\nthese shared resources. With a large number of such tests executed on a regular\nbasis, this scheduling becomes difficult to manage manually. In fact, with\nmanual test execution planning and scheduling, some robots may remain\nunoccupied for long periods of time and some test cases may not be executed.\nThis paper introduces TC-Sched, a time-aware method for automated test case\nexecution scheduling. TC-Sched uses Constraint Programming to schedule tests to\nrun on multiple machines constrained by the tests' access to shared resources,\nsuch as measurement or networking devices. The CP model is written in SICStus\nProlog and uses the Cumulatives global constraint. Given a set of test cases, a\nset of machines, and a set of shared resources, TC-Sched produces an execution\nschedule where each test is executed once with minimal time between when a\nsource code change is committed and the test results are reported to the\ndeveloper. Experiments reveal that TC-Sched can schedule 500 test cases over\n100 machines in less than 4 minutes for 99.5% of the instances. In addition,\nTC-Sched largely outperforms simpler methods based on a greedy algorithm and is\nsuitable for deployment on industrial robot testing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 20:39:05 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Mossige", "Morten", ""], ["Gotlieb", "Arnaud", ""], ["Spieker", "Helge", ""], ["Meling", "Hein", ""], ["Carlsson", "Mats", ""]]}, {"id": "1902.04698", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Samy Bengio and Moritz Hardt and Michael C. Mozer\n  and Yoram Singer", "title": "Identity Crisis: Memorization and Generalization under Extreme\n  Overparameterization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the interplay between memorization and generalization of\noverparameterized networks in the extreme case of a single training example and\nan identity-mapping task. We examine fully-connected and convolutional networks\n(FCN and CNN), both linear and nonlinear, initialized randomly and then trained\nto minimize the reconstruction error. The trained networks stereotypically take\none of two forms: the constant function (memorization) and the identity\nfunction (generalization). We formally characterize generalization in\nsingle-layer FCNs and CNNs. We show empirically that different architectures\nexhibit strikingly different inductive biases. For example, CNNs of up to 10\nlayers are able to generalize from a single example, whereas FCNs cannot learn\nthe identity function reliably from 60k examples. Deeper CNNs often fail, but\nnonetheless do astonishing work to memorize the training output: because CNN\nbiases are location invariant, the model must progressively grow an output\npattern from the image boundaries via the coordination of many layers. Our work\nhelps to quantify and visualize the sensitivity of inductive biases to\narchitectural choices such as depth, kernel width, and number of channels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 01:45:30 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 00:29:36 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 23:29:28 GMT"}, {"version": "v4", "created": "Thu, 9 Jan 2020 04:31:25 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Bengio", "Samy", ""], ["Hardt", "Moritz", ""], ["Mozer", "Michael C.", ""], ["Singer", "Yoram", ""]]}, {"id": "1902.04832", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Relative rationality: Is machine rationality subjective?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rational decision making in its linguistic description means making logical\ndecisions. In essence, a rational agent optimally processes all relevant\ninformation to achieve its goal. Rationality has two elements and these are the\nuse of relevant information and the efficient processing of such information.\nIn reality, relevant information is incomplete, imperfect and the processing\nengine, which is a brain for humans, is suboptimal. Humans are risk averse\nrather than utility maximizers. In the real world, problems are predominantly\nnon-convex and this makes the idea of rational decision-making fundamentally\nunachievable and Herbert Simon called this bounded rationality. There is a\ntrade-off between the amount of information used for decision-making and the\ncomplexity of the decision model used. This explores whether machine\nrationality is subjective and concludes that indeed it is.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 10:08:12 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1902.04885", "submitter": "Yang Liu", "authors": "Qiang Yang, Yang Liu, Tianjian Chen, Yongxin Tong", "title": "Federated Machine Learning: Concept and Applications", "comments": null, "journal-ref": "ACM Transactions on Intelligent Systems and Technology (TIST)\n  Volume 10 Issue 2, Article No. 12, January 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's AI still faces two major challenges. One is that in most industries,\ndata exists in the form of isolated islands. The other is the strengthening of\ndata privacy and security. We propose a possible solution to these challenges:\nsecure federated learning. Beyond the federated learning framework first\nproposed by Google in 2016, we introduce a comprehensive secure federated\nlearning framework, which includes horizontal federated learning, vertical\nfederated learning and federated transfer learning. We provide definitions,\narchitectures and applications for the federated learning framework, and\nprovide a comprehensive survey of existing works on this subject. In addition,\nwe propose building data networks among organizations based on federated\nmechanisms as an effective solution to allow knowledge to be shared without\ncompromising user privacy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 13:16:46 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Yang", "Qiang", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Tong", "Yongxin", ""]]}, {"id": "1902.04982", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Noam Brown, Tuomas Sandholm", "title": "Stable-Predictive Optimistic Counterfactual Regret Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CFR framework has been a powerful tool for solving large-scale\nextensive-form games in practice. However, the theoretical rate at which past\nCFR-based algorithms converge to the Nash equilibrium is on the order of\n$O(T^{-1/2})$, where $T$ is the number of iterations. In contrast, first-order\nmethods can be used to achieve a $O(T^{-1})$ dependence on iterations, yet\nthese methods have been less successful in practice. In this work we present\nthe first CFR variant that breaks the square-root dependence on iterations. By\ncombining and extending recent advances on predictive and stable regret\nminimizers for the matrix-game setting we show that it is possible to leverage\n\"optimistic\" regret minimizers to achieve a $O(T^{-3/4})$ convergence rate\nwithin CFR. This is achieved by introducing a new notion of\nstable-predictivity, and by setting the stability of each counterfactual regret\nminimizer relative to its location in the decision tree. Experiments show that\nthis method is faster than the original CFR algorithm, although not as fast as\nnewer variants, in spite of their worst-case $O(T^{-1/2})$ dependence on\niterations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 16:18:21 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1902.05066", "submitter": "Weijia Zhang", "authors": "Weijia Zhang and Jiuyong Li and Lin Liu", "title": "Robust Multi-instance Learning with Stable Instances", "comments": "In Proceedings of the Twenty-Fourth European Conference on Artificial\n  Intelligence (ECAI'20)", "journal-ref": null, "doi": "10.3233/FAIA200280", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-instance learning (MIL) deals with tasks where data is represented by a\nset of bags and each bag is described by a set of instances. Unlike standard\nsupervised learning, only the bag labels are observed whereas the label for\neach instance is not available to the learner. Previous MIL studies typically\nfollow the i.i.d. assumption, that the training and test samples are\nindependently drawn from the same distribution. However, such assumption is\noften violated in real-world applications. Efforts have been made towards\naddressing distribution changes by importance weighting the training data with\nthe density ratio between the training and test samples. Unfortunately, models\noften need to be trained without seeing the test distributions. In this paper\nwe propose possibly the first framework for addressing distribution change in\nMIL without requiring access to the unlabeled test data. Our framework builds\nupon identifying a novel connection between MIL and the potential outcome\nframework in causal effect estimation. Experimental results on synthetic\ndistribution change datasets, real-world datasets with synthetic distribution\nbiases and real distributional biased image classification datasets validate\nthe effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 03:55:36 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 23:08:50 GMT"}, {"version": "v3", "created": "Tue, 21 May 2019 11:11:11 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 01:42:19 GMT"}, {"version": "v5", "created": "Mon, 26 Apr 2021 13:34:21 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Weijia", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""]]}, {"id": "1902.05070", "submitter": "Mee Seong Im", "authors": "Mee Seong Im, Venkat R. Dasari, Lubjana Beshaj, Dale Shires", "title": "Optimization problems with low SWaP tactical Computing", "comments": "8 pages, 1 figure. To appear in Proc. SPIE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a resource-constrained, contested environment, computing resources need to\nbe aware of possible size, weight, and power (SWaP) restrictions. SWaP-aware\ncomputational efficiency depends upon optimization of computational resources\nand intelligent time versus efficiency tradeoffs in decision making. In this\npaper we address the complexity of various optimization strategies related to\nlow SWaP computing. Due to these restrictions, only a small subset of less\ncomplicated and fast computable algorithms can be used for tactical, adaptive\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 11:17:43 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Im", "Mee Seong", ""], ["Dasari", "Venkat R.", ""], ["Beshaj", "Lubjana", ""], ["Shires", "Dale", ""]]}, {"id": "1902.05284", "submitter": "Xin Tong Mr.", "authors": "Xin Tong, Weiming Liu and Bin Li", "title": "Learn a Prior for RHEA for Better Online Planning", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rolling Horizon Evolutionary Algorithms (RHEA) are a class of online planning\nmethods for real-time game playing; their performance is closely related to the\nplanning horizon and the search time allowed. In this paper, we propose to\nlearn a prior for RHEA in an offline manner by training a value network and a\npolicy network. The value network is used to reduce the planning horizon by\nproviding an estimation of future rewards, and the policy network is used to\ninitialize the population, which helps to narrow down the search scope. The\nproposed algorithm, named prior-based RHEA (p-RHEA), trains policy and value\nnetworks by performing planning and learning iteratively. In the planning\nstage, the horizon-limited search assisted with the policy network and value\nnetwork is performed to improve the policies and collect training samples. In\nthe learning stage, the policy network and value network are trained with the\ncollected samples to learn better prior knowledge. Experimental results on\nOpenAI Gym MuJoCo tasks show that the performance of the proposed p-RHEA is\nsignificantly improved compared to that of RHEA.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 09:56:00 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 12:25:06 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Tong", "Xin", ""], ["Liu", "Weiming", ""], ["Li", "Bin", ""]]}, {"id": "1902.05357", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Gaurav Kolhe, Setareh Rafatirad, Sai Manoj P. D., Houman\n  Homayoun, Liang Zhao, Chang-Tien Lu", "title": "Estimating the Circuit Deobfuscating Runtime based on Graph Deep\n  Learning", "comments": "Design, Automation and Test in Europe (DATE) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circuit obfuscation is a recently proposed defense mechanism to protect\ndigital integrated circuits (ICs) from reverse engineering by using camouflaged\ngates i.e., logic gates whose functionality cannot be precisely determined by\nthe attacker. There have been effective schemes such as satisfiability-checking\n(SAT)-based attacks that can potentially decrypt obfuscated circuits, called\ndeobfuscation. Deobfuscation runtime could have a large span ranging from few\nmilliseconds to thousands of years or more, depending on the number and layouts\nof the ICs and camouflaged gates. And hence accurately pre-estimating the\ndeobfuscation runtime is highly crucial for the defenders to maximize it and\noptimize their defense. However, estimating the deobfuscation runtime is a\nchallenging task due to 1) the complexity and heterogeneity of graph-structured\ncircuit, 2) the unknown and sophisticated mechanisms of the attackers for\ndeobfuscation. To address the above mentioned challenges, this work proposes\nthe first machine-learning framework that predicts the deobfuscation runtime\nbased on graph deep learning techniques. Specifically, we design a new model,\nICNet with new input and convolution layers to characterize and extract graph\nfrequencies from ICs, which are then integrated by heterogeneous deep\nfully-connected layers to obtain final output. ICNet is an end-to-end framework\nwhich can automatically extract the determinant features for deobfuscation\nruntime. Extensive experiments demonstrate its effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 13:57:11 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 13:34:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chen", "Zhiqian", ""], ["Kolhe", "Gaurav", ""], ["Rafatirad", "Setareh", ""], ["D.", "Sai Manoj P.", ""], ["Homayoun", "Houman", ""], ["Zhao", "Liang", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1902.05454", "submitter": "Devon Graham Mr", "authors": "Robert Kleinberg, Kevin Leyton-Brown, Brendan Lucier and Devon Graham", "title": "Procrastinating with Confidence: Near-Optimal, Anytime, Adaptive\n  Algorithm Configuration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm configuration methods optimize the performance of a parameterized\nheuristic algorithm on a given distribution of problem instances. Recent work\nintroduced an algorithm configuration procedure (\"Structured Procrastination\")\nthat provably achieves near optimal performance with high probability and with\nnearly minimal runtime in the worst case. It also offers an $\\textit{anytime}$\nproperty: it keeps tightening its optimality guarantees the longer it is run.\nUnfortunately, Structured Procrastination is not $\\textit{adaptive}$ to\ncharacteristics of the parameterized algorithm: it treats every input like the\nworst case. Follow-up work (\"LeapsAndBounds\") achieves adaptivity but trades\naway the anytime property. This paper introduces a new algorithm, \"Structured\nProcrastination with Confidence\", that preserves the near-optimality and\nanytime properties of Structured Procrastination while adding adaptivity. In\nparticular, the new algorithm will perform dramatically faster in settings\nwhere many algorithm configurations perform poorly. We show empirically both\nthat such settings arise frequently in practice and that the anytime property\nis useful for finding good configurations quickly.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 15:47:15 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 14:13:07 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 15:05:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kleinberg", "Robert", ""], ["Leyton-Brown", "Kevin", ""], ["Lucier", "Brendan", ""], ["Graham", "Devon", ""]]}, {"id": "1902.05522", "submitter": "Brian Cheung", "authors": "Brian Cheung, Alex Terekhov, Yubei Chen, Pulkit Agrawal, Bruno\n  Olshausen", "title": "Superposition of many models into one", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for storing multiple models within a single set of\nparameters. Models can coexist in superposition and still be retrieved\nindividually. In experiments with neural networks, we show that a surprisingly\nlarge number of models can be effectively stored within a single parameter\ninstance. Furthermore, each of these models can undergo thousands of training\nsteps without significantly interfering with other models within the\nsuperposition. This approach may be viewed as the online complement of\ncompression: rather than reducing the size of a network after training, we make\nuse of the unrealized capacity of a network during training.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 17:59:13 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 17:58:36 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Cheung", "Brian", ""], ["Terekhov", "Alex", ""], ["Chen", "Yubei", ""], ["Agrawal", "Pulkit", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1902.05546", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Chris Lu, Trevor Darrell, Phillip Isola, Alexei A.\n  Efros", "title": "Learning to Control Self-Assembling Morphologies: A Study of\n  Generalization via Modularity", "comments": "NeurIPS 2019 (Spotlight). Videos at\n  https://pathak22.github.io/modular-assemblies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary sensorimotor learning approaches typically start with an\nexisting complex agent (e.g., a robotic arm), which they learn to control. In\ncontrast, this paper investigates a modular co-evolution strategy: a collection\nof primitive agents learns to dynamically self-assemble into composite bodies\nwhile also learning to coordinate their behavior to control these bodies. Each\nprimitive agent consists of a limb with a motor attached at one end. Limbs may\nchoose to link up to form collectives. When a limb initiates a link-up action,\nand there is another limb nearby, the latter is magnetically connected to the\n'parent' limb's motor. This forms a new single agent, which may further link\nwith other agents. In this way, complex morphologies can emerge, controlled by\na policy whose architecture is in explicit correspondence with the morphology.\nWe evaluate the performance of these dynamic and modular agents in simulated\nenvironments. We demonstrate better generalization to test-time changes both in\nthe environment, as well as in the structure of the agent, compared to static\nand monolithic baselines. Project video and code are available at\nhttps://pathak22.github.io/modular-assemblies/\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 21:35:27 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pathak", "Deepak", ""], ["Lu", "Chris", ""], ["Darrell", "Trevor", ""], ["Isola", "Phillip", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1902.05632", "submitter": "Nathan Fulton", "authors": "Nathan Fulton and Andre Platzer", "title": "Verifiably Safe Off-Model Reinforcement Learning", "comments": "TACAS 2019", "journal-ref": null, "doi": "10.1007/978-3-030-17462-0_28", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The desire to use reinforcement learning in safety-critical settings has\ninspired a recent interest in formal methods for learning algorithms. Existing\nformal methods for learning and optimization primarily consider the problem of\nconstrained learning or constrained optimization. Given a single correct model\nand associated safety constraint, these approaches guarantee efficient learning\nwhile provably avoiding behaviors outside the safety constraint. Acting well\ngiven an accurate environmental model is an important pre-requisite for safe\nlearning, but is ultimately insufficient for systems that operate in complex\nheterogeneous environments. This paper introduces verification-preserving model\nupdates, the first approach toward obtaining formal safety guarantees for\nreinforcement learning in settings where multiple environmental models must be\ntaken into account. Through a combination of design-time model updates and\nruntime model falsification, we provide a first approach toward obtaining\nformal safety proofs for autonomous systems acting in heterogeneous\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:36:54 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Fulton", "Nathan", ""], ["Platzer", "Andre", ""]]}, {"id": "1902.05644", "submitter": "Macheng Shen", "authors": "Macheng Shen and Jonathan P How", "title": "Active Perception in Adversarial Scenarios using Maximum Entropy Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We pose an active perception problem where an autonomous agent actively\ninteracts with a second agent with potentially adversarial behaviors. Given the\nuncertainty in the intent of the other agent, the objective is to collect\nfurther evidence to help discriminate potential threats. The main technical\nchallenges are the partial observability of the agent intent, the adversary\nmodeling, and the corresponding uncertainty modeling. Note that an adversary\nagent may act to mislead the autonomous agent by using a deceptive strategy\nthat is learned from past experiences. We propose an approach that combines\nbelief space planning, generative adversary modeling, and maximum entropy\nreinforcement learning to obtain a stochastic belief space policy. By\naccounting for various adversarial behaviors in the simulation framework and\nminimizing the predictability of the autonomous agent's action, the resulting\npolicy is more robust to unmodeled adversarial strategies. This improved\nrobustness is empirically shown against an adversary that adapts to and\nexploits the autonomous agent's policy when compared with a standard\nChance-Constraint Partially Observable Markov Decision Process robust approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 23:44:22 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 23:38:54 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Shen", "Macheng", ""], ["How", "Jonathan P", ""]]}, {"id": "1902.05677", "submitter": "Paul Cohen", "authors": "Paul Cohen", "title": "Probabilistic Relational Agent-based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PRAM puts agent-based models on a sound probabilistic footing as a basis for\nintegrating agent-based and probabilistic models. It extends the themes of\nprobabilistic relational models and lifted inference to incorporate dynamical\nmodels and simulation. It can also be much more efficient than agent-based\nsimulation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 04:03:30 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Cohen", "Paul", ""]]}, {"id": "1902.05715", "submitter": "Shalini Ghosh", "authors": "Shalini Ghosh, Giedrius Burachas, Arijit Ray, Avi Ziskind", "title": "Generating Natural Language Explanations for Visual Question Answering\n  using Scene Graphs and Visual Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for the task of eXplainable\nQuestion Answering (XQA), i.e., generating natural language (NL) explanations\nfor the Visual Question Answering (VQA) problem. We generate NL explanations\ncomprising of the evidence to support the answer to a question asked to an\nimage using two sources of information: (a) annotations of entities in an image\n(e.g., object labels, region descriptions, relation phrases) generated from the\nscene graph of the image, and (b) the attention map generated by a VQA model\nwhen answering the question. We show how combining the visual attention map\nwith the NL representation of relevant scene graph entities, carefully selected\nusing a language model, can give reasonable textual explanations without the\nneed of any additional collected data (explanation captions, etc). We run our\nalgorithms on the Visual Genome (VG) dataset and conduct internal user-studies\nto demonstrate the efficacy of our approach over a strong baseline. We have\nalso released a live web demo showcasing our VQA and textual explanation\ngeneration using scene graphs and visual attention.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 07:59:11 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Ghosh", "Shalini", ""], ["Burachas", "Giedrius", ""], ["Ray", "Arijit", ""], ["Ziskind", "Avi", ""]]}, {"id": "1902.05727", "submitter": "Sebastian Junges", "authors": "Milan Ceska, Nils Jansen, Sebastian Junges, Joost-Pieter Katoen", "title": "Shepherding Hordes of Markov Chains", "comments": "Full version of TACAS'19 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers large families of Markov chains (MCs) that are defined\nover a set of parameters with finite discrete domains. Such families occur in\nsoftware product lines, planning under partial observability, and sketching of\nprobabilistic programs. Simple questions, like `does at least one family member\nsatisfy a property?', are NP-hard. We tackle two problems: distinguish family\nmembers that satisfy a given quantitative property from those that do not, and\ndetermine a family member that satisfies the property optimally, i.e., with the\nhighest probability or reward. We show that combining two well-known\ntechniques, MDP model checking and abstraction refinement, mitigates the\ncomputational complexity. Experiments on a broad set of benchmarks show that in\nmany situations, our approach is able to handle families of millions of MCs,\nproviding superior scalability compared to existing solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 09:12:34 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 10:36:07 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Ceska", "Milan", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "1902.05761", "submitter": "Emmanuel Vincent", "authors": "Dayana Ribas, Emmanuel Vincent (MULTISPEECH)", "title": "An improved uncertainty propagation method for robust i-vector based\n  speaker recognition", "comments": null, "journal-ref": "44th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2019), May 2019, Brighton, United Kingdom", "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speaker recognition systems degrades when facing\ndistorted speech data containing additive noise and/or reverberation.\nStatistical uncertainty propagation has been introduced as a promising paradigm\nto address this challenge. So far, different uncertainty propagation methods\nhave been proposed to compensate noise and reverberation in i-vectors in the\ncontext of speaker recognition. They have achieved promising results on small\ndatasets such as YOHO and Wall Street Journal, but little or no improvement on\nthe larger, highly variable NIST Speaker Recognition Evaluation (SRE) corpus.\nIn this paper, we propose a complete uncertainty propagation method, whereby we\nmodel the effect of uncertainty both in the computation of unbiased Baum-Welch\nstatistics and in the derivation of the posterior expectation of the i-vector.\nWe conduct experiments on the NIST-SRE corpus mixed with real domestic noise\nand reverberation from the CHiME-2 corpus and preprocessed by multichannel\nspeech enhancement. The proposed method improves the equal error rate (EER) by\n4% relative compared to a conventional i-vector based speaker verification\nbaseline. This is to be compared with previous methods which degrade\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 10:45:02 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 12:18:14 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Ribas", "Dayana", "", "MULTISPEECH"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "1902.05770", "submitter": "Zhaopeng Tu", "authors": "Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Longyue Wang, Shuming Shi, Tong\n  Zhang", "title": "Dynamic Layer Aggregation for Neural Machine Translation with\n  Routing-by-Agreement", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the promising progress of deep neural networks, layer aggregation has\nbeen used to fuse information across layers in various fields, such as computer\nvision and machine translation. However, most of the previous methods combine\nlayers in a static fashion in that their aggregation strategy is independent of\nspecific hidden states. Inspired by recent progress on capsule networks, in\nthis paper we propose to use routing-by-agreement strategies to aggregate\nlayers dynamically. Specifically, the algorithm learns the probability of a\npart (individual layer representations) assigned to a whole (aggregated\nrepresentations) in an iterative way and combines parts accordingly. We\nimplement our algorithm on top of the state-of-the-art neural machine\ntranslation model TRANSFORMER and conduct experiments on the widely-used WMT14\nEnglish-German and WMT17 Chinese-English translation datasets. Experimental\nresults across language pairs show that the proposed approach consistently\noutperforms the strong baseline model and a representative static aggregation\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 11:14:35 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""]]}, {"id": "1902.05772", "submitter": "Zhengwei Bai", "authors": "Zhengwei Bai, Baigen Cai, Wei Shangguan, Linguo Chai", "title": "Deep Reinforcement Learning Based High-level Driving Behavior\n  Decision-making Model in Heterogeneous Traffic", "comments": "7 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level driving behavior decision-making is an open-challenging problem\nfor connected vehicle technology, especially in heterogeneous traffic\nscenarios. In this paper, a deep reinforcement learning based high-level\ndriving behavior decision-making approach is proposed for connected vehicle in\nheterogeneous traffic situations. The model is composed of three main parts: a\ndata preprocessor that maps hybrid data into a data format called hyper-grid\nmatrix, a two-stream deep neural network that extracts the hidden features, and\na deep reinforcement learning network that learns the optimal policy. Moreover,\na simulation environment, which includes different heterogeneous traffic\nscenarios, is built to train and test the proposed method. The results\ndemonstrate that the model has the capability to learn the optimal high-level\ndriving policy such as driving fast through heterogeneous traffic without\nunnecessary lane changes. Furthermore, two separate models are used to compare\nwith the proposed model, and the performances are analyzed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 11:25:55 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:02:43 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Bai", "Zhengwei", ""], ["Cai", "Baigen", ""], ["Shangguan", "Wei", ""], ["Chai", "Linguo", ""]]}, {"id": "1902.05795", "submitter": "Yuhui Wang", "authors": "Yuhui Wang, Hao He, Xiaoyang Tan", "title": "Robust Reinforcement Learning in POMDPs with Incomplete and Noisy\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, the observation data for reinforcement learning with\ncontinuous control is commonly noisy and part of it may be dynamically missing\nover time, which violates the assumption of many current methods developed for\nthis. We addressed the issue within the framework of partially observable\nMarkov Decision Process (POMDP) using a model-based method, in which the\ntransition model is estimated from the incomplete and noisy observations using\na newly proposed surrogate loss function with local approximation, while the\npolicy and value function is learned with the help of belief imputation. For\nthe latter purpose, a generative model is constructed and is seamlessly\nincorporated into the belief updating procedure of POMDP, which enables robust\nexecution even under a significant incompleteness and noise. The effectiveness\nof the proposed method is verified on a collection of benchmark tasks, showing\nthat our approach outperforms several compared methods under various\nchallenging scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 12:47:50 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Wang", "Yuhui", ""], ["He", "Hao", ""], ["Tan", "Xiaoyang", ""]]}, {"id": "1902.05811", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Kenneth Fung, Steffen E. Petersen,\n  Nicholas Ayache", "title": "Unsupervised shape and motion analysis of 3822 cardiac 4D MRIs of UK\n  Biobank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform unsupervised analysis of image-derived shape and motion features\nextracted from 3822 cardiac 4D MRIs of the UK Biobank. First, with a feature\nextraction method previously published based on deep learning models, we\nextract from each case 9 feature values characterizing both the cardiac shape\nand motion. Second, a feature selection is performed to remove highly\ncorrelated feature pairs. Third, clustering is carried out using a Gaussian\nmixture model on the selected features. After analysis, we identify two small\nclusters which probably correspond to two pathological categories. Further\nconfirmation using a trained classification model and dimensionality reduction\ntools is carried out to support this discovery. Moreover, we examine the\ndifferences between the other large clusters and compare our measures with the\nground-truth.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 13:56:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Fung", "Kenneth", ""], ["Petersen", "Steffen E.", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1902.05943", "submitter": "Marius Silaghi", "authors": "Viorel D. Silaghi, Marius C. Silaghi, Ren\\'e Mandiau", "title": "Privacy of Existence of Secrets: Introducing Steganographic DCOPs and\n  Revisiting DCOP Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we identify a type of privacy concern in Distributed Constraint\nOptimization (DCOPs) not previously addressed in literature, despite its\nimportance and impact on the application field: the privacy of existence of\nsecrets. Science only starts where metrics and assumptions are clearly defined.\nThe area of Distributed Constraint Optimization has emerged at the intersection\nof the multi-agent system community and constraint programming. For the\nmulti-agent community, the constraint optimization problems are an elegant way\nto express many of the problems occurring in trading and distributed robotics.\nFor the theoretical constraint programming community the DCOPs are a natural\nextension of their main object of study, the constraint satisfaction problem.\nAs such, the understanding of the DCOP framework has been refined with the\nneeds of the two communities, but sometimes without spelling the new\nassumptions formally and therefore making it difficult to compare techniques.\nHere we give a direction to the efforts for structuring concepts in this area.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 18:52:26 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Silaghi", "Viorel D.", ""], ["Silaghi", "Marius C.", ""], ["Mandiau", "Ren\u00e9", ""]]}, {"id": "1902.05946", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani, Marcella S. R. Martins, Myriam R. B. S. Delgado,\n  Inkyung Sung, Ricardo L\\\"uders, Markus Wagner", "title": "On resampling vs. adjusting probabilistic graphical models in estimation\n  of distribution algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian Optimisation Algorithm (BOA) is an Estimation of Distribution\nAlgorithm (EDA) that uses a Bayesian network as probabilistic graphical model\n(PGM). Determining the optimal Bayesian network structure given a solution\nsample is an NP-hard problem. This step should be completed at each iteration\nof BOA, resulting in a very time-consuming process. For this reason most\nimplementations use greedy estimation algorithms such as K2. However, we show\nin this paper that significant changes in PGM structure do not occur so\nfrequently, and can be particularly sparse at the end of evolution. A\nstatistical study of BOA is thus presented to characterise a pattern of PGM\nadjustments that can be used as a guide to reduce the frequency of PGM updates\nduring the evolutionary process. This is accomplished by proposing a new\nBOA-based optimisation approach (FBOA) whose PGM is not updated at each\niteration. This new approach avoids the computational burden usually found in\nthe standard BOA. The results compare the performances of both algorithms on an\nNK-landscape optimisation problem using the correlation between the ruggedness\nand the expected runtime over enumerated instances. The experiments show that\nFBOA presents competitive results while significantly saving computational\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:59:20 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Yafrani", "Mohamed El", ""], ["Martins", "Marcella S. R.", ""], ["Delgado", "Myriam R. B. S.", ""], ["Sung", "Inkyung", ""], ["L\u00fcders", "Ricardo", ""], ["Wagner", "Markus", ""]]}, {"id": "1902.05947", "submitter": "Fereshteh Sadeghi", "authors": "Fereshteh Sadeghi", "title": "DIViS: Domain Invariant Visual Servoing for Collision-Free Goal Reaching", "comments": "Supplementary videos: https://fsadeghi.github.io/DIViS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots should understand both semantics and physics to be functional in the\nreal world. While robot platforms provide means for interacting with the\nphysical world they cannot autonomously acquire object-level semantics without\nneeding human. In this paper, we investigate how to minimize human effort and\nintervention to teach robots perform real world tasks that incorporate\nsemantics. We study this question in the context of visual servoing of mobile\nrobots and propose DIViS, a Domain Invariant policy learning approach for\ncollision free Visual Servoing. DIViS incorporates high level semantics from\npreviously collected static human-labeled datasets and learns collision free\nservoing entirely in simulation and without any real robot data. However, DIViS\ncan directly be deployed on a real robot and is capable of servoing to the\nuser-specified object categories while avoiding collisions in the real world.\nDIViS is not constrained to be queried by the final view of goal but rather is\nrobust to servo to image goals taken from initial robot view with high\nocclusions without this impairing its ability to maintain a collision free\npath. We show the generalization capability of DIViS on real mobile robots in\nmore than 90 real world test scenarios with various unseen object goals in\nunstructured environments. DIViS is compared to prior approaches via real world\nexperiments and rigorous tests in simulation. For supplementary videos, see:\n\\href{https://fsadeghi.github.io/DIViS}{https://fsadeghi.github.io/DIViS}\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 18:57:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Sadeghi", "Fereshteh", ""]]}, {"id": "1902.06000", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Panupong Pasupat, Sonal Gupta, Rushin Shah, Mrinal\n  Mohit, Mike Lewis, Luke Zettlemoyer", "title": "Improving Semantic Parsing for Task Oriented Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing using hierarchical representations has recently been\nproposed for task oriented dialog with promising results [Gupta et al 2018]. In\nthis paper, we present three different improvements to the model:\ncontextualized embeddings, ensembling, and pairwise re-ranking based on a\nlanguage model. We taxonomize the errors possible for the hierarchical\nrepresentation, such as wrong top intent, missing spans or split spans, and\nshow that the three approaches correct different kinds of errors. The best\nmodel combines the three techniques and gives 6.4% better exact match accuracy\nthan the state-of-the-art, with an error reduction of 33%, resulting in a new\nstate-of-the-art result on the Task Oriented Parsing (TOP) dataset.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 22:54:32 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Einolghozati", "Arash", ""], ["Pasupat", "Panupong", ""], ["Gupta", "Sonal", ""], ["Shah", "Rushin", ""], ["Mohit", "Mrinal", ""], ["Lewis", "Mike", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1902.06007", "submitter": "Andrew Silva", "authors": "Andrew Silva, Matthew Gombolay", "title": "Neural-encoding Human Experts' Domain Knowledge to Warm Start\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been successful in a variety of tasks, such\nas game playing and robotic manipulation. However, attempting to learn\n\\textit{tabula rasa} disregards the logical structure of many domains as well\nas the wealth of readily available knowledge from domain experts that could\nhelp \"warm start\" the learning process. We present a novel reinforcement\nlearning technique that allows for intelligent initialization of a neural\nnetwork weights and architecture. Our approach permits the encoding domain\nknowledge directly into a neural decision tree, and improves upon that\nknowledge with policy gradient updates. We empirically validate our approach on\ntwo OpenAI Gym tasks and two modified StarCraft 2 tasks, showing that our novel\narchitecture outperforms multilayer-perceptron and recurrent architectures. Our\nknowledge-based framework finds superior policies compared to imitation\nlearning-based and prior knowledge-based approaches. Importantly, we\ndemonstrate that our approach can be used by untrained humans to initially\nprovide >80% increase in expected reward relative to baselines prior to\ntraining (p < 0.001), which results in a >60% increase in expected reward after\npolicy optimization (p = 0.011).\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 23:28:59 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 14:23:30 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 17:47:06 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 22:17:29 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Silva", "Andrew", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1902.06075", "submitter": "James Goodman", "authors": "James Goodman", "title": "Re-determinizing Information Set Monte Carlo Tree Search in Hanabi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report documents the winner of the Computational Intelligence\nin Games(CIG) 2018 Hanabi competition. We introduce Re-determinizing IS-MCTS, a\nnovel extension of Information Set Monte Carlo Tree Search (IS-MCTS) that\nprevents a leakage of hidden information into opponent models that can occur in\nIS-MCTS, and is particularly severe in Hanabi. Re-determinizing IS-MCTS scores\nhigher in Hanabi for 2-4 players than previously published work at the time of\nthe competition. Given the 40ms competition time limit per move we use a\nlearned evaluation function to estimate leaf node values and avoid full\nsimulations during MCTS. For the Mixed track competition, in which the identity\nof the other players is unknown, a simple Bayesian opponent model is used that\nis updated as each game proceeds.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 09:42:41 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 18:19:19 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Goodman", "James", ""]]}, {"id": "1902.06123", "submitter": "Nicola Gigante", "authors": "Nicola Gigante", "title": "Timeline-based planning: Expressiveness and Complexity", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Timeline-based planning is an approach originally developed in the context of\nspace mission planning and scheduling, where problem domains are modelled as\nsystems made of a number of independent but interacting components, whose\nbehaviour over time, the timelines, is governed by a set of temporal\nconstraints. This approach is different from the action-based perspective of\ncommon PDDL-like planning languages. Timeline-based systems have been\nsuccessfully deployed in a number of space missions and other domains. However,\ndespite this practical success, a thorough theoretical understanding of the\nparadigm was missing.\n  This thesis fills this gap, providing the first detailed account of formal\nand computational properties of the timeline-based approach to planning. In\nparticular, we show that a particularly restricted variant of the formalism is\nalready expressive enough to compactly capture action-based temporal planning\nproblems. Then, finding a solution plan for a timeline-based planning problem\nis proved to be EXPSPACE-complete.\n  Then, we study the problem of timeline-based planning with uncertainty, that\ninclude external components whose behaviour is not under the control of the\nplanned system. We identify a few issues in the state-of-the-art approach based\non flexible plans, proposing timeline-based games, a more general\ngame-theoretic formulation of the problem, that addresses those issues. We show\nthat winning strategies for such games can be found in doubly-exponential time.\n  Then, we study the expressiveness of the formalism from a logic point of\nview, showing that (most of) timeline-based planning problems can be captured\nby Bounded TPTL with Past, a fragment of TPTL+P that, unlike the latter, keeps\nan EXPSPACE satisfiability problem. The logic is introduced and its\nsatisfiabilty problem is solved by extending a recent one-pass tree-shaped\ntableau method for LTL.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 16:45:03 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 12:20:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Gigante", "Nicola", ""]]}, {"id": "1902.06178", "submitter": "Marlo Souza", "authors": "Marlo Souza, \\'Alvaro Moreira, Renata Vieira", "title": "Iterated Belief Base Revision: A Dynamic Epistemic Logic Approach", "comments": "8 pages, AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AGM's belief revision is one of the main paradigms in the study of belief\nchange operations. In this context, belief bases (prioritised bases) have been\nlargely used to specify the agent's belief state - whether representing the\nagent's `explicit beliefs' or as a computational model for her belief state.\nWhile the connection of iterated AGM-like operations and their encoding in\ndynamic epistemic logics have been studied before, few works considered how\nwell-known postulates from iterated belief revision theory can be characterised\nby means of belief bases and their counterpart in a dynamic epistemic logic.\nThis work investigates how priority graphs, a syntactic representation of\npreference relations deeply connected to prioritised bases, can be used to\ncharacterise belief change operators, focusing on well-known postulates of\nIterated Belief Change. We provide syntactic representations of belief change\noperators in a dynamic context, as well as new negative results regarding the\npossibility of representing an iterated belief revision operation using\ntransformations on priority graphs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 00:14:26 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Souza", "Marlo", ""], ["Moreira", "\u00c1lvaro", ""], ["Vieira", "Renata", ""]]}, {"id": "1902.06239", "submitter": "Babak Badnava", "authors": "Babak Badnava and Nasser Mozayani", "title": "A new Potential-Based Reward Shaping for Reinforcement Learning Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential-based reward shaping (PBRS) is a particular category of machine\nlearning methods which aims to improve the learning speed of a reinforcement\nlearning agent by extracting and utilizing extra knowledge while performing a\ntask. There are two steps in the process of transfer learning: extracting\nknowledge from previously learned tasks and transferring that knowledge to use\nit in a target task. The latter step is well discussed in the literature with\nvarious methods being proposed for it, while the former has been explored less.\nWith this in mind, the type of knowledge that is transmitted is very important\nand can lead to considerable improvement. Among the literature of both the\ntransfer learning and the potential-based reward shaping, a subject that has\nnever been addressed is the knowledge gathered during the learning process\nitself. In this paper, we presented a novel potential-based reward shaping\nmethod that attempted to extract knowledge from the learning process. The\nproposed method extracts knowledge from episodes' cumulative rewards. The\nproposed method has been evaluated in the Arcade learning environment and the\nresults indicate an improvement in the learning process in both the single-task\nand the multi-task reinforcement learner agents.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 10:34:18 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 07:49:15 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Badnava", "Babak", ""], ["Mozayani", "Nasser", ""]]}, {"id": "1902.06335", "submitter": "Christian Kroer", "authors": "Christian Kroer and Tuomas Sandholm", "title": "Limited Lookahead in Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited lookahead has been studied for decades in perfect-information games.\nWe initiate a new direction via two simultaneous deviation points:\ngeneralization to imperfect-information games and a game-theoretic approach. We\nstudy how one should act when facing an opponent whose lookahead is limited. We\nstudy this for opponents that differ based on their lookahead depth, based on\nwhether they, too, have imperfect information, and based on how they break\nties. We characterize the hardness of finding a Nash equilibrium or an optimal\ncommitment strategy for either player, showing that in some of these variations\nthe problem can be solved in polynomial time while in others it is PPAD-hard,\nNP-hard, or inapproximable. We proceed to design algorithms for computing\noptimal commitment strategies---for when the opponent breaks ties favorably,\naccording to a fixed rule, or adversarially. We then experimentally investigate\nthe impact of limited lookahead. The limited-lookahead player often obtains the\nvalue of the game if she knows the expected values of nodes in the game tree\nfor some equilibrium---but we prove this is not sufficient in general. Finally,\nwe study the impact of noise in those estimates and different lookahead depths.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 21:50:05 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 13:42:28 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1902.06349", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, Armando Solar-Lezama", "title": "Learning to Infer Program Sketches", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to build systems which write code automatically from the kinds of\nspecifications humans can most easily provide, such as examples and natural\nlanguage instruction. The key idea of this work is that a flexible combination\nof pattern recognition and explicit reasoning can be used to solve these\ncomplex programming problems. We propose a method for dynamically integrating\nthese types of information. Our novel intermediate representation and training\nalgorithm allow a program synthesis system to learn, without direct\nsupervision, when to rely on pattern recognition and when to perform symbolic\nsearch. Our model matches the memorization and generalization performance of\nneural synthesis and symbolic search, respectively, and achieves\nstate-of-the-art performance on a dataset of simple English description-to-code\nprogramming problems.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 23:21:34 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 21:36:48 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Nye", "Maxwell", ""], ["Hewitt", "Luke", ""], ["Tenenbaum", "Joshua", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1902.06370", "submitter": "Chen Wang", "authors": "Chen Wang, Hui Ma, Gang Chen and Sven Hartmann", "title": "Evolutionary Multitasking for Semantic Web Service Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web services are basic functions of a software system to support the concept\nof service-oriented architecture. They are often composed together to provide\nadded values, known as web service composition. Researchers often employ\nEvolutionary Computation techniques to efficiently construct composite services\nwith near-optimized functional quality (i.e., Quality of Semantic Matchmaking)\nor non-functional quality (i.e., Quality of Service) or both due to the\ncomplexity of this problem. With a significant increase in service composition\nrequests, many composition requests have similar input and output requirements\nbut may vary due to different preferences from different user segments. This\nproblem is often treated as a multi-objective service composition so as to cope\nwith different preferences from different user segments simultaneously. Without\ntaking a multi-objective approach that gives rise to a solution selection\nchallenge, we perceive multiple similar service composition requests as jointly\nforming an evolutionary multi-tasking problem in this work. We propose an\neffective permutation-based evolutionary multi-tasking approach that can\nsimultaneously generate a set of solutions, with one for each service request.\nWe also introduce a neighborhood structure over multiple tasks to allow newly\nevolved solutions to be evaluated on related tasks. Our proposed method can\nperform better at the cost of only a fraction of time, compared to one\nstate-of-art single-tasking EC-based method. We also found that the use of the\nproper neighborhood structure can enhance the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 01:22:02 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wang", "Chen", ""], ["Ma", "Hui", ""], ["Chen", "Gang", ""], ["Hartmann", "Sven", ""]]}, {"id": "1902.06377", "submitter": "Yu Zhao", "authors": "Yu Zhao and Ji Liu", "title": "SCEF: A Support-Confidence-aware Embedding Framework for Knowledge Graph\n  Refinement", "comments": "(1)the model are unreasonable;(2)the experiments are unfair to\n  baselines;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph (KG) refinement mainly aims at KG completion and correction\n(i.e., error detection). However, most conventional KG embedding models only\nfocus on KG completion with an unreasonable assumption that all facts in KG\nhold without noises, ignoring error detection which also should be significant\nand essential for KG refinement.In this paper, we propose a novel\nsupport-confidence-aware KG embedding framework (SCEF), which implements KG\ncompletion and correction simultaneously by learning knowledge representations\nwith both triple support and triple confidence. Specifically, we build model\nenergy function by incorporating conventional translation-based model with\nsupport and confidence. To make our triple support-confidence more sufficient\nand robust, we not only consider the internal structural information in KG,\nstudying the approximate relation entailment as triple confidence constraints,\nbut also the external textual evidence, proposing two kinds of triple supports\nwith entity types and descriptions respectively.Through extensive experiments\non real-world datasets, we demonstrate SCEF's effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 02:00:23 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 02:07:10 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhao", "Yu", ""], ["Liu", "Ji", ""]]}, {"id": "1902.06410", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen, Atsushi Masumori, Ikegami Takashi", "title": "Reactive, Proactive, and Inductive Agents: An evolutionary path for\n  biological and artificial spiking networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex environments provide structured yet variable sensory inputs. To best\nexploit information from these environments, organisms must evolve the ability\nto anticipate consequences of unknown stimuli, and act on these predictions. We\npropose an evolutionary path for neural networks, leading an organism from\nreactive behavior to simple proactive behavior and from simple proactive\nbehavior to induction-based behavior. Through in-vitro and in-silico\nexperiments, we define the conditions necessary in a network with spike-timing\ndependent plasticity for the organism to go from reactive to proactive\nbehavior. Our results support the existence of specific evolutionary steps and\nfour conditions necessary for embodied neural networks to evolve predictive and\ninductive abilities from an initial reactive strategy. We extend these\nconditions to more general structures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 05:38:39 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 06:58:49 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Sinapayen", "Lana", ""], ["Masumori", "Atsushi", ""], ["Takashi", "Ikegami", ""]]}, {"id": "1902.06527", "submitter": "Woojun Kim", "authors": "Woojun Kim, Myungsik Cho, Youngchul Sung", "title": "Message-Dropout: An Efficient Training Method for Multi-Agent Deep\n  Reinforcement Learning", "comments": "The 33rd AAAI Conference on Artificial Intelligence (AAAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new learning technique named message-dropout to\nimprove the performance for multi-agent deep reinforcement learning under two\napplication scenarios: 1) classical multi-agent reinforcement learning with\ndirect message communication among agents and 2) centralized training with\ndecentralized execution. In the first application scenario of multi-agent\nsystems in which direct message communication among agents is allowed, the\nmessage-dropout technique drops out the received messages from other agents in\na block-wise manner with a certain probability in the training phase and\ncompensates for this effect by multiplying the weights of the dropped-out block\nunits with a correction probability. The applied message-dropout technique\neffectively handles the increased input dimension in multi-agent reinforcement\nlearning with communication and makes learning robust against communication\nerrors in the execution phase. In the second application scenario of\ncentralized training with decentralized execution, we particularly consider the\napplication of the proposed message-dropout to Multi-Agent Deep Deterministic\nPolicy Gradient (MADDPG), which uses a centralized critic to train a\ndecentralized actor for each agent. We evaluate the proposed message-dropout\ntechnique for several games, and numerical results show that the proposed\nmessage-dropout technique with proper dropout rate improves the reinforcement\nlearning performance significantly in terms of the training speed and the\nsteady-state performance in the execution phase.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:40:29 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kim", "Woojun", ""], ["Cho", "Myungsik", ""], ["Sung", "Youngchul", ""]]}, {"id": "1902.06632", "submitter": "Tim Lyon", "authors": "Kees van Berkel and Tim Lyon", "title": "Appendix for: Cut-free Calculi and Relational Semantics for Temporal\n  STIT logics", "comments": "Appendix to paper \"Cut-free Calculi and Relational Semantics for\n  Temporal STIT logics\", accepted to the 16th Joint European Conference on\n  Logics in Artificial Intelligence (JELIA 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an appendix to the paper \"Cut-free Calculi and Relational\nSemantics for Temporal STIT logics\" by Berkel and Lyon, 2019. It provides the\ncompleteness proof for the basic STIT logic Ldm (relative to irreflexive,\ntemporal Kripke STIT frames) as well as gives the derivation of the\nindependence of agents axiom for the logic Xstit.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 16:13:22 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["van Berkel", "Kees", ""], ["Lyon", "Tim", ""]]}, {"id": "1902.06670", "submitter": "Olivera Kotevska", "authors": "Olivera Kotevska", "title": "Increasing city safety awareness regarding disruptive traffic stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transportation systems serve the people in essence, in this study we focus in\ntraffic information related to violation events to respond to safety\nrequirements of the cities. Traffic violation events have an important role in\ncity safety awareness and secure travel. In this work, we describe the use of\nknowledge discovery from traffic violation reports in combination with\ndemographics approach using inductive logic programming to automatically\nextract knowledge about traffic violation behavior and their impact on the\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:36:44 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kotevska", "Olivera", ""]]}, {"id": "1902.06744", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Using Machine Learning to Guide Cognitive Modeling: A Case Study in\n  Moral Reasoning", "comments": "Camera ready version for Cognitive Science Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale behavioral datasets enable researchers to use complex machine\nlearning algorithms to better predict human behavior, yet this increased\npredictive power does not always lead to a better understanding of the behavior\nin question. In this paper, we outline a data-driven, iterative procedure that\nallows cognitive scientists to use machine learning to generate models that are\nboth interpretable and accurate. We demonstrate this method in the domain of\nmoral decision-making, where standard experimental approaches often identify\nrelevant principles that influence human judgments, but fail to generalize\nthese findings to \"real world\" situations that place these principles in\nconflict. The recently released Moral Machine dataset allows us to build a\npowerful model that can predict the outcomes of these conflicts while remaining\nsimple enough to explain the basis behind human decisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:01:05 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 23:34:57 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:57:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1902.06766", "submitter": "Ilya Feige", "authors": "Christopher Frye, Ilya Feige", "title": "Parenting: Safe Reinforcement Learning from Human Input", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents trained via reinforcement learning present numerous safety\nconcerns: reward hacking, negative side effects, and unsafe exploration, among\nothers. In the context of near-future autonomous agents, operating in\nenvironments where humans understand the existing dangers, human involvement in\nthe learning process has proved a promising approach to AI Safety. Here we\ndemonstrate that a precise framework for learning from human input, loosely\ninspired by the way humans parent children, solves a broad class of safety\nproblems in this context. We show that our Parenting algorithm solves these\nproblems in the relevant AI Safety gridworlds of Leike et al. (2017), that an\nagent can learn to outperform its parent as it \"matures\", and that policies\nlearnt through Parenting are generalisable to new environments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:10:18 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Frye", "Christopher", ""], ["Feige", "Ilya", ""]]}, {"id": "1902.06804", "submitter": "Alexander Wong", "authors": "Raymond Bond, Ansgar Koene, Alan Dix, Jennifer Boger, Maurice D.\n  Mulvenna, Mykola Galushka, Bethany Waterhouse Bradley, Fiona Browne, Hui\n  Wang, and Alexander Wong", "title": "Democratisation of Usable Machine Learning in Computer Vision", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many industries are now investing heavily in data science and automation to\nreplace manual tasks and/or to help with decision making, especially in the\nrealm of leveraging computer vision to automate many monitoring, inspection,\nand surveillance tasks. This has resulted in the emergence of the 'data\nscientist' who is conversant in statistical thinking, machine learning (ML),\ncomputer vision, and computer programming. However, as ML becomes more\naccessible to the general public and more aspects of ML become automated,\napplications leveraging computer vision are increasingly being created by\nnon-experts with less opportunity for regulatory oversight. This points to the\noverall need for more educated responsibility for these lay-users of usable ML\ntools in order to mitigate potentially unethical ramifications. In this paper,\nwe undertake a SWOT analysis to study the strengths, weaknesses, opportunities,\nand threats of building usable ML tools for mass adoption for important areas\nleveraging ML such as computer vision. The paper proposes a set of data science\nliteracy criteria for educating and supporting lay-users in the responsible\ndevelopment and deployment of ML applications.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 21:22:45 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Bond", "Raymond", ""], ["Koene", "Ansgar", ""], ["Dix", "Alan", ""], ["Boger", "Jennifer", ""], ["Mulvenna", "Maurice D.", ""], ["Galushka", "Mykola", ""], ["Bradley", "Bethany Waterhouse", ""], ["Browne", "Fiona", ""], ["Wang", "Hui", ""], ["Wong", "Alexander", ""]]}, {"id": "1902.06824", "submitter": "Syed Arbab Mohd Shihab", "authors": "Syed Arbab Mohd Shihab, Caleb Logemann, Deepak-George Thomas and Peng\n  Wei", "title": "Autonomous Airline Revenue Management: A Deep Reinforcement Learning\n  Approach to Seat Inventory Control and Overbooking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revenue management can enable airline corporations to maximize the revenue\ngenerated from each scheduled flight departing in their transportation network\nby means of finding the optimal policies for differential pricing, seat\ninventory control and overbooking. As different demand segments in the market\nhave different Willingness-To-Pay (WTP), airlines use differential pricing,\nbooking restrictions, and service amenities to determine different fare classes\nor products targeted at each of these demand segments. Because seats are\nlimited for each flight, airlines also need to allocate seats for each of these\nfare classes to prevent lower fare class passengers from displacing higher fare\nclass ones and set overbooking limits in anticipation of cancellations and\nno-shows such that revenue is maximized. Previous work addresses these problems\nusing optimization techniques or classical Reinforcement Learning methods. This\npaper focuses on the latter problem - the seat inventory control problem -\ncasting it as a Markov Decision Process to be able to find the optimal policy.\nMultiple fare classes, concurrent continuous arrival of passengers of different\nfare classes, overbooking and random cancellations that are independent of\nclass have been considered in the model. We have addressed this problem using\nDeep Q-Learning with the goal of maximizing the reward for each flight\ndeparture. The implementation of this technique allows us to employ large\ncontinuous state space but also presents the potential opportunity to test on\nreal time airline data. To generate data and train the agent, a basic\nair-travel market simulator was developed. The performance of the agent in\ndifferent simulated market scenarios was compared against theoretically optimal\nsolutions and was found to be nearly close to the expected optimal revenue.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 22:31:09 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 19:14:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Shihab", "Syed Arbab Mohd", ""], ["Logemann", "Caleb", ""], ["Thomas", "Deepak-George", ""], ["Wei", "Peng", ""]]}, {"id": "1902.06853", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Arnaud Doucet, Judith Rousseau", "title": "On the Impact of the Activation Function on Deep Neural Networks\n  Training", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weight initialization and the activation function of deep neural networks\nhave a crucial impact on the performance of the training procedure. An\ninappropriate selection can lead to the loss of information of the input during\nforward propagation and the exponential vanishing/exploding of gradients during\nback-propagation. Understanding the theoretical properties of untrained random\nnetworks is key to identifying which deep networks may be trained successfully\nas recently demonstrated by Samuel et al (2017) who showed that for deep\nfeedforward neural networks only a specific choice of hyperparameters known as\nthe `Edge of Chaos' can lead to good performance. While the work by Samuel et\nal (2017) discuss trainability issues, we focus here on training acceleration\nand overall performance. We give a comprehensive theoretical analysis of the\nEdge of Chaos and show that we can indeed tune the initialization parameters\nand the activation function in order to accelerate the training and improve the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 00:50:19 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 18:52:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hayou", "Soufiane", ""], ["Doucet", "Arnaud", ""], ["Rousseau", "Judith", ""]]}, {"id": "1902.06897", "submitter": "Shubham Gupta", "authors": "Shubham Gupta and Ambedkar Dukkipati", "title": "Winning an Election: On Emergent Strategic Communication in Multi-Agent\n  Networks", "comments": "A shorter version of this paper has been accepted as an extended\n  abstract at AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans use language to collectively execute abstract strategies besides using\nit as a referential tool for identifying physical entities. Recently, multiple\nattempts at replicating the process of emergence of language in artificial\nagents have been made. While existing approaches study emergent languages as\nreferential tools, in this paper, we study their role in discovering and\nimplementing strategies. We formulate the problem using a voting game where two\ncandidate agents contest in an election with the goal of convincing population\nmembers (other agents), that are connected to each other via an underlying\nnetwork, to vote for them. To achieve this goal, agents are only allowed to\nexchange messages in the form of sequences of discrete symbols to spread their\npropaganda. We use neural networks with Gumbel-Softmax relaxation for sampling\ncategorical random variables to parameterize the policies followed by all\nagents. Using our proposed framework, we provide concrete answers to the\nfollowing questions: (i) Do the agents learn to communicate in a meaningful way\nand does the emergent communication play a role in deciding the winner? (ii)\nDoes the system evolve as expected under various reward structures? (iii) How\nis the emergent language affected by the community structure in the network? To\nthe best of our knowledge, we are the first to explore emergence of\ncommunication for discovering and implementing strategies in a setting where\nagents communicate over a network.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 05:14:14 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 05:41:09 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gupta", "Shubham", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1902.07015", "submitter": "Olivier Sigaud", "authors": "Chenyang Zhao, Olivier Sigaud, Freek Stulp, Timothy M. Hospedales", "title": "Investigating Generalisation in Continuous Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has shown great success in a variety of control\ntasks. However, it is unclear how close we are to the vision of putting Deep RL\ninto practice to solve real world problems. In particular, common practice in\nthe field is to train policies on largely deterministic simulators and to\nevaluate algorithms through training performance alone, without a train/test\ndistinction to ensure models generalise and are not overfitted. Moreover, it is\nnot standard practice to check for generalisation under domain shift, although\nrobustness to such system change between training and testing would be\nnecessary for real-world Deep RL control, for example, in robotics. In this\npaper we study these issues by first characterising the sources of uncertainty\nthat provide generalisation challenges in Deep RL. We then provide a new\nbenchmark and thorough empirical evaluation of generalisation challenges for\nstate of the art Deep RL methods. In particular, we show that, if\ngeneralisation is the goal, then common practice of evaluating algorithms based\non their training performance leads to the wrong conclusions about algorithm\nchoice. Finally, we evaluate several techniques for improving generalisation\nand draw conclusions about the most robust techniques to date.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 12:20:36 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 16:19:07 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Zhao", "Chenyang", ""], ["Sigaud", "Olivier", ""], ["Stulp", "Freek", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1902.07102", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Kimmo Karkkainen, Orpaz Goldstein, Davina\n  Zamanzadeh, and Majid Sarrafzadeh", "title": "Cost-Sensitive Diagnosis and Learning Leveraging Public Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, machine learning algorithms rely on the assumption that all\nfeatures of a given dataset are available for free. However, there are many\nconcerns such as monetary data collection costs, patient discomfort in medical\nprocedures, and privacy impacts of data collection that require careful\nconsideration in any real-world health analytics system. An efficient solution\nwould only acquire a subset of features based on the value it provides while\nconsidering acquisition costs. Moreover, datasets that provide feature costs\nare very limited, especially in healthcare. In this paper, we provide a health\ndataset as well as a method for assigning feature costs based on the total\nlevel of inconvenience asking for each feature entails. Furthermore, based on\nthe suggested dataset, we provide a comparison of recent and state-of-the-art\napproaches to cost-sensitive feature acquisition and learning. Specifically, we\nanalyze the performance of major sensitivity-based and reinforcement learning\nbased methods in the literature on three different problems in the health\ndomain, including diabetes, heart disease, and hypertension classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 15:37:13 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 22:28:15 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Goldstein", "Orpaz", ""], ["Zamanzadeh", "Davina", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1902.07151", "submitter": "Siqi Liu", "authors": "Siqi Liu, Guy Lever, Josh Merel, Saran Tunyasuvunakool, Nicolas Heess,\n  Thore Graepel", "title": "Emergent Coordination Through Competition", "comments": null, "journal-ref": "ICLR (2019)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence of cooperative behaviors in reinforcement learning\nagents by introducing a challenging competitive multi-agent soccer environment\nwith continuous simulated physics. We demonstrate that decentralized,\npopulation-based training with co-play can lead to a progression in agents'\nbehaviors: from random, to simple ball chasing, and finally showing evidence of\ncooperation. Our study highlights several of the challenges encountered in\nlarge scale multi-agent training in continuous control. In particular, we\ndemonstrate that the automatic optimization of simple shaping rewards, not\nthemselves conducive to co-operative behavior, can lead to long-horizon team\nbehavior. We further apply an evaluation scheme, grounded by game theoretic\nprincipals, that can assess agent performance in the absence of pre-defined\nevaluation tasks or human baselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 17:18:14 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 14:20:32 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Liu", "Siqi", ""], ["Lever", "Guy", ""], ["Merel", "Josh", ""], ["Tunyasuvunakool", "Saran", ""], ["Heess", "Nicolas", ""], ["Graepel", "Thore", ""]]}, {"id": "1902.07178", "submitter": "Jinxi Guo", "authors": "Jinxi Guo, Tara N. Sainath, Ron J. Weiss", "title": "A spelling correction model for end-to-end speech recognition", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models for speech recognition jointly\ntrain an acoustic model, language model (LM), and alignment mechanism using a\nsingle neural network and require only parallel audio-text pairs. Thus, the\nlanguage model component of the end-to-end model is only trained on transcribed\naudio-text pairs, which leads to performance degradation especially on rare\nwords. While there have been a variety of work that look at incorporating an\nexternal LM trained on text-only data into the end-to-end framework, none of\nthem have taken into account the characteristic error distribution made by the\nmodel. In this paper, we propose a novel approach to utilizing text-only data,\nby training a spelling correction (SC) model to explicitly correct those\nerrors. On the LibriSpeech dataset, we demonstrate that the proposed model\nresults in an 18.6% relative improvement in WER over the baseline model when\ndirectly correcting top ASR hypothesis, and a 29.0% relative improvement when\nfurther rescoring an expanded n-best list using an external LM.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:18:59 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Guo", "Jinxi", ""], ["Sainath", "Tara N.", ""], ["Weiss", "Ron J.", ""]]}, {"id": "1902.07198", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Chen Liang, Dale Schuurmans, Mohammad Norouzi", "title": "Learning to Generalize from Sparse and Underspecified Rewards", "comments": "ICML 2019", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:130-140, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from sparse and underspecified rewards,\nwhere an agent receives a complex input, such as a natural language\ninstruction, and needs to generate a complex response, such as an action\nsequence, while only receiving binary success-failure feedback. Such\nsuccess-failure rewards are often underspecified: they do not distinguish\nbetween purposeful and accidental success. Generalization from underspecified\nrewards hinges on discounting spurious trajectories that attain accidental\nsuccess, while learning from sparse feedback requires effective exploration. We\naddress exploration by using a mode covering direction of KL divergence to\ncollect a diverse set of successful trajectories, followed by a mode seeking KL\ndivergence to train a robust policy. We propose Meta Reward Learning (MeRL) to\nconstruct an auxiliary reward function that provides more refined feedback for\nlearning. The parameters of the auxiliary reward function are optimized with\nrespect to the validation performance of a trained policy. The MeRL approach\noutperforms our alternative reward learning technique based on Bayesian\nOptimization, and achieves the state-of-the-art on weakly-supervised semantic\nparsing. It improves previous work by 1.2% and 2.4% on WikiTableQuestions and\nWikiSQL datasets respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 18:51:10 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 07:21:04 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 18:21:10 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 20:54:19 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Liang", "Chen", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1902.07280", "submitter": "Chris Mesterharm", "authors": "Chris Mesterharm and Rauf Izmailov and Scott Alexander and Simon Tsang", "title": "Subspace Methods That Are Resistant to a Limited Number of Features\n  Corrupted by an Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider batch supervised learning where an adversary is\nallowed to corrupt instances with arbitrarily large noise. The adversary is\nallowed to corrupt any $l$ features in each instance and the adversary can\nchange their values in any way. This noise is introduced on test instances and\nthe algorithm receives no label feedback for these instances. We provide\nseveral subspace voting techniques that can be used to transform existing\nalgorithms and prove data-dependent performance bounds in this setting. The key\ninsight to our results is that we set our parameters so that a significant\nfraction of the voting hypotheses do not contain corrupt features and, for many\nreal world problems, these uncorrupt hypotheses are sufficient to achieve high\naccuracy. We empirically validate our approach on several datasets including\nthree new datasets that deal with side channel electromagnetic information.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 20:55:01 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 16:44:32 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mesterharm", "Chris", ""], ["Izmailov", "Rauf", ""], ["Alexander", "Scott", ""], ["Tsang", "Simon", ""]]}, {"id": "1902.07282", "submitter": "Linfeng Song", "authors": "Linfeng Song, Daniel Gildea, Yue Zhang, Zhiguo Wang and Jinsong Su", "title": "Semantic Neural Machine Translation using AMR", "comments": "Transaction of ACL 2019", "journal-ref": "Transactions of the Association for Computational Linguistics, 7,\n  pages19-31, 2019", "doi": "10.1162/tacl_a_00252", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is intuitive that semantic representations can be useful for machine\ntranslation, mainly because they can help in enforcing meaning preservation and\nhandling data sparsity (many sentences correspond to one meaning) of machine\ntranslation models. On the other hand, little work has been done on leveraging\nsemantics for neural machine translation (NMT). In this work, we study the\nusefulness of AMR (short for abstract meaning representation) on NMT.\nExperiments on a standard English-to-German dataset show that incorporating AMR\nas additional knowledge can significantly improve a strong attention-based\nsequence-to-sequence neural translation model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 21:03:35 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Song", "Linfeng", ""], ["Gildea", "Daniel", ""], ["Zhang", "Yue", ""], ["Wang", "Zhiguo", ""], ["Su", "Jinsong", ""]]}, {"id": "1902.07422", "submitter": "Yi-Fan Song", "authors": "Jie Wang, Yi-Fan Song and Tian-Lei Ma", "title": "Mexican Hat Wavelet Kernel ELM for Multiclass Classification", "comments": "Published by Computational Intelligence and Neuroscience, 8 pages, 1\n  figure, 13 tables", "journal-ref": "Volume 2017, 2017: 1-8", "doi": "10.1155/2017/7479140", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel extreme learning machine (KELM) is a novel feedforward neural network,\nwhich is widely used in classification problems. To some extent, it solves the\nexisting problems of the invalid nodes and the large computational complexity\nin ELM. However, the traditional KELM classifier usually has a low test\naccuracy when it faces multiclass classification problems. In order to solve\nthe above problem, a new classifier, Mexican Hat wavelet KELM classifier, is\nproposed in this paper. The proposed classifier successfully improves the\ntraining accuracy and reduces the training time in the multiclass\nclassification problems. Moreover, the validity of the Mexican Hat wavelet as a\nkernel function of ELM is rigorously proved. Experimental results on different\ndata sets show that the performance of the proposed classifier is significantly\nsuperior to the compared classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 05:57:58 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Wang", "Jie", ""], ["Song", "Yi-Fan", ""], ["Ma", "Tian-Lei", ""]]}, {"id": "1902.07501", "submitter": "Sascha Fleer", "authors": "Sascha Fleer, Alexandra Moringen, Roberta L. Klatzky, Helge Ritter", "title": "Learning efficient haptic shape exploration with a rigid tactile sensor\n  array", "comments": null, "journal-ref": "PLOS ONE 15(1): e0226880 (2020)", "doi": "10.1371/journal.pone.0226880", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haptic exploration is a key skill for both robots and humans to discriminate\nand handle unknown objects or to recognize familiar objects. Its active nature\nis evident in humans who from early on reliably acquire sophisticated\nsensory-motor capabilities for active exploratory touch and directed manual\nexploration that associates surfaces and object properties with their spatial\nlocations. This is in stark contrast to robotics. In this field, the relative\nlack of good real-world interaction models - along with very restricted sensors\nand a scarcity of suitable training data to leverage machine learning methods -\nhas so far rendered haptic exploration a largely underdeveloped skill. In the\npresent work, we connect recent advances in recurrent models of visual\nattention with previous insights about the organisation of human haptic search\nbehavior, exploratory procedures and haptic glances for a novel architecture\nthat learns a generative model of haptic exploration in a simulated\nthree-dimensional environment. The proposed algorithm simultaneously optimizes\nmain perception-action loop components: feature extraction, integration of\nfeatures over time, and the control strategy, while continuously acquiring data\nonline. We perform a multi-module neural network training, including a feature\nextractor and a recurrent neural network module aiding pose control for storing\nand combining sequential sensory data. The resulting haptic meta-controller for\nthe rigid $16 \\times 16$ tactile sensor array moving in a physics-driven\nsimulation environment, called the Haptic Attention Model, performs a sequence\nof haptic glances, and outputs corresponding force measurements. The resulting\nmethod has been successfully tested with four different objects. It achieved\nresults close to $100 \\%$ while performing object contour exploration that has\nbeen optimized for its own sensor morphology.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 10:51:10 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 09:51:55 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 07:59:07 GMT"}, {"version": "v4", "created": "Sun, 26 Jan 2020 14:13:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fleer", "Sascha", ""], ["Moringen", "Alexandra", ""], ["Klatzky", "Roberta L.", ""], ["Ritter", "Helge", ""]]}, {"id": "1902.07526", "submitter": "Kristijonas \\v{C}yras", "authors": "Kristijonas \\v{C}yras, Tiago Oliveira", "title": "Resolving Conflicts in Clinical Guidelines using Argumentation", "comments": "Paper accepted for publication at AAAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically reasoning with conflicting generic clinical guidelines is a\nburning issue in patient-centric medical reasoning where patient-specific\nconditions and goals need to be taken into account. It is even more challenging\nin the presence of preferences such as patient's wishes and clinician's\npriorities over goals. We advance a structured argumentation formalism for\nreasoning with conflicting clinical guidelines, patient-specific information\nand preferences. Our formalism integrates assumption-based reasoning and\ngoal-driven selection among reasoning outcomes. Specifically, we assume\napplicability of guideline recommendations concerning the generic goal of\npatient well-being, resolve conflicts among recommendations using patient's\nconditions and preferences, and then consider prioritised patient-centered\ngoals to yield non-conflicting, goal-maximising and preference-respecting\nrecommendations. We rely on the state-of-the-art Transition-based Medical\nRecommendation model for representing guideline recommendations and augment it\nwith context given by the patient's conditions, goals, as well as preferences\nover recommendations and goals. We establish desirable properties of our\napproach in terms of sensitivity to recommendation conflicts and patient\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 11:55:02 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["\u010cyras", "Kristijonas", ""], ["Oliveira", "Tiago", ""]]}, {"id": "1902.07651", "submitter": "Victor Boutin", "authors": "Victor Boutin, Angelo Franciosini, Frederic Chavane, Franck Ruffier,\n  Laurent Perrinet", "title": "Sparse Deep Predictive Coding captures contour integration capabilities\n  of the early visual system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both neurophysiological and psychophysical experiments have pointed out the\ncrucial role of recurrent and feedback connections to process context-dependent\ninformation in the early visual cortex. While numerous models have accounted\nfor feedback effects at either neural or representational level, none of them\nwere able to bind those two levels of analysis. Is it possible to describe\nfeedback effects at both levels using the same model? We answer this question\nby combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical\nand convolutional framework. In this Sparse Deep Predictive Coding (SDPC)\nmodel, the SC component models the internal recurrent processing within each\nlayer, and the PC component describes the interactions between layers using\nfeedforward and feedback connections. Here, we train a 2-layered SDPC on two\ndifferent databases of images, and we interpret it as a model of the early\nvisual system (V1 & V2). We first demonstrate that once the training has\nconverged, SDPC exhibits oriented and localized receptive fields in V1 and more\ncomplex features in V2. Second, we analyze the effects of feedback on the\nneural organization beyond the classical receptive field of V1 neurons using\ninteraction maps. These maps are similar to association fields and reflect the\nGestalt principle of good continuation. We demonstrate that feedback signals\nreorganize interaction maps and modulate neural activity to promote contour\nintegration. Third, we demonstrate at the representational level that the SDPC\nfeedback connections are able to overcome noise in input images. Therefore, the\nSDPC captures the association field principle at the neural level which results\nin better disambiguation of blurred images at the representational level.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:06:00 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 07:43:28 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 15:46:21 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Boutin", "Victor", ""], ["Franciosini", "Angelo", ""], ["Chavane", "Frederic", ""], ["Ruffier", "Franck", ""], ["Perrinet", "Laurent", ""]]}, {"id": "1902.07656", "submitter": "{\\L}ukasz Maziarka", "authors": "Bartosz W\\'ojcik, {\\L}ukasz Maziarka, Jacek Tabor", "title": "LOSSGRAD: automatic learning rate in gradient descent", "comments": "TFML 2019", "journal-ref": "Schedae Informaticae, 2018, Volume 27", "doi": "10.4467/20838476SI.18.004.10409", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple, fast and easy to implement algorithm\nLOSSGRAD (locally optimal step-size in gradient descent), which automatically\nmodifies the step-size in gradient descent during neural networks training.\nGiven a function $f$, a point $x$, and the gradient $\\nabla_x f$ of $f$, we aim\nto find the step-size $h$ which is (locally) optimal, i.e. satisfies: $$\nh=arg\\,min_{t \\geq 0} f(x-t \\nabla_x f). $$ Making use of quadratic\napproximation, we show that the algorithm satisfies the above assumption. We\nexperimentally show that our method is insensitive to the choice of initial\nlearning rate while achieving results comparable to other methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 17:11:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["Maziarka", "\u0141ukasz", ""], ["Tabor", "Jacek", ""]]}, {"id": "1902.07685", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Mohammad Gheshlaghi Azar and Bilal Piot and Bernardo Avila Pires and\n  Jean-Bastien Grill and Florent Altch\\'e and R\\'emi Munos", "title": "World Discovery Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans we are driven by a strong desire for seeking novelty in our world.\nAlso upon observing a novel pattern we are capable of refining our\nunderstanding of the world based on the new information---humans can discover\ntheir world. The outstanding ability of the human mind for discovery has led to\nmany breakthroughs in science, art and technology. Here we investigate the\npossibility of building an agent capable of discovering its world using the\nmodern AI technology. In particular we introduce NDIGO, Neural Differential\nInformation Gain Optimisation, a self-supervised discovery model that aims at\nseeking new information to construct a global view of its world from partial\nand noisy observations. Our experiments on some controlled 2-D navigation tasks\nshow that NDIGO outperforms state-of-the-art information-seeking methods in\nterms of the quality of the learned representation. The improvement in\nperformance is particularly significant in the presence of white or structured\nnoise where other information-seeking methods follow the noise instead of\ndiscovering their world.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 18:07:18 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 15:21:34 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2019 20:25:58 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Azar", "Mohammad Gheshlaghi", ""], ["Piot", "Bilal", ""], ["Pires", "Bernardo Avila", ""], ["Grill", "Jean-Bastien", ""], ["Altch\u00e9", "Florent", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1902.07741", "submitter": "Jorge Fandinno", "authors": "Pedro Cabalar, Jorge Fandinno and Luis Fari\\~nas", "title": "Founded World Views with Autoepistemic Equilibrium Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defined by Gelfond in 1991 (G91), epistemic specifications (or programs) are\nan extension of logic programming under stable models semantics that\nintroducessubjective literals. A subjective literal al-lows checking whether\nsome regular literal is true in all (or in some of) the stable models of the\nprogram, being those models collected in a setcalledworld view. One epistemic\nprogram may yield several world views but, under the original G91 semantics,\nsome of them resulted from self-supported derivations. During the last eight\nyears, several alternative approaches have been proposed to get rid of these\nself-supported worldviews. Unfortunately, their success could only be measured\nby studying their behaviour on a set of common examples in the literature,\nsince no formal property of \"self-supportedness\" had been defined. To fill this\ngap, we extend in this paper the idea of unfounded set from standard logic\nprogramming to the epistemic case. We define when a world view is founded with\nrespect to some program and propose the foundedness property for any semantics\nwhose world views are always founded. Using counterexamples, we explain that\nthe previous approaches violate foundedness, and proceed to propose a new\nsemantics based on a combination of Moore's Autoepistemic Logic and Pearce's\nEquilibrium Logic. The main result proves that this new semantics precisely\ncaptures the set of founded G91 world views.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 19:20:44 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["Fari\u00f1as", "Luis", ""]]}, {"id": "1902.07747", "submitter": "Ziran Wang", "authors": "Ziran Wang and Kyuntae Han and BaekGyu Kim and Guoyuan Wu and Matthew\n  J. Barth", "title": "Lookup Table-Based Consensus Algorithm for Real-Time Longitudinal Motion\n  Control of Connected and Automated Vehicles", "comments": "2019 American Control Conference (ACC)Philadelphia, PA, USA, July\n  10-12, 2019978-1-5386-7928-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and automated vehicle (CAV) technology is one of the promising\nsolutions to addressing the safety, mobility and sustainability issues of our\ncurrent transportation systems. Specifically, the control algorithm plays an\nimportant role in a CAV system, since it executes the commands generated by\nformer steps, such as communication, perception, and planning. In this study,\nwe propose a consensus algorithm to control the longitudinal motion of CAVs in\nreal time. Different from previous studies in this field where control gains of\nthe consensus algorithm are pre-determined and fixed, we develop algorithms to\nbuild up a lookup table, searching for the ideal control gains with respect to\ndifferent initial conditions of CAVs in real time. Numerical simulation shows\nthat, the proposed lookup table-based consensus algorithm outperforms the\nauthors' previous work, as well as van Arem's linear feedback-based\nlongitudinal motion control algorithm in all four different scenarios with\nvarious initial conditions of CAVs, in terms of convergence time and maximum\njerk of the simulation run.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 19:39:28 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 19:09:07 GMT"}, {"version": "v3", "created": "Sat, 20 Jul 2019 19:19:08 GMT"}, {"version": "v4", "created": "Sat, 27 Jul 2019 23:50:46 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wang", "Ziran", ""], ["Han", "Kyuntae", ""], ["Kim", "BaekGyu", ""], ["Wu", "Guoyuan", ""], ["Barth", "Matthew J.", ""]]}, {"id": "1902.07802", "submitter": "Xiaoxiao Wang", "authors": "Xueying Guo, Xiaoxiao Wang, Xin Liu", "title": "AdaLinUCB: Opportunistic Learning for Contextual Bandits", "comments": "IJCAI. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study opportunistic contextual bandits - a\nspecial case of contextual bandits where the exploration cost varies under\ndifferent environmental conditions, such as network load or return variation in\nrecommendations. When the exploration cost is low, so is the actual regret of\npulling a sub-optimal arm (e.g., trying a suboptimal recommendation).\nTherefore, intuitively, we could explore more when the exploration cost is\nrelatively low and exploit more when the exploration cost is relatively high.\nInspired by this intuition, for opportunistic contextual bandits with Linear\npayoffs, we propose an Adaptive Upper-Confidence-Bound algorithm (AdaLinUCB) to\nadaptively balance the exploration-exploitation trade-off for opportunistic\nlearning. We prove that AdaLinUCB achieves O((log T)^2) problem-dependent\nregret upper bound, which has a smaller coefficient than that of the\ntraditional LinUCB algorithm. Moreover, based on both synthetic and real-world\ndataset, we show that AdaLinUCB significantly outperforms other contextual\nbandit algorithms, under large exploration cost fluctuations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 22:35:24 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 03:44:15 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Guo", "Xueying", ""], ["Wang", "Xiaoxiao", ""], ["Liu", "Xin", ""]]}, {"id": "1902.07823", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang and Nisheeth K. Vishnoi", "title": "Stable and Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has been a topic of intense study in machine learning,\nand several algorithms have been proposed towards this important task. However,\nin a recent study, Friedler et al. observed that fair classification algorithms\nmay not be stable with respect to variations in the training dataset -- a\ncrucial consideration in several real-world applications. Motivated by their\nwork, we study the problem of designing classification algorithms that are both\nfair and stable. We propose an extended framework based on fair classification\nalgorithms that are formulated as optimization problems, by introducing a\nstability-focused regularization term. Theoretically, we prove a stability\nguarantee, that was lacking in fair classification algorithms, and also provide\nan accuracy guarantee for our extended framework. Our accuracy guarantee can be\nused to inform the selection of the regularization parameter in our framework.\nTo the best of our knowledge, this is the first work that combines stability\nand fairness in automated decision-making tasks. We assess the benefits of our\napproach empirically by extending several fair classification algorithms that\nare shown to achieve the best balance between fairness and accuracy over the\nAdult dataset. Our empirical results show that our framework indeed improves\nthe stability at only a slight sacrifice in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 00:56:14 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:15:32 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 16:22:18 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 12:32:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Huang", "Lingxiao", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1902.07831", "submitter": "Yilun Zhou", "authors": "Yilun Zhou, Steven Schockaert, Julie A. Shah", "title": "Predicting ConceptNet Path Quality Using Crowdsourced Assessments of\n  Naturalness", "comments": "In Proceedings of the Web Conference (WWW) 2019", "journal-ref": null, "doi": "10.1145/3308558.3313486", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications, it is important to characterize the way in which two\nconcepts are semantically related. Knowledge graphs such as ConceptNet provide\na rich source of information for such characterizations by encoding relations\nbetween concepts as edges in a graph. When two concepts are not directly\nconnected by an edge, their relationship can still be described in terms of the\npaths that connect them. Unfortunately, many of these paths are uninformative\nand noisy, which means that the success of applications that use such path\nfeatures crucially relies on their ability to select high-quality paths. In\nexisting applications, this path selection process is based on relatively\nsimple heuristics. In this paper we instead propose to learn to predict path\nquality from crowdsourced human assessments. Since we are interested in a\ngeneric task-independent notion of quality, we simply ask human participants to\nrank paths according to their subjective assessment of the paths' naturalness,\nwithout attempting to define naturalness or steering the participants towards\nparticular indicators of quality. We show that a neural network model trained\non these assessments is able to predict human judgments on unseen paths with\nnear optimal performance. Most notably, we find that the resulting path\nselection method is substantially better than the current heuristic approaches\nat identifying meaningful paths.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 01:12:07 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Zhou", "Yilun", ""], ["Schockaert", "Steven", ""], ["Shah", "Julie A.", ""]]}, {"id": "1902.07864", "submitter": "Ramakrishna Vedantam", "authors": "Ramakrishna Vedantam, Karan Desai, Stefan Lee, Marcus Rohrbach, Dhruv\n  Batra, Devi Parikh", "title": "Probabilistic Neural-symbolic Models for Interpretable Visual Question\n  Answering", "comments": "ICML 2019 Camera Ready + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of probabilistic neural-symbolic models, that have\nsymbolic functional programs as a latent, stochastic variable. Instantiated in\nthe context of visual question answering, our probabilistic formulation offers\ntwo key conceptual advantages over prior neural-symbolic models for VQA.\nFirstly, the programs generated by our model are more understandable while\nrequiring lesser number of teaching examples. Secondly, we show that one can\npose counterfactual scenarios to the model, to probe its beliefs on the\nprograms that could lead to a specified answer given an image. Our results on\nthe CLEVR and SHAPES datasets verify our hypotheses, showing that the model\ngets better program (and answer) prediction accuracy even in the low data\nregime, and allows one to probe the coherence and consistency of reasoning\nperformed.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 04:55:56 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 22:12:00 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Vedantam", "Ramakrishna", ""], ["Desai", "Karan", ""], ["Lee", "Stefan", ""], ["Rohrbach", "Marcus", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1902.07867", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Chunyan Miao", "title": "ntuer at SemEval-2019 Task 3: Emotion Classification with Word and\n  Sentence Representations in RCNN", "comments": "SemEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our model on the task of emotion detection in\ntextual conversations in SemEval-2019. Our model extends the Recurrent\nConvolutional Neural Network (RCNN) by using external fine-tuned word\nrepresentations and DeepMoji sentence representations. We also explored several\nother competitive pre-trained word and sentence representations including ELMo,\nBERT and InferSent but found inferior performance. In addition, we conducted\nextensive sensitivity analysis, which empirically shows that our model is\nrelatively robust to hyper-parameters. Our model requires no handcrafted\nfeatures or emotion lexicons but achieved good performance with a micro-F1\nscore of 0.7463.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 05:16:45 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 02:29:57 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Zhong", "Peixiang", ""], ["Miao", "Chunyan", ""]]}, {"id": "1902.08039", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Curiosity-Driven Experience Prioritization via Density Estimation", "comments": "Accepted by NIPS Deep RL Workshop, 2018, link:\n  https://sites.google.com/view/deep-rl-workshop-nips-2018 . arXiv admin note:\n  substantial text overlap with arXiv:1810.01363 and text overlap with\n  arXiv:1905.08786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reinforcement Learning (RL), an agent explores the environment and\ncollects trajectories into the memory buffer for later learning. However, the\ncollected trajectories can easily be imbalanced with respect to the achieved\ngoal states. The problem of learning from imbalanced data is a well-known\nproblem in supervised learning, but has not yet been thoroughly researched in\nRL. To address this problem, we propose a novel Curiosity-Driven Prioritization\n(CDP) framework to encourage the agent to over-sample those trajectories that\nhave rare achieved goal states. The CDP framework mimics the human learning\nprocess and focuses more on relatively uncommon events. We evaluate our methods\nusing the robotic environment provided by OpenAI Gym. The environment contains\nsix robot manipulation tasks. In our experiments, we combined CDP with Deep\nDeterministic Policy Gradient (DDPG) with or without Hindsight Experience\nReplay (HER). The experimental results show that CDP improves both performance\nand sample-efficiency of reinforcement learning agents, compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 12:31:23 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 11:38:48 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:15:29 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1902.08093", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Unsupervised Grounding of Plannable First-Order Logic Representation\n  from Images", "comments": "Accepted in 29th International Conference of Automated Planning and\n  Scheduling (ICAPS-2019), Planning and Learning track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is an increasing interest in obtaining the relational\nstructures of the environment in the Reinforcement Learning community. However,\nthe resulting \"relations\" are not the discrete, logical predicates compatible\nto the symbolic reasoning such as classical planning or goal recognition.\nMeanwhile, Latplan (Asai and Fukunaga 2018) bridged the gap between\ndeep-learning perceptual systems and symbolic classical planners. One key\ncomponent of the system is a Neural Network called State AutoEncoder (SAE),\nwhich encodes an image-based input into a propositional representation\ncompatible to classical planning. To get the best of both worlds, we propose\nFirst-Order State AutoEncoder, an unsupervised architecture for grounding the\nfirst-order logic predicates and facts. Each predicate models a relationship\nbetween objects by taking the interpretable arguments and returning a\npropositional value. In the experiment using 8-Puzzle and a photo-realistic\nBlocksworld environment, we show that (1) the resulting predicates capture the\ninterpretable relations (e.g. spatial), (2) they help obtaining the compact,\nabstract model of the environment, and finally, (3) the resulting model is\ncompatible to symbolic classical planning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 15:16:38 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 05:57:02 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 05:25:15 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 07:10:38 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1902.08246", "submitter": "Aven Samareh", "authors": "Aven Samareh and Shuai Huang", "title": "UQ-CHI: An Uncertainty Quantification-Based Contemporaneous Health Index\n  for Degenerative Disease Monitoring", "comments": "Submitted to the Journal of Biomedical Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing knowledge-driven contemporaneous health index (CHI) that can\nprecisely reflect the underlying patient across the course of the condition's\nprogression holds a unique value, like facilitating a range of clinical\ndecision-making opportunities. This is particularly important for monitoring\ndegenerative condition such as Alzheimer's disease (AD), where the condition of\nthe patient will decay over time. Detecting early symptoms and progression\nsign, and continuous severity evaluation, are all essential for disease\nmanagement. While a few methods have been developed in the literature,\nuncertainty quantification of those health index models has been largely\nneglected. To ensure the continuity of the care, we should be more explicit\nabout the level of confidence in model outputs. Ideally, decision-makers should\nbe provided with recommendations that are robust in the face of substantial\nuncertainty about future outcomes. In this paper, we aim at filling this gap by\ndeveloping an uncertainty quantification based contemporaneous longitudinal\nindex, named UQ-CHI, with a particular focus on continuous patient monitoring\nof degenerative conditions. Our method is to combine convex optimization and\nBayesian learning using the maximum entropy learning (MEL) framework,\nintegrating uncertainty on labels as well. Our methodology also provides\nclosed-form solutions in some important decision making tasks, e.g., such as\npredicting the label of a new sample. Numerical studies demonstrate the\neffectiveness of the propose UQ-CHI method in prediction accuracy, monitoring\nefficacy, and unique advantages if uncertainty quantification is enabled\npractice.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 20:19:20 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Samareh", "Aven", ""], ["Huang", "Shuai", ""]]}, {"id": "1902.08251", "submitter": "Rafael S. Gon\\c{c}alves", "authors": "Matthew Horridge, Rafael S. Gon\\c{c}alves, Csongor I. Nyulas, Tania\n  Tudorache, Mark A. Musen", "title": "WebProt\\'eg\\'e: A Cloud-Based Ontology Editor", "comments": null, "journal-ref": null, "doi": "10.1145/3308560.3317707", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present WebProt\\'eg\\'e, a tool to develop ontologies represented in the\nWeb Ontology Language (OWL). WebProt\\'eg\\'e is a cloud-based application that\nallows users to collaboratively edit OWL ontologies, and it is available for\nuse at https://webprotege.stanford.edu. WebProt\\'ege\\'e currently hosts more\nthan 68,000 OWL ontology projects and has over 50,000 user accounts. In this\npaper, we detail the main new features of the latest version of WebProt\\'eg\\'e.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 20:25:46 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 04:48:38 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Horridge", "Matthew", ""], ["Gon\u00e7alves", "Rafael S.", ""], ["Nyulas", "Csongor I.", ""], ["Tudorache", "Tania", ""], ["Musen", "Mark A.", ""]]}, {"id": "1902.08274", "submitter": "Abhishek Dubey", "authors": "Ayan Mukhopadhyay and Geoffrey Pettet and Chinmaya Samal and Abhishek\n  Dubey and Yevgeniy Vorobeychik", "title": "An Online Decision-Theoretic Pipeline for Responder Dispatch", "comments": "Appeared in ICCPS 2019", "journal-ref": null, "doi": "10.1145/3302509.3311055", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of dispatching emergency responders to service traffic accidents,\nfire, distress calls and crimes plagues urban areas across the globe. While\nsuch problems have been extensively looked at, most approaches are offline.\nSuch methodologies fail to capture the dynamically changing environments under\nwhich critical emergency response occurs, and therefore, fail to be implemented\nin practice. Any holistic approach towards creating a pipeline for effective\nemergency response must also look at other challenges that it subsumes -\npredicting when and where incidents happen and understanding the changing\nenvironmental dynamics. We describe a system that collectively deals with all\nthese problems in an online manner, meaning that the models get updated with\nstreaming data sources. We highlight why such an approach is crucial to the\neffectiveness of emergency response, and present an algorithmic framework that\ncan compute promising actions for a given decision-theoretic model for\nresponder dispatch. We argue that carefully crafted heuristic measures can\nbalance the trade-off between computational time and the quality of solutions\nachieved and highlight why such an approach is more scalable and tractable than\ntraditional approaches. We also present an online mechanism for incident\nprediction, as well as an approach based on recurrent neural networks for\nlearning and predicting environmental features that affect responder dispatch.\nWe compare our methodology with prior state-of-the-art and existing dispatch\nstrategies in the field, which show that our approach results in a reduction in\nresponse time with a drastic reduction in computational time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 21:27:43 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Mukhopadhyay", "Ayan", ""], ["Pettet", "Geoffrey", ""], ["Samal", "Chinmaya", ""], ["Dubey", "Abhishek", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "1902.08283", "submitter": "Babak Salimi", "authors": "Babak Salimi, Luke Rodriguez, Bill Howe, Dan Suciu", "title": "Capuchin: Causal Database Repair for Algorithmic Fairness", "comments": null, "journal-ref": "Proceedings of the 2019 International Conference on Management of\n  Data. ACM, 2019", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is increasingly recognized as a critical component of machine\nlearning systems. However, it is the underlying data on which these systems are\ntrained that often reflect discrimination, suggesting a database repair\nproblem. Existing treatments of fairness rely on statistical correlations that\ncan be fooled by statistical anomalies, such as Simpson's paradox. Proposals\nfor causality-based definitions of fairness can correctly model some of these\nsituations, but they require specification of the underlying causal models. In\nthis paper, we formalize the situation as a database repair problem, proving\nsufficient conditions for fair classifiers in terms of admissible variables as\nopposed to a complete causal model. We show that these conditions correctly\ncapture subtle fairness violations. We then use these conditions as the basis\nfor database repair algorithms that provide provable fairness guarantees about\nclassifiers trained on their training labels. We evaluate our algorithms on\nreal data, demonstrating improvement over the state of the art on multiple\nfairness metrics proposed in the literature while retaining high utility.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 22:13:29 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 00:20:52 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 23:34:33 GMT"}, {"version": "v4", "created": "Mon, 22 Jul 2019 01:35:59 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 19:37:23 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Salimi", "Babak", ""], ["Rodriguez", "Luke", ""], ["Howe", "Bill", ""], ["Suciu", "Dan", ""]]}, {"id": "1902.08349", "submitter": "Sek Chai", "authors": "Aswin Raghavan, Jesse Hostetler, Sek Chai", "title": "Generative Memory for Lifelong Reinforcement Learning", "comments": "Abstract NICE 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research is focused on understanding and applying biological memory\ntransfers to new AI systems that can fundamentally improve their performance,\nthroughout their fielded lifetime experience. We leverage current understanding\nof biological memory transfer to arrive at AI algorithms for memory\nconsolidation and replay. In this paper, we propose the use of generative\nmemory that can be recalled in batch samples to train a multi-task agent in a\npseudo-rehearsal manner. We show results motivating the need for task-agnostic\nseparation of latent space for the generative memory to address issues of\ncatastrophic forgetting in lifelong learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 02:58:50 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Raghavan", "Aswin", ""], ["Hostetler", "Jesse", ""], ["Chai", "Sek", ""]]}, {"id": "1902.08438", "submitter": "Aravind Rajeswaran", "authors": "Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey Levine", "title": "Online Meta-Learning", "comments": "ICML 2019. The first two authors contributed equally. Expanded\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central capability of intelligent systems is the ability to continuously\nbuild upon previous experiences to speed up and enhance learning of new tasks.\nTwo distinct research paradigms have studied this question. Meta-learning views\nthis problem as learning a prior over model parameters that is amenable for\nfast adaptation on a new task, but typically assumes the set of tasks are\navailable together as a batch. In contrast, online (regret based) learning\nconsiders a sequential setting in which problems are revealed one after the\nother, but conventionally train only a single model without any task-specific\nadaptation. This work introduces an online meta-learning setting, which merges\nideas from both the aforementioned paradigms to better capture the spirit and\npractice of continual lifelong learning. We propose the follow the meta leader\nalgorithm which extends the MAML algorithm to this setting. Theoretically, this\nwork provides an $\\mathcal{O}(\\log T)$ regret guarantee with only one\nadditional higher order smoothness assumption in comparison to the standard\nonline setting. Our experimental evaluation on three different large-scale\ntasks suggest that the proposed algorithm significantly outperforms\nalternatives based on traditional online learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 11:20:42 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 19:25:58 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 01:02:06 GMT"}, {"version": "v4", "created": "Wed, 3 Jul 2019 20:50:53 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Finn", "Chelsea", ""], ["Rajeswaran", "Aravind", ""], ["Kakade", "Sham", ""], ["Levine", "Sergey", ""]]}, {"id": "1902.08627", "submitter": "Ethan Roberts", "authors": "Ethan Roberts, Bruce A. Bassett, Michelle Lochner", "title": "Bayesian Anomaly Detection and Classification", "comments": "29 pages, 13 figures, Demo available:\n  https://github.com/ethyroberts/BADAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical uncertainties are rarely incorporated in machine learning\nalgorithms, especially for anomaly detection. Here we present the Bayesian\nAnomaly Detection And Classification (BADAC) formalism, which provides a\nunified statistical approach to classification and anomaly detection within a\nhierarchical Bayesian framework. BADAC deals with uncertainties by\nmarginalising over the unknown, true, value of the data. Using simulated data\nwith Gaussian noise, BADAC is shown to be superior to standard algorithms in\nboth classification and anomaly detection performance in the presence of\nuncertainties, though with significantly increased computational cost.\nAdditionally, BADAC provides well-calibrated classification probabilities,\nvaluable for use in scientific pipelines. We show that BADAC can work in online\nmode and is fairly robust to model errors, which can be diagnosed through\nmodel-selection methods. In addition it can perform unsupervised new class\ndetection and can naturally be extended to search for anomalous subsets of\ndata. BADAC is therefore ideal where computational cost is not a limiting\nfactor and statistical rigour is important. We discuss approximations to speed\nup BADAC, such as the use of Gaussian processes, and finally introduce a new\nmetric, the Rank-Weighted Score (RWS), that is particularly suited to\nevaluating the ability of algorithms to detect anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:00:06 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Roberts", "Ethan", ""], ["Bassett", "Bruce A.", ""], ["Lochner", "Michelle", ""]]}, {"id": "1902.08639", "submitter": "Yinjie Huang", "authors": "Yinjie Huang and Michael Georgiopoulos and Georgios C. Anagnostopoulos", "title": "Learning Hash Function through Codewords", "comments": "arXiv admin note: substantial text overlap with arXiv:1508.03285", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel hash learning approach that has the\nfollowing main distinguishing features, when compared to past frameworks.\nFirst, the codewords are utilized in the Hamming space as ancillary techniques\nto accomplish its hash learning task. These codewords, which are inferred from\nthe data, attempt to capture grouping aspects of the data's hash codes.\nFurthermore, the proposed framework is capable of addressing supervised,\nunsupervised and, even, semi-supervised hash learning scenarios. Additionally,\nthe framework adopts a regularization term over the codewords, which\nautomatically chooses the codewords for the problem. To efficiently solve the\nproblem, one Block Coordinate Descent algorithm is showcased in the paper. We\nalso show that one step of the algorithms can be casted into several Support\nVector Machine problems which enables our algorithms to utilize efficient\nsoftware package. For the regularization term, a closed form solution of the\nproximal operator is provided in the paper. A series of comparative experiments\nfocused on content-based image retrieval highlights its performance advantages.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:18:02 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Huang", "Yinjie", ""], ["Georgiopoulos", "Michael", ""], ["Anagnostopoulos", "Georgios C.", ""]]}, {"id": "1902.08649", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli", "title": "Saliency Learning: Teaching the Model Where to Pay Attention", "comments": "Accepted as a short paper at NAACL 2019. 10 pages, 2 figures, 6\n  tables", "journal-ref": "NAACL 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a compelling solution to many NLP tasks with\nremarkable performances. However, due to their opacity, such models are hard to\ninterpret and trust. Recent work on explaining deep models has introduced\napproaches to provide insights toward the model's behaviour and predictions,\nwhich are helpful for assessing the reliability of the model's predictions.\nHowever, such methods do not improve the model's reliability. In this paper, we\naim to teach the model to make the right prediction for the right reason by\nproviding explanation training and ensuring the alignment of the model's\nexplanation with the ground truth explanation. Our experimental results on\nmultiple tasks and datasets demonstrate the effectiveness of the proposed\nmethod, which produces more reliable predictions while delivering better\nresults compared to traditionally trained models.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:38:36 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 00:01:28 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 04:42:28 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Shahbazi", "Hamed", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1902.08705", "submitter": "Jayesh Gupta", "authors": "Jayesh K. Gupta, Kunal Menda, Zachary Manchester and Mykel J.\n  Kochenderfer", "title": "A General Framework for Structured Learning of Mechanical Systems", "comments": "10 pages, 7 figures. First two authors contributed equally. Submitted\n  to IROS/RA-L. Code at https://github.com/sisl/mechamodlearn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning accurate dynamics models is necessary for optimal, compliant control\nof robotic systems. Current approaches to white-box modeling using analytic\nparameterizations, or black-box modeling using neural networks, can suffer from\nhigh bias or high variance. We address the need for a flexible, gray-box model\nof mechanical systems that can seamlessly incorporate prior knowledge where it\nis available, and train expressive function approximators where it is not. We\npropose to parameterize a mechanical system using neural networks to model its\nLagrangian and the generalized forces that act on it. We test our method on a\nsimulated, actuated double pendulum. We show that our method outperforms a\nnaive, black-box model in terms of data-efficiency, as well as performance in\nmodel-based reinforcement learning. We also conduct a systematic study of our\nmethod's ability to incorporate available prior knowledge about the system to\nimprove data efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 23:45:40 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 21:11:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Gupta", "Jayesh K.", ""], ["Menda", "Kunal", ""], ["Manchester", "Zachary", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1902.08722", "submitter": "Hadi Salman", "authors": "Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang", "title": "A Convex Relaxation Barrier to Tight Robustness Verification of Neural\n  Networks", "comments": "Poster at the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of neural networks enables us to gauge their robustness against\nadversarial attacks. Verification algorithms fall into two categories: exact\nverifiers that run in exponential time and relaxed verifiers that are efficient\nbut incomplete. In this paper, we unify all existing LP-relaxed verifiers, to\nthe best of our knowledge, under a general convex relaxation framework. This\nframework works for neural networks with diverse architectures and\nnonlinearities and covers both primal and dual views of robustness\nverification. We further prove strong duality between the primal and dual\nproblems under very mild conditions. Next, we perform large-scale experiments,\namounting to more than 22 CPU-years, to obtain exact solution to the\nconvex-relaxed problem that is optimal within our framework for ReLU networks.\nWe find the exact solution does not significantly improve upon the gap between\nPGD and existing relaxed verifiers for various networks trained normally or\nrobustly on MNIST and CIFAR datasets. Our results suggest there is an inherent\nbarrier to tight verification for the large class of methods captured by our\nframework. We discuss possible causes of this barrier and potential future\ndirections for bypassing it. Our code and trained models are available at\nhttp://github.com/Hadisalman/robust-verify-benchmark .\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 03:01:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 18:53:39 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 02:17:14 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 09:31:37 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 00:20:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Salman", "Hadi", ""], ["Yang", "Greg", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""], ["Zhang", "Pengchuan", ""]]}, {"id": "1902.08789", "submitter": "Weijun Zhu", "authors": "Weijun ZHU", "title": "Experimental Study on CTL model checking using Machine Learning", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing core methods, which are employed by the popular CTL model\nchecking tools, are facing the famous state explode problem. In our previous\nstudy, a method based on the Machine Learning (ML) algorithms was proposed to\naddress this problem. However, the accuracy is not satisfactory. First, we\nconduct a comprehensive experiment on Graph Lab to seek the optimal accuracy\nusing the five machine learning algorithms. Second, given the optimal accuracy,\nthe average time is seeked. The results show that the Logistic Regressive\n(LR)-based approach can simulate CTL model checking with the accuracy of 98.8%,\nand its average efficiency is 459 times higher than that of the existing\nmethod, as well as the Boosted Tree (BT)-based approach can simulate CTL model\nchecking with the accuracy of 98.7%, and its average efficiency is 639 times\nhigher than that of the existing method.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 14:04:50 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["ZHU", "Weijun", ""]]}, {"id": "1902.08858", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Kaige Xie and Maxine Eskenazi", "title": "Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog\n  Agents with Latent Variable Models", "comments": "Camera ready version for NAACL 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defining action spaces for conversational agents and optimizing their\ndecision-making process with reinforcement learning is an enduring challenge.\nCommon practice has been to use handcrafted dialog acts, or the output\nvocabulary, e.g. in neural encoder decoders, as the action spaces. Both have\ntheir own limitations. This paper proposes a novel latent action framework that\ntreats the action spaces of an end-to-end dialog agent as latent variables and\ndevelops unsupervised methods in order to induce its own action space from the\ndata. Comprehensive experiments are conducted examining both continuous and\ndiscrete action types and two different optimization methods based on\nstochastic variational inference. Results show that the proposed latent actions\nachieve superior empirical performance improvement over previous word-level\npolicy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed\nanalysis also provides insights about various latent variable approaches for\npolicy learning and can serve as a foundation for developing better latent\nactions in future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 22:27:45 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 17:07:43 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Xie", "Kaige", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1902.08882", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Tao Zhuang, Minlie Huang, Jun Feng, Haihong Tang, Bo\n  Zheng", "title": "Aggregating E-commerce Search Results from Heterogeneous Sources via\n  Hierarchical Reinforcement Learning", "comments": "WWW 19, 11 pages", "journal-ref": null, "doi": "10.1145/3308558.3313455", "report-no": null, "categories": "cs.IR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the task of aggregating search results from\nheterogeneous sources in an E-commerce environment. First, unlike traditional\naggregated web search that merely presents multi-sourced results in the first\npage, this new task may present aggregated results in all pages and has to\ndynamically decide which source should be presented in the current page.\nSecond, as pointed out by many existing studies, it is not trivial to rank\nitems from heterogeneous sources because the relevance scores from different\nsource systems are not directly comparable. To address these two issues, we\ndecompose the task into two subtasks in a hierarchical structure: a high-level\ntask for source selection where we model the sequential patterns of user\nbehaviors onto aggregated results in different pages so as to understand user\nintents and select the relevant sources properly; and a low-level task for item\npresentation where we formulate a slot filling process to sequentially present\nthe items instead of giving each item a relevance score when deciding the\npresentation order of heterogeneous items. Since both subtasks can be naturally\nformulated as sequential decision problems and learn from the future user\nfeedback on search results, we build our model with hierarchical reinforcement\nlearning. Extensive experiments demonstrate that our model obtains remarkable\nimprovements in search performance metrics, and achieves a higher user\nsatisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 03:18:43 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhuang", "Tao", ""], ["Huang", "Minlie", ""], ["Feng", "Jun", ""], ["Tang", "Haihong", ""], ["Zheng", "Bo", ""]]}, {"id": "1902.08921", "submitter": "Hongjoon Ahn", "authors": "Hongjoon Ahn, Taesup Moon", "title": "Iterative Channel Estimation for Discrete Denoising under Channel\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel iterative channel estimation (ICE) algorithm that\nessentially removes the critical known noisy channel assumption for universal\ndiscrete denoising problem. Our algorithm is based on Neural DUDE (N-DUDE), a\nrecently proposed neural network-based discrete denoiser, and it estimates the\nchannel transition matrix as well as the neural network parameters in an\nalternating manner until convergence. While we do not make any probabilistic\nassumption on the underlying clean data, our ICE resembles\nExpectation-Maximization (EM) with variational approximation, and it takes\nadvantage of the property of N-DUDE being locally robust around the true\nchannel. With extensive experiments on several radically different types of\ndata, we show that the ICE equipped N-DUDE (dubbed as ICE-N-DUDE) can perform\n\\emph{universally} well regardless of the uncertainties in both the channel and\nthe clean source. Moreover, we show ICE-N-DUDE becomes extremely robust to its\nhyperparameters and significantly outperforms the strong baseline that can deal\nwith the channel uncertainties for denoising, the widely used Baum-Welch (BW)\nalgorithm for hidden Markov models (HMM).\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 10:58:39 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 04:10:38 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ahn", "Hongjoon", ""], ["Moon", "Taesup", ""]]}, {"id": "1902.08930", "submitter": "Palash Dey", "authors": "Palash Dey, Swaprava Nath, Garima Shakya", "title": "Testing Preferential Domains Using Sampling", "comments": "Accepted as a full paper in AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A preferential domain is a collection of sets of preferences which are linear\norders over a set of alternatives. These domains have been studied extensively\nin social choice theory due to both its practical importance and theoretical\nelegance. Examples of some extensively studied preferential domains include\nsingle peaked, single crossing, Euclidean, etc. In this paper, we study the\nsample complexity of testing whether a given preference profile is close to\nsome specific domain. We consider two notions of closeness: (a) closeness via\npreferences, and (b) closeness via alternatives. We further explore the effect\nof assuming that the {\\em outlier} preferences/alternatives to be random\n(instead of arbitrary) on the sample complexity of the testing problem. In most\ncases, we show that the above testing problem can be solved with high\nprobability for all commonly used domains by observing only a small number of\nsamples (independent of the number of preferences, $n$, and often the number of\nalternatives, $m$). In the remaining few cases, we prove either impossibility\nresults or $\\Omega(n)$ lower bound on the sample complexity. We complement our\ntheoretical findings with extensive simulations to figure out the actual\nconstant factors of our asymptotic sample complexity bounds.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 11:42:13 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Dey", "Palash", ""], ["Nath", "Swaprava", ""], ["Shakya", "Garima", ""]]}, {"id": "1902.08990", "submitter": "Chongyang Wang", "authors": "Chongyang Wang, Temitayo A. Olugbade, Akhil Mathur, Amanda C. De C.\n  Williams, Nicholas D. Lane, Nadia Bianchi-Berthouze", "title": "Chronic-Pain Protective Behavior Detection with Deep Learning", "comments": "24 pages, 12 figures, 7 tables. Accepted by ACM Transactions on\n  Computing for Healthcare", "journal-ref": null, "doi": "10.1145/3449068", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In chronic pain rehabilitation, physiotherapists adapt physical activity to\npatients' performance based on their expression of protective behavior,\ngradually exposing them to feared but harmless and essential everyday\nactivities. As rehabilitation moves outside the clinic, technology should\nautomatically detect such behavior to provide similar support. Previous works\nhave shown the feasibility of automatic protective behavior detection (PBD)\nwithin a specific activity. In this paper, we investigate the use of deep\nlearning for PBD across activity types, using wearable motion capture and\nsurface electromyography data collected from healthy participants and people\nwith chronic pain. We approach the problem by continuously detecting protective\nbehavior within an activity rather than estimating its overall presence. The\nbest performance reaches mean F1 score of 0.82 with leave-one-subject-out cross\nvalidation. When protective behavior is modelled per activity type, performance\nis mean F1 score of 0.77 for bend-down, 0.81 for one-leg-stand, 0.72 for\nsit-to-stand, 0.83 for stand-to-sit, and 0.67 for reach-forward. This\nperformance reaches excellent level of agreement with the average experts'\nrating performance suggesting potential for personalized chronic pain\nmanagement at home. We analyze various parameters characterizing our approach\nto understand how the results could generalize to other PBD datasets and\ndifferent levels of ground truth granularity.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 17:50:44 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 18:48:08 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 01:03:12 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 06:10:35 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Wang", "Chongyang", ""], ["Olugbade", "Temitayo A.", ""], ["Mathur", "Akhil", ""], ["Williams", "Amanda C. De C.", ""], ["Lane", "Nicholas D.", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "1902.09006", "submitter": "Catherine Chen", "authors": "Catherine Chen, Qihong Lu, Andre Beukers, Christopher Baldassano, and\n  Kenneth A. Norman", "title": "Learning to Perform Role-Filler Binding with Schematic Knowledge", "comments": null, "journal-ref": "PeerJ 9:e11046 (2021)", "doi": "10.7717/peerj.11046", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through specific experiences, humans learn relationships underlying the\nstructure of events in the world. Schema theory suggests that we organize this\ninformation in mental frameworks called \"schemata,\" which represent our\nknowledge of the structure of the world. Generalizing knowledge of structural\nrelationships to new situations requires role-filler binding, the ability to\nassociate specific \"fillers\" with abstract \"roles.\" For instance, when we hear\nthe sentence \"Alice ordered a tea from Bob,\" the role-filler bindings\n\"Alice:customer,\" \"tea:drink,\" and \"Bob:barista\" allow us to understand and\nmake inferences about the sentence. We can perform these bindings for arbitrary\nfillers -- we understand this sentence even if we have never heard the names\n\"Alice,\" \"tea,\" or \"Bob\" before. In this work, we define a model as capable of\nperforming role-filler binding if it can recall arbitrary fillers corresponding\nto a specified role, even when these pairings violate correlations seen during\ntraining. Previous work found that models can learn this ability when\nexplicitly told what the roles and fillers are, or when given fillers seen\nduring training. We show that networks with external memory can learn these\nrelationships with fillers not seen during training and without explicitly\nlabeled role-filler bindings, and show that analyses inspired by neural\ndecoding can provide a means of understanding what the networks have learned.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 20:05:07 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 00:21:08 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 00:48:54 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chen", "Catherine", ""], ["Lu", "Qihong", ""], ["Beukers", "Andre", ""], ["Baldassano", "Christopher", ""], ["Norman", "Kenneth A.", ""]]}, {"id": "1902.09041", "submitter": "Cagri Ozcaglar", "authors": "Cagri Ozcaglar, Sahin Geyik, Brian Schmitz, Prakhar Sharma, Alex\n  Shelkovnykov, Yiming Ma, Erik Buchanan", "title": "Entity Personalized Talent Search Models with Tree Interaction Features", "comments": "This paper has been accepted for publication at ACM WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313672", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Talent Search systems aim to recommend potential candidates who are a good\nmatch to the hiring needs of a recruiter expressed in terms of the recruiter's\nsearch query or job posting. Past work in this domain has focused on linear and\nnonlinear models which lack preference personalization in the user-level due to\nbeing trained only with globally collected recruiter activity data. In this\npaper, we propose an entity-personalized Talent Search model which utilizes a\ncombination of generalized linear mixed (GLMix) models and gradient boosted\ndecision tree (GBDT) models, and provides personalized talent recommendations\nusing nonlinear tree interaction features generated by the GBDT. We also\npresent the offline and online system architecture for the productionization of\nthis hybrid model approach in our Talent Search systems. Finally, we provide\noffline and online experiment results benchmarking our entity-personalized\nmodel with tree interaction features, which demonstrate significant\nimprovements in our precision metrics compared to globally trained\nnon-personalized models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 00:00:45 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Ozcaglar", "Cagri", ""], ["Geyik", "Sahin", ""], ["Schmitz", "Brian", ""], ["Sharma", "Prakhar", ""], ["Shelkovnykov", "Alex", ""], ["Ma", "Yiming", ""], ["Buchanan", "Erik", ""]]}, {"id": "1902.09091", "submitter": "Bishan Yang", "authors": "Bishan Yang, Tom Mitchell", "title": "Leveraging Knowledge Bases in LSTMs for Improving Machine Reading", "comments": "published at ACL 2017", "journal-ref": "ACL 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on how to take advantage of external knowledge bases (KBs)\nto improve recurrent neural networks for machine reading. Traditional methods\nthat exploit knowledge from KBs encode knowledge as discrete indicator\nfeatures. Not only do these features generalize poorly, but they require\ntask-specific feature engineering to achieve good performance. We propose\nKBLSTM, a novel neural model that leverages continuous representations of KBs\nto enhance the learning of recurrent neural networks for machine reading. To\neffectively integrate background knowledge with information from the currently\nprocessed text, our model employs an attention mechanism with a sentinel to\nadaptively decide whether to attend to background knowledge and which\ninformation from KBs is useful. Experimental results show that our model\nachieves accuracies that surpass the previous state-of-the-art results for both\nentity extraction and event extraction on the widely used ACE2005 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:00 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Yang", "Bishan", ""], ["Mitchell", "Tom", ""]]}, {"id": "1902.09092", "submitter": "Guangyu Zheng", "authors": "Wanyun Cui, Guangyu Zheng, Zhiqiang Shen, Sihang Jiang, Wei Wang", "title": "Transfer Learning for Sequences via Learning to Collocate", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning aims to solve the data sparsity for a target domain by\napplying information of the source domain. Given a sequence (e.g. a natural\nlanguage sentence), the transfer learning, usually enabled by recurrent neural\nnetwork (RNN), represents the sequential information transfer. RNN uses a chain\nof repeating cells to model the sequence data. However, previous studies of\nneural network based transfer learning simply represents the whole sentence by\na single vector, which is unfeasible for seq2seq and sequence labeling.\nMeanwhile, such layer-wise transfer learning mechanisms lose the fine-grained\ncell-level information from the source domain.\n  In this paper, we proposed the aligned recurrent transfer, ART, to achieve\ncell-level information transfer. ART is under the pre-training framework. Each\ncell attentively accepts transferred information from a set of positions in the\nsource domain. Therefore, ART learns the cross-domain word collocations in a\nmore flexible way. We conducted extensive experiments on both sequence labeling\ntasks (POS tagging, NER) and sentence classification (sentiment analysis). ART\noutperforms the state-of-the-arts over all experiments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cui", "Wanyun", ""], ["Zheng", "Guangyu", ""], ["Shen", "Zhiqiang", ""], ["Jiang", "Sihang", ""], ["Wang", "Wei", ""]]}, {"id": "1902.09093", "submitter": "Bishan Yang", "authors": "Igor Labutov, Bishan Yang, Anusha Prakash, Amos Azaria", "title": "Multi-Relational Question Answering from Narratives: Machine Reading and\n  Reasoning in Simulated Worlds", "comments": "published at ACL 2018", "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA), as a research field, has primarily focused on either\nknowledge bases (KBs) or free text as a source of knowledge. These two sources\nhave historically shaped the kinds of questions that are asked over these\nsources, and the methods developed to answer them. In this work, we look\ntowards a practical use-case of QA over user-instructed knowledge that uniquely\ncombines elements of both structured QA over knowledge bases, and unstructured\nQA over narrative, introducing the task of multi-relational QA over personal\nnarrative. As a first step towards this goal, we make three key contributions:\n(i) we generate and release TextWorldsQA, a set of five diverse datasets, where\neach dataset contains dynamic narrative that describes entities and relations\nin a simulated world, paired with variably compositional questions over that\nknowledge, (ii) we perform a thorough evaluation and analysis of several\nstate-of-the-art QA models and their variants at this task, and (iii) we\nrelease a lightweight Python-based framework we call TextWorlds for easily\ngenerating arbitrary additional worlds and narrative, with the goal of allowing\nthe community to create and share a growing collection of diverse worlds as a\ntest-bed for this task.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:04:26 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Labutov", "Igor", ""], ["Yang", "Bishan", ""], ["Prakash", "Anusha", ""], ["Azaria", "Amos", ""]]}, {"id": "1902.09097", "submitter": "Joe Booth", "authors": "Joe Booth, Jackson Booth", "title": "Marathon Environments: Multi-Agent Continuous Control Benchmarks in a\n  Modern Video Game Engine", "comments": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "journal-ref": "AAAI-2019 Workshop on Games and Simulations for Artificial\n  Intelligence", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning in the paradigm of locomotion\nusing continuous control have raised the interest of game makers for the\npotential of digital actors using active ragdoll. Currently, the available\noptions to develop these ideas are either researchers' limited codebase or\nproprietary closed systems. We present Marathon Environments, a suite of open\nsource, continuous control benchmarks implemented on the Unity game engine,\nusing the Unity ML- Agents Toolkit. We demonstrate through these benchmarks\nthat continuous control research is transferable to a commercial game engine.\nFurthermore, we exhibit the robustness of these environments by reproducing\nadvanced continuous control research, such as learning to walk, run and\nbackflip from motion capture data; learning to navigate complex terrains; and\nby implementing a video game input control system. We show further robustness\nby training with alternative algorithms found in OpenAI.Baselines. Finally, we\nshare strategies for significantly reducing the training time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 05:56:35 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Booth", "Joe", ""], ["Booth", "Jackson", ""]]}, {"id": "1902.09192", "submitter": "Zhijie Deng", "authors": "Zhijie Deng and Yinpeng Dong and Jun Zhu", "title": "Batch Virtual Adversarial Training for Graph Convolutional Networks", "comments": "ICML 2019 Workshop on Learning and Reasoning with Graph-Structured\n  Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present batch virtual adversarial training (BVAT), a novel regularization\nmethod for graph convolutional networks (GCNs). BVAT addresses the shortcoming\nof GCNs that do not consider the smoothness of the model's output distribution\nagainst local perturbations around the input. We propose two algorithms,\nsample-based BVAT and optimization-based BVAT, which are suitable to promote\nthe smoothness of the model for graph-structured data by either finding virtual\nadversarial perturbations for a subset of nodes far from each other or\ngenerating virtual adversarial perturbations for all nodes with an optimization\nprocess. Extensive experiments on three citation network datasets Cora,\nCiteseer and Pubmed and a knowledge graph dataset Nell validate the\neffectiveness of the proposed method, which establishes state-of-the-art\nresults in the semi-supervised node classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 10:57:43 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 02:05:30 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Deng", "Zhijie", ""], ["Dong", "Yinpeng", ""], ["Zhu", "Jun", ""]]}, {"id": "1902.09229", "submitter": "Nikunj Saunshi", "authors": "Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis\n  Plevrakis, Nikunj Saunshi", "title": "A Theoretical Analysis of Contrastive Unsupervised Representation\n  Learning", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent empirical works have successfully used unlabeled data to learn feature\nrepresentations that are broadly useful in downstream classification tasks.\nSeveral of these methods are reminiscent of the well-known word2vec embedding\nalgorithm: leveraging availability of pairs of semantically \"similar\" data\npoints and \"negative samples,\" the learner forces the inner product of\nrepresentations of similar pairs with each other to be higher on average than\nwith negative samples. The current paper uses the term contrastive learning for\nsuch algorithms and presents a theoretical framework for analyzing them by\nintroducing latent classes and hypothesizing that semantically similar points\nare sampled from the same latent class. This framework allows us to show\nprovable guarantees on the performance of the learned representations on the\naverage classification task that is comprised of a subset of the same set of\nlatent classes. Our generalization bound also shows that learned\nrepresentations can reduce (labeled) sample complexity on downstream tasks. We\nconduct controlled experiments in both the text and image domains to support\nthe theory.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 12:32:15 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Arora", "Sanjeev", ""], ["Khandeparkar", "Hrishikesh", ""], ["Khodak", "Mikhail", ""], ["Plevrakis", "Orestis", ""], ["Saunshi", "Nikunj", ""]]}, {"id": "1902.09243", "submitter": "Haoyu Zhang", "authors": "Haoyu Zhang, Jianjun Xu, Ji Wang", "title": "Pretraining-Based Natural Language Generation for Text Summarization", "comments": "7 pages", "journal-ref": "CoNLL'2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel pretraining-based encoder-decoder\nframework, which can generate the output sequence based on the input sequence\nin a two-stage manner. For the encoder of our model, we encode the input\nsequence into context representations using BERT. For the decoder, there are\ntwo stages in our model, in the first stage, we use a Transformer-based decoder\nto generate a draft output sequence. In the second stage, we mask each word of\nthe draft sequence and feed it to BERT, then by combining the input sequence\nand the draft representation generated by BERT, we use a Transformer-based\ndecoder to predict the refined word for each masked position. To the best of\nour knowledge, our approach is the first method which applies the BERT into\ntext generation tasks. As the first step in this direction, we evaluate our\nproposed method on the text summarization task. Experimental results show that\nour model achieves new state-of-the-art on both CNN/Daily Mail and New York\nTimes datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:07:32 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 05:00:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Zhang", "Haoyu", ""], ["Xu", "Jianjun", ""], ["Wang", "Ji", ""]]}, {"id": "1902.09244", "submitter": "Viktoria Hauder", "authors": "Viktoria A. Hauder, Andreas Beham, Sebastian Raggl, Sophie N. Parragh,\n  Michael Affenzeller", "title": "Resource-constrained multi-project scheduling with activity and time\n  flexibility", "comments": null, "journal-ref": "Computers & Industrial Engineering, 106857 (2020)", "doi": "10.1016/j.cie.2020.106857", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Project scheduling in manufacturing environments often requires flexibility\nin terms of the selection and the exact length of alternative production\nactivities. Moreover, the simultaneous scheduling of multiple lots is mandatory\nin many production planning applications. To meet these requirements, a new\nresource-constrained project scheduling problem (RCPSP) is introduced where\nboth decisions (activity flexibility and time flexibility) are integrated.\nBesides the minimization of makespan, two new alternative objectives are\npresented: maximization of balanced length of selected activities (time\nbalance) and maximization of balanced resource utilization (resource balance).\nNew mixed integer and constraint programming (CP) models are proposed for the\ndeveloped integrated flexible project scheduling problem. Benchmark instances\non an already existing flexible RCPSP and the newly developed problem are\nsolved to optimality. The real-world applicability of the suggested CP models\nis shown by additionally solving a large industry case.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:08:53 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 07:54:09 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Hauder", "Viktoria A.", ""], ["Beham", "Andreas", ""], ["Raggl", "Sebastian", ""], ["Parragh", "Sophie N.", ""], ["Affenzeller", "Michael", ""]]}, {"id": "1902.09291", "submitter": "Guilherme Wachs-Lopes", "authors": "Mariana B. Santos, Amanda M. Lima, Lucas A. Silva, Felipe S. Vargas,\n  Guilherme A. Wachs-Lopes, Paulo S. Rodrigues", "title": "MIRA: A Computational Neuro-Based Cognitive Architecture Applied to\n  Movie Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human mind is still an unknown process of neuroscience in many aspects.\nNevertheless, for decades the scientific community has proposed computational\nmodels that try to simulate their parts, specific applications, or their\nbehavior in different situations. The most complete model in this line is\nundoubtedly the LIDA model, proposed by Stan Franklin with the aim of serving\nas a generic computational architecture for several applications. The present\nproject is inspired by the LIDA model to apply it to the process of movie\nrecommendation, the model called MIRA (Movie Intelligent Recommender Agent)\npresented percentages of precision similar to a traditional model when\nsubmitted to the same assay conditions. Moreover, the proposed model reinforced\nthe precision indexes when submitted to tests with volunteers, proving once\nagain its performance as a cognitive model, when executed with small data\nvolumes. Considering that the proposed model achieved a similar behavior to the\ntraditional models under conditions expected to be similar for natural systems,\nit can be said that MIRA reinforces the applicability of LIDA as a path to be\nfollowed for the study and generation of computational agents inspired by\nneural behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 14:32:18 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 11:21:29 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Santos", "Mariana B.", ""], ["Lima", "Amanda M.", ""], ["Silva", "Lucas A.", ""], ["Vargas", "Felipe S.", ""], ["Wachs-Lopes", "Guilherme A.", ""], ["Rodrigues", "Paulo S.", ""]]}, {"id": "1902.09335", "submitter": "Sabrina Evans", "authors": "Sabrina Evans, Paolo Turrini", "title": "Similarity Measures based on Local Game Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study strategic similarity of game positions in two-player extensive games\nof perfect information, by looking at the structure of their local game trees,\nwith the aim of improving the performance of game playing agents in detecting\nforcing continuations. We present a range of measures over the induced game\ntrees and compare them against benchmark problems in chess, observing a\npromising level of accuracy in matching up trap states.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:06:26 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Evans", "Sabrina", ""], ["Turrini", "Paolo", ""]]}, {"id": "1902.09355", "submitter": "Andrea Censi", "authors": "Andrea Censi, Konstantin Slutsky, Tichakorn Wongpiromsarn, Dmitry\n  Yershov, Scott Pendleton, James Fu, Emilio Frazzoli", "title": "Liability, Ethics, and Culture-Aware Behavior Specification using\n  Rulebooks", "comments": "To appear in ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of self-driving cars must be compatible with an enormous set of\nconflicting and ambiguous objectives, from law, from ethics, from the local\nculture, and so on. This paper describes a new way to conveniently define the\ndesired behavior for autonomous agents, which we use on the self-driving cars\ndeveloped at nuTonomy. We define a \"rulebook\" as a pre-ordered set of \"rules\",\neach akin to a violation metric on the possible outcomes (\"realizations\"). The\nrules are partially ordered by priority. The semantics of a rulebook imposes a\npre-order on the set of realizations. We study the compositional properties of\nthe rulebooks, and we derive which operations we can allow on the rulebooks to\npreserve previously-introduced constraints. While we demonstrate the\napplication of these techniques in the self-driving domain, the methods are\ndomain-independent.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:17:15 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 07:09:30 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Censi", "Andrea", ""], ["Slutsky", "Konstantin", ""], ["Wongpiromsarn", "Tichakorn", ""], ["Yershov", "Dmitry", ""], ["Pendleton", "Scott", ""], ["Fu", "James", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1902.09359", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Aris Filos-Ratsikas, Boi Faltings", "title": "Anytime Heuristic for Weighted Matching Through Altruism-Inspired\n  Behavior", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2019/31", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel anytime heuristic (ALMA), inspired by the human principle\nof altruism, for solving the assignment problem. ALMA is decentralized,\ncompletely uncoupled, and requires no communication between the participants.\nWe prove an upper bound on the convergence speed that is polynomial in the\ndesired number of resources and competing agents per resource; crucially, in\nthe realistic case where the aforementioned quantities are bounded\nindependently of the total number of agents/resources, the convergence time\nremains constant as the total problem size increases.\n  We have evaluated ALMA under three test cases: (i) an anti-coordination\nscenario where agents with similar preferences compete over the same set of\nactions, (ii) a resource allocation scenario in an urban environment, under a\nconstant-time constraint, and finally, (iii) an on-line matching scenario using\nreal passenger-taxi data. In all of the cases, ALMA was able to reach high\nsocial welfare, while being orders of magnitude faster than the centralized,\noptimal algorithm. The latter allows our algorithm to scale to realistic\nscenarios with hundreds of thousands of agents, e.g., vehicle coordination in\nurban environments.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:24:19 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1902.09393", "submitter": "Serhii Havrylov", "authors": "Serhii Havrylov, Germ\\'an Kruszewski, Armand Joulin", "title": "Cooperative Learning of Disjoint Syntax and Semantics", "comments": "The paper was accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable attention devoted to models that learn to jointly\ninfer an expression's syntactic structure and its semantics. Yet,\n\\citet{NangiaB18} has recently shown that the current best systems fail to\nlearn the correct parsing strategy on mathematical expressions generated from a\nsimple context-free grammar. In this work, we present a recursive model\ninspired by \\newcite{ChoiYL18} that reaches near perfect accuracy on this task.\nOur model is composed of two separated modules for syntax and semantics. They\nare cooperatively trained with standard continuous and discrete optimization\nschemes. Our model does not require any linguistic structure for supervision\nand its recursive nature allows for out-of-domain generalization with little\nloss in performance. Additionally, our approach performs competitively on\nseveral natural language tasks, such as Natural Language Inference or Sentiment\nAnalysis.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 15:56:34 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 12:42:17 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Havrylov", "Serhii", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Joulin", "Armand", ""]]}, {"id": "1902.09451", "submitter": "Guiying Huang", "authors": "Victoria Huang (1), Gang Chen (1), Qiang Fu (1), Elliott Wen (2) ((1)\n  Victoria University of Wellington, (2) The University of Auckland)", "title": "Optimizing Controller Placement for Software-Defined Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controller placement problem (CPP) is a key issue for Software-Defined\nNetworking (SDN) with distributed controller architectures. This problem aims\nto determine a suitable number of controllers deployed in important locations\nso as to optimize the overall network performance. In comparison to\ncommunication delay, existing literature on the CPP assumes that the influence\nof controller workload distribution on network performance is negligible. In\nthis paper, we tackle the CPP that simultaneously considers the communication\ndelay, the control plane utilization, and the controller workload distribution.\nDue to this reason, our CPP is intrinsically different from and clearly more\ndifficult than any previously studied CPPs that are NP-hard. To tackle this\nchallenging issue, we develop a new algorithm that seamlessly integrates the\ngenetic algorithm (GA) and the gradient descent (GD) optimization method.\nParticularly, GA is used to search for suitable CPP solutions. The quality of\neach solution is further evaluated through GD. Simulation results on two\nrepresentative network scenarios (small-scale and large-scale) show that our\nalgorithm can effectively strike the trade-off between the control plane\nutilization and the network response time.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 11:13:50 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Huang", "Victoria", ""], ["Chen", "Gang", ""], ["Fu", "Qiang", ""], ["Wen", "Elliott", ""]]}, {"id": "1902.09458", "submitter": "Aleksandra Faust", "authors": "Anthony Francis and Aleksandra Faust and Hao-Tien Lewis Chiang and\n  Jasmine Hsu and J. Chase Kew and Marek Fiser and Tsang-Wei Edward Lee", "title": "Long-Range Indoor Navigation with PRM-RL", "comments": "Accepted to T-RO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range indoor navigation requires guiding robots with noisy sensors and\ncontrols through cluttered environments along paths that span a variety of\nbuildings. We achieve this with PRM-RL, a hierarchical robot navigation method\nin which reinforcement learning agents that map noisy sensors to robot controls\nlearn to solve short-range obstacle avoidance tasks, and then sampling-based\nplanners map where these agents can reliably navigate in simulation; these\nroadmaps and agents are then deployed on robots, guiding them along the\nshortest path where the agents are likely to succeed. Here we use Probabilistic\nRoadmaps (PRMs) as the sampling-based planner, and AutoRL as the reinforcement\nlearning method in the indoor navigation context. We evaluate the method in\nsimulation for kinematic differential drive and kinodynamic car-like robots in\nseveral environments, and on differential-drive robots at three physical sites.\nOur results show PRM-RL with AutoRL is more successful than several baselines,\nis robust to noise, and can guide robots over hundreds of meters in the face of\nnoise and obstacles in both simulation and on robots, including over 5.8\nkilometers of physical robot navigation. Video: https://youtu.be/xN-OWX5gKvQ\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:20:06 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 20:27:22 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Francis", "Anthony", ""], ["Faust", "Aleksandra", ""], ["Chiang", "Hao-Tien Lewis", ""], ["Hsu", "Jasmine", ""], ["Kew", "J. Chase", ""], ["Fiser", "Marek", ""], ["Lee", "Tsang-Wei Edward", ""]]}, {"id": "1902.09469", "submitter": "Scott Garrabrant", "authors": "Abram Demski and Scott Garrabrant", "title": "Embedded Agency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional models of rational action treat the agent as though it is cleanly\nseparated from its environment, and can act on that environment from the\noutside. Such agents have a known functional relationship with their\nenvironment, can model their environment in every detail, and do not need to\nreason about themselves or their internal parts.\n  We provide an informal survey of obstacles to formalizing good reasoning for\nagents embedded in their environment. Such agents must optimize an environment\nthat is not of type \"function\"; they must rely on models that fit within the\nmodeled environment; and they must reason about themselves as just another\nphysical system, made of parts that can be modified and that can work at cross\npurposes.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:38:48 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 18:36:39 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 21:20:37 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Demski", "Abram", ""], ["Garrabrant", "Scott", ""]]}, {"id": "1902.09487", "submitter": "R\\'emi Cad\\`ene", "authors": "Remi Cadene and Hedi Ben-younes and Matthieu Cord and Nicolas Thome", "title": "MUREL: Multimodal Relational Reasoning for Visual Question Answering", "comments": "CVPR2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal attentional networks are currently state-of-the-art models for\nVisual Question Answering (VQA) tasks involving real images. Although attention\nallows to focus on the visual content relevant to the question, this simple\nmechanism is arguably insufficient to model complex reasoning features required\nfor VQA or other high-level tasks.\n  In this paper, we propose MuRel, a multimodal relational network which is\nlearned end-to-end to reason over real images. Our first contribution is the\nintroduction of the MuRel cell, an atomic reasoning primitive representing\ninteractions between question and image regions by a rich vectorial\nrepresentation, and modeling region relations with pairwise combinations.\nSecondly, we incorporate the cell into a full MuRel network, which\nprogressively refines visual and question interactions, and can be leveraged to\ndefine visualization schemes finer than mere attention maps.\n  We validate the relevance of our approach with various ablation studies, and\nshow its superiority to attention-based methods on three datasets: VQA 2.0,\nVQA-CP v2 and TDIUC. Our final MuRel network is competitive to or outperforms\nstate-of-the-art results in this challenging context.\n  Our code is available: https://github.com/Cadene/murel.bootstrap.pytorch\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:04:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Cadene", "Remi", ""], ["Ben-younes", "Hedi", ""], ["Cord", "Matthieu", ""], ["Thome", "Nicolas", ""]]}, {"id": "1902.09506", "submitter": "Drew A. Hudson", "authors": "Drew A. Hudson and Christopher D. Manning", "title": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional\n  Question Answering", "comments": "Published as a conference paper at CVPR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce GQA, a new dataset for real-world visual reasoning and\ncompositional question answering, seeking to address key shortcomings of\nprevious VQA datasets. We have developed a strong and robust question engine\nthat leverages scene graph structures to create 22M diverse reasoning\nquestions, all come with functional programs that represent their semantics. We\nuse the programs to gain tight control over the answer distribution and present\na new tunable smoothing technique to mitigate question biases. Accompanying the\ndataset is a suite of new metrics that evaluate essential qualities such as\nconsistency, grounding and plausibility. An extensive analysis is performed for\nbaselines as well as state-of-the-art models, providing fine-grained results\nfor different question types and topologies. Whereas a blind LSTM obtains mere\n42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%,\noffering ample opportunity for new research to explore. We strongly hope GQA\nwill provide an enabling resource for the next generation of models with\nenhanced robustness, improved consistency, and deeper semantic understanding\nfor images and language.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 18:37:49 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 09:10:11 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:24:55 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hudson", "Drew A.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1902.09628", "submitter": "Fan Fei", "authors": "Fan Fei, Zhan Tu, Yilun Yang, Jian Zhang, Xinyan Deng", "title": "Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing\n  Robots and Animals", "comments": "The code is available at\n  (https://github.com/purdue-biorobotics/flappy). 6 pages, 10 figure, accepted\n  at ICRA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insects and hummingbirds exhibit extraordinary flight capabilities and can\nsimultaneously master seemingly conflicting goals: stable hovering and\naggressive maneuvering, unmatched by small scale man-made vehicles. Flapping\nWing Micro Air Vehicles (FWMAVs) hold great promise for closing this\nperformance gap. However, design and control of such systems remain challenging\ndue to various constraints. Here, we present an open source high fidelity\ndynamic simulation for FWMAVs to serve as a testbed for the design,\noptimization and flight control of FWMAVs. For simulation validation, we\nrecreated the hummingbird-scale robot developed in our lab in the simulation.\nSystem identification was performed to obtain the model parameters. The force\ngeneration, open-loop and closed-loop dynamic response between simulated and\nexperimental flights were compared and validated. The unsteady aerodynamics and\nthe highly nonlinear flight dynamics present challenging control problems for\nconventional and learning control algorithms such as Reinforcement Learning.\nThe interface of the simulation is fully compatible with OpenAI Gym\nenvironment. As a benchmark study, we present a linear controller for hovering\nstabilization and a Deep Reinforcement Learning control policy for\ngoal-directed maneuvering. Finally, we demonstrate direct simulation-to-real\ntransfer of both control policies onto the physical robot, further\ndemonstrating the fidelity of the simulation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Fei", "Fan", ""], ["Tu", "Zhan", ""], ["Yang", "Yilun", ""], ["Zhang", "Jian", ""], ["Deng", "Xinyan", ""]]}, {"id": "1902.09630", "submitter": "Nathan Tsoi", "authors": "Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian\n  Reid, Silvio Savarese", "title": "Generalized Intersection over Union: A Metric and A Loss for Bounding\n  Box Regression", "comments": "accepted in CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intersection over Union (IoU) is the most popular evaluation metric used in\nthe object detection benchmarks. However, there is a gap between optimizing the\ncommonly used distance losses for regressing the parameters of a bounding box\nand maximizing this metric value. The optimal objective for a metric is the\nmetric itself. In the case of axis-aligned 2D bounding boxes, it can be shown\nthat $IoU$ can be directly used as a regression loss. However, $IoU$ has a\nplateau making it infeasible to optimize in the case of non-overlapping\nbounding boxes. In this paper, we address the weaknesses of $IoU$ by\nintroducing a generalized version as both a new loss and a new metric. By\nincorporating this generalized $IoU$ ($GIoU$) as a loss into the state-of-the\nart object detection frameworks, we show a consistent improvement on their\nperformance using both the standard, $IoU$ based, and new, $GIoU$ based,\nperformance measures on popular object detection benchmarks such as PASCAL VOC\nand MS COCO.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:47:33 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 03:18:03 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Rezatofighi", "Hamid", ""], ["Tsoi", "Nathan", ""], ["Gwak", "JunYoung", ""], ["Sadeghian", "Amir", ""], ["Reid", "Ian", ""], ["Savarese", "Silvio", ""]]}, {"id": "1902.09696", "submitter": "Nguyen Van Huynh", "authors": "Nguyen Van Huynh, Dinh Thai Hoang, Diep N. Nguyen, and Eryk Dutkiewicz", "title": "Optimal and Fast Real-time Resources Slicing with Deep Dueling Neural\n  Networks", "comments": "16 pages, 14 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective network slicing requires an infrastructure/network provider to deal\nwith the uncertain demand and real-time dynamics of network resource requests.\nAnother challenge is the combinatorial optimization of numerous resources,\ne.g., radio, computing, and storage. This article develops an optimal and fast\nreal-time resource slicing framework that maximizes the long-term return of the\nnetwork provider while taking into account the uncertainty of resource demand\nfrom tenants. Specifically, we first propose a novel system model which enables\nthe network provider to effectively slice various types of resources to\ndifferent classes of users under separate virtual slices. We then capture the\nreal-time arrival of slice requests by a semi-Markov decision process. To\nobtain the optimal resource allocation policy under the dynamics of slicing\nrequests, e.g., uncertain service time and resource demands, a Q-learning\nalgorithm is often adopted in the literature. However, such an algorithm is\nnotorious for its slow convergence, especially for problems with large\nstate/action spaces. This makes Q-learning practically inapplicable to our case\nin which multiple resources are simultaneously optimized. To tackle it, we\npropose a novel network slicing approach with an advanced deep learning\narchitecture, called deep dueling that attains the optimal average reward much\nfaster than the conventional Q-learning algorithm. This property is especially\ndesirable to cope with real-time resource requests and the dynamic demands of\nusers. Extensive simulations show that the proposed framework yields up to 40%\nhigher long-term average return while being few thousand times faster, compared\nwith state of the art network slicing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 01:46:01 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Van Huynh", "Nguyen", ""], ["Hoang", "Dinh Thai", ""], ["Nguyen", "Diep N.", ""], ["Dutkiewicz", "Eryk", ""]]}, {"id": "1902.09705", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Lorenzo Jamone, Alexandre Bernardino, Giampiero\n  Salvi", "title": "Beyond the Self: Using Grounded Affordances to Interpret and Describe\n  Others' Actions", "comments": "code available at https://github.com/gsaponaro/tcds-gestures, IEEE\n  Transactions on Cognitive and Developmental Systems", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, vol. 12,\n  no. 2, pp. 209-221, June 2020", "doi": "10.1109/TCDS.2018.2882140", "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a developmental approach that allows a robot to interpret and\ndescribe the actions of human agents by reusing previous experience. The robot\nfirst learns the association between words and object affordances by\nmanipulating the objects in its environment. It then uses this information to\nlearn a mapping between its own actions and those performed by a human in a\nshared environment. It finally fuses the information from these two models to\ninterpret and describe human actions in light of its own experience. In our\nexperiments, we show that the model can be used flexibly to do inference on\ndifferent aspects of the scene. We can predict the effects of an action on the\nbasis of object properties. We can revise the belief that a certain action\noccurred, given the observed effects of the human action. In an early action\nrecognition fashion, we can anticipate the effects when the action has only\nbeen partially observed. By estimating the probability of words given the\nevidence and feeding them into a pre-defined grammar, we can generate relevant\ndescriptions of the scene. We believe that this is a step towards providing\nrobots with the fundamental skills to engage in social collaboration with\nhumans.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:14:10 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1902.09706", "submitter": "Wenjian Luo", "authors": "Yamin Hu, Wenjian Luo, Junteng Wang", "title": "Community-based 3-SAT Formulas with a Predefined Solution", "comments": "23 pages; due to the limitation \"The abstract field cannot be longer\n  than 1,920 characters\", the abstract appearing here is slightly shorter than\n  that in the PDF file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial to generate crafted SAT formulas with predefined solutions for\nthe testing and development of SAT solvers since many SAT formulas from\nreal-world applications have solutions. Although some generating algorithms\nhave been proposed to generate SAT formulas with predefined solutions,\ncommunity structures of SAT formulas are not considered. We propose a 3-SAT\nformula generating algorithm that not only guarantees the existence of a\npredefined solution, but also simultaneously considers community structures and\nclause distributions. The proposed 3-SAT formula generating algorithm controls\nthe quality of community structures through controlling (1) the number of\nclauses whose variables have a common community, which we call intra-community\nclauses, and (2) the number of variables that only belong to one community,\nwhich we call intra-community variables. To study the combined effect of\ncommunity structures and clause distributions on the hardness of SAT formulas,\nwe measure solving runtimes of two solvers, gluHack (a leading CDCL solver) and\nCPSparrow (a leading SLS solver), on the generated SAT formulas under different\ngroups of parameter settings. Through extensive experiments, we obtain some\nnoteworthy observations on the SAT formulas generated by the proposed\nalgorithm: (1) The community structure has little or no effects on the hardness\nof SAT formulas with regard to CPSparrow but a strong effect with regard to\ngluHack. (2) Only when the proportion of true literals in a SAT formula in\nterms of the predefined solution is 0.5, SAT formulas are hard-to-solve with\nregard to gluHack; when this proportion is below 0.5, SAT formulas are\nhard-to-solve with regard to CPSparrow. (3) When the ratio of the number of\nclauses to that of variables is around 4.25, the SAT formulas are hard-to-solve\nwith regard to both gluHack and CPSparrow.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:16:30 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Hu", "Yamin", ""], ["Luo", "Wenjian", ""], ["Wang", "Junteng", ""]]}, {"id": "1902.09713", "submitter": "Khalil Mrini", "authors": "Khalil Mrini, Claudiu Musat, Michael Baeriswyl, Martin Jaggi", "title": "Interpretable Structure-aware Document Encoders with Hierarchical\n  Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to create document representations that reflect their\ninternal structure. We modify Tree-LSTMs to hierarchically merge basic elements\nsuch as words and sentences into blocks of increasing complexity. Our Structure\nTree-LSTM implements a hierarchical attention mechanism over individual\ncomponents and combinations thereof. We thus emphasize the usefulness of\nTree-LSTMs for texts larger than a sentence. We show that structure-aware\nencoders can be used to improve the performance of document classification. We\ndemonstrate that our method is resilient to changes to the basic building\nblocks, as it performs well with both sentence and word embeddings. The\nStructure Tree-LSTM outperforms all the baselines on two datasets by leveraging\nstructural clues. We show our model's interpretability by visualizing how our\nmodel distributes attention inside a document. On a third dataset from the\nmedical domain, our model achieves competitive performance with the state of\nthe art. This result shows the Structure Tree-LSTM can leverage dependency\nrelations other than text structure, such as a set of reports on the same\npatient.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 02:54:03 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 05:45:39 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Mrini", "Khalil", ""], ["Musat", "Claudiu", ""], ["Baeriswyl", "Michael", ""], ["Jaggi", "Martin", ""]]}, {"id": "1902.09725", "submitter": "Alexander Turner", "authors": "Alexander Matt Turner, Dylan Hadfield-Menell, Prasad Tadepalli", "title": "Conservative Agency via Attainable Utility Preservation", "comments": "Published in AI, Ethics, and Society 2020", "journal-ref": null, "doi": "10.1145/3375627.3375851", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward functions are easy to misspecify; although designers can make\ncorrections after observing mistakes, an agent pursuing a misspecified reward\nfunction can irreversibly change the state of its environment. If that change\nprecludes optimization of the correctly specified reward function, then\ncorrection is futile. For example, a robotic factory assistant could break\nexpensive equipment due to a reward misspecification; even if the designers\nimmediately correct the reward function, the damage is done. To mitigate this\nrisk, we introduce an approach that balances optimization of the primary reward\nfunction with preservation of the ability to optimize auxiliary reward\nfunctions. Surprisingly, even when the auxiliary reward functions are randomly\ngenerated and therefore uninformative about the correctly specified reward\nfunction, this approach induces conservative, effective behavior.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:42:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 15:31:07 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 15:10:04 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Turner", "Alexander Matt", ""], ["Hadfield-Menell", "Dylan", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1902.09835", "submitter": "C\\'eline Hocquette", "authors": "C\\'eline Hocquette and Stephen H. Muggleton", "title": "Can Meta-Interpretive Learning outperform Deep Reinforcement Learning of\n  Evaluable Game strategies?", "comments": "7 pages 5 figures 3 tables 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  World-class human players have been outperformed in a number of complex two\nperson games (Go, Chess, Checkers) by Deep Reinforcement Learning systems.\nHowever, owing to tractability considerations minimax regret of a learning\nsystem cannot be evaluated in such games. In this paper we consider simple\ngames (Noughts-and-Crosses and Hexapawn) in which minimax regret can be\nefficiently evaluated. We use these games to compare Cumulative Minimax Regret\nfor variants of both standard and deep reinforcement learning against two\nvariants of a new Meta-Interpretive Learning system called MIGO. In our\nexperiments all tested variants of both normal and deep reinforcement learning\nhave worse performance (higher cumulative minimax regret) than both variants of\nMIGO on Noughts-and-Crosses and Hexapawn. Additionally, MIGO's learned rules\nare relatively easy to comprehend, and are demonstrated to achieve significant\ntransfer learning in both directions between Noughts-and-Crosses and Hexapawn.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:04:19 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Hocquette", "C\u00e9line", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "1902.09840", "submitter": "Mikko Lauri", "authors": "Mikko Lauri, Joni Pajarinen, Jan Peters", "title": "Information Gathering in Decentralized POMDPs by Policy Graph\n  Improvement", "comments": "18th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized policies for information gathering are required when multiple\nautonomous agents are deployed to collect data about a phenomenon of interest\nwithout the ability to communicate. Decentralized partially observable Markov\ndecision processes (Dec-POMDPs) are a general, principled model well-suited for\nsuch decentralized multiagent decision-making problems. In this paper, we\ninvestigate Dec-POMDPs for decentralized information gathering problems. An\noptimal solution of a Dec-POMDP maximizes the expected sum of rewards over\ntime. To encourage information gathering, we set the reward as a function of\nthe agents' state information, for example the negative Shannon entropy. We\nprove that if the reward is convex, then the finite-horizon value function of\nthe corresponding Dec-POMDP is also convex. We propose the first heuristic\nalgorithm for information gathering Dec-POMDPs, and empirically prove its\neffectiveness by solving problems an order of magnitude larger than previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 10:18:48 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Lauri", "Mikko", ""], ["Pajarinen", "Joni", ""], ["Peters", "Jan", ""]]}, {"id": "1902.09948", "submitter": "Christian Gumbsch", "authors": "Christian Gumbsch, Martin V. Butz and Georg Martius", "title": "Autonomous Identification and Goal-Directed Invocation of\n  Event-Predictive Behavioral Primitives", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voluntary behavior of humans appears to be composed of small, elementary\nbuilding blocks or behavioral primitives. While this modular organization seems\ncrucial for the learning of complex motor skills and the flexible adaption of\nbehavior to new circumstances, the problem of learning meaningful,\ncompositional abstractions from sensorimotor experiences remains an open\nchallenge. Here, we introduce a computational learning architecture, termed\nsurprise-based behavioral modularization into event-predictive structures\n(SUBMODES), that explores behavior and identifies the underlying behavioral\nunits completely from scratch. The SUBMODES architecture bootstraps\nsensorimotor exploration using a self-organizing neural controller. While\nexploring the behavioral capabilities of its own body, the system learns\nmodular structures that predict the sensorimotor dynamics and generate the\nassociated behavior. In line with recent theories of event perception, the\nsystem uses unexpected prediction error signals, i.e., surprise, to detect\ntransitions between successive behavioral primitives. We show that, when\napplied to two robotic systems with completely different body kinematics, the\nsystem manages to learn a variety of complex and realistic behavioral\nprimitives. Moreover, after initial self-exploration the system can use its\nlearned predictive models progressively more effectively for invoking model\npredictive planning and goal-directed control in different tasks and\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:17:59 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 14:31:46 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Gumbsch", "Christian", ""], ["Butz", "Martin V.", ""], ["Martius", "Georg", ""]]}, {"id": "1902.09980", "submitter": "Tom Everitt", "authors": "Tom Everitt, Pedro A. Ortega, Elizabeth Barnes, Shane Legg", "title": "Understanding Agent Incentives using Causal Influence Diagrams. Part I:\n  Single Action Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents are systems that optimize an objective function in an environment.\nTogether, the goal and the environment induce secondary objectives, incentives.\nModeling the agent-environment interaction using causal influence diagrams, we\ncan answer two fundamental questions about an agent's incentives directly from\nthe graph: (1) which nodes can the agent have an incentivize to observe, and\n(2) which nodes can the agent have an incentivize to control? The answers tell\nus which information and influence points need extra protection. For example,\nwe may want a classifier for job applications to not use the ethnicity of the\ncandidate, and a reinforcement learning agent not to take direct control of its\nreward mechanism. Different algorithms and training paradigms can lead to\ndifferent causal influence diagrams, so our method can be used to identify\nalgorithms with problematic incentives and help in designing algorithms with\nbetter incentives.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 14:54:09 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 12:20:42 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 10:31:00 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 09:57:41 GMT"}, {"version": "v5", "created": "Thu, 1 Aug 2019 16:16:14 GMT"}, {"version": "v6", "created": "Fri, 6 Sep 2019 16:38:10 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Everitt", "Tom", ""], ["Ortega", "Pedro A.", ""], ["Barnes", "Elizabeth", ""], ["Legg", "Shane", ""]]}, {"id": "1902.09992", "submitter": "Ruben Martinez-Cantin", "authors": "Javier Garcia-Barcos, Ruben Martinez-Cantin", "title": "Fully Distributed Bayesian Optimization with Stochastic Policies", "comments": null, "journal-ref": "Proceedings of the International Joint Conference on Artificial\n  Intelligence (IJCAI-19), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a popular method for high-throughput\ncomputing, like the design of computer experiments or hyperparameter tuning of\nexpensive models, where sample efficiency is mandatory. In these applications,\ndistributed and scalable architectures are a necessity. However, Bayesian\noptimization is mostly sequential. Even parallel variants require certain\ncomputations between samples, limiting the parallelization bandwidth. Thompson\nsampling has been previously applied for distributed Bayesian optimization.\nBut, when compared with other acquisition functions in the sequential setting,\nThompson sampling is known to perform suboptimally. In this paper, we present a\nnew method for fully distributed Bayesian optimization, which can be combined\nwith any acquisition function. Our approach considers Bayesian optimization as\na partially observable Markov decision process. In this context, stochastic\npolicies, such as the Boltzmann policy, have some interesting properties which\ncan also be studied for Bayesian optimization. Furthermore, the Boltzmann\npolicy trivially allows a distributed Bayesian optimization implementation with\nhigh level of parallelism and scalability. We present results in several\nbenchmarks and applications that shows the performance of our method.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:13:17 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 17:52:55 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Garcia-Barcos", "Javier", ""], ["Martinez-Cantin", "Ruben", ""]]}, {"id": "1902.09996", "submitter": "Anna Harutyunyan", "authors": "Anna Harutyunyan, Will Dabney, Diana Borsa, Nicolas Heess, Remi Munos,\n  Doina Precup", "title": "The Termination Critic", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of autonomously discovering behavioral\nabstractions, or options, for reinforcement learning agents. We propose an\nalgorithm that focuses on the termination condition, as opposed to -- as is\ncommon -- the policy. The termination condition is usually trained to optimize\na control objective: an option ought to terminate if another has better value.\nWe offer a different, information-theoretic perspective, and propose that\nterminations should focus instead on the compressibility of the option's\nencoding -- arguably a key reason for using abstractions. To achieve this\nalgorithmically, we leverage the classical options framework, and learn the\noption transition model as a \"critic\" for the termination condition. Using this\nmodel, we derive gradients that optimize the desired criteria. We show that the\nresulting options are non-trivial, intuitively meaningful, and useful for\nlearning and planning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:26:10 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Harutyunyan", "Anna", ""], ["Dabney", "Will", ""], ["Borsa", "Diana", ""], ["Heess", "Nicolas", ""], ["Munos", "Remi", ""], ["Precup", "Doina", ""]]}, {"id": "1902.10027", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi and Sudipta Chattopadhyay", "title": "Grammar Based Directed Testing of Machine Learning Systems", "comments": "Accepted to appear in the IEEE Transactions on Software Engineering\n  (TSE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The massive progress of machine learning has seen its application over a\nvariety of domains in the past decade. But how do we develop a systematic,\nscalable and modular strategy to validate machine-learning systems? We present,\nto the best of our knowledge, the first approach, which provides a systematic\ntest framework for machine-learning systems that accepts grammar-based inputs.\nOur OGMA approach automatically discovers erroneous behaviours in classifiers\nand leverages these erroneous behaviours to improve the respective models. OGMA\nleverages inherent robustness properties present in any well trained\nmachine-learning model to direct test generation and thus, implementing a\nscalable test generation methodology. To evaluate our OGMA approach, we have\ntested it on three real world natural language processing (NLP) classifiers. We\nhave found thousands of erroneous behaviours in these systems. We also compare\nOGMA with a random test generation approach and observe that OGMA is more\neffective than such random test generation by up to 489%.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:12:45 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 03:40:34 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 07:15:26 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1902.10058", "submitter": "Peng Yin", "authors": "Peng Yin, Lingyun Xu, Xueqian Li, Chen Yin, Yingli Li, Rangaprasad\n  Arun Srivatsan, Lu Li, Jianmin Ji, Yuqing He", "title": "A Multi-Domain Feature Learning Method for Visual Place Recognition", "comments": "6 pages, 5 figures, ICRA 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Place Recognition (VPR) is an important component in both computer\nvision and robotics applications, thanks to its ability to determine whether a\nplace has been visited and where specifically. A major challenge in VPR is to\nhandle changes of environmental conditions including weather, season and\nillumination. Most VPR methods try to improve the place recognition performance\nby ignoring the environmental factors, leading to decreased accuracy decreases\nwhen environmental conditions change significantly, such as day versus night.\nTo this end, we propose an end-to-end conditional visual place recognition\nmethod. Specifically, we introduce the multi-domain feature learning method\n(MDFL) to capture multiple attribute-descriptions for a given place, and then\nuse a feature detaching module to separate the environmental condition-related\nfeatures from those that are not. The only label required within this feature\nlearning pipeline is the environmental condition. Evaluation of the proposed\nmethod is conducted on the multi-season \\textit{NORDLAND} dataset, and the\nmulti-weather \\textit{GTAV} dataset. Experimental results show that our method\nimproves the feature robustness against variant environmental conditions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 17:09:49 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Yin", "Peng", ""], ["Xu", "Lingyun", ""], ["Li", "Xueqian", ""], ["Yin", "Chen", ""], ["Li", "Yingli", ""], ["Srivatsan", "Rangaprasad Arun", ""], ["Li", "Lu", ""], ["Ji", "Jianmin", ""], ["He", "Yuqing", ""]]}, {"id": "1902.10086", "submitter": "Alexander Kott", "authors": "Alexander Kott, Ethan Stump", "title": "Intelligent Autonomous Things on the Battlefield", "comments": "This is a much expanded version of an earlier conference paper\n  available at arXiv:803.11256", "journal-ref": "In Artificial Intelligence for the Internet of Everything, pp.\n  47-65. Academic Press, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous, artificially intelligent, networked things will populate the\nbattlefield of the future, operating in close collaboration with human\nwarfighters, and fighting as teams in highly adversarial environments. This\nchapter explores the characteristics, capabilities and intelli-gence required\nof such a network of intelligent things and humans - Internet of Battle Things\n(IOBT). The IOBT will experience unique challenges that are not yet well\naddressed by the current generation of AI and machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 17:59:55 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Kott", "Alexander", ""], ["Stump", "Ethan", ""]]}, {"id": "1902.10119", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Pooyan Jamshidi, Marco Valtorta", "title": "Transfer Learning for Performance Modeling of Configurable Systems: A\n  Causal Analysis", "comments": "Accepted for presentation at the First AAAI Spring Symposium: Beyond\n  Curve Fitting: Causation, Counterfactuals, and Imagination-based AI, 2019\n  Stanford, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern systems (e.g., deep neural networks, big data analytics, and\ncompilers) are highly configurable, which means they expose different\nperformance behavior under different configurations. The fundamental challenge\nis that one cannot simply measure all configurations due to the sheer size of\nthe configuration space. Transfer learning has been used to reduce the\nmeasurement efforts by transferring knowledge about performance behavior of\nsystems across environments. Previously, research has shown that statistical\nmodels are indeed transferable across environments. In this work, we\ninvestigate identifiability and transportability of causal effects and\nstatistical relations in highly-configurable systems. Our causal analysis\nagrees with previous exploratory analysis \\cite{Jamshidi17} and confirms that\nthe causal effects of configuration options can be carried over across\nenvironments with high confidence. We expect that the ability to carry over\ncausal relations will enable effective performance analysis of\nhighly-configurable systems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 18:53:38 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Jamshidi", "Pooyan", ""], ["Valtorta", "Marco", ""]]}, {"id": "1902.10126", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Luk\\'a\\v{s} Burget, Pavel Smrz", "title": "BUT-FIT at SemEval-2019 Task 7: Determining the Rumour Stance with\n  Pre-Trained Deep Bidirectional Transformers", "comments": "This work has been submitted to NAACL SemEval workshop. Work in\n  progress", "journal-ref": "Proceedings of the 13th International Workshop on Semantic\n  Evaluation 13 (2019) 1097-1104", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system submitted to SemEval 2019 Task 7: RumourEval\n2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell\net al., 2019). The challenge focused on classifying whether posts from Twitter\nand Reddit support, deny, query, or comment a hidden rumour, truthfulness of\nwhich is the topic of an underlying discussion thread. We formulate the problem\nas a stance classification, determining the rumour stance of a post with\nrespect to the previous thread post and the source thread post. The recent BERT\narchitecture was employed to build an end-to-end system which has reached the\nF1 score of 61.67% on the provided test data. It finished at the 2nd place in\nthe competition, without any hand-crafted features, only 0.2% behind the\nwinner.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:53:01 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 08:43:35 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Fajcik", "Martin", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Smrz", "Pavel", ""]]}, {"id": "1902.10140", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour", "title": "Planning in Hierarchical Reinforcement Learning: Guarantees for Using\n  Local Policies", "comments": "Extends previous paper (arXiv:1803.04674) by the same authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a settings of hierarchical reinforcement learning, in which the\nreward is a sum of components. For each component we are given a policy that\nmaximizes it and our goal is to assemble a policy from the individual policies\nthat maximizes the sum of the components. We provide theoretical guarantees for\nassembling such policies in deterministic MDPs with collectible rewards. Our\napproach builds on formulating this problem as a traveling salesman problem\nwith discounted reward. We focus on local solutions, i.e., policies that only\nuse information from the current state; thus, they are easy to implement and do\nnot require substantial computational resources. We propose three local\nstochastic policies and prove that they guarantee better performance than any\ndeterministic local policy in the worst case; experimental results suggest that\nthey also perform better on average.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:04:18 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 15:59:35 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zahavy", "Tom", ""], ["Hasidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""]]}, {"id": "1902.10162", "submitter": "Jiayi Huang", "authors": "Jiayi Huang, Mostofa Patwary, Gregory Diamos", "title": "Coloring Big Graphs with AlphaGoZero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that recent innovations in deep reinforcement learning can\neffectively color very large graphs -- a well-known NP-hard problem with clear\ncommercial applications. Because the Monte Carlo Tree Search with Upper\nConfidence Bound algorithm used in AlphaGoZero can improve the performance of a\ngiven heuristic, our approach allows deep neural networks trained using high\nperformance computing (HPC) technologies to transform computation into improved\nheuristics with zero prior knowledge. Key to our approach is the introduction\nof a novel deep neural network architecture (FastColorNet) that has access to\nthe full graph context and requires $O(V)$ time and space to color a graph with\n$V$ vertices, which enables scaling to very large graphs that arise in real\napplications like parallel computing, compilers, numerical solvers, and design\nautomation, among others. As a result, we are able to learn new state of the\nart heuristics for graph coloring.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:05:30 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 23:53:29 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 17:24:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Jiayi", ""], ["Patwary", "Mostofa", ""], ["Diamos", "Gregory", ""]]}, {"id": "1902.10176", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer and Jeff Bilmes", "title": "A Memoization Framework for Scaling Submodular Optimization to Large\n  Scale Problems", "comments": "To Appear in Proc. AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are motivated by large scale submodular optimization problems, where\nstandard algorithms that treat the submodular functions in the \\emph{value\noracle model} do not scale. In this paper, we present a model called the\n\\emph{precomputational complexity model}, along with a unifying memoization\nbased framework, which looks at the specific form of the given submodular\nfunction. A key ingredient in this framework is the notion of a\n\\emph{precomputed statistic}, which is maintained in the course of the\nalgorithms. We show that we can easily integrate this idea into a large class\nof submodular optimization problems including constrained and unconstrained\nsubmodular maximization, minimization, difference of submodular optimization,\noptimization with submodular constraints and several other related optimization\nproblems. Moreover, memoization can be integrated in both discrete and\ncontinuous relaxation flavors of algorithms for these problems. We demonstrate\nthis idea for several commonly occurring submodular functions, and show how the\nprecomputational model provides significant speedups compared to the value\noracle model. Finally, we empirically demonstrate this for large scale machine\nlearning problems of data subset selection and summarization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:22:57 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Iyer", "Rishabh", ""], ["Bilmes", "Jeff", ""]]}, {"id": "1902.10178", "submitter": "Wojciech Samek", "authors": "Sebastian Lapuschkin, Stephan W\\\"aldchen, Alexander Binder, Gr\\'egoire\n  Montavon, Wojciech Samek, Klaus-Robert M\\\"uller", "title": "Unmasking Clever Hans Predictors and Assessing What Machines Really\n  Learn", "comments": "Accepted for publication in Nature Communications", "journal-ref": null, "doi": "10.1038/s41467-019-08987-4", "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current learning machines have successfully solved hard application problems,\nreaching high accuracy and displaying seemingly \"intelligent\" behavior. Here we\napply recent techniques for explaining decisions of state-of-the-art learning\nmachines and analyze various tasks from computer vision and arcade games. This\nshowcases a spectrum of problem-solving behaviors ranging from naive and\nshort-sighted, to well-informed and strategic. We observe that standard\nperformance evaluation metrics can be oblivious to distinguishing these diverse\nproblem solving behaviors. Furthermore, we propose our semi-automated Spectral\nRelevance Analysis that provides a practically effective way of characterizing\nand validating the behavior of nonlinear learning machines. This helps to\nassess whether a learned model indeed delivers reliably for the problem that it\nwas conceived for. Furthermore, our work intends to add a voice of caution to\nthe ongoing excitement about machine intelligence and pledges to evaluate and\njudge some of these recent successes in a more nuanced manner.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:25:11 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Lapuschkin", "Sebastian", ""], ["W\u00e4ldchen", "Stephan", ""], ["Binder", "Alexander", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1902.10186", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Byron C. Wallace", "title": "Attention is not Explanation", "comments": "Accepted as NAACL 2019 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have seen wide adoption in neural NLP models. In\naddition to improving predictive performance, these are often touted as\naffording transparency: models equipped with attention provide a distribution\nover attended-to input units, and this is often presented (at least implicitly)\nas communicating the relative importance of inputs. However, it is unclear what\nrelationship exists between attention weights and model outputs. In this work,\nwe perform extensive experiments across a variety of NLP tasks that aim to\nassess the degree to which attention weights provide meaningful `explanations'\nfor predictions. We find that they largely do not. For example, learned\nattention weights are frequently uncorrelated with gradient-based measures of\nfeature importance, and one can identify very different attention distributions\nthat nonetheless yield equivalent predictions. Our findings show that standard\nattention modules do not provide meaningful explanations and should not be\ntreated as though they do. Code for all experiments is available at\nhttps://github.com/successar/AttentionExplanation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 19:59:15 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 16:55:39 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 18:05:56 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Jain", "Sarthak", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1902.10194", "submitter": "Georgi Tinchev", "authors": "Georgi Tinchev, Adrian Penate-Sanchez and Maurice Fallon", "title": "Learning to See the Wood for the Trees: Deep Laser Localization in Urban\n  and Natural Environments on a CPU", "comments": "Accepted for publication at RA-L/ICRA 2019. More info:\n  https://ori.ox.ac.uk/esm-localization", "journal-ref": null, "doi": "10.1109/LRA.2019.2895264", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization in challenging, natural environments such as forests or\nwoodlands is an important capability for many applications from guiding a robot\nnavigating along a forest trail to monitoring vegetation growth with handheld\nsensors. In this work we explore laser-based localization in both urban and\nnatural environments, which is suitable for online applications. We propose a\ndeep learning approach capable of learning meaningful descriptors directly from\n3D point clouds by comparing triplets (anchor, positive and negative examples).\nThe approach learns a feature space representation for a set of segmented point\nclouds that are matched between a current and previous observations. Our\nlearning method is tailored towards loop closure detection resulting in a small\nmodel which can be deployed using only a CPU. The proposed learning method\nwould allow the full pipeline to run on robots with limited computational\npayload such as drones, quadrupeds or UGVs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:13:14 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Tinchev", "Georgi", ""], ["Penate-Sanchez", "Adrian", ""], ["Fallon", "Maurice", ""]]}, {"id": "1902.10213", "submitter": "Qian Hu", "authors": "Qian Hu, Huzefa Rangwala", "title": "Reliable Deep Grade Prediction with Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, college-going students are taking longer to graduate than their\nparental generations. Further, in the United States, the six-year graduation\nrate has been 59% for decades. Improving the educational quality by training\nbetter-prepared students who can successfully graduate in a timely manner is\ncritical. Accurately predicting students' grades in future courses has\nattracted much attention as it can help identify at-risk students early so that\npersonalized feedback can be provided to them on time by advisors. Prior\nresearch on students' grade prediction include shallow linear models; however,\nstudents' learning is a highly complex process that involves the accumulation\nof knowledge across a sequence of courses that can not be sufficiently modeled\nby these linear models. In addition to that, prior approaches focus on\nprediction accuracy without considering prediction uncertainty, which is\nessential for advising and decision making. In this work, we present two types\nof Bayesian deep learning models for grade prediction. The MLP ignores the\ntemporal dynamics of students' knowledge evolution. Hence, we propose RNN for\nstudents' performance prediction. To evaluate the performance of the proposed\nmodels, we performed extensive experiments on data collected from a large\npublic university. The experimental results show that the proposed models\nachieve better performance than prior state-of-the-art approaches. Besides more\naccurate results, Bayesian deep learning models estimate uncertainty associated\nwith the predictions. We explore how uncertainty estimation can be applied\ntowards developing a reliable educational early warning system. In addition to\nuncertainty, we also develop an approach to explain the prediction results,\nwhich is useful for advisors to provide personalized feedback to students.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:47:51 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Hu", "Qian", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1902.10214", "submitter": "Chun-Liang Li", "authors": "Chun-Liang Li, Wei-Cheng Chang, Youssef Mroueh, Yiming Yang,\n  Barnab\\'as P\\'oczos", "title": "Implicit Kernel Learning", "comments": "In the Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernels are powerful and versatile tools in machine learning and statistics.\nAlthough the notion of universal kernels and characteristic kernels has been\nstudied, kernel selection still greatly influences the empirical performance.\nWhile learning the kernel in a data driven way has been investigated, in this\npaper we explore learning the spectral distribution of kernel via implicit\ngenerative models parametrized by deep neural networks. We called our method\nImplicit Kernel Learning (IKL). The proposed framework is simple to train and\ninference is performed via sampling random Fourier features. We investigate two\napplications of the proposed IKL as examples, including generative adversarial\nnetworks with MMD (MMD GAN) and standard supervised learning. Empirically, MMD\nGAN with IKL outperforms vanilla predefined kernels on both image and text\ngeneration benchmarks; using IKL with Random Kitchen Sinks also leads to\nsubstantial improvement over existing state-of-the-art kernel learning\nalgorithms on popular supervised learning benchmarks. Theory and conditions for\nusing IKL in both applications are also studied as well as connections to\nprevious state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:47:56 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Li", "Chun-Liang", ""], ["Chang", "Wei-Cheng", ""], ["Mroueh", "Youssef", ""], ["Yang", "Yiming", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "1902.10319", "submitter": "Eric Liang", "authors": "Eric Liang, Hang Zhu, Xin Jin, Ion Stoica", "title": "Neural Packet Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Packet classification is a fundamental problem in computer networking. This\nproblem exposes a hard tradeoff between the computation and state complexity,\nwhich makes it particularly challenging. To navigate this tradeoff, existing\nsolutions rely on complex hand-tuned heuristics, which are brittle and hard to\noptimize. In this paper, we propose a deep reinforcement learning (RL) approach\nto solve the packet classification problem. There are several characteristics\nthat make this problem a good fit for Deep RL. First, many of the existing\nsolutions are iteratively building a decision tree by splitting nodes in the\ntree. Second, the effects of these actions (e.g., splitting nodes) can only be\nevaluated once we are done with building the tree. These two characteristics\nare naturally captured by the ability of RL to take actions that have sparse\nand delayed rewards. Third, it is computationally efficient to generate data\ntraces and evaluate decision trees, which alleviate the notoriously high sample\ncomplexity problem of Deep RL algorithms. Our solution, NeuroCuts, uses\nsuccinct representations to encode state and action space, and efficiently\nexplore candidate decision trees to optimize for a global objective. It\nproduces compact decision trees optimized for a specific set of rules and a\ngiven performance metric, such as classification time, memory footprint, or a\ncombination of the two. Evaluation on ClassBench shows that NeuroCuts\noutperforms existing hand-crafted algorithms in classification time by 18% at\nthe median, and reduces both time and memory footprint by up to 3x.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 03:24:40 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Liang", "Eric", ""], ["Zhu", "Hang", ""], ["Jin", "Xin", ""], ["Stoica", "Ion", ""]]}, {"id": "1902.10499", "submitter": "Maxat Kulmanov", "authors": "Maxat Kulmanov, Wang Liu-Wei, Yuan Yan and Robert Hoehndorf", "title": "EL Embeddings: Geometric construction of models for the Description\n  Logic EL ++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An embedding is a function that maps entities from one algebraic structure\ninto another while preserving certain characteristics. Embeddings are being\nused successfully for mapping relational data or text into vector spaces where\nthey can be used for machine learning, similarity search, or similar tasks. We\naddress the problem of finding vector space embeddings for theories in the\nDescription Logic $\\mathcal{EL}^{++}$ that are also models of the TBox. To find\nsuch embeddings, we define an optimization problem that characterizes the\nmodel-theoretic semantics of the operators in $\\mathcal{EL}^{++}$ within\n$\\Re^n$, thereby solving the problem of finding an interpretation function for\nan $\\mathcal{EL}^{++}$ theory given a particular domain $\\Delta$. Our approach\nis mainly relevant to large $\\mathcal{EL}^{++}$ theories and knowledge bases\nsuch as the ontologies and knowledge graphs used in the life sciences. We\ndemonstrate that our method can be used for improved prediction of\nprotein--protein interactions when compared to semantic similarity measures or\nknowledge graph embedding\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:04:44 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Kulmanov", "Maxat", ""], ["Liu-Wei", "Wang", ""], ["Yan", "Yuan", ""], ["Hoehndorf", "Robert", ""]]}, {"id": "1902.10552", "submitter": "Marcos Cramer", "authors": "Marcos Cramer, Mathieu Guillaume", "title": "Technical report of \"Empirical Study on Human Evaluation of Complex\n  Argumentation Frameworks\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In abstract argumentation, multiple argumentation semantics have been\nproposed that allow to select sets of jointly acceptable arguments from a given\nargumentation framework, i.e. based only on the attack relation between\narguments. The existence of multiple argumentation semantics raises the\nquestion which of these semantics predicts best how humans evaluate arguments.\nPrevious empirical cognitive studies that have tested how humans evaluate sets\nof arguments depending on the attack relation between them have been limited to\na small set of very simple argumentation frameworks, so that some semantics\nstudied in the literature could not be meaningfully distinguished by these\nstudies. In this paper we report on an empirical cognitive study that overcomes\nthese limitations by taking into consideration twelve argumentation frameworks\nof three to eight arguments each. These argumentation frameworks were mostly\nmore complex than the argumentation frameworks considered in previous studies.\nAll twelve argumentation framework were systematically instantiated with\nnatural language arguments based on a certain fictional scenario, and\nparticipants were shown both the natural language arguments and a graphical\ndepiction of the attack relation between them. Our data shows that grounded and\nCF2 semantics were the best predictors of human argument evaluation. A detailed\nanalysis revealed that part of the participants chose a cognitively simpler\nstrategy that is predicted very well by grounded semantics, while another part\nof the participants chose a cognitively more demanding strategy that is mostly\npredicted well by CF2 semantics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 14:29:34 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Cramer", "Marcos", ""], ["Guillaume", "Mathieu", ""]]}, {"id": "1902.10590", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng, Dhiraj Gulati, Rongjie Yan", "title": "Architecting Dependable Learning-enabled Autonomous Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a summary over architectural approaches that can be used to\nconstruct dependable learning-enabled autonomous systems, with a focus on\nautomated driving. We consider three technology pillars for architecting\ndependable autonomy, namely diverse redundancy, information fusion, and runtime\nmonitoring. For learning-enabled components, we additionally summarize recent\narchitectural approaches to increase the dependability beyond standard\nconvolutional neural networks. We conclude the study with a list of promising\nresearch directions addressing the challenges of existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 15:31:34 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Cheng", "Chih-Hong", ""], ["Gulati", "Dhiraj", ""], ["Yan", "Rongjie", ""]]}, {"id": "1902.10619", "submitter": "Craig Innes", "authors": "Craig Innes, Alex Lascarides", "title": "Learning Factored Markov Decision Processes with Unawareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for learning and planning in sequential decision problems often\nassume the learner is aware of all possible states and actions in advance. This\nassumption is sometimes untenable. In this paper, we give a method to learn\nfactored markov decision problems from both domain exploration and expert\nassistance, which guarantees convergence to near-optimal behaviour, even when\nthe agent begins unaware of factors critical to success. Our experiments show\nour agent learns optimal behaviour on small and large problems, and that\nconserving information on discovering new possibilities results in faster\nconvergence.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 16:21:13 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Innes", "Craig", ""], ["Lascarides", "Alex", ""]]}, {"id": "1902.10644", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Provable Guarantees for Gradient-Based Meta-Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of meta-learning through the lens of online convex\noptimization, developing a meta-algorithm bridging the gap between popular\ngradient-based meta-learning and classical regularization-based multi-task\ntransfer methods. Our method is the first to simultaneously satisfy good sample\nefficiency guarantees in the convex setting, with generalization bounds that\nimprove with task-similarity, while also being computationally scalable to\nmodern deep learning architectures and the many-task setting. Despite its\nsimplicity, the algorithm matches, up to a constant factor, a lower bound on\nthe performance of any such parameter-transfer method under natural task\nsimilarity assumptions. We use experiments in both convex and deep learning\nsettings to verify and demonstrate the applicability of our theory.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:24:38 GMT"}, {"version": "v2", "created": "Thu, 16 May 2019 13:27:36 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "1902.10646", "submitter": "Adish Singla", "authors": "Rishav Chourasia, Adish Singla", "title": "Unifying Ensemble Methods for Q-learning via Social Choice Theory", "comments": "Learning with Rich Experience (LIRE) Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods have been widely applied in Reinforcement Learning (RL) in\norder to enhance stability, increase convergence speed, and improve\nexploration. These methods typically work by employing an aggregation mechanism\nover actions of different RL algorithms. We show that a variety of these\nmethods can be unified by drawing parallels from committee voting rules in\nSocial Choice Theory. We map the problem of designing an action aggregation\nmechanism in an ensemble method to a voting problem which, under different\nvoting rules, yield popular ensemble-based RL algorithms like Majority Voting\nQ-learning or Bootstrapped Q-learning. Our unification framework, in turn,\nallows us to design new ensemble-RL algorithms with better performance. For\ninstance, we map two diversity-centered committee voting rules, namely Single\nNon-Transferable Voting Rule and Chamberlin-Courant Rule, into new RL\nalgorithms that demonstrate excellent exploratory behavior in our experiments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 17:27:30 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 09:14:26 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Chourasia", "Rishav", ""], ["Singla", "Adish", ""]]}, {"id": "1902.10667", "submitter": "Omid Rohanian", "authors": "Omid Rohanian, Shiva Taslimipoor, Samaneh Kouchaki, Le An Ha, Ruslan\n  Mitkov", "title": "Bridging the Gap: Attending to Discontinuity in Identification of\n  Multiword Expressions", "comments": "Accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method to tag Multiword Expressions (MWEs) using a\nlinguistically interpretable language-independent deep learning architecture.\nWe specifically target discontinuity, an under-explored aspect that poses a\nsignificant challenge to computational treatment of MWEs. Two neural\narchitectures are explored: Graph Convolutional Network (GCN) and multi-head\nself-attention. GCN leverages dependency parse information, and self-attention\nattends to long-range relations. We finally propose a combined model that\nintegrates complementary information from both through a gating mechanism. The\nexperiments on a standard multilingual dataset for verbal MWEs show that our\nmodel outperforms the baselines not only in the case of discontinuous MWEs but\nalso in overall F-score.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:01:53 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 13:41:57 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Rohanian", "Omid", ""], ["Taslimipoor", "Shiva", ""], ["Kouchaki", "Samaneh", ""], ["Ha", "Le An", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "1902.10677", "submitter": "Tal Friedman", "authors": "Tal Friedman, Guy Van den Broeck", "title": "On Constrained Open-World Probabilistic Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing amounts of available data have led to a heightened need for\nrepresenting large-scale probabilistic knowledge bases. One approach is to use\na probabilistic database, a model with strong assumptions that allow for\nefficiently answering many interesting queries. Recent work on open-world\nprobabilistic databases strengthens the semantics of these probabilistic\ndatabases by discarding the assumption that any information not present in the\ndata must be false. While intuitive, these semantics are not sufficiently\nprecise to give reasonable answers to queries. We propose overcoming these\nissues by using constraints to restrict this open world. We provide an\nalgorithm for one class of queries, and establish a basic hardness result for\nanother. Finally, we propose an efficient and tight approximation for a large\nclass of queries.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 18:31:10 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 19:02:17 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Friedman", "Tal", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1902.10731", "submitter": "Shay Moran", "authors": "Amos Beimel and Shay Moran and Kobbi Nissim and Uri Stemmer", "title": "Private Center Points and Learning of Halfspaces", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a private learner for halfspaces over an arbitrary finite domain\n$X\\subset \\mathbb{R}^d$ with sample complexity $mathrm{poly}(d,2^{\\log^*|X|})$.\nThe building block for this learner is a differentially private algorithm for\nlocating an approximate center point of $m>\\mathrm{poly}(d,2^{\\log^*|X|})$\npoints -- a high dimensional generalization of the median function. Our\nconstruction establishes a relationship between these two problems that is\nreminiscent of the relation between the median and learning one-dimensional\nthresholds [Bun et al.\\ FOCS '15]. This relationship suggests that the problem\nof privately locating a center point may have further applications in the\ndesign of differentially private algorithms.\n  We also provide a lower bound on the sample complexity for privately finding\na point in the convex hull. For approximate differential privacy, we show a\nlower bound of $m=\\Omega(d+\\log^*|X|)$, whereas for pure differential privacy\n$m=\\Omega(d\\log|X|)$.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 19:06:12 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Beimel", "Amos", ""], ["Moran", "Shay", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1902.10770", "submitter": "Vahid Mokhtari", "authors": "Vahid Mokhtari, Luis Seabra Lopes, Armando Pinho and Roman Manevich", "title": "Learning Task Knowledge and its Scope of Applicability in\n  Experience-Based Planning Domains", "comments": "25 pages, 6 figures, 6 tables, 1 algorithm, 6 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience-based planning domains (EBPDs) have been recently proposed to\nimprove problem solving by learning from experience. EBPDs provide important\nconcepts for long-term learning and planning in robotics. They rely on\nacquiring and using task knowledge, i.e., activity schemata, for generating\nconcrete solutions to problem instances in a class of tasks. Using Three-Valued\nLogic Analysis (TVLA), we extend previous work to generate a set of conditions\nas the scope of applicability for an activity schema. The inferred scope is a\nbounded representation of a set of problems of potentially unbounded size, in\nthe form of a 3-valued logical structure, which allows an EBPD system to\nautomatically find an applicable activity schema for solving task problems. We\ndemonstrate the utility of our approach in a set of classes of problems in a\nsimulated domain and a class of real world tasks in a fully physically\nsimulated PR2 robot in Gazebo.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 20:32:29 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 11:28:10 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Mokhtari", "Vahid", ""], ["Lopes", "Luis Seabra", ""], ["Pinho", "Armando", ""], ["Manevich", "Roman", ""]]}, {"id": "1902.10798", "submitter": "Yitao Liang", "authors": "Yitao Liang and Guy Van den Broeck", "title": "Learning Logistic Circuits", "comments": "Published in the Proceedings of the Thirty-Third AAAI Conference on\n  Artificial Intelligence (AAAI19)", "journal-ref": "@proceedings{liang2019logistic, title = {Proceedings of the\n  Thirty-Third {AAAI} Conference on Artificial Intelligence (AAAI-19)},\n  publisher = {{AAAI} Press}, year = {2019} }", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new classification model called logistic circuits. On\nMNIST and Fashion datasets, our learning algorithm outperforms neural networks\nthat have an order of magnitude more parameters. Yet, logistic circuits have a\ndistinct origin in symbolic AI, forming a discriminative counterpart to\nprobabilistic-logical circuits such as ACs, SPNs, and PSDDs. We show that\nparameter learning for logistic circuits is convex optimization, and that a\nsimple local search algorithm can induce strong model structures from data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 21:49:29 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "1902.10870", "submitter": "Takayuki Osogami Ph.D.", "authors": "Takayuki Osogami, Toshihiro Takahashi", "title": "Real-time tree search with pessimistic scenarios", "comments": "14 pages, 3 figures, Published as IBM Research Report RT0982", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents need to make decisions in a sequential manner, under\npartially observable environment, and in consideration of how other agents\nbehave. In critical situations, such decisions need to be made in real time for\nexample to avoid collisions and recover to safe conditions. We propose a\ntechnique of tree search where a deterministic and pessimistic scenario is used\nafter a specified depth. Because there is no branching with the deterministic\nscenario, the proposed technique allows us to take into account the events that\ncan occur far ahead in the future. The effectiveness of the proposed technique\nis demonstrated in Pommerman, a multi-agent environment used in a NeurIPS 2018\ncompetition, where the agents that implement the proposed technique have won\nthe first and third places.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 02:47:05 GMT"}, {"version": "v2", "created": "Sun, 14 Jul 2019 12:28:45 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Osogami", "Takayuki", ""], ["Takahashi", "Toshihiro", ""]]}, {"id": "1902.10899", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Qiang Zhang, Rongyao Fang, Bingbing Ni, Jinxian Liu,\n  Qi Tian", "title": "Adversarial Attack and Defense on Point Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emergence of the utility of 3D point cloud data in safety-critical vision\ntasks (e.g., ADAS) urges researchers to pay more attention to the robustness of\n3D representations and deep networks. To this end, we develop an attack and\ndefense scheme, dedicated to 3D point cloud data, for preventing 3D point\nclouds from manipulated as well as pursuing noise-tolerable 3D representation.\nA set of novel 3D point cloud attack operations are proposed via pointwise\ngradient perturbation and adversarial point attachment / detachment. We then\ndevelop a flexible perturbation-measurement scheme for 3D point cloud data to\ndetect potential attack data or noisy sensing data. Notably, the proposed\ndefense methods are even effective to detect the adversarial point clouds\ngenerated by a proof-of-concept attack directly targeting the defense.\nTransferability of adversarial attacks between several point cloud networks is\naddressed, and we propose an momentum-enhanced pointwise gradient to improve\nthe attack transferability. We further analyze the transferability from\nadversarial point clouds to grid CNNs and the inverse. Extensive experimental\nresults on common point cloud benchmarks demonstrate the validity of the\nproposed 3D attack and defense framework.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 05:27:40 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 16:31:38 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:13:03 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 16:03:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yang", "Jiancheng", ""], ["Zhang", "Qiang", ""], ["Fang", "Rongyao", ""], ["Ni", "Bingbing", ""], ["Liu", "Jinxian", ""], ["Tian", "Qi", ""]]}, {"id": "1902.11074", "submitter": "Ning Gui Prof. dr.", "authors": "Ning Gui, Danni Ge, Ziyin Hu", "title": "AFS: An Attention-based mechanism for Supervised Feature Selection", "comments": "9 pages, 5 figures, published in the AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective data preprocessing step, feature selection has shown its\neffectiveness to prepare high-dimensional data for many machine learning tasks.\nThe proliferation of high di-mension and huge volume big data, however, has\nbrought major challenges, e.g. computation complexity and stability on noisy\ndata, upon existing feature-selection techniques. This paper introduces a novel\nneural network-based feature selection architecture, dubbed Attention-based\nFeature Selec-tion (AFS). AFS consists of two detachable modules: an at-tention\nmodule for feature weight generation and a learning module for the problem\nmodeling. The attention module for-mulates correlation problem among features\nand supervision target into a binary classification problem, supported by a\nshallow attention net for each feature. Feature weights are generated based on\nthe distribution of respective feature se-lection patterns adjusted by\nbackpropagation during the train-ing process. The detachable structure allows\nexisting off-the-shelf models to be directly reused, which allows for much less\ntraining time, demands for the training data and requirements for expertise. A\nhybrid initialization method is also intro-duced to boost the selection\naccuracy for datasets without enough samples for feature weight generation.\nExperimental results show that AFS achieves the best accuracy and stability in\ncomparison to several state-of-art feature selection algo-rithms upon both\nMNIST, noisy MNIST and several datasets with small samples.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 13:34:11 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Gui", "Ning", ""], ["Ge", "Danni", ""], ["Hu", "Ziyin", ""]]}, {"id": "1902.11106", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Turker Ince, Alexandros Iosifidis and Moncef Gabbouj", "title": "Operational Neural Networks", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward, fully-connected Artificial Neural Networks (ANNs) or the\nso-called Multi-Layer Perceptrons (MLPs) are well-known universal\napproximators. However, their learning performance varies significantly\ndepending on the function or the solution space that they attempt to\napproximate. This is mainly because of their homogenous configuration based\nsolely on the linear neuron model. Therefore, while they learn very well those\nproblems with a monotonous, relatively simple and linearly separable solution\nspace, they may entirely fail to do so when the solution space is highly\nnonlinear and complex. Sharing the same linear neuron model with two additional\nconstraints (local connections and weight sharing), this is also true for the\nconventional Convolutional Neural Networks (CNNs) and, it is, therefore, not\nsurprising that in many challenging problems only the deep CNNs with a massive\ncomplexity and depth can achieve the required diversity and the learning\nperformance. In order to address this drawback and also to accomplish a more\ngeneralized model over the convolutional neurons, this study proposes a novel\nnetwork model, called Operational Neural Networks (ONNs), which can be\nheterogeneous and encapsulate neurons with any set of operators to boost\ndiversity and to learn highly complex and multi-modal functions or spaces with\nminimal network complexity and training data. Finally, a novel training method\nis formulated to back-propagate the error through the operational layers of\nONNs. Experimental results over highly challenging problems demonstrate the\nsuperior learning capabilities of ONNs even with few neurons and hidden layers.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 20:13:51 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 11:19:56 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1902.11122", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos and Dimitrios Koutsouris", "title": "Deep Learning in Cardiology", "comments": "27 pages, 2 figures, 10 tables", "journal-ref": "IEEE Reviews in Biomedical Engineering 12 (2019): 168-193", "doi": "10.1109/RBME.2018.2885714", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical field is creating large amount of data that physicians are unable\nto decipher and use efficiently. Moreover, rule-based expert systems are\ninefficient in solving complicated medical tasks or for creating insights using\nbig data. Deep learning has emerged as a more accurate and effective technology\nin a wide range of medical problems such as diagnosis, prediction and\nintervention. Deep learning is a representation learning method that consists\nof layers that transform the data non-linearly, thus, revealing hierarchical\nrelationships and structures. In this review we survey deep learning\napplication papers that use structured data, signal and imaging modalities from\ncardiology. We discuss the advantages and limitations of applying deep learning\nin cardiology that also apply in medicine in general, while proposing certain\ndirections as the most viable for clinical use.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 10:09:11 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 21:22:09 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:43:32 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""], ["Koutsouris", "Dimitrios", ""]]}, {"id": "1902.11205", "submitter": "Xiang Gao", "authors": "Xiang Gao, Sungjin Lee, Yizhe Zhang, Chris Brockett, Michel Galley,\n  Jianfeng Gao, Bill Dolan", "title": "Jointly Optimizing Diversity and Relevance in Neural Response Generation", "comments": "Long paper accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent neural conversation models have shown great potential, they\noften generate bland and generic responses. While various approaches have been\nexplored to diversify the output of the conversation model, the improvement\noften comes at the cost of decreased relevance. In this paper, we propose a\nSpaceFusion model to jointly optimize diversity and relevance that essentially\nfuses the latent space of a sequence-to-sequence model and that of an\nautoencoder model by leveraging novel regularization terms. As a result, our\napproach induces a latent space in which the distance and direction from the\npredicted response vector roughly match the relevance and diversity,\nrespectively. This property also lends itself well to an intuitive\nvisualization of the latent space. Both automatic and human evaluation results\ndemonstrate that the proposed approach brings significant improvement compared\nto strong baselines in both diversity and relevance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 16:45:19 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 02:29:46 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 18:09:05 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Gao", "Xiang", ""], ["Lee", "Sungjin", ""], ["Zhang", "Yizhe", ""], ["Brockett", "Chris", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}]