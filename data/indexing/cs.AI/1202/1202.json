[{"id": "1202.0255", "submitter": "Graham White", "authors": "Graham White", "title": "Reasoning about Unreliable Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the philosopher Davidson's semantics of actions, using a strongly\ntyped logic with contexts given by sets of partial equations between the\noutcomes of actions. This provides a perspicuous and elegant treatment of\nreasoning about action, analogous to Reiter's work on artificial intelligence.\nWe define a sequent calculus for this logic, prove cut elimination, and give a\nsemantics based on fibrations over partial cartesian categories: we give a\nstructure theory for such fibrations. The existence of lax comma objects is\nnecessary for the proof of cut elimination, and we give conditions on the\ndomain fibration of a partial cartesian category for such comma objects to\nexist.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 19:40:18 GMT"}, {"version": "v2", "created": "Thu, 3 May 2012 13:24:56 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["White", "Graham", ""]]}, {"id": "1202.0440", "submitter": "Matej Hoffmann", "authors": "Matej Hoffmann and Rolf Pfeifer", "title": "The implications of embodiment for behavior and cognition: animal and\n  robotic case studies", "comments": "Book chapter in W. Tschacher & C. Bergomi, ed., 'The Implications of\n  Embodiment: Cognition and Communication', Exeter: Imprint Academic, pp. 31-58", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will argue that if we want to understand the function of\nthe brain (or the control in the case of robots), we must understand how the\nbrain is embedded into the physical system, and how the organism interacts with\nthe real world. While embodiment has often been used in its trivial meaning,\ni.e. 'intelligence requires a body', the concept has deeper and more important\nimplications, concerned with the relation between physical and information\n(neural, control) processes. A number of case studies are presented to\nillustrate the concept. These involve animals and robots and are concentrated\naround locomotion, grasping, and visual perception. A theoretical scheme that\ncan be used to embed the diverse case studies will be presented. Finally, we\nwill establish a link between the low-level sensory-motor processes and\ncognition. We will present an embodied view on categorization, and propose the\nconcepts of 'body schema' and 'forward models' as a natural extension of the\nembodied approach toward first representations.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 14:25:38 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Hoffmann", "Matej", ""], ["Pfeifer", "Rolf", ""]]}, {"id": "1202.0515", "submitter": "Makoto Yamada", "authors": "Makoto Yamada, Wittawat Jitkrittum, Leonid Sigal, Eric P. Xing,\n  Masashi Sugiyama", "title": "High-Dimensional Feature Selection by Feature-Wise Kernelized Lasso", "comments": "18 pages", "journal-ref": "Neural Computation 2014", "doi": "10.1162/NECO_a_00537", "report-no": null, "categories": "stat.ML cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of supervised feature selection is to find a subset of input\nfeatures that are responsible for predicting output values. The least absolute\nshrinkage and selection operator (Lasso) allows computationally efficient\nfeature selection based on linear dependency between input features and output\nvalues. In this paper, we consider a feature-wise kernelized Lasso for\ncapturing non-linear input-output dependency. We first show that, with\nparticular choices of kernel functions, non-redundant features with strong\nstatistical dependence on output values can be found in terms of kernel-based\nindependence measures. We then show that the globally optimal solution can be\nefficiently computed; this makes the approach scalable to high-dimensional\nproblems. The effectiveness of the proposed method is demonstrated through\nfeature selection experiments with thousands of features.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2012 19:06:02 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2012 02:26:05 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2013 05:25:29 GMT"}, {"version": "v4", "created": "Fri, 4 Jan 2019 00:04:52 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Yamada", "Makoto", ""], ["Jitkrittum", "Wittawat", ""], ["Sigal", "Leonid", ""], ["Xing", "Eric P.", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1202.0837", "submitter": "Jose Hernandez-Orallo", "authors": "Javier Insa-Cabrera, Jose-Luis Benacloch-Ayuso, Jose Hernandez-Orallo", "title": "On the influence of intelligence in (social) intelligence testing\n  environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the influence of including agents of different degrees of\nintelligence in a multiagent system. The goal is to better understand how we\ncan develop intelligence tests that can evaluate social intelligence. We\nanalyse several reinforcement algorithms in several contexts of cooperation and\ncompetition. Our experimental setting is inspired by the recently developed\nDarwin-Wallace distribution.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 22:38:04 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Insa-Cabrera", "Javier", ""], ["Benacloch-Ayuso", "Jose-Luis", ""], ["Hernandez-Orallo", "Jose", ""]]}, {"id": "1202.0862", "submitter": "Sarang Aravamuthan", "authors": "Sarang Aravamuthan and Biswajit Ganguly", "title": "e-Valuate: A Two-player Game on Arithmetic Expressions -- An Update", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  e-Valuate is a game on arithmetic expressions. The players have contrasting\nroles of maximizing and minimizing the given expression. The maximizer proposes\nvalues and the minimizer substitutes them for variables of his choice. When the\nexpression is fully instantiated, its value is compared with a certain minimax\nvalue that would result if the players played to their optimal strategies. The\nwinner is declared based on this comparison.\n  We use a game tree to represent the state of the game and show how the\nminimax value can be computed efficiently using backward induction and\nalpha-beta pruning. The efficacy of alpha-beta pruning depends on the order in\nwhich the nodes are evaluated. Further improvements can be obtained by using\ntransposition tables to prevent reevaluation of the same nodes. We propose a\nheuristic for node ordering. We show how the use of the heuristic and\ntransposition tables lead to improved performance by comparing the number of\nnodes pruned by each method.\n  We describe some domain-specific variants of this game. The first is a graph\ntheoretic formulation wherein two players share a set of elements of a graph by\ncoloring a related set with each player looking to maximize his share. The set\nbeing shared could be either the set of vertices, edges or faces (for a planar\ngraph). An application of this is the sharing of regions enclosed by a planar\ngraph where each player's aim is to maximize the area of his share. Another\nvariant is a tiling game where the players alternately place dominoes on a $8\n\\times 8$ checkerboard to construct a maximal partial tiling. We show that the\nsize of the tiling $x$ satisfies $22 \\le x \\le 32$ by proving that any maximal\npartial tiling requires at least $22$ dominoes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 02:38:36 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 14:54:22 GMT"}, {"version": "v3", "created": "Mon, 30 Jun 2014 12:42:39 GMT"}, {"version": "v4", "created": "Fri, 12 Sep 2014 18:28:39 GMT"}], "update_date": "2014-09-15", "authors_parsed": [["Aravamuthan", "Sarang", ""], ["Ganguly", "Biswajit", ""]]}, {"id": "1202.0914", "submitter": "Sebastian Rudolph", "authors": "Sebastian Rudolph (Karlsruhe Institute of Technology), Markus\n  Kr\\\"otzsch (Oxford University), Pascal Hitzler (Wright State University,\n  Dayton, Ohio)", "title": "Type-elimination-based reasoning for the description logic SHIQbs using\n  decision diagrams and disjunctive datalog", "comments": "38 pages, 3 figures, camera ready version of paper accepted for\n  publication in Logical Methods in Computer Science", "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (February\n  27, 2012) lmcs:806", "doi": "10.2168/LMCS-8(1:12)2012", "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, type-elimination-based method for reasoning in the\ndescription logic SHIQbs including DL-safe rules. To this end, we first\nestablish a knowledge compilation method converting the terminological part of\nan ALCIb knowledge base into an ordered binary decision diagram (OBDD) which\nrepresents a canonical model. This OBDD can in turn be transformed into\ndisjunctive Datalog and merged with the assertional part of the knowledge base\nin order to perform combined reasoning. In order to leverage our technique for\nfull SHIQbs, we provide a stepwise reduction from SHIQbs to ALCIb that\npreserves satisfiability and entailment of positive and negative ground facts.\nThe proposed technique is shown to be worst case optimal w.r.t. combined and\ndata complexity and easily admits extensions with ground conjunctive queries.\n", "versions": [{"version": "v1", "created": "Sat, 4 Feb 2012 18:50:13 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 23:59:27 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Rudolph", "Sebastian", "", "Karlsruhe Institute of Technology"], ["Kr\u00f6tzsch", "Markus", "", "Oxford University"], ["Hitzler", "Pascal", "", "Wright State University,\n  Dayton, Ohio"]]}, {"id": "1202.0940", "submitter": "Alex James Dr", "authors": "Alex Pappachen James and Akshay Maan", "title": "Improving feature selection algorithms using normalised feature\n  histograms", "comments": null, "journal-ref": "Electronics Letters,47, 8, 490-491, 2011", "doi": "10.1049/el.2010.3672", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The proposed feature selection method builds a histogram of the most stable\nfeatures from random subsets of a training set and ranks the features based on\na classifier based cross-validation. This approach reduces the instability of\nfeatures obtained by conventional feature selection methods that occur with\nvariation in training data and selection criteria. Classification results on\nfour microarray and three image datasets using three major feature selection\ncriteria and a naive Bayes classifier show considerable improvement over\nbenchmark results.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2012 04:37:40 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["James", "Alex Pappachen", ""], ["Maan", "Akshay", ""]]}, {"id": "1202.0984", "submitter": "Aidan Hogan", "authors": "Birte Glimm and Aidan Hogan and Markus Kr\\\"otzsch and Axel Polleres", "title": "OWL: Yet to arrive on the Web of Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seven years on from OWL becoming a W3C recommendation, and two years on from\nthe more recent OWL 2 W3C recommendation, OWL has still experienced only patchy\nuptake on the Web. Although certain OWL features (like owl:sameAs) are very\npopular, other features of OWL are largely neglected by publishers in the\nLinked Data world. This may suggest that despite the promise of easy\nimplementations and the proposal of tractable profiles suggested in OWL's\nsecond version, there is still no \"right\" standard fragment for the Linked Data\ncommunity. In this paper, we (1) analyse uptake of OWL on the Web of Data, (2)\ngain insights into the OWL fragment that is actually used/usable on the Web,\nwhere we arrive at the conclusion that this fragment is likely to be a\nsimplified profile based on OWL RL, (3) propose and discuss such a new\nfragment, which we call OWL LD (for Linked Data).\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2012 17:51:00 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Glimm", "Birte", ""], ["Hogan", "Aidan", ""], ["Kr\u00f6tzsch", "Markus", ""], ["Polleres", "Axel", ""]]}, {"id": "1202.1395", "submitter": "Majid Yousefikhoshbakht", "authors": "Majid Yousefikhoshbakht, Farzad Didehvar, Farhad Rahmati", "title": "Modification of the Elite Ant System in Order to Avoid Local Optimum\n  Points in the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new algorithm which is a modified version of the\nelite ant system (EAS) algorithm. The new version utilizes an effective\ncriterion for escaping from the local optimum points. In contrast to the\nclassical EAC algorithms, the proposed algorithm uses only a global updating,\nwhich will increase pheromone on the edges of the best (i.e. the shortest)\nroute and will at the same time decrease the amount of pheromone on the edges\nof the worst (i.e. the longest) route. In order to assess the efficiency of the\nnew algorithm, some standard traveling salesman problems (TSPs) were studied\nand their results were compared with classical EAC and other well-known\nmeta-heuristic algorithms. The results indicate that the proposed algorithm has\nbeen able to improve the efficiency of the algorithms in all instances and it\nis competitive with other algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 11:12:22 GMT"}], "update_date": "2012-02-08", "authors_parsed": [["Yousefikhoshbakht", "Majid", ""], ["Didehvar", "Farzad", ""], ["Rahmati", "Farhad", ""]]}, {"id": "1202.1409", "submitter": "Roberto Sebastiani", "authors": "Roberto Sebastiani and Silvia Tomasi", "title": "Optimization in SMT with LA(Q) Cost Functions", "comments": "A shorter version is currently under submission", "journal-ref": null, "doi": null, "report-no": "Technical report # DISI-12-003, DISI, University of Trento, Italy", "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contexts of automated reasoning and formal verification, important\ndecision problems are effectively encoded into Satisfiability Modulo Theories\n(SMT). In the last decade efficient SMT solvers have been developed for several\ntheories of practical interest (e.g., linear arithmetic, arrays, bit-vectors).\nSurprisingly, very few work has been done to extend SMT to deal with\noptimization problems; in particular, we are not aware of any work on SMT\nsolvers able to produce solutions which minimize cost functions over\narithmetical variables. This is unfortunate, since some problems of interest\nrequire this functionality.\n  In this paper we start filling this gap. We present and discuss two general\nprocedures for leveraging SMT to handle the minimization of LA(Q) cost\nfunctions, combining SMT with standard minimization techniques. We have\nimplemented the proposed approach within the MathSAT SMT solver. Due to the\nlack of competitors in AR and SMT domains, we experimentally evaluated our\nimplementation against state-of-the-art tools for the domain of linear\ngeneralized disjunctive programming (LGDP), which is closest in spirit to our\ndomain, on sets of problems which have been previously proposed as benchmarks\nfor the latter tools. The results show that our tool is very competitive with,\nand often outperforms, these tools on these problems, clearly demonstrating the\npotential of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 13:05:30 GMT"}], "update_date": "2012-02-08", "authors_parsed": [["Sebastiani", "Roberto", ""], ["Tomasi", "Silvia", ""]]}, {"id": "1202.1886", "submitter": "Sodbileg Shirmen", "authors": "N.Ugtakhbayar, D.Battulga and Sh.Sodbileg", "title": "Classification of artificial intelligence ids for smurf attack", "comments": "6 pages, 5 figures, 1 table", "journal-ref": "IJAIA (2012);", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods have been developed to secure the network infrastructure and\ncommunication over the Internet. Intrusion detection is a relatively new\naddition to such techniques. Intrusion detection systems (IDS) are used to find\nout if someone has intrusion into or is trying to get it the network. One big\nproblem is amount of Intrusion which is increasing day by day. We need to know\nabout network attack information using IDS, then analysing the effect. Due to\nthe nature of IDSs which are solely signature based, every new intrusion cannot\nbe detected; so it is important to introduce artificial intelligence (AI)\nmethods / techniques in IDS. Introduction of AI necessitates the importance of\nnormalization in intrusions. This work is focused on classification of AI based\nIDS techniques which will help better design intrusion detection systems in the\nfuture. We have also proposed a support vector machine for IDS to detect Smurf\nattack with much reliable accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 04:28:16 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Ugtakhbayar", "N.", ""], ["Battulga", "D.", ""], ["Sodbileg", "Sh.", ""]]}, {"id": "1202.1891", "submitter": "Ei  Shwe Sin", "authors": "Ei Shwe Sin, Nang Saing Moon Kham", "title": "Hyper heuristic based on great deluge and its variants for exam\n  timetabling problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Today, University Timetabling problems are occurred annually and they are\noften hard and time consuming to solve. This paper describes Hyper Heuristics\n(HH) method based on Great Deluge (GD) and its variants for solving large,\nhighly constrained timetabling problems from different domains. Generally, in\nhyper heuristic framework, there are two main stages: heuristic selection and\nmove acceptance. This paper emphasizes on the latter stage to develop Hyper\nHeuristic (HH) framework. The main contribution of this paper is that Great\nDeluge (GD) and its variants: Flex Deluge(FD), Non-linear(NLGD), Extended Great\nDeluge(EGD) are used as move acceptance method in HH by combining Reinforcement\nlearning (RL).These HH methods are tested on exam benchmark timetabling problem\nand best results and comparison analysis are reported.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 05:51:18 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Sin", "Ei Shwe", ""], ["Kham", "Nang Saing Moon", ""]]}, {"id": "1202.1945", "submitter": "Jayabrabu R", "authors": "R. Jayabrabu, V. Saravanan, K. Vivekanandan", "title": "A framework: Cluster detection and multidimensional visualization of\n  automated data mining using intelligent agents", "comments": "15 pages", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.1, January 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Mining techniques plays a vital role like extraction of required\nknowledge, finding unsuspected information to make strategic decision in a\nnovel way which in term understandable by domain experts. A generalized frame\nwork is proposed by considering non - domain experts during mining process for\nbetter understanding, making better decision and better finding new patters in\ncase of selecting suitable data mining techniques based on the user profile by\nmeans of intelligent agents. KEYWORDS: Data Mining Techniques, Intelligent\nAgents, User Profile, Multidimensional Visualization, Knowledge Discovery.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 10:57:53 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Jayabrabu", "R.", ""], ["Saravanan", "V.", ""], ["Vivekanandan", "K.", ""]]}, {"id": "1202.2112", "submitter": "Debadeepta Dey", "authors": "Debadeepta Dey, Tian Yu Liu, Martial Hebert, J. Andrew Bagnell", "title": "Predicting Contextual Sequences via Submodular Function Maximization", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": "CMU-RI-TR-12-05", "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence optimization, where the items in a list are ordered to maximize some\nreward has many applications such as web advertisement placement, search, and\ncontrol libraries in robotics. Previous work in sequence optimization produces\na static ordering that does not take any features of the item or context of the\nproblem into account. In this work, we propose a general approach to order the\nitems within the sequence based on the context (e.g., perceptual information,\nenvironment description, and goals). We take a simple, efficient,\nreduction-based approach where the choice and order of the items is established\nby repeatedly learning simple classifiers or regressors for each \"slot\" in the\nsequence. Our approach leverages recent work on submodular function\nmaximization to provide a formal regret reduction from submodular sequence\noptimization to simple cost-sensitive prediction. We apply our contextual\nsequence prediction algorithm to optimize control libraries and demonstrate\nresults on two robotics problems: manipulator trajectory prediction and mobile\nrobot path planning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 20:48:22 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Dey", "Debadeepta", ""], ["Liu", "Tian Yu", ""], ["Hebert", "Martial", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "1202.2167", "submitter": "Eray Ozkural", "authors": "Eray Ozkural", "title": "Abstract Representations and Frequent Pattern Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the frequent pattern mining problem in a general setting. From an\nanalysis of abstract representations, summarization and frequent pattern\nmining, we arrive at a generalization of the problem. Then, we show how the\nproblem can be cast into the powerful language of algorithmic information\ntheory. This allows us to formulate a simple algorithm to mine for all frequent\npatterns.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 02:12:03 GMT"}], "update_date": "2012-02-13", "authors_parsed": [["Ozkural", "Eray", ""]]}, {"id": "1202.2523", "submitter": "Jose Alberto Garc\\'ia Guti\\'errez Sr.", "authors": "Jos\\'e A. Garc\\'ia Guti\\'errez, Carlos Cotta, and Antonio J.\n  Fern\\'andez-Leiva", "title": "Evolutionary Computation in Astronomy and Astrophysics: A Review", "comments": "* PRE-PRINT *", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI astro-ph.IM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general Evolutionary Computation (EC) includes a number of optimization\nmethods inspired by biological mechanisms of evolution. The methods catalogued\nin this area use the Darwinian principles of life evolution to produce\nalgorithms that returns high quality solutions to hard-to-solve optimization\nproblems. The main strength of EC is precisely that they provide good solutions\neven if the computational resources (e.g., running time) are limited. Astronomy\nand Astrophysics are two fields that often require optimizing problems of high\ncomplexity or analyzing a huge amount of data and the so-called complete\noptimization methods are inherently limited by the size of the problem/data.\nFor instance, reliable analysis of large amounts of data is central to modern\nastrophysics and astronomical sciences in general. EC techniques perform well\nwhere other optimization methods are inherently limited (as complete methods\napplied to NP-hard problems), and in the last ten years, numerous proposals\nhave come up that apply with greater or lesser success methodologies of\nevolutional computation to common engineering problems. Some of these problems,\nsuch as the estimation of non-lineal parameters, the development of automatic\nlearning techniques, the implementation of control systems, or the resolution\nof multi-objective optimization problems, have had (and have) a special\nrepercussion in the fields. For these reasons EC emerges as a feasible\nalternative for traditional methods. In this paper, we discuss some promising\napplications in this direction and a number of recent works in this area; the\npaper also includes a general description of EC to provide a global perspective\nto the reader and gives some guidelines of application of EC techniques for\nfuture research\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 12:12:14 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2012 17:13:45 GMT"}], "update_date": "2012-04-11", "authors_parsed": [["Guti\u00e9rrez", "Jos\u00e9 A. Garc\u00eda", ""], ["Cotta", "Carlos", ""], ["Fern\u00e1ndez-Leiva", "Antonio J.", ""]]}, {"id": "1202.2536", "submitter": "Pan Zhang", "authors": "Pan Zhang, Abolfazl Ramezanpour, Lenka Zdeborov\\'a and Riccardo\n  Zecchina", "title": "Message passing for quantified Boolean formulas", "comments": "14 pages, 7 figures", "journal-ref": "J. Stat. Mech. (2012) P05025", "doi": "10.1088/1742-5468/2012/05/P05025", "report-no": null, "categories": "cs.AI cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two types of message passing algorithms for quantified Boolean\nformulas (QBF). The first type is a message passing based heuristics that can\nprove unsatisfiability of the QBF by assigning the universal variables in such\na way that the remaining formula is unsatisfiable. In the second type, we use\nmessage passing to guide branching heuristics of a Davis-Putnam\nLogemann-Loveland (DPLL) complete solver. Numerical experiments show that on\nrandom QBFs our branching heuristics gives robust exponential efficiency gain\nwith respect to the state-of-art solvers. We also manage to solve some\npreviously unsolved benchmarks from the QBFLIB library. Apart from this our\nstudy sheds light on using message passing in small systems and as subroutines\nin complete solvers.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 15:47:29 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Zhang", "Pan", ""], ["Ramezanpour", "Abolfazl", ""], ["Zdeborov\u00e1", "Lenka", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1202.2577", "submitter": "Carol Christian", "authors": "Carol Christian, Chris Lintott, Arfon Smith, Lucy Fortson, and Steven\n  Bamford", "title": "Citizen Science: Contributions to Astronomy Research", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contributions of everyday individuals to significant research has grown\ndramatically beyond the early days of classical birdwatching and endeavors of\namateurs of the 19th century. Now people who are casually interested in science\ncan participate directly in research covering diverse scientific fields.\nRegarding astronomy, volunteers, either as individuals or as networks of\npeople, are involved in a variety of types of studies. Citizen Science is\nintuitive, engaging, yet necessarily robust in its adoption of sci-entific\nprinciples and methods. Herein, we discuss Citizen Science, focusing on fully\nparticipatory projects such as Zooniverse (by several of the au-thors CL, AS,\nLF, SB), with mention of other programs. In particular, we make the case that\ncitizen science (CS) can be an important aspect of the scientific data analysis\npipelines provided to scientists by observatories.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 21:25:00 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Christian", "Carol", ""], ["Lintott", "Chris", ""], ["Smith", "Arfon", ""], ["Fortson", "Lucy", ""], ["Bamford", "Steven", ""]]}, {"id": "1202.2745", "submitter": "Dan Ciresan", "authors": "Dan Cire\\c{s}an, Ueli Meier, Juergen Schmidhuber", "title": "Multi-column Deep Neural Networks for Image Classification", "comments": "20 pages, 14 figures, 8 tables", "journal-ref": "CVPR 2012, p. 3642-3649", "doi": null, "report-no": "IDSIA-04-12", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods of computer vision and machine learning cannot match\nhuman performance on tasks such as the recognition of handwritten digits or\ntraffic signs. Our biologically plausible deep artificial neural network\narchitectures can. Small (often minimal) receptive fields of convolutional\nwinner-take-all neurons yield large network depth, resulting in roughly as many\nsparsely connected neural layers as found in mammals between retina and visual\ncortex. Only winner neurons are trained. Several deep neural columns become\nexperts on inputs preprocessed in different ways; their predictions are\naveraged. Graphics cards allow for fast training. On the very competitive MNIST\nhandwriting benchmark, our method is the first to achieve near-human\nperformance. On a traffic sign recognition benchmark it outperforms humans by a\nfactor of two. We also improve the state-of-the-art on a plethora of common\nimage classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 14:35:41 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Cire\u015fan", "Dan", ""], ["Meier", "Ueli", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1202.2770", "submitter": "Amir Hesam Salavati", "authors": "Amir Hesam Salavati, Amin Karbasi", "title": "Multi-Level Error-Resilient Neural Networks with Learning", "comments": "Part of this draft has been submitted to International Symposium on\n  Information Theory (ISIT) 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of neural network association is to retrieve a previously\nmemorized pattern from its noisy version using a network of neurons. An ideal\nneural network should include three components simultaneously: a learning\nalgorithm, a large pattern retrieval capacity and resilience against noise.\nPrior works in this area usually improve one or two aspects at the cost of the\nthird.\n  Our work takes a step forward in closing this gap. More specifically, we show\nthat by forcing natural constraints on the set of learning patterns, we can\ndrastically improve the retrieval capacity of our neural network. Moreover, we\ndevise a learning algorithm whose role is to learn those patterns satisfying\nthe above mentioned constraints. Finally we show that our neural network can\ncope with a fair amount of noise.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 15:48:04 GMT"}, {"version": "v2", "created": "Tue, 15 May 2012 12:56:31 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2012 09:58:22 GMT"}, {"version": "v4", "created": "Thu, 21 Jun 2012 15:42:41 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Salavati", "Amir Hesam", ""], ["Karbasi", "Amin", ""]]}, {"id": "1202.2773", "submitter": "Peter Nov\\'ak", "authors": "Anton\\'in Komenda, Peter Nov\\'ak, Michal P\\v{e}chou\\v{c}ek", "title": "Decentralized Multi-agent Plan Repair in Dynamic Environments", "comments": "21 pages, 5 algorithms, 3 figures. This is the full version of an\n  extended abstract published in Proceedings of the 11th International\n  Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012),\n  Conitzer, Winikoff, Padgham, and van der Hoek (eds.), June, 4--8, 2012,\n  Valencia, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving joint objectives by teams of cooperative planning agents requires\nsignificant coordination and communication efforts. For a single-agent system\nfacing a plan failure in a dynamic environment, arguably, attempts to repair\nthe failed plan in general do not straightforwardly bring any benefit in terms\nof time complexity. However, in multi-agent settings the communication\ncomplexity might be of a much higher importance, possibly a high communication\noverhead might be even prohibitive in certain domains. We hypothesize that in\ndecentralized systems, where coordination is enforced to achieve joint\nobjectives, attempts to repair failed multi-agent plans should lead to lower\ncommunication overhead than replanning from scratch.\n  The contribution of the presented paper is threefold. Firstly, we formally\nintroduce the multi-agent plan repair problem and formally present the core\nhypothesis underlying our work. Secondly, we propose three algorithms for\nmulti-agent plan repair reducing the problem to specialized instances of the\nmulti-agent planning problem. Finally, we present results of experimental\nvalidation confirming the core hypothesis of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 15:57:51 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Komenda", "Anton\u00edn", ""], ["Nov\u00e1k", "Peter", ""], ["P\u011bchou\u010dek", "Michal", ""]]}, {"id": "1202.2892", "submitter": "Dmitry Ignatov", "authors": "Dmitry I. Ignatov, Jonas Poelmans, Vasily Zaharchuk", "title": "Recommender System Based on Algorithm of Bicluster Analysis RecBi", "comments": null, "journal-ref": "CEUR Workshop proceedings Vol-757, CDUD'11 - Concept Discovery in\n  Unstructured Data, pp. 122-126, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose two new algorithms based on biclustering analysis,\nwhich can be used at the basis of a recommender system for educational\norientation of Russian School graduates. The first algorithm was designed to\nhelp students make a choice between different university faculties when some of\ntheir preferences are known. The second algorithm was developed for the special\nsituation when nothing is known about their preferences. The final version of\nthis recommender system will be used by Higher School of Economics.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 23:10:08 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Ignatov", "Dmitry I.", ""], ["Poelmans", "Jonas", ""], ["Zaharchuk", "Vasily", ""]]}, {"id": "1202.2895", "submitter": "Dmitry Ignatov", "authors": "Jonas Poelmans, Paul Elzinga, Alexey Neznanov, Stijn Viaene, Sergei O.\n  Kuznetsov, Dmitry Ignatov, Guido Dedene", "title": "Concept Relation Discovery and Innovation Enabling Technology (CORDIET)", "comments": null, "journal-ref": "In CEUR Workshop proceedings Vol-757, CDUD'11 - Concept Discovery\n  in Unstructured Data, pp. 53-62, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept Relation Discovery and Innovation Enabling Technology (CORDIET), is a\ntoolbox for gaining new knowledge from unstructured text data. At the core of\nCORDIET is the C-K theory which captures the essential elements of innovation.\nThe tool uses Formal Concept Analysis (FCA), Emergent Self Organizing Maps\n(ESOM) and Hidden Markov Models (HMM) as main artifacts in the analysis\nprocess. The user can define temporal, text mining and compound attributes. The\ntext mining attributes are used to analyze the unstructured text in documents,\nthe temporal attributes use these document's timestamps for analysis. The\ncompound attributes are XML rules based on text mining and temporal attributes.\nThe user can cluster objects with object-cluster rules and can chop the data in\npieces with segmentation rules. The artifacts are optimized for efficient data\nanalysis; object labels in the FCA lattice and ESOM map contain an URL on which\nthe user can click to open the selected document.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 23:19:51 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Poelmans", "Jonas", ""], ["Elzinga", "Paul", ""], ["Neznanov", "Alexey", ""], ["Viaene", "Stijn", ""], ["Kuznetsov", "Sergei O.", ""], ["Ignatov", "Dmitry", ""], ["Dedene", "Guido", ""]]}, {"id": "1202.3046", "submitter": "Subhadip Basu", "authors": "Subhadip Basu, Chitrita Chaudhuri, Mahantapas Kundu, Mita Nasipuri,\n  Dipak K. Basu", "title": "Segmentation of Offline Handwritten Bengali Script", "comments": "Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science\n  City, Kolkata", "journal-ref": "Proceedings of 28th IEEE ACE, pp. 171-174, December 2002, Science\n  City, Kolkata", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character segmentation has long been one of the most critical areas of\noptical character recognition process. Through this operation, an image of a\nsequence of characters, which may be connected in some cases, is decomposed\ninto sub-images of individual alphabetic symbols. In this paper, segmentation\nof cursive handwritten script of world's fourth popular language, Bengali, is\nconsidered. Unlike English script, Bengali handwritten characters and its\ncomponents often encircle the main character, making the conventional\nsegmentation methodologies inapplicable. Experimental results, using the\nproposed segmentation technique, on sample cursive handwritten data containing\n218 ideal segmentation points show a success rate of 97.7%. Further\nfeature-analysis on these segments may lead to actual recognition of\nhandwritten cursive Bengali script.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 14:22:24 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Basu", "Subhadip", ""], ["Chaudhuri", "Chitrita", ""], ["Kundu", "Mahantapas", ""], ["Nasipuri", "Mita", ""], ["Basu", "Dipak K.", ""]]}, {"id": "1202.3335", "submitter": "Sarge Rogatch", "authors": "Sarge Rogatch", "title": "An efficient high-quality hierarchical clustering algorithm for\n  automatic inference of software architecture from the source code of a\n  software system", "comments": "130 pages. I am looking for someone serious about investing into\n  development of a commercial tool on the basis of my algorithm and my\n  prototype. arXiv admin note: text overlap with arXiv:0803.4025 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  It is a high-quality algorithm for hierarchical clustering of large software\nsource code. This effectively allows to break the complexity of tens of\nmillions lines of source code, so that a human software engineer can comprehend\na software system at high level by means of looking at its architectural\ndiagram that is reconstructed automatically from the source code of the\nsoftware system. The architectural diagram shows a tree of subsystems having\nOOP classes in its leaves (in the other words, a nested software\ndecomposition). The tool reconstructs the missing\n(inconsistent/incomplete/inexistent) architectural documentation for a software\nsystem from its source code. This facilitates software maintenance: change\nrequests can be performed substantially faster. Simply speaking, this unique\ntool allows to lift the comprehensible grain of object-oriented software\nsystems from OOP class-level to subsystem-level. It is estimated that a\ncommercial tool, developed on the basis of this work, will reduce software\nmaintenance expenses 10 times on the current needs, and will allow to implement\nnext-generation software systems which are currently too complex to be within\nthe range of human comprehension, therefore can't yet be designed or\nimplemented. Implemented prototype in Open Source:\nhttp://sourceforge.net/p/insoar/code-0/1/tree/\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2012 15:03:01 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Rogatch", "Sarge", ""]]}, {"id": "1202.3538", "submitter": "Hans van Ditmarsch", "authors": "Laura Bozzelli, Hans van Ditmarsch, Tim French, James Hales, and\n  Sophie Pinchinat", "title": "Refinement Modal Logic", "comments": null, "journal-ref": "Information and Computation, Volume 239, December 2014, Pages\n  303-339", "doi": "10.1016/j.ic.2014.07.013", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present {\\em refinement modal logic}. A refinement is like a\nbisimulation, except that from the three relational requirements only `atoms'\nand `back' need to be satisfied. Our logic contains a new operator 'all' in\naddition to the standard modalities 'box' for each agent. The operator 'all'\nacts as a quantifier over the set of all refinements of a given model. As a\nvariation on a bisimulation quantifier, this refinement operator or refinement\nquantifier 'all' can be seen as quantifying over a variable not occurring in\nthe formula bound by it. The logic combines the simplicity of multi-agent modal\nlogic with some powers of monadic second-order quantification. We present a\nsound and complete axiomatization of multi-agent refinement modal logic. We\nalso present an extension of the logic to the modal mu-calculus, and an\naxiomatization for the single-agent version of this logic. Examples and\napplications are also discussed: to software verification and design (the set\nof agents can also be seen as a set of actions), and to dynamic epistemic\nlogic. We further give detailed results on the complexity of satisfiability,\nand on succinctness.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 09:13:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2013 09:29:30 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Bozzelli", "Laura", ""], ["van Ditmarsch", "Hans", ""], ["French", "Tim", ""], ["Hales", "James", ""], ["Pinchinat", "Sophie", ""]]}, {"id": "1202.3602", "submitter": "Robert Hoehndorf", "authors": "Robert Hoehndorf and Michel Dumontier and Georgios V. Gkoutos", "title": "Towards quantitative measures in applied ontology", "comments": "Initial manuscript, submitted to FOIS 2012", "journal-ref": null, "doi": "10.1093/bib/bbs053", "report-no": null, "categories": "cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applied ontology is a relatively new field which aims to apply theories and\nmethods from diverse disciplines such as philosophy, cognitive science,\nlinguistics and formal logics to perform or improve domain-specific tasks. To\nsupport the development of effective research methodologies for applied\nontology, we critically discuss the question how its research results should be\nevaluated. We propose that results in applied ontology must be evaluated within\ntheir domain of application, based on some ontology-based task within the\ndomain, and discuss quantitative measures which would facilitate the objective\nevaluation and comparison of research results in applied ontology.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 14:26:03 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Hoehndorf", "Robert", ""], ["Dumontier", "Michel", ""], ["Gkoutos", "Georgios V.", ""]]}, {"id": "1202.3698", "submitter": "Udi Apsel", "authors": "Udi Apsel, Ronen I. Brafman", "title": "Extended Lifted Inference with Joint Formulas", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-11-18", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The First-Order Variable Elimination (FOVE) algorithm allows exact inference\nto be applied directly to probabilistic relational models, and has proven to be\nvastly superior to the application of standard inference methods on a grounded\npropositional model. Still, FOVE operators can be applied under restricted\nconditions, often forcing one to resort to propositional inference. This paper\naims to extend the applicability of FOVE by providing two new model conversion\noperators: the first and the primary is joint formula conversion and the second\nis just-different counting conversion. These new operations allow efficient\ninference methods to be applied directly on relational models, where no\nexisting efficient method could be applied hitherto. In addition, aided by\nthese capabilities, we show how to adapt FOVE to provide exact solutions to\nMaximum Expected Utility (MEU) queries over relational models for decision\nunder uncertainty. Experimental evaluations show our algorithms to provide\nsignificant speedup over the alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Apsel", "Udi", ""], ["Brafman", "Ronen I.", ""]]}, {"id": "1202.3699", "submitter": "John Asmuth", "authors": "John Asmuth, Michael L. Littman", "title": "Learning is planning: near Bayes-optimal reinforcement learning via\n  Monte-Carlo tree search", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-19-26", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayes-optimal behavior, while well-defined, is often difficult to achieve.\nRecent advances in the use of Monte-Carlo tree search (MCTS) have shown that it\nis possible to act near-optimally in Markov Decision Processes (MDPs) with very\nlarge or infinite state spaces. Bayes-optimal behavior in an unknown MDP is\nequivalent to optimal behavior in the known belief-space MDP, although the size\nof this belief-space MDP grows exponentially with the amount of history\nretained, and is potentially infinite. We show how an agent can use one\nparticular MCTS algorithm, Forward Search Sparse Sampling (FSSS), in an\nefficient way to act nearly Bayes-optimally for all but a polynomial number of\nsteps, assuming that FSSS can be used to act efficiently in any possible\nunderlying MDP.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Asmuth", "John", ""], ["Littman", "Michael L.", ""]]}, {"id": "1202.3700", "submitter": "Yoram Bachrach", "authors": "Yoram Bachrach, Reshef Meir, Michal Feldman, Moshe Tennenholtz", "title": "Solving Cooperative Reliability Games", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-27-34", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative games model the allocation of profit from joint actions,\nfollowing considerations such as stability and fairness. We propose the\nreliability extension of such games, where agents may fail to participate in\nthe game. In the reliability extension, each agent only \"survives\" with a\ncertain probability, and a coalition's value is the probability that its\nsurviving members would be a winning coalition in the base game. We study\nprominent solution concepts in such games, showing how to approximate the\nShapley value and how to compute the core in games with few agent types. We\nalso show that applying the reliability extension may stabilize the game,\nmaking the core non-empty even when the base game has an empty core.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Bachrach", "Yoram", ""], ["Meir", "Reshef", ""], ["Feldman", "Michal", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "1202.3701", "submitter": "Gowtham Bellala", "authors": "Gowtham Bellala, Jason Stanley, Clayton Scott, Suresh K. Bhavnani", "title": "Active Diagnosis via AUC Maximization: An Efficient Approach for\n  Multiple Fault Identification in Large Scale, Noisy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-35-42", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of active diagnosis arises in several applications such as\ndisease diagnosis, and fault diagnosis in computer networks, where the goal is\nto rapidly identify the binary states of a set of objects (e.g., faulty or\nworking) by sequentially selecting, and observing, (noisy) responses to binary\nvalued queries. Current algorithms in this area rely on loopy belief\npropagation for active query selection. These algorithms have an exponential\ntime complexity, making them slow and even intractable in large networks. We\npropose a rank-based greedy algorithm that sequentially chooses queries such\nthat the area under the ROC curve of the rank-based output is maximized. The\nAUC criterion allows us to make a simplifying assumption that significantly\nreduces the complexity of active query selection (from exponential to near\nquadratic), with little or no compromise on the performance quality.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Bellala", "Gowtham", ""], ["Stanley", "Jason", ""], ["Scott", "Clayton", ""], ["Bhavnani", "Suresh K.", ""]]}, {"id": "1202.3703", "submitter": "E. Busra Celikkaya", "authors": "E. Busra Celikkaya, Christian R. Shelton, William Lam", "title": "Factored Filtering of Continuous-Time Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-61-68", "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider filtering for a continuous-time, or asynchronous, stochastic\nsystem where the full distribution over states is too large to be stored or\ncalculated. We assume that the rate matrix of the system can be compactly\nrepresented and that the belief distribution is to be approximated as a product\nof marginals. The essential computation is the matrix exponential. We look at\ntwo different methods for its computation: ODE integration and uniformization\nof the Taylor expansion. For both we consider approximations in which only a\nfactored belief state is maintained. For factored uniformization we demonstrate\nthat the KL-divergence of the filtering is bounded. Our experimental results\nconfirm our factored uniformization performs better than previously suggested\nuniformization methods and the mean field algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Celikkaya", "E. Busra", ""], ["Shelton", "Christian R.", ""], ["Lam", "William", ""]]}, {"id": "1202.3705", "submitter": "Archie C. Chapman", "authors": "Archie C. Chapman, Simon A. Williamson, Nicholas R. Jennings", "title": "Filtered Fictitious Play for Perturbed Observation Potential Games and\n  Decentralised POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-77-85", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential games and decentralised partially observable MDPs (Dec-POMDPs) are\ntwo commonly used models of multi-agent interaction, for static optimisation\nand sequential decisionmaking settings, respectively. In this paper we\nintroduce filtered fictitious play for solving repeated potential games in\nwhich each player's observations of others' actions are perturbed by random\nnoise, and use this algorithm to construct an online learning method for\nsolving Dec-POMDPs. Specifically, we prove that noise in observations prevents\nstandard fictitious play from converging to Nash equilibrium in potential\ngames, which also makes fictitious play impractical for solving Dec-POMDPs. To\ncombat this, we derive filtered fictitious play, and provide conditions under\nwhich it converges to a Nash equilibrium in potential games with noisy\nobservations. We then use filtered fictitious play to construct a solver for\nDec-POMDPs, and demonstrate our new algorithm's performance in a box pushing\nproblem. Our results show that we consistently outperform the state-of-the-art\nDec-POMDP solver by an average of 100% across the range of noise in the\nobservation function.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Chapman", "Archie C.", ""], ["Williamson", "Simon A.", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1202.3706", "submitter": "Laurent Charlin", "authors": "Laurent Charlin, Richard S. Zemel, Craig Boutilier", "title": "A Framework for Optimizing Paper Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-86-95", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of many scientific conferences is the problem of matching\nsubmitted papers to suitable reviewers. Arriving at a good assignment is a\nmajor and important challenge for any conference organizer. In this paper we\npropose a framework to optimize paper-to-reviewer assignments. Our framework\nuses suitability scores to measure pairwise affinity between papers and\nreviewers. We show how learning can be used to infer suitability scores from a\nsmall set of provided scores, thereby reducing the burden on reviewers and\norganizers. We frame the assignment problem as an integer program and propose\nseveral variations for the paper-to-reviewer matching domain. We also explore\nhow learning and matching interact. Experiments on two conference data sets\nexamine the performance of several learning methods as well as the\neffectiveness of the matching formulations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Charlin", "Laurent", ""], ["Zemel", "Richard S.", ""], ["Boutilier", "Craig", ""]]}, {"id": "1202.3707", "submitter": "Shaunak Chatterjee", "authors": "Shaunak Chatterjee, Stuart Russell", "title": "A temporally abstracted Viterbi algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-96-104", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical problem abstraction, when applicable, may offer exponential\nreductions in computational complexity. Previous work on coarse-to-fine dynamic\nprogramming (CFDP) has demonstrated this possibility using state abstraction to\nspeed up the Viterbi algorithm. In this paper, we show how to apply temporal\nabstraction to the Viterbi problem. Our algorithm uses bounds derived from\nanalysis of coarse timescales to prune large parts of the state trellis at\nfiner timescales. We demonstrate improvements of several orders of magnitude\nover the standard Viterbi algorithm, as well as significant speedups over CFDP,\nfor problems whose state variables evolve at widely differing rates.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Chatterjee", "Shaunak", ""], ["Russell", "Stuart", ""]]}, {"id": "1202.3709", "submitter": "Arthur Choi", "authors": "Arthur Choi, Khaled S. Refaat, Adnan Darwiche", "title": "EDML: A Method for Learning Parameters in Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-115-124", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method called EDML for learning MAP parameters in binary\nBayesian networks under incomplete data. The method assumes Beta priors and can\nbe used to learn maximum likelihood parameters when the priors are\nuninformative. EDML exhibits interesting behaviors, especially when compared to\nEM. We introduce EDML, explain its origin, and study some of its properties\nboth analytically and empirically.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Choi", "Arthur", ""], ["Refaat", "Khaled S.", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1202.3710", "submitter": "SangIn Chun", "authors": "SangIn Chun, Ross D. Shachter", "title": "Strictly Proper Mechanisms with Cooperating Players", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-125-134", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction markets provide an efficient means to assess uncertain quantities\nfrom forecasters. Traditional and competitive strictly proper scoring rules\nhave been shown to incentivize players to provide truthful probabilistic\nforecasts. However, we show that when those players can cooperate, these\nmechanisms can instead discourage them from reporting what they really believe.\nWhen players with different beliefs are able to cooperate and form a coalition,\nthese mechanisms admit arbitrage and there is a report that will always pay\ncoalition members more than their truthful forecasts. If the coalition were\ncreated by an intermediary, such as a web portal, the intermediary would be\nguaranteed a profit.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Chun", "SangIn", ""], ["Shachter", "Ross D.", ""]]}, {"id": "1202.3711", "submitter": "Tom Claassen", "authors": "Tom Claassen, Tom Heskes", "title": "A Logical Characterization of Constraint-Based Causal Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-135-144", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to constraint-based causal discovery, that takes\nthe form of straightforward logical inference, applied to a list of simple,\nlogical statements about causal relations that are derived directly from\nobserved (in)dependencies. It is both sound and complete, in the sense that all\ninvariant features of the corresponding partial ancestral graph (PAG) are\nidentified, even in the presence of latent variables and selection bias. The\napproach shows that every identifiable causal relation corresponds to one of\njust two fundamental forms. More importantly, as the basic building blocks of\nthe method do not rely on the detailed (graphical) structure of the\ncorresponding PAG, it opens up a range of new opportunities, including more\nrobust inference, detailed accountability, and application to large models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Claassen", "Tom", ""], ["Heskes", "Tom", ""]]}, {"id": "1202.3713", "submitter": "James Cussens", "authors": "James Cussens", "title": "Bayesian network learning with cutting planes", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-153-160", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning the structure of Bayesian networks from complete\ndiscrete data with a limit on parent set size is considered. Learning is cast\nexplicitly as an optimisation problem where the goal is to find a BN structure\nwhich maximises log marginal likelihood (BDe score). Integer programming,\nspecifically the SCIP framework, is used to solve this optimisation problem.\nAcyclicity constraints are added to the integer program (IP) during solving in\nthe form of cutting planes. Finding good cutting planes is the key to the\nsuccess of the approach -the search for such cutting planes is effected using a\nsub-IP. Results show that this is a particularly fast method for exact BN\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Cussens", "James", ""]]}, {"id": "1202.3718", "submitter": "Helene Fargier", "authors": "Helene Fargier, Nahla Ben Amor, Wided Guezguez", "title": "On the Complexity of Decision Making in Possibilistic Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-203-210", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the information about uncertainty cannot be quantified in a simple,\nprobabilistic way, the topic of possibilistic decision theory is often a\nnatural one to consider. The development of possibilistic decision theory has\nlead to a series of possibilistic criteria, e.g pessimistic possibilistic\nqualitative utility, possibilistic likely dominance, binary possibilistic\nutility and possibilistic Choquet integrals. This paper focuses on sequential\ndecision making in possibilistic decision trees. It proposes a complexity study\nof the problem of finding an optimal strategy depending on the monotonicity\nproperty of the optimization criteria which allows the application of dynamic\nprogramming that offers a polytime reduction of the decision problem. It also\nshows that possibilistic Choquet integrals do not satisfy this property, and\nthat in this case the optimization problem is NP - hard.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Fargier", "Helene", ""], ["Amor", "Nahla Ben", ""], ["Guezguez", "Wided", ""]]}, {"id": "1202.3719", "submitter": "Daan Fierens", "authors": "Daan Fierens, Guy Van den Broeck, Ingo Thon, Bernd Gutmann, Luc De\n  Raedt", "title": "Inference in Probabilistic Logic Programs using Weighted CNF's", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-211-220", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic logic programs are logic programs in which some of the facts\nare annotated with probabilities. Several classical probabilistic inference\ntasks (such as MAP and computing marginals) have not yet received a lot of\nattention for this formalism. The contribution of this paper is that we develop\nefficient inference algorithms for these tasks. This is based on a conversion\nof the probabilistic logic program and the query and evidence to a weighted CNF\nformula. This allows us to reduce the inference tasks to well-studied tasks\nsuch as weighted model counting. To solve such tasks, we employ\nstate-of-the-art methods. We consider multiple methods for the conversion of\nthe programs as well as for inference on the weighted CNF. The resulting\napproach is evaluated experimentally and shown to improve upon the\nstate-of-the-art in probabilistic logic programming.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Fierens", "Daan", ""], ["Broeck", "Guy Van den", ""], ["Thon", "Ingo", ""], ["Gutmann", "Bernd", ""], ["De Raedt", "Luc", ""]]}, {"id": "1202.3720", "submitter": "Thomas Furmston", "authors": "Thomas Furmston, David Barber", "title": "Efficient Inference in Markov Control Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-221-229", "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov control algorithms that perform smooth, non-greedy updates of the\npolicy have been shown to be very general and versatile, with policy gradient\nand Expectation Maximisation algorithms being particularly popular. For these\nalgorithms, marginal inference of the reward weighted trajectory distribution\nis required to perform policy updates. We discuss a new exact inference\nalgorithm for these marginals in the finite horizon case that is more efficient\nthan the standard approach based on classical forward-backward recursions. We\nalso provide a principled extension to infinite horizon Markov Decision\nProblems that explicitly accounts for an infinite horizon. This extension\nprovides a novel algorithm for both policy gradients and Expectation\nMaximisation in infinite horizon problems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Furmston", "Thomas", ""], ["Barber", "David", ""]]}, {"id": "1202.3721", "submitter": "Phan H. Giang", "authors": "Phan H. Giang", "title": "Dynamic consistency and decision making under vacuous belief", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-230-237", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ideas about decision making under ignorance in economics are combined\nwith the ideas about uncertainty representation in computer science. The\ncombination sheds new light on the question of how artificial agents can act in\na dynamically consistent manner. The notion of sequential consistency is\nformalized by adapting the law of iterated expectation for plausibility\nmeasures. The necessary and sufficient condition for a certainty equivalence\noperator for Nehring-Puppe's preference to be sequentially consistent is given.\nThis result sheds light on the models of decision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Giang", "Phan H.", ""]]}, {"id": "1202.3722", "submitter": "Inmar Givoni", "authors": "Inmar Givoni, Clement Chung, Brendan J. Frey", "title": "Hierarchical Affinity Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-238-246", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affinity propagation is an exemplar-based clustering algorithm that finds a\nset of data-points that best exemplify the data, and associates each datapoint\nwith one exemplar. We extend affinity propagation in a principled way to solve\nthe hierarchical clustering problem, which arises in a variety of domains\nincluding biology, sensor networks and decision making in operational research.\nWe derive an inference algorithm that operates by propagating information up\nand down the hierarchy, and is efficient despite the high-order potentials\nrequired for the graphical model formulation. We demonstrate that our method\noutperforms greedy techniques that cluster one layer at a time. We show that on\nan artificial dataset designed to mimic the HIV-strain mutation dynamics, our\nmethod outperforms related methods. For real HIV sequences, where the ground\ntruth is not available, we show our method achieves better results, in terms of\nthe underlying objective function, and show the results correspond meaningfully\nto geographical location and strain subtypes. Finally we report results on\nusing the method for the analysis of mass spectra, showing it performs\nfavorably compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Givoni", "Inmar", ""], ["Chung", "Clement", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1202.3723", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Pedro Domingos", "title": "Approximation by Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-247-255", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in graphical models consists of repeatedly multiplying and summing\nout potentials. It is generally intractable because the derived potentials\nobtained in this way can be exponentially large. Approximate inference\ntechniques such as belief propagation and variational methods combat this by\nsimplifying the derived potentials, typically by dropping variables from them.\nWe propose an alternate method for simplifying potentials: quantizing their\nvalues. Quantization causes different states of a potential to have the same\nvalue, and therefore introduces context-specific independencies that can be\nexploited to represent the potential more compactly. We use algebraic decision\ndiagrams (ADDs) to do this efficiently. We apply quantization and ADD reduction\nto variable elimination and junction tree propagation, yielding a family of\nbounded approximate inference schemes. Our experimental tests show that our new\nschemes significantly outperform state-of-the-art approaches on many benchmark\ninstances.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Gogate", "Vibhav", ""], ["Domingos", "Pedro", ""]]}, {"id": "1202.3724", "submitter": "Vibhav Gogate", "authors": "Vibhav Gogate, Pedro Domingos", "title": "Probabilistic Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-256-265", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many representation schemes combining first-order logic and probability have\nbeen proposed in recent years. Progress in unifying logical and probabilistic\ninference has been slower. Existing methods are mainly variants of lifted\nvariable elimination and belief propagation, neither of which take logical\nstructure into account. We propose the first method that has the full power of\nboth graphical model inference and first-order theorem proving (in finite\ndomains with Herbrand interpretations). We first define probabilistic theorem\nproving, their generalization, as the problem of computing the probability of a\nlogical formula given the probabilities or weights of a set of formulas. We\nthen show how this can be reduced to the problem of lifted weighted model\ncounting, and develop an efficient algorithm for the latter. We prove the\ncorrectness of this algorithm, investigate its properties, and show how it\ngeneralizes previous approaches. Experiments show that it greatly outperforms\nlifted variable elimination when logical structure is present. Finally, we\npropose an algorithm for approximate probabilistic theorem proving, and show\nthat it can greatly outperform lifted belief propagation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Gogate", "Vibhav", ""], ["Domingos", "Pedro", ""]]}, {"id": "1202.3728", "submitter": "Hannaneh Hajishirzi", "authors": "Hannaneh Hajishirzi, Julia Hockenmaier, Erik T. Mueller, Eyal Amir", "title": "Reasoning about RoboCup Soccer Narratives", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-291-300", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for learning to translate simple narratives,\ni.e., texts (sequences of sentences) describing dynamic systems, into coherent\nsequences of events without the need for labeled training data. Our approach\nincorporates domain knowledge in the form of preconditions and effects of\nevents, and we show that it outperforms state-of-the-art supervised learning\nsystems on the task of reconstructing RoboCup soccer games from their\ncommentaries.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Hajishirzi", "Hannaneh", ""], ["Hockenmaier", "Julia", ""], ["Mueller", "Erik T.", ""], ["Amir", "Eyal", ""]]}, {"id": "1202.3729", "submitter": "Eric A. Hansen", "authors": "Eric A. Hansen", "title": "Suboptimality Bounds for Stochastic Shortest Path Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-301-310", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how to use the Bellman residual of the dynamic programming\noperator to compute suboptimality bounds for solutions to stochastic shortest\npath problems. Such bounds have been previously established only in the special\ncase that \"all policies are proper,\" in which case the dynamic programming\noperator is known to be a contraction, and have been shown to be easily\ncomputable only in the more limited special case of discounting. Under the\ncondition that transition costs are positive, we show that suboptimality bounds\ncan be easily computed even when not all policies are proper. In the general\ncase when there are no restrictions on transition costs, the analysis is more\ncomplex. But we present preliminary results that show such bounds are possible.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Hansen", "Eric A.", ""]]}, {"id": "1202.3732", "submitter": "Hoifung Poon", "authors": "Hoifung Poon, Pedro Domingos", "title": "Sum-Product Networks: A New Deep Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-337-346", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key limiting factor in graphical model inference and learning is the\ncomplexity of the partition function. We thus ask the question: what are\ngeneral conditions under which the partition function is tractable? The answer\nleads to a new kind of deep architecture, which we call sum-product networks\n(SPNs). SPNs are directed acyclic graphs with variables as leaves, sums and\nproducts as internal nodes, and weighted edges. We show that if an SPN is\ncomplete and consistent it represents the partition function and all marginals\nof some graphical model, and give semantics to its nodes. Essentially all\ntractable graphical models can be cast as SPNs, but SPNs are also strictly more\ngeneral. We then propose learning algorithms for SPNs, based on backpropagation\nand EM. Experiments show that inference and learning with SPNs can be both\nfaster and more accurate than with standard deep networks. For example, SPNs\nperform image completion better than state-of-the-art deep networks for this\ntask. SPNs also have intriguing potential connections to the architecture of\nthe cortex.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Poon", "Hoifung", ""], ["Domingos", "Pedro", ""]]}, {"id": "1202.3734", "submitter": "Jonathan Huang", "authors": "Jonathan Huang, Ashish Kapoor, Carlos E. Guestrin", "title": "Efficient Probabilistic Inference with Partial Ranking Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-355-362", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions over rankings are used to model data in various settings such\nas preference analysis and political elections. The factorial size of the space\nof rankings, however, typically forces one to make structural assumptions, such\nas smoothness, sparsity, or probabilistic independence about these underlying\ndistributions. We approach the modeling problem from the computational\nprinciple that one should make structural assumptions which allow for efficient\ncalculation of typical probabilistic queries. For ranking models, \"typical\"\nqueries predominantly take the form of partial ranking queries (e.g., given a\nuser's top-k favorite movies, what are his preferences over remaining movies?).\nIn this paper, we argue that riffled independence factorizations proposed in\nrecent literature [7, 8] are a natural structural assumption for ranking\ndistributions, allowing for particularly efficient processing of partial\nranking queries.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Huang", "Jonathan", ""], ["Kapoor", "Ashish", ""], ["Guestrin", "Carlos E.", ""]]}, {"id": "1202.3738", "submitter": "Alex Kulesza", "authors": "Alex Kulesza, Ben Taskar", "title": "Learning Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-419-427", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs), which arise in random matrix theory and\nquantum physics, are natural models for subset selection problems where\ndiversity is preferred. Among many remarkable properties, DPPs offer tractable\nalgorithms for exact inference, including computing marginal probabilities and\nsampling; however, an important open question has been how to learn a DPP from\nlabeled training data. In this paper we propose a natural feature-based\nparameterization of conditional DPPs, and show how it leads to a convex and\nefficient learning formulation. We analyze the relationship between our model\nand binary Markov random fields with repulsive potentials, which are\nqualitatively similar but computationally intractable. Finally, we apply our\napproach to the task of extractive summarization, where the goal is to choose a\nsmall subset of sentences conveying the most important information from a set\nof documents. In this task there is a fundamental tradeoff between sentences\nthat are highly relevant to the collection as a whole, and sentences that are\ndiverse and not repetitive. Our parameterization allows us to naturally balance\nthese two characteristics. We evaluate our system on data from the DUC 2003/04\nmulti-document summarization task, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Kulesza", "Alex", ""], ["Taskar", "Ben", ""]]}, {"id": "1202.3739", "submitter": "Akshat Kumar", "authors": "Akshat Kumar, Shlomo Zilberstein", "title": "Message-Passing Algorithms for Quadratic Programming Formulations of MAP\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-428-435", "categories": "cs.AI cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing maximum a posteriori (MAP) estimation in graphical models is an\nimportant inference problem with many applications. We present message-passing\nalgorithms for quadratic programming (QP) formulations of MAP estimation for\npairwise Markov random fields. In particular, we use the concave-convex\nprocedure (CCCP) to obtain a locally optimal algorithm for the non-convex QP\nformulation. A similar technique is used to derive a globally convergent\nalgorithm for the convex QP relaxation of MAP. We also show that a recently\ndeveloped expectation-maximization (EM) algorithm for the QP formulation of MAP\ncan be derived from the CCCP perspective. Experiments on synthetic and\nreal-world problems confirm that our new approach is competitive with\nmax-product and its variations. Compared with CPLEX, we achieve more than an\norder-of-magnitude speedup in solving optimally the convex QP relaxation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Kumar", "Akshat", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1202.3740", "submitter": "Minyi Li", "authors": "Minyi Li, Quoc Bao Vo, Ryszard Kowalczyk", "title": "An Efficient Protocol for Negotiation over Combinatorial Domains with\n  Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-436-444", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of agent-based negotiation in combinatorial domains. It\nis difficult to reach optimal agreements in bilateral or multi-lateral\nnegotiations when the agents' preferences for the possible alternatives are not\ncommon knowledge. Self-interested agents often end up negotiating inefficient\nagreements in such situations. In this paper, we present a protocol for\nnegotiation in combinatorial domains which can lead rational agents to reach\noptimal agreements under incomplete information setting. Our proposed protocol\nenables the negotiating agents to identify efficient solutions using\ndistributed search that visits only a small subspace of the whole outcome\nspace. Moreover, the proposed protocol is sufficiently general that it is\napplicable to most preference representation models in combinatorial domains.\nWe also present results of experiments that demonstrate the feasibility and\ncomputational efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Li", "Minyi", ""], ["Vo", "Quoc Bao", ""], ["Kowalczyk", "Ryszard", ""]]}, {"id": "1202.3741", "submitter": "Shiau Hong Lim", "authors": "Shiau Hong Lim, Peter Auer", "title": "Noisy Search with Comparative Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-445-452", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present theoretical results in terms of lower and upper bounds on the\nquery complexity of noisy search with comparative feedback. In this search\nmodel, the noise in the feedback depends on the distance between query points\nand the search target. Consequently, the error probability in the feedback is\nnot fixed but varies for the queries posed by the search algorithm. Our results\nshow that a target out of n items can be found in O(log n) queries. We also\nshow the surprising result that for k possible answers per query, the speedup\nis not log k (as for k-ary search) but only log log k in some cases.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Lim", "Shiau Hong", ""], ["Auer", "Peter", ""]]}, {"id": "1202.3742", "submitter": "Qiang Liu", "authors": "Qiang Liu, Alexander T. Ihler", "title": "Variational Algorithms for Marginal MAP", "comments": "conference version. full journal version is at arXiv:1302.6584", "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-453-462", "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal MAP problems are notoriously difficult tasks for graphical models.\nWe derive a general variational framework for solving marginal MAP problems, in\nwhich we apply analogues of the Bethe, tree-reweighted, and mean field\napproximations. We then derive a \"mixed\" message passing algorithm and a\nconvergent alternative using CCCP to solve the BP-type approximations.\nTheoretically, we give conditions under which the decoded solution is a global\nor local optimum, and obtain novel upper bounds on solutions. Experimentally we\ndemonstrate that our algorithms outperform related approaches. We also show\nthat EM and variational EM comprise a special case of our framework.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2013-02-28", "authors_parsed": [["Liu", "Qiang", ""], ["Ihler", "Alexander T.", ""]]}, {"id": "1202.3743", "submitter": "Jianbing Ma", "authors": "Jianbing Ma, Weiru Liu, Paul Miller", "title": "Belief change with noisy sensing in the situation calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-471-478", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Situation calculus has been applied widely in artificial intelligence to\nmodel and reason about actions and changes in dynamic systems. Since actions\ncarried out by agents will cause constant changes of the agents' beliefs, how\nto manage these changes is a very important issue. Shapiro et al. [22] is one\nof the studies that considered this issue. However, in this framework, the\nproblem of noisy sensing, which often presents in real-world applications, is\nnot considered. As a consequence, noisy sensing actions in this framework will\nlead to an agent facing inconsistent situation and subsequently the agent\ncannot proceed further. In this paper, we investigate how noisy sensing actions\ncan be handled in iterated belief change within the situation calculus\nformalism. We extend the framework proposed in [22] with the capability of\nmanaging noisy sensings. We demonstrate that an agent can still detect the\nactual situation when the ratio of noisy sensing actions vs. accurate sensing\nactions is limited. We prove that our framework subsumes the iterated belief\nchange strategy in [22] when all sensing actions are accurate. Furthermore, we\nprove that our framework can adequately handle belief introspection, mistaken\nbeliefs, belief revision and belief update even with noisy sensing, as done in\n[22] with accurate sensing actions only.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Ma", "Jianbing", ""], ["Liu", "Weiru", ""], ["Miller", "Paul", ""]]}, {"id": "1202.3744", "submitter": "Brandon Malone", "authors": "Brandon Malone, Changhe Yuan, Eric A. Hansen, Susan Bridges", "title": "Improving the Scalability of Optimal Bayesian Network Learning with\n  External-Memory Frontier Breadth-First Branch and Bound Search", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-479-488", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that the problem of learning the optimal structure of\na Bayesian network can be formulated as a shortest path finding problem in a\ngraph and solved using A* search. In this paper, we improve the scalability of\nthis approach by developing a memory-efficient heuristic search algorithm for\nlearning the structure of a Bayesian network. Instead of using A*, we propose a\nfrontier breadth-first branch and bound search that leverages the layered\nstructure of the search graph of this problem so that no more than two layers\nof the graph, plus solution reconstruction information, need to be stored in\nmemory at a time. To further improve scalability, the algorithm stores most of\nthe graph in external memory, such as hard disk, when it does not fit in RAM.\nExperimental results show that the resulting algorithm solves significantly\nlarger problems than the current state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Malone", "Brandon", ""], ["Yuan", "Changhe", ""], ["Hansen", "Eric A.", ""], ["Bridges", "Susan", ""]]}, {"id": "1202.3745", "submitter": "Radu Marinescu", "authors": "Radu Marinescu, Nic Wilson", "title": "Order-of-Magnitude Influence Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-489-496", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a qualitative theory of influence diagrams that can\nbe used to model and solve sequential decision making tasks when only\nqualitative (or imprecise) information is available. Our approach is based on\nan order-of-magnitude approximation of both probabilities and utilities and\nallows for specifying partially ordered preferences via sets of utility values.\nWe also propose a dedicated variable elimination algorithm that can be applied\nfor solving order-of-magnitude influence diagrams.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Marinescu", "Radu", ""], ["Wilson", "Nic", ""]]}, {"id": "1202.3749", "submitter": "Hala Mostafa", "authors": "Hala Mostafa, Victor Lesser", "title": "Compact Mathematical Programs For DEC-MDPs With Structured Agent\n  Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-523-530", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with the prohibitive complexity of calculating policies in\nDecentralized MDPs, researchers have proposed models that exploit structured\nagent interactions. Settings where most agent actions are independent except\nfor few actions that affect the transitions and/or rewards of other agents can\nbe modeled using Event-Driven Interactions with Complex Rewards (EDI-CR).\nFinding the optimal joint policy can be formulated as an optimization problem.\nHowever, existing formulations are too verbose and/or lack optimality\nguarantees. We propose a compact Mixed Integer Linear Program formulation of\nEDI-CR instances. The key insight is that most action sequences of a group of\nagents have the same effect on a given agent. This allows us to treat these\nsequences similarly and use fewer variables. Experiments show that our\nformulation is more compact and leads to faster solution times and better\nsolutions than existing formulations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Mostafa", "Hala", ""], ["Lesser", "Victor", ""]]}, {"id": "1202.3751", "submitter": "Swaprava Nath", "authors": "Swaprava Nath, Onno Zoeter, Yadati Narahari, Christopher R. Dance", "title": "Dynamic Mechanism Design for Markets with Strategic Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-539-546", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assignment of tasks to multiple resources becomes an interesting game\ntheoretic problem, when both the task owner and the resources are strategic. In\nthe classical, nonstrategic setting, where the states of the tasks and\nresources are observable by the controller, this problem is that of finding an\noptimal policy for a Markov decision process (MDP). When the states are held by\nstrategic agents, the problem of an efficient task allocation extends beyond\nthat of solving an MDP and becomes that of designing a mechanism. Motivated by\nthis fact, we propose a general mechanism which decides on an allocation rule\nfor the tasks and resources and a payment rule to incentivize agents'\nparticipation and truthful reports. In contrast to related dynamic strategic\ncontrol problems studied in recent literature, the problem studied here has\ninterdependent values: the benefit of an allocation to the task owner is not\nsimply a function of the characteristics of the task itself and the allocation,\nbut also of the state of the resources. We introduce a dynamic extension of\nMezzetti's two phase mechanism for interdependent valuations. In this changed\nsetting, the proposed dynamic mechanism is efficient, within period ex-post\nincentive compatible, and within period ex-post individually rational.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Nath", "Swaprava", ""], ["Zoeter", "Onno", ""], ["Narahari", "Yadati", ""], ["Dance", "Christopher R.", ""]]}, {"id": "1202.3754", "submitter": "Eunsoo Oh", "authors": "Eunsoo Oh, Kee-Eung Kim", "title": "A Geometric Traversal Algorithm for Reward-Uncertain MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-565-572", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are widely used in modeling decision making\nproblems in stochastic environments. However, precise specification of the\nreward functions in MDPs is often very difficult. Recent approaches have\nfocused on computing an optimal policy based on the minimax regret criterion\nfor obtaining a robust policy under uncertainty in the reward function. One of\nthe core tasks in computing the minimax regret policy is to obtain the set of\nall policies that can be optimal for some candidate reward function. In this\npaper, we propose an efficient algorithm that exploits the geometric properties\nof the reward function associated with the policies. We also present an\napproximate version of the method for further speed up. We experimentally\ndemonstrate that our algorithm improves the performance by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Oh", "Eunsoo", ""], ["Kim", "Kee-Eung", ""]]}, {"id": "1202.3755", "submitter": "Takayuki Osogami", "authors": "Takayuki Osogami", "title": "Iterated risk measures for risk-sensitive Markov decision processes with\n  discounted cost", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-573-580", "categories": "cs.GT cs.AI q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a limitation of discounted expected utility, a standard\napproach for representing the preference to risk when future cost is\ndiscounted. Specifically, we provide an example of the preference of a decision\nmaker that appears to be rational but cannot be represented with any discounted\nexpected utility. A straightforward modification to discounted expected utility\nleads to inconsistent decision making over time. We will show that an iterated\nrisk measure can represent the preference that cannot be represented by any\ndiscounted expected utility and that the decisions based on the iterated risk\nmeasure are consistent over time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Osogami", "Takayuki", ""]]}, {"id": "1202.3756", "submitter": "David M Pennock", "authors": "David M. Pennock, Lirong Xia", "title": "Price Updating in Combinatorial Prediction Markets with Bayesian\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-581-588", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To overcome the #P-hardness of computing/updating prices in logarithm market\nscoring rule-based (LMSR-based) combinatorial prediction markets, Chen et al.\n[5] recently used a simple Bayesian network to represent the prices of\nsecurities in combinatorial predictionmarkets for tournaments, and showed that\ntwo types of popular securities are structure preserving. In this paper, we\nsignificantly extend this idea by employing Bayesian networks in general\ncombinatorial prediction markets. We reveal a very natural connection between\nLMSR-based combinatorial prediction markets and probabilistic belief\naggregation,which leads to a complete characterization of all structure\npreserving securities for decomposable network structures. Notably, the main\nresults by Chen et al. [5] are corollaries of our characterization. We then\nprove that in order for a very basic set of securities to be structure\npreserving, the graph of the Bayesian network must be decomposable. We also\ndiscuss some approximation techniques for securities that are not structure\npreserving.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Pennock", "David M.", ""], ["Xia", "Lirong", ""]]}, {"id": "1202.3759", "submitter": "Gungor Polatkan", "authors": "Gungor Polatkan, Oncel Tuzel", "title": "Compressed Inference for Probabilistic Sequential Models", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-609-618", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov models (HMMs) and conditional random fields (CRFs) are two\npopular techniques for modeling sequential data. Inference algorithms designed\nover CRFs and HMMs allow estimation of the state sequence given the\nobservations. In several applications, estimation of the state sequence is not\nthe end goal; instead the goal is to compute some function of it. In such\nscenarios, estimating the state sequence by conventional inference techniques,\nfollowed by computing the functional mapping from the estimate is not\nnecessarily optimal. A more formal approach is to directly infer the final\noutcome from the observations. In particular, we consider the specific\ninstantiation of the problem where the goal is to find the state trajectories\nwithout exact transition points and derive a novel polynomial time inference\nalgorithm that outperforms vanilla inference techniques. We show that this\nparticular problem arises commonly in many disparate applications and present\nexperiments on three of them: (1) Toy robot tracking; (2) Single stroke\ncharacter recognition; (3) Handwritten word recognition.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Polatkan", "Gungor", ""], ["Tuzel", "Oncel", ""]]}, {"id": "1202.3762", "submitter": "Scott Sanner", "authors": "Scott Sanner, Karina Valdivia Delgado, Leliane Nunes de Barros", "title": "Symbolic Dynamic Programming for Discrete and Continuous State MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-643-652", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world decision-theoretic planning problems can be naturally modeled\nwith discrete and continuous state Markov decision processes (DC-MDPs). While\nprevious work has addressed automated decision-theoretic planning for DCMDPs,\noptimal solutions have only been defined so far for limited settings, e.g.,\nDC-MDPs having hyper-rectangular piecewise linear value functions. In this\nwork, we extend symbolic dynamic programming (SDP) techniques to provide\noptimal solutions for a vastly expanded class of DCMDPs. To address the\ninherent combinatorial aspects of SDP, we introduce the XADD - a continuous\nvariable extension of the algebraic decision diagram (ADD) - that maintains\ncompact representations of the exact value function. Empirically, we\ndemonstrate an implementation of SDP with XADDs on various DC-MDPs, showing the\nfirst optimal automated solutions to DCMDPs with linear and nonlinear piecewise\npartitioned value functions and showing the advantages of constraint-based\npruning for XADDs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Sanner", "Scott", ""], ["Delgado", "Karina Valdivia", ""], ["de Barros", "Leliane Nunes", ""]]}, {"id": "1202.3764", "submitter": "Johannes Textor", "authors": "Johannes Textor, Maciej Liskiewicz", "title": "Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-681-688", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and controlling bias is a key problem in empirical sciences.\nCausal diagram theory provides graphical criteria for deciding whether and how\ncausal effects can be identified from observed (nonexperimental) data by\ncovariate adjustment. Here we prove equivalences between existing as well as\nnew criteria for adjustment and we provide a new simplified but still\nequivalent notion of d-separation. These lead to efficient algorithms for two\nimportant tasks in causal diagram analysis: (1) listing minimal covariate\nadjustments (with polynomial delay); and (2) identifying the subdiagram\ninvolved in biasing paths (in linear time). Our results improve upon existing\nexponential-time solutions for these problems, enabling users to assess the\neffects of covariate adjustment on diagrams with tens to hundreds of variables\ninteractively in real time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Textor", "Johannes", ""], ["Liskiewicz", "Maciej", ""]]}, {"id": "1202.3767", "submitter": "Joop van de Ven", "authors": "Joop van de Ven, Fabio Ramos", "title": "Distributed Anytime MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-708-716", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed anytime algorithm for performing MAP inference in\ngraphical models. The problem is formulated as a linear programming relaxation\nover the edges of a graph. The resulting program has a constraint structure\nthat allows application of the Dantzig-Wolfe decomposition principle.\nSubprograms are defined over individual edges and can be computed in a\ndistributed manner. This accommodates solutions to graphs whose state space\ndoes not fit in memory. The decomposition master program is guaranteed to\ncompute the optimal solution in a finite number of iterations, while the\nsolution converges monotonically with each iteration. Formulating the MAP\ninference problem as a linear program allows additional (global) constraints to\nbe defined; something not possible with message passing algorithms.\nExperimental results show that our algorithm's solution quality outperforms\nmost current algorithms and it scales well to large problems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["van de Ven", "Joop", ""], ["Ramos", "Fabio", ""]]}, {"id": "1202.3768", "submitter": "Michael P. Wellman", "authors": "Michael P. Wellman, Lu Hong, Scott E. Page", "title": "The Structure of Signals: Causal Interdependence Models for Games of\n  Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-727-735", "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional economic models typically treat private information, or signals,\nas generated from some underlying state. Recent work has explicated alternative\nmodels, where signals correspond to interpretations of available information.\nWe show that the difference between these formulations can be sharply cast in\nterms of causal dependence structure, and employ graphical models to illustrate\nthe distinguishing characteristics. The graphical representation supports\ninferences about signal patterns in the interpreted framework, and suggests how\nresults based on the generated model can be extended to more general\nsituations. Specific insights about bidding games in classical auction\nmechanisms derive from qualitative graphical models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Wellman", "Michael P.", ""], ["Hong", "Lu", ""], ["Page", "Scott E.", ""]]}, {"id": "1202.3773", "submitter": "Haohai Yu", "authors": "Haohai Yu, Robert A. van Engelen", "title": "Measuring the Hardness of Stochastic Sampling on Bayesian Networks with\n  Deterministic Causalities: the k-Test", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-786-795", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian inference is NP-hard. Dagum and Luby defined the Local\nVariance Bound (LVB) to measure the approximation hardness of Bayesian\ninference on Bayesian networks, assuming the networks model strictly positive\njoint probability distributions, i.e. zero probabilities are not permitted.\nThis paper introduces the k-test to measure the approximation hardness of\ninference on Bayesian networks with deterministic causalities in the\nprobability distribution, i.e. when zero conditional probabilities are\npermitted. Approximation by stochastic sampling is a widely-used inference\nmethod that is known to suffer from inefficiencies due to sample rejection. The\nk-test predicts when rejection rates of stochastic sampling a Bayesian network\nwill be low, modest, high, or when sampling is intractable.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Yu", "Haohai", ""], ["van Engelen", "Robert A.", ""]]}, {"id": "1202.3777", "submitter": "Lu Zheng", "authors": "Lu Zheng, Ole Mengshoel, Jike Chong", "title": "Belief Propagation by Message Passing in Junction Trees: Computing Each\n  Message Faster Using GPU Parallelization", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-822-830", "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compiling Bayesian networks (BNs) to junction trees and performing belief\npropagation over them is among the most prominent approaches to computing\nposteriors in BNs. However, belief propagation over junction tree is known to\nbe computationally intensive in the general case. Its complexity may increase\ndramatically with the connectivity and state space cardinality of Bayesian\nnetwork nodes. In this paper, we address this computational challenge using GPU\nparallelization. We develop data structures and algorithms that extend existing\njunction tree techniques, and specifically develop a novel approach to\ncomputing each belief propagation message in parallel. We implement our\napproach on an NVIDIA GPU and test it using BNs from several applications.\nExperimentally, we study how junction tree parameters affect parallelization\nopportunities and hence the performance of our algorithm. We achieve speedups\nranging from 0.68 to 9.18 for the BNs studied.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Zheng", "Lu", ""], ["Mengshoel", "Ole", ""], ["Chong", "Jike", ""]]}, {"id": "1202.3782", "submitter": "Kareem Amin", "authors": "Kareem Amin, Michael Kearns, Umar Syed", "title": "Graphical Models for Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "UAI-P-2011-PG-1-10", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a rich class of graphical models for multi-armed bandit problems\nthat permit both the state or context space and the action space to be very\nlarge, yet succinctly specify the payoffs for any context-action pair. Our main\nresult is an algorithm for such models whose regret is bounded by the number of\nparameters and whose running time depends only on the treewidth of the graph\nsubstructure induced by the action space.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 16:41:17 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Amin", "Kareem", ""], ["Kearns", "Michael", ""], ["Syed", "Umar", ""]]}, {"id": "1202.3887", "submitter": "Hamid Salimi", "authors": "Hamid Salimi, Davar Giveki, Mohammad Ali Soltanshahi, Javad Hatami", "title": "Extended Mixture of MLP Experts by Hybrid of Conjugate Gradient Method\n  and Modified Cuckoo Search", "comments": "13 pages, 2 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.3, No.1, January 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper investigates a new method for improving the learning algorithm of\nMixture of Experts (ME) model using a hybrid of Modified Cuckoo Search (MCS)\nand Conjugate Gradient (CG) as a second order optimization technique. The CG\ntechnique is combined with Back-Propagation (BP) algorithm to yield a much more\nefficient learning algorithm for ME structure. In addition, the experts and\ngating networks in enhanced model are replaced by CG based Multi-Layer\nPerceptrons (MLPs) to provide faster and more accurate learning. The CG is\nconsiderably depends on initial weights of connections of Artificial Neural\nNetwork (ANN), so, a metaheuristic algorithm, the so-called Modified Cuckoo\nSearch is applied in order to select the optimal weights. The performance of\nproposed method is compared with Gradient Decent Based ME (GDME) and Conjugate\nGradient Based ME (CGME) in classification and regression problems. The\nexperimental results show that hybrid MSC and CG based ME (MCS-CGME) has faster\nconvergence and better performance in utilized benchmark data sets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2012 11:49:56 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Salimi", "Hamid", ""], ["Giveki", "Davar", ""], ["Soltanshahi", "Mohammad Ali", ""], ["Hatami", "Javad", ""]]}, {"id": "1202.4063", "submitter": "Rafi Muhammad", "authors": "Sundus Hassan, Muhammad Rafi and Muhammad Shahid Shaikh", "title": "Comparing SVM and Naive Bayes classifiers for text categorization with\n  Wikitology as knowledge enrichment", "comments": "5 pages", "journal-ref": "Multitopic Conference (INMIC), 2011 IEEE 14th International", "doi": "10.1109/INMIC.2011.6151495", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The activity of labeling of documents according to their content is known as\ntext categorization. Many experiments have been carried out to enhance text\ncategorization by adding background knowledge to the document using knowledge\nrepositories like Word Net, Open Project Directory (OPD), Wikipedia and\nWikitology. In our previous work, we have carried out intensive experiments by\nextracting knowledge from Wikitology and evaluating the experiment on Support\nVector Machine with 10- fold cross-validations. The results clearly indicate\nWikitology is far better than other knowledge bases. In this paper we are\ncomparing Support Vector Machine (SVM) and Na\\\"ive Bayes (NB) classifiers under\ntext enrichment through Wikitology. We validated results with 10-fold cross\nvalidation and shown that NB gives an improvement of +28.78%, on the other hand\nSVM gives an improvement of +6.36% when compared with baseline results. Na\\\"ive\nBayes classifier is better choice when external enriching is used through any\nexternal knowledge base.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2012 09:23:02 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Hassan", "Sundus", ""], ["Rafi", "Muhammad", ""], ["Shaikh", "Muhammad Shahid", ""]]}, {"id": "1202.4144", "submitter": "Adolfo Neto", "authors": "Adolfo Neto, Celso A. A. Kaestner and Marcelo Finger", "title": "Towards an efficient prover for the C1 paraconsistent logic", "comments": "16 pages", "journal-ref": "Electronic Notes in Theoretical Computer Science. Volume 256, 2\n  December 2009, Pages 87-102. Proceedings of the Fourth Workshop on Logical\n  and Semantic Frameworks, with Applications (LSFA 2009)", "doi": "10.1016/j.entcs.2009.11.007", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The KE inference system is a tableau method developed by Marco Mondadori\nwhich was presented as an improvement, in the computational efficiency sense,\nover Analytic Tableaux. In the literature, there is no description of a theorem\nprover based on the KE method for the C1 paraconsistent logic. Paraconsistent\nlogics have several applications, such as in robot control and medicine. These\napplications could benefit from the existence of such a prover. We present a\nsound and complete KE system for C1, an informal specification of a strategy\nfor the C1 prover as well as problem families that can be used to evaluate\nprovers for C1. The C1 KE system and the strategy described in this paper will\nbe used to implement a KE based prover for C1, which will be useful for those\nwho study and apply paraconsistent logics.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 11:14:50 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Neto", "Adolfo", ""], ["Kaestner", "Celso A. A.", ""], ["Finger", "Marcelo", ""]]}, {"id": "1202.4174", "submitter": "Ahmed Mahran", "authors": "Ahmed M. Mahran", "title": "Perception Lie Paradox: Mathematically Proved Uncertainty about Humans\n  Perception Similarity", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents' judgment depends on perception and previous knowledge. Assuming that\nprevious knowledge depends on perception, we can say that judgment depends on\nperception. So, if judgment depends on perception, can agents judge that they\nhave the same perception? In few words, this is the addressed paradox through\nthis document. While illustrating on the paradox, it's found that to reach\nagreement in communication, it's not necessary for parties to have the same\nperception however the necessity is to have perception correspondence. The\nattempted solution to this paradox reveals a potential uncertainty in judging\nthe matter thus supporting the skeptical view of the problem. Moreover,\nrelating perception to intelligence, the same uncertainty is inherited by\njudging the level of intelligence of an agent compared to others not\nnecessarily from the same kind (e.g. machine intelligence compared to human\nintelligence). Using a proposed simple mathematical model for perception and\naction, a tool is developed to construct scenarios, and the problem is\naddressed mathematically such that conclusions are drawn systematically based\non mathematically defined properties. When it comes to formalization,\nphilosophical arguments and views become more visible and explicit.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 18:12:28 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Mahran", "Ahmed M.", ""]]}, {"id": "1202.4177", "submitter": "Phillip J. Schulte", "authors": "Phillip J. Schulte, Anastasios A. Tsiatis, Eric B. Laber, Marie\n  Davidian", "title": "$Q$- and $A$-Learning Methods for Estimating Optimal Dynamic Treatment\n  Regimes", "comments": "Published in at http://dx.doi.org/10.1214/13-STS450 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 4, 640-661", "doi": "10.1214/13-STS450", "report-no": "IMS-STS-STS450", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical practice, physicians make a series of treatment decisions over\nthe course of a patient's disease based on his/her baseline and evolving\ncharacteristics. A dynamic treatment regime is a set of sequential decision\nrules that operationalizes this process. Each rule corresponds to a decision\npoint and dictates the next treatment action based on the accrued information.\nUsing existing data, a key goal is estimating the optimal regime, that, if\nfollowed by the patient population, would yield the most favorable outcome on\naverage. Q- and A-learning are two main approaches for this purpose. We provide\na detailed account of these methods, study their performance, and illustrate\nthem using data from a depression study.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 19:17:01 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 16:23:17 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2015 10:52:21 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Schulte", "Phillip J.", ""], ["Tsiatis", "Anastasios A.", ""], ["Laber", "Eric B.", ""], ["Davidian", "Marie", ""]]}, {"id": "1202.4190", "submitter": "Feng Lin", "authors": "Feng Lin, Robert C. Qiu, Zhen Hu, Shujie Hou, James P. Browning,\n  Michael C. Wicks", "title": "Generalized FMD Detection for Spectrum Sensing Under Low Signal-to-Noise\n  Ratio", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Spectrum sensing is a fundamental problem in cognitive radio. We propose a\nfunction of covariance matrix based detection algorithm for spectrum sensing in\ncognitive radio network. Monotonically increasing property of function of\nmatrix involving trace operation is utilized as the cornerstone for this\nalgorithm. The advantage of proposed algorithm is it works under extremely low\nsignal-to-noise ratio, like lower than -30 dB with limited sample data.\nTheoretical analysis of threshold setting for the algorithm is discussed. A\nperformance comparison between the proposed algorithm and other\nstate-of-the-art methods is provided, by the simulation on captured digital\ntelevision (DTV) signal.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 21:50:58 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Lin", "Feng", ""], ["Qiu", "Robert C.", ""], ["Hu", "Zhen", ""], ["Hou", "Shujie", ""], ["Browning", "James P.", ""], ["Wicks", "Michael C.", ""]]}, {"id": "1202.4331", "submitter": "Serge Gaspers", "authors": "Serge Gaspers and Stefan Szeider", "title": "Strong Backdoors to Nested Satisfiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knuth (1990) introduced the class of nested formulas and showed that their\nsatisfiability can be decided in polynomial time. We show that, parameterized\nby the size of a smallest strong backdoor set to the target class of nested\nformulas, checking the satisfiability of any CNF formula is fixed-parameter\ntractable. Thus, for any k>0, the satisfiability problem can be solved in\npolynomial time for any formula F for which there exists a variable set B of\nsize at most k such that for every truth assignment t to B, the formula F[t] is\nnested; moreover, the degree of the polynomial is independent of k.\n  Our algorithm uses the grid-minor theorem of Robertson and Seymour (1986) to\neither find that the incidence graph of the formula has bounded treewidth - a\ncase that is solved using model checking for monadic second order logic - or to\nfind many vertex-disjoint obstructions in the incidence graph. For the latter\ncase, new combinatorial arguments are used to find a small backdoor set.\nCombining both cases leads to an approximation algorithm producing a strong\nbackdoor set whose size is upper bounded by a function of the optimum. Going\nthrough all assignments to this set of variables and using Knuth's algorithm,\nthe satisfiability of the input formula is decided.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 14:10:02 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2012 16:26:35 GMT"}], "update_date": "2012-03-07", "authors_parsed": [["Gaspers", "Serge", ""], ["Szeider", "Stefan", ""]]}, {"id": "1202.4465", "submitter": "Jason Yosinski", "authors": "Jason Yosinski and Cooper Bills", "title": "MAV Stabilization using Machine Learning and Onboard Sensors", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In many situations, Miniature Aerial Vehicles (MAVs) are limited to using\nonly on-board sensors for navigation. This limits the data available to\nalgorithms used for stabilization and localization, and current control methods\nare often insufficient to allow reliable hovering in place or trajectory\nfollowing. In this research, we explore using machine learning to predict the\ndrift (flight path errors) of an MAV while executing a desired flight path.\nThis predicted drift will allow the MAV to adjust it's flightpath to maintain a\ndesired course.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 21:06:43 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Yosinski", "Jason", ""], ["Bills", "Cooper", ""]]}, {"id": "1202.4478", "submitter": "Elad Hazan", "authors": "Elad Hazan, Sham Kakade", "title": "(weak) Calibration is Computationally Hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the existence of a computationally efficient calibration\nalgorithm, with a low weak calibration rate, would imply the existence of an\nefficient algorithm for computing approximate Nash equilibria - thus implying\nthe unlikely conclusion that every problem in PPAD is solvable in polynomial\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 21:48:09 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Hazan", "Elad", ""], ["Kakade", "Sham", ""]]}, {"id": "1202.4828", "submitter": "EPTCS", "authors": "Serge Autexier (German Research Center for Artificial Intelligence\n  (DFKI), Bremen, Germany), Dominik Dietrich (German Research Center for\n  Artificial Intelligence (DFKI), Bremen, Germany), Marvin Schiller (Brunel\n  University, London, UK)", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 1-28", "doi": "10.4204/EPTCS.79.1", "report-no": null, "categories": "cs.AI cs.LO cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-supported learning is an increasingly important form of study since\nit allows for independent learning and individualized instruction. In this\npaper, we discuss a novel approach to developing an intelligent tutoring system\nfor teaching textbook-style mathematical proofs. We characterize the\nparticularities of the domain and discuss common ITS design models. Our\napproach is motivated by phenomena found in a corpus of tutorial dialogs that\nwere collected in a Wizard-of-Oz experiment. We show how an intelligent tutor\nfor textbook-style mathematical proofs can be built on top of an adapted\nassertion-level proof assistant by reusing representations and proof search\nstrategies originally developed for automated and interactive theorem proving.\nThe resulting prototype was successfully evaluated on a corpus of tutorial\ndialogs and yields good results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:20 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Autexier", "Serge", "", "German Research Center for Artificial Intelligence"], ["Dietrich", "Dominik", "", "German Research Center for\n  Artificial Intelligence"], ["Schiller", "Marvin", "", "Brunel\n  University, London, UK"]]}, {"id": "1202.4835", "submitter": "EPTCS", "authors": "Makarius Wenzel, Burkhart Wolff", "title": "Isabelle/PIDE as Platform for Educational Tools", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 143-153", "doi": "10.4204/EPTCS.79.9", "report-no": null, "categories": "cs.LO cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isabelle/PIDE platform addresses the question whether proof assistants of\nthe LCF family are suitable as technological basis for educational tools. The\ntraditionally strong logical foundations of systems like HOL, Coq, or Isabelle\nhave so far been counter-balanced by somewhat inaccessible interaction via the\nTTY (or minor variations like the well-known Proof General / Emacs interface).\nThus the fundamental question of math education tools with fully-formal\nbackground theories has often been answered negatively due to accidental\nweaknesses of existing proof engines.\n  The idea of \"PIDE\" (which means \"Prover IDE\") is to integrate existing\nprovers like Isabelle into a larger environment, that facilitates access by\nend-users and other tools. We use Scala to expose the proof engine in ML to the\nJVM world, where many user-interfaces, editor frameworks, and educational tools\nalready exist. This shall ultimately lead to combined mathematical assistants,\nwhere the logical engine is in the background, without obstructing the view on\napplications of formal methods, formalized mathematics, and math education in\nparticular.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:17 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Wenzel", "Makarius", ""], ["Wolff", "Burkhart", ""]]}, {"id": "1202.4905", "submitter": "Enrico Tassi", "authors": "Andrea Asperti (University of Bologna), Wilmer Ricciotti (University\n  of Bologna), Claudio Sacerdoti Coen (University of Bologna), Enrico Tassi\n  (INRIA - Microsoft Research)", "title": "A Bi-Directional Refinement Algorithm for the Calculus of (Co)Inductive\n  Constructions", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 8, Issue 1 (March 2,\n  2012) lmcs:1044", "doi": "10.2168/LMCS-8(1:18)2012", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the refinement algorithm for the Calculus of\n(Co)Inductive Constructions (CIC) implemented in the interactive theorem prover\nMatita. The refinement algorithm is in charge of giving a meaning to the terms,\ntypes and proof terms directly written by the user or generated by using\ntactics, decision procedures or general automation. The terms are written in an\n\"external syntax\" meant to be user friendly that allows omission of\ninformation, untyped binders and a certain liberal use of user defined\nsub-typing. The refiner modifies the terms to obtain related well typed terms\nin the internal syntax understood by the kernel of the ITP. In particular, it\nacts as a type inference algorithm when all the binders are untyped. The\nproposed algorithm is bi-directional: given a term in external syntax and a\ntype expected for the term, it propagates as much typing information as\npossible towards the leaves of the term. Traditional mono-directional\nalgorithms, instead, proceed in a bottom-up way by inferring the type of a\nsub-term and comparing (unifying) it with the type expected by its context only\nat the end. We propose some novel bi-directional rules for CIC that are\nparticularly effective. Among the benefits of bi-directionality we have better\nerror message reporting and better inference of dependent types. Moreover,\nthanks to bi-directionality, the coercion system for sub-typing is more\neffective and type inference generates simpler unification problems that are\nmore likely to be solved by the inherently incomplete higher order unification\nalgorithms implemented. Finally we introduce in the external syntax the notion\nof vector of placeholders that enables to omit at once an arbitrary number of\narguments. Vectors of placeholders allow a trivial implementation of implicit\narguments and greatly simplify the implementation of primitive and simple\ntactics.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 13:33:26 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 20:49:22 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Asperti", "Andrea", "", "University of Bologna"], ["Ricciotti", "Wilmer", "", "University\n  of Bologna"], ["Coen", "Claudio Sacerdoti", "", "University of Bologna"], ["Tassi", "Enrico", "", "INRIA - Microsoft Research"]]}, {"id": "1202.5284", "submitter": "Alex Ter-Sarkissov", "authors": "Aram Ter-Sarkisov", "title": "Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on\n  Unimodal Functions", "comments": "accepted to Congress on Evolutionary Computation (WCCI/CEC) 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present an Elitism Levels Traverse Mechanism that we\ndesigned to find bounds on population-based Evolutionary algorithms solving\nunimodal functions. We prove its efficiency theoretically and test it on OneMax\nfunction deriving bounds c{\\mu}n log n - O({\\mu} n). This analysis can be\ngeneralized to any similar algorithm using variants of tournament selection and\ngenetic operators that flip or swap only 1 bit in each string.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 20:21:57 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2012 04:55:09 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2012 04:27:11 GMT"}], "update_date": "2012-04-03", "authors_parsed": [["Ter-Sarkisov", "Aram", ""]]}, {"id": "1202.5597", "submitter": "Ali Jalali", "authors": "Javad Azimi, Ali Jalali and Xiaoli Fern", "title": "Hybrid Batch Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization aims at optimizing an unknown non-convex/concave\nfunction that is costly to evaluate. We are interested in application scenarios\nwhere concurrent function evaluations are possible. Under such a setting, BO\ncould choose to either sequentially evaluate the function, one input at a time\nand wait for the output of the function before making the next selection, or\nevaluate the function at a batch of multiple inputs at once. These two\ndifferent settings are commonly referred to as the sequential and batch\nsettings of Bayesian Optimization. In general, the sequential setting leads to\nbetter optimization performance as each function evaluation is selected with\nmore information, whereas the batch setting has an advantage in terms of the\ntotal experimental time (the number of iterations). In this work, our goal is\nto combine the strength of both settings. Specifically, we systematically\nanalyze Bayesian optimization using Gaussian process as the posterior estimator\nand provide a hybrid algorithm that, based on the current state, dynamically\nswitches between a sequential policy and a batch policy with variable batch\nsizes. We provide theoretical justification for our algorithm and present\nexperimental results on eight benchmark BO problems. The results show that our\nmethod achieves substantial speedup (up to %78) compared to a pure sequential\npolicy, without suffering any significant performance loss.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 02:00:51 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 01:55:33 GMT"}, {"version": "v3", "created": "Tue, 1 May 2012 03:08:22 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Azimi", "Javad", ""], ["Jalali", "Ali", ""], ["Fern", "Xiaoli", ""]]}, {"id": "1202.5600", "submitter": "Chrystopher L. Nehaniv", "authors": "Frank Broz, Chrystopher L. Nehaniv, Hatice Kose-Bagci, and Kerstin\n  Dautenhahn", "title": "Interaction Histories and Short Term Memory: Enactive Development of\n  Turn-taking Behaviors in a Childlike Humanoid Robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, an enactive architecture is described that allows a humanoid\nrobot to learn to compose simple actions into turn-taking behaviors while\nplaying interaction games with a human partner. The robot's action choices are\nreinforced by social feedback from the human in the form of visual attention\nand measures of behavioral synchronization. We demonstrate that the system can\nacquire and switch between behaviors learned through interaction based on\nsocial feedback from the human partner. The role of reinforcement based on a\nshort term memory of the interaction is experimentally investigated. Results\nindicate that feedback based only on the immediate state is insufficient to\nlearn certain turn-taking behaviors. Therefore some history of the interaction\nmust be considered in the acquisition of turn-taking, which can be efficiently\nhandled through the use of short term memory.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2012 02:23:48 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Broz", "Frank", ""], ["Nehaniv", "Chrystopher L.", ""], ["Kose-Bagci", "Hatice", ""], ["Dautenhahn", "Kerstin", ""]]}, {"id": "1202.6009", "submitter": "Josep Domingo-Ferrer", "authors": "Josep Domingo-Ferrer", "title": "Marginality: a numerical mapping for enhanced treatment of nominal and\n  hierarchical attributes", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of statistical disclosure control (SDC) of microdata, a.k.a. data\nanonymization or privacy-preserving data mining, is to publish data sets\ncontaining the answers of individual respondents in such a way that the\nrespondents corresponding to the released records cannot be re-identified and\nthe released data are analytically useful. SDC methods are either based on\nmasking the original data, generating synthetic versions of them or creating\nhybrid versions by combining original and synthetic data. The choice of SDC\nmethods for categorical data, especially nominal data, is much smaller than the\nchoice of methods for numerical data. We mitigate this problem by introducing a\nnumerical mapping for hierarchical nominal data which allows computing means,\nvariances and covariances on them.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 17:37:20 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Domingo-Ferrer", "Josep", ""]]}, {"id": "1202.6079", "submitter": "Aleks Kissinger", "authors": "Aleks Kissinger", "title": "Synthesising Graphical Theories", "comments": "10 pages, 22 figures. Shortened and one theorem added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, diagrammatic languages have been shown to be a powerful and\nexpressive tool for reasoning about physical, logical, and semantic processes\nrepresented as morphisms in a monoidal category. In particular, categorical\nquantum mechanics, or \"Quantum Picturalism\", aims to turn concrete features of\nquantum theory into abstract structural properties, expressed in the form of\ndiagrammatic identities. One way we search for these properties is to start\nwith a concrete model (e.g. a set of linear maps or finite relations) and start\ncomposing generators into diagrams and looking for graphical identities.\n  Naively, we could automate this procedure by enumerating all diagrams up to a\ngiven size and check for equalities, but this is intractable in practice\nbecause it produces far too many equations. Luckily, many of these identities\nare not primitive, but rather derivable from simpler ones. In 2010, Johansson,\nDixon, and Bundy developed a technique called conjecture synthesis for\nautomatically generating conjectured term equations to feed into an inductive\ntheorem prover. In this extended abstract, we adapt this technique to\ndiagrammatic theories, expressed as graph rewrite systems, and demonstrate its\napplication by synthesising a graphical theory for studying entangled quantum\nstates.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 21:40:45 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2012 21:36:25 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Kissinger", "Aleks", ""]]}, {"id": "1202.6153", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "One Decade of Universal Artificial Intelligence", "comments": "20 LaTeX pages", "journal-ref": "In Theoretical Foundations of Artificial General Intelligence,\n  Vol.4 (2012) pages 67--88", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first decade of this century has seen the nascency of the first\nmathematical theory of general artificial intelligence. This theory of\nUniversal Artificial Intelligence (UAI) has made significant contributions to\nmany theoretical, philosophical, and practical AI questions. In a series of\npapers culminating in book (Hutter, 2005), an exciting sound and complete\nmathematical model for a super intelligent agent (AIXI) has been developed and\nrigorously analyzed. While nowadays most AI researchers avoid discussing\nintelligence, the award-winning PhD thesis (Legg, 2008) provided the\nphilosophical embedding and investigated the UAI-based universal measure of\nrational intelligence, which is formal, objective and non-anthropocentric.\nRecently, effective approximations of AIXI have been derived and experimentally\ninvestigated in JAIR paper (Veness et al. 2011). This practical breakthrough\nhas resulted in some impressive applications, finally muting earlier critique\nthat UAI is only a theory. For the first time, without providing any domain\nknowledge, the same agent is able to self-adapt to a diverse range of\ninteractive environments. For instance, AIXI is able to learn from scratch to\nplay TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without\neven providing the rules of the games.\n  These achievements give new hope that the grand goal of Artificial General\nIntelligence is not elusive.\n  This article provides an informal overview of UAI in context. It attempts to\ngently introduce a very theoretical, formal, and mathematical subject, and\ndiscusses philosophical and technical ingredients, traits of intelligence, some\nsocial questions, and the past and future of UAI.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 09:19:32 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1202.6157", "submitter": "Luca Rose", "authors": "Luca Rose, Samir M. Perlaza, M\\'erouane Debbah, Christophe J. Le\n  Martret", "title": "Distributed Power Allocation with SINR Constraints Using Trial and Error\n  Learning", "comments": "6 pages, 3 figures, accepted at WCNC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of global transmit power minimization\nin a self-congiguring network where radio devices are subject to operate at a\nminimum signal to interference plus noise ratio (SINR) level. We model the\nnetwork as a parallel Gaussian interference channel and we introduce a fully\ndecentralized algorithm (based on trial and error) able to statistically\nachieve a congiguration where the performance demands are met. Contrary to\nexisting solutions, our algorithm requires only local information and can learn\nstable and efficient working points by using only one bit feedback. We model\nthe network under two different game theoretical frameworks: normal form and\nsatisfaction form. We show that the converging points correspond to equilibrium\npoints, namely Nash and satisfaction equilibrium. Similarly, we provide\nsufficient conditions for the algorithm to converge in both formulations.\nMoreover, we provide analytical results to estimate the algorithm's\nperformance, as a function of the network parameters. Finally, numerical\nresults are provided to validate our theoretical conclusions. Keywords:\nLearning, power control, trial and error, Nash equilibrium, spectrum sharing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 09:51:29 GMT"}], "update_date": "2012-02-29", "authors_parsed": [["Rose", "Luca", ""], ["Perlaza", "Samir M.", ""], ["Debbah", "M\u00e9rouane", ""], ["Martret", "Christophe J. Le", ""]]}, {"id": "1202.6177", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Can Intelligence Explode?", "comments": "20 LaTeX pages", "journal-ref": "Journal of Consciousness Studies, 19:1-2 (2012) 143-166", "doi": null, "report-no": null, "categories": "cs.AI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technological singularity refers to a hypothetical scenario in which\ntechnological advances virtually explode. The most popular scenario is the\ncreation of super-intelligent algorithms that recursively create ever higher\nintelligences. It took many decades for these ideas to spread from science\nfiction to popular science magazines and finally to attract the attention of\nserious philosophers. David Chalmers' (JCS 2010) article is the first\ncomprehensive philosophical analysis of the singularity in a respected\nphilosophy journal. The motivation of my article is to augment Chalmers' and to\ndiscuss some issues not addressed by him, in particular what it could mean for\nintelligence to explode. In this course, I will (have to) provide a more\ncareful treatment of what intelligence actually is, separate speed from\nintelligence explosion, compare what super-intelligent participants and\nclassical human observers might experience and do, discuss immediate\nimplications for the diversity and value of life, consider possible bounds on\nintelligence, and contemplate intelligences right at the singularity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 10:46:29 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1202.6386", "submitter": "Shiwali Mohan", "authors": "Shiwali Mohan and John E. Laird", "title": "Relational Reinforcement Learning in Infinite Mario", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational representations in reinforcement learning allow for the use of\nstructural information like the presence of objects and relationships between\nthem in the description of value functions. Through this paper, we show that\nsuch representations allow for the inclusion of background knowledge that\nqualitatively describes a state and can be used to design agents that\ndemonstrate learning behavior in domains with large state and actions spaces\nsuch as computer games.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 21:36:22 GMT"}], "update_date": "2012-03-01", "authors_parsed": [["Mohan", "Shiwali", ""], ["Laird", "John E.", ""]]}, {"id": "1202.6609", "submitter": "Gilles Falquet", "authors": "Claudine M\\'etral, Nizar Ghoula, Gilles Falquet", "title": "Towards an Integrated Visualization Of Semantically Enriched 3D City\n  Models: An Ontology of 3D Visualization Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D city models - which represent in 3 dimensions the geometric elements of a\ncity - are increasingly used for an intended wide range of applications. Such\nuses are made possible by using semantically enriched 3D city models and by\npresenting such enriched 3D city models in a way that allows decision-making\nprocesses to be carried out from the best choices among sets of objectives, and\nacross issues and scales. In order to help in such a decision-making process we\nhave defined a framework to find the best visualization technique(s) for a set\nof potentially heterogeneous data that have to be visualized within the same 3D\ncity model, in order to perform a given task in a specific context. We have\nchosen an ontology-based approach. This approach and the specification and use\nof the resulting ontology of 3D visualization techniques are described in this\npaper.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 17:15:53 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2012 13:33:10 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["M\u00e9tral", "Claudine", ""], ["Ghoula", "Nizar", ""], ["Falquet", "Gilles", ""]]}]