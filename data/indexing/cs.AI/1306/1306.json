[{"id": "1306.0095", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov and Sergey Rodionov", "title": "Universal Induction with Varying Sets of Combinators", "comments": "To appear in the proceedings of AGI 2013, Lecture Notes in Artificial\n  Intelligence, Vol. 7999, pp. 88-97, Springer-Verlag, 2013. The final\n  publication is available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal induction is a crucial issue in AGI. Its practical applicability\ncan be achieved by the choice of the reference machine or representation of\nalgorithms agreed with the environment. This machine should be updatable for\nsolving subsequent tasks more efficiently. We study this problem on an example\nof combinatory logic as the very simple Turing-complete reference machine,\nwhich enables modifying program representations by introducing different sets\nof primitive combinators. Genetic programming system is used to search for\ncombinator expressions, which are easily decomposed into sub-expressions being\nrecombined in crossover. Our experiments show that low-complexity induction or\nprediction tasks can be solved by the developed system (much more efficiently\nthan using brute force); useful combinators can be revealed and included into\nthe representation simplifying more difficult tasks. However, optimal sets of\ncombinators depend on the specific task, so the reference machine should be\nadaptively chosen in coordination with the search engine.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 10:47:23 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1306.0128", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Towards Detection of Bottlenecks in Modular Systems", "comments": "12 pp., tables 4, figures 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes some basic approaches to detection of bottlenecks in\ncomposite (modular) systems. The following basic system bottlenecks detection\nproblems are examined: (1) traditional quality management approaches (Pareto\nchart based method, multicriteria analysis as selection of Pareto-efficient\npoints, and/or multicriteria ranking), (2) selection of critical system\nelements (critical components/modules, critical component interconnection), (3)\nselection of interconnected system components as composite system faults (via\nclique-based fusion), (4) critical elements (e.g., nodes) in networks, and (5)\npredictive detection of system bottlenecks (detection of system components\nbased on forecasting of their parameters). Here, heuristic solving schemes are\nused. Numerical examples illustrate the approaches.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 17:22:00 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1306.0386", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (BIGS)", "title": "Improved and Generalized Upper Bounds on the Complexity of Policy\n  Iteration", "comments": "Markov decision processes, Dynamic Programming, Analysis of\n  Algorithms, Mathematics of Operations Research, INFORMS, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a Markov Decision Process (MDP) with $n$ states and a totalnumber $m$\nof actions, we study the number of iterations needed byPolicy Iteration (PI)\nalgorithms to converge to the optimal$\\gamma$-discounted policy. We consider\ntwo variations of PI: Howard'sPI that changes the actions in all states with a\npositive advantage,and Simplex-PI that only changes the action in the state\nwith maximaladvantage. We show that Howard's PI terminates after at most\n$O\\left(\\frac{m}{1-\\gamma}\\log\\left(\\frac{1}{1-\\gamma}\\right)\\right)$iterations,\nimproving by a factor $O(\\log n)$ a result by Hansen etal., while Simplex-PI\nterminates after at most\n$O\\left(\\frac{nm}{1-\\gamma}\\log\\left(\\frac{1}{1-\\gamma}\\right)\\right)$iterations,\nimproving by a factor $O(\\log n)$ a result by Ye. Undersome structural\nproperties of the MDP, we then consider bounds thatare independent of the\ndiscount factor~$\\gamma$: quantities ofinterest are bounds $\\tau\\_t$ and\n$\\tau\\_r$---uniform on all states andpolicies---respectively on the\n\\emph{expected time spent in transientstates} and \\emph{the inverse of the\nfrequency of visits in recurrentstates} given that the process starts from the\nuniform distribution.Indeed, we show that Simplex-PI terminates after at most\n$\\tilde O\\left(n^3 m^2 \\tau\\_t \\tau\\_r \\right)$ iterations. This extends\narecent result for deterministic MDPs by Post & Ye, in which $\\tau\\_t\\le 1$ and\n$\\tau\\_r \\le n$, in particular it shows that Simplex-PI isstrongly polynomial\nfor a much larger class of MDPs. We explain whysimilar results seem hard to\nderive for Howard's PI. Finally, underthe additional (restrictive) assumption\nthat the state space ispartitioned in two sets, respectively states that are\ntransient andrecurrent for all policies, we show that both Howard's PI\nandSimplex-PI terminate after at most $\\tilde\nO(m(n^2\\tau\\_t+n\\tau\\_r))$iterations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 12:48:27 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2013 14:14:54 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2013 14:09:56 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2016 09:09:49 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Scherrer", "Bruno", "", "BIGS"]]}, {"id": "1306.0539", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (INRIA Nancy - Grand Est / LORIA)", "title": "On the Performance Bounds of some Policy Search Dynamic Programming\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the infinite-horizon discounted optimal control problem\nformalized by Markov Decision Processes. We focus on Policy Search algorithms,\nthat compute an approximately optimal policy by following the standard Policy\nIteration (PI) scheme via an -approximate greedy operator (Kakade and Langford,\n2002; Lazaric et al., 2010). We describe existing and a few new performance\nbounds for Direct Policy Iteration (DPI) (Lagoudakis and Parr, 2003; Fern et\nal., 2006; Lazaric et al., 2010) and Conservative Policy Iteration (CPI)\n(Kakade and Langford, 2002). By paying a particular attention to the\nconcentrability constants involved in such guarantees, we notably argue that\nthe guarantee of CPI is much better than that of DPI, but this comes at the\ncost of a relative--exponential in $\\frac{1}{\\epsilon}$-- increase of time\ncomplexity. We then describe an algorithm, Non-Stationary Direct Policy\nIteration (NSDPI), that can either be seen as 1) a variation of Policy Search\nby Dynamic Programming by Bagnell et al. (2003) to the infinite horizon\nsituation or 2) a simplified version of the Non-Stationary PI with growing\nperiod of Scherrer and Lesner (2012). We provide an analysis of this algorithm,\nthat shows in particular that it enjoys the best of both worlds: its\nperformance guarantee is similar to that of CPI, but within a time complexity\nsimilar to that of DPI.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 19:13:53 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Scherrer", "Bruno", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1306.0665", "submitter": "Manfred Eppe", "authors": "Manfred Eppe and Mehul Bhatt", "title": "Narrative based Postdictive Reasoning for Cognitive Robotics", "comments": "Commonsense Reasoning Symposium, Ayia Napa, Cyprus, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sense of incomplete and conflicting narrative knowledge in the\npresence of abnormalities, unobservable processes, and other real world\nconsiderations is a challenge and crucial requirement for cognitive robotics\nsystems. An added challenge, even when suitably specialised action languages\nand reasoning systems exist, is practical integration and application within\nlarge-scale robot control frameworks.\n  In the backdrop of an autonomous wheelchair robot control task, we report on\napplication-driven work to realise postdiction triggered abnormality detection\nand re-planning for real-time robot control: (a) Narrative-based knowledge\nabout the environment is obtained via a larger smart environment framework; and\n(b) abnormalities are postdicted from stable-models of an answer-set program\ncorresponding to the robot's epistemic model. The overall reasoning is\nperformed in the context of an approximate epistemic action theory based\nplanner implemented via a translation to answer-set programming.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 06:28:49 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Eppe", "Manfred", ""], ["Bhatt", "Mehul", ""]]}, {"id": "1306.0686", "submitter": "Pooria Joulani", "authors": "Pooria Joulani, Andr\\'as Gy\\\"orgy, Csaba Szepesv\\'ari", "title": "Online Learning under Delayed Feedback", "comments": "Extended version of a paper accepted to ICML-2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning with delayed feedback has received increasing attention\nrecently due to its several applications in distributed, web-based learning\nproblems. In this paper we provide a systematic study of the topic, and analyze\nthe effect of delay on the regret of online learning algorithms. Somewhat\nsurprisingly, it turns out that delay increases the regret in a multiplicative\nway in adversarial problems, and in an additive way in stochastic problems. We\ngive meta-algorithms that transform, in a black-box fashion, algorithms\ndeveloped for the non-delayed case into ones that can handle the presence of\ndelays in the feedback loop. Modifications of the well-known UCB algorithm are\nalso developed for the bandit problem with delayed feedback, with the advantage\nover the meta-algorithms that they can be implemented with lower complexity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 07:39:21 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2013 01:01:04 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Joulani", "Pooria", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1306.0694", "submitter": "Tao  Ye", "authors": "Tao Ye and Wenqi Huang and Zhipeng Lu", "title": "Iterated Tabu Search Algorithm for Packing Unequal Circles in a Circle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an Iterated Tabu Search algorithm (denoted by ITS-PUCC)\nfor solving the problem of Packing Unequal Circles in a Circle. The algorithm\nexploits the continuous and combinatorial nature of the unequal circles packing\nproblem. It uses a continuous local optimization method to generate locally\noptimal packings. Meanwhile, it builds a neighborhood structure on the set of\nlocal minimum via two appropriate perturbation moves and integrates two\ncombinatorial optimization methods, Tabu Search and Iterated Local Search, to\nsystematically search for good local minima. Computational experiments on two\nsets of widely-used test instances prove its effectiveness and efficiency. For\nthe first set of 46 instances coming from the famous circle packing contest and\nthe second set of 24 instances widely used in the literature, the algorithm is\nable to discover respectively 14 and 16 better solutions than the previous\nbest-known records.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 08:04:10 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Ye", "Tao", ""], ["Huang", "Wenqi", ""], ["Lu", "Zhipeng", ""]]}, {"id": "1306.0751", "submitter": "Nima Taghipour", "authors": "Nima Taghipour, Jesse Davis, Hendrik Blockeel", "title": "First-Order Decomposition Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifting attempts to speed up probabilistic inference by exploiting symmetries\nin the model. Exact lifted inference methods, like their propositional\ncounterparts, work by recursively decomposing the model and the problem. In the\npropositional case, there exist formal structures, such as decomposition trees\n(dtrees), that represent such a decomposition and allow us to determine the\ncomplexity of inference a priori. However, there is currently no equivalent\nstructure nor analogous complexity results for lifted inference. In this paper,\nwe introduce FO-dtrees, which upgrade propositional dtrees to the first-order\nlevel. We show how these trees can characterize a lifted inference solution for\na probabilistic logical model (in terms of a sequence of lifted operations),\nand make a theoretical analysis of the complexity of lifted inference in terms\nof the novel notion of lifted width for the tree.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 12:43:07 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Taghipour", "Nima", ""], ["Davis", "Jesse", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1306.0963", "submitter": "Been Kim", "authors": "Been Kim, Caleb M. Chacha, Julie Shah", "title": "Inferring Robot Task Plans from Human Team Meetings: A Generative\n  Modeling Approach with Logic-Based Prior", "comments": "Appears in Proceedings of the Twenty-Seventh AAAI Conference on\n  Artificial Intelligence (AAAI-13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to reduce the burden of programming and deploying autonomous systems\nto work in concert with people in time-critical domains, such as military field\noperations and disaster response. Deployment plans for these operations are\nfrequently negotiated on-the-fly by teams of human planners. A human operator\nthen translates the agreed upon plan into machine instructions for the robots.\nWe present an algorithm that reduces this translation burden by inferring the\nfinal plan from a processed form of the human team's planning conversation. Our\napproach combines probabilistic generative modeling with logical plan\nvalidation used to compute a highly structured prior over possible plans. This\nhybrid approach enables us to overcome the challenge of performing inference\nover the large solution space with only a small amount of noisy data from the\nteam planning session. We validate the algorithm through human subject\nexperimentation and show we are able to infer a human team's final plan with\n83% accuracy on average. We also describe a robot demonstration in which two\npeople plan and execute a first-response collaborative task with a PR2 robot.\nTo the best of our knowledge, this is the first work that integrates a logical\nplanning technique within a generative model to perform plan inference.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 02:17:11 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Kim", "Been", ""], ["Chacha", "Caleb M.", ""], ["Shah", "Julie", ""]]}, {"id": "1306.1031", "submitter": "Lars Kotthoff", "authors": "Lars Kotthoff", "title": "LLAMA: Leveraging Learning to Automatically Manage Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm portfolio and selection approaches have achieved remarkable\nimprovements over single solvers. However, the implementation of such systems\nis often highly customised and specific to the problem domain. This makes it\ndifficult for researchers to explore different techniques for their specific\nproblems. We present LLAMA, a modular and extensible toolkit implemented as an\nR package that facilitates the exploration of a range of different portfolio\ntechniques on any problem domain. It implements the algorithm selection\napproaches most commonly used in the literature and leverages the extensive\nlibrary of machine learning algorithms and techniques in R. We describe the\ncurrent capabilities and limitations of the toolkit and illustrate its usage on\na set of example SAT problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 09:35:35 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2013 13:31:08 GMT"}, {"version": "v3", "created": "Wed, 30 Apr 2014 12:55:03 GMT"}], "update_date": "2014-05-01", "authors_parsed": [["Kotthoff", "Lars", ""]]}, {"id": "1306.1034", "submitter": "Mehul Bhatt", "authors": "Mehul Bhatt and Jakob Suchan and Christian Freksa", "title": "ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets,\n  and Benchmarks for Cognitive Interpretation and Control", "comments": "Appears in AAAI-2013 Workshop on: Space, Time, and Ambient\n  Intelligence (STAMI 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construe smart meeting cinematography with a focus on professional\nsituations such as meetings and seminars, possibly conducted in a distributed\nmanner across socio-spatially separated groups. The basic objective in smart\nmeeting cinematography is to interpret professional interactions involving\npeople, and automatically produce dynamic recordings of discussions, debates,\npresentations etc in the presence of multiple communication modalities. Typical\nmodalities include gestures (e.g., raising one's hand for a question,\napplause), voice and interruption, electronic apparatus (e.g., pressing a\nbutton), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance\nof smart meeting cinematography concept, aims to: (a) develop\nfunctionality-driven benchmarks with respect to the interpretation and control\ncapabilities of human-cinematographers, real-time video editors, surveillance\npersonnel, and typical human performance in everyday situations; (b) Develop\ngeneral tools for the commonsense cognitive interpretation of dynamic scenes\nfrom the viewpoint of visuo-spatial cognition centred perceptual\nnarrativisation. Particular emphasis is placed on declarative representations\nand interfacing mechanisms that seamlessly integrate within large-scale\ncognitive (interaction) systems and companion technologies consisting of\ndiverse AI sub-components. For instance, the envisaged tools would provide\ngeneral capabilities for high-level commonsense reasoning about space, events,\nactions, change, and interaction.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 09:40:24 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Bhatt", "Mehul", ""], ["Suchan", "Jakob", ""], ["Freksa", "Christian", ""]]}, {"id": "1306.1267", "submitter": "Michael Chertkov", "authors": "Michael Chertkov, Andrew Gelfand, and Jinwoo Shin", "title": "Loop Calculus and Bootstrap-Belief Propagation for Perfect Matchings on\n  Arbitrary Graphs", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.1088/1742-6596/473/1/012007", "report-no": null, "categories": "cond-mat.stat-mech cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript discusses computation of the Partition Function (PF) and the\nMinimum Weight Perfect Matching (MWPM) on arbitrary, non-bipartite graphs. We\npresent two novel problem formulations - one for computing the PF of a Perfect\nMatching (PM) and one for finding MWPMs - that build upon the inter-related\nBethe Free Energy, Belief Propagation (BP), Loop Calculus (LC), Integer Linear\nProgramming (ILP) and Linear Programming (LP) frameworks. First, we describe an\nextension of the LC framework to the PM problem. The resulting formulas, coined\n(fractional) Bootstrap-BP, express the PF of the original model via the BFE of\nan alternative PM problem. We then study the zero-temperature version of this\nBootstrap-BP formula for approximately solving the MWPM problem. We do so by\nleveraging the Bootstrap-BP formula to construct a sequence of MWPM problems,\nwhere each new problem in the sequence is formed by contracting odd-sized\ncycles (or blossoms) from the previous problem. This Bootstrap-and-Contract\nprocedure converges reliably and generates an empirically tight upper bound for\nthe MWPM. We conclude by discussing the relationship between our iterative\nprocedure and the famous Blossom Algorithm of Edmonds '65 and demonstrate the\nperformance of the Bootstrap-and-Contract approach on a variety of weighted PM\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2013 23:39:06 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Chertkov", "Michael", ""], ["Gelfand", "Andrew", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1306.1421", "submitter": "Juyong Park", "authors": "Juyong Park, Soon-Hyung Yook", "title": "Bayesian Inference of Natural Rankings in Incomplete Competition\n  Networks", "comments": "5 pages, 2 figures", "journal-ref": "Scientific Reports 4, 6212 (2014)", "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competition between a complex system's constituents and a corresponding\nreward mechanism based on it have profound influence on the functioning,\nstability, and evolution of the system. But determining the dominance hierarchy\nor ranking among the constituent parts from the strongest to the weakest --\nessential in determining reward or penalty -- is almost always an ambiguous\ntask due to the incomplete nature of competition networks. Here we introduce\n``Natural Ranking,\" a desirably unambiguous ranking method applicable to a\ncomplete (full) competition network, and formulate an analytical model based on\nthe Bayesian formula inferring the expected mean and error of the natural\nranking of nodes from an incomplete network. We investigate its potential and\nuses in solving issues in ranking by applying to a real-world competition\nnetwork of economic and social importance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 14:47:36 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Park", "Juyong", ""], ["Yook", "Soon-Hyung", ""]]}, {"id": "1306.1520", "submitter": "Bruno Scherrer", "authors": "Bruno Scherrer (INRIA Nancy - Grand Est / LORIA), Matthieu Geist", "title": "Policy Search: Any Local Optimum Enjoys a Global Performance Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Policy Search is a popular reinforcement learning approach for handling\nlarge state spaces. Formally, it searches locally in a paramet erized policy\nspace in order to maximize the associated value function averaged over some\npredefined distribution. It is probably commonly b elieved that the best one\ncan hope in general from such an approach is to get a local optimum of this\ncriterion. In this article, we show th e following surprising result:\n\\emph{any} (approximate) \\emph{local optimum} enjoys a \\emph{global performance\nguarantee}. We compare this g uarantee with the one that is satisfied by Direct\nPolicy Iteration, an approximate dynamic programming algorithm that does some\nform of Poli cy Search: if the approximation error of Local Policy Search may\ngenerally be bigger (because local search requires to consider a space of s\ntochastic policies), we argue that the concentrability coefficient that appears\nin the performance bound is much nicer. Finally, we discuss several practical\nand theoretical consequences of our analysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 19:27:01 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Scherrer", "Bruno", "", "INRIA Nancy - Grand Est / LORIA"], ["Geist", "Matthieu", ""]]}, {"id": "1306.1553", "submitter": "Sergey Rodionov", "authors": "Sergey Rodionov, Alexey Potapov, Yurii Vinogradov", "title": "Direct Uncertainty Estimation in Reinforcement Learning", "comments": "AGI-13 Workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal probabilistic approach in reinforcement learning is computationally\ninfeasible. Its simplification consisting in neglecting difference between true\nenvironment and its model estimated using limited number of observations causes\nexploration vs exploitation problem. Uncertainty can be expressed in terms of a\nprobability distribution over the space of environment models, and this\nuncertainty can be propagated to the action-value function via Bellman\niterations, which are computationally insufficiently efficient though. We\nconsider possibility of directly measuring uncertainty of the action-value\nfunction, and analyze sufficiency of this facilitated approach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 20:57:19 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 14:32:12 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Rodionov", "Sergey", ""], ["Potapov", "Alexey", ""], ["Vinogradov", "Yurii", ""]]}, {"id": "1306.1557", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov", "title": "Extending Universal Intelligence Models with Formal Notion of\n  Representation", "comments": "proceedings of AGI 2012, Lecture Notes in Artificial Intelligence,\n  Vol. 7716, pp. 242-251, Springer-Verlag, 2012. The final publication is\n  available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solomonoff induction is known to be universal, but incomputable. Its\napproximations, namely, the Minimum Description (or Message) Length (MDL)\nprinciples, are adopted in practice in the efficient, but non-universal form.\nRecent attempts to bridge this gap leaded to development of the\nRepresentational MDL principle that originates from formal decomposition of the\ntask of induction. In this paper, possible extension of the RMDL principle in\nthe context of universal intelligence agents is considered, for which\nintroduction of representations is shown to be an unavoidable meta-heuristic\nand a step toward efficient general intelligence. Hierarchical representations\nand model optimization with the use of information-theoretic interpretation of\nthe adaptive resonance are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 21:11:19 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1306.1591", "submitter": "Branko Ristic", "authors": "Branko Ristic, Alex Skvortsov, Andrew Walker", "title": "Autonomous search for a diffusive source in an unknown environment", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": "10.3390/e16020789", "report-no": null, "categories": "cs.AI cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an approach to olfactory search for a diffusive emitting\nsource of tracer (e.g. aerosol, gas) in an environment with unknown map of\nrandomly placed and shaped obstacles.\n  The measurements of tracer concentration are sporadic, noisy and without\ndirectional information. The search domain is discretised and modelled by a\nfinite two-dimensional lattice. The links is the lattice represent the\ntraversable paths for emitted particles and for the searcher. A missing link in\nthe lattice indicates a blocked paths, due to the walls or obstacles. The\nsearcher must simultaneously estimate the source parameters, the map of the\nsearch domain and its own location within the map. The solution is formulated\nin the sequential Bayesian framework and implemented as a Rao-Blackwellised\nparticle filter with information-driven motion control. The numerical results\ndemonstrate the concept and its performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 02:38:50 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Ristic", "Branko", ""], ["Skvortsov", "Alex", ""], ["Walker", "Andrew", ""]]}, {"id": "1306.1849", "submitter": "Nicolas Maudet", "authors": "J\\'er\\^ome Lang, Nicolas Maudet, Maria Polukarov, Alice Cohen-Hadria", "title": "New Results on Equilibria in Strategic Candidacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a voting setting where candidates have preferences about the\noutcome of the election and are free to join or leave the election. The\ncorresponding candidacy game, where candidates choose strategically to\nparticipate or not, has been studied %initially by Dutta et al., who showed\nthat no non-dictatorial voting procedure satisfying unanimity is\ncandidacy-strategyproof, that is, is such that the joint action where all\ncandidates enter the election is always a pure strategy Nash equilibrium. Dutta\net al. also showed that for some voting tree procedures, there are candidacy\ngames with no pure Nash equilibria, and that for the rule that outputs the\nsophisticated winner of voting by successive elimination, all games have a pure\nNash equilibrium. No results were known about other voting rules. Here we prove\nseveral such results. For four candidates, the message is, roughly, that most\nscoring rules (with the exception of Borda) do not guarantee the existence of a\npure Nash equilibrium but that Condorcet-consistent rules, for an odd number of\nvoters, do. For five candidates, most rules we study no longer have this\nguarantee. Finally, we identify one prominent rule that guarantees the\nexistence of a pure Nash equilibrium for any number of candidates (and for an\nodd number of voters): the Copeland rule. We also show that under mild\nassumptions on the voting rule, the existence of strong equilibria cannot be\nguaranteed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 21:49:30 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2016 00:01:09 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Lang", "J\u00e9r\u00f4me", ""], ["Maudet", "Nicolas", ""], ["Polukarov", "Maria", ""], ["Cohen-Hadria", "Alice", ""]]}, {"id": "1306.2025", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Flexibly-bounded Rationality and Marginalization of Irrationality\n  Theories for Decision Making", "comments": "17 pages, submitted to Springer-Verlag. arXiv admin note: substantial\n  text overlap with arXiv:1305.6037", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the theory of flexibly-bounded rationality which is an\nextension to the theory of bounded rationality is revisited. Rational decision\nmaking involves using information which is almost always imperfect and\nincomplete together with some intelligent machine which if it is a human being\nis inconsistent to make decisions. In bounded rationality, this decision is\nmade irrespective of the fact that the information to be used is incomplete and\nimperfect and that the human brain is inconsistent and thus this decision that\nis to be made is taken within the bounds of these limitations. In the theory of\nflexibly-bounded rationality, advanced information analysis is used, the\ncorrelation machine is applied to complete missing information and artificial\nintelligence is used to make more consistent decisions. Therefore\nflexibly-bounded rationality expands the bounds within which rationality is\nexercised. Because human decision making is essentially irrational, this paper\nproposes the theory of marginalization of irrationality in decision making to\ndeal with the problem of satisficing in the presence of irrationality.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2013 14:58:23 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1306.2268", "submitter": "Mi-Young  Park", "authors": "Keehang Kwon and Mi-Young Park", "title": "Accomplishable Tasks in Knowledge Representation", "comments": "arXiv admin note: substantial text overlap with arXiv:1305.2004", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Representation (KR) is traditionally based on the logic of facts,\nexpressed in boolean logic. However, facts about an agent can also be seen as a\nset of accomplished tasks by the agent. This paper proposes a new approach to\nKR: the notion of task logical KR based on Computability Logic. This notion\nallows the user to represent both accomplished tasks and accomplishable tasks\nby the agent. This notion allows us to build sophisticated KRs about many\ninteresting agents, which have not been supported by previous logical\nlanguages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 04:42:02 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Kwon", "Keehang", ""], ["Park", "Mi-Young", ""]]}, {"id": "1306.2295", "submitter": "Alejandro Edera", "authors": "Alejandro Edera, Facundo Bromberg, and Federico Schl\\\"uter", "title": "Markov random fields factorization with context-specific independences", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov random fields provide a compact representation of joint probability\ndistributions by representing its independence properties in an undirected\ngraph. The well-known Hammersley-Clifford theorem uses these conditional\nindependences to factorize a Gibbs distribution into a set of factors. However,\nan important issue of using a graph to represent independences is that it\ncannot encode some types of independence relations, such as the\ncontext-specific independences (CSIs). They are a particular case of\nconditional independences that is true only for a certain assignment of its\nconditioning set; in contrast to conditional independences that must hold for\nall its assignments. This work presents a method for factorizing a Markov\nrandom field according to CSIs present in a distribution, and formally\nguarantees that this factorization is correct. This is presented in our main\ncontribution, the context-specific Hammersley-Clifford theorem, a\ngeneralization to CSIs of the Hammersley-Clifford theorem that applies for\nconditional independences.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 19:36:31 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Edera", "Alejandro", ""], ["Bromberg", "Facundo", ""], ["Schl\u00fcter", "Federico", ""]]}, {"id": "1306.2558", "submitter": "William Cohen", "authors": "William W. Cohen and David P. Redlawsk and Douglas Pierce", "title": "The Effect of Biased Communications On Both Trusting and Suspicious\n  Voters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies of political decision-making, apparently anomalous behavior\nhas been observed on the part of voters, in which negative information about a\ncandidate strengthens, rather than weakens, a prior positive opinion about the\ncandidate. This behavior appears to run counter to rational models of decision\nmaking, and it is sometimes interpreted as evidence of non-rational \"motivated\nreasoning\". We consider scenarios in which this effect arises in a model of\nrational decision making which includes the possibility of deceptive\ninformation. In particular, we will consider a model in which there are two\nclasses of voters, which we will call trusting voters and suspicious voters,\nand two types of information sources, which we will call unbiased sources and\nbiased sources. In our model, new data about a candidate can be efficiently\nincorporated by a trusting voter, and anomalous updates are impossible;\nhowever, anomalous updates can be made by suspicious voters, if the information\nsource mistakenly plans for an audience of trusting voters, and if the partisan\ngoals of the information source are known by the suspicious voter to be\n\"opposite\" to his own. Our model is based on a formalism introduced by the\nartificial intelligence community called \"multi-agent influence diagrams\",\nwhich generalize Bayesian networks to settings involving multiple agents with\ndistinct goals.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2013 15:45:11 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Cohen", "William W.", ""], ["Redlawsk", "David P.", ""], ["Pierce", "Douglas", ""]]}, {"id": "1306.2863", "submitter": "Jun Sun", "authors": "Jun Sun, Xiaojun Wu, Vasile Palade, Wei Fang, Yuhui Shi", "title": "Random Drift Particle Swarm Optimization", "comments": "The paper is the work in progress on particle swarm optimization. It\n  has 41 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random drift particle swarm optimization (RDPSO) algorithm, inspired by\nthe free electron model in metal conductors placed in an external electric\nfield, is presented, systematically analyzed and empirically studied in this\npaper. The free electron model considers that electrons have both a thermal and\na drift motion in a conductor that is placed in an external electric field. The\nmotivation of the RDPSO algorithm is described first, and the velocity equation\nof the particle is designed by simulating the thermal motion as well as the\ndrift motion of the electrons, both of which lead the electrons to a location\nwith minimum potential energy in the external electric field. Then, a\ncomprehensive analysis of the algorithm is made, in order to provide a deep\ninsight into how the RDPSO algorithm works. It involves a theoretical analysis\nand the simulation of the stochastic dynamical behavior of a single particle in\nthe RDPSO algorithm. The search behavior of the algorithm itself is also\ninvestigated in detail, by analyzing the interaction between the particles.\nSome variants of the RDPSO algorithm are proposed by incorporating different\nrandom velocity components with different neighborhood topologies. Finally,\nempirical studies on the RDPSO algorithm are performed by using a set of\nbenchmark functions from the CEC2005 benchmark suite. Based on the theoretical\nanalysis of the particle's behavior, two methods of controlling the algorithmic\nparameters are employed, followed by an experimental analysis on how to select\nthe parameter values, in order to obtain a good overall performance of the\nRDPSO algorithm and its variants in real-world applications. A further\nperformance comparison between the RDPSO algorithms and other variants of PSO\nis made to prove the efficiency of the RDPSO algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 15:34:51 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Sun", "Jun", ""], ["Wu", "Xiaojun", ""], ["Palade", "Vasile", ""], ["Fang", "Wei", ""], ["Shi", "Yuhui", ""]]}, {"id": "1306.2864", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Andreas Wichert", "title": "Finding Academic Experts on a MultiSensor Approach using Shannon's\n  Entropy", "comments": null, "journal-ref": "Journal of Expert Systems with Applications, 2013, volume 40,\n  issue 14", "doi": "10.1016/j.eswa.2013.04.001", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert finding is an information retrieval task concerned with the search for\nthe most knowledgeable people, in some topic, with basis on documents\ndescribing peoples activities. The task involves taking a user query as input\nand returning a list of people sorted by their level of expertise regarding the\nuser query. This paper introduces a novel approach for combining multiple\nestimators of expertise based on a multisensor data fusion framework together\nwith the Dempster-Shafer theory of evidence and Shannon's entropy. More\nspecifically, we defined three sensors which detect heterogeneous information\nderived from the textual contents, from the graph structure of the citation\npatterns for the community of experts, and from profile information about the\nacademic experts. Given the evidences collected, each sensor may define\ndifferent candidates as experts and consequently do not agree in a final\nranking decision. To deal with these conflicts, we applied the Dempster-Shafer\ntheory of evidence combined with Shannon's Entropy formula to fuse this\ninformation and come up with a more accurate and reliable final ranking list.\nExperiments made over two datasets of academic publications from the Computer\nScience domain attest for the adequacy of the proposed approach over the\ntraditional state of the art approaches. We also made experiments against\nrepresentative supervised state of the art algorithms. Results revealed that\nthe proposed method achieved a similar performance when compared to these\nsupervised techniques, confirming the capabilities of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 15:35:57 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Moreira", "Catarina", ""], ["Wichert", "Andreas", ""]]}, {"id": "1306.3317", "submitter": "Mohsen Joneidi", "authors": "Mohsen Joneidi", "title": "Sparse Auto-Regressive: Robust Estimation of AR Parameters", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper I present a new approach for regression of time series using\ntheir own samples. This is a celebrated problem known as Auto-Regression.\nDealing with outlier or missed samples in a time series makes the problem of\nestimation difficult, so it should be robust against them. Moreover for coding\npurposes I will show that it is desired the residual of auto-regression be\nsparse. To these aims, I first assume a multivariate Gaussian prior on the\nresidual and then obtain the estimation. Two simple simulations have been done\non spectrum estimation and speech coding.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2013 07:49:44 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 16:59:06 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Joneidi", "Mohsen", ""]]}, {"id": "1306.3542", "submitter": "Saadat Anwar", "authors": "Saadat Anwar, Chitta Baral, Katsumi Inoue", "title": "Encoding Petri Nets in Answer Set Programming for Simulation Based\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of our long term research goals is to develop systems to answer realistic\nquestions (e.g., some mentioned in textbooks) about biological pathways that a\nbiologist may ask. To answer such questions we need formalisms that can model\npathways, simulate their execution, model intervention to those pathways, and\ncompare simulations under different circumstances. We found Petri Nets to be\nthe starting point of a suitable formalism for the modeling and simulation\nneeds. However, we need to make extensions to the Petri Net model and also\nreason with multiple simulation runs and parallel state evolutions. Towards\nthat end Answer Set Programming (ASP) implementation of Petri Nets would allow\nus to do both. In this paper we show how ASP can be used to encode basic Petri\nNets in an intuitive manner. We then show how we can modify this encoding to\nmodel several Petri Net extensions by making small changes. We then highlight\nsome of the reasoning capabilities that we will use to accomplish our ultimate\nresearch goal.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 03:10:56 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2013 18:27:12 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Anwar", "Saadat", ""], ["Baral", "Chitta", ""], ["Inoue", "Katsumi", ""]]}, {"id": "1306.3548", "submitter": "Saadat Anwar", "authors": "Saadat Anwar, Chitta Baral, Katsumi Inoue", "title": "Encoding Higher Level Extensions of Petri Nets in Answer Set Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering realistic questions about biological systems and pathways similar\nto the ones used by text books to test understanding of students about\nbiological systems is one of our long term research goals. Often these\nquestions require simulation based reasoning. To answer such questions, we need\nformalisms to build pathway models, add extensions, simulate, and reason with\nthem. We chose Petri Nets and Answer Set Programming (ASP) as suitable\nformalisms, since Petri Net models are similar to biological pathway diagrams;\nand ASP provides easy extension and strong reasoning abilities. We found that\ncertain aspects of biological pathways, such as locations and substance types,\ncannot be represented succinctly using regular Petri Nets. As a result, we need\nhigher level constructs like colored tokens. In this paper, we show how Petri\nNets with colored tokens can be encoded in ASP in an intuitive manner, how\nadditional Petri Net extensions can be added by making small code changes, and\nhow this work furthers our long term research goals. Our approach can be\nadapted to other domains with similar modeling needs.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2013 04:28:49 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2013 18:27:24 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Anwar", "Saadat", ""], ["Baral", "Chitta", ""], ["Inoue", "Katsumi", ""]]}, {"id": "1306.3884", "submitter": "Martin Slota", "authors": "Martin Slota and Jo\\~ao Leite", "title": "The Rise and Fall of Semantic Rule Updates Based on SE-Models", "comments": "38 pages, to appear in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 869-907", "doi": "10.1017/S1471068413000100", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic programs under the stable model semantics, or answer-set programs,\nprovide an expressive rule-based knowledge representation framework, featuring\na formal, declarative and well-understood semantics. However, handling the\nevolution of rule bases is still a largely open problem. The AGM framework for\nbelief change was shown to give inappropriate results when directly applied to\nlogic programs under a non-monotonic semantics such as the stable models. The\napproaches to address this issue, developed so far, proposed update semantics\nbased on manipulating the syntactic structure of programs and rules.\n  More recently, AGM revision has been successfully applied to a significantly\nmore expressive semantic characterisation of logic programs based on SE-models.\nThis is an important step, as it changes the focus from the evolution of a\nsyntactic representation of a rule base to the evolution of its semantic\ncontent.\n  In this paper, we borrow results from the area of belief update to tackle the\nproblem of updating (instead of revising) answer-set programs. We prove a\nrepresentation theorem which makes it possible to constructively define any\noperator satisfying a set of postulates derived from Katsuno and Mendelzon's\npostulates for belief update. We define a specific operator based on this\ntheorem, examine its computational complexity and compare the behaviour of this\noperator with syntactic rule update semantics from the literature. Perhaps\nsurprisingly, we uncover a serious drawback of all rule update operators based\non Katsuno and Mendelzon's approach to update and on SE-models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 15:02:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Slota", "Martin", ""], ["Leite", "Jo\u00e3o", ""]]}, {"id": "1306.3888", "submitter": "J. G. Wolff", "authors": "J. Gerard Wolff", "title": "The SP theory of intelligence: an overview", "comments": "arXiv admin note: text overlap with arXiv:cs/0401009,\n  arXiv:1303.2071, arXiv:cs/0307010, arXiv:1212.0229, arXiv:1303.2013", "journal-ref": "J G Wolff, Information, 4 (3), 283-341, 2013", "doi": "10.3390/info4030283", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an overview of the \"SP theory of intelligence\". The theory\naims to simplify and integrate concepts across artificial intelligence,\nmainstream computing and human perception and cognition, with information\ncompression as a unifying theme. It is conceived as a brain-like system that\nreceives 'New' information and stores some or all of it in compressed form as\n'Old' information. It is realised in the form of a computer model -- a first\nversion of the SP machine. The concept of \"multiple alignment\" is a powerful\ncentral idea. Using heuristic techniques, the system builds multiple alignments\nthat are 'good' in terms of information compression. For each multiple\nalignment, probabilities may be calculated. These provide the basis for\ncalculating the probabilities of inferences. The system learns new structures\nfrom partial matches between patterns. Using heuristic techniques, the system\nsearches for sets of structures that are 'good' in terms of information\ncompression. These are normally ones that people judge to be 'natural', in\naccordance with the 'DONSVIC' principle -- the discovery of natural structures\nvia information compression. The SP theory may be applied in several areas\nincluding 'computing', aspects of mathematics and logic, representation of\nknowledge, natural language processing, pattern recognition, several kinds of\nreasoning, information storage and retrieval, planning and problem solving,\ninformation compression, neuroscience, and human perception and cognition.\nExamples include the parsing and production of language including discontinuous\ndependencies in syntax, pattern recognition at multiple levels of abstraction\nand its integration with part-whole relations, nonmonotonic reasoning and\nreasoning with default values, reasoning in Bayesian networks including\n'explaining away', causal diagnosis, and the solving of a geometric analogy\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 11:51:17 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2013 16:31:15 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2013 12:16:05 GMT"}, {"version": "v4", "created": "Wed, 7 Jan 2015 11:44:26 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Wolff", "J. Gerard", ""]]}, {"id": "1306.3890", "submitter": "J. G. Wolff", "authors": "J. Gerard Wolff", "title": "Big data and the SP theory of intelligence", "comments": "Accepted for publication in IEEE Access", "journal-ref": "J G Wolff, IEEE Access, 2, 301-315, 2014", "doi": "10.1109/ACCESS.2014.2315297", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about how the \"SP theory of intelligence\" and its realisation\nin the \"SP machine\" may, with advantage, be applied to the management and\nanalysis of big data. The SP system -- introduced in the article and fully\ndescribed elsewhere -- may help to overcome the problem of variety in big data:\nit has potential as \"a universal framework for the representation and\nprocessing of diverse kinds of knowledge\" (UFK), helping to reduce the\ndiversity of formalisms and formats for knowledge and the different ways in\nwhich they are processed. It has strengths in the unsupervised learning or\ndiscovery of structure in data, in pattern recognition, in the parsing and\nproduction of natural language, in several kinds of reasoning, and more. It\nlends itself to the analysis of streaming data, helping to overcome the problem\nof velocity in big data. Central in the workings of the system is lossless\ncompression of information: making big data smaller and reducing problems of\nstorage and management. There is potential for substantial economies in the\ntransmission of data, for big cuts in the use of energy in computing, for\nfaster processing, and for smaller and lighter computers. The system provides a\nhandle on the problem of veracity in big data, with potential to assist in the\nmanagement of errors and uncertainties in data. It lends itself to the\nvisualisation of knowledge structures and inferential processes. A\nhigh-parallel, open-source version of the SP machine would provide a means for\nresearchers everywhere to explore what can be done with the system and to\ncreate new versions of it.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 13:15:41 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 16:34:23 GMT"}, {"version": "v3", "created": "Tue, 18 Mar 2014 17:18:20 GMT"}, {"version": "v4", "created": "Mon, 31 Mar 2014 19:45:42 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Wolff", "J. Gerard", ""]]}, {"id": "1306.4040", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Gerardo Richarte (1), Jorge Lucangeli Obes\n  (3) ((1) Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos\n  Aires), (3) UBA (Universidad de Buenos Aires))", "title": "An Algorithm to Find Optimal Attack Paths in Nondeterministic Scenarios", "comments": "ACM Workshop on Artificial Intelligence and Security (AISec 2011), at\n  ACM CCS Conference 2011", "journal-ref": null, "doi": "10.1145/2046684.2046695", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  As penetration testing frameworks have evolved and have become more complex,\nthe problem of controlling automatically the pentesting tool has become an\nimportant question. This can be naturally addressed as an attack planning\nproblem. Previous approaches to this problem were based on modeling the actions\nand assets in the PDDL language, and using off-the-shelf AI tools to generate\nattack plans. These approaches however are limited. In particular, the planning\nis classical (the actions are deterministic) and thus not able to handle the\nuncertainty involved in this form of attack planning.\n  We herein contribute a planning model that does capture the uncertainty about\nthe results of the actions, which is modeled as a probability of success of\neach action. We present efficient planning algorithms, specifically designed\nfor this problem, that achieve industrial-scale runtime performance (able to\nsolve scenarios with several hundred hosts and exploits). These algorithms take\ninto account the probability of success of the actions and their expected cost\n(for example in terms of execution time, or network traffic generated).\n  We thus show that probabilistic attack planning can be solved efficiently for\nthe scenarios that arise when assessing the security of large networks. Two\n\"primitives\" are presented, which are used as building blocks in a framework\nseparating the overall problem into two levels of abstraction. We also present\nthe experimental results obtained with our implementation, and conclude with\nsome ideas for further work.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2013 23:26:23 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Richarte", "Gerardo", ""], ["Obes", "Jorge Lucangeli", ""]]}, {"id": "1306.4044", "submitter": "Carlos Sarraute", "authors": "Jorge Lucangeli Obes (1), Carlos Sarraute (1 and 2), Gerardo Richarte\n  (1) ((1) Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos\n  Aires))", "title": "Attack Planning in the Real World", "comments": "SecArt'2010 at AAAI 2010, Atlanta, USA. July 12, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Assessing network security is a complex and difficult task. Attack graphs\nhave been proposed as a tool to help network administrators understand the\npotential weaknesses of their network. However, a problem has not yet been\naddressed by previous work on this subject; namely, how to actually execute and\nvalidate the attack paths resulting from the analysis of the attack graph. In\nthis paper we present a complete PDDL representation of an attack model, and an\nimplementation that integrates a planner into a penetration testing tool. This\nallows to automatically generate attack paths for penetration testing\nscenarios, and to validate these attacks by executing the corresponding actions\n-including exploits- against the real target network. We present an algorithm\nfor transforming the information present in the penetration testing tool to the\nplanning domain, and show how the scalability issues of attack graphs can be\nsolved using current planners. We include an analysis of the performance of our\nsolution, showing how our model scales to medium-sized networks and the number\nof actions available in current penetration testing tools.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2013 00:06:52 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 22:43:15 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Obes", "Jorge Lucangeli", "", "1 and 2"], ["Sarraute", "Carlos", "", "1 and 2"], ["Richarte", "Gerardo", ""]]}, {"id": "1306.4411", "submitter": "Nguyen Vo", "authors": "Chitta Baral, Nguyen H. Vo", "title": "Event-Object Reasoning with Curated Knowledge Bases: Deriving Missing\n  Information", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broader goal of our research is to formulate answers to why and how\nquestions with respect to knowledge bases, such as AURA. One issue we face when\nreasoning with many available knowledge bases is that at times needed\ninformation is missing. Examples of this include partially missing information\nabout next sub-event, first sub-event, last sub-event, result of an event,\ninput to an event, destination of an event, and raw material involved in an\nevent. In many cases one can recover part of the missing knowledge through\nreasoning. In this paper we give a formal definition about how such missing\ninformation can be recovered and then give an ASP implementation of it. We then\ndiscuss the implication of this with respect to answering why and how\nquestions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 01:58:21 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 00:19:24 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Baral", "Chitta", ""], ["Vo", "Nguyen H.", ""]]}, {"id": "1306.4418", "submitter": "Geoffrey Chu", "authors": "Geoffrey Chu, Peter J. Stuckey", "title": "Structure Based Extended Resolution for Constraint Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nogood learning is a powerful approach to reducing search in Constraint\nProgramming (CP) solvers. The current state of the art, called Lazy Clause\nGeneration (LCG), uses resolution to derive nogoods expressing the reasons for\neach search failure. Such nogoods can prune other parts of the search tree,\nproducing exponential speedups on a wide variety of problems. Nogood learning\nsolvers can be seen as resolution proof systems. The stronger the proof system,\nthe faster it can solve a CP problem. It has recently been shown that the proof\nsystem used in LCG is at least as strong as general resolution. However,\nstronger proof systems such as \\emph{extended resolution} exist. Extended\nresolution allows for literals expressing arbitrary logical concepts over\nexisting variables to be introduced and can allow exponentially smaller proofs\nthan general resolution. The primary problem in using extended resolution is to\nfigure out exactly which literals are useful to introduce. In this paper, we\nshow that we can use the structural information contained in a CP model in\norder to introduce useful literals, and that this can translate into\nsignificant speedups on a range of problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 04:18:45 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Chu", "Geoffrey", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "1306.4460", "submitter": "Michal \\v{C}ertick\\'y", "authors": "Michal Certicky", "title": "Implementing a Wall-In Building Placement in StarCraft with Declarative\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-time strategy games like StarCraft, skilled players often block the\nentrance to their base with buildings to prevent the opponent's units from\ngetting inside. This technique, called \"walling-in\", is a vital part of\nplayer's skill set, allowing him to survive early aggression. However, current\nartificial players (bots) do not possess this skill, due to numerous\ninconveniences surfacing during its implementation in imperative languages like\nC++ or Java. In this text, written as a guide for bot programmers, we address\nthe problem of finding an appropriate building placement that would block the\nentrance to player's base, and present a ready to use declarative solution\nemploying the paradigm of answer set programming (ASP). We also encourage the\nreaders to experiment with different declarative approaches to this problem.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 09:08:48 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Certicky", "Michal", ""]]}, {"id": "1306.4532", "submitter": "EPTCS", "authors": "Ross Duncan (University of Strathclyde, Glasgow, UK), Maxime Lucas\n  (Universit\\'e Libre de Bruxelles, Brussels, Belgium)", "title": "Verifying the Steane code with Quantomatic", "comments": "In Proceedings QPL 2013, arXiv:1412.7917", "journal-ref": "EPTCS 171, 2014, pp. 33-49", "doi": "10.4204/EPTCS.171.4", "report-no": null, "categories": "quant-ph cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we give a partially mechanized proof of the correctness of\nSteane's 7-qubit error correcting code, using the tool Quantomatic. To the best\nof our knowledge, this represents the largest and most complicated verification\ntask yet carried out using Quantomatic.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 13:10:46 GMT"}, {"version": "v2", "created": "Tue, 30 Dec 2014 01:42:59 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Duncan", "Ross", "", "University of Strathclyde, Glasgow, UK"], ["Lucas", "Maxime", "", "Universit\u00e9 Libre de Bruxelles, Brussels, Belgium"]]}, {"id": "1306.4635", "submitter": "Mark Levin", "authors": "Mark Sh. Levin", "title": "Towards Multistage Design of Modular Systems", "comments": "13 pages, 25 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes multistage design of composite (modular) systems (i.e.,\ndesign of a system trajectory). This design process consists of the following:\n(i) definition of a set of time/logical points; (ii) modular design of the\nsystem for each time/logical point (e.g., on the basis of combinatorial\nsynthesis as hierarchical morphological design or multiple choice problem) to\nobtain several system solutions; (iii) selection of the system solution for\neach time/logical point while taking into account their quality and the quality\nof compatibility between neighbor selected system solutions (here,\ncombinatorial synthesis is used as well). Mainly, the examined time/logical\npoints are based on a time chain. In addition, two complicated cases are\nconsidered: (a) the examined logical points are based on a tree-like structure,\n(b) the examined logical points are based on a digraph. Numerical examples\nillustrate the approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 18:07:54 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "1306.4714", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (1 and 2), Olivier Buffet (3), Joerg Hoffmann (3) ((1)\n  Core Security Technologies, (2) ITBA (Instituto Tecnologico Buenos Aires),\n  (3) INRIA)", "title": "Penetration Testing == POMDP Solving?", "comments": "Proceedings of the 3rd Workshop on Intelligent Security (SecArt'11),\n  at IJCAI'11", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Penetration Testing is a methodology for assessing network security, by\ngenerating and executing possible attacks. Doing so automatically allows for\nregular and systematic testing without a prohibitive amount of human labor. A\nkey question then is how to generate the attacks. This is naturally formulated\nas a planning problem. Previous work (Lucangeli et al. 2010) used classical\nplanning and hence ignores all the incomplete knowledge that characterizes\nhacking. More recent work (Sarraute et al. 2011) makes strong independence\nassumptions for the sake of scaling, and lacks a clear formal concept of what\nthe attack planning problem actually is. Herein, we model that problem in terms\nof partially observable Markov decision processes (POMDP). This grounds\npenetration testing in a well-researched formalism, highlighting important\naspects of this problem's nature. POMDPs allow to model information gathering\nas an integral part of the problem, thus providing for the first time a means\nto intelligently mix scanning actions with actual exploits.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 22:39:20 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Sarraute", "Carlos", "", "1 and 2"], ["Buffet", "Olivier", ""], ["Hoffmann", "Joerg", ""]]}, {"id": "1306.4753", "submitter": "Geoffrey Gordon", "authors": "Geoffrey J. Gordon", "title": "Galerkin Methods for Complementarity Problems and Variational\n  Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementarity problems and variational inequalities arise in a wide variety\nof areas, including machine learning, planning, game theory, and physical\nsimulation. In all of these areas, to handle large-scale problem instances, we\nneed fast approximate solution methods. One promising idea is Galerkin\napproximation, in which we search for the best answer within the span of a\ngiven set of basis functions. Bertsekas proposed one possible Galerkin method\nfor variational inequalities. However, this method can exhibit two problems in\npractice: its approximation error is worse than might be expected based on the\nability of the basis to represent the desired solution, and each iteration\nrequires a projection step that is not always easy to implement efficiently.\nSo, in this paper, we present a new Galerkin method with improved behavior: our\nnew error bounds depend directly on the distance from the true solution to the\nsubspace spanned by our basis, and the only projections we require are onto the\nfeasible region or onto the span of our basis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 04:48:37 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Gordon", "Geoffrey J.", ""]]}, {"id": "1306.4925", "submitter": "Francesco Ricca", "authors": "Marco Maratea, Luca Pulina, Francesco Ricca", "title": "A Multi-Engine Approach to Answer Set Programming", "comments": "26 pages, 8 figures", "journal-ref": "Theory and Practice of Logic Programming 14 (2014) 841-868", "doi": "10.1017/S1471068413000094", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a truly-declarative programming paradigm\nproposed in the area of non-monotonic reasoning and logic programming, that has\nbeen recently employed in many applications. The development of efficient ASP\nsystems is, thus, crucial. Having in mind the task of improving the solving\nmethods for ASP, there are two usual ways to reach this goal: $(i)$ extending\nstate-of-the-art techniques and ASP solvers, or $(ii)$ designing a new ASP\nsolver from scratch. An alternative to these trends is to build on top of\nstate-of-the-art solvers, and to apply machine learning techniques for choosing\nautomatically the \"best\" available solver on a per-instance basis.\n  In this paper we pursue this latter direction. We first define a set of\ncheap-to-compute syntactic features that characterize several aspects of ASP\nprograms. Then, we apply classification methods that, given the features of the\ninstances in a {\\sl training} set and the solvers' performance on these\ninstances, inductively learn algorithm selection strategies to be applied to a\n{\\sl test} set. We report the results of a number of experiments considering\nsolvers and different training and test sets of instances taken from the ones\nsubmitted to the \"System Track\" of the 3rd ASP Competition. Our analysis shows\nthat, by applying machine learning techniques to ASP solving, it is possible to\nobtain very robust performance: our approach can solve more instances compared\nwith any solver that entered the 3rd ASP Competition. (To appear in Theory and\nPractice of Logic Programming (TPLP).)\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 16:03:19 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Maratea", "Marco", ""], ["Pulina", "Luca", ""], ["Ricca", "Francesco", ""]]}, {"id": "1306.4999", "submitter": "Lizi Zhang", "authors": "Lizi Zhang", "title": "Safeguarding E-Commerce against Advisor Cheating Behaviors: Towards More\n  Robust Trust Models for Handling Unfair Ratings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In electronic marketplaces, after each transaction buyers will rate the\nproducts provided by the sellers. To decide the most trustworthy sellers to\ntransact with, buyers rely on trust models to leverage these ratings to\nevaluate the reputation of sellers. Although the high effectiveness of\ndifferent trust models for handling unfair ratings have been claimed by their\ndesigners, recently it is argued that these models are vulnerable to more\nintelligent attacks, and there is an urgent demand that the robustness of the\nexisting trust models has to be evaluated in a more comprehensive way. In this\nwork, we classify the existing trust models into two broad categories and\npropose an extendable e-marketplace testbed to evaluate their robustness\nagainst different unfair rating attacks comprehensively. On top of highlighting\nthe robustness of the existing trust models for handling unfair ratings is far\nfrom what they were claimed to be, we further propose and validate a novel\ncombination mechanism for the existing trust models, Discount-then-Filter, to\nnotably enhance their robustness against the investigated attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 20:56:20 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Zhang", "Lizi", ""]]}, {"id": "1306.5053", "submitter": "Toby Walsh", "authors": "Nina Narodytska and Toby Walsh", "title": "Breaking Symmetry with Different Orderings", "comments": "To appear in Proceedings of CP 2013, 19th International Conference on\n  Principles and Practice of Constraint Programming. Slightly longer version\n  with a proof sketch expanded compared to official LNCS conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can break symmetry by eliminating solutions within each symmetry class.\nFor instance, the Lex-Leader method eliminates all but the smallest solution in\nthe lexicographical ordering. Unfortunately, the Lex-Leader method is\nintractable in general. We prove that, under modest assumptions, we cannot\nreduce the worst case complexity of breaking symmetry by using other orderings\non solutions. We also prove that a common type of symmetry, where rows and\ncolumns in a matrix of decision variables are interchangeable, is intractable\nto break when we use two promising alternatives to the lexicographical\nordering: the Gray code ordering (which uses a different ordering on\nsolutions), and the Snake-Lex ordering (which is a variant of the\nlexicographical ordering that re-orders the variables). Nevertheless, we show\nexperimentally that using other orderings like the Gray code to break symmetry\ncan be beneficial in practice as they may better align with the objective\nfunction and branching heuristic.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 06:04:00 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Narodytska", "Nina", ""], ["Walsh", "Toby", ""]]}, {"id": "1306.5070", "submitter": "Mina Farmanbar Ms", "authors": "Nasser Lotfi, Jamshid Tamouk, Mina Farmanbar", "title": "3-SAT Problem A New Memetic-PSO Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3-SAT problem is of great importance to many technical and scientific\napplications. This paper presents a new hybrid evolutionary algorithm for\nsolving this satisfiability problem. 3-SAT problem has the huge search space\nand hence it is known as a NP-hard problem. So, deterministic approaches are\nnot applicable in this context. Thereof, application of evolutionary processing\napproaches and especially PSO will be very effective for solving these kinds of\nproblems. In this paper, we introduce a new evolutionary optimization technique\nbased on PSO, Memetic algorithm and local search approaches. When some\nheuristics are mixed, their advantages are collected as well and we can reach\nto the better outcomes. Finally, we test our proposed algorithm over some\nbenchmarks used by some another available algorithms. Obtained results show\nthat our new method leads to the suitable results by the appropriate time.\nThereby, it achieves a better result in compared with the existent approaches\nsuch as pure genetic algorithm and some verified types\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 08:10:44 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Lotfi", "Nasser", ""], ["Tamouk", "Jamshid", ""], ["Farmanbar", "Mina", ""]]}, {"id": "1306.5215", "submitter": "Andreas Tolk", "authors": "Andreas Tolk, Saikou Y. Diallo, Jose J. Padilla, Ross Gore", "title": "Epistemology of Modeling and Simulation: How can we gain Knowledge from\n  Simulations?", "comments": "MODSIM World 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemology is the branch of philosophy that deals with gaining knowledge.\nIt is closely related to ontology. The branch that deals with questions like\n\"What is real?\" and \"What do we know?\" as it provides these components. When\nusing modeling and simulation, we usually imply that we are doing so to either\napply knowledge, in particular when we are using them for training and\nteaching, or that we want to gain new knowledge, for example when doing\nanalysis or conducting virtual experiments. This paper looks at the history of\nscience to give a context to better cope with the question, how we can gain\nknowledge from simulation. It addresses aspects of computability and the\ngeneral underlying mathematics, and applies the findings to validation and\nverification and development of federations. As simulations are understood as\ncomputable executable hypotheses, validation can be understood as hypothesis\ntesting and theory building. The mathematical framework allows furthermore\naddressing some challenges when developing federations and the potential\nintroduction of contradictions when composing different theories, as they are\nrepresented by the federated simulation systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 19:15:51 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Tolk", "Andreas", ""], ["Diallo", "Saikou Y.", ""], ["Padilla", "Jose J.", ""], ["Gore", "Ross", ""]]}, {"id": "1306.5279", "submitter": "Jesse Hoey", "authors": "Jesse Hoey, Tobias Schroeder, Areej Alhothali", "title": "Affect Control Processes: Intelligent Affective Interaction using a\n  Partially Observable Markov Decision Process", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2015.09.004", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel method for building affectively intelligent\nhuman-interactive agents. The method is based on a key sociological insight\nthat has been developed and extensively verified over the last twenty years,\nbut has yet to make an impact in artificial intelligence. The insight is that\nresource bounded humans will, by default, act to maintain affective\nconsistency. Humans have culturally shared fundamental affective sentiments\nabout identities, behaviours, and objects, and they act so that the transient\naffective sentiments created during interactions confirm the fundamental\nsentiments. Humans seek and create situations that confirm or are consistent\nwith, and avoid and supress situations that disconfirm or are inconsistent\nwith, their culturally shared affective sentiments. This \"affect control\nprinciple\" has been shown to be a powerful predictor of human behaviour. In\nthis paper, we present a probabilistic and decision-theoretic generalisation of\nthis principle, and we demonstrate how it can be leveraged to build affectively\nintelligent artificial agents. The new model, called BayesAct, can maintain\nmultiple hypotheses about sentiments simultaneously as a probability\ndistribution, and can make use of an explicit utility function to make\nvalue-directed action choices. This allows the model to generate affectively\nintelligent interactions with people by learning about their identity,\npredicting their behaviours using the affect control principle, and taking\nactions that are simultaneously goal-directed and affect-sensitive. We\ndemonstrate this generalisation with a set of simulations. We then show how our\nmodel can be used as an emotional \"plug-in\" for artificially intelligent\nsystems that interact with humans in two different settings: an exam practice\nassistant (tutor) and an assistive device for persons with a cognitive\ndisability.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2013 01:02:03 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 13:49:43 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Hoey", "Jesse", ""], ["Schroeder", "Tobias", ""], ["Alhothali", "Areej", ""]]}, {"id": "1306.5308", "submitter": "Mehul Bhatt", "authors": "Mehul Bhatt, Jakob Suchan, Carl Schultz", "title": "Cognitive Interpretation of Everyday Activities: Toward Perceptual\n  Narrative Based Visuo-Spatial Scene Interpretation", "comments": "To appear at: Computational Models of Narrative (CMN) 2013., a\n  satellite event of CogSci 2013: The 35th meeting of the Cognitive Science\n  Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We position a narrative-centred computational model for high-level knowledge\nrepresentation and reasoning in the context of a range of assistive\ntechnologies concerned with \"visuo-spatial perception and cognition\" tasks. Our\nproposed narrative model encompasses aspects such as \\emph{space, events,\nactions, change, and interaction} from the viewpoint of commonsense reasoning\nand learning in large-scale cognitive systems. The broad focus of this paper is\non the domain of \"human-activity interpretation\" in smart environments, ambient\nintelligence etc. In the backdrop of a \"smart meeting cinematography\" domain,\nwe position the proposed narrative model, preliminary work on perceptual\nnarrativisation, and the immediate outlook on constructing general-purpose\nopen-source tools for perceptual narrativisation.\n  ACM Classification: I.2 Artificial Intelligence: I.2.0 General -- Cognitive\nSimulation, I.2.4 Knowledge Representation Formalisms and Methods, I.2.10\nVision and Scene Understanding: Architecture and control structures, Motion,\nPerceptual reasoning, Shape, Video analysis\n  General keywords: cognitive systems; human-computer interaction; spatial\ncognition and computation; commonsense reasoning; spatial and temporal\nreasoning; assistive technologies\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2013 10:37:34 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Bhatt", "Mehul", ""], ["Suchan", "Jakob", ""], ["Schultz", "Carl", ""]]}, {"id": "1306.5601", "submitter": "Moritz M\\\"uhlenthaler", "authors": "Moritz M\\\"uhlenthaler and Rolf Wanka", "title": "A Decomposition of the Max-min Fair Curriculum-based Course Timetabling\n  Problem", "comments": "revised version (fixed problems in the notation and general\n  improvements); original paper: 16 pages, accepted for publication at the\n  Multidisciplinary International Scheduling Conference 2013 (MISTA 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decomposition of the max-min fair curriculum-based course\ntimetabling (MMF-CB-CTT) problem. The decomposition models the room assignment\nsubproblem as a generalized lexicographic bottleneck optimization problem\n(LBOP). We show that the generalized LBOP can be solved efficiently if the\ncorresponding sum optimization problem can be solved efficiently. As a\nconsequence, the room assignment subproblem of the MMF-CB-CTT problem can be\nsolved efficiently. We use this insight to improve a previously proposed\nheuristic algorithm for the MMF-CB-CTT problem. Our experimental results\nindicate that using the new decomposition improves the performance of the\nalgorithm on most of the 21 ITC2007 test instances with respect to the quality\nof the best solution found. Furthermore, we introduce a measure of the quality\nof a solution to a max-min fair optimization problem. This measure helps to\novercome some limitations imposed by the qualitative nature of max-min fairness\nand aids the statistical evaluation of the performance of randomized algorithms\nfor such problems. We use this measure to show that using the new decomposition\nthe algorithm outperforms the original one on most instances with respect to\nthe average solution quality.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 12:54:50 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2013 13:33:24 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["M\u00fchlenthaler", "Moritz", ""], ["Wanka", "Rolf", ""]]}, {"id": "1306.5606", "submitter": "Barry Hurley", "authors": "Barry Hurley, Lars Kotthoff, Yuri Malitsky, Barry O'Sullivan", "title": "Proteus: A Hierarchical Portfolio of Solvers and Transformations", "comments": "11th International Conference on Integration of AI and OR Techniques\n  in Constraint Programming for Combinatorial Optimization Problems. The final\n  publication is available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, portfolio approaches to solving SAT problems and CSPs have\nbecome increasingly common. There are also a number of different encodings for\nrepresenting CSPs as SAT instances. In this paper, we leverage advances in both\nSAT and CSP solving to present a novel hierarchical portfolio-based approach to\nCSP solving, which we call Proteus, that does not rely purely on CSP solvers.\nInstead, it may decide that it is best to encode a CSP problem instance into\nSAT, selecting an appropriate encoding and a corresponding SAT solver. Our\nexperimental evaluation used an instance of Proteus that involved four CSP\nsolvers, three SAT encodings, and six SAT solvers, evaluated on the most\nchallenging problem instances from the CSP solver competitions, involving\nglobal and intensional constraints. We show that significant performance\nimprovements can be achieved by Proteus obtained by exploiting alternative\nview-points and solvers for combinatorial problem-solving.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 13:11:54 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 12:26:45 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Hurley", "Barry", ""], ["Kotthoff", "Lars", ""], ["Malitsky", "Yuri", ""], ["O'Sullivan", "Barry", ""]]}, {"id": "1306.5667", "submitter": "W B Langdon", "authors": "W. B. Langdon and M. Harman", "title": "Using Genetic Programming to Model Software", "comments": "As UCL computer science Technical Report RN/13/12", "journal-ref": null, "doi": null, "report-no": "RN/13/12", "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generic program to investigate the scope for automatically\ncustomising it for a vital current task, which was not considered when it was\nfirst written. In detail, we show genetic programming (GP) can evolve models of\naspects of BLAST's output when it is used to map Solexa Next-Gen DNA sequences\nto the human genome.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 16:35:37 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Langdon", "W. B.", ""], ["Harman", "M.", ""]]}, {"id": "1306.5707", "submitter": "Jaeyong Sung", "authors": "Jaeyong Sung, Bart Selman, Ashutosh Saxena", "title": "Synthesizing Manipulation Sequences for Under-Specified Tasks using\n  Unrolled Markov Random Fields", "comments": "To Appear in IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2014 (A preliminary version of this work was presented at\n  International Conference of Machine Learning (ICML) workshop on Prediction\n  with Sequential Models, 2013)", "journal-ref": null, "doi": "10.1109/IROS.2014.6942972", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in human environments require performing a sequence of navigation\nand manipulation steps involving objects. In unstructured human environments,\nthe location and configuration of the objects involved often change in\nunpredictable ways. This requires a high-level planning strategy that is robust\nand flexible in an uncertain environment. We propose a novel dynamic planning\nstrategy, which can be trained from a set of example sequences. High level\ntasks are expressed as a sequence of primitive actions or controllers (with\nappropriate parameters). Our score function, based on Markov Random Field\n(MRF), captures the relations between environment, controllers, and their\narguments. By expressing the environment using sets of attributes, the approach\ngeneralizes well to unseen scenarios. We train the parameters of our MRF using\na maximum margin learning method. We provide a detailed empirical validation of\nour overall framework demonstrating successful plan strategies for a variety of\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 18:48:54 GMT"}, {"version": "v2", "created": "Tue, 24 Jun 2014 05:10:50 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Sung", "Jaeyong", ""], ["Selman", "Bart", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1306.5858", "submitter": "Raz Nissim", "authors": "Raz Nissim and Ronen Brafman", "title": "Distributed Heuristic Forward Search for Multi-Agent Systems", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a number of distributed forward search algorithms for\nsolving multi-agent planning problems. We introduce a distributed formulation\nof non-optimal forward search, as well as an optimal version, MAD-A*. Our\nalgorithms exploit the structure of multi-agent problems to not only distribute\nthe work efficiently among different agents, but also to remove symmetries and\nreduce the overall workload. The algorithms ensure that private information is\nnot shared among agents, yet computation is still efficient -- outperforming\ncurrent state-of-the-art distributed planners, and in some cases even\ncentralized search -- despite the fact that each agent has access only to\npartial information.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 06:58:31 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Nissim", "Raz", ""], ["Brafman", "Ronen", ""]]}, {"id": "1306.5884", "submitter": "Sandeep Venkatesh", "authors": "Sandeep Venkatesh, Meera V Patil, Nanditha Swamy", "title": "Design of an Agent for Answering Back in Smart Phones", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  erro", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the paper is to design an agent which provides efficient\nresponse to the caller when a call goes unanswered in smartphones. The agent\nprovides responses through text messages, email etc stating the most likely\nreason as to why the callee is unable to answer a call. Responses are composed\ntaking into consideration the importance of the present call and the situation\nthe callee is in at the moment like driving, sleeping, at work etc. The agent\nmakes decisons in the compostion of response messages based on the patterns it\nhas come across in the learning environment. Initially the user helps the agent\nto compose response messages. The agent associates this message to the percept\nit recieves with respect to the environment the callee is in. The user may\nthereafter either choose to make to response system automatic or choose to\nrecieve suggestions from the agent for responses messages and confirm what is\nto be sent to the caller.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 08:56:58 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2014 11:02:00 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Venkatesh", "Sandeep", ""], ["Patil", "Meera V", ""], ["Swamy", "Nanditha", ""]]}, {"id": "1306.5960", "submitter": "Shofwatul Uyun Mrs", "authors": "Sri Hartati, Shofwatul 'Uyun", "title": "Computation of Diet Composition for Patients Suffering from Kidney and\n  Urinary Tract Diseases with the Fuzzy Genetic System", "comments": "8 pages", "journal-ref": "International Journal of Computer Applications (0975-8887)-Volume\n  36, No.6, December 2011", "doi": "10.5120/4499-6350", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Determination of dietary food consumed a day for patients with diseases in\ngeneral, greatly affect the health of the body and the healing process, is no\nexception for people with kidney disease and urinary tract. This paper presents\nthe determination of diet composition in the form of food subtance for people\nwith kidney and urinary tract diseases with a genetic fuzzy approach. This\napproach combines fuzzy logic and genetic algorithms, which utilizing fuzzy\nlogic fuzzy tools and techniques to model the components of the genetic\nalgorithm and adapting genetic algorithm control parameters, with the aim of\nimproving system performance. The Mamdani fuzzy inference model and fuzzy rules\nbased on population parameters and generation are used to determine the\nprobability of crossover and mutation, and was using In this study, 400 food\nsurvey data along with their substances was used as test material. From the\ndata, a varying amount of population is established. Each chromosome has 10\ngenes in which the value of each gene indicates the index number of foodstuffs\nin the database. The fuzzy genetic approach produces 10 best food substance and\ntheir compositions. The composition of these foods has nutritional value in\naccordance with the number of calories needed by people with kidney and urinary\ntract diseases by type of food.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 13:43:27 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Hartati", "Sri", ""], ["'Uyun", "Shofwatul", ""]]}, {"id": "1306.5982", "submitter": "Menaka Gandhi  J", "authors": "Menaka Gandhi.J and K.S.Gayathri", "title": "Activity Modeling in Smart Home using High Utility Pattern Mining over\n  Data Streams", "comments": "This research paper consists of 7 pages, 7 figures and 4 algorithms", "journal-ref": "\"Interactive mining of high utility patterns over data streams\",\n  Elsevier, Vol. 39, No. 15, 2012", "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Smart home technology is a better choice for the people to care about\nsecurity, comfort and power saving as well. It is required to develop\ntechnologies that recognize the Activities of Daily Living (ADLs) of the\nresidents at home and detect the abnormal behavior in the individual's\npatterns. Data mining techniques such as Frequent pattern mining (FPM), High\nUtility Pattern (HUP) Mining were used to find those activity patterns from the\ncollected sensor data. But applying the above technique for Activity\nRecognition from the temporal sensor data stream is highly complex and\nchallenging task. So, a new approach is proposed for activity recognition from\nsensor data stream which is achieved by constructing Frequent Pattern Stream\ntree (FPS - tree). FPS is a sliding window based approach to discover the\nrecent activity patterns over time from data streams. The proposed work aims at\nidentifying the frequent pattern of the user from the sensor data streams which\nare later modeled for activity recognition. The proposed FPM algorithm uses a\ndata structure called Linked Sensor Data Stream (LSDS) for storing the sensor\ndata stream information which increases the efficiency of frequent pattern\nmining algorithm through both space and time. The experimental results show the\nefficiency of the proposed algorithm and this FPM is further extended for\napplying for power efficiency using HUP to detect the high usage of power\nconsumption of residents at smart home.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 14:39:17 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["J", "Menaka Gandhi.", ""], ["Gayathri", "K. S.", ""]]}, {"id": "1306.6294", "submitter": "Ashesh Jain", "authors": "Ashesh Jain and Brian Wojcik, Thorsten Joachims and Ashutosh Saxena", "title": "Learning Trajectory Preferences for Manipulators via Iterative\n  Improvement", "comments": "9 pages. To appear in NIPS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning good trajectories for manipulation tasks.\nThis is challenging because the criterion defining a good trajectory varies\nwith users, tasks and environments. In this paper, we propose a co-active\nonline learning framework for teaching robots the preferences of its users for\nobject manipulation tasks. The key novelty of our approach lies in the type of\nfeedback expected from the user: the human user does not need to demonstrate\noptimal trajectories as training data, but merely needs to iteratively provide\ntrajectories that slightly improve over the trajectory currently proposed by\nthe system. We argue that this co-active preference feedback can be more easily\nelicited from the user than demonstrations of optimal trajectories, which are\noften challenging and non-intuitive to provide on high degrees of freedom\nmanipulators. Nevertheless, theoretical regret bounds of our algorithm match\nthe asymptotic rates of optimal trajectory algorithms. We demonstrate the\ngeneralizability of our algorithm on a variety of grocery checkout tasks, for\nwhom, the preferences were not only influenced by the object being manipulated\nbut also by the surrounding environment.\\footnote{For more details and a\ndemonstration video, visit: \\url{http://pr.cs.cornell.edu/coactive}}\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 17:07:58 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2013 17:55:31 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Jain", "Ashesh", ""], ["Wojcik", "Brian", ""], ["Joachims", "Thorsten", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1306.6302", "submitter": "Roni Khardon", "authors": "S. Joshi, R. Khardon, P. Tadepalli, A. Raghavan, A. Fern", "title": "Solving Relational MDPs with Exogenous Events and Additive Rewards", "comments": "This is an extended version of our ECML/PKDD 2013 paper including all\n  proofs. (v2 corrects typos and updates ref [10] to cite this report as the\n  full version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize a simple but natural subclass of service domains for relational\nplanning problems with object-centered, independent exogenous events and\nadditive rewards capturing, for example, problems in inventory control.\nFocusing on this subclass, we present a new symbolic planning algorithm which\nis the first algorithm that has explicit performance guarantees for relational\nMDPs with exogenous events. In particular, under some technical conditions, our\nplanning algorithm provides a monotonic lower bound on the optimal value\nfunction. To support this algorithm we present novel evaluation and reduction\ntechniques for generalized first order decision diagrams, a knowledge\nrepresentation for real-valued functions over relational world states. Our\nplanning algorithm uses a set of focus states, which serves as a training set,\nto simplify and approximate the symbolic solution, and can thus be seen to\nperform learning for planning. A preliminary experimental evaluation\ndemonstrates the validity of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 17:59:49 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2013 13:57:19 GMT"}], "update_date": "2013-06-28", "authors_parsed": [["Joshi", "S.", ""], ["Khardon", "R.", ""], ["Tadepalli", "P.", ""], ["Raghavan", "A.", ""], ["Fern", "A.", ""]]}, {"id": "1306.6375", "submitter": "Vena Pearl Bongolan Dr.", "authors": "Vena Pearl Bongolan, Florencio C. Ballesteros, Jr., Joyce Anne M.\n  Banting, Aina Marie Q. Olaes, Charlymagne R. Aquino", "title": "Metaheuristics in Flood Disaster Management and Risk Assessment", "comments": "UP ICE Centennial Conference Harmonizing Infrastructure with the\n  Environment November 12, 2010 in Manila, Philippines 8th National conference\n  on Information Technology Education (NCITE 2010) October 20-23, 2010 in\n  Boracay, Philippines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conceptual area is divided into units or barangays, each was allowed to\nevolve under a physical constraint. A risk assessment method was then used to\nidentify the flood risk in each community using the following risk factors: the\narea's urbanized area ratio, literacy rate, mortality rate, poverty incidence,\nradio/TV penetration, and state of structural and non-structural measures.\nVulnerability is defined as a weighted-sum of these components. A penalty was\nimposed for reduced vulnerability. Optimization comparison was done with\nMatLab's Genetic Algorithms and Simulated Annealing; results showed 'extreme'\nsolutions and realistic designs, for simulated annealing and genetic algorithm,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2013 22:59:01 GMT"}], "update_date": "2013-06-28", "authors_parsed": [["Bongolan", "Vena Pearl", ""], ["Ballesteros,", "Florencio C.", "Jr."], ["Banting", "Joyce Anne M.", ""], ["Olaes", "Aina Marie Q.", ""], ["Aquino", "Charlymagne R.", ""]]}, {"id": "1306.6489", "submitter": "Shofwatul Uyun Mrs", "authors": "Shofwatul 'Uyun, Imam Riadi", "title": "A Fuzzy Topsis Multiple-Attribute Decision Making for Scholarship\n  Selection", "comments": "10 pages, 5 figures, arXiv admin note: substantial text overlap with\n  arXiv:1306.5960", "journal-ref": "TELKOMNIKA Journal Vol.9 No.1 April 2011", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  As the education fees are becoming more expensive, more students apply for\nscholarships. Consequently, hundreds and even thousands of applications need to\nbe handled by the sponsor. To solve the problems, some alternatives based on\nseveral attributes (criteria) need to be selected. In order to make a decision\non such fuzzy problems, Fuzzy Multiple Attribute Decision Making (FMDAM) can be\napplied. In this study, Unified Modeling Language (UML) in FMADM with TOPSIS\nand Weighted Product (WP) methods is applied to select the candidates for\nacademic and non-academic scholarships at Universitas Islam Negeri Sunan\nKalijaga. Data used were a crisp and fuzzy data. The results show that TOPSIS\nand Weighted Product FMADM methods can be used to select the most suitable\ncandidates to receive the scholarships since the preference values applied in\nthis method can show applicants with the highest eligibility\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 13:11:41 GMT"}], "update_date": "2013-06-28", "authors_parsed": [["'Uyun", "Shofwatul", ""], ["Riadi", "Imam", ""]]}, {"id": "1306.6649", "submitter": "Jose Hernandez-Orallo", "authors": "Michel Halmes", "title": "Measurements of collective machine intelligence", "comments": "78 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent from the still ongoing research in measuring individual\nintelligence, we anticipate and provide a framework for measuring collective\nintelligence. Collective intelligence refers to the idea that several\nindividuals can collaborate in order to achieve high levels of intelligence. We\npresent thus some ideas on how the intelligence of a group can be measured and\nsimulate such tests. We will however focus here on groups of artificial\nintelligence agents (i.e., machines). We will explore how a group of agents is\nable to choose the appropriate problem and to specialize for a variety of\ntasks. This is a feature which is an important contributor to the increase of\nintelligence in a group (apart from the addition of more agents and the\nimprovement due to common decision making). Our results reveal some interesting\nresults about how (collective) intelligence can be modeled, about how\ncollective intelligence tests can be designed and about the underlying dynamics\nof collective intelligence. As it will be useful for our simulations, we\nprovide also some improvements of the threshold allocation model originally\nused in the area of swarm intelligence but further generalized here.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2013 20:10:45 GMT"}], "update_date": "2013-07-01", "authors_parsed": [["Halmes", "Michel", ""]]}, {"id": "1306.6709", "submitter": "Aur\\'elien Bellet", "authors": "Aur\\'elien Bellet, Amaury Habrard and Marc Sebban", "title": "A Survey on Metric Learning for Feature Vectors and Structured Data", "comments": "Technical report, 59 pages. Changes in v2: fixed typos and improved\n  presentation. Changes in v3: fixed typos. Changes in v4: fixed typos and new\n  methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for appropriate ways to measure the distance or similarity between\ndata is ubiquitous in machine learning, pattern recognition and data mining,\nbut handcrafting such good metrics for specific problems is generally\ndifficult. This has led to the emergence of metric learning, which aims at\nautomatically learning a metric from data and has attracted a lot of interest\nin machine learning and related fields for the past ten years. This survey\npaper proposes a systematic review of the metric learning literature,\nhighlighting the pros and cons of each approach. We pay particular attention to\nMahalanobis distance metric learning, a well-studied and successful framework,\nbut additionally present a wide range of methods that have recently emerged as\npowerful alternatives, including nonlinear metric learning, similarity learning\nand local metric learning. Recent trends and extensions, such as\nsemi-supervised metric learning, metric learning for histogram data and the\nderivation of generalization guarantees, are also covered. Finally, this survey\naddresses metric learning for structured data, in particular edit distance\nlearning, and attempts to give an overview of the remaining challenges in\nmetric learning for the years to come.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 03:56:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2013 04:48:05 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2013 21:28:07 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2014 07:45:11 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bellet", "Aur\u00e9lien", ""], ["Habrard", "Amaury", ""], ["Sebban", "Marc", ""]]}, {"id": "1306.6802", "submitter": "Aris Kosmopoulos", "authors": "Aris Kosmopoulos, Ioannis Partalas, Eric Gaussier, Georgios Paliouras,\n  Ion Androutsopoulos", "title": "Evaluation Measures for Hierarchical Classification: a unified view and\n  novel approaches", "comments": "Submitted to journal", "journal-ref": null, "doi": "10.1007/s10618-014-0382-x", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical classification addresses the problem of classifying items into a\nhierarchy of classes. An important issue in hierarchical classification is the\nevaluation of different classification algorithms, which is complicated by the\nhierarchical relations among the classes. Several evaluation measures have been\nproposed for hierarchical classification using the hierarchy in different ways.\nThis paper studies the problem of evaluation in hierarchical classification by\nanalyzing and abstracting the key components of the existing performance\nmeasures. It also proposes two alternative generic views of hierarchical\nevaluation and introduces two corresponding novel measures. The proposed\nmeasures, along with the state-of-the art ones, are empirically tested on three\nlarge datasets from the domain of text classification. The empirical results\nillustrate the undesirable behavior of existing approaches and how the proposed\nmethods overcome most of these methods across a range of cases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 11:49:53 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 17:33:58 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Kosmopoulos", "Aris", ""], ["Partalas", "Ioannis", ""], ["Gaussier", "Eric", ""], ["Paliouras", "Georgios", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1306.6843", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Error AMP Chain Graphs", "comments": "In Proceedings of the 12th Scandinavian Conference on Artificial\n  Intelligence (SCAI 2013), to appear. Changes from v1 to v2: Minor correction\n  in Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any regular Gaussian probability distribution that can be represented by an\nAMP chain graph (CG) can be expressed as a system of linear equations with\ncorrelated errors whose structure depends on the CG. However, the CG represents\nthe errors implicitly, as no nodes in the CG correspond to the errors. We\npropose in this paper to add some deterministic nodes to the CG in order to\nrepresent the errors explicitly. We call the result an EAMP CG. We will show\nthat, as desired, every AMP CG is Markov equivalent to its corresponding EAMP\nCG under marginalization of the error nodes. We will also show that every EAMP\nCG under marginalization of the error nodes is Markov equivalent to some LWF CG\nunder marginalization of the error nodes, and that the latter is Markov\nequivalent to some directed and acyclic graph (DAG) under marginalization of\nthe error nodes and conditioning on some selection nodes. This is important\nbecause it implies that the independence model represented by an AMP CG can be\naccounted for by some data generating process that is partially observed and\nhas selection bias. Finally, we will show that EAMP CGs are closed under\nmarginalization. This is a desirable feature because it guarantees parsimonious\nmodels under marginalization.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 13:55:04 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2013 21:37:21 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "1306.6852", "submitter": "Matteo Brunelli", "authors": "Matteo Brunelli and Michele Fedrizzi", "title": "Axiomatic properties of inconsistency indices for pairwise comparisons", "comments": "25 pages, 3 figures", "journal-ref": "Journal of the Operational Research Society, 66(1), 1-15, (2015)", "doi": "10.1057/jors.2013.135", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparisons are a well-known method for the representation of the\nsubjective preferences of a decision maker. Evaluating their inconsistency has\nbeen a widely studied and discussed topic and several indices have been\nproposed in the literature to perform this task. Since an acceptable level of\nconsistency is closely related with the reliability of preferences, a suitable\nchoice of an inconsistency index is a crucial phase in decision making\nprocesses. The use of different methods for measuring consistency must be\ncarefully evaluated, as it can affect the decision outcome in practical\napplications. In this paper, we present five axioms aimed at characterizing\ninconsistency indices. In addition, we prove that some of the indices proposed\nin the literature satisfy these axioms, while others do not, and therefore, in\nour view, they may fail to correctly evaluate inconsistency.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2013 14:27:03 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Brunelli", "Matteo", ""], ["Fedrizzi", "Michele", ""]]}]