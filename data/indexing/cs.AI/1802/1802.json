[{"id": "1802.00029", "submitter": "Mawulolo Ameko", "authors": "Mawulolo K. Ameko, Lihua Cai, Mehdi Boukhechba, Alexander Daros,\n  Philip I. Chow, Bethany A. Teachman, Matthew S. Gerber, Laura E. Barnes", "title": "Cluster-based Approach to Improve Affect Recognition from Passively\n  Sensed Data", "comments": "BHI2018", "journal-ref": null, "doi": "10.1109/BHI.2018.8333461", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative affect is a proxy for mental health in adults. By being able to\npredict participants' negative affect states unobtrusively, researchers and\nclinicians will be better positioned to deliver targeted, just-in-time mental\nhealth interventions via mobile applications. This work attempts to personalize\nthe passive recognition of negative affect states via group-based modeling of\nuser behavior patterns captured from mobility, communication, and activity\npatterns. Results show that group models outperform generalized models in a\ndataset based on two weeks of users' daily lives.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 19:26:27 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Ameko", "Mawulolo K.", ""], ["Cai", "Lihua", ""], ["Boukhechba", "Mehdi", ""], ["Daros", "Alexander", ""], ["Chow", "Philip I.", ""], ["Teachman", "Bethany A.", ""], ["Gerber", "Matthew S.", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1802.00033", "submitter": "Peter Sch\\\"uller", "authors": "Peter Sch\\\"uller", "title": "Technical Report: Adjudication of Coreference Annotations via Answer Set\n  Optimization", "comments": "3 tables, 10 figures, preliminary version presented at LPNMR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the first automatic approach for merging coreference annotations\nobtained from multiple annotators into a single gold standard. This merging is\nsubject to certain linguistic hard constraints and optimization criteria that\nprefer solutions with minimal divergence from annotators. The representation\ninvolves an equivalence relation over a large number of elements. We use Answer\nSet Programming to describe two representations of the problem and four\nobjective functions suitable for different datasets. We provide two\nstructurally different real-world benchmark datasets based on the METU-Sabanci\nTurkish Treebank and we report our experiences in using the Gringo, Clasp, and\nWasp tools for computing optimal adjudication results on these datasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 19:41:19 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Sch\u00fcller", "Peter", ""]]}, {"id": "1802.00048", "submitter": "Damien Anderson Mr", "authors": "Damien Anderson, Matthew Stephenson, Julian Togelius, Christian Salge,\n  John Levine and Jochen Renz", "title": "Deceptive Games", "comments": "16 pages, accepted at EvoStar2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deceptive games are games where the reward structure or other aspects of the\ngame are designed to lead the agent away from a globally optimal policy. While\nmany games are already deceptive to some extent, we designed a series of games\nin the Video Game Description Language (VGDL) implementing specific types of\ndeception, classified by the cognitive biases they exploit. VGDL games can be\nrun in the General Video Game Artificial Intelligence (GVGAI) Framework, making\nit possible to test a variety of existing AI agents that have been submitted to\nthe GVGAI Competition on these deceptive games. Our results show that all\ntested agents are vulnerable to several kinds of deception, but that different\nagents have different weaknesses. This suggests that we can use deception to\nunderstand the capabilities of a game-playing algorithm, and game-playing\nalgorithms to characterize the deception displayed by a game.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 20:06:05 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 23:12:14 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Anderson", "Damien", ""], ["Stephenson", "Matthew", ""], ["Togelius", "Julian", ""], ["Salge", "Christian", ""], ["Levine", "John", ""], ["Renz", "Jochen", ""]]}, {"id": "1802.00050", "submitter": "Lior Friedman Mr", "authors": "Lior Friedman and Shaul Markovitch", "title": "Recursive Feature Generation for Knowledge-based Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When humans perform inductive learning, they often enhance the process with\nbackground knowledge. With the increasing availability of well-formed\ncollaborative knowledge bases, the performance of learning algorithms could be\nsignificantly enhanced if a way were found to exploit these knowledge bases. In\nthis work, we present a novel algorithm for injecting external knowledge into\ninduction algorithms using feature generation. Given a feature, the algorithm\ndefines a new learning task over its set of values, and uses the knowledge base\nto solve the constructed learning task. The resulting classifier is then used\nas a new feature for the original problem. We have applied our algorithm to the\ndomain of text classification using large semantic knowledge bases. We have\nshown that the generated features significantly improve the performance of\nexisting learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 20:18:36 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Friedman", "Lior", ""], ["Markovitch", "Shaul", ""]]}, {"id": "1802.00209", "submitter": "Ahmed Osman", "authors": "Ahmed Osman and Wojciech Samek", "title": "Dual Recurrent Attention Units for Visual Question Answering", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question Answering (VQA) requires AI models to comprehend data in two\ndomains, vision and text. Current state-of-the-art models use learned attention\nmechanisms to extract relevant information from the input domains to answer a\ncertain question. Thus, robust attention mechanisms are essential for powerful\nVQA models. In this paper, we propose a recurrent attention mechanism and show\nits benefits compared to the traditional convolutional approach. We perform two\nablation studies to evaluate recurrent attention. First, we introduce a\nbaseline VQA model with visual attention and test the performance difference\nbetween convolutional and recurrent attention on the VQA 2.0 dataset. Secondly,\nwe design an architecture for VQA which utilizes dual (textual and visual)\nRecurrent Attention Units (RAUs). Using this model, we show the effect of all\npossible combinations of recurrent and convolutional dual attention. Our single\nmodel outperforms the first place winner on the VQA 2016 challenge and to the\nbest of our knowledge, it is the second best performing single model on the VQA\n1.0 dataset. Furthermore, our model noticeably improves upon the winner of the\nVQA 2017 challenge. Moreover, we experiment replacing attention mechanisms in\nstate-of-the-art models with our RAUs and show increased performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 09:35:33 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:27:26 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 13:41:21 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Osman", "Ahmed", ""], ["Samek", "Wojciech", ""]]}, {"id": "1802.00295", "submitter": "Gilles Falquet", "authors": "Sahar Aljalbout and Gilles Falquet", "title": "A Semantic Model for Historical Manuscripts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study and publication of historical scientific manuscripts are com- plex\ntasks that involve, among others, the explicit representation of the text mean-\nings and reasoning on temporal entities. In this paper we present the first\nresults of an interdisciplinary project dedicated to the study of Saussure's\nmanuscripts. These results aim to fulfill requirements elaborated with\nSaussurean humanists. They comprise a model for the representation of\ntime-varying statements and time-varying domain knowledge (in particular\nterminologies) as well as imple- mentation techniques for the semantic indexing\nof manuscripts and for temporal reasoning on knowledge extracted from the\nmanuscripts.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 12:47:25 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 07:30:17 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Aljalbout", "Sahar", ""], ["Falquet", "Gilles", ""]]}, {"id": "1802.00332", "submitter": "Jingchu Liu", "authors": "Jingchu Liu, Pengfei Hou, Lisen Mu, Yinan Yu, Chang Huang", "title": "Elements of Effective Deep Reinforcement Learning towards Tactical\n  Driving Decision Making", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactical driving decision making is crucial for autonomous driving systems\nand has attracted considerable interest in recent years. In this paper, we\npropose several practical components that can speed up deep reinforcement\nlearning algorithms towards tactical decision making tasks: 1) non-uniform\naction skipping as a more stable alternative to action-repetition frame\nskipping, 2) a counter-based penalty for lanes on which ego vehicle has less\nright-of-road, and 3) heuristic inference-time action masking for apparently\nundesirable actions. We evaluate the proposed components in a realistic driving\nsimulator and compare them with several baselines. Results show that the\nproposed scheme provides superior performance in terms of safety, efficiency,\nand comfort.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 15:13:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Liu", "Jingchu", ""], ["Hou", "Pengfei", ""], ["Mu", "Lisen", ""], ["Yu", "Yinan", ""], ["Huang", "Chang", ""]]}, {"id": "1802.00386", "submitter": "Leye Wang", "authors": "Leye Wang, Xu Geng, Xiaojuan Ma, Feng Liu, Qiang Yang", "title": "Cross-City Transfer Learning for Deep Spatio-Temporal Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal prediction is a key type of tasks in urban computing, e.g.,\ntraffic flow and air quality. Adequate data is usually a prerequisite,\nespecially when deep learning is adopted. However, the development levels of\ndifferent cities are unbalanced, and still many cities suffer from data\nscarcity. To address the problem, we propose a novel cross-city transfer\nlearning method for deep spatio-temporal prediction tasks, called RegionTrans.\nRegionTrans aims to effectively transfer knowledge from a data-rich source city\nto a data-scarce target city. More specifically, we first learn an inter-city\nregion matching function to match each target city region to a similar source\ncity region. A neural network is designed to effectively extract region-level\nrepresentation for spatio-temporal prediction. Finally, an optimization\nalgorithm is proposed to transfer learned features from the source city to the\ntarget city with the region matching function. Using citywide crowd flow\nprediction as a demonstration experiment, we verify the effectiveness of\nRegionTrans. Results show that RegionTrans can outperform the state-of-the-art\nfine-tuning deep spatio-temporal prediction models by reducing up to 10.7%\nprediction error.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 16:52:42 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 04:38:57 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Wang", "Leye", ""], ["Geng", "Xu", ""], ["Ma", "Xiaojuan", ""], ["Liu", "Feng", ""], ["Yang", "Qiang", ""]]}, {"id": "1802.00411", "submitter": "Bo Yang", "authors": "Bo Yang, Stefano Rosa, Andrew Markham, Niki Trigoni, Hongkai Wen", "title": "Dense 3D Object Reconstruction from a Single Depth View", "comments": "TPAMI 2018. Code and data are available at:\n  https://github.com/Yang7879/3D-RecGAN-extended. This article extends from\n  arXiv:1708.07969", "journal-ref": null, "doi": "10.1109/TPAMI.2018.2868195", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach, 3D-RecGAN++, which reconstructs\nthe complete 3D structure of a given object from a single arbitrary depth view\nusing generative adversarial networks. Unlike existing work which typically\nrequires multiple views of the same object or class labels to recover the full\n3D geometry, the proposed 3D-RecGAN++ only takes the voxel grid representation\nof a depth view of the object as input, and is able to generate the complete 3D\noccupancy grid with a high resolution of 256^3 by recovering the\noccluded/missing regions. The key idea is to combine the generative\ncapabilities of autoencoders and the conditional Generative Adversarial\nNetworks (GAN) framework, to infer accurate and fine-grained 3D structures of\nobjects in high-dimensional voxel space. Extensive experiments on large\nsynthetic datasets and real-world Kinect datasets show that the proposed\n3D-RecGAN++ significantly outperforms the state of the art in single view 3D\nobject reconstruction, and is able to reconstruct unseen types of objects.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 17:39:15 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 23:54:05 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Yang", "Bo", ""], ["Rosa", "Stefano", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""], ["Wen", "Hongkai", ""]]}, {"id": "1802.00420", "submitter": "Anish Athalye", "authors": "Anish Athalye, Nicholas Carlini, David Wagner", "title": "Obfuscated Gradients Give a False Sense of Security: Circumventing\n  Defenses to Adversarial Examples", "comments": "ICML 2018. Source code at\n  https://github.com/anishathalye/obfuscated-gradients", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\nthat leads to a false sense of security in defenses against adversarial\nexamples. While defenses that cause obfuscated gradients appear to defeat\niterative optimization-based attacks, we find defenses relying on this effect\ncan be circumvented. We describe characteristic behaviors of defenses\nexhibiting the effect, and for each of the three types of obfuscated gradients\nwe discover, we develop attack techniques to overcome it. In a case study,\nexamining non-certified white-box-secure defenses at ICLR 2018, we find\nobfuscated gradients are a common occurrence, with 7 of 9 defenses relying on\nobfuscated gradients. Our new attacks successfully circumvent 6 completely, and\n1 partially, in the original threat model each paper considers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 18:20:05 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 16:32:56 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 16:37:42 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 00:09:56 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Athalye", "Anish", ""], ["Carlini", "Nicholas", ""], ["Wagner", "David", ""]]}, {"id": "1802.00510", "submitter": "Asim Kadav", "authors": "Daniel Li, Asim Kadav", "title": "Adaptive Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Adaptive Memory Networks (AMN) that processes input-question pairs\nto dynamically construct a network architecture optimized for lower inference\ntimes for Question Answering (QA) tasks. AMN processes the input story to\nextract entities and stores them in memory banks. Starting from a single bank,\nas the number of input entities increases, AMN learns to create new banks as\nthe entropy in a single bank becomes too high. Hence, after processing an\ninput-question(s) pair, the resulting network represents a hierarchical\nstructure where entities are stored in different banks, distanced by question\nrelevance. At inference, one or few banks are used, creating a tradeoff between\naccuracy and performance. AMN is enabled by dynamic networks that allow input\ndependent network creation and efficiency in dynamic mini-batching as well as\nour novel bank controller that allows learning discrete decision making with\nhigh accuracy. In our results, we demonstrate that AMN learns to create\nvariable depth networks depending on task complexity and reduces inference\ntimes for QA tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 22:33:56 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Li", "Daniel", ""], ["Kadav", "Asim", ""]]}, {"id": "1802.00530", "submitter": "Phillip Alexander Jang", "authors": "Phillip A. Jang, Andrew E. Loeb, Matthew B. Davidow, Andrew Gordon\n  Wilson", "title": "Scalable L\\'evy Process Priors for Spectral Kernel Learning", "comments": "Appears in Advances in Neural Information Processing Systems 30\n  (NIPS), 2017", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are rich distributions over functions, with generalization\nproperties determined by a kernel function. When used for long-range\nextrapolation, predictions are particularly sensitive to the choice of kernel\nparameters. It is therefore critical to account for kernel uncertainty in our\npredictive distributions. We propose a distribution over kernels formed by\nmodelling a spectral mixture density with a L\\'evy process. The resulting\ndistribution has support for all stationary covariances--including the popular\nRBF, periodic, and Mat\\'ern kernels--combined with inductive biases which\nenable automatic and data efficient learning, long-range extrapolation, and\nstate of the art predictive performance. The proposed model also presents an\napproach to spectral regularization, as the L\\'evy process introduces a\nsparsity-inducing prior over mixture components, allowing automatic selection\nover model order and pruning of extraneous components. We exploit the algebraic\nstructure of the proposed process for $\\mathcal{O}(n)$ training and\n$\\mathcal{O}(1)$ predictions. We perform extrapolations having reasonable\nuncertainty estimates on several benchmarks, show that the proposed model can\nrecover flexible ground truth covariances and that it is robust to errors in\ninitialization.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 01:40:46 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Jang", "Phillip A.", ""], ["Loeb", "Andrew E.", ""], ["Davidow", "Matthew B.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1802.00541", "submitter": "Brian Ruttenberg", "authors": "Michael Harradon, Jeff Druce, Brian Ruttenberg", "title": "Causal Learning and Explanation of Deep Neural Networks via Autoencoded\n  Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are complex and opaque. As they enter application in a\nvariety of important and safety critical domains, users seek methods to explain\ntheir output predictions. We develop an approach to explaining deep neural\nnetworks by constructing causal models on salient concepts contained in a CNN.\nWe develop methods to extract salient concepts throughout a target network by\nusing autoencoders trained to extract human-understandable representations of\nnetwork activations. We then build a bayesian causal model using these\nextracted concepts as variables in order to explain image classification.\nFinally, we use this causal model to identify and visualize features with\nsignificant causal influence on final classification.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 02:24:24 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Harradon", "Michael", ""], ["Druce", "Jeff", ""], ["Ruttenberg", "Brian", ""]]}, {"id": "1802.00554", "submitter": "Andrew Lensen", "authors": "Andrew Lensen, Bing Xue, and Mengjie Zhang", "title": "Generating Redundant Features with Unsupervised Multi-Tree Genetic\n  Programming", "comments": "16 pages, preprint for EuroGP '18", "journal-ref": null, "doi": "10.1007/978-3-319-77553-1_6", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, feature selection has become an increasingly important area of\nresearch due to the surge in high-dimensional datasets in all areas of modern\nlife. A plethora of feature selection algorithms have been proposed, but it is\ndifficult to truly analyse the quality of a given algorithm. Ideally, an\nalgorithm would be evaluated by measuring how well it removes known bad\nfeatures. Acquiring datasets with such features is inherently difficult, and so\na common technique is to add synthetic bad features to an existing dataset.\nWhile adding noisy features is an easy task, it is very difficult to\nautomatically add complex, redundant features. This work proposes one of the\nfirst approaches to generating redundant features, using a novel genetic\nprogramming approach. Initial experiments show that our proposed method can\nautomatically create difficult, redundant features which have the potential to\nbe used for creating high-quality feature selection benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 04:19:04 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 06:35:56 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lensen", "Andrew", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1802.00560", "submitter": "Xuan Liu", "authors": "Xuan Liu, Xiaoguang Wang, Stan Matwin", "title": "Interpretable Deep Convolutional Neural Networks via Meta-learning", "comments": "9 pages, 9 figures, 2018 International Joint Conference on Neural\n  Networks, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability is a requirement in many applications in which crucial\ndecisions are made by users relying on a model's outputs. The recent movement\nfor \"algorithmic fairness\" also stipulates explainability, and therefore\ninterpretability of learning models. And yet the most successful contemporary\nMachine Learning approaches, the Deep Neural Networks, produce models that are\nhighly non-interpretable. We attempt to address this challenge by proposing a\ntechnique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN)\nvia meta-learning. In this work, we interpret a specific hidden layer of the\ndeep CNN model on the MNIST image dataset. We use a clustering algorithm in a\ntwo-level structure to find the meta-level training data and Random Forest as\nbase learning algorithms to generate the meta-level test data. The\ninterpretation results are displayed visually via diagrams, which clearly\nindicates how a specific test instance is classified. Our method achieves\nglobal interpretation for all the test instances without sacrificing the\naccuracy obtained by the original deep CNN model. This means our model is\nfaithful to the deep CNN model, which leads to reliable interpretations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 05:09:10 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 03:20:07 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Liu", "Xuan", ""], ["Wang", "Xiaoguang", ""], ["Matwin", "Stan", ""]]}, {"id": "1802.00682", "submitter": "Finale Doshi-Velez", "authors": "Menaka Narayanan, Emily Chen, Jeffrey He, Been Kim, Sam Gershman,\n  Finale Doshi-Velez", "title": "How do Humans Understand Explanations from Machine Learning Systems? An\n  Evaluation of the Human-Interpretability of Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a boom in interest in machine learning systems that\ncan provide a human-understandable rationale for their predictions or\ndecisions. However, exactly what kinds of explanation are truly\nhuman-interpretable remains poorly understood. This work advances our\nunderstanding of what makes explanations interpretable in the specific context\nof verification. Suppose we have a machine learning system that predicts X, and\nwe provide rationale for this prediction X. Given an input, an explanation, and\nan output, is the output consistent with the input and the supposed rationale?\nVia a series of user-studies, we identify what kinds of increases in complexity\nhave the greatest effect on the time it takes for humans to verify the\nrationale, and which seem relatively insensitive.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 13:53:13 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Narayanan", "Menaka", ""], ["Chen", "Emily", ""], ["He", "Jeffrey", ""], ["Kim", "Been", ""], ["Gershman", "Sam", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1802.00690", "submitter": "Peter Bruza", "authors": "Peter D. Bruza", "title": "Modelling contextuality by probabilistic programs with hypergraph\n  semantics", "comments": "Accepted for \"Theoretical Computer Science\"", "journal-ref": null, "doi": "10.1016/j.tcs.2017.11.028", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of a phenomenon are often developed by examining it under different\nexperimental conditions, or measurement contexts. The resultant probabilistic\nmodels assume that the underlying random variables, which define a measurable\nset of outcomes, can be defined independent of the measurement context. The\nphenomenon is deemed contextual when this assumption fails. Contextuality is an\nimportant issue in quantum physics. However, there has been growing speculation\nthat it manifests outside the quantum realm with human cognition being a\nparticularly prominent area of investigation. This article contributes the\nfoundations of a probabilistic programming language that allows convenient\nexploration of contextuality in wide range of applications relevant to\ncognitive science and artificial intelligence. Specific syntax is proposed to\nallow the specification of \"measurement contexts\". Each such context delivers a\npartial model of the phenomenon based on the associated experimental condition\ndescribed by the measurement context. The probabilistic program is translated\ninto a hypergraph in a modular way. Recent theoretical results from the field\nof quantum physics show that contextuality can be equated with the possibility\nof constructing a probabilistic model on the resulting hypergraph. The use of\nhypergraphs opens the door for a theoretically succinct and efficient\ncomputational semantics sensitive to modelling both contextual and\nnon-contextual phenomena. Finally, this article raises awareness of\ncontextuality beyond quantum physics and to contribute formal methods to detect\nits presence by means of hypergraph semantics.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 22:19:41 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Bruza", "Peter D.", ""]]}, {"id": "1802.00748", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio", "title": "Short-term Memory of Deep RNN", "comments": "This is a pre-print (pre-review) version of the paper accepted for\n  presentation at the 26th European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN), Bruges (Belgium),\n  25-27 April 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of deep learning towards temporal data processing is gaining an\nincreasing research interest. In this paper we investigate the properties of\nstate dynamics developed in successive levels of deep recurrent neural networks\n(RNNs) in terms of short-term memory abilities. Our results reveal interesting\ninsights that shed light on the nature of layering as a factor of RNN design.\nNoticeably, higher layers in a hierarchically organized RNN architecture\nresults to be inherently biased towards longer memory spans even prior to\ntraining of the recurrent connections. Moreover, in the context of Reservoir\nComputing framework, our analysis also points out the benefit of a layered\nrecurrent organization as an efficient approach to improve the memory skills of\nreservoir models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 16:14:59 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Gallicchio", "Claudio", ""]]}, {"id": "1802.00844", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Intriguing Properties of Randomly Weighted Networks: Generalizing While\n  Learning Next to Nothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks results in strong learned representations that\nshow good generalization capabilities. In most cases, training involves\niterative modification of all weights inside the network via back-propagation.\nIn Extreme Learning Machines, it has been suggested to set the first layer of a\nnetwork to fixed random values instead of learning it. In this paper, we\npropose to take this approach a step further and fix almost all layers of a\ndeep convolutional neural network, allowing only a small portion of the weights\nto be learned. As our experiments show, fixing even the majority of the\nparameters of the network often results in performance which is on par with the\nperformance of learning all of them. The implications of this intriguing\nproperty of deep neural networks are discussed and we suggest ways to harness\nit to create more robust representations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 20:53:31 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.00864", "submitter": "Fatima Zohra Smaili", "authors": "Fatima Zohra Smaili, Xin Gao, and Robert Hoehndorf", "title": "Onto2Vec: joint vector-based representation of biological entities and\n  their ontology-based annotations", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/bty259", "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the Onto2Vec method, an approach to learn feature vectors for\nbiological entities based on their annotations to biomedical ontologies. Our\nmethod can be applied to a wide range of bioinformatics research problems such\nas similarity-based prediction of interactions between proteins, classification\nof interaction types using supervised learning, or clustering.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 08:23:45 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Smaili", "Fatima Zohra", ""], ["Gao", "Xin", ""], ["Hoehndorf", "Robert", ""]]}, {"id": "1802.00923", "submitter": "Paul Pu Liang", "authors": "Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria,\n  Louis-Philippe Morency", "title": "Multi-attention Recurrent Network for Human Communication Comprehension", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human face-to-face communication is a complex multimodal signal. We use words\n(language modality), gestures (vision modality) and changes in tone (acoustic\nmodality) to convey our intentions. Humans easily process and understand\nface-to-face communication, however, comprehending this form of communication\nremains a significant challenge for Artificial Intelligence (AI). AI must\nunderstand each modality and the interactions between them that shape human\ncommunication. In this paper, we present a novel neural architecture for\nunderstanding human communication called the Multi-attention Recurrent Network\n(MARN). The main strength of our model comes from discovering interactions\nbetween modalities through time using a neural component called the\nMulti-attention Block (MAB) and storing them in the hybrid memory of a\nrecurrent component called the Long-short Term Hybrid Memory (LSTHM). We\nperform extensive comparisons on six publicly available datasets for multimodal\nsentiment analysis, speaker trait recognition and emotion recognition. MARN\nshows state-of-the-art performance on all the datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:29:17 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zadeh", "Amir", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Vij", "Prateek", ""], ["Cambria", "Erik", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00924", "submitter": "Paul Pu Liang", "authors": "Minghai Chen, Sen Wang, Paul Pu Liang, Tadas Baltru\\v{s}aitis, Amir\n  Zadeh, Louis-Philippe Morency", "title": "Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n  Learning", "comments": "ICMI 2017 Oral Presentation, Honorable Mention Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of video sharing websites such as YouTube and\nFacebook, multimodal sentiment analysis has received increasing attention from\nthe scientific community. Contrary to previous works in multimodal sentiment\nanalysis which focus on holistic information in speech segments such as bag of\nwords representations and average facial expression intensity, we develop a\nnovel deep architecture for multimodal sentiment analysis that performs\nmodality fusion at the word level. In this paper, we propose the Gated\nMultimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\ncomposed of 2 modules. The Gated Multimodal Embedding alleviates the\ndifficulties of fusion when there are noisy modalities. The LSTM with Temporal\nAttention performs word level fusion at a finer fusion resolution between input\nmodalities and attends to the most important time steps. As a result, the\nGME-LSTM(A) is able to better model the multimodal structure of speech through\ntime and perform better sentiment comprehension. We demonstrate the\neffectiveness of this approach on the publicly-available Multimodal Corpus of\nSentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\nstate-of-the-art sentiment classification and regression results. Qualitative\nanalysis on our model emphasizes the importance of the Temporal Attention Layer\nin sentiment prediction because the additional acoustic and visual modalities\nare noisy. We also demonstrate the effectiveness of the Gated Multimodal\nEmbedding in selectively filtering these noisy modalities out. Our results and\nanalysis open new areas in the study of sentiment analysis in human\ncommunication and provide new models for multimodal fusion.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:30:09 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chen", "Minghai", ""], ["Wang", "Sen", ""], ["Liang", "Paul Pu", ""], ["Baltru\u0161aitis", "Tadas", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00927", "submitter": "Paul Pu Liang", "authors": "Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik\n  Cambria, Louis-Philippe Morency", "title": "Memory Fusion Network for Multi-view Sequential Learning", "comments": "AAAI 2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view sequential learning is a fundamental problem in machine learning\ndealing with multi-view sequences. In a multi-view sequence, there exists two\nforms of interactions between different views: view-specific interactions and\ncross-view interactions. In this paper, we present a new neural architecture\nfor multi-view sequential learning called the Memory Fusion Network (MFN) that\nexplicitly accounts for both interactions in a neural architecture and\ncontinuously models them through time. The first component of the MFN is called\nthe System of LSTMs, where view-specific interactions are learned in isolation\nthrough assigning an LSTM function to each view. The cross-view interactions\nare then identified using a special attention mechanism called the Delta-memory\nAttention Network (DMAN) and summarized through time with a Multi-view Gated\nMemory. Through extensive experimentation, MFN is compared to various proposed\napproaches for multi-view sequential learning on multiple publicly available\nbenchmark datasets. MFN outperforms all the existing multi-view approaches.\nFurthermore, MFN outperforms all current state-of-the-art models, setting new\nstate-of-the-art results for these multi-view datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 06:37:46 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zadeh", "Amir", ""], ["Liang", "Paul Pu", ""], ["Mazumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1802.00934", "submitter": "Mohammad Asif Khan", "authors": "Agustinus Kristiadi, Mohammad Asif Khan, Denis Lukovnikov, Jens\n  Lehmann, Asja Fischer", "title": "Incorporating Literals into Knowledge Graph Embeddings", "comments": "9 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs, on top of entities and their relationships, contain other\nimportant elements: literals. Literals encode interesting properties (e.g. the\nheight) of entities that are not captured by links between entities alone. Most\nof the existing work on embedding (or latent feature) based knowledge graph\nanalysis focuses mainly on the relations between entities. In this work, we\nstudy the effect of incorporating literal information into existing link\nprediction methods. Our approach, which we name LiteralE, is an extension that\ncan be plugged into existing latent feature methods. LiteralE merges entity\nembeddings with their literal information using a learnable, parametrized\nfunction, such as a simple linear or nonlinear transformation, or a multilayer\nneural network. We extend several popular embedding models based on LiteralE\nand evaluate their performance on the task of link prediction. Despite its\nsimplicity, LiteralE proves to be an effective way to incorporate literal\ninformation into existing embedding based methods, improving their performance\non different standard datasets, which we augmented with their literals and\nprovide as testbed for further research.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 08:16:31 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 10:11:23 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2019 14:39:54 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["Khan", "Mohammad Asif", ""], ["Lukovnikov", "Denis", ""], ["Lehmann", "Jens", ""], ["Fischer", "Asja", ""]]}, {"id": "1802.00977", "submitter": "Cewu Lu", "authors": "Yuliang Xiu, Jiefeng Li, Haoyu Wang, Yinghong Fang, Cewu Lu", "title": "Pose Flow: Efficient Online Pose Tracking", "comments": "Our source codes and models are made publicly available at\n  https://github.com/YuliangXiu/PoseFlow and\n  https://github.com/MVIG-SJTU/AlphaPose", "journal-ref": "British Machine Vision Conference (BMVC), 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-person articulated pose tracking in unconstrained videos is an\nimportant while challenging problem. In this paper, going along the road of\ntop-down approaches, we propose a decent and efficient pose tracker based on\npose flows. First, we design an online optimization framework to build the\nassociation of cross-frame poses and form pose flows (PF-Builder). Second, a\nnovel pose flow non-maximum suppression (PF-NMS) is designed to robustly reduce\nredundant pose flows and re-link temporal disjoint ones. Extensive experiments\nshow that our method significantly outperforms best-reported results on two\nstandard Pose Tracking datasets by 13 mAP 25 MOTA and 6 mAP 3 MOTA\nrespectively. Moreover, in the case of working on detected poses in individual\nframes, the extra computation of pose tracker is very minor, guaranteeing\nonline 10FPS tracking. Our source codes are made publicly\navailable(https://github.com/YuliangXiu/PoseFlow).\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:08:36 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 18:40:46 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Xiu", "Yuliang", ""], ["Li", "Jiefeng", ""], ["Wang", "Haoyu", ""], ["Fang", "Yinghong", ""], ["Lu", "Cewu", ""]]}, {"id": "1802.00981", "submitter": "Baihan Lin", "authors": "Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi, Irina Rish", "title": "Contextual Bandit with Adaptive Feature Extraction", "comments": "IEEE ICDMW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online decision making setting known as contextual bandit\nproblem, and propose an approach for improving contextual bandit performance by\nusing an adaptive feature extraction (representation learning) based on online\nclustering. Our approach starts with an off-line pre-training on unlabeled\nhistory of contexts (which can be exploited by our approach, but not by the\nstandard contextual bandit), followed by an online selection and adaptation of\nencoders. Specifically, given an input sample (context), the proposed approach\nselects the most appropriate encoding function to extract a feature vector\nwhich becomes an input for a contextual bandit, and updates both the bandit and\nthe encoding function based on the context and on the feedback (reward). Our\nexperiments on a variety of datasets, and both in stationary and non-stationary\nenvironments of several kinds demonstrate clear advantages of the proposed\nadaptive representation learning over the standard contextual bandit based on\n\"raw\" input contexts.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 14:44:51 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 19:30:15 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 01:28:57 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 15:32:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lin", "Baihan", ""], ["Bouneffouf", "Djallel", ""], ["Cecchi", "Guillermo", ""], ["Rish", "Irina", ""]]}, {"id": "1802.01013", "submitter": "Sarath Sreedharan", "authors": "Tathagata Chakraborti, Sarath Sreedharan, Sachin Grover, Subbarao\n  Kambhampati", "title": "Plan Explanations as Model Reconciliation -- An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in explanation generation for decision making agents has looked\nat how unexplained behavior of autonomous systems can be understood in terms of\ndifferences in the model of the system and the human's understanding of the\nsame, and how the explanation process as a result of this mismatch can be then\nseen as a process of reconciliation of these models. Existing algorithms in\nsuch settings, while having been built on contrastive, selective and social\nproperties of explanations as studied extensively in the psychology literature,\nhave not, to the best of our knowledge, been evaluated in settings with actual\nhumans in the loop. As such, the applicability of such explanations to human-AI\nand human-robot interactions remains suspect. In this paper, we set out to\nevaluate these explanation generation algorithms in a series of studies in a\nmock search and rescue scenario with an internal semi-autonomous robot and an\nexternal human commander. We demonstrate to what extent the properties of these\nalgorithms hold as they are evaluated by humans, and how the dynamics of trust\nbetween the human and the robot evolve during the process of these\ninteractions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 19:17:58 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Sreedharan", "Sarath", ""], ["Grover", "Sachin", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1802.01096", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Carlos Lucena, Paulo Alencar and Donald Cowan", "title": "Software Engineers vs. Machine Learning Algorithms: An Empirical Study\n  Assessing Performance and Reuse Tasks", "comments": "22 pages. To be submitted to IEEE Transactions on Software\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several papers have recently contained reports on applying machine learning\n(ML) to the automation of software engineering (SE) tasks, such as project\nmanagement, modeling and development. However, there appear to be no approaches\ncomparing how software engineers fare against machine-learning algorithms as\napplied to specific software development tasks. Such a comparison is essential\nto gain insight into which tasks are better performed by humans and which by\nmachine learning and how cooperative work or human-in-the-loop processes can be\nimplemented more effectively. In this paper, we present an empirical study that\ncompares how software engineers and machine-learning algorithms perform and\nreuse tasks. The empirical study involves the synthesis of the control\nstructure of an autonomous streetlight application. Our approach consists of\nfour steps. First, we solved the problem using machine learning to determine\nspecific performance and reuse tasks. Second, we asked software engineers with\ndifferent domain knowledge levels to provide a solution to the same tasks.\nThird, we compared how software engineers fare against machine-learning\nalgorithms when accomplishing the performance and reuse tasks based on criteria\nsuch as energy consumption and safety. Finally, we analyzed the results to\nunderstand which tasks are better performed by either humans or algorithms so\nthat they can work together more effectively. Such an understanding and the\nresulting human-in-the-loop approaches, which take into account the strengths\nand weaknesses of humans and machine-learning algorithms, are fundamental not\nonly to provide a basis for cooperative work in support of software\nengineering, but also, in other areas.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 09:38:48 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 21:32:02 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Lucena", "Carlos", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""]]}, {"id": "1802.01173", "submitter": "Zhi-Hua Zhou", "authors": "Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, Zhi-Hua Zhou", "title": "Tunneling Neural Perception and Logic Reasoning through Abductive\n  Learning", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception and reasoning are basic human abilities that are seamlessly\nconnected as part of human intelligence. However, in current machine learning\nsystems, the perception and reasoning modules are incompatible. Tasks requiring\njoint perception and reasoning ability are difficult to accomplish autonomously\nand still demand human intervention. Inspired by the way language experts\ndecoded Mayan scripts by joining two abilities in an abductive manner, this\npaper proposes the abductive learning framework. The framework learns\nperception and reasoning simultaneously with the help of a trial-and-error\nabductive process. We present the Neural-Logical Machine as an implementation\nof this novel learning framework. We demonstrate that--using human-like\nabductive learning--the machine learns from a small set of simple hand-written\nequations and then generalizes well to complex equations, a feat that is beyond\nthe capability of state-of-the-art neural network models. The abductive\nlearning framework explores a new direction for approaching human-level\nlearning ability.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 18:27:53 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 12:34:01 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Dai", "Wang-Zhou", ""], ["Xu", "Qiu-Ling", ""], ["Yu", "Yang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1802.01177", "submitter": "Jochen Burghardt", "authors": "Jochen Burghardt", "title": "A Scheme-Driven Approach to Learning Programs from Input/Output\n  Equations", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an approach to learn, in a term-rewriting setting, function\ndefinitions from input/output equations. By confining ourselves to structurally\nrecursive definitions we obtain a fairly fast learning algorithm that often\nyields definitions close to intuitive expectations. We provide a Prolog\nprototype implementation of our approach, and indicate open issues of further\ninvestigation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 19:17:57 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Burghardt", "Jochen", ""]]}, {"id": "1802.01186", "submitter": "Oggi Rudovic", "authors": "Ognjen Rudovic, Jaeryoung Lee, Miles Dai, Bjorn Schuller and Rosalind\n  Picard", "title": "Personalized Machine Learning for Robot Perception of Affect and\n  Engagement in Autism Therapy", "comments": "The paper has undergone a major revision and its content is outdated", "journal-ref": null, "doi": "10.1126/scirobotics.aao6760", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots have great potential to facilitate future therapies for children on\nthe autism spectrum. However, existing robots lack the ability to automatically\nperceive and respond to human affect, which is necessary for establishing and\nmaintaining engaging interactions. Moreover, their inference challenge is made\nharder by the fact that many individuals with autism have atypical and\nunusually diverse styles of expressing their affective-cognitive states. To\ntackle the heterogeneity in behavioral cues of children with autism, we use the\nlatest advances in deep learning to formulate a personalized machine learning\n(ML) framework for automatic perception of the childrens affective states and\nengagement during robot-assisted autism therapy. The key to our approach is a\nnovel shift from the traditional ML paradigm - instead of using\n'one-size-fits-all' ML models, our personalized ML framework is optimized for\neach child by leveraging relevant contextual information (demographics and\nbehavioral assessment scores) and individual characteristics of each child. We\ndesigned and evaluated this framework using a dataset of multi-modal audio,\nvideo and autonomic physiology data of 35 children with autism (age 3-13) and\nfrom 2 cultures (Asia and Europe), participating in a 25-minute child-robot\ninteraction (~500k datapoints). Our experiments confirm the feasibility of the\nrobot perception of affect and engagement, showing clear improvements due to\nthe model personalization. The proposed approach has potential to improve\nexisting therapies for autism by offering more efficient monitoring and\nsummarization of the therapy progress.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 20:05:26 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 01:21:12 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Lee", "Jaeryoung", ""], ["Dai", "Miles", ""], ["Schuller", "Bjorn", ""], ["Picard", "Rosalind", ""]]}, {"id": "1802.01239", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, Kun Zhang", "title": "Counting and Sampling from Markov Equivalent DAGs Using Clique Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A directed acyclic graph (DAG) is the most common graphical model for\nrepresenting causal relationships among a set of variables. When restricted to\nusing only observational data, the structure of the ground truth DAG is\nidentifiable only up to Markov equivalence, based on conditional independence\nrelations among the variables. Therefore, the number of DAGs equivalent to the\nground truth DAG is an indicator of the causal complexity of the underlying\nstructure--roughly speaking, it shows how many interventions or how much\nadditional information is further needed to recover the underlying DAG. In this\npaper, we propose a new technique for counting the number of DAGs in a Markov\nequivalence class. Our approach is based on the clique tree representation of\nchordal graphs. We show that in the case of bounded degree graphs, the proposed\nalgorithm is polynomial time. We further demonstrate that this technique can be\nutilized for uniform sampling from a Markov equivalence class, which provides a\nstochastic way to enumerate DAGs in the equivalence class and may be needed for\nfinding the best DAG or for causal inference given the equivalence class as\ninput. We also extend our counting and sampling method to the case where prior\nknowledge about the underlying DAG is available, and present applications of\nthis extension in causal experiment design and estimating the causal effect of\njoint interventions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 02:32:05 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 01:49:04 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Salehkaleybar", "Saber", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1802.01274", "submitter": "Emily Spratt L", "authors": "Emily L. Spratt", "title": "Dream Formulations and Deep Neural Networks: Humanistic Themes in the\n  Iconology of the Machine-Learned Image", "comments": "29 pages, 8 Figures, This paper was originally presented as Dream\n  Formulations and Image Recognition: Algorithms for the Study of Renaissance\n  Art, at Critical Approaches to Digital Art History, The Villa I Tatti, The\n  Harvard University Center for Italian Renaissance Studies and The Newberry\n  Center for Renaissance Studies, Renaissance Society of America Annual\n  Meeting, Chicago, 31 March 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the interpretability of deep learning-enabled image\nrecognition processes in computer vision science in relation to theories in art\nhistory and cognitive psychology on the vision-related perceptual capabilities\nof humans. Examination of what is determinable about the machine-learned image\nin comparison to humanistic theories of visual perception, particularly in\nregard to art historian Erwin Panofsky's methodology for image analysis and\npsychologist Eleanor Rosch's theory of graded categorization according to\nprototypes, finds that there are surprising similarities between the two that\nsuggest that researchers in the arts and the sciences would have much to\nbenefit from closer collaborations. Utilizing the examples of Google's\nDeepDream and the Machine Learning and Perception Lab at Georgia Tech's\nGrad-CAM: Gradient-weighted Class Activation Mapping programs, this study\nsuggests that a revival of art historical research in iconography and formalism\nin the age of AI is essential for shaping the future navigation and\ninterpretation of all machine-learned images, given the rapid developments in\nimage recognition technologies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 05:57:40 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Spratt", "Emily L.", ""]]}, {"id": "1802.01282", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Benjamin Van Roy", "title": "Coordinated Exploration in Concurrent Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, volume 80 of Proceedings of Machine Learning Research, pages\n  1271-1279, Stockholmsm\\\"assan, Stockholm Sweden, 10-15 Jul 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a team of reinforcement learning agents that concurrently learn\nto operate in a common environment. We identify three properties - adaptivity,\ncommitment, and diversity - which are necessary for efficient coordinated\nexploration and demonstrate that straightforward extensions to single-agent\noptimistic and posterior sampling approaches fail to satisfy them. As an\nalternative, we propose seed sampling, which extends posterior sampling in a\nmanner that meets these requirements. Simulation results investigate how\nper-agent regret decreases as the number of agents grows, establishing\nsubstantial advantages of seed sampling over alternative exploration schemes.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 06:51:12 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1802.01433", "submitter": "Haonan Yu", "authors": "Haonan Yu, Haichao Zhang, Wei Xu", "title": "Interactive Grounded Language Acquisition and Generalization in a 2D\n  World", "comments": "ICLR 2018 (Figure 6 caption improved)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build a virtual agent for learning language in a 2D maze-like world. The\nagent sees images of the surrounding environment, listens to a virtual teacher,\nand takes actions to receive rewards. It interactively learns the teacher's\nlanguage from scratch based on two language use cases: sentence-directed\nnavigation and question answering. It learns simultaneously the visual\nrepresentations of the world, the language, and the action control. By\ndisentangling language grounding from other computational routines and sharing\na concept detection function between language grounding and prediction, the\nagent reliably interpolates and extrapolates to interpret sentences that\ncontain new word combinations or new words missing from training sentences. The\nnew words are transferred from the answers of language prediction. Such a\nlanguage ability is trained and evaluated on a population of over 1.6 million\ndistinct sentences consisting of 119 object words, 8 color words, 9\nspatial-relation words, and 50 grammatical words. The proposed model\nsignificantly outperforms five comparison methods for interpreting zero-shot\nsentences. In addition, we demonstrate human-interpretable intermediate outputs\nof the model in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:35:46 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 22:03:27 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 19:36:51 GMT"}, {"version": "v4", "created": "Mon, 13 Aug 2018 23:29:31 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Yu", "Haonan", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1802.01435", "submitter": "Joshua Chacksfield", "authors": "Alexey Chaplygin and Joshua Chacksfield", "title": "A Method for Restoring the Training Set Distribution in an Image\n  Classifier", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks are a well-known staple of modern image\nclassification. However, it can be difficult to assess the quality and\nrobustness of such models. Deep models are known to perform well on a given\ntraining and estimation set, but can easily be fooled by data that is\nspecifically generated for the purpose. It has been shown that one can produce\nan artificial example that does not represent the desired class, but activates\nthe network in the desired way. This paper describes a new way of\nreconstructing a sample from the training set distribution of an image\nclassifier without deep knowledge about the underlying distribution. This\nenables access to the elements of images that most influence the decision of a\nconvolutional network and to extract meaningful information about the training\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 14:49:06 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Chaplygin", "Alexey", ""], ["Chacksfield", "Joshua", ""]]}, {"id": "1802.01451", "submitter": "Filip Klubicka", "authors": "Filip Klubi\\v{c}ka, Antonio Toral, V\\'ictor M. S\\'anchez-Cartagena", "title": "Quantitative Fine-Grained Human Evaluation of Machine Translation\n  Systems: a Case Study on English to Croatian", "comments": "22 pages, 2 figures, 9 tables, 1 equation. This is a\n  post-peer-review, pre-copyedit version of an article published in Machine\n  Translation Journal. The final authenticated version will be available online\n  at the journal page. arXiv admin note: substantial text overlap with\n  arXiv:1706.04389", "journal-ref": "Machine Translation, pp 1-21, (2018), http://rdcu.be/GIkb", "doi": "10.1007/s10590-018-9214-x", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a quantitative fine-grained manual evaluation approach to\ncomparing the performance of different machine translation (MT) systems. We\nbuild upon the well-established Multidimensional Quality Metrics (MQM) error\ntaxonomy and implement a novel method that assesses whether the differences in\nperformance for MQM error types between different MT systems are statistically\nsignificant. We conduct a case study for English-to-Croatian, a language\ndirection that involves translating into a morphologically rich language, for\nwhich we compare three MT systems belonging to different paradigms: pure\nphrase-based, factored phrase-based and neural. First, we design an\nMQM-compliant error taxonomy tailored to the relevant linguistic phenomena of\nSlavic languages, which made the annotation process feasible and accurate.\nErrors in MT outputs were then annotated by two annotators following this\ntaxonomy. Subsequently, we carried out a statistical analysis which showed that\nthe best-performing system (neural) reduces the errors produced by the worst\nsystem (pure phrase-based) by more than half (54\\%). Moreover, we conducted an\nadditional analysis of agreement errors in which we distinguished between short\n(phrase-level) and long distance (sentence-level) errors. We discovered that\nphrase-based MT approaches are of limited use for long distance agreement\nphenomena, for which neural MT was found to be especially effective.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 14:41:08 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Toral", "Antonio", ""], ["S\u00e1nchez-Cartagena", "V\u00edctor M.", ""]]}, {"id": "1802.01482", "submitter": "Jo\\~ao Pedro Pedroso", "authors": "Jo\\~ao Pedro Pedroso, Alpar Vajk Kramer, Ke Zhang", "title": "The Sea Exploration Problem: Data-driven Orienteering on a Continuous\n  Surface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a problem arising in sea exploration, where the aim is\nto schedule the expedition of a ship for collecting information about the\nresources on the seafloor. The aim is to collect data by probing on a set of\ncarefully chosen locations, so that the information available is optimally\nenriched. This problem has similarities with the orienteering problem, where\nthe aim is to plan a time-limited trip for visiting a set of vertices,\ncollecting a prize at each of them, in such a way that the total value\ncollected is maximum. In our problem, the score at each vertex is associated\nwith an estimation of the level of the resource on the given surface, which is\ndone by regression using Gaussian processes. Hence, there is a correlation\namong scores on the selected vertices; this is a first difference with respect\nto the standard orienteering problem. The second difference is the location of\neach vertex, which in our problem is a freely chosen point on a given surface.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 15:57:15 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 05:24:48 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Pedroso", "Jo\u00e3o Pedro", ""], ["Kramer", "Alpar Vajk", ""], ["Zhang", "Ke", ""]]}, {"id": "1802.01518", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Matthew S. Emigh and Jose C. Principe", "title": "Guided Policy Exploration for Markov Decision Processes using an\n  Uncertainty-Based Value-of-Information Criterion", "comments": "IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2812709", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning in environments with many action-state pairs is\nchallenging. At issue is the number of episodes needed to thoroughly search the\npolicy space. Most conventional heuristics address this search problem in a\nstochastic manner. This can leave large portions of the policy space unvisited\nduring the early training stages. In this paper, we propose an\nuncertainty-based, information-theoretic approach for performing guided\nstochastic searches that more effectively cover the policy space. Our approach\nis based on the value of information, a criterion that provides the optimal\ntrade-off between expected costs and the granularity of the search process. The\nvalue of information yields a stochastic routine for choosing actions during\nlearning that can explore the policy space in a coarse to fine manner. We\naugment this criterion with a state-transition uncertainty factor, which guides\nthe search process into previously unexplored regions of the policy space.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:24:13 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Emigh", "Matthew S.", ""], ["Principe", "Jose C.", ""]]}, {"id": "1802.01526", "submitter": "Ryuta Arisaka", "authors": "Ryuta Arisaka, Jeremie Dauphin", "title": "Abstractly Interpreting Argumentation Frameworks for Sharpening\n  Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cycles of attacking arguments pose non-trivial issues in Dung style\nargumentation theory, apparent behavioural difference between odd and even\nlength cycles being a notable one. While a few methods were proposed for\ntreating them, to - in particular - enable selection of acceptable arguments in\nan odd-length cycle when Dung semantics could select none, so far the issues\nhave been observed from a purely argument-graph-theoretic perspective. Per\ncontra, we consider argument graphs together with a certain lattice like\nsemantic structure over arguments e.g. ontology. As we show, the\nsemantic-argumentgraphic hybrid theory allows us to apply abstract\ninterpretation, a widely known methodology in static program analysis, to\nformal argumentation. With this, even where no arguments in a cycle could be\nselected sensibly, we could say more about arguments acceptability of an\nargument framework that contains it. In a certain sense, we can verify Dung\nextensions with respect to a semantic structure in this hybrid theory, to\nconsolidate our confidence in their suitability. By defining the theory, and by\nmaking comparisons to existing approaches, we ultimately discover that whether\nDung semantics, or an alternative semantics such as cf2, is adequate or\nproblematic depends not just on an argument graph but also on the semantic\nrelation among the arguments in the graph.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 17:36:40 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Arisaka", "Ryuta", ""], ["Dauphin", "Jeremie", ""]]}, {"id": "1802.01548", "submitter": "Esteban Real", "authors": "Esteban Real, Alok Aggarwal, Yanping Huang and Quoc V Le", "title": "Regularized Evolution for Image Classifier Architecture Search", "comments": "Accepted for publication at AAAI 2019, the Thirty-Third AAAI\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effort devoted to hand-crafting neural network image classifiers has\nmotivated the use of architecture search to discover them automatically.\nAlthough evolutionary algorithms have been repeatedly applied to neural network\ntopologies, the image classifiers thus discovered have remained inferior to\nhuman-crafted ones. Here, we evolve an image classifier---AmoebaNet-A---that\nsurpasses hand-designs for the first time. To do this, we modify the tournament\nselection evolutionary algorithm by introducing an age property to favor the\nyounger genotypes. Matching size, AmoebaNet-A has comparable accuracy to\ncurrent state-of-the-art ImageNet models discovered with more complex\narchitecture-search methods. Scaled to larger size, AmoebaNet-A sets a new\nstate-of-the-art 83.9% / 96.6% top-5 ImageNet accuracy. In a controlled\ncomparison against a well known reinforcement learning algorithm, we give\nevidence that evolution can obtain results faster with the same hardware,\nespecially at the earlier stages of the search. This is relevant when fewer\ncompute resources are available. Evolution is, thus, a simple method to\neffectively discover high-quality architectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:20:52 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 18:24:29 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 00:10:00 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 06:21:47 GMT"}, {"version": "v5", "created": "Thu, 4 Oct 2018 00:11:37 GMT"}, {"version": "v6", "created": "Fri, 26 Oct 2018 05:56:00 GMT"}, {"version": "v7", "created": "Sat, 16 Feb 2019 23:28:16 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Real", "Esteban", ""], ["Aggarwal", "Alok", ""], ["Huang", "Yanping", ""], ["Le", "Quoc V", ""]]}, {"id": "1802.01549", "submitter": "Zhezhi He", "authors": "Adnan Siraj Rakin, Zhezhi He, Boqing Gong, Deliang Fan", "title": "Blind Pre-Processing: A Robust Defense Method Against Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms and networks are vulnerable to perturbed inputs\nwhich is known as the adversarial attack. Many defense methodologies have been\ninvestigated to defend against such adversarial attack. In this work, we\npropose a novel methodology to defend the existing powerful attack model. We\nfor the first time introduce a new attacking scheme for the attacker and set a\npractical constraint for white box attack. Under this proposed attacking\nscheme, we present the best defense ever reported against some of the recent\nstrong attacks. It consists of a set of nonlinear function to process the input\ndata which will make it more robust over the adversarial attack. However, we\nmake this processing layer completely hidden from the attacker. Blind\npre-processing improves the white box attack accuracy of MNIST from 94.3\\% to\n98.7\\%. Even with increasing defense when others defenses completely fail,\nblind pre-processing remains one of the strongest ever reported. Another\nstrength of our defense is that it eliminates the need for adversarial training\nas it can significantly increase the MNIST accuracy without adversarial\ntraining as well. Additionally, blind pre-processing can also increase the\ninference accuracy in the face of a powerful attack on CIFAR-10 and SVHN data\nset as well without much sacrificing clean data accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:21:31 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 17:46:02 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Rakin", "Adnan Siraj", ""], ["He", "Zhezhi", ""], ["Gong", "Boqing", ""], ["Fan", "Deliang", ""]]}, {"id": "1802.01557", "submitter": "Chelsea Finn", "authors": "Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Tianhao Zhang,\n  Pieter Abbeel, Sergey Levine", "title": "One-Shot Imitation from Observing Humans via Domain-Adaptive\n  Meta-Learning", "comments": "First two authors contributed equally. Video available at\n  https://sites.google.com/view/daml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are capable of learning a new behavior by observing others\nperform the skill just once. We consider the problem of allowing a robot to do\nthe same -- learning from a raw video pixels of a human, even when there is\nsubstantial domain shift in the perspective, environment, and embodiment\nbetween the robot and the observed human. Prior approaches to this problem have\nhand-specified how human and robot actions correspond and often relied on\nexplicit human pose detection systems. In this work, we present an approach for\none-shot learning from a video of a human by using human and robot\ndemonstration data from a variety of previous tasks to build up prior knowledge\nthrough meta-learning. Then, combining this prior knowledge and only a single\nvideo demonstration from a human, the robot can perform the task that the human\ndemonstrated. We show experiments on both a PR2 arm and a Sawyer arm,\ndemonstrating that after meta-learning, the robot can learn to place, push, and\npick-and-place new objects using just one video of a human performing the\nmanipulation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:36:19 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Yu", "Tianhe", ""], ["Finn", "Chelsea", ""], ["Xie", "Annie", ""], ["Dasari", "Sudeep", ""], ["Zhang", "Tianhao", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.01561", "submitter": "Lasse Espeholt", "authors": "Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir\n  Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane\n  Legg, Koray Kavukcuoglu", "title": "IMPALA: Scalable Distributed Deep-RL with Importance Weighted\n  Actor-Learner Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we aim to solve a large collection of tasks using a single\nreinforcement learning agent with a single set of parameters. A key challenge\nis to handle the increased amount of data and extended training time. We have\ndeveloped a new distributed agent IMPALA (Importance Weighted Actor-Learner\nArchitecture) that not only uses resources more efficiently in single-machine\ntraining but also scales to thousands of machines without sacrificing data\nefficiency or resource utilisation. We achieve stable learning at high\nthroughput by combining decoupled acting and learning with a novel off-policy\ncorrection method called V-trace. We demonstrate the effectiveness of IMPALA\nfor multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the\nDeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available\nAtari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our\nresults show that IMPALA is able to achieve better performance than previous\nagents with less data, and crucially exhibits positive transfer between tasks\nas a result of its multi-task approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 18:47:30 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 15:09:30 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 06:54:39 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Espeholt", "Lasse", ""], ["Soyer", "Hubert", ""], ["Munos", "Remi", ""], ["Simonyan", "Karen", ""], ["Mnih", "Volodymir", ""], ["Ward", "Tom", ""], ["Doron", "Yotam", ""], ["Firoiu", "Vlad", ""], ["Harley", "Tim", ""], ["Dunning", "Iain", ""], ["Legg", "Shane", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1802.01569", "submitter": "Nicolas Masse", "authors": "Nicolas Y. Masse, Gregory D. Grant, David J. Freedman", "title": "Alleviating catastrophic forgetting using context-dependent gating and\n  synaptic stabilization", "comments": "Published in PNAS, https://www.pnas.org/content/115/44/E10467", "journal-ref": "Proceedings of the National Academy of Sciences, 115(44),\n  E10467-E10475", "doi": "10.1073/pnas.1803839115", "report-no": null, "categories": "cs.LG cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans and most animals can learn new tasks without forgetting old ones.\nHowever, training artificial neural networks (ANNs) on new tasks typically\ncause it to forget previously learned tasks. This phenomenon is the result of\n\"catastrophic forgetting\", in which training an ANN disrupts connection weights\nthat were important for solving previous tasks, degrading task performance.\nSeveral recent studies have proposed methods to stabilize connection weights of\nANNs that are deemed most important for solving a task, which helps alleviate\ncatastrophic forgetting. Here, drawing inspiration from algorithms that are\nbelieved to be implemented in vivo, we propose a complementary method: adding a\ncontext-dependent gating signal, such that only sparse, mostly non-overlapping\npatterns of units are active for any one task. This method is easy to\nimplement, requires little computational overhead, and allows ANNs to maintain\nhigh performance across large numbers of sequentially presented tasks when\ncombined with weight stabilization. This work provides another example of how\nneuroscience-inspired algorithms can benefit ANN design and capability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 23:49:44 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 16:44:16 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Masse", "Nicolas Y.", ""], ["Grant", "Gregory D.", ""], ["Freedman", "David J.", ""]]}, {"id": "1802.01604", "submitter": "Chandrayee Basu", "authors": "Chandrayee Basu, Mukesh Singhal, Anca D. Dragan", "title": "Learning from Richer Human Guidance: Augmenting Comparison-Based\n  Learning with Feature Queries", "comments": "8 pages, 8 figures, HRI 2018", "journal-ref": null, "doi": "10.1145/3171221.3171284", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on learning the desired objective function for a robot. Although\ntrajectory demonstrations can be very informative of the desired objective,\nthey can also be difficult for users to provide. Answers to comparison queries,\nasking which of two trajectories is preferable, are much easier for users, and\nhave emerged as an effective alternative. Unfortunately, comparisons are far\nless informative. We propose that there is much richer information that users\ncan easily provide and that robots ought to leverage. We focus on augmenting\ncomparisons with feature queries, and introduce a unified formalism for\ntreating all answers as observations about the true desired reward. We derive\nan active query selection algorithm, and test these queries in simulation and\non real users. We find that richer, feature-augmented queries can extract more\ninformation faster, leading to robots that better match user preferences in\ntheir behavior.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 19:03:26 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Basu", "Chandrayee", ""], ["Singhal", "Mukesh", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1802.01730", "submitter": "Flavio L. Pinheiro", "authors": "Fl\\'avio L. Pinheiro and Fernando P. Santos", "title": "Local Wealth Redistribution Promotes Cooperation in Multiagent Systems", "comments": "9 pages, 8 figures, AAMAS2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing mechanisms that leverage cooperation between agents has been a\nlong-lasting goal in Multiagent Systems. The task is especially challenging\nwhen agents are selfish, lack common goals and face social dilemmas, i.e.,\nsituations in which individual interest conflicts with social welfare. Past\nworks explored mechanisms that explain cooperation in biological and social\nsystems, providing important clues for the aim of designing cooperative\nartificial societies. In particular, several works show that cooperation is\nable to emerge when specific network structures underlie agents' interactions.\nNotwithstanding, social dilemmas in which defection is highly tempting still\npose challenges concerning the effective sustainability of cooperation. Here we\npropose a new redistribution mechanism that can be applied in structured\npopulations of agents. Importantly, we show that, when implemented locally\n(i.e., agents share a fraction of their wealth surplus with their nearest\nneighbors), redistribution excels in promoting cooperation under regimes where,\nbefore, only defection prevailed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 23:30:55 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Pinheiro", "Fl\u00e1vio L.", ""], ["Santos", "Fernando P.", ""]]}, {"id": "1802.01772", "submitter": "Maxime Bouton", "authors": "Maxime Bouton, Kyle Julian, Alireza Nakhaei, Kikuo Fujimura, and Mykel\n  J. Kochenderfer", "title": "Decomposition Methods with Deep Corrections for Reinforcement Learning", "comments": null, "journal-ref": "Journal of Agents and Multi-Agent Systems (JAAMAS), 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition methods have been proposed to approximate solutions to large\nsequential decision making problems. In contexts where an agent interacts with\nmultiple entities, utility decomposition can be used to separate the global\nobjective into local tasks considering each individual entity independently. An\narbitrator is then responsible for combining the individual utilities and\nselecting an action in real time to solve the global problem. Although these\ntechniques can perform well empirically, they rely on strong assumptions of\nindependence between the local tasks and sacrifice the optimality of the global\nsolution. This paper proposes an approach that improves upon such approximate\nsolutions by learning a correction term represented by a neural network. We\ndemonstrate this approach on a fisheries management problem where multiple\nboats must coordinate to maximize their catch over time as well as on a\npedestrian avoidance problem for autonomous driving. In each problem,\ndecomposition methods can scale to multiple boats or pedestrians by using\nstrategies involving one entity. We verify empirically that the proposed\ncorrection method significantly improves the decomposition method and\noutperforms a policy trained on the full scale problem without utility\ndecomposition.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 03:02:22 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 19:54:27 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Bouton", "Maxime", ""], ["Julian", "Kyle", ""], ["Nakhaei", "Alireza", ""], ["Fujimura", "Kikuo", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1802.01780", "submitter": "Jaime Fisac", "authors": "Chang Liu, Jessica B. Hamrick, Jaime F. Fisac, Anca D. Dragan, J. Karl\n  Hedrick, S. Shankar Sastry, Thomas L. Griffiths", "title": "Goal Inference Improves Objective and Perceived Performance in\n  Human-Robot Collaboration", "comments": "Published at the International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2016)", "journal-ref": "C. Liu, J. Hamrick, J. Fisac, A. Dragan, J. K. Hedrick, S. Sastry,\n  T. Griffiths. \"Goal Inference Improves Objective and Perceived Performance in\n  Human-Robot Collaboration\". Autonomous Agents and Multiagent Systems (AAMAS),\n  2016", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of human-robot interaction is fundamental to the design and use of\nrobotics in real-world applications. Robots will need to predict and adapt to\nthe actions of human collaborators in order to achieve good performance and\nimprove safety and end-user adoption. This paper evaluates a human-robot\ncollaboration scheme that combines the task allocation and motion levels of\nreasoning: the robotic agent uses Bayesian inference to predict the next goal\nof its human partner from his or her ongoing motion, and re-plans its own\nactions in real time. This anticipative adaptation is desirable in many\npractical scenarios, where humans are unable or unwilling to take on the\ncognitive overhead required to explicitly communicate their intent to the\nrobot. A behavioral experiment indicates that the combination of goal inference\nand dynamic task planning significantly improves both objective and perceived\nperformance of the human-robot team. Participants were highly sensitive to the\ndifferences between robot behaviors, preferring to work with a robot that\nadapted to their actions over one that did not.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 03:31:23 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Liu", "Chang", ""], ["Hamrick", "Jessica B.", ""], ["Fisac", "Jaime F.", ""], ["Dragan", "Anca D.", ""], ["Hedrick", "J. Karl", ""], ["Sastry", "S. Shankar", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1802.01812", "submitter": "Shuming Ma", "authors": "Junyang Lin, Shuming Ma, Qi Su, Xu Sun", "title": "Decoding-History-Based Adaptive Control of Attention for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence model has proved successful in Neural\nMachine Translation (NMT). However, the attention without consideration of\ndecoding history, which includes the past information in the decoder and the\nattention mechanism, often causes much repetition. To address this problem, we\npropose the decoding-history-based Adaptive Control of Attention (ACA) for the\nNMT model. ACA learns to control the attention by keeping track of the decoding\nhistory and the current information with a memory vector, so that the model can\ntake the translated contents and the current information into consideration.\nExperiments on Chinese-English translation and the English-Vietnamese\ntranslation have demonstrated that our model significantly outperforms the\nstrong baselines. The analysis shows that our model is capable of generating\ntranslation with less repetition and higher accuracy. The code will be\navailable at https://github.com/lancopku\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 06:18:56 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Lin", "Junyang", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1802.01933", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini,\n  Dino Pedreschi, Fosca Giannotti", "title": "A Survey Of Methods For Explaining Black Box Models", "comments": "This work is currently under review on an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years many accurate decision support systems have been\nconstructed as black boxes, that is as systems that hide their internal logic\nto the user. This lack of explanation constitutes both a practical and an\nethical issue. The literature reports many approaches aimed at overcoming this\ncrucial weakness sometimes at the cost of scarifying accuracy for\ninterpretability. The applications in which black box decision systems can be\nused are various, and each approach is typically developed to provide a\nsolution for a specific problem and, as a consequence, delineating explicitly\nor implicitly its own definition of interpretability and explanation. The aim\nof this paper is to provide a classification of the main problems addressed in\nthe literature with respect to the notion of explanation and the type of black\nbox system. Given a problem definition, a black box type, and a desired\nexplanation this survey should help the researcher to find the proposals more\nuseful for his own work. The proposed classification of approaches to open\nblack box models should also be useful for putting the many research open\nquestions in perspective.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 13:20:02 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 12:29:56 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 08:15:38 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Ruggieri", "Salvatore", ""], ["Turini", "Franco", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""]]}, {"id": "1802.02032", "submitter": "Hui Su", "authors": "Xiaoyu Shen, Hui Su, Shuzi Niu and Vera Demberg", "title": "Improving Variational Encoder-Decoders in Dialogue Generation", "comments": "Accepted by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational encoder-decoders (VEDs) have shown promising results in dialogue\ngeneration. However, the latent variable distributions are usually approximated\nby a much simpler model than the powerful RNN structure used for encoding and\ndecoding, yielding the KL-vanishing problem and inconsistent training\nobjective. In this paper, we separate the training step into two phases: The\nfirst phase learns to autoencode discrete texts into continuous embeddings,\nfrom which the second phase learns to generalize latent representations by\nreconstructing the encoded embedding. In this case, latent variables are\nsampled by transforming Gaussian noise through multi-layer perceptrons and are\ntrained with a separate VED model, which has the potential of realizing a much\nmore flexible distribution. We compare our model with current popular models\nand the experiment demonstrates substantial improvement in both metric-based\nand human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 16:19:05 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Shen", "Xiaoyu", ""], ["Su", "Hui", ""], ["Niu", "Shuzi", ""], ["Demberg", "Vera", ""]]}, {"id": "1802.02172", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Bogdan Grechuk, Ivan Y. Tyukin", "title": "Augmented Artificial Intelligence: a Conceptual Framework", "comments": "The mathematical part is significantly extended. New stochastic\n  separation theorems are proven for log-concave distributions. Some previously\n  formulated hypotheses are confirmed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. The mathematical foundations of AI non-destructive\ncorrection are presented and a series of new stochastic separation theorems is\nproven. These theorems provide a new instrument for the development, analysis,\nand assessment of machine learning methods and algorithms in high dimension.\nThey demonstrate that in high dimensions and even for exponentially large\nsamples, linear classifiers in their classical Fisher's form are powerful\nenough to separate errors from correct responses with high probability and to\nprovide efficient solution to the non-destructive corrector problem. In\nparticular, we prove some hypotheses formulated in our paper `Stochastic\nSeparation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one\ngeneral problem published by Donoho and Tanner in 2009.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 19:05:27 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 16:19:55 GMT"}, {"version": "v3", "created": "Sat, 24 Mar 2018 13:40:05 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Grechuk", "Bogdan", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "1802.02186", "submitter": "John Olafenwa", "authors": "John Olafenwa, Moses Olafenwa", "title": "FastNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inception and the Resnet family of Convolutional Neural Network\narchi-tectures have broken records in the past few years, but recent state of\nthe art models have also incurred very high computational cost in terms of\ntraining, inference and model size. Making the deployment of these models on\nEdge devices, impractical. In light of this, we present a new novel\narchitecture that is designed for high computational efficiency on both GPUs\nand CPUs, and is highly suited for deployment on Mobile Applications, Smart\nCameras, Iot devices and controllers as well as low cost drones. Our\narchitecture boasts competitive accuracies on standard Datasets even\nout-performing the original Resnet. We present below the motivation for this\nresearch, the architecture of the network, single test accuracies on CIFAR 10\nand CIFAR 100 , a detailed comparison with other well-known architectures and\nlink to an implementation in Keras.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 10:37:58 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Olafenwa", "John", ""], ["Olafenwa", "Moses", ""]]}, {"id": "1802.02195", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Djordje Miladinovic, Walter Karlen", "title": "Granger-causal Attentive Mixtures of Experts: Learning Important\n  Features with Neural Networks", "comments": "AAAI Conference on Artificial Intelligence 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33014846", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of the importance of input features towards decisions made by\nmachine-learning models is essential to increase our understanding of both the\nmodels and the underlying data. Here, we present a new approach to estimating\nfeature importance with neural networks based on the idea of distributing the\nfeatures of interest among experts in an attentive mixture of experts (AME).\nAMEs use attentive gating networks trained with a Granger-causal objective to\nlearn to jointly produce accurate predictions as well as estimates of feature\nimportance in a single model. Our experiments show (i) that the feature\nimportance estimates provided by AMEs compare favourably to those provided by\nstate-of-the-art methods, (ii) that AMEs are significantly faster at estimating\nfeature importance than existing methods, and (iii) that the associations\ndiscovered by AMEs are consistent with those reported by domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 20:21:30 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 11:18:22 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 12:49:54 GMT"}, {"version": "v4", "created": "Fri, 7 Sep 2018 12:15:56 GMT"}, {"version": "v5", "created": "Mon, 1 Oct 2018 12:36:39 GMT"}, {"version": "v6", "created": "Wed, 14 Nov 2018 23:57:14 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Schwab", "Patrick", ""], ["Miladinovic", "Djordje", ""], ["Karlen", "Walter", ""]]}, {"id": "1802.02209", "submitter": "Changhao Chen", "authors": "Changhao Chen, Xiaoxuan Lu, Andrew Markham, Niki Trigoni", "title": "IONet: Learning to Cure the Curse of Drift in Inertial Odometry", "comments": "To appear in AAAI18 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inertial sensors play a pivotal role in indoor localization, which in turn\nlays the foundation for pervasive personal applications. However, low-cost\ninertial sensors, as commonly found in smartphones, are plagued by bias and\nnoise, which leads to unbounded growth in error when accelerations are double\nintegrated to obtain displacement. Small errors in state estimation propagate\nto make odometry virtually unusable in a matter of seconds. We propose to break\nthe cycle of continuous integration, and instead segment inertial data into\nindependent windows. The challenge becomes estimating the latent states of each\nwindow, such as velocity and orientation, as these are not directly observable\nfrom sensor data. We demonstrate how to formulate this as an optimization\nproblem, and show how deep recurrent neural networks can yield highly accurate\ntrajectories, outperforming state-of-the-art shallow techniques, on a wide\nrange of tests and attachments. In particular, we demonstrate that IONet can\ngeneralize to estimate odometry for non-periodic motion, such as a shopping\ntrolley or baby-stroller, an extremely challenging task for existing\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 18:29:02 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Chen", "Changhao", ""], ["Lu", "Xiaoxuan", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1802.02219", "submitter": "Matthias Feurer", "authors": "Matthias Feurer, Benjamin Letham, Frank Hutter, Eytan Bakshy", "title": "Practical Transfer Learning for Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a standard technique for hyperparameter\noptimization of machine learning algorithms. We consider the setting where\nprevious optimization runs are available, and we wish to transfer their\noutcomes to a new optimization run and thereby accelerate the search. We\ndevelop a new hyperparameter-free ensemble model for Bayesian optimization,\nbased on a linear combination of Gaussian Processes and Agnostic Bayesian\nLearning of Ensembles. We show that this is a generalization of two existing\ntransfer learning extensions to Bayesian optimization and establish a\nworst-case bound compared to vanilla Bayesian optimization. Using a large\ncollection of hyperparameter optimization benchmark problems, we demonstrate\nthat our contributions substantially reduce optimization time compared to\nstandard Gaussian process-based Bayesian optimization and improve over the\ncurrent state-of-the-art for warm-starting Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 21:02:59 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 11:41:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Feurer", "Matthias", ""], ["Letham", "Benjamin", ""], ["Hutter", "Frank", ""], ["Bakshy", "Eytan", ""]]}, {"id": "1802.02274", "submitter": "Vikas Dhiman", "authors": "Vikas Dhiman, Shurjo Banerjee, Brent Griffin, Jeffrey M Siskind, Jason\n  J Corso", "title": "A Critical Investigation of Deep Reinforcement Learning for Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The navigation problem is classically approached in two steps: an exploration\nstep, where map-information about the environment is gathered; and an\nexploitation step, where this information is used to navigate efficiently. Deep\nreinforcement learning (DRL) algorithms, alternatively, approach the problem of\nnavigation in an end-to-end fashion. Inspired by the classical approach, we ask\nwhether DRL algorithms are able to inherently explore, gather and exploit\nmap-information over the course of navigation. We build upon Mirowski et al.\n[2017] work and introduce a systematic suite of experiments that vary three\nparameters: the agent's starting location, the agent's target location, and the\nmaze structure. We choose evaluation metrics that explicitly measure the\nalgorithm's ability to gather and exploit map-information. Our experiments show\nthat when trained and tested on the same maps, the algorithm successfully\ngathers and exploits map-information. However, when trained and tested on\ndifferent sets of maps, the algorithm fails to transfer the ability to gather\nand exploit map-information to unseen maps. Furthermore, we find that when the\ngoal location is randomized and the map is kept static, the algorithm is able\nto gather and exploit map-information but the exploitation is far from optimal.\nWe open-source our experimental suite in the hopes that it serves as a\nframework for the comparison of future algorithms and leads to the discovery of\nrobust alternatives to classical navigation methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 00:44:59 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 20:47:12 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dhiman", "Vikas", ""], ["Banerjee", "Shurjo", ""], ["Griffin", "Brent", ""], ["Siskind", "Jeffrey M", ""], ["Corso", "Jason J", ""]]}, {"id": "1802.02353", "submitter": "Neel Kant", "authors": "Neel Kant", "title": "Recent Advances in Neural Program Synthesis", "comments": "16 pages (without citations); Literature Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has made tremendous progress in a number of\nfields that were previously out of reach for artificial intelligence. The\nsuccesses in these problems has led researchers to consider the possibilities\nfor intelligent systems to tackle a problem that humans have only recently\nthemselves considered: program synthesis. This challenge is unlike others such\nas object recognition and speech translation, since its abstract nature and\ndemand for rigor make it difficult even for human minds to attempt. While it is\nstill far from being solved or even competitive with most existing methods,\nneural program synthesis is a rapidly growing discipline which holds great\npromise if completely realized. In this paper, we start with exploring the\nproblem statement and challenges of program synthesis. Then, we examine the\nfascinating evolution of program induction models, along with how they have\nsucceeded, failed and been reimagined since. Finally, we conclude with a\ncontrastive look at program synthesis and future research recommendations for\nthe field.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 08:44:38 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Kant", "Neel", ""]]}, {"id": "1802.02434", "submitter": "Junhua Wu", "authors": "Junhua Wu and Sergey Polyakovskiy and Markus Wagner and Frank Neumann", "title": "Evolutionary Computation plus Dynamic Programming for the Bi-Objective\n  Travelling Thief Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes a novel indicator-based hybrid evolutionary approach\nthat combines approximate and exact algorithms. We apply it to a new\nbi-criteria formulation of the travelling thief problem, which is known to the\nEvolutionary Computation community as a benchmark multi-component optimisation\nproblem that interconnects two classical NP-hard problems: the travelling\nsalesman problem and the 0-1 knapsack problem. Our approach employs the exact\ndynamic programming algorithm for the underlying Packing-While-Travelling (PWT)\nproblem as a subroutine within a bi-objective evolutionary algorithm. This\ndesign takes advantage of the data extracted from Pareto fronts generated by\nthe dynamic program to achieve better solutions. Furthermore, we develop a\nnumber of novel indicators and selection mechanisms to strengthen synergy of\nthe two algorithmic components of our approach. The results of computational\nexperiments show that the approach is capable to outperform the\nstate-of-the-art results for the single-objective case of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 14:34:53 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Wu", "Junhua", ""], ["Polyakovskiy", "Sergey", ""], ["Wagner", "Markus", ""], ["Neumann", "Frank", ""]]}, {"id": "1802.02468", "submitter": "Mauro Scanagatta", "authors": "Mauro Scanagatta, Giorgio Corani, Marco Zaffalon, Jaemin Yoo, U Kang", "title": "Efficient Learning of Bounded-Treewidth Bayesian Networks from Complete\n  and Incomplete Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning a Bayesian networks with bounded treewidth is important for reducing\nthe complexity of the inferences. We present a novel anytime algorithm (k-MAX)\nmethod for this task, which scales up to thousands of variables. Through\nextensive experiments we show that it consistently yields higher-scoring\nstructures than its competitors on complete data sets. We then consider the\nproblem of structure learning from incomplete data sets. This can be addressed\nby structural EM, which however is computationally very demanding. We thus\nadopt the novel k-MAX algorithm in the maximization step of structural EM,\nobtaining an efficient computation of the expected sufficient statistics. We\ntest the resulting structural EM method on the task of imputing missing data,\ncomparing it against the state-of-the-art approach based on random forests. Our\napproach achieves the same imputation accuracy of the competitors, but in about\none tenth of the time. Furthermore we show that it has worst-case complexity\nlinear in the input size, and that it is easily parallelizable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 15:09:32 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Scanagatta", "Mauro", ""], ["Corani", "Giorgio", ""], ["Zaffalon", "Marco", ""], ["Yoo", "Jaemin", ""], ["Kang", "U", ""]]}, {"id": "1802.02511", "submitter": "Avesh Singh", "authors": "Brandon Ballinger, Johnson Hsieh, Avesh Singh, Nimit Sohoni, Jack\n  Wang, Geoffrey H. Tison, Gregory M. Marcus, Jose M. Sanchez, Carol Maguire,\n  Jeffrey E. Olgin, Mark J. Pletcher", "title": "DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk\n  Prediction", "comments": "Presented at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train and validate a semi-supervised, multi-task LSTM on 57,675\nperson-weeks of data from off-the-shelf wearable heart rate sensors, showing\nhigh accuracy at detecting multiple medical conditions, including diabetes\n(0.8451), high cholesterol (0.7441), high blood pressure (0.8086), and sleep\napnea (0.8298). We compare two semi-supervised train- ing methods,\nsemi-supervised sequence learning and heuristic pretraining, and show they\noutperform hand-engineered biomarkers from the medical literature. We believe\nour work suggests a new approach to patient risk stratification based on\ncardiovascular risk scores derived from popular wearables such as Fitbit, Apple\nWatch, or Android Wear.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:31:50 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Ballinger", "Brandon", ""], ["Hsieh", "Johnson", ""], ["Singh", "Avesh", ""], ["Sohoni", "Nimit", ""], ["Wang", "Jack", ""], ["Tison", "Geoffrey H.", ""], ["Marcus", "Gregory M.", ""], ["Sanchez", "Jose M.", ""], ["Maguire", "Carol", ""], ["Olgin", "Jeffrey E.", ""], ["Pletcher", "Mark J.", ""]]}, {"id": "1802.02528", "submitter": "Rahul Parundekar", "authors": "Rahul Parundekar", "title": "Classification of Things in DBpedia using Deep Neural Networks", "comments": null, "journal-ref": "Classification of Things in DBpedia using Deep Neural Networks, R\n  Parundekar, International Journal of Web & Semantic Technology (IJWesT)\n  Vol.9, No.1, January 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web aims at representing knowledge about the real world at web\nscale - things, their attributes and relationships among them can be\nrepresented as nodes and edges in an inter-linked semantic graph. In the\npresence of noisy data, as is typical of data on the Semantic Web, a software\nAgent needs to be able to robustly infer one or more associated actionable\nclasses for the individuals in order to act automatically on it. We model this\nproblem as a multi-label classification task where we want to robustly identify\ntypes of the individuals in a semantic graph such as DBpedia, which we use as\nan exemplary dataset on the Semantic Web. Our approach first extracts multiple\nfeatures for the individuals using random walks and then performs multi-label\nclassification using fully-connected Neural Networks. Through systematic\nexploration and experimentation, we identify the effect of hyper-parameters of\nthe feature extraction and the fully-connected Neural Network structure on the\nclassification performance. Our final results show that our method performs\nbetter than state-of-the-art inferencing systems like SDtype and SLCN, from\nwhich we can conclude that random-walk-based feature extraction of individuals\nand their multi-label classification using Deep Neural Networks is a promising\nalternative to these systems for type classification of individuals on the\nSemantic Web. The main contribution of our work is to introduce a novel\napproach that allows us to use Deep Neural Networks to identify types of\nindividuals in a noisy semantic graph by extracting features using random walks\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 17:12:54 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Parundekar", "Rahul", ""]]}, {"id": "1802.02534", "submitter": "Dario Zanca", "authors": "Dario Zanca, Valeria Serchi, Pietro Piu, Francesca Rosini and\n  Alessandra Rufa", "title": "FixaTons: A collection of Human Fixations Datasets and Metrics for\n  Scanpath Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last three decades, human visual attention has been a topic of great\ninterest in various disciplines. In computer vision, many models have been\nproposed to predict the distribution of human fixations on a visual stimulus.\nRecently, thanks to the creation of large collections of data, machine learning\nalgorithms have obtained state-of-the-art performance on the task of saliency\nmap estimation. On the other hand, computational models of scanpath are much\nless studied. Works are often only descriptive or task specific. This is due to\nthe fact that the scanpath is harder to model because it must include the\ndescription of a dynamic. General purpose computational models are present in\nthe literature, but are then evaluated in tasks of saliency prediction, losing\ntherefore information about the dynamics and the behaviour. In addition, two\ntechnical reasons have limited the research. The first reason is the lack of\nrobust and uniformly used set of metrics to compare the similarity between\nscanpath. The second reason is the lack of sufficiently large and varied\nscanpath datasets. In this report we want to help in both directions. We\npresent FixaTons, a large collection of datasets human scanpaths (temporally\nordered sequences of fixations) and saliency maps. It comes along with a\nsoftware library for easy data usage, statistics calculation and implementation\nof metrics for scanpath and saliency prediction evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 17:20:31 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 09:48:42 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 15:20:59 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Zanca", "Dario", ""], ["Serchi", "Valeria", ""], ["Piu", "Pietro", ""], ["Rosini", "Francesca", ""], ["Rufa", "Alessandra", ""]]}, {"id": "1802.02548", "submitter": "Sam Ganzfried", "authors": "Sheila Alemany, Jonathan Beltran, Adrian Perez, Sam Ganzfried", "title": "Predicting Hurricane Trajectories using a Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hurricanes are cyclones circulating about a defined center whose closed wind\nspeeds exceed 75 mph originating over tropical and subtropical waters. At\nlandfall, hurricanes can result in severe disasters. The accuracy of predicting\ntheir trajectory paths is critical to reduce economic loss and save human\nlives. Given the complexity and nonlinearity of weather data, a recurrent\nneural network (RNN) could be beneficial in modeling hurricane behavior. We\npropose the application of a fully connected RNN to predict the trajectory of\nhurricanes. We employed the RNN over a fine grid to reduce typical truncation\nerrors. We utilized their latitude, longitude, wind speed, and pressure\npublicly provided by the National Hurricane Center (NHC) to predict the\ntrajectory of a hurricane at 6-hour intervals. Results show that this proposed\ntechnique is competitive to methods currently employed by the NHC and can\npredict up to approximately 120 hours of hurricane path.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 08:17:58 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 08:59:55 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 07:30:52 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Alemany", "Sheila", ""], ["Beltran", "Jonathan", ""], ["Perez", "Adrian", ""], ["Ganzfried", "Sam", ""]]}, {"id": "1802.02565", "submitter": "Johannes Wagner", "authors": "Johannes Wagner, Tobias Baur, Yue Zhang, Michel F. Valstar, Bj\\\"orn\n  Schuller, Elisabeth Andr\\'e", "title": "Applying Cooperative Machine Learning to Speed Up the Annotation of\n  Social Signals in Large Multi-modal Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific disciplines, such as Behavioural Psychology, Anthropology and\nrecently Social Signal Processing are concerned with the systematic exploration\nof human behaviour. A typical work-flow includes the manual annotation (also\ncalled coding) of social signals in multi-modal corpora of considerable size.\nFor the involved annotators this defines an exhausting and time-consuming task.\nIn the article at hand we present a novel method and also provide the tools to\nspeed up the coding procedure. To this end, we suggest and evaluate the use of\nCooperative Machine Learning (CML) techniques to reduce manual labelling\nefforts by combining the power of computational capabilities and human\nintelligence. The proposed CML strategy starts with a small number of labelled\ninstances and concentrates on predicting local parts first. Afterwards, a\nsession-independent classification model is created to finish the remaining\nparts of the database. Confidence values are computed to guide the manual\ninspection and correction of the predictions. To bring the proposed approach\ninto application we introduce NOVA - an open-source tool for collaborative and\nmachine-aided annotations. In particular, it gives labellers immediate access\nto CML strategies and directly provides visual feedback on the results. Our\nexperiments show that the proposed method has the potential to significantly\nreduce human labelling efforts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 18:47:49 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Wagner", "Johannes", ""], ["Baur", "Tobias", ""], ["Zhang", "Yue", ""], ["Valstar", "Michel F.", ""], ["Schuller", "Bj\u00f6rn", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "1802.02669", "submitter": "Tolga Birdal", "authors": "Haowen Deng, Tolga Birdal and Slobodan Ilic", "title": "PPFNet: Global Context Aware Local Features for Robust 3D Point Matching", "comments": "Accepted for publication at CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PPFNet - Point Pair Feature NETwork for deeply learning a globally\ninformed 3D local feature descriptor to find correspondences in unorganized\npoint clouds. PPFNet learns local descriptors on pure geometry and is highly\naware of the global context, an important cue in deep learning. Our 3D\nrepresentation is computed as a collection of point-pair-features combined with\nthe points and normals within a local vicinity. Our permutation invariant\nnetwork design is inspired by PointNet and sets PPFNet to be ordering-free. As\nopposed to voxelization, our method is able to consume raw point clouds to\nexploit the full sparsity. PPFNet uses a novel $\\textit{N-tuple}$ loss and\narchitecture injecting the global information naturally into the local\ndescriptor. It shows that context awareness also boosts the local feature\nrepresentation. Qualitative and quantitative evaluations of our network suggest\nincreased recall, improved robustness and invariance as well as a vital step in\nthe 3D descriptor extraction performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 23:01:52 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 20:26:25 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Deng", "Haowen", ""], ["Birdal", "Tolga", ""], ["Ilic", "Slobodan", ""]]}, {"id": "1802.02674", "submitter": "Siddhartha Verma", "authors": "Siddhartha Verma and Guido Novati and Petros Koumoutsakos", "title": "Efficient collective swimming by harnessing vortices through deep\n  reinforcement learning", "comments": "26 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fish in schooling formations navigate complex flow-fields replete with\nmechanical energy in the vortex wakes of their companions. Their schooling\nbehaviour has been associated with evolutionary advantages including collective\nenergy savings. How fish harvest energy from their complex fluid environment\nand the underlying physical mechanisms governing energy-extraction during\ncollective swimming, is still unknown. Here we show that fish can improve their\nsustained propulsive efficiency by actively following, and judiciously\nintercepting, vortices in the wake of other swimmers. This swimming strategy\nleads to collective energy-savings and is revealed through the first ever\ncombination of deep reinforcement learning with high-fidelity flow simulations.\nWe find that a `smart-swimmer' can adapt its position and body deformation to\nsynchronise with the momentum of the oncoming vortices, improving its average\nswimming-efficiency at no cost to the leader. The results show that fish may\nharvest energy deposited in vortices produced by their peers, and support the\nconjecture that swimming in formation is energetically advantageous. Moreover,\nthis study demonstrates that deep reinforcement learning can produce navigation\nalgorithms for complex flow-fields, with promising implications for energy\nsavings in autonomous robotic swarms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 23:42:42 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Verma", "Siddhartha", ""], ["Novati", "Guido", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1802.02732", "submitter": "Christoph Benzm\\\"uller", "authors": "Alexander Steen and Christoph Benzm\\\"uller", "title": "The Higher-Order Prover Leo-III (Extended Version)", "comments": "13 pages (this is an extended version of the IJCAR 2018 paper)", "journal-ref": "9th International Joint Conference on Automated Reasoning, IJCAR\n  2018, Oxford, UK, July 14-17, 2018, Proceedings, Springer", "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated theorem prover Leo-III for classical higher-order logic with\nHenkin semantics and choice is presented. Leo-III is based on extensional\nhigher-order paramodulation and accepts every common TPTP dialect (FOF, TFF,\nTHF), including their recent extensions to rank-1 polymorphism (TF1, TH1). In\naddition, the prover natively supports almost every normal higher-order modal\nlogic. Leo-III cooperates with first-order reasoning tools using translations\nto many-sorted first-order logic and produces verifiable proof certificates.\nThe prover is evaluated on heterogeneous benchmark sets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 07:48:31 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 11:45:07 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Steen", "Alexander", ""], ["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1802.02892", "submitter": "Douwe Kiela", "authors": "D. Kiela, E. Grave, A. Joulin, T. Mikolov", "title": "Efficient Large-Scale Multi-Modal Classification", "comments": "Published at AAAI-18, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the incipient internet was largely text-based, the modern digital world\nis becoming increasingly multi-modal. Here, we examine multi-modal\nclassification where one modality is discrete, e.g. text, and the other is\ncontinuous, e.g. visual representations transferred from a convolutional neural\nnetwork. In particular, we focus on scenarios where we have to be able to\nclassify large quantities of data quickly. We investigate various methods for\nperforming multi-modal fusion and analyze their trade-offs in terms of\nclassification accuracy and computational efficiency. Our findings indicate\nthat the inclusion of continuous information improves performance over\ntext-only on a range of multi-modal classification tasks, even with simple\nfusion methods. In addition, we experiment with discretizing the continuous\nfeatures in order to speed up and simplify the fusion process even further. Our\nresults show that fusion with discretized features outperforms text-only\nclassification, at a fraction of the computational cost of full multi-modal\nfusion, with the additional benefit of improved interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 20:30:59 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Kiela", "D.", ""], ["Grave", "E.", ""], ["Joulin", "A.", ""], ["Mikolov", "T.", ""]]}, {"id": "1802.02896", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Ryan Rossi, John Boaz Lee, Theodore L. Willke, Rong\n  Zhou, Xiangnan Kong, Hoda Eldardiry", "title": "Learning Role-based Graph Embeddings", "comments": "StarAI workshop @ IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walks are at the heart of many existing network embedding methods.\nHowever, such algorithms have many limitations that arise from the use of\nrandom walks, e.g., the features resulting from these methods are unable to\ntransfer to new nodes and graphs as they are tied to vertex identity. In this\nwork, we introduce the Role2Vec framework which uses the flexible notion of\nattributed random walks, and serves as a basis for generalizing existing\nmethods such as DeepWalk, node2vec, and many others that leverage random walks.\nOur proposed framework enables these methods to be more widely applicable for\nboth transductive and inductive learning as well as for use on graphs with\nattributes (if available). This is achieved by learning functions that\ngeneralize to new nodes and graphs. We show that our proposed framework is\neffective with an average AUC improvement of 16.55% while requiring on average\n853x less space than existing methods on a variety of graphs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 00:29:44 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 23:36:25 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan", ""], ["Lee", "John Boaz", ""], ["Willke", "Theodore L.", ""], ["Zhou", "Rong", ""], ["Kong", "Xiangnan", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "1802.02987", "submitter": "HyeonSeok Lee", "authors": "HyeonSeok Lee, Hyo Seon Park", "title": "A Generalization Method of Partitioned Activation Function for Complex\n  Number", "comments": "Complex Activation Function, Holomorphic, Phase-preserving,\n  real-complex interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to convert real number partitioned activation function into complex\nnumber one is provided. The method has 4em variations; 1 has potential to get\nholomorphic activation, 2 has potential to conserve complex angle, and the last\n1 guarantees interaction between real and imaginary parts. The method has been\napplied to LReLU and SELU as examples. The complex number activation function\nis an building block of complex number ANN, which has potential to properly\ndeal with complex number problems. But the complex activation is not well\nestablished yet. Therefore, we propose a way to extend the partitioned real\nactivation to complex number.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 17:57:58 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Lee", "HyeonSeok", ""], ["Park", "Hyo Seon", ""]]}, {"id": "1802.03052", "submitter": "Peter Jansen", "authors": "Peter A. Jansen, Elizabeth Wainwright, Steven Marmorstein, Clayton T.\n  Morrison", "title": "WorldTree: A Corpus of Explanation Graphs for Elementary Science\n  Questions supporting Multi-Hop Inference", "comments": "Accepted at the Language Resource and Evaluation Conference (LREC)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing methods of automated inference that are able to provide users with\ncompelling human-readable justifications for why the answer to a question is\ncorrect is critical for domains such as science and medicine, where user trust\nand detecting costly errors are limiting factors to adoption. One of the\ncentral barriers to training question answering models on explainable inference\ntasks is the lack of gold explanations to serve as training data. In this paper\nwe present a corpus of explanations for standardized science exams, a recent\nchallenge task for question answering. We manually construct a corpus of\ndetailed explanations for nearly all publicly available standardized elementary\nscience question (approximately 1,680 3rd through 5th grade questions) and\nrepresent these as \"explanation graphs\" -- sets of lexically overlapping\nsentences that describe how to arrive at the correct answer to a question\nthrough a combination of domain and world knowledge. We also provide an\nexplanation-centered tablestore, a collection of semi-structured tables that\ncontain the knowledge to construct these elementary science explanations.\nTogether, these two knowledge resources map out a substantial portion of the\nknowledge required for answering and explaining elementary science exams, and\nprovide both structured and free-text training data for the explainable\ninference task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 21:26:03 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Jansen", "Peter A.", ""], ["Wainwright", "Elizabeth", ""], ["Marmorstein", "Steven", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1802.03144", "submitter": "Christian Walder Dr", "authors": "Christian J. Walder and Dongwoo Kim", "title": "Neural Dynamic Programming for Musical Self Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural sequence model designed specifically for symbolic music.\nThe model is based on a learned edit distance mechanism which generalises a\nclassic recursion from computer sci- ence, leading to a neural dynamic program.\nRe- peated motifs are detected by learning the transfor- mations between them.\nWe represent the arising computational dependencies using a novel data\nstructure, the edit tree; this perspective suggests natural approximations\nwhich afford the scaling up of our otherwise cubic time algorithm. We\ndemonstrate our model on real and synthetic data; in all cases it out-performs\na strong stacked long short-term memory benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 06:37:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 10:19:36 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 02:21:07 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Walder", "Christian J.", ""], ["Kim", "Dongwoo", ""]]}, {"id": "1802.03171", "submitter": "Long Yang", "authors": "Long Yang, Minhao Shi, Qian Zheng, Wenjia Meng, Gang Pan", "title": "A Unified Approach for Multi-step Temporal-Difference Learning with\n  Eligibility Traces in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a new multi-step temporal learning algorithm, called $Q(\\sigma)$,\nunifies $n$-step Tree-Backup (when $\\sigma=0$) and $n$-step Sarsa (when\n$\\sigma=1$) by introducing a sampling parameter $\\sigma$. However, similar to\nother multi-step temporal-difference learning algorithms, $Q(\\sigma)$ needs\nmuch memory consumption and computation time. Eligibility trace is an important\nmechanism to transform the off-line updates into efficient on-line ones which\nconsume less memory and computation time. In this paper, we further develop the\noriginal $Q(\\sigma)$, combine it with eligibility traces and propose a new\nalgorithm, called $Q(\\sigma ,\\lambda)$, in which $\\lambda$ is trace-decay\nparameter. This idea unifies Sarsa$(\\lambda)$ (when $\\sigma =1$) and\n$Q^{\\pi}(\\lambda)$ (when $\\sigma =0$). Furthermore, we give an upper error\nbound of $Q(\\sigma ,\\lambda)$ policy evaluation algorithm. We prove that\n$Q(\\sigma,\\lambda)$ control algorithm can converge to the optimal value\nfunction exponentially. We also empirically compare it with conventional\ntemporal-difference learning methods. Results show that, with an intermediate\nvalue of $\\sigma$, $Q(\\sigma ,\\lambda)$ creates a mixture of the existing\nalgorithms that can learn the optimal value significantly faster than the\nextreme end ($\\sigma=0$, or $1$).\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 08:46:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Yang", "Long", ""], ["Shi", "Minhao", ""], ["Zheng", "Qian", ""], ["Meng", "Wenjia", ""], ["Pan", "Gang", ""]]}, {"id": "1802.03216", "submitter": "Jordi Grau-Moya", "authors": "Jordi Grau-Moya and Felix Leibfried and Haitham Bou-Ammar", "title": "Balancing Two-Player Stochastic Games with Soft Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of video games the notion of perfectly rational agents can\nbe undesirable as it leads to uninteresting situations, where humans face tough\nadversarial decision makers. Current frameworks for stochastic games and\nreinforcement learning prohibit tuneable strategies as they seek optimal\nperformance. In this paper, we enable such tuneable behaviour by generalising\nsoft Q-learning to stochastic games, where more than one agent interact\nstrategically. We contribute both theoretically and empirically. On the theory\nside, we show that games with soft Q-learning exhibit a unique value and\ngeneralise team games and zero-sum games far beyond these two extremes to cover\na continuous spectrum of gaming behaviour. Experimentally, we show how tuning\nagents' constraints affect performance and demonstrate, through a neural\nnetwork architecture, how to reliably balance games with high-dimensional\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 12:03:15 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 13:14:52 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Grau-Moya", "Jordi", ""], ["Leibfried", "Felix", ""], ["Bou-Ammar", "Haitham", ""]]}, {"id": "1802.03236", "submitter": "Daniel J Mankowitz", "authors": "Daniel J. Mankowitz, Timothy A. Mann, Pierre-Luc Bacon, Doina Precup\n  and Shie Mannor", "title": "Learning Robust Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust reinforcement learning aims to produce policies that have strong\nguarantees even in the face of environments/transition models whose parameters\nhave strong uncertainty. Existing work uses value-based methods and the usual\nprimitive action setting. In this paper, we propose robust methods for learning\ntemporally abstract actions, in the framework of options. We present a Robust\nOptions Policy Iteration (ROPI) algorithm with convergence guarantees, which\nlearns options that are robust to model uncertainty. We utilize ROPI to learn\nrobust options with the Robust Options Deep Q Network (RO-DQN) that solves\nmultiple tasks and mitigates model misspecification due to model uncertainty.\nWe present experimental results which suggest that policy iteration with linear\nfeatures may have an inherent form of robustness when using coarse feature\nrepresentations. In addition, we present experimental results which demonstrate\nthat robustness helps policy iteration implemented on top of deep neural\nnetworks to generalize over a much broader range of dynamics than non-robust\npolicy iteration.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 12:52:06 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Mankowitz", "Daniel J.", ""], ["Mann", "Timothy A.", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""], ["Mannor", "Shie", ""]]}, {"id": "1802.03239", "submitter": "Avi Rosenfeld", "authors": "Avi Rosenfeld and Ron Illuz and Dovid Gottesman and Mark Last", "title": "Using Discretization for Extending the Set of Predictive Features", "comments": "14 pages", "journal-ref": "EURASIP Journal on Advances in Signal Processing 2018:7", "doi": "10.1186/s13634-018-0528-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, attribute discretization is typically performed by replacing the\noriginal set of continuous features with a transposed set of discrete ones.\nThis paper provides support for a new idea that discretized features should\noften be used in addition to existing features and as such, datasets should be\nextended, and not replaced, by discretization. We also claim that\ndiscretization algorithms should be developed with the explicit purpose of\nenriching a non-discretized dataset with discretized values. We present such an\nalgorithm, D-MIAT, a supervised algorithm that discretizes data based on\nMinority Interesting Attribute Thresholds. D-MIAT only generates new features\nwhen strong indications exist for one of the target values needing to be\nlearned and thus is intended to be used in addition to the original data. We\npresent extensive empirical results demonstrating the success of using D-MIAT\non $ 28 $ benchmark datasets. We also demonstrate that $ 10 $ other\ndiscretization algorithms can also be used to generate features that yield\nimproved performance when used in combination with the original non-discretized\ndata. Our results show that the best predictive performance is attained using a\ncombination of the original dataset with added features from a \"standard\"\nsupervised discretization algorithm and D-MIAT.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 13:00:44 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Rosenfeld", "Avi", ""], ["Illuz", "Ron", ""], ["Gottesman", "Dovid", ""], ["Last", "Mark", ""]]}, {"id": "1802.03275", "submitter": "Michael Ying Yang", "authors": "Oliver Mueller, Michael Ying Yang, Bodo Rosenhahn", "title": "Slice Sampling Particle Belief Propagation", "comments": "published in ICCV 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in continuous label Markov random fields is a challenging task. We\nuse particle belief propagation (PBP) for solving the inference problem in\ncontinuous label space. Sampling particles from the belief distribution is\ntypically done by using Metropolis-Hastings Markov chain Monte Carlo methods\nwhich involves sampling from a proposal distribution. This proposal\ndistribution has to be carefully designed depending on the particular model and\ninput data to achieve fast convergence. We propose to avoid dependence on a\nproposal distribution by introducing a slice sampling based PBP algorithm. The\nproposed approach shows superior convergence performance on an image denoising\ntoy example. Our findings are validated on a challenging relational 2D feature\ntracking application.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 14:27:58 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Mueller", "Oliver", ""], ["Yang", "Michael Ying", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1802.03318", "submitter": "Alexander Wong", "authors": "Audrey G. Chung, Paul Fieguth, and Alexander Wong", "title": "Nature vs. Nurture: The Role of Environmental Resources in Evolutionary\n  Deep Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary deep intelligence synthesizes highly efficient deep neural\nnetworks architectures over successive generations. Inspired by the nature\nversus nurture debate, we propose a study to examine the role of external\nfactors on the network synthesis process by varying the availability of\nsimulated environmental resources. Experimental results were obtained for\nnetworks synthesized via asexual evolutionary synthesis (1-parent) and sexual\nevolutionary synthesis (2-parent, 3-parent, and 5-parent) using a 10% subset of\nthe MNIST dataset. Results show that a lower environmental factor model\nresulted in a more gradual loss in performance accuracy and decrease in storage\nsize. This potentially allows significantly reduced storage size with minimal\nto no drop in performance accuracy, and the best networks were synthesized\nusing the lowest environmental factor models.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 15:58:58 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Chung", "Audrey G.", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1802.03375", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban", "title": "ATPboost: Learning Premise Selection in Binary Setting with ATP Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ATPboost is a system for solving sets of large-theory problems by\ninterleaving ATP runs with state-of-the-art machine learning of premise\nselection from the proofs. Unlike many previous approaches that use multi-label\nsetting, the learning is implemented as binary classification that estimates\nthe pairwise-relevance of (theorem, premise) pairs. ATPboost uses for this the\nXGBoost gradient boosting algorithm, which is fast and has state-of-the-art\nperformance on many tasks. Learning in the binary setting however requires\nnegative examples, which is nontrivial due to many alternative proofs. We\ndiscuss and implement several solutions in the context of the ATP/ML feedback\nloop, and show that ATPboost with such methods significantly outperforms the\nk-nearest neighbors multilabel classifier.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 18:29:26 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "1802.03390", "submitter": "Junkyung Kim", "authors": "Matthew Ricci, Junkyung Kim, Thomas Serre", "title": "Same-different problems strain convolutional neural networks", "comments": "6 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust and efficient recognition of visual relations in images is a\nhallmark of biological vision. We argue that, despite recent progress in visual\nrecognition, modern machine vision algorithms are severely limited in their\nability to learn visual relations. Through controlled experiments, we\ndemonstrate that visual-relation problems strain convolutional neural networks\n(CNNs). The networks eventually break altogether when rote memorization becomes\nimpossible, as when intra-class variability exceeds network capacity. Motivated\nby the comparable success of biological vision, we argue that feedback\nmechanisms including attention and perceptual grouping may be the key\ncomputational components underlying abstract visual reasoning.\\\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 18:55:34 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 22:29:20 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 17:00:23 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ricci", "Matthew", ""], ["Kim", "Junkyung", ""], ["Serre", "Thomas", ""]]}, {"id": "1802.03396", "submitter": "Bryan Gregory", "authors": "Bryan Gregory", "title": "Predicting Customer Churn: Extreme Gradient Boosting with Temporal Data", "comments": "WSDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting customer churn using large scale time-series data is a\ncommon problem facing many business domains. The creation of model features\nacross various time windows for training and testing can be particularly\nchallenging due to temporal issues common to time-series data. In this paper,\nwe will explore the application of extreme gradient boosting (XGBoost) on a\ncustomer dataset with a wide-variety of temporal features in order to create a\nhighly-accurate customer churn model. In particular, we describe an effective\nmethod for handling temporally sensitive feature engineering. The proposed\nmodel was submitted in the WSDM Cup 2018 Churn Challenge and achieved\nfirst-place out of 575 teams.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:24:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Gregory", "Bryan", ""]]}, {"id": "1802.03417", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac and Fabrice Larribe", "title": "Narrow Artificial Intelligence with Machine Learning for Real-Time\n  Estimation of a Mobile Agents Location Using Hidden Markov Models", "comments": null, "journal-ref": "International Journal of Computer Games Technology, vol. 2017,\n  Article ID 4939261, 10 pages, 2017", "doi": "10.1155/2017/4939261", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose to use a supervised machine learning technique to track the\nlocation of a mobile agent in real time. Hidden Markov Models are used to build\nartificial intelligence that estimates the unknown position of a mobile target\nmoving in a defined environment. This narrow artificial intelligence performs\ntwo distinct tasks. First, it provides real-time estimation of the mobile\nagent's position using the forward algorithm. Second, it uses the Baum-Welch\nalgorithm as a statistical learning tool to gain knowledge of the mobile\ntarget. Finally, an experimental environment is proposed, namely a video game\nthat we use to test our artificial intelligence. We present statistical and\ngraphical results to illustrate the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:18:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Larribe", "Fabrice", ""]]}, {"id": "1802.03471", "submitter": "Mathias Lecuyer", "authors": "Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu,\n  Suman Jana", "title": "Certified Robustness to Adversarial Examples with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples that fool machine learning models, particularly deep\nneural networks, have been a topic of intense research interest, with attacks\nand defenses being developed in a tight back-and-forth. Most past defenses are\nbest effort and have been shown to be vulnerable to sophisticated attacks.\nRecently a set of certified defenses have been introduced, which provide\nguarantees of robustness to norm-bounded attacks, but they either do not scale\nto large datasets or are limited in the types of models they can support. This\npaper presents the first certified defense that both scales to large networks\nand datasets (such as Google's Inception network for ImageNet) and applies\nbroadly to arbitrary model types. Our defense, called PixelDP, is based on a\nnovel connection between robustness against adversarial examples and\ndifferential privacy, a cryptographically-inspired formalism, that provides a\nrigorous, generic, and flexible foundation for defense.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 22:24:50 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 15:54:44 GMT"}, {"version": "v3", "created": "Sun, 7 Oct 2018 18:37:06 GMT"}, {"version": "v4", "created": "Wed, 29 May 2019 15:17:39 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Lecuyer", "Mathias", ""], ["Atlidakis", "Vaggelis", ""], ["Geambasu", "Roxana", ""], ["Hsu", "Daniel", ""], ["Jana", "Suman", ""]]}, {"id": "1802.03493", "submitter": "Yinlam Chow", "authors": "Mehrdad Farajtabar, Yinlam Chow, and Mohammad Ghavamzadeh", "title": "More Robust Doubly Robust Off-policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy evaluation (OPE) in reinforcement learning\n(RL), where the goal is to estimate the performance of a policy from the data\ngenerated by another policy(ies). In particular, we focus on the doubly robust\n(DR) estimators that consist of an importance sampling (IS) component and a\nperformance model, and utilize the low (or zero) bias of IS and low variance of\nthe model at the same time. Although the accuracy of the model has a huge\nimpact on the overall performance of DR, most of the work on using the DR\nestimators in OPE has been focused on improving the IS part, and not much on\nhow to learn the model. In this paper, we propose alternative DR estimators,\ncalled more robust doubly robust (MRDR), that learn the model parameter by\nminimizing the variance of the DR estimator. We first present a formulation for\nlearning the DR model in RL. We then derive formulas for the variance of the DR\nestimator in both contextual bandits and RL, such that their gradients\nw.r.t.~the model parameters can be estimated from the samples, and propose\nmethods to efficiently minimize the variance. We prove that the MRDR estimators\nare strongly consistent and asymptotically optimal. Finally, we evaluate MRDR\nin bandits and RL benchmark problems, and compare its performance with the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:32:03 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:13:43 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Chow", "Yinlam", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1802.03495", "submitter": "Zilong Zhong", "authors": "Zilong Zhong and Jonathan Li", "title": "Generative Adversarial Networks and Probabilistic Graph Models for\n  Hyperspectral Image Classification", "comments": "Accepted by AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High spectral dimensionality and the shortage of annotations make\nhyperspectral image (HSI) classification a challenging problem. Recent studies\nsuggest that convolutional neural networks can learn discriminative spatial\nfeatures, which play a paramount role in HSI interpretation. However, most of\nthese methods ignore the distinctive spectral-spatial characteristic of\nhyperspectral data. In addition, a large amount of unlabeled data remains an\nunexploited gold mine for efficient data use. Therefore, we proposed an\nintegration of generative adversarial networks (GANs) and probabilistic\ngraphical models for HSI classification. Specifically, we used a\nspectral-spatial generator and a discriminator to identify land cover\ncategories of hyperspectral cubes. Moreover, to take advantage of a large\namount of unlabeled data, we adopted a conditional random field to refine the\npreliminary classification results generated by GANs. Experimental results\nobtained using two commonly studied datasets demonstrate that the proposed\nframework achieved encouraging classification accuracy using a small number of\ndata for training.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:33:52 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Zhong", "Zilong", ""], ["Li", "Jonathan", ""]]}, {"id": "1802.03499", "submitter": "Chuanyun Xu Dr.", "authors": "Chuanyun Xu, Yang Zhang, Xin Feng, YongXing Ge, Yihao Zhang, Jianwu\n  Long", "title": "Local Contrast Learning", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a deep model from small data is yet an opening and challenging\nproblem. We focus on one-shot classification by deep learning approach based on\na small quantity of training samples. We proposed a novel deep learning\napproach named Local Contrast Learning (LCL) based on the key insight about a\nhuman cognitive behavior that human recognizes the objects in a specific\ncontext by contrasting the objects in the context or in her/his memory. LCL is\nused to train a deep model that can contrast the recognizing sample with a\ncouple of contrastive samples randomly drawn and shuffled. On one-shot\nclassification task on Omniglot, the deep model based LCL with 122 layers and\n1.94 millions of parameters, which was trained on a tiny dataset with only 60\nclasses and 20 samples per class, achieved the accuracy 97.99% that outperforms\nhuman and state-of-the-art established by Bayesian Program Learning (BPL)\ntrained on 964 classes. LCL is a fundamental idea which can be applied to\nalleviate parametric model's overfitting resulted by lack of training samples.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:54:44 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Xu", "Chuanyun", ""], ["Zhang", "Yang", ""], ["Feng", "Xin", ""], ["Ge", "YongXing", ""], ["Zhang", "Yihao", ""], ["Long", "Jianwu", ""]]}, {"id": "1802.03501", "submitter": "Yinlam Chow", "authors": "Ofir Nachum, Yinlam Chow, and Mohammad Ghavamzadeh", "title": "Path Consistency Learning in Tsallis Entropy Regularized MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sparse entropy-regularized reinforcement learning (ERL) problem\nin which the entropy term is a special form of the Tsallis entropy. The optimal\npolicy of this formulation is sparse, i.e.,~at each state, it has non-zero\nprobability for only a small number of actions. This addresses the main\ndrawback of the standard Shannon entropy-regularized RL (soft ERL) formulation,\nin which the optimal policy is softmax, and thus, may assign a non-negligible\nprobability mass to non-optimal actions. This problem is aggravated as the\nnumber of actions is increased. In this paper, we follow the work of Nachum et\nal. (2017) in the soft ERL setting, and propose a class of novel path\nconsistency learning (PCL) algorithms, called {\\em sparse PCL}, for the sparse\nERL problem that can work with both on-policy and off-policy data. We first\nderive a {\\em sparse consistency} equation that specifies a relationship\nbetween the optimal value function and policy of the sparse ERL along any\nsystem trajectory. Crucially, a weak form of the converse is also true, and we\nquantify the sub-optimality of a policy which satisfies sparse consistency, and\nshow that as we increase the number of actions, this sub-optimality is better\nthan that of the soft ERL optimal policy. We then use this result to derive the\nsparse PCL algorithms. We empirically compare sparse PCL with its soft\ncounterpart, and show its advantage, especially in problems with a large number\nof actions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 01:57:49 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Nachum", "Ofir", ""], ["Chow", "Yinlam", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1802.03544", "submitter": "Kyrylo Malakhov", "authors": "A.V. Palagin, N.G. Petrenko, V.Yu. Velychko, K.S. Malakhov, Yu.L.\n  Tikhonov", "title": "To the problem of \"The Instrumental complex for ontological engineering\n  purpose\" software system design", "comments": "in Russian; updated \"Bibliography\" section for correct identification\n  of references by the Google Scholar parser software; updated figures; 10\n  pages; 8 figures", "journal-ref": "Problems in programming, 2012, (2-3), pp.289-298. PROBLEMS IN\n  PROGRAMMING SCIENTIFIC JOURNAL , (2-3), pp.289-298", "doi": null, "report-no": null, "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The given work describes methodological principles of design instrumental\ncomplex of ontological purpose. Instrumental complex intends for the\nimplementation of the integrated information technologies automated build of\ndomain ontologies. Results focus on enhancing the effectiveness of the\nautomatic analysis and understanding of natural-language texts, building of\nknowledge description of subject areas (primarily in the area of science and\ntechnology) and for interdisciplinary research in conjunction with the solution\nof complex problems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 08:13:54 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 11:35:22 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""], ["Tikhonov", "Yu. L.", ""]]}, {"id": "1802.03638", "submitter": "Tommaso Soru", "authors": "Tommaso Soru and Andr\\'e Valdestilhas and Edgard Marx and Axel-Cyrille\n  Ngonga Ngomo", "title": "Beyond Markov Logic: Efficient Mining of Prediction Rules in Large\n  Graphs", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representations of large knowledge bases may comprise billions of\nedges. Usually built upon human-generated ontologies, several knowledge bases\ndo not feature declared ontological rules and are far from being complete.\nCurrent rule mining approaches rely on schemata or store the graph in-memory,\nwhich can be unfeasible for large graphs. In this paper, we introduce\nHornConcerto, an algorithm to discover Horn clauses in large graphs without the\nneed of a schema. Using a standard fact-based confidence score, we can mine\nclose Horn rules having an arbitrary body size. We show that our method can\noutperform existing approaches in terms of runtime and memory consumption and\nmine high-quality rules for the link prediction task, achieving\nstate-of-the-art results on a widely-used benchmark. Moreover, we find that\nrules alone can perform inference significantly faster than embedding-based\nmethods and achieve accuracies on link prediction comparable to\nresource-demanding approaches such as Markov Logic Networks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 18:46:54 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 13:48:30 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Soru", "Tommaso", ""], ["Valdestilhas", "Andr\u00e9", ""], ["Marx", "Edgard", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1802.03642", "submitter": "Krishnendu Chatterjee", "authors": "Krishnendu Chatterjee and Laurent Doyen", "title": "Graph Planning with Expected Finite Horizon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph planning gives rise to fundamental algorithmic questions such as\nshortest path, traveling salesman problem, etc. A classical problem in discrete\nplanning is to consider a weighted graph and construct a path that maximizes\nthe sum of weights for a given time horizon $T$. However, in many scenarios,\nthe time horizon is not fixed, but the stopping time is chosen according to\nsome distribution such that the expected stopping time is $T$. If the stopping\ntime distribution is not known, then to ensure robustness, the distribution is\nchosen by an adversary, to represent the worst-case scenario.\n  A stationary plan for every vertex always chooses the same outgoing edge. For\nfixed horizon or fixed stopping-time distribution, stationary plans are not\nsufficient for optimality. Quite surprisingly we show that when an adversary\nchooses the stopping-time distribution with expected stopping time $T$, then\nstationary plans are sufficient. While computing optimal stationary plans for\nfixed horizon is NP-complete, we show that computing optimal stationary plans\nunder adversarial stopping-time distribution can be achieved in polynomial\ntime. Consequently, our polynomial-time algorithm for adversarial stopping time\nalso computes an optimal plan among all possible plans.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 19:12:03 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Doyen", "Laurent", ""]]}, {"id": "1802.03654", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "Beyond the One Step Greedy Approach in Reinforcement Learning", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous Policy Iteration algorithm alternates between policy improvement\nand policy evaluation. Implementations of this algorithm with several variants\nof the latter evaluation stage, e.g, $n$-step and trace-based returns, have\nbeen analyzed in previous works. However, the case of multiple-step lookahead\npolicy improvement, despite the recent increase in empirical evidence of its\nstrength, has to our knowledge not been carefully analyzed yet. In this work,\nwe introduce the first such analysis. Namely, we formulate variants of\nmultiple-step policy improvement, derive new algorithms using these definitions\nand prove their convergence. Moreover, we show that recent prominent\nReinforcement Learning algorithms are, in fact, instances of our framework. We\nthus shed light on their empirical success and give a recipe for deriving new\nalgorithms for future study.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 22:22:03 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 17:19:20 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 18:02:11 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1802.03685", "submitter": "Daniel Selsam", "authors": "Daniel Selsam, Matthew Lamm, Benedikt B\\\"unz, Percy Liang, Leonardo de\n  Moura, David L. Dill", "title": "Learning a SAT Solver from Single-Bit Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NeuroSAT, a message passing neural network that learns to solve\nSAT problems after only being trained as a classifier to predict\nsatisfiability. Although it is not competitive with state-of-the-art SAT\nsolvers, NeuroSAT can solve problems that are substantially larger and more\ndifficult than it ever saw during training by simply running for more\niterations. Moreover, NeuroSAT generalizes to novel distributions; after\ntraining only on random SAT problems, at test time it can solve SAT problems\nencoding graph coloring, clique detection, dominating set, and vertex cover\nproblems, all on a range of distributions over small random graphs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 03:04:28 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 22:52:15 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 22:20:18 GMT"}, {"version": "v4", "created": "Tue, 12 Mar 2019 00:56:48 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Selsam", "Daniel", ""], ["Lamm", "Matthew", ""], ["B\u00fcnz", "Benedikt", ""], ["Liang", "Percy", ""], ["de Moura", "Leonardo", ""], ["Dill", "David L.", ""]]}, {"id": "1802.03691", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Chang Liu, Dawn Song", "title": "Tree-to-tree Neural Networks for Program Translation", "comments": "Published in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program translation is an important tool to migrate legacy code in one\nlanguage into an ecosystem built in a different language. In this work, we are\nthe first to employ deep neural networks toward tackling this problem. We\nobserve that program translation is a modular procedure, in which a sub-tree of\nthe source tree is translated into the corresponding target sub-tree at each\nstep. To capture this intuition, we design a tree-to-tree neural network to\ntranslate a source tree into a target one. Meanwhile, we develop an attention\nmechanism for the tree-to-tree model, so that when the decoder expands one\nnon-terminal in the target tree, the attention mechanism locates the\ncorresponding sub-tree in the source tree to guide the expansion of the\ndecoder. We evaluate the program translation capability of our tree-to-tree\nmodel against several state-of-the-art approaches. Compared against other\nneural translation models, we observe that our approach is consistently better\nthan the baselines with a margin of up to 15 points. Further, our approach can\nimprove the previous state-of-the-art program translation approaches by a\nmargin of 20 points on the translation of real-world projects.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 04:42:03 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:43:13 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 03:51:27 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Chen", "Xinyun", ""], ["Liu", "Chang", ""], ["Song", "Dawn", ""]]}, {"id": "1802.03701", "submitter": "Ankur Padia", "authors": "Sourish Dasgupta, Ankur Padia, Gaurav Maheshwari, Priyansh Trivedi,\n  Jens Lehmann", "title": "Formal Ontology Learning from English IS-A Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ontology learning (OL) is the process of automatically generating an\nontological knowledge base from a plain text document. In this paper, we\npropose a new ontology learning approach and tool, called DLOL, which generates\na knowledge base in the description logic (DL) SHOQ(D) from a collection of\nfactual non-negative IS-A sentences in English. We provide extensive\nexperimental results on the accuracy of DLOL, giving experimental comparisons\nto three state-of-the-art existing OL tools, namely Text2Onto, FRED, and LExO.\nHere, we use the standard OL accuracy measure, called lexical accuracy, and a\nnovel OL accuracy measure, called instance-based inference model. In our\nexperimental results, DLOL turns out to be about 21% and 46%, respectively,\nbetter than the best of the other three approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 06:41:54 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Dasgupta", "Sourish", ""], ["Padia", "Ankur", ""], ["Maheshwari", "Gaurav", ""], ["Trivedi", "Priyansh", ""], ["Lehmann", "Jens", ""]]}, {"id": "1802.03707", "submitter": "Andreas Holzinger", "authors": "Bernd Malle, Nicola Giuliani, Peter Kieseberg, Andreas Holzinger", "title": "The Need for Speed of AI Applications: Performance Comparison of Native\n  vs. Browser-based Algorithm Implementations", "comments": "21 Pages, Technical Report of the Holzinger Group", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI applications pose increasing demands on performance, so it is not\nsurprising that the era of client-side distributed software is becoming\nimportant. On top of many AI applications already using mobile hardware, and\neven browsers for computationally demanding AI applications, we are already\nwitnessing the emergence of client-side (federated) machine learning\nalgorithms, driven by the interests of large corporations and startups alike.\nApart from mathematical and algorithmic concerns, this trend especially demands\nnew levels of computational efficiency from client environments. Consequently,\nthis paper deals with the question of state-of-the-art performance by\npresenting a comparison study between native code and different browser-based\nimplementations: JavaScript, ASM.js as well as WebAssembly on a representative\nmix of algorithms. Our results show that current efforts in runtime\noptimization push the boundaries well towards (and even beyond) native binary\nperformance. We analyze the results obtained and speculate on the reasons\nbehind some surprises, rounding the paper off by outlining future possibilities\nas well as some of our own research efforts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 08:09:17 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Malle", "Bernd", ""], ["Giuliani", "Nicola", ""], ["Kieseberg", "Peter", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1802.03753", "submitter": "Pawe{\\l} Budzianowski", "authors": "Gell\\'ert Weisz, Pawe{\\l} Budzianowski, Pei-Hao Su, Milica Ga\\v{s}i\\'c", "title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 15:37:37 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1802.03774", "submitter": "Shiyu Duan", "authors": "Shiyu Duan, Shujian Yu, Yunmei Chen, Jose Principe", "title": "On Kernel Method-Based Connectionist Models and Supervised Deep Learning\n  Without Backpropagation", "comments": "8 pages main text, 16 pages of references and appendix, 2 figures", "journal-ref": "Neural Computation, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel family of connectionist models based on kernel machines\nand consider the problem of learning layer-by-layer a compositional hypothesis\nclass, i.e., a feedforward, multilayer architecture, in a supervised setting.\nIn terms of the models, we present a principled method to \"kernelize\" (partly\nor completely) any neural network (NN). With this method, we obtain a\ncounterpart of any given NN that is powered by kernel machines instead of\nneurons. In terms of learning, when learning a feedforward deep architecture in\na supervised setting, one needs to train all the components simultaneously\nusing backpropagation (BP) since there are no explicit targets for the hidden\nlayers (Rumelhart86). We consider without loss of generality the two-layer case\nand present a general framework that explicitly characterizes a target for the\nhidden layer that is optimal for minimizing the objective function of the\nnetwork. This characterization then makes possible a purely greedy training\nscheme that learns one layer at a time, starting from the input layer. We\nprovide realizations of the abstract framework under certain architectures and\nobjective functions. Based on these realizations, we present a layer-wise\ntraining algorithm for an l-layer feedforward network for classification, where\nl>=2 can be arbitrary. This algorithm can be given an intuitive geometric\ninterpretation that makes the learning dynamics transparent. Empirical results\nare provided to complement our theory. We show that the kernelized networks,\ntrained layer-wise, compare favorably with classical kernel machines as well as\nother connectionist models trained by BP. We also visualize the inner workings\nof the greedy kernelized models to validate our claim on the transparency of\nthe layer-wise algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 17:18:28 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 03:30:06 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 05:09:06 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2019 03:48:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Duan", "Shiyu", ""], ["Yu", "Shujian", ""], ["Chen", "Yunmei", ""], ["Principe", "Jose", ""]]}, {"id": "1802.03788", "submitter": "Klas Leino", "authors": "Klas Leino, Shayak Sen, Anupam Datta, Matt Fredrikson, Linyi Li", "title": "Influence-Directed Explanations for Deep Convolutional Networks", "comments": "To appear in International Test Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of explaining a rich class of behavioral properties of\ndeep neural networks. Distinctively, our influence-directed explanations\napproach this problem by peering inside the network to identify neurons with\nhigh influence on a quantity and distribution of interest, using an\naxiomatically-justified influence measure, and then providing an interpretation\nfor the concepts these neurons represent. We evaluate our approach by\ndemonstrating a number of its unique capabilities on convolutional neural\nnetworks trained on ImageNet. Our evaluation demonstrates that\ninfluence-directed explanations (1) identify influential concepts that\ngeneralize across instances, (2) can be used to extract the \"essence\" of what\nthe network learned about a class, and (3) isolate individual features the\nnetwork uses to make decisions and distinguish related classes.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 18:28:56 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 06:02:57 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Leino", "Klas", ""], ["Sen", "Shayak", ""], ["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""], ["Li", "Linyi", ""]]}, {"id": "1802.03855", "submitter": "Feichen Shen PhD", "authors": "Feichen Shen, Yugyung Lee", "title": "MedTQ: Dynamic Topic Discovery and Query Generation for Medical\n  Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biomedical ontology refers to a shared conceptualization for a biomedical\ndomain of interest that has vastly improved data management and data sharing\nthrough the open data movement. The rapid growth and availability of biomedical\ndata make it impractical and computationally expensive to perform manual\nanalysis and query processing with the large scale ontologies. The lack of\nability in analyzing ontologies from such a variety of sources, and supporting\nknowledge discovery for clinical practice and biomedical research should be\novercome with new technologies. In this study, we developed a Medical Topic\ndiscovery and Query generation framework (MedTQ), which was composed by a\nseries of approaches and algorithms. A predicate neighborhood pattern-based\napproach introduced has the ability to compute the similarity of predicates\n(relations) in ontologies. Given a predicate similarity metric, machine\nlearning algorithms have been developed for automatic topic discovery and query\ngeneration. The topic discovery algorithm, called the hierarchical K-Means\nalgorithm was designed by extending an existing supervised algorithm (K-means\nclustering) for the construction of a topic hierarchy. In the hierarchical\nK-Means algorithm, a level-by-level optimization strategy was selected for\nconsistent with the strongly association between elements within a topic.\nAutomatic query generation was facilitated for discovered topic that could be\nguided users for interactive query design and processing. Evaluation was\nconducted to generate topic hierarchy for DrugBank ontology as a case study.\nResults demonstrated that the MedTQ framework can enhance knowledge discovery\nby capturing underlying structures from domain specific data and ontologies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 01:22:10 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Shen", "Feichen", ""], ["Lee", "Yugyung", ""]]}, {"id": "1802.03875", "submitter": "Craig Atkinson", "authors": "Craig Atkinson, Brendan McCane, Lech Szymanski, Anthony Robins", "title": "Pseudo-Recursal: Solving the Catastrophic Forgetting Problem in Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, neural networks are not currently capable of learning tasks in a\nsequential fashion. When a novel, unrelated task is learnt by a neural network,\nit substantially forgets how to solve previously learnt tasks. One of the\noriginal solutions to this problem is pseudo-rehearsal, which involves learning\nthe new task while rehearsing generated items representative of the previous\ntask/s. This is very effective for simple tasks. However, pseudo-rehearsal has\nnot yet been successfully applied to very complex tasks because in these tasks\nit is difficult to generate representative items. We accomplish\npseudo-rehearsal by using a Generative Adversarial Network to generate items so\nthat our deep network can learn to sequentially classify the CIFAR-10, SVHN and\nMNIST datasets. After training on all tasks, our network loses only 1.67%\nabsolute accuracy on CIFAR-10 and gains 0.24% absolute accuracy on SVHN. Our\nmodel's performance is a substantial improvement compared to the current state\nof the art solution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 03:51:41 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 01:42:04 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Atkinson", "Craig", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Robins", "Anthony", ""]]}, {"id": "1802.03881", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Yu-Jung Heo, Byoung-Tak Zhang", "title": "Answerer in Questioner's Mind: Information Theoretic Approach to\n  Goal-Oriented Visual Dialog", "comments": "Selected for a spotlight presentation at NIPS, 2018. Camera ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialog has been given attention due to its numerous\napplications in artificial intelligence. Goal-oriented dialogue tasks occur\nwhen a questioner asks an action-oriented question and an answerer responds\nwith the intent of letting the questioner know a correct action to take. To ask\nthe adequate question, deep learning and reinforcement learning have been\nrecently applied. However, these approaches struggle to find a competent\nrecurrent neural questioner, owing to the complexity of learning a series of\nsentences. Motivated by theory of mind, we propose \"Answerer in Questioner's\nMind\" (AQM), a novel information theoretic algorithm for goal-oriented dialog.\nWith AQM, a questioner asks and infers based on an approximated probabilistic\nmodel of the answerer. The questioner figures out the answerer's intention via\nselecting a plausible question by explicitly calculating the information gain\nof the candidate intentions and possible answers to each question. We test our\nframework on two goal-oriented visual dialog tasks: \"MNIST Counting Dialog\" and\n\"GuessWhat?!\". In our experiments, AQM outperforms comparative algorithms by a\nlarge margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:08:06 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 07:31:24 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 05:07:23 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1802.03916", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Yu-Xiang Wang, Alex Smola", "title": "Detecting and Correcting for Label Shift with Black Box Predictors", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with distribution shift between training and test set, we wish to\ndetect and quantify the shift, and to correct our classifiers without test set\nlabels. Motivated by medical diagnosis, where diseases (targets) cause symptoms\n(observations), we focus on label shift, where the label marginal $p(y)$\nchanges but the conditional $p(x| y)$ does not. We propose Black Box Shift\nEstimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits\narbitrary black box predictors to reduce dimensionality prior to shift\ncorrection. While better predictors give tighter estimates, BBSE works even\nwhen predictors are biased, inaccurate, or uncalibrated, so long as their\nconfusion matrices are invertible. We prove BBSE's consistency, bound its\nerror, and introduce a statistical test that uses BBSE to detect shift. We also\nleverage BBSE to correct classifiers. Experiments demonstrate accurate\nestimates and improved prediction, even on high-dimensional datasets of natural\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 07:16:03 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 17:23:51 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 12:51:37 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Wang", "Yu-Xiang", ""], ["Smola", "Alex", ""]]}, {"id": "1802.03930", "submitter": "Pengfei Zhang", "authors": "Yadong Wu, Pengfei Zhang, Huitao Shen and Hui Zhai", "title": "Visualizing Neural Network Developing Perturbation Theory", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. A 98, 010701 (2018)", "doi": "10.1103/PhysRevA.98.010701", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.quant-gas cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, motivated by the question that whether the empirical fitting\nof data by neural network can yield the same structure of physical laws, we\napply the neural network to a simple quantum mechanical two-body scattering\nproblem with short-range potentials, which by itself also plays an important\nrole in many branches of physics. We train a neural network to accurately\npredict $ s $-wave scattering length, which governs the low-energy scattering\nphysics, directly from the scattering potential without solving Schr\\\"odinger\nequation or obtaining the wavefunction. After analyzing the neural network, it\nis shown that the neural network develops perturbation theory order by order\nwhen the potential increases. This provides an important benchmark to the\nmachine-assisted physics research or even automated machine learning physics\nlaws.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 08:25:55 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 21:46:23 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wu", "Yadong", ""], ["Zhang", "Pengfei", ""], ["Shen", "Huitao", ""], ["Zhai", "Hui", ""]]}, {"id": "1802.03976", "submitter": "Mohammed Amin Abdullah Dr", "authors": "Mohammed Amin Abdullah, Aldo Pacchiano, Moez Draief", "title": "Reinforcement Learning with Wasserstein Distance Regularisation, with\n  Applications to Multipolicy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an application of Wasserstein distance to Reinforcement Learning.\nThe Wasserstein distance in question is between the distribution of mappings of\ntrajectories of a policy into some metric space, and some other fixed\ndistribution (which may, for example, come from another policy). Different\npolicies induce different distributions, so given an underlying metric, the\nWasserstein distance quantifies how different policies are. This can be used to\nlearn multiple polices which are different in terms of such Wasserstein\ndistances by using a Wasserstein regulariser. Changing the sign of the\nregularisation parameter, one can learn a policy for which its trajectory\nmapping distribution is attracted to a given fixed distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 11:08:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 23:09:21 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Abdullah", "Mohammed Amin", ""], ["Pacchiano", "Aldo", ""], ["Draief", "Moez", ""]]}, {"id": "1802.04007", "submitter": "Zarathustra Amadeus Goertzel", "authors": "Zarathustra Goertzel (1), Jan Jakub\\r{u}v (1), Stephan Schulz (2),\n  Josef Urban (1) ((1) Czech Technical University in Prague, (2) DHBW\n  Stuttgart)", "title": "ProofWatch: Watchlist Guidance for Large Theories in E", "comments": "19 pages, 10 tables, submitted to ITP 2018 at FLOC", "journal-ref": null, "doi": "10.1007/978-3-319-94821-8_16", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watchlist (also hint list) is a mechanism that allows related proofs to guide\na proof search for a new conjecture. This mechanism has been used with the\nOtter and Prover9 theorem provers, both for interactive formalizations and for\nhuman-assisted proving of open conjectures in small theories. In this work we\nexplore the use of watchlists in large theories coming from first-order\ntranslations of large ITP libraries, aiming at improving hammer-style\nautomation by smarter internal guidance of the ATP systems. In particular, we\n(i) design watchlist-based clause evaluation heuristics inside the E ATP\nsystem, and (ii) develop new proof guiding algorithms that load many previous\nproofs inside the ATP and focus the proof search using a dynamically updated\nnotion of proof matching. The methods are evaluated on a large set of problems\ncoming from the Mizar library, showing significant improvement of E's standard\nportfolio of strategies, and also of the previous best set of strategies\ninvented for Mizar by evolutionary methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 12:38:55 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 10:43:49 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Goertzel", "Zarathustra", ""], ["Jakub\u016fv", "Jan", ""], ["Schulz", "Stephan", ""], ["Urban", "Josef", ""]]}, {"id": "1802.04009", "submitter": "Yuan Jin", "authors": "Yuan Jin, Mark Carman, Ye Zhu, Wray Buntine", "title": "Distinguishing Question Subjectivity from Difficulty for Improved\n  Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The questions in a crowdsourcing task typically exhibit varying degrees of\ndifficulty and subjectivity. Their joint effects give rise to the variation in\nresponses to the same question by different crowd-workers. This variation is\nlow when the question is easy to answer and objective, and high when it is\ndifficult and subjective. Unfortunately, current quality control methods for\ncrowdsourcing consider only the question difficulty to account for the\nvariation. As a result,these methods cannot distinguish workers personal\npreferences for different correct answers of a partially subjective question\nfrom their ability/expertise to avoid objectively wrong answers for that\nquestion. To address this issue, we present a probabilistic model which (i)\nexplicitly encodes question difficulty as a model parameter and (ii) implicitly\nencodes question subjectivity via latent preference factors for crowd-workers.\nWe show that question subjectivity induces grouping of crowd-workers, revealed\nthrough clustering of their latent preferences. Moreover, we develop a\nquantitative measure of the subjectivity of a question. Experiments show that\nour model(1) improves the performance of both quality control for crowd-sourced\nanswers and next answer prediction for crowd-workers,and (2) can potentially\nprovide coherent rankings of questions in terms of their difficulty and\nsubjectivity, so that task providers can refine their designs of the\ncrowdsourcing tasks, e.g. by removing highly subjective questions or\ninappropriately difficult questions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 12:39:28 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 04:44:00 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Jin", "Yuan", ""], ["Carman", "Mark", ""], ["Zhu", "Ye", ""], ["Buntine", "Wray", ""]]}, {"id": "1802.04030", "submitter": "Giacomo Kahn", "authors": "Giacomo Kahn (LIMOS), Alexandre Bazin (LIMOS)", "title": "Introducer Concepts in n-Dimensional Contexts", "comments": "ICCS, Jun 2018, Edinburgh, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept lattices are well-known conceptual structures that organise\ninteresting patterns-the concepts-extracted from data. In some applications,\nsuch as software engineering or data mining, the size of the lattice can be a\nproblem, as it is often too large to be efficiently computed, and too complex\nto be browsed. For this reason, the Galois Sub-Hierarchy, a restriction of the\nconcept lattice to introducer concepts, has been introduced as a smaller\nalternative. In this paper, we generalise the Galois Sub-Hierarchy to\nn-lattices, conceptual structures obtained from multidimensional data in the\nsame way that concept lattices are obtained from binary relations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:29:46 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kahn", "Giacomo", "", "LIMOS"], ["Bazin", "Alexandre", "", "LIMOS"]]}, {"id": "1802.04032", "submitter": "Giacomo Kahn", "authors": "Giacomo Kahn (LIMOS), Alexandre Bazin (Le2i)", "title": "Average Size of Implicational Bases", "comments": "CLA, Jun 2018, Olomouc, Czech Republic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DB math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicational bases are objects of interest in formal concept analysis and\nits applications. Unfortunately, even the smallest base, the Duquenne-Guigues\nbase, has an exponential size in the worst case. In this paper, we use results\non the average number of minimal transversals in random hypergraphs to show\nthat the base of proper premises is, on average, of quasi-polynomial size.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:31:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kahn", "Giacomo", "", "LIMOS"], ["Bazin", "Alexandre", "", "Le2i"]]}, {"id": "1802.04086", "submitter": "Evangelos Michelioudakis", "authors": "Elias Alevizos, Alexander Artikis, Nikos Katzouris, Evangelos\n  Michelioudakis, Georgios Paliouras", "title": "The Complex Event Recognition Group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Complex Event Recognition (CER) group is a research team, affiliated with\nthe National Centre of Scientific Research \"Demokritos\" in Greece. The CER\ngroup works towards advanced and efficient methods for the recognition of\ncomplex events in a multitude of large, heterogeneous and interdependent data\nstreams. Its research covers multiple aspects of complex event recognition,\nfrom efficient detection of patterns on event streams to handling uncertainty\nand noise in streams, and machine learning techniques for inferring interesting\npatterns. Lately, it has expanded to methods for forecasting the occurrence of\nevents. It was founded in 2009 and currently hosts 3 senior researchers, 5 PhD\nstudents and works regularly with under-graduate students.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:54:30 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Alevizos", "Elias", ""], ["Artikis", "Alexander", ""], ["Katzouris", "Nikos", ""], ["Michelioudakis", "Evangelos", ""], ["Paliouras", "Georgios", ""]]}, {"id": "1802.04093", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Reasoning in a Hierarchical System with Missing Group Size Information", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper analyzes the problem of judgments or preferences subsequent to\ninitial analysis by autonomous agents in a hierarchical system where the higher\nlevel agents does not have access to group size information. We propose methods\nthat reduce instances of preference reversal of the kind encountered in\nSimpson's paradox.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 23:08:31 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1802.04095", "submitter": "Tevfik Bulut Industry and Technology Specialist", "authors": "Tevfik Bulut", "title": "A New Multi Criteria Decision Making Method: Approach of Logarithmic\n  Concept (APLOCO)", "comments": "19 pages", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol.9, No.1, January 2018. p.15-33", "doi": "10.5121/ijaia.2018.9102", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary aim of the study is to introduce APLOCO method which is developed\nfor the solution of multicriteria decision making problems both theoretically\nand practically. In this context, application subject of APLACO constitutes\nevaluation of investment potential of different cities in metropolitan status\nin Turkey. The secondary purpose of the study is to identify the independent\nvariables affecting the factories in the operating phase and to estimate the\neffect levels of independent variables on the dependent variable in the\norganized industrial zones (OIZs), whose mission is to reduce regional\ndevelopment disparities and to mobilize local production dynamics. For this\npurpose, the effect levels of independent variables on dependent variables have\nbeen determined using the multilayer perceptron (MLP) method, which has a wide\nuse in artificial neural networks (ANNs). The effect levels derived from MLP\nhave been then used as the weight levels of the decision criteria in APLOCO.\nThe independent variables included in MLP are also used as the decision\ncriteria in APLOCO. According to the results obtained from APLOCO, Istanbul\ncity is the best alternative in term of the investment potential and other\nalternatives are Manisa, Denizli, Izmir, Kocaeli, Bursa, Ankara, Adana, and\nAntalya, respectively. Although APLOCO is used to solve the ranking problem in\norder to show application process in the paper, it can be employed easily in\nthe solution of classification and selection problems. On the other hand, the\nstudy also shows a rare example of the nested usage of APLOCO which is one of\nthe methods of operation research as well as MLP used in determination of\nweights.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 20:19:34 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Bulut", "Tevfik", ""]]}, {"id": "1802.04127", "submitter": "Arif G\\\"ursoy", "authors": "Necla Kircali Gursoy, Ibrahim Senturk, Tahsin Oner, Arif Gursoy", "title": "A New Algorithmic Decision for Categorical Syllogisms via Caroll's\n  Diagrams", "comments": null, "journal-ref": null, "doi": "10.1007/s00500-019-04598-9", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with a calculus system SLCD (Syllogistic Logic with\nCarroll Diagrams), which gives a formal approach to logical reasoning with\ndiagrams, for representations of the fundamental Aristotelian categorical\npropositions and show that they are closed under the syllogistic criterion of\ninference which is the deletion of middle term. Therefore, it is implemented to\nlet the formalism comprise synchronically bilateral and trilateral\ndiagrammatical appearance and a naive algorithmic nature. And also, there is no\nneed specific knowledge or exclusive ability to understand as well as to use\nit. Consequently, we give an effective algorithm used to determine whether a\nsyllogistic reasoning valid or not by using SLCD.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 11:29:59 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 11:17:01 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 06:25:46 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 09:36:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Gursoy", "Necla Kircali", ""], ["Senturk", "Ibrahim", ""], ["Oner", "Tahsin", ""], ["Gursoy", "Arif", ""]]}, {"id": "1802.04181", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Natalia D\\'iaz-Rodr\\'iguez, Jean-Fran\\c{c}ois\n  Goudou, David Filliat", "title": "State Representation Learning for Control: An Overview", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2018.07.006", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning algorithms are designed to learn abstract features\nthat characterize data. State representation learning (SRL) focuses on a\nparticular kind of representation learning where learned features are in low\ndimension, evolve through time, and are influenced by actions of an agent. The\nrepresentation is learned to capture the variation in the environment generated\nby the agent's actions; this kind of representation is particularly suitable\nfor robotics and control scenarios. In particular, the low dimension\ncharacteristic of the representation helps to overcome the curse of\ndimensionality, provides easier interpretation and utilization by humans and\ncan help improve performance and speed in policy learning algorithms such as\nreinforcement learning.\n  This survey aims at covering the state-of-the-art on state representation\nlearning in the most recent years. It reviews different SRL methods that\ninvolve interaction with the environment, their implementations and their\napplications in robotics control tasks (simulated or real). In particular, it\nhighlights how generic learning objectives are differently exploited in the\nreviewed algorithms. Finally, it discusses evaluation methods to assess the\nrepresentation learned and summarizes current and future lines of research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 16:53:48 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 13:52:23 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Goudou", "Jean-Fran\u00e7ois", ""], ["Filliat", "David", ""]]}, {"id": "1802.04205", "submitter": "Ajinkya Jain", "authors": "Ajinkya Jain and Scott Niekum", "title": "Efficient Hierarchical Robot Motion Planning Under Uncertainty and\n  Hybrid Dynamics", "comments": "2nd Conference on Robot Learning (CoRL 2018), Zurich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy observations coupled with nonlinear dynamics pose one of the biggest\nchallenges in robot motion planning. By decomposing nonlinear dynamics into a\ndiscrete set of local dynamics models, hybrid dynamics provide a natural way to\nmodel nonlinear dynamics, especially in systems with sudden discontinuities in\ndynamics due to factors such as contacts. We propose a hierarchical POMDP\nplanner that develops cost-optimized motion plans for hybrid dynamics models.\nThe hierarchical planner first develops a high-level motion plan to sequence\nthe local dynamics models to be visited and then converts it into a detailed\ncontinuous state plan. This hierarchical planning approach results in a\ndecomposition of the POMDP planning problem into smaller sub-parts that can be\nsolved with significantly lower computational costs. The ability to sequence\nthe visitation of local dynamics models also provides a powerful way to\nleverage the hybrid dynamics to reduce state uncertainty. We evaluate the\nproposed planner on a navigation task in the simulated domain and on an\nassembly task with a robotic manipulator, showing that our approach can solve\ntasks having high observation noise and nonlinear dynamics effectively with\nsignificantly lower computational costs compared to direct planning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 17:47:13 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 18:51:05 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 23:42:37 GMT"}, {"version": "v4", "created": "Mon, 8 Oct 2018 19:45:10 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Jain", "Ajinkya", ""], ["Niekum", "Scott", ""]]}, {"id": "1802.04240", "submitter": "Mohammadreza Nazari", "authors": "Mohammadreza Nazari, Afshin Oroojlooy, Lawrence V. Snyder, Martin\n  Tak\\'a\\v{c}", "title": "Reinforcement Learning for Solving the Vehicle Routing Problem", "comments": "more results and illustrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end framework for solving the Vehicle Routing Problem\n(VRP) using reinforcement learning. In this approach, we train a single model\nthat finds near-optimal solutions for problem instances sampled from a given\ndistribution, only by observing the reward signals and following feasibility\nrules. Our model represents a parameterized stochastic policy, and by applying\na policy gradient algorithm to optimize its parameters, the trained model\nproduces the solution as a sequence of consecutive actions in real time,\nwithout the need to re-train for every new problem instance. On capacitated\nVRP, our approach outperforms classical heuristics and Google's OR-Tools on\nmedium-sized instances in solution quality with comparable computation time\n(after training). We demonstrate how our approach can handle problems with\nsplit delivery and explore the effect of such deliveries on the solution\nquality. Our proposed framework can be applied to other variants of the VRP\nsuch as the stochastic VRP, and has the potential to be applied more generally\nto combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:41:57 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 18:25:38 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Nazari", "Mohammadreza", ""], ["Oroojlooy", "Afshin", ""], ["Snyder", "Lawrence V.", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1802.04253", "submitter": "Chengliang Yang", "authors": "Chengliang Yang, Anand Rangarajan, Sanjay Ranka", "title": "Global Model Interpretation via Recursive Partitioning", "comments": "Accepted by The 4th IEEE International Conference on Data Science and\n  Systems (DSS-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a simple but effective method to interpret black-box\nmachine learning models globally. That is, we use a compact binary tree, the\ninterpretation tree, to explicitly represent the most important decision rules\nthat are implicitly contained in the black-box machine learning models. This\ntree is learned from the contribution matrix which consists of the\ncontributions of input variables to predicted scores for each single\nprediction. To generate the interpretation tree, a unified process recursively\npartitions the input variable space by maximizing the difference in the average\ncontribution of the split variable between the divided spaces. We demonstrate\nthe effectiveness of our method in diagnosing machine learning models on\nmultiple tasks. Also, it is useful for new knowledge discovery as such insights\nare not easily identifiable when only looking at single predictions. In\ngeneral, our work makes it easier and more efficient for human beings to\nunderstand machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 00:24:32 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 04:05:40 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Yang", "Chengliang", ""], ["Rangarajan", "Anand", ""], ["Ranka", "Sanjay", ""]]}, {"id": "1802.04289", "submitter": "Sneha Kudugunta", "authors": "Sneha Kudugunta, Emilio Ferrara", "title": "Deep Neural Networks for Bot Detection", "comments": null, "journal-ref": "Information Sciences, Volume 467, October 2018, Pages 312-322,\n  2018", "doi": "10.1016/j.ins.2018.08.019", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting bots, automated social media accounts governed by\nsoftware but disguising as human users, has strong implications. For example,\nbots have been used to sway political elections by distorting online discourse,\nto manipulate the stock market, or to push anti-vaccine conspiracy theories\nthat caused health epidemics. Most techniques proposed to date detect bots at\nthe account level, by processing large amount of social media posts, and\nleveraging information from network structure, temporal dynamics, sentiment\nanalysis, etc.\n  In this paper, we propose a deep neural network based on contextual long\nshort-term memory (LSTM) architecture that exploits both content and metadata\nto detect bots at the tweet level: contextual features are extracted from user\nmetadata and fed as auxiliary input to LSTM deep nets processing the tweet\ntext.\n  Another contribution that we make is proposing a technique based on synthetic\nminority oversampling to generate a large labeled dataset, suitable for deep\nnets training, from a minimal amount of labeled data (roughly 3,000 examples of\nsophisticated Twitter bots). We demonstrate that, from just one single tweet,\nour architecture can achieve high classification accuracy (AUC > 96%) in\nseparating bots from humans.\n  We apply the same architecture to account-level bot detection, achieving\nnearly perfect classification accuracy (AUC > 99%). Our system outperforms\nprevious state of the art while leveraging a small and interpretable set of\nfeatures yet requiring minimal training data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:00:15 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 05:15:16 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Kudugunta", "Sneha", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1802.04325", "submitter": "Dane Corneil", "authors": "Dane Corneil, Wulfram Gerstner and Johanni Brea", "title": "Efficient Model-Based Deep Reinforcement Learning with Variational State\n  Tabulation", "comments": "Accepted at ICML 2018; camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern reinforcement learning algorithms reach super-human performance on\nmany board and video games, but they are sample inefficient, i.e. they\ntypically require significantly more playing experience than humans to reach an\nequal performance level. To improve sample efficiency, an agent may build a\nmodel of the environment and use planning methods to update its policy. In this\narticle we introduce Variational State Tabulation (VaST), which maps an\nenvironment with a high-dimensional state space (e.g. the space of visual\ninputs) to an abstract tabular model. Prioritized sweeping with small backups,\na highly efficient planning method, can then be used to update state-action\nvalues. We show how VaST can rapidly learn to maximize reward in tasks like 3D\nnavigation and efficiently adapt to sudden changes in rewards or transition\nprobabilities.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:38:44 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 15:27:18 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Corneil", "Dane", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1802.04335", "submitter": "Illia Polosukhin", "authors": "Illia Polosukhin, Alexander Skidanov", "title": "Neural Program Search: Solving Programming Tasks from Description and\n  Examples", "comments": "9 pages, 3 figures, ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Neural Program Search, an algorithm to generate programs from\nnatural language description and a small number of input/output examples. The\nalgorithm combines methods from Deep Learning and Program Synthesis fields by\ndesigning rich domain-specific language (DSL) and defining efficient search\nalgorithm guided by a Seq2Tree model on it. To evaluate the quality of the\napproach we also present a semi-synthetic dataset of descriptions with test\nexamples and corresponding programs. We show that our algorithm significantly\noutperforms a sequence-to-sequence model with attention baseline.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:05:26 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Polosukhin", "Illia", ""], ["Skidanov", "Alexander", ""]]}, {"id": "1802.04337", "submitter": "Sridhar Chimalakonda", "authors": "Sridhar Chimalakonda, Kesav V. Nori", "title": "An Ontology Based Modeling Framework for Design of Educational\n  Technologies", "comments": "Preprint Submitted to International Journal of Artificial\n  Intelligence in Education, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid progress, most of the educational technologies today lack a\nstrong instructional design knowledge basis leading to questionable quality of\ninstruction. In addition, a major challenge is to customize these educational\ntechnologies for a wide range of instructional designs. Ontologies are one of\nthe pertinent mechanisms to represent instructional design in the literature.\nHowever, existing approaches do not support modeling of flexible instructional\ndesigns. To address this problem, in this paper, we propose an ontology based\nframework for systematic modeling of different aspects of instructional design\nknowledge based on domain patterns. As part of the framework, we present\nontologies for modeling goals, instructional processes and instructional\nmaterials. We demonstrate the ontology framework by presenting instances of the\nontology for the large scale case study of adult literacy in India (287 million\nlearners spread across 22 Indian Languages), which requires creation of 1000\nsimilar but varied eLearning Systems based on flexible instructional designs.\nThe implemented framework is available at http://rice.iiit.ac.in and is\ntransferred to National Literacy Mission of Government of India. This framework\ncould be used for modeling instructional design knowledge of systems for\nskills, school education and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 23:57:44 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Chimalakonda", "Sridhar", ""], ["Nori", "Kesav V.", ""]]}, {"id": "1802.04394", "submitter": "Jianshu Chen", "authors": "Yelong Shen, Jianshu Chen, Po-Sen Huang, Yuqing Guo, Jianfeng Gao", "title": "M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search", "comments": "Yelong Shen, Jianshu Chen and Po-Sen Huang contributed equally to the\n  paper. Published at 32nd Conference on Neural Information Processing Systems\n  (NeurIPS 2018), Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to walk over a graph towards a target node for a given query and a\nsource node is an important problem in applications such as knowledge base\ncompletion (KBC). It can be formulated as a reinforcement learning (RL) problem\nwith a known state transition model. To overcome the challenge of sparse\nrewards, we develop a graph-walking agent called M-Walk, which consists of a\ndeep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN\nencodes the state (i.e., history of the walked path) and maps it separately to\na policy and Q-values. In order to effectively train the agent from sparse\nrewards, we combine MCTS with the neural policy to generate trajectories\nyielding more positive rewards. From these trajectories, the network is\nimproved in an off-policy manner using Q-learning, which modifies the RNN\npolicy via parameter sharing. Our proposed RL algorithm repeatedly applies this\npolicy-improvement step to learn the model. At test time, MCTS is combined with\nthe neural policy to predict the target node. Experimental results on several\ngraph-walking benchmarks show that M-Walk is able to learn better policies than\nother RL-based methods, which are mainly based on policy gradients. M-Walk also\noutperforms traditional KBC baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:27:23 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 21:02:01 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 00:19:45 GMT"}, {"version": "v4", "created": "Wed, 28 Nov 2018 19:16:36 GMT"}, {"version": "v5", "created": "Tue, 18 Dec 2018 17:43:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Shen", "Yelong", ""], ["Chen", "Jianshu", ""], ["Huang", "Po-Sen", ""], ["Guo", "Yuqing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1802.04397", "submitter": "Bryon Aragam", "authors": "Bryon Aragam, Chen Dan, Eric P. Xing, Pradeep Ravikumar", "title": "Identifiability of Nonparametric Mixture Models and Bayes Optimal\n  Clustering", "comments": "35 pages, to appear in the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable, by\nintroducing a novel framework involving clustering overfitted \\emph{parametric}\n(i.e. misspecified) mixture models. These identifiability conditions generalize\nexisting conditions in the literature, and are flexible enough to include for\nexample mixtures of Gaussian mixtures. In contrast to the recent literature on\nestimating nonparametric mixtures, we allow for general nonparametric mixture\ncomponents, and instead impose regularity assumptions on the underlying mixing\nmeasure. As our primary application, we apply these results to partition-based\nclustering, generalizing the notion of a Bayes optimal partition from classical\nparametric model-based clustering to nonparametric settings. Furthermore, this\nframework is constructive so that it yields a practical algorithm for learning\nidentified mixtures, which is illustrated through several examples on real\ndata. The key conceptual device in the analysis is the convex, metric geometry\nof probability measures on metric spaces and its connection to the Wasserstein\nconvergence of mixing measures. The result is a flexible framework for\nnonparametric clustering with formal consistency guarantees.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 23:53:52 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 16:20:25 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 20:31:51 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 03:52:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Aragam", "Bryon", ""], ["Dan", "Chen", ""], ["Xing", "Eric P.", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1802.04403", "submitter": "Haque Ishfaq", "authors": "Haque Ishfaq, Assaf Hoogi and Daniel Rubin", "title": "TVAE: Triplet-Based Variational Autoencoder using Metric Learning", "comments": "After submission, we realized that our work is very similar to work\n  done in \"Bayesian representation learning with oracle constraints\" by\n  Karaletsos et al (arXiv:1506.05011). This paper somehow didn't come into our\n  notice earlier and now that we know the idea we presented in our paper was\n  already explored there, we decided to withdraw our paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning has been demonstrated to be highly effective in learning\nsemantic representation and encoding information that can be used to measure\ndata similarity, by relying on the embedding learned from metric learning. At\nthe same time, variational autoencoder (VAE) has widely been used to\napproximate inference and proved to have a good performance for directed\nprobabilistic models. However, for traditional VAE, the data label or feature\ninformation are intractable. Similarly, traditional representation learning\napproaches fail to represent many salient aspects of the data. In this project,\nwe propose a novel integrated framework to learn latent embedding in VAE by\nincorporating deep metric learning. The features are learned by optimizing a\ntriplet loss on the mean vectors of VAE in conjunction with standard evidence\nlower bound (ELBO) of VAE. This approach, which we call Triplet based\nVariational Autoencoder (TVAE), allows us to capture more fine-grained\ninformation in the latent embedding. Our model is tested on MNIST data set and\nachieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &\nWelling, 2013) achieves triplet accuracy of 75.08%.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:05:19 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 15:31:47 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ishfaq", "Haque", ""], ["Hoogi", "Assaf", ""], ["Rubin", "Daniel", ""]]}, {"id": "1802.04408", "submitter": "Jeevana Priya Inala", "authors": "Jeevana Priya Inala, Sicun Gao, Soonho Kong and Armando Solar-Lezama", "title": "REAS: Combining Numerical Optimization with SAT Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present ReaS, a technique that combines numerical\noptimization with SAT solving to synthesize unknowns in a program that involves\ndiscrete and floating point computation. ReaS makes the program end-to-end\ndifferentiable by smoothing any Boolean expression that introduces\ndiscontinuity such as conditionals and relaxing the Boolean unknowns so that\nnumerical optimization can be performed. On top of this, ReaS uses a SAT solver\nto help the numerical search overcome local solutions by incrementally fixing\nvalues to the Boolean expressions. We evaluated the approach on 5 case studies\ninvolving hybrid systems and show that ReaS can synthesize programs that could\nnot be solved by previous SMT approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:29:31 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Inala", "Jeevana Priya", ""], ["Gao", "Sicun", ""], ["Kong", "Soonho", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1802.04412", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli and Animashree Anandkumar", "title": "Efficient Exploration through Bayesian Deep Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) in high dimensional episodic Markov\ndecision processes (MDP). We consider value-based RL when the optimal Q-value\nis a linear function of d-dimensional state-action feature representation. For\ninstance, in deep-Q networks (DQN), the Q-value is a linear function of the\nfeature representation layer (output layer). We propose two algorithms, one\nbased on optimism, LINUCB, and another based on posterior sampling, LINPSRL. We\nguarantee frequentist and Bayesian regret upper bounds of O(d sqrt{T}) for\nthese two algorithms, where T is the number of episodes. We extend these\nmethods to deep RL and propose Bayesian deep Q-networks (BDQN), which uses an\nefficient Thompson sampling algorithm for high dimensional RL. We deploy the\ndouble DQN (DDQN) approach, and instead of learning the last layer of Q-network\nusing linear regression, we use Bayesian linear regression, resulting in an\napproximated posterior over Q-function. This allows us to directly incorporate\nthe uncertainty over the Q-function and deploy Thompson sampling on the learned\nposterior distribution resulting in efficient exploration/exploitation\ntrade-off. We empirically study the behavior of BDQN on a wide range of Atari\ngames. Since BDQN carries out more efficient exploration and exploitation, it\nis able to reach higher return substantially faster compared to DDQN.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 00:48:17 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 03:26:22 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 18:44:40 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 20:54:19 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1802.04425", "submitter": "Hannah Morrison", "authors": "Hannah Morrison and Chris Martens", "title": "\"How Was Your Weekend?\" A Generative Model of Phatic Conversation", "comments": "Accepted submission at FLAIRS-31", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unspoken social rules, such as those that govern choosing a proper discussion\ntopic and when to change discussion topics, guide conversational behaviors. We\npropose a computational model of conversation that can follow or break such\nrules, with participant agents that respond accordingly. Additionally, we\ndemonstrate an application of the model: the Experimental Social Tutor (EST), a\nfirst step toward a social skills training tool that generates human-readable\nconversation and a conversational guideline at each point in the dialogue.\nFinally, we discuss the design and results of a pilot study evaluating the EST.\nResults show that our model is capable of producing conversations that follow\nsocial norms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:43:44 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Morrison", "Hannah", ""], ["Martens", "Chris", ""]]}, {"id": "1802.04451", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Bo Xing", "title": "Blockchain and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is undeniable that artificial intelligence (AI) and blockchain concepts\nare spreading at a phenomenal rate. Both technologies have distinct degree of\ntechnological complexity and multi-dimensional business implications. However,\na common misunderstanding about blockchain concept, in particular, is that\nblockchain is decentralized and is not controlled by anyone. But the underlying\ndevelopment of a blockchain system is still attributed to a cluster of core\ndevelopers. Take smart contract as an example, it is essentially a collection\nof codes (or functions) and data (or states) that are programmed and deployed\non a blockchain (say, Ethereum) by different human programmers. It is thus,\nunfortunately, less likely to be free of loopholes and flaws. In this article,\nthrough a brief overview about how artificial intelligence could be used to\ndeliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we\nto emphasize that the blockchain implementation can be assisted or enhanced via\nvarious AI techniques. The alliance of AI and blockchain is expected to create\nnumerous possibilities.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 03:10:59 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 15:43:32 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Xing", "Bo", ""]]}, {"id": "1802.04520", "submitter": "Max Ferguson", "authors": "M Ferguson, K. H. Law", "title": "Learning Robust and Adaptive Real-World Continuous Control Using\n  Simulation and Transfer Learning", "comments": "The paper has several technical errors. Rather than correct these\n  errors we have chosen to significantly reformulate the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use model-free reinforcement learning, extensive simulation, and transfer\nlearning to develop a continuous control algorithm that has good zero-shot\nperformance in a real physical environment. We train a simulated agent to act\noptimally across a set of similar environments, each with dynamics drawn from a\nprior distribution. We propose that the agent is able to adjust its actions\nalmost immediately, based on small set of observations. This robust and\nadaptive behavior is enabled by using a policy gradient algorithm with an Long\nShort Term Memory (LSTM) function approximation. Finally, we train an agent to\nnavigate a two-dimensional environment with uncertain dynamics and noisy\nobservations. We demonstrate that this agent has good zero-shot performance in\na real physical environment. Our preliminary results indicate that the agent is\nable to infer the environmental dynamics after only a few timesteps, and adjust\nits actions accordingly.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 09:23:14 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 07:43:44 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Ferguson", "M", ""], ["Law", "K. H.", ""]]}, {"id": "1802.04544", "submitter": "Matthias Buttkus", "authors": "Beate Bollig and Matthias Buttkus", "title": "On the Relative Succinctness of Sentential Decision Diagrams", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentential decision diagrams (SDDs) introduced by Darwiche in 2011 are a\npromising representation type used in knowledge compilation. The relative\nsuccinctness of representation types is an important subject in this area. The\naim of the paper is to identify which kind of Boolean functions can be\nrepresented by SDDs of small size with respect to the number of variables the\nfunctions are defined on. For this reason the sets of Boolean functions\nrepresentable by different representation types in polynomial size are\ninvestigated and SDDs are compared with representation types from the classical\nknowledge compilation map of Darwiche and Marquis. Ordered binary decision\ndiagrams (OBDDs) which are a popular data structure for Boolean functions are\none of these representation types. SDDs are more general than OBDDs by\ndefinition but only recently, a Boolean function was presented with polynomial\nSDD size but exponential OBDD size. This result is strengthened in several\nways. The main result is a quasipolynomial simulation of SDDs by equivalent\nunambiguous nondeterministic OBDDs, a nondeterministic variant where there\nexists exactly one accepting computation for each satisfying input. As a side\neffect an open problem about the relative succinctness between SDDs and free\nbinary decision diagrams (FBDDs) which are more general than OBDDs is answered.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 10:34:27 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Bollig", "Beate", ""], ["Buttkus", "Matthias", ""]]}, {"id": "1802.04564", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Tzu-Yun Shann, Shih-Yang Su, Yi-Hsiang Chang, Chun-Yi\n  Lee", "title": "Diversity-Driven Exploration Strategy for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration remains a challenging research problem in reinforcement\nlearning, especially when an environment contains large state spaces, deceptive\nlocal optima, or sparse rewards. To tackle this problem, we present a\ndiversity-driven approach for exploration, which can be easily combined with\nboth off- and on-policy reinforcement learning algorithms. We show that by\nsimply adding a distance measure to the loss function, the proposed methodology\nsignificantly enhances an agent's exploratory behaviors, and thus preventing\nthe policy from being trapped in local optima. We further propose an adaptive\nscaling method for stabilizing the learning process. Our experimental results\nin Atari 2600 show that our method outperforms baseline approaches in several\ntasks in terms of mean scores and exploration efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 11:18:41 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 04:47:56 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Shann", "Tzu-Yun", ""], ["Su", "Shih-Yang", ""], ["Chang", "Yi-Hsiang", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1802.04592", "submitter": "Ling Pan", "authors": "Ling Pan and Qingpeng Cai and Zhixuan Fang and Pingzhong Tang and\n  Longbo Huang", "title": "A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike\n  Sharing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike sharing provides an environment-friendly way for traveling and is\nbooming all over the world. Yet, due to the high similarity of user travel\npatterns, the bike imbalance problem constantly occurs, especially for dockless\nbike sharing systems, causing significant impact on service quality and company\nrevenue. Thus, it has become a critical task for bike sharing systems to\nresolve such imbalance efficiently. In this paper, we propose a novel deep\nreinforcement learning framework for incentivizing users to rebalance such\nsystems. We model the problem as a Markov decision process and take both\nspatial and temporal features into consideration. We develop a novel deep\nreinforcement learning algorithm called Hierarchical Reinforcement Pricing\n(HRP), which builds upon the Deep Deterministic Policy Gradient algorithm.\nDifferent from existing methods that often ignore spatial information and rely\nheavily on accurate prediction, HRP captures both spatial and temporal\ndependencies using a divide-and-conquer structure with an embedded localized\nmodule. We conduct extensive experiments to evaluate HRP, based on a dataset\nfrom Mobike, a major Chinese dockless bike sharing company. Results show that\nHRP performs close to the 24-timeslot look-ahead optimization, and outperforms\nstate-of-the-art methods in both service level and bike distribution. It also\ntransfers well when applied to unseen areas.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 12:43:03 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 02:42:48 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 15:57:01 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 05:02:51 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Pan", "Ling", ""], ["Cai", "Qingpeng", ""], ["Fang", "Zhixuan", ""], ["Tang", "Pingzhong", ""], ["Huang", "Longbo", ""]]}, {"id": "1802.04675", "submitter": "Parth Mehta", "authors": "Parth Mehta, Gaurav Arora, Prasenjit Majumder", "title": "Attention based Sentence Extraction from Scientific Articles using\n  Pseudo-Labeled data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a weakly supervised sentence extraction technique\nfor identifying important sentences in scientific papers that are worthy of\ninclusion in the abstract. We propose a new attention based deep learning\narchitecture that jointly learns to identify important content, as well as the\ncue phrases that are indicative of summary worthy sentences. We propose a new\ncontext embedding technique for determining the focus of a given paper using\ntopic models and use it jointly with an LSTM based sequence encoder to learn\nattention weights across the sentence words. We use a collection of articles\npublicly available through ACL anthology for our experiments. Our system\nachieves a performance that is better, in terms of several ROUGE metrics, as\ncompared to several state of art extractive techniques. It also generates more\ncoherent summaries and preserves the overall structure of the document.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 15:13:28 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Mehta", "Parth", ""], ["Arora", "Gaurav", ""], ["Majumder", "Prasenjit", ""]]}, {"id": "1802.04697", "submitter": "Arthur Guez", "authors": "Arthur Guez, Th\\'eophane Weber, Ioannis Antonoglou, Karen Simonyan,\n  Oriol Vinyals, Daan Wierstra, R\\'emi Munos, David Silver", "title": "Learning to Search with MCTSnets", "comments": "ICML 2018 (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning problems are among the most important and well-studied problems in\nartificial intelligence. They are most typically solved by tree search\nalgorithms that simulate ahead into the future, evaluate future states, and\nback-up those evaluations to the root of a search tree. Among these algorithms,\nMonte-Carlo tree search (MCTS) is one of the most general, powerful and widely\nused. A typical implementation of MCTS uses cleverly designed rules, optimized\nto the particular characteristics of the domain. These rules control where the\nsimulation traverses, what to evaluate in the states that are reached, and how\nto back-up those evaluations. In this paper we instead learn where, what and\nhow to search. Our architecture, which we call an MCTSnet, incorporates\nsimulation-based search inside a neural network, by expanding, evaluating and\nbacking-up a vector embedding. The parameters of the network are trained\nend-to-end using gradient-based optimisation. When applied to small searches in\nthe well known planning problem Sokoban, the learned search algorithm\nsignificantly outperformed MCTS baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 16:10:10 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 14:16:12 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Guez", "Arthur", ""], ["Weber", "Th\u00e9ophane", ""], ["Antonoglou", "Ioannis", ""], ["Simonyan", "Karen", ""], ["Vinyals", "Oriol", ""], ["Wierstra", "Daan", ""], ["Munos", "R\u00e9mi", ""], ["Silver", "David", ""]]}, {"id": "1802.04742", "submitter": "Thomas Vandal", "authors": "Thomas Vandal, Evan Kodra, Jennifer Dy, Sangram Ganguly, Ramakrishna\n  Nemani, Auroop R. Ganguly", "title": "Quantifying Uncertainty in Discrete-Continuous and Skewed Data with\n  Bayesian Deep Learning", "comments": "10 Pages", "journal-ref": "The 24th ACM SIGKDD International Conference on Knowledge\n  Discovery & Data Mining, August 19--23, 2018, London, United Kingdom", "doi": "10.1145/3219819.3219996", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) methods have been transforming computer vision with\ninnovative adaptations to other domains including climate change. For DL to\npervade Science and Engineering (S&E) applications where risk management is a\ncore component, well-characterized uncertainty estimates must accompany\npredictions. However, S&E observations and model-simulations often follow\nheavily skewed distributions and are not well modeled with DL approaches, since\nthey usually optimize a Gaussian, or Euclidean, likelihood loss. Recent\ndevelopments in Bayesian Deep Learning (BDL), which attempts to capture\nuncertainties from noisy observations, aleatoric, and from unknown model\nparameters, epistemic, provide us a foundation. Here we present a\ndiscrete-continuous BDL model with Gaussian and lognormal likelihoods for\nuncertainty quantification (UQ). We demonstrate the approach by developing UQ\nestimates on `DeepSD', a super-resolution based DL model for Statistical\nDownscaling (SD) in climate applied to precipitation, which follows an\nextremely skewed distribution. We find that the discrete-continuous models\noutperform a basic Gaussian distribution in terms of predictive accuracy and\nuncertainty calibration. Furthermore, we find that the lognormal distribution,\nwhich can handle skewed distributions, produces quality uncertainty estimates\nat the extremes. Such results may be important across S&E, as well as other\ndomains such as finance and economics, where extremes are often of significant\ninterest. Furthermore, to our knowledge, this is the first UQ model in SD where\nboth aleatoric and epistemic uncertainties are characterized.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:07:13 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 16:35:23 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Vandal", "Thomas", ""], ["Kodra", "Evan", ""], ["Dy", "Jennifer", ""], ["Ganguly", "Sangram", ""], ["Nemani", "Ramakrishna", ""], ["Ganguly", "Auroop R.", ""]]}, {"id": "1802.04765", "submitter": "Glen Berseth", "authors": "Glen Berseth, Cheng Xie, Paul Cernek, Michiel Van de Panne", "title": "Progressive Reinforcement Learning with Distillation for Multi-Skilled\n  Motion Control", "comments": "15 pages, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has demonstrated increasing capabilities for\ncontinuous control problems, including agents that can move with skill and\nagility through their environment. An open problem in this setting is that of\ndeveloping good strategies for integrating or merging policies for multiple\nskills, where each individual skill is a specialist in a specific skill and its\nassociated state distribution. We extend policy distillation methods to the\ncontinuous action setting and leverage this technique to combine expert\npolicies, as evaluated in the domain of simulated bipedal locomotion across\ndifferent classes of terrain. We also introduce an input injection method for\naugmenting an existing policy network to exploit new input features. Lastly,\nour method uses transfer learning to assist in the efficient acquisition of new\nskills. The combination of these methods allows a policy to be incrementally\naugmented with new skills. We compare our progressive learning and integration\nvia distillation (PLAID) method against three alternative baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:57:21 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Berseth", "Glen", ""], ["Xie", "Cheng", ""], ["Cernek", "Paul", ""], ["Van de Panne", "Michiel", ""]]}, {"id": "1802.04780", "submitter": "David Dao", "authors": "David Dao, Dan Alistarh, Claudiu Musat, Ce Zhang", "title": "DataBright: Towards a Global Exchange for Decentralized Data Ownership\n  and Trusted Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is safe to assume that, for the foreseeable future, machine learning,\nespecially deep learning will remain both data- and computation-hungry. In this\npaper, we ask: Can we build a global exchange where everyone can contribute\ncomputation and data to train the next generation of machine learning\napplications?\n  We present an early, but running prototype of DataBright, a system that turns\nthe creation of training examples and the sharing of computation into an\ninvestment mechanism. Unlike most crowdsourcing platforms, where the\ncontributor gets paid when they submit their data, DataBright pays dividends\nwhenever a contributor's data or hardware is used by someone to train a machine\nlearning model. The contributor becomes a shareholder in the dataset they\ncreated. To enable the measurement of usage, a computation platform that\ncontributors can trust is also necessary. DataBright thus merges both a data\nmarket and a trusted computation market.\n  We illustrate that trusted computation can enable the creation of an AI\nmarket, where each data point has an exact value that should be paid to its\ncreator. DataBright allows data creators to retain ownership of their\ncontribution and attaches to it a measurable value. The value of the data is\ngiven by its utility in subsequent distributed computation done on the\nDataBright computation market. The computation market allocates tasks and\nsubsequent payments to pooled hardware. This leads to the creation of a\ndecentralized AI cloud. Our experiments show that trusted hardware such as\nIntel SGX can be added to the usual ML pipeline with no additional costs. We\nuse this setting to orchestrate distributed computation that enables the\ncreation of a computation market. DataBright is available for download at\nhttps://github.com/ds3lab/databright.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:20:07 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Dao", "David", ""], ["Alistarh", "Dan", ""], ["Musat", "Claudiu", ""], ["Zhang", "Ce", ""]]}, {"id": "1802.04799", "submitter": "Tianqi Chen", "authors": "Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan,\n  Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos\n  Guestrin, Arvind Krishnamurthy", "title": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning", "comments": "Significantly improved version, add automated optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing need to bring machine learning to a wide diversity of\nhardware devices. Current frameworks rely on vendor-specific operator libraries\nand optimize for a narrow range of server-class GPUs. Deploying workloads to\nnew platforms -- such as mobile phones, embedded devices, and accelerators\n(e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a\ncompiler that exposes graph-level and operator-level optimizations to provide\nperformance portability to deep learning workloads across diverse hardware\nback-ends. TVM solves optimization challenges specific to deep learning, such\nas high-level operator fusion, mapping to arbitrary hardware primitives, and\nmemory latency hiding. It also automates optimization of low-level programs to\nhardware characteristics by employing a novel, learning-based cost modeling\nmethod for rapid exploration of code optimizations. Experimental results show\nthat TVM delivers performance across hardware back-ends that are competitive\nwith state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and\nserver-class GPUs. We also demonstrate TVM's ability to target new accelerator\nback-ends, such as the FPGA-based generic deep learning accelerator. The system\nis open sourced and in production use inside several major companies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:49:34 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 18:44:40 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 18:47:38 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Chen", "Tianqi", ""], ["Moreau", "Thierry", ""], ["Jiang", "Ziheng", ""], ["Zheng", "Lianmin", ""], ["Yan", "Eddie", ""], ["Cowan", "Meghan", ""], ["Shen", "Haichen", ""], ["Wang", "Leyuan", ""], ["Hu", "Yuwei", ""], ["Ceze", "Luis", ""], ["Guestrin", "Carlos", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1802.04818", "submitter": "Peter Clark", "authors": "Peter Clark", "title": "Story Generation and Aviation Incident Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": "Working Note 14 (1999)", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This working note discusses the topic of story generation, with a view to\nidentifying the knowledge required to understand aviation incident narratives\n(which have structural similarities to stories), following the premise that to\nunderstand aviation incidents, one should at least be able to generate examples\nof them. We give a brief overview of aviation incidents and their relation to\nstories, and then describe two of our earlier attempts (using `scripts' and\n`story grammars') at incident generation which did not evolve promisingly.\nFollowing this, we describe a simple incident generator which did work (at a\n`toy' level), using a `world simulation' approach. This generator is based on\nMeehan's TALE-SPIN story generator (1977). We conclude with a critique of the\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:03:21 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Clark", "Peter", ""]]}, {"id": "1802.04821", "submitter": "Rein Houthooft", "authors": "Rein Houthooft, Richard Y. Chen, Phillip Isola, Bradly C. Stadie,\n  Filip Wolski, Jonathan Ho, Pieter Abbeel", "title": "Evolved Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a metalearning approach for learning gradient-based reinforcement\nlearning (RL) algorithms. The idea is to evolve a differentiable loss function,\nsuch that an agent, which optimizes its policy to minimize this loss, will\nachieve high rewards. The loss is parametrized via temporal convolutions over\nthe agent's experience. Because this loss is highly flexible in its ability to\ntake into account the agent's history, it enables fast task learning. Empirical\nresults show that our evolved policy gradient algorithm (EPG) achieves faster\nlearning on several randomized environments compared to an off-the-shelf policy\ngradient method. We also demonstrate that EPG's learned loss can generalize to\nout-of-distribution test time tasks, and exhibits qualitatively different\nbehavior from other popular metalearning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:07:43 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 04:32:51 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Houthooft", "Rein", ""], ["Chen", "Richard Y.", ""], ["Isola", "Phillip", ""], ["Stadie", "Bradly C.", ""], ["Wolski", "Filip", ""], ["Ho", "Jonathan", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1802.04834", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Challenging Images For Minds and Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no denying the tremendous leap in the performance of machine\nlearning methods in the past half-decade. Some might even say that specific\nsub-fields in pattern recognition, such as machine-vision, are as good as\nsolved, reaching human and super-human levels. Arguably, lack of training data\nand computation power are all that stand between us and solving the remaining\nones. In this position paper we underline cases in vision which are challenging\nto machines and even to human observers. This is to show limitations of\ncontemporary models that are hard to ameliorate by following the current trend\nto increase training data, network capacity or computational power. Moreover,\nwe claim that attempting to do so is in principle a suboptimal approach. We\nprovide a taster of such examples in hope to encourage and challenge the\nmachine learning community to develop new directions to solve the said\ndifficulties.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 19:50:41 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.04887", "submitter": "David Blum", "authors": "David M. Blum, M. Elisabeth Pate-Cornell", "title": "Probabilistic Warnings in National Security Crises: Pearl Harbor\n  Revisited", "comments": null, "journal-ref": "Decision Analysis 13:1 (2015) 1-25", "doi": "10.1287/deca.2015.0321", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a situation where a group of adversaries is preparing an attack on\nthe United States or U.S. interests. An intelligence analyst has observed some\nsignals, but the situation is rapidly changing. The analyst faces the decision\nto alert a principal decision maker that an attack is imminent, or to wait\nuntil more is known about the situation. This warning decision is based on the\nanalyst's observation and evaluation of signals, independent or correlated, and\non her updating of the prior probabilities of possible scenarios and their\noutcomes. The warning decision also depends on the analyst's assessment of the\ncrisis' dynamics and perception of the preferences of the principal decision\nmaker, as well as the lead time needed for an appropriate response. This\narticle presents a model to support this analyst's dynamic warning decision. As\nwith most problems involving warning, the key is to manage the tradeoffs\nbetween false positives and false negatives given the probabilities and the\nconsequences of intelligence failures of both types. The model is illustrated\nby revisiting the case of the attack on Pearl Harbor in December 1941. It shows\nthat the radio silence of the Japanese fleet carried considerable information\n(Sir Arthur Conan Doyle's \"dog in the night\" problem), which was misinterpreted\nat the time. Even though the probabilities of different attacks were relatively\nlow, their consequences were such that the Bayesian dynamic reasoning described\nhere may have provided valuable information to key decision makers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 22:54:28 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Blum", "David M.", ""], ["Pate-Cornell", "M. Elisabeth", ""]]}, {"id": "1802.04942", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Xuechen Li, Roger Grosse, David Duvenaud", "title": "Isolating Sources of Disentanglement in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We decompose the evidence lower bound to show the existence of a term\nmeasuring the total correlation between latent variables. We use this to\nmotivate our $\\beta$-TCVAE (Total Correlation Variational Autoencoder), a\nrefinement of the state-of-the-art $\\beta$-VAE objective for learning\ndisentangled representations, requiring no additional hyperparameters during\ntraining. We further propose a principled classifier-free measure of\ndisentanglement called the mutual information gap (MIG). We perform extensive\nquantitative and qualitative experiments, in both restricted and non-restricted\nsettings, and show a strong relation between total correlation and\ndisentanglement, when the latent variables model is trained using our\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 03:48:06 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 21:01:39 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 22:26:42 GMT"}, {"version": "v4", "created": "Tue, 22 Jan 2019 21:50:57 GMT"}, {"version": "v5", "created": "Tue, 23 Apr 2019 17:20:14 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Li", "Xuechen", ""], ["Grosse", "Roger", ""], ["Duvenaud", "David", ""]]}, {"id": "1802.04987", "submitter": "Luca Pappalardo", "authors": "Luca Pappalardo and Paolo Cintia and Paolo Ferragina and Emanuele\n  Massucco and Dino Pedreschi and Fosca Giannotti", "title": "PlayeRank: data-driven performance evaluation and player ranking in\n  soccer via a machine learning approach", "comments": null, "journal-ref": "PlayeRank: Data-driven Performance Evaluation and Player Ranking\n  in Soccer via a Machine Learning Approach. ACM Trans. Intell. Syst. Technol.\n  10, 5, Article 59 (September 2019), 27 pages", "doi": "10.1145/3343172", "report-no": null, "categories": "stat.AP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of evaluating the performance of soccer players is attracting the\ninterest of many companies and the scientific community, thanks to the\navailability of massive data capturing all the events generated during a match\n(e.g., tackles, passes, shots, etc.). Unfortunately, there is no consolidated\nand widely accepted metric for measuring performance quality in all of its\nfacets. In this paper, we design and implement PlayeRank, a data-driven\nframework that offers a principled multi-dimensional and role-aware evaluation\nof the performance of soccer players. We build our framework by deploying a\nmassive dataset of soccer-logs and consisting of millions of match events\npertaining to four seasons of 18 prominent soccer competitions. By comparing\nPlayeRank to known algorithms for performance evaluation in soccer, and by\nexploiting a dataset of players' evaluations made by professional soccer\nscouts, we show that PlayeRank significantly outperforms the competitors. We\nalso explore the ratings produced by {\\sf PlayeRank} and discover interesting\npatterns about the nature of excellent performances and what distinguishes the\ntop players from the others. At the end, we explore some applications of\nPlayeRank -- i.e. searching players and player versatility --- showing its\nflexibility and efficiency, which makes it worth to be used in the design of a\nscalable platform for soccer analytics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 08:43:43 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 12:22:23 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 13:48:06 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Pappalardo", "Luca", ""], ["Cintia", "Paolo", ""], ["Ferragina", "Paolo", ""], ["Massucco", "Emanuele", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""]]}, {"id": "1802.05027", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Emanuela Keller, Carl Muroi, David J. Mack, Christian\n  Str\\\"assle, Walter Karlen", "title": "Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical\n  Care", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:4518-4527, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients in the intensive care unit (ICU) require constant and close\nsupervision. To assist clinical staff in this task, hospitals use monitoring\nsystems that trigger audiovisual alarms if their algorithms indicate that a\npatient's condition may be worsening. However, current monitoring systems are\nextremely sensitive to movement artefacts and technical errors. As a result,\nthey typically trigger hundreds to thousands of false alarms per patient per\nday - drowning the important alarms in noise and adding to the exhaustion of\nclinical staff. In this setting, data is abundantly available, but obtaining\ntrustworthy annotations by experts is laborious and expensive. We frame the\nproblem of false alarm reduction from multivariate time series as a\nmachine-learning task and address it with a novel multitask network\narchitecture that utilises distant supervision through multiple related\nauxiliary tasks in order to reduce the number of expensive labels required for\ntraining. We show that our approach leads to significant improvements over\nseveral state-of-the-art baselines on real-world ICU data and provide new\ninsights on the importance of task selection and architectural choices in\ndistantly supervised multitask learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:35:08 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 23:31:24 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Schwab", "Patrick", ""], ["Keller", "Emanuela", ""], ["Muroi", "Carl", ""], ["Mack", "David J.", ""], ["Str\u00e4ssle", "Christian", ""], ["Karlen", "Walter", ""]]}, {"id": "1802.05098", "submitter": "Jakob Foerster", "authors": "Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim\n  Rockt\\\"aschel, Eric P. Xing, Shimon Whiteson", "title": "DiCE: The Infinitely Differentiable Monte-Carlo Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The score function estimator is widely used for estimating gradients of\nstochastic objectives in stochastic computation graphs (SCG), eg, in\nreinforcement learning and meta-learning. While deriving the first-order\ngradient estimators by differentiating a surrogate loss (SL) objective is\ncomputationally and conceptually simple, using the same approach for\nhigher-order derivatives is more challenging. Firstly, analytically deriving\nand implementing such estimators is laborious and not compliant with automatic\ndifferentiation. Secondly, repeatedly applying SL to construct new objectives\nfor each order derivative involves increasingly cumbersome graph manipulations.\nLastly, to match the first-order gradient under differentiation, SL treats part\nof the cost as a fixed sample, which we show leads to missing and wrong terms\nfor estimators of higher-order derivatives. To address all these shortcomings\nin a unified way, we introduce DiCE, which provides a single objective that can\nbe differentiated repeatedly, generating correct estimators of derivatives of\nany order in SCGs. Unlike SL, DiCE relies on automatic differentiation for\nperforming the requisite graph manipulations. We verify the correctness of DiCE\nboth through a proof and numerical evaluation of the DiCE derivative estimates.\nWe also use DiCE to propose and evaluate a novel approach for multi-agent\nlearning. Our code is available at https://www.github.com/alshedivat/lola.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:05:54 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 10:59:41 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 19:11:15 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Foerster", "Jakob", ""], ["Farquhar", "Gregory", ""], ["Al-Shedivat", "Maruan", ""], ["Rockt\u00e4schel", "Tim", ""], ["Xing", "Eric P.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1802.05101", "submitter": "James Bagrow", "authors": "James P. Bagrow", "title": "Democratizing AI: Non-expert design of prediction tasks", "comments": "17 pages, 6 figures", "journal-ref": "PeerJ Computer Science, 6: e296, 2020", "doi": "10.7717/peerj-cs.296", "report-no": null, "categories": "cs.HC cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-experts have long made important contributions to machine learning (ML)\nby contributing training data, and recent work has shown that non-experts can\nalso help with feature engineering by suggesting novel predictive features.\nHowever, non-experts have only contributed features to prediction tasks already\nposed by experienced ML practitioners. Here we study how non-experts can design\nprediction tasks themselves, what types of tasks non-experts will design, and\nwhether predictive models can be automatically trained on data sourced for\ntheir tasks. We use a crowdsourcing platform where non-experts design\npredictive tasks that are then categorized and ranked by the crowd.\nCrowdsourced data are collected for top-ranked tasks and predictive models are\nthen trained and evaluated automatically using those data. We show that\nindividuals without ML experience can collectively construct useful datasets\nand that predictive models can be learned on these datasets, but challenges\nremain. The prediction tasks designed by non-experts covered a broad range of\ndomains, from politics and current events to health behavior, demographics, and\nmore. Proper instructions are crucial for non-experts, so we also conducted a\nrandomized trial to understand how different instructions may influence the\ntypes of prediction tasks being proposed. In general, understanding better how\nnon-experts can contribute to ML can further leverage advances in Automatic ML\nand has important implications as ML continues to drive workplace automation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:16:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 20:04:50 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bagrow", "James P.", ""]]}, {"id": "1802.05141", "submitter": "Kelvin Loh", "authors": "Kelvin Loh, Pejman Shoeibi Omrani, Ruud van der Linden", "title": "Deep Learning and Data Assimilation for Real-Time Production Prediction\n  in Natural Gas Wells", "comments": "Reduced length preprint submitted to IJCAI 2018 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.flu-dyn physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of the gas production from mature gas wells, due to their\ncomplex end-of-life behavior, is challenging and crucial for operational\ndecision making. In this paper, we apply a modified deep LSTM model for\nprediction of the gas flow rates in mature gas wells, including the\nuncertainties in input parameters. Additionally, due to changes in the system\nin time and in order to increase the accuracy and robustness of the prediction,\nthe Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions\nbased on new observations. The developed approach was tested on the data from\ntwo mature gas production wells in which their production is highly dynamic and\nsuffering from salt deposition. The results show that the flow predictions\nusing the EnKF updated model leads to better Jeffreys' J-divergences than the\npredictions without the EnKF model updating scheme.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 15:03:09 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 03:16:08 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Loh", "Kelvin", ""], ["Omrani", "Pejman Shoeibi", ""], ["van der Linden", "Ruud", ""]]}, {"id": "1802.05142", "submitter": "Ram\\'on Pino P\\'erez", "authors": "Isabelle Bloch, J\\'er\\^ome Lang, Ram\\'on Pino P\\'erez, Carlos\n  Uzc\\'ategui", "title": "Morphologic for knowledge dynamics: revision, fusion, abduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several tasks in artificial intelligence require to be able to find models\nabout knowledge dynamics. They include belief revision, fusion and belief\nmerging, and abduction. In this paper we exploit the algebraic framework of\nmathematical morphology in the context of propositional logic, and define\noperations such as dilation or erosion of a set of formulas. We derive concrete\noperators, based on a semantic approach, that have an intuitive interpretation\nand that are formally well behaved, to perform revision, fusion and abduction.\nComputation and tractability are addressed, and simple examples illustrate the\ntypical results that can be obtained.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 15:08:06 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Bloch", "Isabelle", ""], ["Lang", "J\u00e9r\u00f4me", ""], ["P\u00e9rez", "Ram\u00f3n Pino", ""], ["Uzc\u00e1tegui", "Carlos", ""]]}, {"id": "1802.05219", "submitter": "Michael Green", "authors": "Gabriella A. B. Barros, Michael Cerny Green, Antonios Liapis, and\n  Julian Togelius", "title": "Who Killed Albert Einstein? From Open Data to Murder Mystery Games", "comments": "11 pages, 6 figures, 2 tables", "journal-ref": "10.1109/TG.2018.2806190", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for generating adventure games from open\ndata. Focusing on the murder mystery type of adventure games, the generator is\nable to transform open data from Wikipedia articles, OpenStreetMap and images\nfrom Wikimedia Commons into WikiMysteries. Every WikiMystery game revolves\naround the murder of a person with a Wikipedia article and populates the game\nwith suspects who must be arrested by the player if guilty of the murder or\nabsolved if innocent. Starting from only one person as the victim, an extensive\ngenerative pipeline finds suspects, their alibis, and paths connecting them\nfrom open data, transforms open data into cities, buildings, non-player\ncharacters, locks and keys and dialog options. The paper describes in detail\neach generative step, provides a specific playthrough of one WikiMystery where\nAlbert Einstein is murdered, and evaluates the outcomes of games generated for\nthe 100 most influential people of the 20th century.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 17:17:54 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Barros", "Gabriella A. B.", ""], ["Green", "Michael Cerny", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1802.05250", "submitter": "Jaime Fisac", "authors": "Jaime F. Fisac, Chang Liu, Jessica B. Hamrick, S. Shankar Sastry, J.\n  Karl Hedrick, Thomas L. Griffiths, and Anca D. Dragan", "title": "Generating Plans that Predict Themselves", "comments": "Published at the Workshop on Algorithmic Foundations of Robotics\n  (WAFR 2016)", "journal-ref": "Jaime F. Fisac, Chang Liu, Jessica B. Hamrick, S. Shankar Sastry,\n  J. Karl Hedrick, Thomas L. Griffiths, and Anca D. Dragan. \"Generating Plans\n  that Predict Themselves\". Workshop on Algorithmic Foundations of Robotics\n  (WAFR), 2016", "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration requires coordination, and we coordinate by anticipating our\nteammates' future actions and adapting to their plan. In some cases, our\nteammates' actions early on can give us a clear idea of what the remainder of\ntheir plan is, i.e. what action sequence we should expect. In others, they\nmight leave us less confident, or even lead us to the wrong conclusion. Our\ngoal is for robot actions to fall in the first category: we want to enable\nrobots to select their actions in such a way that human collaborators can\neasily use them to correctly anticipate what will follow. While previous work\nhas focused on finding initial plans that convey a set goal, here we focus on\nfinding two portions of a plan such that the initial portion conveys the final\none. We introduce $t$-\\ACty{}: a measure that quantifies the accuracy and\nconfidence with which human observers can predict the remaining robot plan from\nthe overall task goal and the observed initial $t$ actions in the plan. We\ncontribute a method for generating $t$-predictable plans: we search for a full\nplan that accomplishes the task, but in which the first $t$ actions make it as\neasy as possible to infer the remaining ones. The result is often different\nfrom the most efficient plan, in which the initial actions might leave a lot of\nambiguity as to how the task will be completed. Through an online experiment\nand an in-person user study with physical robots, we find that our approach\noutperforms a traditional efficiency-based planner in objective and subjective\ncollaboration metrics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 18:20:19 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Fisac", "Jaime F.", ""], ["Liu", "Chang", ""], ["Hamrick", "Jessica B.", ""], ["Sastry", "S. Shankar", ""], ["Hedrick", "J. Karl", ""], ["Griffiths", "Thomas L.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1802.05312", "submitter": "Karl Ridgeway", "authors": "Karl Ridgeway, Michael C. Mozer", "title": "Learning Deep Disentangled Embeddings with the F-Statistic Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-embedding methods aim to discover representations of a domain that make\nexplicit the domain's class structure and thereby support few-shot learning.\nDisentangling methods aim to make explicit compositional or factorial\nstructure. We combine these two active but independent lines of research and\npropose a new paradigm suitable for both goals. We propose and evaluate a novel\nloss function based on the $F$ statistic, which describes the separation of two\nor more distributions. By ensuring that distinct classes are well separated on\na subset of embedding dimensions, we obtain embeddings that are useful for\nfew-shot learning. By not requiring separation on all dimensions, we encourage\nthe discovery of disentangled representations. Our embedding method matches or\nbeats state-of-the-art, as evaluated by performance on recall@$k$ and few-shot\nlearning tasks. Our method also obtains performance superior to a variety of\nalternatives on disentangling, as evaluated by two key properties of a\ndisentangled representation: modularity and explicitness. The goal of our work\nis to obtain more interpretable, manipulable, and generalizable deep\nrepresentations of concepts and categories.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:28:38 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 00:25:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ridgeway", "Karl", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1802.05313", "submitter": "Huazhe Xu", "authors": "Yang Gao, Huazhe Xu, Ji Lin, Fisher Yu, Sergey Levine, Trevor Darrell", "title": "Reinforcement Learning from Imperfect Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust real-world learning should benefit from both demonstrations and\ninteractions with the environment. Current approaches to learning from\ndemonstration and reward perform supervised learning on expert demonstration\ndata and use reinforcement learning to further improve performance based on the\nreward received from the environment. These tasks have divergent losses which\nare difficult to jointly optimize and such methods can be very sensitive to\nnoisy demonstrations. We propose a unified reinforcement learning algorithm,\nNormalized Actor-Critic (NAC), that effectively normalizes the Q-function,\nreducing the Q-values of actions unseen in the demonstration data. NAC learns\nan initial policy network from demonstrations and refines the policy in the\nenvironment, surpassing the demonstrator's performance. Crucially, both\nlearning from demonstration and interactive refinement use the same objective,\nunlike prior approaches that combine distinct supervised and reinforcement\nlosses. This makes NAC robust to suboptimal demonstration data since the method\nis not forced to mimic all of the examples in the dataset. We show that our\nunified reinforcement learning algorithm can learn robustly and outperform\nexisting baselines when evaluated on several realistic driving games.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 20:37:38 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 04:39:22 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gao", "Yang", ""], ["Xu", "Huazhe", ""], ["Lin", "Ji", ""], ["Yu", "Fisher", ""], ["Levine", "Sergey", ""], ["Darrell", "Trevor", ""]]}, {"id": "1802.05340", "submitter": "Fei Wang", "authors": "Fei Wang, Tiark Rompf", "title": "From Gameplay to Symbolic Reasoning: Learning SAT Solver Heuristics in\n  the Style of Alpha(Go) Zero", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep neural networks in various fields such\nas image and speech recognition, natural language processing, and reinforcement\nlearning, we still face big challenges in bringing the power of numeric\noptimization to symbolic reasoning. Researchers have proposed different avenues\nsuch as neural machine translation for proof synthesis, vectorization of\nsymbols and expressions for representing symbolic patterns, and coupling of\nneural back-ends for dimensionality reduction with symbolic front-ends for\ndecision making. However, these initial explorations are still only point\nsolutions, and bear other shortcomings such as lack of correctness guarantees.\nIn this paper, we present our approach of casting symbolic reasoning as games,\nand directly harnessing the power of deep reinforcement learning in the style\nof Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT)\nproblem as showcase, we demonstrate the feasibility of our method, and the\nadvantages of modularity, efficiency, and correctness guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 22:25:47 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Wang", "Fei", ""], ["Rompf", "Tiark", ""]]}, {"id": "1802.05382", "submitter": "Himan Abdollahpouri", "authors": "Himan Abdollahpouri, Robin Burke, Bamshad Mobasher", "title": "Popularity-Aware Item Weighting for Long-Tail Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recommender systems suffer from the popularity bias problem: popular\nitems are being recommended frequently while less popular, niche products, are\nrecommended rarely if not at all. However, those ignored products are exactly\nthe products that businesses need to find customers for and their\nrecommendations would be more beneficial. In this paper, we examine an item\nweighting approach to improve long-tail recommendation. Our approach works as a\nsimple yet powerful add-on to existing recommendation algorithms for making a\ntunable trade-off between accuracy and long-tail coverage.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 01:53:59 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 19:49:20 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 14:55:44 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Abdollahpouri", "Himan", ""], ["Burke", "Robin", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1802.05383", "submitter": "Xuesong Yang", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Dinei Florencio,\n  Mark Hasegawa-Johnson", "title": "Deep Learning Based Speech Beamforming", "comments": "Accepted in The 43rd IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-channel speech enhancement with ad-hoc sensors has been a challenging\ntask. Speech model guided beamforming algorithms are able to recover natural\nsounding speech, but the speech models tend to be oversimplified or the\ninference would otherwise be too complicated. On the other hand, deep learning\nbased enhancement approaches are able to learn complicated speech distributions\nand perform efficient inference, but they are unable to deal with variable\nnumber of input channels. Also, deep learning approaches introduce a lot of\nerrors, particularly in the presence of unseen noise types and settings. We\nhave therefore proposed an enhancement framework called DEEPBEAM, which\ncombines the two complementary classes of algorithms. DEEPBEAM introduces a\nbeamforming filter to produce natural sounding speech, but the filter\ncoefficients are determined with the help of a monaural speech enhancement\nneural network. Experiments on synthetic and real-world data show that DEEPBEAM\nis able to produce clean, dry and natural sounding speech, and is robust\nagainst unseen noise.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:00:54 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Qian", "Kaizhi", ""], ["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Yang", "Xuesong", ""], ["Florencio", "Dinei", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "1802.05385", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Fooling OCR Systems with Adversarial Text Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that state-of-the-art optical character recognition (OCR)\nbased on deep learning is vulnerable to adversarial images. Minor modifications\nto images of printed text, which do not change the meaning of the text to a\nhuman reader, cause the OCR system to \"recognize\" a different text where\ncertain words chosen by the adversary are replaced by their semantic opposites.\nThis completely changes the meaning of the output produced by the OCR system\nand by the NLP applications that use OCR for preprocessing their inputs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 02:08:19 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1802.05438", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, Jun Wang", "title": "Mean Field Multi-Agent Reinforcement Learning", "comments": "ICML 2018 (Full paper + Long talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-agent reinforcement learning methods are limited typically to\na small number of agents. When the agent number increases largely, the learning\nbecomes intractable due to the curse of the dimensionality and the exponential\ngrowth of agent interactions. In this paper, we present \\emph{Mean Field\nReinforcement Learning} where the interactions within the population of agents\nare approximated by those between a single agent and the average effect from\nthe overall population or neighboring agents; the interplay between the two\nentities is mutually reinforced: the learning of the individual agent's optimal\npolicy depends on the dynamics of the population, while the dynamics of the\npopulation change according to the collective patterns of the individual\npolicies. We develop practical mean field Q-learning and mean field\nActor-Critic algorithms and analyze the convergence of the solution to Nash\nequilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\njustify the learning effectiveness of our mean field approaches. In addition,\nwe report the first result to solve the Ising model via model-free\nreinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 09:07:57 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 16:26:20 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 07:19:04 GMT"}, {"version": "v4", "created": "Thu, 19 Jul 2018 22:15:36 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 11:26:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Li", "Minne", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Wang", "Jun", ""]]}, {"id": "1802.05472", "submitter": "Yan Zhu", "authors": "Yan Zhu, Abdullah Mueen, Eamonn Keogh", "title": "Admissible Time Series Motif Discovery with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of time series motifs has emerged as one of the most useful\nprimitives in time series data mining. Researchers have shown its utility for\nexploratory data mining, summarization, visualization, segmentation,\nclassification, clustering, and rule discovery. Although there has been more\nthan a decade of extensive research, there is still no technique to allow the\ndiscovery of time series motifs in the presence of missing data, despite the\nwell-documented ubiquity of missing data in scientific, industrial, and medical\ndatasets. In this work, we introduce a technique for motif discovery in the\npresence of missing data. We formally prove that our method is admissible,\nproducing no false negatives. We also show that our method can piggy-back off\nthe fastest known motif discovery method with a small constant factor\ntime/space overhead. We will demonstrate our approach on diverse datasets with\nvarying amounts of missing data\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:45:46 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Zhu", "Yan", ""], ["Mueen", "Abdullah", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1802.05594", "submitter": "Beno\\^it Girard", "authors": "Lise Aubin, Mehdi Khamassi (ISIR), Beno\\^it Girard (ISIR)", "title": "Prioritized Sweeping Neural DynaQ with Multiple Predecessors, and\n  Hippocampal Replays", "comments": "Living Machines 2018 (Paris, France)", "journal-ref": null, "doi": "10.1007/978-3-319-95972-6_4", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During sleep and awake rest, the hippocampus replays sequences of place cells\nthat have been activated during prior experiences. These have been interpreted\nas a memory consolidation process, but recent results suggest a possible\ninterpretation in terms of reinforcement learning. The Dyna reinforcement\nlearning algorithms use off-line replays to improve learning. Under limited\nreplay budget, a prioritized sweeping approach, which requires a model of the\ntransitions to the predecessors, can be used to improve performance. We\ninvestigate whether such algorithms can explain the experimentally observed\nreplays. We propose a neural network version of prioritized sweeping\nQ-learning, for which we developed a growing multiple expert algorithm, able to\ncope with multiple predecessors. The resulting architecture is able to improve\nthe learning of simulated agents confronted to a navigation task. We predict\nthat, in animals, learning the world model should occur during rest periods,\nand that the corresponding replays should be shuffled.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 15:15:19 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 12:27:55 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Aubin", "Lise", "", "ISIR"], ["Khamassi", "Mehdi", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"]]}, {"id": "1802.05639", "submitter": "Alessandro Antonucci", "authors": "Sabina Marchetti and Alessandro Antonucci", "title": "Reliable Uncertain Evidence Modeling in Bayesian Networks by Credal\n  Networks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable modeling of uncertain evidence in Bayesian networks based on a\nset-valued quantification is proposed. Both soft and virtual evidences are\nconsidered. We show that evidence propagation in this setup can be reduced to\nstandard updating in an augmented credal network, equivalent to a set of\nconsistent Bayesian networks. A characterization of the computational\ncomplexity for this task is derived together with an efficient exact procedure\nfor a subclass of instances. In the case of multiple uncertain evidences over\nthe same variable, the proposed procedure can provide a set-valued version of\nthe geometric approach to opinion pooling.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 16:25:47 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Marchetti", "Sabina", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "1802.05786", "submitter": "Papis Wongchaisuwat", "authors": "Papis Wongchaisuwat and Diego Klabjan", "title": "Truth Validation with Evidence", "comments": "40 pages (including Appendix), 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern era, abundant information is easily accessible from various\nsources, however only a few of these sources are reliable as they mostly\ncontain unverified contents. We develop a system to validate the truthfulness\nof a given statement together with underlying evidence. The proposed system\nprovides supporting evidence when the statement is tagged as false. Our work\nrelies on an inference method on a knowledge graph (KG) to identify the\ntruthfulness of statements. In order to extract the evidence of falseness, the\nproposed algorithm takes into account combined knowledge from KG and\nontologies. The system shows very good results as it provides valid and concise\nevidence. The quality of KG plays a role in the performance of the inference\nmethod which explicitly affects the performance of our evidence-extracting\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:01:04 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Wongchaisuwat", "Papis", ""], ["Klabjan", "Diego", ""]]}, {"id": "1802.05800", "submitter": "Deboleena Roy", "authors": "Deboleena Roy, Priyadarshini Panda, Kaushik Roy", "title": "Tree-CNN: A Hierarchical Deep Convolutional Neural Network for\n  Incremental Learning", "comments": "8 pages, 6 figures, 7 tables Accepted in Neural Networks, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, Deep Convolutional Neural Networks (DCNNs) have shown\nremarkable performance in most computer vision tasks. These tasks traditionally\nuse a fixed dataset, and the model, once trained, is deployed as is. Adding new\ninformation to such a model presents a challenge due to complex training\nissues, such as \"catastrophic forgetting\", and sensitivity to hyper-parameter\ntuning. However, in this modern world, data is constantly evolving, and our\ndeep learning models are required to adapt to these changes. In this paper, we\npropose an adaptive hierarchical network structure composed of DCNNs that can\ngrow and learn as new data becomes available. The network grows in a tree-like\nfashion to accommodate new classes of data, while preserving the ability to\ndistinguish the previously trained classes. The network organizes the\nincrementally available data into feature-driven super-classes and improves\nupon existing hierarchical CNN models by adding the capability of self-growth.\nThe proposed hierarchical model, when compared against fine-tuning a deep\nnetwork, achieves significant reduction of training effort, while maintaining\ncompetitive accuracy on CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:36:56 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 18:45:12 GMT"}, {"version": "v3", "created": "Sun, 8 Sep 2019 15:58:05 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Roy", "Deboleena", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1802.05818", "submitter": "Shuai Wang", "authors": "Shuai Wang, Mianwei Zhou, Sahisnu Mazumder, Bing Liu, Yi Chang", "title": "Disentangling Aspect and Opinion Words in Target-based Sentiment\n  Analysis using Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a target name, which can be a product aspect or entity, identifying its\naspect words and opinion words in a given corpus is a fine-grained task in\ntarget-based sentiment analysis (TSA). This task is challenging, especially\nwhen we have no labeled data and we want to perform it for any given domain. To\naddress it, we propose a general two-stage approach. Stage one extracts/groups\nthe target-related words (call t-words) for a given target. This is relatively\neasy as we can apply an existing semantics-based learning technique. Stage two\nseparates the aspect and opinion words from the grouped t-words, which is\nchallenging because we often do not have enough word-level aspect and opinion\nlabels. In this work, we formulate this problem in a PU learning setting and\nincorporate the idea of lifelong learning to solve it. Experimental results\nshow the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 02:00:10 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Wang", "Shuai", ""], ["Zhou", "Mianwei", ""], ["Mazumder", "Sahisnu", ""], ["Liu", "Bing", ""], ["Chang", "Yi", ""]]}, {"id": "1802.05835", "submitter": "Siddharth Srivastava", "authors": "Siddharth Srivastava, Nishant Desai, Richard Freedman, Shlomo\n  Zilberstein", "title": "An Anytime Algorithm for Task and Motion MDPs", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated task and motion planning has emerged as a challenging problem in\nsequential decision making, where a robot needs to compute high-level strategy\nand low-level motion plans for solving complex tasks. While high-level\nstrategies require decision making over longer time-horizons and scales, their\nfeasibility depends on low-level constraints based upon the geometries and\ncontinuous dynamics of the environment. The hybrid nature of this problem makes\nit difficult to scale; most existing approaches focus on deterministic, fully\nobservable scenarios. We present a new approach where the high-level decision\nproblem occurs in a stochastic setting and can be modeled as a Markov decision\nprocess. In contrast to prior efforts, we show that complete MDP policies, or\ncontingent behaviors, can be computed effectively in an anytime fashion. Our\nalgorithm continuously improves the quality of the solution and is guaranteed\nto be probabilistically complete. We evaluate the performance of our approach\non a challenging, realistic test problem: autonomous aircraft inspection. Our\nresults show that we can effectively compute consistent task and motion\npolicies for the most likely execution-time outcomes using only a fraction of\nthe computation required to develop the complete task and motion policy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 04:52:58 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Srivastava", "Siddharth", ""], ["Desai", "Nishant", ""], ["Freedman", "Richard", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1802.05844", "submitter": "Kui Yu", "authors": "Kui Yu, Lin Liu, and Jiuyong Li", "title": "A Unified View of Causal and Non-causal Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to develop a unified view of causal and non-causal\nfeature selection methods. The unified view will fill in the gap in the\nresearch of the relation between the two types of methods. Based on the\nBayesian network framework and information theory, we first show that causal\nand non-causal feature selection methods share the same objective. That is to\nfind the Markov blanket of a class attribute, the theoretically optimal feature\nset for classification. We then examine the assumptions made by causal and\nnon-causal feature selection methods when searching for the optimal feature\nset, and unify the assumptions by mapping them to the restrictions on the\nstructure of the Bayesian network model of the studied problem. We further\nanalyze in detail how the structural assumptions lead to the different levels\nof approximations employed by the methods in their search, which then result in\nthe approximations in the feature sets found by the methods with respect to the\noptimal feature set. With the unified view, we are able to interpret the output\nof non-causal methods from a causal perspective and derive the error bounds of\nboth types of methods. Finally, we present practical understanding of the\nrelation between causal and non-causal methods using extensive experiments with\nsynthetic data and various types of real-word data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 06:18:06 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 23:49:40 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 06:38:53 GMT"}, {"version": "v4", "created": "Sun, 16 Dec 2018 03:45:56 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Yu", "Kui", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""]]}, {"id": "1802.05875", "submitter": "Zolt\\'an Kov\\'acs", "authors": "Zolt\\'an Kov\\'acs, Tom\\'as Recio, M. Pilar V\\'elez", "title": "Detecting truth, just on parts", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and discuss, through a computational algebraic geometry\napproach, the automatic reasoning handling of propositions that are\nsimultaneously true and false over some relevant collections of instances. A\nrigorous, algorithmic criterion is presented for detecting such cases, and its\nperformance is exemplified through the implementation of this test on the\ndynamic geometry program GeoGebra.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 09:24:29 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 19:45:41 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Kov\u00e1cs", "Zolt\u00e1n", ""], ["Recio", "Tom\u00e1s", ""], ["V\u00e9lez", "M. Pilar", ""]]}, {"id": "1802.05883", "submitter": "Wilker Aziz", "authors": "Miguel Rios and Wilker Aziz and Khalil Sima'an", "title": "Deep Generative Model for Joint Alignment and Word Representation", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work exploits translation data as a source of semantically relevant\nlearning signal for models of word representation. In particular, we exploit\nequivalence through translation as a form of distributed context and jointly\nlearn how to embed and align with a deep generative model. Our EmbedAlign model\nembeds words in their complete observed context and learns by marginalisation\nof latent lexical alignments. Besides, it embeds words as posterior probability\ndensities, rather than point estimates, which allows us to compare words in\ncontext using a measure of overlap between distributions (e.g. KL divergence).\nWe investigate our model's performance on a range of lexical semantics tasks\nachieving competitive results on several standard benchmarks including natural\nlanguage inference, paraphrasing, and text similarity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 10:11:39 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 11:43:08 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 09:32:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Rios", "Miguel", ""], ["Aziz", "Wilker", ""], ["Sima'an", "Khalil", ""]]}, {"id": "1802.05889", "submitter": "Chao Li", "authors": "Chao Li and Shohei Shimizu", "title": "Combining Linear Non-Gaussian Acyclic Model with Logistic Regression\n  Model for Estimating Causal Structure from Mixed Continuous and Discrete Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating causal models from observational data is a crucial task in data\nanalysis. For continuous-valued data, Shimizu et al. have proposed a linear\nacyclic non-Gaussian model to understand the data generating process, and have\nshown that their model is identifiable when the number of data is sufficiently\nlarge. However, situations in which continuous and discrete variables coexist\nin the same problem are common in practice. Most existing causal discovery\nmethods either ignore the discrete data and apply a continuous-valued algorithm\nor discretize all the continuous data and then apply a discrete Bayesian\nnetwork approach. These methods possibly loss important information when we\nignore discrete data or introduce the approximation error due to\ndiscretization. In this paper, we define a novel hybrid causal model which\nconsists of both continuous and discrete variables. The model assumes: (1) the\nvalue of a continuous variable is a linear function of its parent variables\nplus a non-Gaussian noise, and (2) each discrete variable is a logistic\nvariable whose distribution parameters depend on the values of its parent\nvariables. In addition, we derive the BIC scoring function for model selection.\nThe new discovery algorithm can learn causal structures from mixed continuous\nand discrete data without discretization. We empirically demonstrate the power\nof our method through thorough simulations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 10:45:59 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Li", "Chao", ""], ["Shimizu", "Shohei", ""]]}, {"id": "1802.05929", "submitter": "Jesse Anderton", "authors": "Jesse Anderton, Pavel Metrikov, Virgil Pavlu, Javed Aslam", "title": "Measuring Human-perceived Similarity in Heterogeneous Collections", "comments": "Reviewed but not accepted for KDD 2014; not resubmitted elsewhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique for estimating the similarity between objects such as\nmovies or foods whose proper representation depends on human perception. Our\ntechnique combines a modest number of human similarity assessments to infer a\npairwise similarity function between the objects. This similarity function\ncaptures some human notion of similarity which may be difficult or impossible\nto automatically extract, such as which movie from a collection would be a\nbetter substitute when the desired one is unavailable. In contrast to prior\ntechniques, our method does not assume that all similarity questions on the\ncollection can be answered or that all users perceive similarity in the same\nway. When combined with a user model, we find how each assessor's tastes vary,\naffecting their perception of similarity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 13:37:45 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Anderton", "Jesse", ""], ["Metrikov", "Pavel", ""], ["Pavlu", "Virgil", ""], ["Aslam", "Javed", ""]]}, {"id": "1802.05944", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Aske Plaat", "title": "Monte Carlo Q-learning for General Game Playing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the recent groundbreaking results of AlphaGo, we have seen a strong\ninterest in reinforcement learning in game playing. General Game Playing (GGP)\nprovides a good testbed for reinforcement learning. In GGP, a specification of\ngames rules is given. GGP problems can be solved by reinforcement learning.\nQ-learning is one of the canonical reinforcement learning methods, and has been\nused by (Banerjee & Stone, IJCAI 2007) in GGP. In this paper we implement\nQ-learning in GGP for three small-board games (Tic-Tac-Toe, Connect Four, Hex),\nto allow comparison to Banerjee et al. As expected, Q-learning converges,\nalthough much slower than MCTS. Borrowing an idea from MCTS, we enhance\nQ-learning with Monte Carlo Search, to give QM-learning. This enhancement\nimproves the performance of pure Q-learning. We believe that QM-learning can\nalso be used to improve performance of reinforcement learning further for\nlarger games, something which we will test in future work.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 14:18:46 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 16:16:27 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Plaat", "Aske", ""]]}, {"id": "1802.05991", "submitter": "Jialin Liu Ph.D", "authors": "Simon M Lucas, Jialin Liu and Diego Perez-Liebana", "title": "The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation", "comments": "9 pages, 3 figures, 3 table. This is the final version of the article\n  accepted by WCCI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the N-Tuple Bandit Evolutionary Algorithm (NTBEA), an\noptimisation algorithm developed for noisy and expensive discrete\n(combinatorial) optimisation problems. The algorithm is applied to two\ngame-based hyper-parameter optimisation problems. The N-Tuple system directly\nmodels the statistics, approximating the fitness and number of evaluations of\neach modelled combination of parameters. The model is simple, efficient and\ninformative. Results show that the NTBEA significantly outperforms grid search\nand an estimation of distribution algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:49:10 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 10:32:58 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Lucas", "Simon M", ""], ["Liu", "Jialin", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "1802.05992", "submitter": "Jakub \\'Swi\\k{a}tkowski", "authors": "Maciej Ja\\'skowski (1), Jakub \\'Swi\\k{a}tkowski (1), Micha{\\l}\n  Zaj\\k{a}c (1), Maciej Klimek (1), Jarek Potiuk (1), Piotr Rybicki (1), Piotr\n  Polatowski (1), Przemys{\\l}aw Walczyk (1), Kacper Nowicki (1), Marek Cygan (1\n  and 2) ((1) NoMagic.AI, (2) Institute of Informatics, University of Warsaw)", "title": "Improved GQ-CNN: Deep Learning Model for Planning Robust Grasps", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the field of robot grasping have shown great\nimprovements in the grasp success rates when dealing with unknown objects. In\nthis work we improve on one of the most promising approaches, the Grasp Quality\nConvolutional Neural Network (GQ-CNN) trained on the DexNet 2.0 dataset. We\npropose a new architecture for the GQ-CNN and describe practical improvements\nthat increase the model validation accuracy from 92.2% to 95.8% and from 85.9%\nto 88.0% on respectively image-wise and object-wise training and validation\nsplits.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 15:54:31 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Ja\u015bkowski", "Maciej", "", "NoMagic.AI"], ["\u015awi\u0105tkowski", "Jakub", "", "NoMagic.AI"], ["Zaj\u0105c", "Micha\u0142", "", "NoMagic.AI"], ["Klimek", "Maciej", "", "NoMagic.AI"], ["Potiuk", "Jarek", "", "NoMagic.AI"], ["Rybicki", "Piotr", "", "NoMagic.AI"], ["Polatowski", "Piotr", "", "NoMagic.AI"], ["Walczyk", "Przemys\u0142aw", "", "NoMagic.AI"], ["Nowicki", "Kacper", "", "NoMagic.AI"], ["Cygan", "Marek", "", "1\n  and 2"]]}, {"id": "1802.05998", "submitter": "Tomas Teijeiro", "authors": "Tom\\'as Teijeiro, Constantino A. Garc\\'ia, Daniel Castro and Paulo\n  F\\'elix", "title": "Abductive reasoning as the basis to reproduce expert criteria in ECG\n  Atrial Fibrillation identification", "comments": "15 pages, 6 figures, 6 tables", "journal-ref": null, "doi": "10.1088/1361-6579/aad7e4", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This work aims at providing a new method for the automatic\ndetection of atrial fibrillation, other arrhythmia and noise on short single\nlead ECG signals, emphasizing the importance of the interpretability of the\nclassification results.\n  Approach: A morphological and rhythm description of the cardiac behavior is\nobtained by a knowledge-based interpretation of the signal using the\n\\textit{Construe} abductive framework. Then, a set of meaningful features are\nextracted for each individual heartbeat and as a summary of the full record.\nThe feature distributions were used to elucidate the expert criteria underlying\nthe labeling of the 2017 Physionet/CinC Challenge dataset, enabling a manual\npartial relabeling to improve the consistency of the classification rules.\nFinally, state-of-the-art machine learning methods are combined to provide an\nanswer on the basis of the feature values.\n  Main results: The proposal tied for the first place in the official stage of\nthe Challenge, with a combined $F_1$ score of 0.83, and was even improved in\nthe follow-up stage to 0.85 with a significant simplification of the model.\n  Significance: This approach demonstrates the potential of \\textit{Construe}\nto provide robust and valuable descriptions of temporal data even with\nsignificant amounts of noise and artifacts. Also, we discuss the importance of\na consistent classification criteria in manually labeled training datasets, and\nthe fundamental advantages of knowledge-based approaches to formalize and\nvalidate that criteria.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:06:42 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Teijeiro", "Tom\u00e1s", ""], ["Garc\u00eda", "Constantino A.", ""], ["Castro", "Daniel", ""], ["F\u00e9lix", "Paulo", ""]]}, {"id": "1802.06024", "submitter": "Sahisnu Mazumder", "authors": "Sahisnu Mazumder, Nianzu Ma and Bing Liu", "title": "Towards a Continuous Knowledge Learning Engine for Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although chatbots have been very popular in recent years, they still have\nsome serious weaknesses which limit the scope of their applications. One major\nweakness is that they cannot learn new knowledge during the conversation\nprocess, i.e., their knowledge is fixed beforehand and cannot be expanded or\nupdated during conversation. In this paper, we propose to build a general\nknowledge learning engine for chatbots to enable them to continuously and\ninteractively learn new knowledge during conversations. As time goes by, they\nbecome more and more knowledgeable and better and better at learning and\nconversation. We model the task as an open-world knowledge base completion\nproblem and propose a novel technique called lifelong interactive learning and\ninference (LiLi) to solve it. LiLi works by imitating how humans acquire\nknowledge and perform inference during an interactive conversation. Our\nexperimental results show LiLi is highly promising.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:50:27 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 06:50:11 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mazumder", "Sahisnu", ""], ["Ma", "Nianzu", ""], ["Liu", "Bing", ""]]}, {"id": "1802.06052", "submitter": "Lin Chen", "authors": "Lin Chen, Hamed Hassani, Amin Karbasi", "title": "Online Continuous Submodular Maximization", "comments": "Accepted by AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an online optimization process, where the\nobjective functions are not convex (nor concave) but instead belong to a broad\nclass of continuous submodular functions. We first propose a variant of the\nFrank-Wolfe algorithm that has access to the full gradient of the objective\nfunctions. We show that it achieves a regret bound of $O(\\sqrt{T})$ (where $T$\nis the horizon of the online optimization problem) against a\n$(1-1/e)$-approximation to the best feasible solution in hindsight. However, in\nmany scenarios, only an unbiased estimate of the gradients are available. For\nsuch settings, we then propose an online stochastic gradient ascent algorithm\nthat also achieves a regret bound of $O(\\sqrt{T})$ regret, albeit against a\nweaker $1/2$-approximation to the best feasible solution in hindsight. We also\ngeneralize our results to $\\gamma$-weakly submodular functions and prove the\nsame sublinear regret bounds. Finally, we demonstrate the efficiency of our\nalgorithms on a few problem instances, including non-convex/non-concave\nquadratic programs, multilinear extensions of submodular set functions, and\nD-optimal design.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 17:56:48 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chen", "Lin", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1802.06068", "submitter": "Peter Kokol PhD", "authors": "Peter Kokol, Jernej Zavr\\v{s}nik, Helena Bla\\v{z}un Vo\\v{s}ner", "title": "Artificial intelligence and pediatrics: A synthetic mini review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of artificial intelligence intelligencein medicine can be traced back\nto 1968 when Paycha published his paper Le diagnostic a l'aide d'intelligences\nartificielle, presentation de la premiere machine diagnostri. Few years later\nShortliffe et al. presented an expert system named Mycin which was able to\nidentify bacteria causing severe blood infections and to recommend antibiotics.\nDespite the fact that Mycin outperformed members of the Stanford medical school\nin the reliability of diagnosis it was never used in practice due to a legal\nissue who do you sue if it gives a wrong diagnosis?. However only in 2016 when\nthe artificial intelligence software built into the IBM Watson AI platform\ncorrectly diagnosed and proposed an effective treatment for a 60-year-old\nwomans rare form of leukemia the AI use in medicine become really popular.On of\nfirst papers presenting the use of AI in paediatrics was published in 1984. The\npaper introduced a computer-assisted medical decision making system called\nSHELP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 18:51:27 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kokol", "Peter", ""], ["Zavr\u0161nik", "Jernej", ""], ["Vo\u0161ner", "Helena Bla\u017eun", ""]]}, {"id": "1802.06070", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, Sergey Levine", "title": "Diversity is All You Need: Learning Skills without a Reward Function", "comments": "Videos and code for our experiments are available at:\n  https://sites.google.com/view/diayn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent creatures can explore their environments and learn useful skills\nwithout supervision. In this paper, we propose DIAYN ('Diversity is All You\nNeed'), a method for learning useful skills without a reward function. Our\nproposed method learns skills by maximizing an information theoretic objective\nusing a maximum entropy policy. On a variety of simulated robotic tasks, we\nshow that this simple objective results in the unsupervised emergence of\ndiverse skills, such as walking and jumping. In a number of reinforcement\nlearning benchmark environments, our method is able to learn a skill that\nsolves the benchmark task despite never receiving the true task reward. We show\nhow pretrained skills can provide a good parameter initialization for\ndownstream tasks, and can be composed hierarchically to solve complex, sparse\nreward tasks. Our results suggest that unsupervised discovery of skills can\nserve as an effective pretraining mechanism for overcoming challenges of\nexploration and data efficiency in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 18:57:57 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 18:45:19 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 18:56:13 GMT"}, {"version": "v4", "created": "Thu, 1 Mar 2018 17:10:25 GMT"}, {"version": "v5", "created": "Wed, 6 Jun 2018 23:07:09 GMT"}, {"version": "v6", "created": "Tue, 9 Oct 2018 23:19:52 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Gupta", "Abhishek", ""], ["Ibarz", "Julian", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.06091", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, John K. Tsotsos", "title": "Bridging Cognitive Programs and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great advances are made in pattern recognition and machine learning,\nthe successes of such fields remain restricted to narrow applications and seem\nto break down when training data is scarce, a shift in domain occurs, or when\nintelligent reasoning is required for rapid adaptation to new environments. In\nthis work, we list several of the shortcomings of modern machine-learning\nsolutions, specifically in the contexts of computer vision and in reinforcement\nlearning and suggest directions to explore in order to try to ameliorate these\nweaknesses.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 19:19:00 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1802.06108", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Clement Moulin-Frier, Marti Sanchez-Fibla, Xerxes D.\n  Arsiwalla, Paul Verschure", "title": "Modeling the Formation of Social Conventions from Embodied Real-Time\n  Interactions", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the role of real-time control and learning in the formation of social\nconventions? To answer this question, we propose a computational model that\nmatches human behavioral data in a social decision-making game that was\nanalyzed both in discrete-time and continuous-time setups. Furthermore, unlike\nprevious approaches, our model takes into account the role of sensorimotor\ncontrol loops in embodied decision-making scenarios. For this purpose, we\nintroduce the Control-based Reinforcement Learning (CRL) model. CRL is grounded\nin the Distributed Adaptive Control (DAC) theory of mind and brain, where\nlow-level sensorimotor control is modulated through perceptual and behavioral\nlearning in a layered structure. CRL follows these principles by implementing a\nfeedback control loop handling the agent's reactive behaviors (pre-wired\nreflexes), along with an adaptive layer that uses reinforcement learning to\nmaximize long-term reward. We test our model in a multi-agent game-theoretic\ntask in which coordination must be achieved to find an optimal solution. We\nshow that CRL is able to reach human-level performance on standard\ngame-theoretic metrics such as efficiency in acquiring rewards and fairness in\nreward distribution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 20:22:41 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:59:56 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 20:08:44 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Freire", "Ismael T.", ""], ["Moulin-Frier", "Clement", ""], ["Sanchez-Fibla", "Marti", ""], ["Arsiwalla", "Xerxes D.", ""], ["Verschure", "Paul", ""]]}, {"id": "1802.06137", "submitter": "Anagha Kulkarni", "authors": "Anagha Kulkarni, Siddharth Srivastava and Subbarao Kambhampati", "title": "A Unified Framework for Planning in Adversarial and Cooperative\n  Environments", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of AI systems may rely upon them to produce plans for achieving desired\nobjectives. Such AI systems should be able to compute obfuscated plans whose\nexecution in adversarial situations protects privacy, as well as legible plans\nwhich are easy for team members to understand in cooperative situations. We\ndevelop a unified framework that addresses these dual problems by computing\nplans with a desired level of comprehensibility from the point of view of a\npartially informed observer. For adversarial settings, our approach produces\nobfuscated plans with observations that are consistent with at least k goals\nfrom a set of decoy goals. By slightly varying our framework, we present an\napproach for goal legibility in cooperative settings which produces plans that\nachieve a goal while being consistent with at most j goals from a set of\nconfounding goals. In addition, we show how the observability of the observer\ncan be controlled to either obfuscate or clarify the next actions in a plan\nwhen the goal is known to the observer. We present theoretical results on the\ncomplexity analysis of our problems. We demonstrate the execution of obfuscated\nand legible plans in a cooking domain using a physical robot Fetch. We also\nprovide an empirical evaluation to show the feasibility and usefulness of our\napproaches using IPC domains.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:53:59 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 04:51:37 GMT"}, {"version": "v3", "created": "Thu, 26 Jul 2018 04:28:41 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kulkarni", "Anagha", ""], ["Srivastava", "Siddharth", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1802.06139", "submitter": "Patrick M. Pilarski", "authors": "Jaden B. Travnik, Kory W. Mathewson, Richard S. Sutton, Patrick M.\n  Pilarski", "title": "Reactive Reinforcement Learning in Asynchronous Environments", "comments": "11 pages, 7 figures, currently under journal peer review", "journal-ref": null, "doi": "10.3389/frobt.2018.00079", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between a reinforcement learning (RL) agent and an\nasynchronous environment is often ignored. Frequently used models of the\ninteraction between an agent and its environment, such as Markov Decision\nProcesses (MDP) or Semi-Markov Decision Processes (SMDP), do not capture the\nfact that, in an asynchronous environment, the state of the environment may\nchange during computation performed by the agent. In an asynchronous\nenvironment, minimizing reaction time---the time it takes for an agent to react\nto an observation---also minimizes the time in which the state of the\nenvironment may change following observation. In many environments, the\nreaction time of an agent directly impacts task performance by permitting the\nenvironment to transition into either an undesirable terminal state or a state\nwhere performing the chosen action is inappropriate. We propose a class of\nreactive reinforcement learning algorithms that address this problem of\nasynchronous environments by immediately acting after observing new state\ninformation. We compare a reactive SARSA learning algorithm with the\nconventional SARSA learning algorithm on two asynchronous robotic tasks\n(emergency stopping and impact prevention), and show that the reactive RL\nalgorithm reduces the reaction time of the agent by approximately the duration\nof the algorithm's learning update. This new class of reactive algorithms may\nfacilitate safer control and faster decision making without any change to\nstandard learning guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 21:55:01 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Travnik", "Jaden B.", ""], ["Mathewson", "Kory W.", ""], ["Sutton", "Richard S.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1802.06215", "submitter": "Panpan Cai", "authors": "Panpan Cai, Yuanfu Luo, David Hsu and Wee Sun Lee", "title": "HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning under uncertainty is critical for robust robot performance in\nuncertain, dynamic environments, but it incurs high computational cost.\nState-of-the-art online search algorithms, such as DESPOT, have vastly improved\nthe computational efficiency of planning under uncertainty and made it a\nvaluable tool for robotics in practice. This work takes one step further by\nleveraging both CPU and GPU parallelization in order to achieve near real-time\nonline planning performance for complex tasks with large state, action, and\nobservation spaces. Specifically, we propose Hybrid Parallel DESPOT\n(HyP-DESPOT), a massively parallel online planning algorithm that integrates\nCPU and GPU parallelism in a multi-level scheme. It performs parallel DESPOT\ntree search by simultaneously traversing multiple independent paths using\nmulti-core CPUs and performs parallel Monte-Carlo simulations at the leaf nodes\nof the search tree using GPUs. Experimental results show that HyP-DESPOT speeds\nup online planning by up to several hundred times, compared with the original\nDESPOT algorithm, in several challenging robotic tasks in simulation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 08:59:56 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Cai", "Panpan", ""], ["Luo", "Yuanfu", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1802.06225", "submitter": "Petros Giannakopoulos", "authors": "Petros Giannakopoulos, Yannis Cotronis", "title": "A Deep Q-Learning Agent for the L-Game with Variable Batch Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ the Deep Q-Learning algorithm with Experience Replay to train an\nagent capable of achieving a high-level of play in the L-Game while\nself-learning from low-dimensional states. We also employ variable batch size\nfor training in order to mitigate the loss of the rare reward signal and\nsignificantly accelerate training. Despite the large action space due to the\nnumber of possible moves, the low-dimensional state space and the rarity of\nrewards, which only come at the end of a game, DQL is successful in training an\nagent capable of strong play without the use of any search methods or domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 11:45:09 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Giannakopoulos", "Petros", ""], ["Cotronis", "Yannis", ""]]}, {"id": "1802.06259", "submitter": "Lingyang Chu", "authors": "Lingyang Chu, Xia Hu, Juhua Hu, Lanjun Wang, Jian Pei", "title": "Exact and Consistent Interpretation for Piecewise Linear Neural\n  Networks: A Closed Form Solution", "comments": "KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strong intelligent machines powered by deep neural networks are increasingly\ndeployed as black boxes to make decisions in risk-sensitive domains, such as\nfinance and medical. To reduce potential risk and build trust with users, it is\ncritical to interpret how such machines make their decisions. Existing works\ninterpret a pre-trained neural network by analyzing hidden neurons, mimicking\npre-trained models or approximating local predictions. However, these methods\ndo not provide a guarantee on the exactness and consistency of their\ninterpretation. In this paper, we propose an elegant closed form solution named\n$OpenBox$ to compute exact and consistent interpretations for the family of\nPiecewise Linear Neural Networks (PLNN). The major idea is to first transform a\nPLNN into a mathematically equivalent set of linear classifiers, then interpret\neach linear classifier by the features that dominate its prediction. We further\napply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse\nconstraints on improving the interpretability of PLNNs. The extensive\nexperiments on both synthetic and real world data sets clearly demonstrate the\nexactness and consistency of our interpretation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 16:47:32 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 17:21:14 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Chu", "Lingyang", ""], ["Hu", "Xia", ""], ["Hu", "Juhua", ""], ["Wang", "Lanjun", ""], ["Pei", "Jian", ""]]}, {"id": "1802.06260", "submitter": "Naji Khosravan", "authors": "Naji Khosravan, Haydar Celik, Baris Turkbey, Elizabeth Jones, Bradford\n  Wood, Ulas Bagci", "title": "A Collaborative Computer Aided Diagnosis (C-CAD) System with\n  Eye-Tracking, Sparse Attentional Model, and Deep Learning", "comments": "Submitted to Medical Image Analysis Journal (MedIA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are at least two categories of errors in radiology screening that can\nlead to suboptimal diagnostic decisions and interventions:(i)human fallibility\nand (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are\ndeveloped to help radiologists to compensate for some of these errors. However,\ndespite their significant improvements over conventional screening strategies,\nmost CAD systems do not go beyond their use as second opinion tools due to\nproducing a high number of false positives, which human interpreters need to\ncorrect. In parallel with efforts in computerized analysis of radiology scans,\nseveral researchers have examined behaviors of radiologists while screening\nmedical images to better understand how and why they miss tumors, how they\ninteract with the information in an image, and how they search for unknown\npathology in the images. Eye-tracking tools have been instrumental in exploring\nanswers to these fundamental questions. In this paper, we aim to develop a\nparadigm shift CAD system, called collaborative CAD (C-CAD), that unifies both\nof the above mentioned research lines: CAD and eye-tracking. We design an\neye-tracking interface providing radiologists with a real radiology reading\nroom experience. Then, we propose a novel algorithm that unifies eye-tracking\ndata and a CAD system. Specifically, we present a new graph based clustering\nand sparsification algorithm to transform eye-tracking data (gaze) into a\nsignal model to interpret gaze patterns quantitatively and qualitatively. The\nproposed C-CAD collaborates with radiologists via eye-tracking technology and\nhelps them to improve diagnostic decisions. The C-CAD learns radiologists'\nsearch efficiency by processing their gaze patterns. To do this, the C-CAD uses\na deep learning algorithm in a newly designed multi-task learning platform to\nsegment and diagnose cancers simultaneously.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 17:20:50 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 15:06:18 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Khosravan", "Naji", ""], ["Celik", "Haydar", ""], ["Turkbey", "Baris", ""], ["Jones", "Elizabeth", ""], ["Wood", "Bradford", ""], ["Bagci", "Ulas", ""]]}, {"id": "1802.06306", "submitter": "Ziming Li", "authors": "Ziming Li, Julia Kiseleva, Alekh Agarwal, Maarten de Rijke", "title": "Learning Data-Driven Objectives to Optimize Interactive Systems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective optimization is essential for interactive systems to provide a\nsatisfactory user experience. However, it is often challenging to find an\nobjective to optimize for. Generally, such objectives are manually crafted and\nrarely capture complex user needs in an accurate manner. We propose an approach\nthat infers the objective directly from observed user interactions. These\ninferences can be made regardless of prior knowledge and across different types\nof user behavior. We introduce interactive system optimization, a novel\nalgorithm that uses these inferred objectives for optimization. Our main\ncontribution is a new general principled approach to optimizing interactive\nsystems using data-driven objectives. We demonstrate the high effectiveness of\ninteractive system optimization over several simulations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 23:04:15 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 09:09:57 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 17:24:19 GMT"}, {"version": "v4", "created": "Wed, 2 May 2018 14:45:08 GMT"}, {"version": "v5", "created": "Tue, 8 May 2018 15:33:21 GMT"}, {"version": "v6", "created": "Tue, 16 Oct 2018 15:54:49 GMT"}, {"version": "v7", "created": "Wed, 17 Oct 2018 10:25:51 GMT"}, {"version": "v8", "created": "Fri, 13 Dec 2019 22:11:21 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["Agarwal", "Alekh", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1802.06314", "submitter": "Sarah Thornton", "authors": "Sarah Thornton", "title": "Autonomous Vehicle Speed Control for Safe Navigation of Occluded\n  Pedestrian Crosswalk", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both humans and the sensors on an autonomous vehicle have limited sensing\ncapabilities. When these limitations coincide with scenarios involving\nvulnerable road users, it becomes important to account for these limitations in\nthe motion planner. For the scenario of an occluded pedestrian crosswalk, the\nspeed of the approaching vehicle should be a function of the amount of\nuncertainty on the roadway. In this work, the longitudinal controller is\nformulated as a partially observable Markov decision process and dynamic\nprogramming is used to compute the control policy. The control policy scales\nthe speed profile to be used by a model predictive steering controller.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 00:18:01 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Thornton", "Sarah", ""]]}, {"id": "1802.06318", "submitter": "Matheus Nohra Haddad", "authors": "Matheus Nohra Haddad, Rafael Martinelli, Thibaut Vidal, Luiz Satoru\n  Ochi, Simone Martins, Marcone Jamilson Freitas Souza, Richard Hartl", "title": "Large Neighborhood-Based Metaheuristic and Branch-and-Price for the\n  Pickup and Delivery Problem with Split Loads", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-vehicle one-to-one pickup and delivery problem with\nsplit loads, a NP-hard problem linked with a variety of applications for bulk\nproduct transportation, bike-sharing systems and inventory re-balancing. This\nproblem is notoriously difficult due to the interaction of two challenging\nvehicle routing attributes, \"pickups and deliveries\" and \"split deliveries\".\nThis possibly leads to optimal solutions of a size that grows exponentially\nwith the instance size, containing multiple visits per customer pair, even in\nthe same route. To solve this problem, we propose an iterated local search\nmetaheuristic as well as a branch-and-price algorithm. The core of the\nmetaheuristic consists of a new large neighborhood search, which reduces the\nproblem of finding the best insertion combination of a pickup and delivery pair\ninto a route (with possible splits) to a resource-constrained shortest path and\nknapsack problem. Similarly, the branch-and-price algorithm uses sophisticated\nlabeling techniques, route relaxations, pre-processing and branching rules for\nan efficient resolution. Our computational experiments on classical\nsingle-vehicle instances demonstrate the excellent performance of the\nmetaheuristic, which produces new best known solutions for 92 out of 93 test\ninstances, and outperforms all previous algorithms. Experimental results on new\nmulti-vehicle instances with distance constraints are also reported. The\nbranch-and-price algorithm produces optimal solutions for instances with up to\n20 pickup-and-delivery pairs, and very accurate solutions are found by the\nmetaheuristic.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 02:09:20 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Haddad", "Matheus Nohra", ""], ["Martinelli", "Rafael", ""], ["Vidal", "Thibaut", ""], ["Ochi", "Luiz Satoru", ""], ["Martins", "Simone", ""], ["Souza", "Marcone Jamilson Freitas", ""], ["Hartl", "Richard", ""]]}, {"id": "1802.06357", "submitter": "Yunwen Lei", "authors": "Yunwen Lei and Ding-Xuan Zhou", "title": "Convergence of Online Mirror Descent", "comments": "Published in Applied and Computational Harmonic Analysis, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider online mirror descent (OMD) algorithms, a class of\nscalable online learning algorithms exploiting data geometric structures\nthrough mirror maps. Necessary and sufficient conditions are presented in terms\nof the step size sequence $\\{\\eta_t\\}_{t}$ for the convergence of an OMD\nalgorithm with respect to the expected Bregman distance induced by the mirror\nmap. The condition is $\\lim_{t\\to\\infty}\\eta_t=0,\n\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of positive variances. It is\nreduced to $\\sum_{t=1}^{\\infty}\\eta_t=\\infty$ in the case of zero variances for\nwhich the linear convergence may be achieved by taking a constant step size\nsequence. A sufficient condition on the almost sure convergence is also given.\nWe establish tight error bounds under mild conditions on the mirror map, the\nloss function, and the regularizer. Our results are achieved by some novel\nanalysis on the one-step progress of the OMD algorithm using smoothness and\nstrong convexity of the mirror map and the loss function.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 09:36:09 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 05:44:02 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Lei", "Yunwen", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1802.06382", "submitter": "Yasuo Tabei", "authors": "Yasuo Tabei, Yoshihiro Yamanishi, Rasmus Pagh", "title": "Space-efficient Feature Maps for String Alignment Kernels", "comments": "Full version for ICDM'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String kernels are attractive data analysis tools for analyzing string data.\nAmong them, alignment kernels are known for their high prediction accuracies in\nstring classifications when tested in combination with SVM in various\napplications. However, alignment kernels have a crucial drawback in that they\nscale poorly due to their quadratic computation complexity in the number of\ninput strings, which limits large-scale applications in practice. We address\nthis need by presenting the first approximation for string alignment kernels,\nwhich we call space-efficient feature maps for edit distance with moves\n(SFMEDM), by leveraging a metric embedding named edit sensitive parsing (ESP)\nand feature maps (FMs) of random Fourier features (RFFs) for large-scale string\nanalyses. The original FMs for RFFs consume a huge amount of memory\nproportional to the dimension d of input vectors and the dimension D of output\nvectors, which prohibits its large-scale applications. We present novel\nspace-efficient feature maps (SFMs) of RFFs for a space reduction from O(dD) of\nthe original FMs to O(d) of SFMs with a theoretical guarantee with respect to\nconcentration bounds. We experimentally test SFMEDM on its ability to learn SVM\nfor large-scale string classifications with various massive string data, and we\ndemonstrate the superior performance of SFMEDM with respect to prediction\naccuracy, scalability and computation efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 14:16:28 GMT"}, {"version": "v10", "created": "Thu, 14 Nov 2019 02:42:51 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 06:29:59 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2018 14:37:53 GMT"}, {"version": "v4", "created": "Sun, 25 Mar 2018 05:46:27 GMT"}, {"version": "v5", "created": "Wed, 28 Mar 2018 01:33:34 GMT"}, {"version": "v6", "created": "Wed, 6 Feb 2019 08:45:03 GMT"}, {"version": "v7", "created": "Mon, 26 Aug 2019 08:36:23 GMT"}, {"version": "v8", "created": "Mon, 2 Sep 2019 07:04:07 GMT"}, {"version": "v9", "created": "Tue, 10 Sep 2019 08:15:08 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Tabei", "Yasuo", ""], ["Yamanishi", "Yoshihiro", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1802.06412", "submitter": "Florian Kreyssig", "authors": "Florian Kreyssig, Chao Zhang, Philip Woodland", "title": "Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs", "comments": "5 pages, 3 figures, 2 tables, to appear in 2018 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time delay neural networks (TDNNs) are an effective acoustic model for large\nvocabulary speech recognition. The strength of the model can be attributed to\nits ability to effectively model long temporal contexts. However, current TDNN\nmodels are relatively shallow, which limits the modelling capability. This\npaper proposes a method of increasing the network depth by deepening the kernel\nused in the TDNN temporal convolutions. The best performing kernel consists of\nthree fully connected layers with a residual (ResNet) connection from the\noutput of the first to the output of the third. The addition of\nspectro-temporal processing as the input to the TDNN in the form of a\nconvolutional neural network (CNN) and a newly designed Grid-RNN was\ninvestigated. The Grid-RNN strongly outperforms a CNN if different sets of\nparameters for different frequency bands are used and can be further enhanced\nby using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast\n(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error\nrate (WER) by 6% relative and when combined with the frequency dependent\nGrid-RNN gives a relative WER reduction of 9%.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 17:54:19 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 14:07:05 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Kreyssig", "Florian", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1802.06416", "submitter": "Zhenqiang Su", "authors": "Yongxi Tan, Jin Yang, Xin Chen, Qitao Song, Yunjun Chen, Zhangxiang\n  Ye, Zhenqiang Su", "title": "Sim-to-Real Optimization of Complex Real World Mobile Network with\n  Imperfect Information via Deep Reinforcement Learning from Self-play", "comments": "Accepted by NIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile network that millions of people use every day is one of the most\ncomplex systems in the world. Optimization of mobile network to meet exploding\ncustomer demand and reduce capital/operation expenditures poses great\nchallenges. Despite recent progress, application of deep reinforcement learning\n(DRL) to complex real world problem still remains unsolved, given data\nscarcity, partial observability, risk and complex rules/dynamics in real world,\nas well as the huge reality gap between simulation and real world. To bridge\nthe reality gap, we introduce a Sim-to-Real framework to directly transfer\nlearning from simulation to real world via graph convolutional neural network\n(CNN) - by abstracting partially observable mobile network into graph, then\ndistilling domain-variant irregular graph into domain-invariant tensor in\nlocally Euclidean space as input to CNN -, domain randomization and multi-task\nlearning. We use a novel self-play mechanism to encourage competition among DRL\nagents for best record on multiple tasks via simulated annealing, just like\nathletes compete for world record in decathlon. We also propose a decentralized\nmulti-agent, competitive and cooperative DRL method to coordinate the actions\nof multi-cells to maximize global reward and minimize negative impact to\nneighbor cells. Using 6 field trials on commercial mobile networks, we\ndemonstrate for the first time that a DRL agent can successfully transfer\nlearning from simulation to complex real world problem with imperfect\ninformation, complex rules/dynamics, huge state/action space, and multi-agent\ninteractions, without any training in the real world.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 18:03:39 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 23:45:16 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 12:09:16 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Tan", "Yongxi", ""], ["Yang", "Jin", ""], ["Chen", "Xin", ""], ["Song", "Qitao", ""], ["Chen", "Yunjun", ""], ["Ye", "Zhangxiang", ""], ["Su", "Zhenqiang", ""]]}, {"id": "1802.06426", "submitter": "Zoran Tiganj", "authors": "Zoran Tiganj, Samuel J. Gershman, Per B. Sederberg, Marc W. Howard", "title": "Estimating scale-invariant future in continuous time", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural learners must compute an estimate of future outcomes that follow from\na stimulus in continuous time. Widely used reinforcement learning algorithms\ndiscretize continuous time and estimate either transition functions from one\nstep to the next (model-based algorithms) or a scalar value of\nexponentially-discounted future reward using the Bellman equation (model-free\nalgorithms). An important drawback of model-based algorithms is that\ncomputational cost grows linearly with the amount of time to be simulated. On\nthe other hand, an important drawback of model-free algorithms is the need to\nselect a time-scale required for exponential discounting. We present a\ncomputational mechanism, developed based on work in psychology and\nneuroscience, for computing a scale-invariant timeline of future outcomes. This\nmechanism efficiently computes an estimate of inputs as a function of future\ntime on a logarithmically-compressed scale, and can be used to generate a\nscale-invariant power-law-discounted estimate of expected future reward. The\nrepresentation of future time retains information about what will happen when.\nThe entire timeline can be constructed in a single parallel operation which\ngenerates concrete behavioral and neural predictions. This computational\nmechanism could be incorporated into future reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 19:09:28 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 21:43:23 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 23:46:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tiganj", "Zoran", ""], ["Gershman", "Samuel J.", ""], ["Sederberg", "Per B.", ""], ["Howard", "Marc W.", ""]]}, {"id": "1802.06444", "submitter": "Kaixiang Lin", "authors": "Kaixiang Lin, Renyu Zhao, Zhe Xu and Jiayu Zhou", "title": "Efficient Collaborative Multi-Agent Deep Reinforcement Learning for\n  Large-Scale Fleet Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale online ride-sharing platforms have substantially transformed our\nlives by reallocating transportation resources to alleviate traffic congestion\nand promote transportation efficiency. An efficient fleet management strategy\nnot only can significantly improve the utilization of transportation resources\nbut also increase the revenue and customer satisfaction. It is a challenging\ntask to design an effective fleet management strategy that can adapt to an\nenvironment involving complex dynamics between demand and supply. Existing\nstudies usually work on a simplified problem setting that can hardly capture\nthe complicated stochastic demand-supply variations in high-dimensional space.\nIn this paper we propose to tackle the large-scale fleet management problem\nusing reinforcement learning, and propose a contextual multi-agent\nreinforcement learning framework including three concrete algorithms to achieve\ncoordination among a large number of agents adaptive to different contexts. We\nshow significant improvements of the proposed framework over state-of-the-art\napproaches through extensive empirical studies.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 21:06:19 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:07:18 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 01:35:56 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lin", "Kaixiang", ""], ["Zhao", "Renyu", ""], ["Xu", "Zhe", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06467", "submitter": "Adam Liska", "authors": "Adam Li\\v{s}ka, Germ\\'an Kruszewski, Marco Baroni", "title": "Memorize or generalize? Searching for a compositional RNN in a haystack", "comments": "AEGAP Workshop (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are very powerful learning systems, but they do not readily\ngeneralize from one task to the other. This is partly due to the fact that they\ndo not learn in a compositional way, that is, by discovering skills that are\nshared by different tasks, and recombining them to solve new problems. In this\npaper, we explore the compositional generalization capabilities of recurrent\nneural networks (RNNs). We first propose the lookup table composition domain as\na simple setup to test compositional behaviour and show that it is\ntheoretically possible for a standard RNN to learn to behave compositionally in\nthis domain when trained with standard gradient descent and provided with\nadditional supervision. We then remove this additional supervision and perform\na search over a large number of model initializations to investigate the\nproportion of RNNs that can still converge to a compositional solution. We\ndiscover that a small but non-negligible proportion of RNNs do reach partial\ncompositional solutions even without special architectural constraints. This\nsuggests that a combination of gradient descent and evolutionary strategies\ndirectly favouring the minority models that developed more compositional\napproaches might suffice to lead standard RNNs towards compositional solutions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 23:15:26 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 18:55:27 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Li\u0161ka", "Adam", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Baroni", "Marco", ""]]}, {"id": "1802.06476", "submitter": "Bin Liu", "authors": "Bin Liu, Ying Li, Soumya Ghosh, Zhaonan Sun, Kenney Ng and Jianying Hu", "title": "Simultaneous Modeling of Multiple Complications for Risk Profiling in\n  Diabetes Care", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2019", "doi": "10.1109/TKDE.2019.2904060", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type 2 diabetes mellitus (T2DM) is a chronic disease that often results in\nmultiple complications. Risk prediction and profiling of T2DM complications is\ncritical for healthcare professionals to design personalized treatment plans\nfor patients in diabetes care for improved outcomes. In this paper, we study\nthe risk of developing complications after the initial T2DM diagnosis from\nlongitudinal patient records. We propose a novel multi-task learning approach\nto simultaneously model multiple complications where each task corresponds to\nthe risk modeling of one complication. Specifically, the proposed method\nstrategically captures the relationships (1) between the risks of multiple T2DM\ncomplications, (2) between the different risk factors, and (3) between the risk\nfactor selection patterns. The method uses coefficient shrinkage to identify an\ninformative subset of risk factors from high-dimensional data, and uses a\nhierarchical Bayesian framework to allow domain knowledge to be incorporated as\npriors. The proposed method is favorable for healthcare applications because in\nadditional to improved prediction performance, relationships among the\ndifferent risks and risk factors are also identified. Extensive experimental\nresults on a large electronic medical claims database show that the proposed\nmethod outperforms state-of-the-art models by a significant margin.\nFurthermore, we show that the risk associations learned and the risk factors\nidentified lead to meaningful clinical insights.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:01:33 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Liu", "Bin", ""], ["Li", "Ying", ""], ["Ghosh", "Soumya", ""], ["Sun", "Zhaonan", ""], ["Ng", "Kenney", ""], ["Hu", "Jianying", ""]]}, {"id": "1802.06480", "submitter": "Qingkai Liang", "authors": "Qingkai Liang, Fanyu Que, Eytan Modiano", "title": "Accelerated Primal-Dual Policy Optimization for Safe Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Process (CMDP) is a natural framework for\nreinforcement learning tasks with safety constraints, where agents learn a\npolicy that maximizes the long-term reward while satisfying the constraints on\nthe long-term cost. A canonical approach for solving CMDPs is the primal-dual\nmethod which updates parameters in primal and dual spaces in turn. Existing\nmethods for CMDPs only use on-policy data for dual updates, which results in\nsample inefficiency and slow convergence. In this paper, we propose a policy\nsearch method for CMDPs called Accelerated Primal-Dual Optimization (APDO),\nwhich incorporates an off-policy trained dual variable in the dual update\nprocedure while updating the policy in primal space with on-policy likelihood\nratio gradient. Experimental results on a simulated robot locomotion task show\nthat APDO achieves better sample efficiency and faster convergence than\nstate-of-the-art approaches for CMDPs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:25:26 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liang", "Qingkai", ""], ["Que", "Fanyu", ""], ["Modiano", "Eytan", ""]]}, {"id": "1802.06485", "submitter": "Arun Sai Suggala", "authors": "Adarsh Prasad, Arun Sai Suggala, Sivaraman Balakrishnan, Pradeep\n  Ravikumar", "title": "Robust Estimation via Robust Gradient Estimation", "comments": "48 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new computationally-efficient class of estimators for risk\nminimization. We show that these estimators are robust for general statistical\nmodels: in the classical Huber epsilon-contamination model and in heavy-tailed\nsettings. Our workhorse is a novel robust variant of gradient descent, and we\nprovide conditions under which our gradient descent variant provides accurate\nestimators in a general convex risk minimization problem. We provide specific\nconsequences of our theory for linear regression, logistic regression and for\nestimation of the canonical parameters in an exponential family. These results\nprovide some of the first computationally tractable and provably robust\nestimators for these canonical statistical models. Finally, we study the\nempirical performance of our proposed methods on synthetic and real datasets,\nand find that our methods convincingly outperform a variety of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:49:31 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:07:30 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Prasad", "Adarsh", ""], ["Suggala", "Arun Sai", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1802.06488", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mohammad Javad Shafiee, Francis Li, Brendan Chwyl", "title": "Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network\n  for Real-time Embedded Object Detection", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is a major challenge in computer vision, involving both\nobject classification and object localization within a scene. While deep neural\nnetworks have been shown in recent years to yield very powerful techniques for\ntackling the challenge of object detection, one of the biggest challenges with\nenabling such object detection networks for widespread deployment on embedded\ndevices is high computational and memory requirements. Recently, there has been\nan increasing focus in exploring small deep neural network architectures for\nobject detection that are more suitable for embedded devices, such as Tiny YOLO\nand SqueezeDet. Inspired by the efficiency of the Fire microarchitecture\nintroduced in SqueezeNet and the object detection performance of the\nsingle-shot detection macroarchitecture introduced in SSD, this paper\nintroduces Tiny SSD, a single-shot detection deep convolutional neural network\nfor real-time embedded object detection that is composed of a highly optimized,\nnon-uniform Fire sub-network stack and a non-uniform sub-network stack of\nhighly optimized SSD-based auxiliary convolutional feature layers designed\nspecifically to minimize model size while maintaining object detection\nperformance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller\nthan Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher\nthan Tiny YOLO). These experimental results show that very small deep neural\nnetwork architectures can be designed for real-time object detection that are\nwell-suited for embedded scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 01:57:46 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Wong", "Alexander", ""], ["Shafiee", "Mohammad Javad", ""], ["Li", "Francis", ""], ["Chwyl", "Brendan", ""]]}, {"id": "1802.06516", "submitter": "Mengying Sun", "authors": "Mengying Sun, Inci M. Baytas, Liang Zhan, Zhangyang Wang, Jiayu Zhou", "title": "Subspace Network: Deep Multi-Task Censored Regression for Modeling\n  Neurodegenerative Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade a wide spectrum of machine learning models have been\ndeveloped to model the neurodegenerative diseases, associating biomarkers,\nespecially non-intrusive neuroimaging markers, with key clinical scores\nmeasuring the cognitive status of patients. Multi-task learning (MTL) has been\ncommonly utilized by these studies to address high dimensionality and small\ncohort size challenges. However, most existing MTL approaches are based on\nlinear models and suffer from two major limitations: 1) they cannot explicitly\nconsider upper/lower bounds in these clinical scores; 2) they lack the\ncapability to capture complicated non-linear interactions among the variables.\nIn this paper, we propose Subspace Network, an efficient deep modeling approach\nfor non-linear multi-task censored regression. Each layer of the subspace\nnetwork performs a multi-task censored regression to improve upon the\npredictions from the last layer via sketching a low-dimensional subspace to\nperform knowledge transfer among learning tasks. Under mild assumptions, for\neach layer the parametric subspace can be recovered using only one pass of\ntraining data. Empirical results demonstrate that the proposed subspace network\nquickly picks up the correct parameter subspaces, and outperforms\nstate-of-the-arts in predicting neurodegenerative clinical scores using\ninformation in brain imaging.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 04:50:14 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 04:34:15 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Sun", "Mengying", ""], ["Baytas", "Inci M.", ""], ["Zhan", "Liang", ""], ["Wang", "Zhangyang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1802.06521", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Li-Wei Ko, Naoyuki Kubota, Lu-An Lin,\n  Shinya Kitaoka, Yu-Te Wang, and Shun-Feng Su", "title": "Human and Smart Machine Co-Learning with Brain Computer Interface", "comments": "This article will be published in IEEE SMC Magazine, vol. 4, no. 2,\n  2018", "journal-ref": null, "doi": "10.1109/MSMC.2017.2785441", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has become a very popular approach for cybernetics systems,\nand it has always been considered important research in the Computational\nIntelligence area. Nevertheless, when it comes to smart machines, it is not\njust about the methodologies. We need to consider systems and cybernetics as\nwell as include human in the loop. The purpose of this article is as follows:\n(1) To integrate the open source Facebook AI Research (FAIR) DarkForest program\nof Facebook with Item Response Theory (IRT), to the new open learning system,\nnamely, DDF learning system; (2) To integrate DDF Go with Robot namely Robotic\nDDF Go system; (3) To invite the professional Go players to attend the activity\nto play Go games on site with a smart machine. The research team will apply\nthis technology to education, such as, playing games to enhance the children\nconcentration on learning mathematics, languages, and other topics. With the\ndetected brainwaves, the robot will be able to speak some words that are very\nmuch to the point for the students and to assist the teachers in classroom in\nthe future.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 05:42:09 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Ko", "Li-Wei", ""], ["Kubota", "Naoyuki", ""], ["Lin", "Lu-An", ""], ["Kitaoka", "Shinya", ""], ["Wang", "Yu-Te", ""], ["Su", "Shun-Feng", ""]]}, {"id": "1802.06588", "submitter": "Rodrigo Marcos", "authors": "Rodrigo Marcos, Oliva Garc\\'ia-Cant\\'u, Ricardo Herranz", "title": "A Machine Learning Approach to Air Traffic Route Choice Modelling", "comments": "Submitted for review to Transportation Research Part C: Emerging\n  Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air Traffic Flow and Capacity Management (ATFCM) is one of the constituent\nparts of Air Traffic Management (ATM). The goal of ATFCM is to make airport and\nairspace capacity meet traffic demand and, when capacity opportunities are\nexhausted, optimise traffic flows to meet the available capacity. One of the\nkey enablers of ATFCM is the accurate estimation of future traffic demand. The\navailable information (schedules, flight plans, etc.) and its associated level\nof uncertainty differ across the different ATFCM planning phases, leading to\nqualitative differences between the types of forecasting that are feasible at\neach time horizon. While abundant research has been conducted on tactical\ntrajectory prediction (i.e., during the day of operations), trajectory\nprediction in the pre-tactical phase, when few or no flight plans are\navailable, has received much less attention. As a consequence, the methods\ncurrently in use for pre-tactical traffic forecast are still rather\nrudimentary, often resulting in suboptimal ATFCM decision making. This paper\nproposes a machine learning approach for the prediction of airlines route\nchoices between two airports as a function of route characteristics, such as\nflight efficiency, air navigation charges and expected level of congestion.\nDifferent predictive models based on multinomial logistic regression and\ndecision trees are formulated and calibrated with historical traffic data, and\na critical evaluation of each model is conducted. We analyse the predictive\npower of each model in terms of its ability to forecast traffic volumes at the\nlevel of charging zones, proving significant potential to enhance pre-tactical\ntraffic forecast. We conclude by discussing the limitations and room for\nimprovement of the proposed approach, as well as the future developments\nrequired to produce reliable traffic forecasts at a higher spatial and temporal\nresolution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 11:25:18 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 07:51:14 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Marcos", "Rodrigo", ""], ["Garc\u00eda-Cant\u00fa", "Oliva", ""], ["Herranz", "Ricardo", ""]]}, {"id": "1802.06604", "submitter": "Garrett Andersen", "authors": "Garrett Andersen, Peter Vrancx, Haitham Bou-Ammar", "title": "Learning High-level Representations from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical learning (HL) is key to solving complex sequential decision\nproblems with long horizons and sparse rewards. It allows learning agents to\nbreak-up large problems into smaller, more manageable subtasks. A common\napproach to HL, is to provide the agent with a number of high-level skills that\nsolve small parts of the overall problem. A major open question, however, is\nhow to identify a suitable set of reusable skills. We propose a principled\napproach that uses human demonstrations to infer a set of subgoals based on\nchanges in the demonstration dynamics. Using these subgoals, we decompose the\nlearning problem into an abstract high-level representation and a set of\nlow-level subtasks. The abstract description captures the overall problem\nstructure, while subtasks capture desired skills. We demonstrate that we can\njointly optimize over both levels of learning. We show that the resulting\nmethod significantly outperforms previous baselines on two challenging\nproblems: the Atari 2600 game Montezuma's Revenge, and a simulated robotics\nproblem moving the ant robot through a maze.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 12:11:16 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 10:09:48 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 17:06:59 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Andersen", "Garrett", ""], ["Vrancx", "Peter", ""], ["Bou-Ammar", "Haitham", ""]]}, {"id": "1802.06698", "submitter": "Patrick Bl\\\"obaum", "authors": "Patrick Bl\\\"obaum, Dominik Janzing, Takashi Washio, Shohei Shimizu,\n  Bernhard Sch\\\"olkopf", "title": "Analysis of cause-effect inference by comparing regression errors", "comments": "This is an extended version of the AISTATS 2018 paper", "journal-ref": "PeerJ, 2019", "doi": "10.7717/peerj-cs.169", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of inferring the causal direction between two\nvariables by comparing the least-squares errors of the predictions in both\npossible directions. Under the assumption of an independence between the\nfunction relating cause and effect, the conditional noise distribution, and the\ndistribution of the cause, we show that the errors are smaller in causal\ndirection if both variables are equally scaled and the causal relation is close\nto deterministic. Based on this, we provide an easily applicable algorithm that\nonly requires a regression in both possible causal directions and a comparison\nof the errors. The performance of the algorithm is compared with various\nrelated causal inference methods in different artificial and real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 16:50:05 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 18:21:20 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bl\u00f6baum", "Patrick", ""], ["Janzing", "Dominik", ""], ["Washio", "Takashi", ""], ["Shimizu", "Shohei", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1802.06767", "submitter": "Kyrylo Malakhov", "authors": "A. V. Palagin, N.G. Petrenko, V.Yu. Velychko, K.S. Malakhov", "title": "The problem of the development ontology-driven architecture of\n  intellectual software systems", "comments": "in Russian; \"Bibliography\" section updated for correct identification\n  of references by the Google Scholar parser software; 6 pages; 6 figures", "journal-ref": "Visnik of the Volodymyr Dahl East ukrainian national university 13\n  (2011) 179-184 Luhansk", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the architecture of the intelligence system for automated\ndesign of ontological knowledge bases of domain areas and the software model of\nthe management GUI (Graphical User Interface) subsystem\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 10:24:01 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 12:57:27 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""]]}, {"id": "1802.06768", "submitter": "Kyrylo Malakhov", "authors": "O. V. Palagin, K. S. Malakhov, V. Yu. Velichko, O. S. Shurov", "title": "Design and software implementation of subsystems for creating and using\n  the ontological base of a research scientist", "comments": "in Ukrainian; updated \"Bibliography\" section for correct\n  identification of references by the Google Scholar parser software; 11 pages;\n  1 figure", "journal-ref": "Problems in programming 2 (2017) 72-81", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creation of the information systems and tools for scientific research and\ndevelopment support has always been one of the central directions of the\ndevelopment of computer science. The main features of the modern evolution of\nscientific research and development are the transdisciplinary approach and the\ndeep intellectualisation of all stages of the life cycle of formulation and\nsolution of scientific problems. The theoretical and practical aspects of the\ndevelopment of perspective complex knowledge-oriented information systems and\ntheir components are considered in the paper. The analysis of existing\nscientific information systems (or current research information systems, CRIS)\nand synthesis of general principles of design of the research and development\nworkstation environment of a researcher and its components are carried out in\nthe work. The functional components of knowledge-oriented information system\nresearch and development workstation environment of a researcher are designed.\nDesigned and developed functional components of knowledge-oriented information\nsystem developing research and development workstation environment,including\nfunctional models and software implementation of the software subsystem for\ncreation and use of ontological knowledge base for research fellow\npublications, as part of personalized knowledge base of scientific researcher.\nResearch in modern conditions of e-Science paradigm requires pooling scientific\ncommunity and intensive exchange of research results that may be achieved\nthrough the use of scientific information systems. research and development\nworkstation environment allows to solve problems of contructivisation and\nformalisation of knowledge representation, obtained during the research process\nand collective accomplices interaction.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 10:46:22 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 11:58:09 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Palagin", "O. V.", ""], ["Malakhov", "K. S.", ""], ["Velichko", "V. Yu.", ""], ["Shurov", "O. S.", ""]]}, {"id": "1802.06769", "submitter": "Kyrylo Malakhov", "authors": "A. V. Palagin, N. G. Petrenko, K. S. Malakhov", "title": "Technique for designing a domain ontology", "comments": "in Russian", "journal-ref": "Computer means, networks and systems 10 (2011) 5-12", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article describes the technique for designing a domain ontology, shows\nthe flowchart of algorithm design and example of constructing a fragment of the\nontology of the subject area of Computer Science is considered.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 10:58:59 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Malakhov", "K. S.", ""]]}, {"id": "1802.06771", "submitter": "Vivek Gupta", "authors": "Dheeraj Mekala, Vivek Gupta, Purushottam Kar, Harish Karnick", "title": "Bayes-optimal Hierarchical Classification over Asymmetric Tree-Distance\n  Loss", "comments": "CS 396 Undergraduate Project Report, 17 Pages 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical classification is supervised multi-class classification problem\nover the set of class labels organized according to a hierarchy. In this\nreport, we study the work by Ramaswamy et. al. on hierarchical classification\nover symmetric tree distance loss. We extend the consistency of hierarchical\nclassification algorithm over asymmetric tree distance loss. We design a\n$\\mathcal{O}(nk\\log{}n)$ algorithm to find Bayes optimal classification for a\nk-ary tree as a hierarchy. We show that under reasonable assumptions over\nasymmetric loss function, the Bayes optimal classification over this asymmetric\nloss can be found in $\\mathcal{O}(k\\log{}n)$. We exploit this insight and\nattempt to extend the Ova-Cascade algorithm \\citet{ramaswamy2015convex} for\nhierarchical classification over the asymmetric loss.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 12:51:06 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Mekala", "Dheeraj", ""], ["Gupta", "Vivek", ""], ["Kar", "Purushottam", ""], ["Karnick", "Harish", ""]]}, {"id": "1802.06806", "submitter": "Ashish Shrivastava", "authors": "Seyed-Mohsen Moosavi-Dezfooli, Ashish Shrivastava, Oncel Tuzel", "title": "Divide, Denoise, and Defend against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, although shown to be a successful class of machine\nlearning algorithms, are known to be extremely unstable to adversarial\nperturbations. Improving the robustness of neural networks against these\nattacks is important, especially for security-critical applications. To defend\nagainst such attacks, we propose dividing the input image into multiple\npatches, denoising each patch independently, and reconstructing the image,\nwithout losing significant image content. We call our method D3. This proposed\ndefense mechanism is non-differentiable which makes it non-trivial for an\nadversary to apply gradient-based attacks. Moreover, we do not fine-tune the\nnetwork with adversarial examples, making it more robust against unknown\nattacks. We present an analysis of the tradeoff between accuracy and robustness\nagainst adversarial attacks. We evaluate our method under black-box, grey-box,\nand white-box settings. On the ImageNet dataset, our method outperforms the\nstate-of-the-art by 19.7% under grey-box setting, and performs comparably under\nblack-box setting. For the white-box setting, the proposed method achieves\n34.4% accuracy compared to the 0% reported in the recent works.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:01:56 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 22:32:22 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Shrivastava", "Ashish", ""], ["Tuzel", "Oncel", ""]]}, {"id": "1802.06816", "submitter": "Nilaksh Das", "authors": "Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei\n  Li, Li Chen, Michael E. Kounavis, Duen Horng Chau", "title": "Shield: Fast, Practical Defense and Vaccination for Deep Learning using\n  JPEG Compression", "comments": "under review at KDD'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing body of research in adversarial machine learning has\ndemonstrated that deep neural networks (DNNs) are highly vulnerable to\nadversarially generated images. This underscores the urgent need for practical\ndefense that can be readily deployed to combat attacks in real-time. Observing\nthat many attack strategies aim to perturb image pixels in ways that are\nvisually imperceptible, we place JPEG compression at the core of our proposed\nShield defense framework, utilizing its capability to effectively \"compress\naway\" such pixel manipulation. To immunize a DNN model from artifacts\nintroduced by compression, Shield \"vaccinates\" a model by re-training it with\ncompressed images, where different compression levels are applied to generate\nmultiple vaccinated models that are ultimately used together in an ensemble\ndefense. On top of that, Shield adds an additional layer of protection by\nemploying randomization at test time that compresses different regions of an\nimage using random compression levels, making it harder for an adversary to\nestimate the transformation performed. This novel combination of vaccination,\nensembling, and randomization makes Shield a fortified multi-pronged\nprotection. We conducted extensive, large-scale experiments using the ImageNet\ndataset, and show that our approaches eliminate up to 94% of black-box attacks\nand 98% of gray-box attacks delivered by the recent, strongest attacks, such as\nCarlini-Wagner's L2 and DeepFool. Our approaches are fast and work without\nrequiring knowledge about the model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:13:42 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Das", "Nilaksh", ""], ["Shanbhogue", "Madhuri", ""], ["Chen", "Shang-Tse", ""], ["Hohman", "Fred", ""], ["Li", "Siwei", ""], ["Chen", "Li", ""], ["Kounavis", "Michael E.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1802.06821", "submitter": "Kyrylo Malakhov", "authors": "V. Yu. Velychko, K. S. Malakhov, V. V. Semenkov, A. E. Strizhak", "title": "Integrated Tools for Engineering Ontologies", "comments": "in Russian", "journal-ref": "Information Models and Analyses 3 (4) (2014) 336-361", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents an overview of current specialized ontology engineering\ntools, as well as texts' annotation tools based on ontologies. The main\nfunctions and features of these tools, their advantages and disadvantages are\ndiscussed. A systematic comparative analysis of means for engineering\nontologies is presented.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:35:14 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""], ["Semenkov", "V. V.", ""], ["Strizhak", "A. E.", ""]]}, {"id": "1802.06829", "submitter": "Kyrylo Malakhov", "authors": "A. V. Palagin, N. G. Petrenko, V. Yu. Velychko, K. S. Malakhov, O. V.\n  Karun", "title": "Principles of design and software development models of\n  ontological-driven computer systems", "comments": "in Russian", "journal-ref": "Problems of Informatization and Management Vol 2 No 34 (2011)\n  96-101", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design principles of methodology of\nknowledge-oriented information systems based on ontological approach. Such\nsystems implement technology subject-oriented extraction of knowledge from the\nset of natural language texts and their formal and logical presentation and\napplication processing\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 10:20:44 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Palagin", "A. V.", ""], ["Petrenko", "N. G.", ""], ["Velychko", "V. Yu.", ""], ["Malakhov", "K. S.", ""], ["Karun", "O. V.", ""]]}, {"id": "1802.06832", "submitter": "Nariman Farsad", "authors": "Nariman Farsad and Milind Rao and Andrea Goldsmith", "title": "Deep Learning for Joint Source-Channel Coding of Text", "comments": "accepted for publication in the proceedings of IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of joint source and channel coding of structured data\nsuch as natural language over a noisy channel. The typical approach to this\nproblem in both theory and practice involves performing source coding to first\ncompress the text and then channel coding to add robustness for the\ntransmission across the channel. This approach is optimal in terms of\nminimizing end-to-end distortion with arbitrarily large block lengths of both\nthe source and channel codes when transmission is over discrete memoryless\nchannels. However, the optimality of this approach is no longer ensured for\ndocuments of finite length and limitations on the length of the encoding. We\nwill show in this scenario that we can achieve lower word error rates by\ndeveloping a deep learning based encoder and decoder. While the approach of\nseparate source and channel coding would minimize bit error rates, our approach\npreserves semantic information of sentences by first embedding sentences in a\nsemantic space where sentences closer in meaning are located closer together,\nand then performing joint source and channel coding on these embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 20:11:36 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Farsad", "Nariman", ""], ["Rao", "Milind", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1802.06866", "submitter": "Ismail Kayali", "authors": "Ismail Kayali", "title": "Expert System for Diagnosis of Chest Diseases Using Neural Networks", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This article represents one of the contemporary trends in the application of\nthe latest methods of information and communication technology for medicine\nthrough an expert system helps the doctor to diagnose some chest diseases which\nis important because of the frequent spread of chest diseases nowadays in\naddition to the overlap symptoms of these diseases, which is difficult to right\ndiagnose by doctors with several algorithms: Forward Chaining, Backward\nChaining, Neural Network(Back Propagation). However, this system cannot replace\nthe doctor function, but it can help the doctor to avoid wrong diagnosis and\ntreatments. It can also be developed in such a way to help the novice doctors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 21:41:32 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Kayali", "Ismail", ""]]}, {"id": "1802.06881", "submitter": "Michael Green", "authors": "Christoffer Holmg{\\aa}rd, Michael Cerny Green, Antonios Liapis, and\n  Julian Togelius", "title": "Automated Playtesting with Procedural Personas through MCTS with Evolved\n  Heuristics", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for generative player modeling and its\napplication to the automatic testing of game content using archetypal player\nmodels called procedural personas. Theoretically grounded in psychological\ndecision theory, procedural personas are implemented using a variation of Monte\nCarlo Tree Search (MCTS) where the node selection criteria are developed using\nevolutionary computation, replacing the standard UCB1 criterion of MCTS. Using\nthese personas we demonstrate how generative player models can be applied to a\nvaried corpus of game levels and demonstrate how different play styles can be\nenacted in each level. In short, we use artificially intelligent personas to\nconstruct synthetic playtesters. The proposed approach could be used as a tool\nfor automatic play testing when human feedback is not readily available or when\nquick visualization of potential interactions is necessary. Possible\napplications include interactive tools during game development or procedural\ncontent generation systems where many evaluations must be conducted within a\nshort time span.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:13:20 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Holmg\u00e5rd", "Christoffer", ""], ["Green", "Michael Cerny", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1802.06888", "submitter": "Ignacio Viglizzo", "authors": "Fernando Tohm\\'e and Ignacio Viglizzo", "title": "Superrational types", "comments": null, "journal-ref": null, "doi": "10.1093/jigpal/jzz007", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal analysis of Douglas Hofstadter's concept of\n\\emph{superrationality}. We start by defining superrationally justifiable\nactions, and study them in symmetric games. We then model the beliefs of the\nplayers, in a way that leads them to different choices than the usual\nassumption of rationality by restricting the range of conceivable choices.\nThese beliefs are captured in the formal notion of \\emph{type} drawn from\nepistemic game theory. The theory of coalgebras is used to frame type spaces\nand to account for the existence of some of them. We find conditions that\nguarantee superrational outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 15:44:38 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Tohm\u00e9", "Fernando", ""], ["Viglizzo", "Ignacio", ""]]}, {"id": "1802.06891", "submitter": "Matthew Fellows", "authors": "Matthew Fellows, Kamil Ciosek and Shimon Whiteson", "title": "Fourier Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way of deriving policy gradient updates for reinforcement\nlearning. Our technique, based on Fourier analysis, recasts integrals that\narise with expected policy gradients as convolutions and turns them into\nmultiplications. The obtained analytical solutions allow us to capture the low\nvariance benefits of EPG in a broad range of settings. For the critic, we treat\ntrigonometric and radial basis functions, two function families with the\nuniversal approximation property. The choice of policy can be almost arbitrary,\nincluding mixtures or hybrid continuous-discrete probability distributions.\nMoreover, we derive a general family of sample-based estimators for stochastic\npolicy gradients, which unifies existing results on sample-based approximation.\nWe believe that this technique has the potential to shape the next generation\nof policy gradient approaches, powered by analytical results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:28:56 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 16:41:30 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Fellows", "Matthew", ""], ["Ciosek", "Kamil", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1802.06895", "submitter": "Sarath Sreedharan", "authors": "Sarath Sreedharan, Siddharth Srivastava, Subbarao Kambhampati", "title": "Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest within the AI research community to develop\nautonomous systems capable of explaining their behavior to users. One aspect of\nthe explanation generation problem that has yet to receive much attention is\nthe task of explaining plans to users whose level of expertise differ from that\nof the explainer. We propose an approach for addressing this problem by\nrepresenting the user's model as an abstraction of the domain model that the\nplanner uses. We present algorithms for generating minimal explanations in\ncases where this abstract human model is not known. We reduce the problem of\ngenerating explanation to a search over the space of abstract models and\ninvestigate possible greedy approximations for minimal explanations. We also\nempirically show that our approach can efficiently compute explanations for a\nvariety of problems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 22:35:13 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Sreedharan", "Sarath", ""], ["Srivastava", "Siddharth", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1802.06926", "submitter": "Yang Gao", "authors": "Yang Gao, Shouyan Guo, Kaimin Huang, Jiaxin Chen, Qian Gong, Yang Zou,\n  Tong Bai and Gary Overett", "title": "Scale Optimization for Full-Image-CNN Vehicle Detection", "comments": "Accepted by 2017 IEEE Intelligent Vehicles Symposium (IV). Link:\n  http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7995812", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art general object detection methods make use of shared\nfull-image convolutional features (as in Faster R-CNN). This achieves a\nreasonable test-phase computation time while enjoys the discriminative power\nprovided by large Convolutional Neural Network (CNN) models. Such designs excel\non benchmarks which contain natural images but which have very unnatural\ndistributions, i.e. they have an unnaturally high-frequency of the target\nclasses and a bias towards a \"friendly\" or \"dominant\" object scale. In this\npaper we present further study of the use and adaptation of the Faster R-CNN\nobject detection method for datasets presenting natural scale distribution and\nunbiased real-world object frequency. In particular, we show that better\nalignment of the detector scale sensitivity to the extant distribution improves\nvehicle detection performance. We do this by modifying both the selection of\nRegion Proposals, and through using more scale-appropriate full-image\nconvolution features within the CNN model. By selecting better scales in the\nregion proposal input and by combining feature maps through careful design of\nthe convolutional neural network, we improve performance on smaller objects. We\nsignificantly increase detection AP for the KITTI dataset car class from 76.3%\non our baseline Faster R-CNN detector to 83.6% in our improved detector.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 00:54:15 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Gao", "Yang", ""], ["Guo", "Shouyan", ""], ["Huang", "Kaimin", ""], ["Chen", "Jiaxin", ""], ["Gong", "Qian", ""], ["Zou", "Yang", ""], ["Bai", "Tong", ""], ["Overett", "Gary", ""]]}, {"id": "1802.06940", "submitter": "Alexander Semenov", "authors": "Irina Gribanova and Alexander Semenov", "title": "Using Automatic Generation of Relaxation Constraints to Improve the\n  Preimage Attack on 39-step MD4", "comments": "This paper was submitted to MIPRO 2018 as a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we construct preimage attack on the truncated variant of the\nMD4 hash function. Specifically, we study the MD4-39 function defined by the\nfirst 39 steps of the MD4 algorithm. We suggest a new attack on MD4-39, which\ndevelops the ideas proposed by H. Dobbertin in 1998. Namely, the special\nrelaxation constraints are introduced in order to simplify the equations\ncorresponding to the problem of finding a preimage for an arbitrary MD4-39 hash\nvalue. The equations supplemented with the relaxation constraints are then\nreduced to the Boolean Satisfiability Problem (SAT) and solved using the\nstate-of-the-art SAT solvers. We show that the effectiveness of a set of\nrelaxation constraints can be evaluated using the black-box function of a\nspecial kind. Thus, we suggest automatic method of relaxation constraints\ngeneration by applying the black-box optimization to this function. The\nproposed method made it possible to find new relaxation constraints that\ncontribute to a SAT-based preimage attack on MD4-39 which significantly\noutperforms the competition.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 02:47:41 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Gribanova", "Irina", ""], ["Semenov", "Alexander", ""]]}, {"id": "1802.06963", "submitter": "Karim Said Barsim", "authors": "Karim Said Barsim, Lukas Mauch, Bin Yang", "title": "Neural Network Ensembles to Real-time Identification of Plug-level\n  Appliance Measurements", "comments": "NILM Workshop 2016", "journal-ref": null, "doi": null, "report-no": "ID09", "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of identifying end-use electrical appliances from their\nindividual consumption profiles, known as the appliance identification problem,\nis a primary stage in both Non-Intrusive Load Monitoring (NILM) and automated\nplug-wise metering. Therefore, appliance identification has received dedicated\nstudies with various electric appliance signatures, classification models, and\nevaluation datasets. In this paper, we propose a neural network ensembles\napproach to address this problem using high resolution measurements. The models\nare trained on the raw current and voltage waveforms, and thus, eliminating the\nneed for well engineered appliance signatures. We evaluate the proposed model\non a publicly available appliance dataset from 55 residential buildings, 11\nappliance categories, and over 1000 measurements. We further study the\nstability of the trained models with respect to training dataset, sampling\nfrequency, and variations in the steady-state operation of appliances.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 04:32:35 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Barsim", "Karim Said", ""], ["Mauch", "Lukas", ""], ["Yang", "Bin", ""]]}, {"id": "1802.07073", "submitter": "Ilija Bogunovic", "authors": "Ilija Bogunovic, Junyao Zhao, Volkan Cevher", "title": "Robust Maximization of Non-Submodular Objectives", "comments": "Revision of Section 4.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing a monotone set function subject to a\ncardinality constraint $k$ in the setting where some number of elements $\\tau$\nis deleted from the returned set. The focus of this work is on the worst-case\nadversarial setting. While there exist constant-factor guarantees when the\nfunction is submodular, there are no guarantees for non-submodular objectives.\nIn this work, we present a new algorithm Oblivious-Greedy and prove the first\nconstant-factor approximation guarantees for a wider class of non-submodular\nobjectives. The obtained theoretical bounds are the first constant-factor\nbounds that also hold in the linear regime, i.e. when the number of deletions\n$\\tau$ is linear in $k$. Our bounds depend on established parameters such as\nthe submodularity ratio and some novel ones such as the inverse curvature. We\nbound these parameters for two important objectives including support selection\nand variance reduction. Finally, we numerically demonstrate the robust\nperformance of Oblivious-Greedy for these two objectives on various datasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:02:01 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 10:58:37 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 11:24:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bogunovic", "Ilija", ""], ["Zhao", "Junyao", ""], ["Cevher", "Volkan", ""]]}, {"id": "1802.07089", "submitter": "Qiuyuan Huang", "authors": "Qiuyuan Huang, Li Deng, Dapeng Wu, Chang Liu, Xiaodong He", "title": "Attentive Tensor Product Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture - Attentive Tensor Product Learning\n(ATPL) - to represent grammatical structures in deep learning models. ATPL is a\nnew architecture to bridge this gap by exploiting Tensor Product\nRepresentations (TPR), a structured neural-symbolic model developed in\ncognitive science, aiming to integrate deep learning with explicit language\nstructures and rules. The key ideas of ATPL are: 1) unsupervised learning of\nrole-unbinding vectors of words via TPR-based deep neural network; 2) employing\nattention modules to compute TPR; and 3) integration of TPR with typical deep\nlearning architectures including Long Short-Term Memory (LSTM) and Feedforward\nNeural Network (FFNN). The novelty of our approach lies in its ability to\nextract the grammatical structure of a sentence by using role-unbinding\nvectors, which are obtained in an unsupervised manner. This ATPL approach is\napplied to 1) image captioning, 2) part of speech (POS) tagging, and 3)\nconstituency parsing of a sentence. Experimental results demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 12:42:07 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 05:14:18 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Deng", "Li", ""], ["Wu", "Dapeng", ""], ["Liu", "Chang", ""], ["He", "Xiaodong", ""]]}, {"id": "1802.07228", "submitter": "Miles Brundage", "authors": "Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley,\n  Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum\n  Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn,\n  Se\\'an \\'O h\\'Eigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar,\n  Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman\n  Yampolskiy, Dario Amodei", "title": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention,\n  and Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report surveys the landscape of potential security threats from\nmalicious uses of AI, and proposes ways to better forecast, prevent, and\nmitigate these threats. After analyzing the ways in which AI may influence the\nthreat landscape in the digital, physical, and political domains, we make four\nhigh-level recommendations for AI researchers and other stakeholders. We also\nsuggest several promising areas for further research that could expand the\nportfolio of defenses, or make attacks less effective or harder to execute.\nFinally, we discuss, but do not conclusively resolve, the long-term equilibrium\nof attackers and defenders.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:07:50 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Brundage", "Miles", ""], ["Avin", "Shahar", ""], ["Clark", "Jack", ""], ["Toner", "Helen", ""], ["Eckersley", "Peter", ""], ["Garfinkel", "Ben", ""], ["Dafoe", "Allan", ""], ["Scharre", "Paul", ""], ["Zeitzoff", "Thomas", ""], ["Filar", "Bobby", ""], ["Anderson", "Hyrum", ""], ["Roff", "Heather", ""], ["Allen", "Gregory C.", ""], ["Steinhardt", "Jacob", ""], ["Flynn", "Carrick", ""], ["h\u00c9igeartaigh", "Se\u00e1n \u00d3", ""], ["Beard", "Simon", ""], ["Belfield", "Haydn", ""], ["Farquhar", "Sebastian", ""], ["Lyle", "Clare", ""], ["Crootof", "Rebecca", ""], ["Evans", "Owain", ""], ["Page", "Michael", ""], ["Bryson", "Joanna", ""], ["Yampolskiy", "Roman", ""], ["Amodei", "Dario", ""]]}, {"id": "1802.07239", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Murray Shanahan, Claudia Clopath", "title": "Continual Reinforcement Learning with Complex Synapses", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike humans, who are capable of continual learning over their lifetimes,\nartificial neural networks have long been known to suffer from a phenomenon\nknown as catastrophic forgetting, whereby new learning can lead to abrupt\nerasure of previously acquired knowledge. Whereas in a neural network the\nparameters are typically modelled as scalar values, an individual synapse in\nthe brain comprises a complex network of interacting biochemical components\nthat evolve at different timescales. In this paper, we show that by equipping\ntabular and deep reinforcement learning agents with a synaptic model that\nincorporates this biological complexity (Benna & Fusi, 2016), catastrophic\nforgetting can be mitigated at multiple timescales. In particular, we find that\nas well as enabling continual learning across sequential training of two simple\ntasks, it can also be used to overcome within-task forgetting by reducing the\nneed for an experience replay database.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:36:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 11:07:28 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Kaplanis", "Christos", ""], ["Shanahan", "Murray", ""], ["Clopath", "Claudia", ""]]}, {"id": "1802.07245", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, Sergey\n  Levine", "title": "Meta-Reinforcement Learning of Structured Exploration Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a fundamental challenge in reinforcement learning (RL). Many\nof the current exploration methods for deep RL use task-agnostic objectives,\nsuch as information gain or bonuses based on state visitation. However, many\npractical applications of RL involve learning more than a single task, and\nprior tasks can be used to inform how exploration should be performed in new\ntasks. In this work, we explore how prior tasks can inform an agent about how\nto explore effectively in new situations. We introduce a novel gradient-based\nfast adaptation algorithm -- model agnostic exploration with structured noise\n(MAESN) -- to learn exploration strategies from prior experience. The prior\nexperience is used both to initialize a policy and to acquire a latent\nexploration space that can inject structured stochasticity into a policy,\nproducing exploration strategies that are informed by prior knowledge and are\nmore effective than random action-space noise. We show that MAESN is more\neffective at learning exploration strategies when compared to prior meta-RL\nmethods, RL without learned exploration strategies, and task-agnostic\nexploration methods. We evaluate our method on a variety of simulated tasks:\nlocomotion with a wheeled robot, locomotion with a quadrupedal walker, and\nobject manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:40:57 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Gupta", "Abhishek", ""], ["Mendonca", "Russell", ""], ["Liu", "YuXuan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1802.07257", "submitter": "Matthias Rauter", "authors": "Matthias Rauter and Daniel Winkler", "title": "Predicting Natural Hazards with Neuronal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational mass flows, such as avalanches, debris flows and rockfalls are\ncommon events in alpine regions with high impact on transport routes. Within\nthe last few decades, hazard zone maps have been developed to systematically\napproach this threat. These maps mark vulnerable zones in habitable areas to\nallow effective planning of hazard mitigation measures and development of\nsettlements. Hazard zone maps have shown to be an effective tool to reduce\nfatalities during extreme events. They are created in a complex process, based\non experience, empirical models, physical simulations and historical data. The\ngeneration of such maps is therefore expensive and limited to crucially\nimportant regions, e.g. permanently inhabited areas.\n  In this work we interpret the task of hazard zone mapping as a classification\nproblem. Every point in a specific area has to be classified according to its\nvulnerability. On a regional scale this leads to a segmentation problem, where\nthe total area has to be divided in the respective hazard zones. The recent\ndevelopments in artificial intelligence, namely convolutional neuronal\nnetworks, have led to major improvement in a very similar task, image\nclassification and semantic segmentation, i.e. computer vision. We use a\nconvolutional neuronal network to identify terrain formations with the\npotential for catastrophic snow avalanches and label points in their reach as\nvulnerable. Repeating this procedure for all points allows us to generate an\nartificial hazard zone map. We demonstrate that the approach is feasible and\npromising based on the hazard zone map of the Tirolean Oberland. However, more\ntraining data and further improvement of the method is required before such\ntechniques can be applied reliably.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:43:56 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Rauter", "Matthias", ""], ["Winkler", "Daniel", ""]]}, {"id": "1802.07284", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu", "title": "Logic Programming Applications: What Are the Abstractions and\n  Implementations?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an overview of applications of logic programming,\nclassifying them based on the abstractions and implementations of logic\nlanguages that support the applications. The three key abstractions are join,\nrecursion, and constraint. Their essential implementations are for-loops, fixed\npoints, and backtracking, respectively. The corresponding kinds of applications\nare database queries, inductive analysis, and combinatorial search,\nrespectively. We also discuss language extensions and programming paradigms,\nsummarize example application problems by application areas, and touch on\nexample systems that support variants of the abstractions with different\nimplementations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:04:14 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Liu", "Yanhong A.", ""]]}, {"id": "1802.07370", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "SufiSent - Universal Sentence Representations Using Suffix Encodings", "comments": "4 pages, Submitted to ICLR 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose a method to learn such\nrepresentations by encoding the suffixes of word sequences in a sentence and\ntraining on the Stanford Natural Language Inference (SNLI) dataset. We\ndemonstrate the effectiveness of our approach by evaluating it on the SentEval\nbenchmark, improving on existing approaches on several transfer tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:08:19 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1802.07374", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "On the scaling of polynomial features for representation matching", "comments": "4 pages, Submitted to ICLR 2018 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many neural models, new features as polynomial functions of existing ones\nare used to augment representations. Using the natural language inference task\nas an example, we investigate the use of scaled polynomials of degree 2 and\nabove as matching features. We find that scaling degree 2 features has the\nhighest impact on performance, reducing classification error by 5% in the best\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 23:22:25 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1802.07384", "submitter": "Xin Zhang", "authors": "Xin Zhang, Armando Solar-Lezama, and Rishabh Singh", "title": "Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic\n  Corrections", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm to generate minimal, stable, and symbolic\ncorrections to an input that will cause a neural network with ReLU activations\nto change its output. We argue that such a correction is a useful way to\nprovide feedback to a user when the network's output is different from a\ndesired output. Our algorithm generates such a correction by solving a series\nof linear constraint satisfaction problems. The technique is evaluated on three\nneural network models: one predicting whether an applicant will pay a mortgage,\none predicting whether a first-order theorem can be proved efficiently by a\nsolver using certain heuristics, and the final one judging whether a drawing is\nan accurate rendition of a canonical drawing of a cat.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 00:47:32 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 21:33:26 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Zhang", "Xin", ""], ["Solar-Lezama", "Armando", ""], ["Singh", "Rishabh", ""]]}, {"id": "1802.07426", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Yoshua Bengio, Vikas Verma, Leslie Pack Kaelbling", "title": "Generalization in Machine Learning via Analytical Learning Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": "Massachusetts Institute of Technology (MIT), MIT-CSAIL-TR-2018-019", "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel measure-theoretic theory for machine learning\nthat does not require statistical assumptions. Based on this theory, a new\nregularization method in deep learning is derived and shown to outperform\nprevious methods in CIFAR-10, CIFAR-100, and SVHN. Moreover, the proposed\ntheory provides a theoretical basis for a family of practically successful\nregularization methods in deep learning. We discuss several consequences of our\nresults on one-shot learning, representation learning, deep learning, and\ncurriculum learning. Unlike statistical learning theory, the proposed learning\ntheory analyzes each problem instance individually via measure theory, rather\nthan a set of problem instances via statistics. As a result, it provides\ndifferent types of results and insights when compared to statistical learning\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 05:03:52 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 17:39:36 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 22:23:14 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Bengio", "Yoshua", ""], ["Verma", "Vikas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1802.07442", "submitter": "Nick Haber", "authors": "Nick Haber, Damian Mrowca, Li Fei-Fei, Daniel L. K. Yamins", "title": "Learning to Play with Intrinsically-Motivated Self-Aware Agents", "comments": "In NIPS 2018. 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to mathematically formalize these abilities using a\nneural network that implements curiosity-driven intrinsic motivation. Using a\nsimple but ecologically naturalistic simulated environment in which an agent\ncan move and interact with objects it sees, we propose a \"world-model\" network\nthat learns to predict the dynamic consequences of the agent's actions.\nSimultaneously, we train a separate explicit \"self-model\" that allows the agent\nto track the error map of its own world-model, and then uses the self-model to\nadversarially challenge the developing world-model. We demonstrate that this\npolicy causes the agent to explore novel and informative interactions with its\nenvironment, leading to the generation of a spectrum of complex behaviors,\nincluding ego-motion prediction, object attention, and object gathering.\nMoreover, the world-model that the agent learns supports improved performance\non object dynamics prediction, detection, localization and recognition tasks.\nTaken together, our results are initial steps toward creating flexible\nautonomous agents that self-supervise in complex novel physical environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 07:01:43 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:08:46 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Haber", "Nick", ""], ["Mrowca", "Damian", ""], ["Fei-Fei", "Li", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1802.07444", "submitter": "Chen Luo", "authors": "Chen Luo, Anshumali Shrivastava", "title": "Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and\npopular variants of MCMC for problems when an MCMC state consists of an unknown\nnumber of components. It is well known that state-of-the-art methods for\nsplit-merge MCMC do not scale well. Strategies for rapid mixing requires smart\nand informative proposals to reduce the rejection rate. However, all known\nsmart proposals involve expensive operations to suggest informative\ntransitions. As a result, the cost of each iteration is prohibitive for massive\nscale datasets. It is further known that uninformative but computationally\nefficient proposals, such as random split-merge, leads to extremely slow\nconvergence. This tradeoff between mixing time and per update cost seems hard\nto get around.\n  In this paper, we show a sweet spot. We leverage some unique properties of\nweighted MinHash, which is a popular LSH, to design a novel class of\nsplit-merge proposals which are significantly more informative than random\nsampling but at the same time efficient to compute. Overall, we obtain a\nsuperior tradeoff between convergence and per update cost. As a direct\nconsequence, our proposals are around 6X faster than the state-of-the-art\nsampling methods on two large real datasets KDDCUP and PubMed with several\nmillions of entities and thousands of clusters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 07:03:32 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 20:36:49 GMT"}, {"version": "v3", "created": "Fri, 12 Oct 2018 05:06:40 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Luo", "Chen", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1802.07461", "submitter": "Nick Haber", "authors": "Nick Haber, Damian Mrowca, Li Fei-Fei, Daniel L. K. Yamins", "title": "Emergence of Structured Behaviors from Curiosity-Based Intrinsic\n  Motivation", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to replicate some of these abilities with a neural\nnetwork that implements curiosity-driven intrinsic motivation. Using a simple\nbut ecologically naturalistic simulated environment in which the agent can move\nand interact with objects it sees, the agent learns a world model predicting\nthe dynamic consequences of its actions. Simultaneously, the agent learns to\ntake actions that adversarially challenge the developing world model, pushing\nthe agent to explore novel and informative interactions with its environment.\nWe demonstrate that this policy leads to the self-supervised emergence of a\nspectrum of complex behaviors, including ego motion prediction, object\nattention, and object gathering. Moreover, the world model that the agent\nlearns supports improved performance on object dynamics prediction and\nlocalization tasks. Our results are a proof-of-principle that computational\nmodels of intrinsic motivation might account for key features of developmental\nvisuomotor learning in infants.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 08:13:12 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Haber", "Nick", ""], ["Mrowca", "Damian", ""], ["Fei-Fei", "Li", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1802.07489", "submitter": "Sylwia Polberg", "authors": "Anthony Hunter, Sylwia Polberg, Matthias Thimm", "title": "Epistemic Graphs for Representing and Reasoning with Positive and\n  Negative Influences of Arguments", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2020.103236", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces epistemic graphs as a generalization of the epistemic\napproach to probabilistic argumentation. In these graphs, an argument can be\nbelieved or disbelieved up to a given degree, thus providing a more\nfine--grained alternative to the standard Dung's approaches when it comes to\ndetermining the status of a given argument. Furthermore, the flexibility of the\nepistemic approach allows us to both model the rationale behind the existing\nsemantics as well as completely deviate from them when required. Epistemic\ngraphs can model both attack and support as well as relations that are neither\nsupport nor attack. The way other arguments influence a given argument is\nexpressed by the epistemic constraints that can restrict the belief we have in\nan argument with a varying degree of specificity. The fact that we can specify\nthe rules under which arguments should be evaluated and we can include\nconstraints between unrelated arguments permits the framework to be more\ncontext--sensitive. It also allows for better modelling of imperfect agents,\nwhich can be important in multi--agent applications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 10:05:49 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 11:45:14 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hunter", "Anthony", ""], ["Polberg", "Sylwia", ""], ["Thimm", "Matthias", ""]]}, {"id": "1802.07512", "submitter": "Ligang Zhang", "authors": "Ligang Zhang, Brijesh Verma, David Stockwell, Sujan Chowdhury", "title": "Density Weighted Connectivity of Grass Pixels in Image Frames for\n  Biomass Estimation", "comments": "28 pages, accepted manuscript, Expert Systems with Applications", "journal-ref": null, "doi": "10.1016/j.eswa.2018.01.055", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of the biomass of roadside grasses plays a significant\nrole in applications such as fire-prone region identification. Current\nsolutions heavily depend on field surveys, remote sensing measurements and\nimage processing using reference markers, which often demand big investments of\ntime, effort and cost. This paper proposes Density Weighted Connectivity of\nGrass Pixels (DWCGP) to automatically estimate grass biomass from roadside\nimage data. The DWCGP calculates the length of continuously connected grass\npixels along a vertical orientation in each image column, and then weights the\nlength by the grass density in a surrounding region of the column. Grass pixels\nare classified using feedforward artificial neural networks and the dominant\ntexture orientation at every pixel is computed using multi-orientation Gabor\nwavelet filter vote. Evaluations on a field survey dataset show that the DWCGP\nreduces Root-Mean-Square Error from 5.84 to 5.52 by additionally considering\ngrass density on top of grass height. The DWCGP shows robustness to\nnon-vertical grass stems and to changes of both Gabor filter parameters and\nsurrounding region widths. It also has performance close to human observation\nand higher than eight baseline approaches, as well as promising results for\nclassifying low vs. high fire risk and identifying fire-prone road regions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 11:07:05 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Zhang", "Ligang", ""], ["Verma", "Brijesh", ""], ["Stockwell", "David", ""], ["Chowdhury", "Sujan", ""]]}, {"id": "1802.07564", "submitter": "Yasuhiro Fujita", "authors": "Yasuhiro Fujita and Shin-ichi Maeda", "title": "Clipped Action Policy Gradient", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many continuous control tasks have bounded action spaces. When policy\ngradient methods are applied to such tasks, out-of-bound actions need to be\nclipped before execution, while policies are usually optimized as if the\nactions are not clipped. We propose a policy gradient estimator that exploits\nthe knowledge of actions being clipped to reduce the variance in estimation. We\nprove that our estimator, named clipped action policy gradient (CAPG), is\nunbiased and achieves lower variance than the conventional estimator that\nignores action bounds. Experimental results demonstrate that CAPG generally\noutperforms the conventional estimator, indicating that it is a better policy\ngradient estimator for continuous control tasks. The source code is available\nat https://github.com/pfnet-research/capg.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:39:28 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 10:19:00 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Fujita", "Yasuhiro", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1802.07606", "submitter": "Luisa Zintgraf", "authors": "Luisa M Zintgraf, Diederik M Roijers, Sjoerd Linders, Catholijn M\n  Jonker, Ann Now\\'e", "title": "Ordered Preference Elicitation Strategies for Supporting Multi-Objective\n  Decision Making", "comments": "AAMAS 2018, Source code at\n  https://github.com/lmzintgraf/gp_pref_elicit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective decision planning and learning, much attention is paid to\nproducing optimal solution sets that contain an optimal policy for every\npossible user preference profile. We argue that the step that follows, i.e,\ndetermining which policy to execute by maximising the user's intrinsic utility\nfunction over this (possibly infinite) set, is under-studied. This paper aims\nto fill this gap. We build on previous work on Gaussian processes and pairwise\ncomparisons for preference modelling, extend it to the multi-objective decision\nsupport scenario, and propose new ordered preference elicitation strategies\nbased on ranking and clustering. Our main contribution is an in-depth\nevaluation of these strategies using computer and human-based experiments. We\nshow that our proposed elicitation strategies outperform the currently used\npairwise methods, and found that users prefer ranking most. Our experiments\nfurther show that utilising monotonicity information in GPs by using a linear\nprior mean at the start and virtual comparisons to the nadir and ideal points,\nincreases performance. We demonstrate our decision support framework in a\nreal-world study on traffic regulation, conducted with the city of Amsterdam.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:05:15 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Zintgraf", "Luisa M", ""], ["Roijers", "Diederik M", ""], ["Linders", "Sjoerd", ""], ["Jonker", "Catholijn M", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "1802.07623", "submitter": "Amit Dhurandhar", "authors": "Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting,\n  Karthikeyan Shanmugam and Payel Das", "title": "Explanations based on the Missing: Towards Contrastive Explanations with\n  Pertinent Negatives", "comments": null, "journal-ref": null, "doi": null, "report-no": "accepted to NIPS 2018", "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel method that provides contrastive\nexplanations justifying the classification of an input by a black box\nclassifier such as a deep neural network. Given an input we find what should be\n%necessarily and minimally and sufficiently present (viz. important object\npixels in an image) to justify its classification and analogously what should\nbe minimally and necessarily \\emph{absent} (viz. certain background pixels). We\nargue that such explanations are natural for humans and are used commonly in\ndomains such as health care and criminology. What is minimally but critically\n\\emph{absent} is an important part of an explanation, which to the best of our\nknowledge, has not been explicitly identified by current explanation methods\nthat explain predictions of neural networks. We validate our approach on three\nreal datasets obtained from diverse domains; namely, a handwritten digits\ndataset MNIST, a large procurement fraud dataset and a brain activity strength\ndataset. In all three cases, we witness the power of our approach in generating\nprecise explanations that are also easy for human experts to understand and\nevaluate.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 15:51:38 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:08:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Chen", "Pin-Yu", ""], ["Luss", "Ronny", ""], ["Tu", "Chun-Chen", ""], ["Ting", "Paishun", ""], ["Shanmugam", "Karthikeyan", ""], ["Das", "Payel", ""]]}, {"id": "1802.07687", "submitter": "Emily Denton", "authors": "Emily Denton and Rob Fergus", "title": "Stochastic Video Generation with a Learned Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating video frames that accurately predict future world states is\nchallenging. Existing approaches either fail to capture the full distribution\nof outcomes, or yield blurry generations, or both. In this paper we introduce\nan unsupervised video generation model that learns a prior model of uncertainty\nin a given environment. Video frames are generated by drawing samples from this\nprior and combining them with a deterministic estimate of the future frame. The\napproach is simple and easily trained end-to-end on a variety of datasets.\nSample generations are both varied and sharp, even many frames into the future,\nand compare favorably to those from existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:36:27 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 17:39:23 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Denton", "Emily", ""], ["Fergus", "Rob", ""]]}, {"id": "1802.07697", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Approximation Algorithms for Cascading Prediction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approximation algorithm that takes a pool of pre-trained models\nas input and produces from it a cascaded model with similar accuracy but lower\naverage-case cost. Applied to state-of-the-art ImageNet classification models,\nthis yields up to a 2x reduction in floating point multiplications, and up to a\n6x reduction in average-case memory I/O. The auto-generated cascades exhibit\nintuitive properties, such as using lower-resolution input for easier images\nand requiring higher prediction confidence when using a computationally cheaper\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 17:56:05 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1802.07740", "submitter": "Neil Rabinowitz", "authors": "Neil C. Rabinowitz, Frank Perbet, H. Francis Song, Chiyuan Zhang, S.M.\n  Ali Eslami, Matthew Botvinick", "title": "Machine Theory of Mind", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'\nability to represent the mental states of others, including their desires,\nbeliefs, and intentions. We propose to train a machine to build such models\ntoo. We design a Theory of Mind neural network -- a ToMnet -- which uses\nmeta-learning to build models of the agents it encounters, from observations of\ntheir behaviour alone. Through this process, it acquires a strong prior model\nfor agents' behaviour, as well as the ability to bootstrap to richer\npredictions about agents' characteristics and mental states using only a small\nnumber of behavioural observations. We apply the ToMnet to agents behaving in\nsimple gridworld environments, showing that it learns to model random,\nalgorithmic, and deep reinforcement learning agents from varied populations,\nand that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer &\nPerner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold\nfalse beliefs about the world. We argue that this system -- which autonomously\nlearns how to model other agents in its world -- is an important step forward\nfor developing multi-agent AI systems, for building intermediating technology\nfor machine-human interaction, and for advancing the progress on interpretable\nAI.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 19:00:10 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 21:37:03 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Rabinowitz", "Neil C.", ""], ["Perbet", "Frank", ""], ["Song", "H. Francis", ""], ["Zhang", "Chiyuan", ""], ["Eslami", "S. M. Ali", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1802.07782", "submitter": "John Kingston", "authors": "John Kingston", "title": "Artificial Intelligence and Legal Liability", "comments": "In: Bramer, Max and Petridis, Miltiadis, eds. Research and\n  Development in Intelligent Systems XXXIII: Incorporating Applications and\n  Innovations in Intelligent Systems XXIV. Springer Verlag, Cambridge, UK, pp.\n  269-279. ISBN 9783319471747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent issue of a popular computing journal asked which laws would apply if\na self-driving car killed a pedestrian. This paper considers the question of\nlegal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of\nsales warranties is also considered. A discussion of some of the practical\nlimitations that AI systems are subject to is also included.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 20:11:28 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Kingston", "John", ""]]}, {"id": "1802.07810", "submitter": "Forough Poursabzi-Sangdeh", "authors": "Forough Poursabzi-Sangdeh, Daniel G. Goldstein, Jake M. Hofman,\n  Jennifer Wortman Vaughan, Hanna Wallach", "title": "Manipulating and Measuring Model Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning models being increasingly used to aid decision making\neven in high-stakes domains, there has been a growing interest in developing\ninterpretable models. Although many supposedly interpretable models have been\nproposed, there have been relatively few experimental studies investigating\nwhether these models achieve their intended effects, such as making people more\nclosely follow a model's predictions when it is beneficial for them to do so or\nenabling them to detect when a model has made a mistake. We present a sequence\nof pre-registered experiments(N=3,800) in which we showed participants\nfunctionally identical models that varied only in two factors commonly thought\nto make machine learning models more or less interpretable: the number of\nfeatures and the transparency of the model (i.e., whether the model internals\nare clear or black box). Predictably, participants who saw a clear model with\nfew features could better simulate the model's predictions. However, we did not\nfind that participants more closely followed its predictions. Furthermore,\nshowing participants a clear model meant that they were less able to detect and\ncorrect for the model's sizable mistakes, seemingly due to information\noverload. These counterintuitive findings emphasize the importance of testing\nover intuition when developing interpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 21:11:36 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 01:19:14 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 20:41:48 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 00:17:19 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Poursabzi-Sangdeh", "Forough", ""], ["Goldstein", "Daniel G.", ""], ["Hofman", "Jake M.", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""]]}, {"id": "1802.07814", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Le Song, Martin J. Wainwright, Michael I. Jordan", "title": "Learning to Explain: An Information-Theoretic Perspective on Model\n  Interpretation", "comments": "Accepted to ICML 2018 as a long oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce instancewise feature selection as a methodology for model\ninterpretation. Our method is based on learning a function to extract a subset\nof features that are most informative for each given example. This feature\nselector is trained to maximize the mutual information between selected\nfeatures and the response variable, where the conditional distribution of the\nresponse variable given the input is the model to be explained. We develop an\nefficient variational approximation to the mutual information, and show the\neffectiveness of our method on a variety of synthetic and real data sets using\nboth quantitative metrics and human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 21:16:21 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 03:38:00 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Chen", "Jianbo", ""], ["Song", "Le", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1802.07833", "submitter": "Tianbing Xu", "authors": "Tianbing Xu", "title": "Variational Inference for Policy Gradient", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the seminal work on Stein Variational Inference and Stein\nVariational Policy Gradient, we derived a method to generate samples from the\nposterior variational parameter distribution by \\textit{explicitly} minimizing\nthe KL divergence to match the target distribution in an amortize fashion.\nConsequently, we applied this varational inference technique into vanilla\npolicy gradient, TRPO and PPO with Bayesian Neural Network parameterizations\nfor reinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 22:18:20 GMT"}, {"version": "v2", "created": "Sun, 25 Mar 2018 23:57:28 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Xu", "Tianbing", ""]]}, {"id": "1802.07842", "submitter": "Hamid Maei", "authors": "Hamid Reza Maei", "title": "Convergent Actor-Critic Algorithms Under Off-Policy Training and\n  Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first class of policy-gradient algorithms that work with both\nstate-value and policy function-approximation, and are guaranteed to converge\nunder off-policy training. Our solution targets problems in reinforcement\nlearning where the action representation adds to the-curse-of-dimensionality;\nthat is, with continuous or large action sets, thus making it infeasible to\nestimate state-action value functions (Q functions). Using state-value\nfunctions helps to lift the curse and as a result naturally turn our\npolicy-gradient solution into classical Actor-Critic architecture whose Actor\nuses state-value function for the update. Our algorithms, Gradient Actor-Critic\nand Emphatic Actor-Critic, are derived based on the exact gradient of averaged\nstate-value function objective and thus are guaranteed to converge to its\noptimal solution, while maintaining all the desirable properties of classical\nActor-Critic methods with no additional hyper-parameters. To our knowledge,\nthis is the first time that convergent off-policy learning methods have been\nextended to classical Actor-Critic methods with function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 23:14:44 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Maei", "Hamid Reza", ""]]}, {"id": "1802.07846", "submitter": "Avi Ben-Cohen", "authors": "Avi Ben-Cohen, Eyal Klang, Stephen P. Raskin, Shelly Soffer, Simona\n  Ben-Haim, Eli Konen, Michal Marianne Amitai and Hayit Greenspan", "title": "Cross-Modality Synthesis from CT to PET using FCN and GAN Networks for\n  Improved Automated Lesion Detection", "comments": "Preprint submitted to Engineering applications of artificial\n  intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel system for generation of virtual PET images\nusing CT scans. We combine a fully convolutional network (FCN) with a\nconditional generative adversarial network (GAN) to generate simulated PET data\nfrom given input CT data. The synthesized PET can be used for false-positive\nreduction in lesion detection solutions. Clinically, such solutions may enable\nlesion detection and drug treatment evaluation in a CT-only environment, thus\nreducing the need for the more expensive and radioactive PET/CT scan. Our\ndataset includes 60 PET/CT scans from Sheba Medical center. We used 23 scans\nfor training and 37 for testing. Different schemes to achieve the synthesized\noutput were qualitatively compared. Quantitative evaluation was conducted using\nan existing lesion detection software, combining the synthesized PET as a false\npositive reduction layer for the detection of malignant lesions in the liver.\nCurrent results look promising showing a 28% reduction in the average false\npositive per case from 2.9 to 2.1. The suggested solution is comprehensive and\ncan be expanded to additional body organs, and different modalities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 23:25:19 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 09:14:59 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ben-Cohen", "Avi", ""], ["Klang", "Eyal", ""], ["Raskin", "Stephen P.", ""], ["Soffer", "Shelly", ""], ["Ben-Haim", "Simona", ""], ["Konen", "Eli", ""], ["Amitai", "Michal Marianne", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1802.07877", "submitter": "Maryam Sabzevari", "authors": "Maryam Sabzevari, Gonzalo Mart\\'inez-Mu\\~noz, Alberto Su\\'arez", "title": "Pooling homogeneous ensembles to build heterogeneous ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In ensemble methods, the outputs of a collection of diverse classifiers are\ncombined in the expectation that the global prediction be more accurate than\nthe individual ones. Heterogeneous ensembles consist of predictors of different\ntypes, which are likely to have different biases. If these biases are\ncomplementary, the combination of their decisions is beneficial. In this work,\na family of heterogeneous ensembles is built by pooling classifiers from M\nhomogeneous ensembles of different types of size T. Depending on the fraction\nof base classifiers of each type, a particular heterogeneous combination in\nthis family is represented by a point in a regular simplex in M dimensions. The\nM vertices of this simplex represent the different homogeneous ensembles. A\ndisplacement away from one of these vertices effects a smooth transformation of\nthe corresponding homogeneous ensemble into a heterogeneous one. The optimal\ncomposition of such heterogeneous ensemble can be determined using\ncross-validation or, if bootstrap samples are used to build the individual\nclassifiers, out-of-bag data. An empirical analysis of such combinations of\nbootstraped ensembles composed of neural networks, SVMs, and random trees (i.e.\nfrom a standard random forest) illustrates the gains that can be achieved by\nthis heterogeneous ensemble creation method.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:17:42 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 21:15:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sabzevari", "Maryam", ""], ["Mart\u00ednez-Mu\u00f1oz", "Gonzalo", ""], ["Su\u00e1rez", "Alberto", ""]]}, {"id": "1802.07896", "submitter": "Haifeng Qian", "authors": "Haifeng Qian, Mark N. Wegman", "title": "L2-Nonexpansive Neural Networks", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR), 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of well-conditioned neural networks in which a\nunit amount of change in the inputs causes at most a unit amount of change in\nthe outputs or any of the internal layers. We develop the known methodology of\ncontrolling Lipschitz constants to realize its full potential in maximizing\nrobustness, with a new regularization scheme for linear layers, new ways to\nadapt nonlinearities and a new loss function. With MNIST and CIFAR-10\nclassifiers, we demonstrate a number of advantages. Without needing any\nadversarial training, the proposed classifiers exceed the state of the art in\nrobustness against white-box L2-bounded adversarial attacks. They generalize\nbetter than ordinary networks from noisy data with partially random labels.\nTheir outputs are quantitatively meaningful and indicate levels of confidence\nand generalization, among other desirable properties.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:01:18 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 18:34:46 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 03:24:08 GMT"}, {"version": "v4", "created": "Wed, 6 Feb 2019 07:12:07 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Qian", "Haifeng", ""], ["Wegman", "Mark N.", ""]]}, {"id": "1802.07966", "submitter": "Arindam Mitra", "authors": "Arindam Mitra and Chitta Baral", "title": "Incremental and Iterative Learning of Answer Set Programs from Mutually\n  Distinct Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years the Artificial Intelligence (AI) community has produced\nseveral datasets which have given the machine learning algorithms the\nopportunity to learn various skills across various domains. However, a subclass\nof these machine learning algorithms that aimed at learning logic programs,\nnamely the Inductive Logic Programming algorithms, have often failed at the\ntask due to the vastness of these datasets. This has impacted the usability of\nknowledge representation and reasoning techniques in the development of AI\nsystems. In this research, we try to address this scalability issue for the\nalgorithms that learn answer set programs. We present a sound and complete\nalgorithm which takes the input in a slightly different manner and performs an\nefficient and more user controlled search for a solution. We show via\nexperiments that our algorithm can learn from two popular datasets from machine\nlearning community, namely bAbl (a question answering dataset) and MNIST (a\ndataset for handwritten digit recognition), which to the best of our knowledge\nwas not previously possible. The system is publicly available at\nhttps://goo.gl/KdWAcV. This paper is under consideration for acceptance in\nTPLP.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 10:22:58 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 14:42:15 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Mitra", "Arindam", ""], ["Baral", "Chitta", ""]]}, {"id": "1802.07997", "submitter": "Dar\\'io Garigliotti", "authors": "Heng Ding, Shuo Zhang, Dar\\'io Garigliotti, and Krisztian Balog", "title": "Generating High-Quality Query Suggestion Candidates for Task-Based\n  Search", "comments": "Advances in Information Retrieval. Proceedings of the 40th European\n  Conference on Information Retrieval (ECIR '18), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_54", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of generating query suggestions for task-based search.\nThe current state of the art relies heavily on suggestions provided by a major\nsearch engine. In this paper, we solve the task without reliance on search\nengines. Specifically, we focus on the first step of a two-stage pipeline\napproach, which is dedicated to the generation of query suggestion candidates.\nWe present three methods for generating candidate suggestions and apply them on\nmultiple information sources. Using a purpose-built test collection, we find\nthat these methods are able to generate high-quality suggestion candidates.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 11:55:28 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Ding", "Heng", ""], ["Zhang", "Shuo", ""], ["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1802.08010", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "Towards an Understanding of Entity-Oriented Search Intents", "comments": "Advances in Information Retrieval. Proceedings of the 40th European\n  Conference on Information Retrieval (ECIR '18), 2018", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_57", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity-oriented search deals with a wide variety of information needs, from\ndisplaying direct answers to interacting with services. In this work, we aim to\nunderstand what are prominent entity-oriented search intents and how they can\nbe fulfilled. We develop a scheme of entity intent categories, and use them to\nannotate a sample of queries. Specifically, we annotate unique query refiners\non the level of entity types. We observe that, on average, over half of those\nrefiners seek to interact with a service, while over a quarter of the refiners\nsearch for information that may be looked up in a knowledge base.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:30:13 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1802.08013", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Jan Peters, Elmar Rueckert", "title": "Intrinsic Motivation and Mental Replay enable Efficient Online\n  Adaptation in Stochastic Recurrent Networks", "comments": "accepted in Neural Networks", "journal-ref": "Volume 109, January 2019, Pages 67-80", "doi": "10.1016/j.neunet.2018.10.005", "report-no": null, "categories": "cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robots need to interact with unknown, unstructured and changing\nenvironments, constantly facing novel challenges. Therefore, continuous online\nadaptation for lifelong-learning and the need of sample-efficient mechanisms to\nadapt to changes in the environment, the constraints, the tasks, or the robot\nitself are crucial. In this work, we propose a novel framework for\nprobabilistic online motion planning with online adaptation based on a\nbio-inspired stochastic recurrent neural network. By using learning signals\nwhich mimic the intrinsic motivation signalcognitive dissonance in addition\nwith a mental replay strategy to intensify experiences, the stochastic\nrecurrent network can learn from few physical interactions and adapts to novel\nenvironments in seconds. We evaluate our online planning and adaptation\nframework on an anthropomorphic KUKA LWR arm. The rapid online adaptation is\nshown by learning unknown workspace constraints sample-efficiently from few\nphysical interactions while following given way points.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:41:06 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 08:36:19 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Peters", "Jan", ""], ["Rueckert", "Elmar", ""]]}, {"id": "1802.08129", "submitter": "Dong Huk Park", "authors": "Dong Huk Park, Lisa Anne Hendricks, Zeynep Akata, Anna Rohrbach, Bernt\n  Schiele, Trevor Darrell, Marcus Rohrbach", "title": "Multimodal Explanations: Justifying Decisions and Pointing to the\n  Evidence", "comments": "arXiv admin note: text overlap with arXiv:1612.04757", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models that are both effective and explainable are desirable in many\nsettings; prior explainable models have been unimodal, offering either\nimage-based visualization of attention weights or text-based generation of\npost-hoc justifications. We propose a multimodal approach to explanation, and\nargue that the two modalities provide complementary explanatory strengths. We\ncollect two new datasets to define and evaluate this task, and propose a novel\nmodel which can provide joint textual rationale generation and attention\nvisualization. Our datasets define visual and textual justifications of a\nclassification decision for activity recognition tasks (ACT-X) and for visual\nquestion answering tasks (VQA-X). We quantitatively show that training with the\ntextual explanations not only yields better textual justification models, but\nalso better localizes the evidence that supports the decision. We also\nqualitatively show cases where visual explanation is more insightful than\ntextual explanation, and vice versa, supporting our thesis that multimodal\nexplanation models offer significant benefits over unimodal approaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 19:12:03 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Park", "Dong Huk", ""], ["Hendricks", "Lisa Anne", ""], ["Akata", "Zeynep", ""], ["Rohrbach", "Anna", ""], ["Schiele", "Bernt", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1802.08138", "submitter": "Muhammed Omer Sayin", "authors": "Muhammed O. Sayin, Chung-Wei Lin, Shinichi Shiraishi, and Tamer\n  Ba\\c{s}ar", "title": "Reliable Intersection Control in Non-cooperative Environments", "comments": "Extended version (including proofs of theorems and lemmas) of the\n  paper: M. O. Sayin, C.-W. Lin, S. Shiraishi, and T. Basar, \"Reliable\n  intersection control in non-cooperative environments\", to appear in the\n  Proceedings of American Control Conference, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reliable intersection control mechanism for strategic autonomous\nand connected vehicles (agents) in non-cooperative environments. Each agent has\naccess to his/her earliest possible and desired passing times, and reports a\npassing time to the intersection manager, who allocates the intersection\ntemporally to the agents in a First-Come-First-Serve basis. However, the agents\nmight have conflicting interests and can take actions strategically. To this\nend, we analyze the strategic behaviors of the agents and formulate Nash\nequilibria for all possible scenarios. Furthermore, among all Nash equilibria\nwe identify a socially optimal equilibrium that leads to a fair intersection\nallocation, and correspondingly we describe a strategy-proof intersection\nmechanism, which achieves reliable intersection control such that the strategic\nagents do not have any incentive to misreport their passing times\nstrategically.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 16:23:39 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Sayin", "Muhammed O.", ""], ["Lin", "Chung-Wei", ""], ["Shiraishi", "Shinichi", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1802.08183", "submitter": "Lin Chen", "authors": "Lin Chen, Christopher Harshaw, Hamed Hassani, Amin Karbasi", "title": "Projection-Free Online Optimization with Stochastic Gradient: From\n  Convexity to Submodularity", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online optimization has been a successful framework for solving large-scale\nproblems under computational constraints and partial information. Current\nmethods for online convex optimization require either a projection or exact\ngradient computation at each step, both of which can be prohibitively expensive\nfor large-scale applications. At the same time, there is a growing trend of\nnon-convex optimization in machine learning community and a need for online\nmethods. Continuous DR-submodular functions, which exhibit a natural\ndiminishing returns condition, have recently been proposed as a broad class of\nnon-convex functions which may be efficiently optimized. Although online\nmethods have been introduced, they suffer from similar problems. In this work,\nwe propose Meta-Frank-Wolfe, the first online projection-free algorithm that\nuses stochastic gradient estimates. The algorithm relies on a careful sampling\nof gradients in each round and achieves the optimal $O( \\sqrt{T})$ adversarial\nregret bounds for convex and continuous submodular optimization. We also\npropose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single\nstochastic gradient estimate in each round and achieves an $O(T^{2/3})$\nstochastic regret bound for convex and continuous submodular optimization. We\napply our methods to develop a novel \"lifting\" framework for the online\ndiscrete submodular maximization and also see that they outperform current\nstate-of-the-art techniques on various experiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 17:13:36 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 21:53:04 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 00:36:28 GMT"}, {"version": "v4", "created": "Thu, 14 Jun 2018 01:10:34 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Chen", "Lin", ""], ["Harshaw", "Christopher", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1802.08200", "submitter": "Michael Jacobs", "authors": "Vishwa S. Parekh, Katarzyna J. Macura, Susan Harvey, Ihab Kamel, Riham\n  EI-Khouli, David A. Bluemke, Michael A. Jacobs", "title": "Multiparametric Deep Learning Tissue Signatures for a Radiological\n  Biomarker of Breast Cancer: Preliminary Results", "comments": "Deep Learning, Machine learning, Magnetic resonance imaging,\n  multiparametric MRI, Breast, Cancer, Diffusion, tissue biomarkers", "journal-ref": "Medical physics 2020 47 (1), 75-88", "doi": "10.1002/mp.13849", "report-no": null, "categories": "physics.med-ph cs.AI cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new paradigm is beginning to emerge in Radiology with the advent of\nincreased computational capabilities and algorithms. This has led to the\nability of real time learning by computer systems of different lesion types to\nhelp the radiologist in defining disease. For example, using a deep learning\nnetwork, we developed and tested a multiparametric deep learning (MPDL) network\nfor segmentation and classification using multiparametric magnetic resonance\nimaging (mpMRI) radiological images. The MPDL network was constructed from\nstacked sparse autoencoders with inputs from mpMRI. Evaluation of MPDL\nconsisted of cross-validation, sensitivity, and specificity. Dice similarity\nbetween MPDL and post-DCE lesions were evaluated. We demonstrate high\nsensitivity and specificity for differentiation of malignant from benign\nlesions of 90% and 85% respectively with an AUC of 0.93. The Integrated MPDL\nmethod accurately segmented and classified different breast tissue from\nmultiparametric breast MRI using deep leaning tissue signatures.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 02:51:59 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Parekh", "Vishwa S.", ""], ["Macura", "Katarzyna J.", ""], ["Harvey", "Susan", ""], ["Kamel", "Ihab", ""], ["EI-Khouli", "Riham", ""], ["Bluemke", "David A.", ""], ["Jacobs", "Michael A.", ""]]}, {"id": "1802.08201", "submitter": "Umberto Straccia", "authors": "Giovanni Casini and Umberto Straccia and Thomas Meyer", "title": "A Polynomial Time Subsumption Algorithm for Nominal Safe\n  $\\mathcal{ELO}_\\bot$ under Rational Closure", "comments": null, "journal-ref": null, "doi": "10.1016/j.ins.2018.09.037", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Description Logics (DLs) under Rational Closure (RC) is a well-known\nframework for non-monotonic reasoning in DLs. In this paper, we address the\nconcept subsumption decision problem under RC for nominal safe\n$\\mathcal{ELO}_\\bot$, a notable and practically important DL representative of\nthe OWL 2 profile OWL 2 EL.\n  Our contribution here is to define a polynomial time subsumption procedure\nfor nominal safe $\\mathcal{ELO}_\\bot$ under RC that relies entirely on a series\nof classical, monotonic $\\mathcal{EL}_\\bot$ subsumption tests. Therefore, any\nexisting classical monotonic $\\mathcal{EL}_\\bot$ reasoner can be used as a\nblack box to implement our method. We then also adapt the method to one of the\nknown extensions of RC for DLs, namely Defeasible Inheritance-based DLs without\nlosing the computational tractability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 17:54:00 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 06:34:08 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Casini", "Giovanni", ""], ["Straccia", "Umberto", ""], ["Meyer", "Thomas", ""]]}, {"id": "1802.08219", "submitter": "Nathaniel Thomas", "authors": "Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai\n  Kohlhoff, Patrick Riley", "title": "Tensor field networks: Rotation- and translation-equivariant neural\n  networks for 3D point clouds", "comments": "changes for NIPS submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce tensor field neural networks, which are locally equivariant to\n3D rotations, translations, and permutations of points at every layer. 3D\nrotation equivariance removes the need for data augmentation to identify\nfeatures in arbitrary orientations. Our network uses filters built from\nspherical harmonics; due to the mathematical consequences of this filter\nchoice, each layer accepts as input (and guarantees as output) scalars,\nvectors, and higher-order tensors, in the geometric sense of these terms. We\ndemonstrate the capabilities of tensor field networks with tasks in geometry,\nphysics, and chemistry.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:17:31 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 18:58:16 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 20:09:34 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Thomas", "Nathaniel", ""], ["Smidt", "Tess", ""], ["Kearnes", "Steven", ""], ["Yang", "Lusann", ""], ["Li", "Li", ""], ["Kohlhoff", "Kai", ""], ["Riley", "Patrick", ""]]}, {"id": "1802.08232", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini and Chang Liu and \\'Ulfar Erlingsson and Jernej Kos\n  and Dawn Song", "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a testing methodology for quantitatively assessing the\nrisk that rare or unique training-data sequences are unintentionally memorized\nby generative sequence models---a common type of machine-learning model.\nBecause such models are sometimes trained on sensitive data (e.g., the text of\nusers' private messages), this methodology can benefit privacy by allowing\ndeep-learning practitioners to select means of training that minimize such\nmemorization.\n  In experiments, we show that unintended memorization is a persistent,\nhard-to-avoid issue that can have serious consequences. Specifically, for\nmodels trained without consideration of memorization, we describe new,\nefficient procedures that can extract unique, secret sequences, such as credit\ncard numbers. We show that our testing strategy is a practical and easy-to-use\nfirst line of defense, e.g., by describing its application to quantitatively\nlimit data exposure in Google's Smart Compose, a commercial text-completion\nneural network trained on millions of users' email messages.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:42:41 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 18:13:03 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 17:05:32 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Carlini", "Nicholas", ""], ["Liu", "Chang", ""], ["Erlingsson", "\u00dalfar", ""], ["Kos", "Jernej", ""], ["Song", "Dawn", ""]]}, {"id": "1802.08235", "submitter": "Daniel Vieira Mr.", "authors": "Daniel Vieira, Fabio Rangel, Fabricio Firmino and Joao Paixao", "title": "Vector Field Based Neural Networks", "comments": "6 pages, 5 figures. To appear in the Proceedings of the 26th European\n  Symposium on Artificial Neural Networks, Computational Intelligence and\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel Neural Network architecture is proposed using the mathematically and\nphysically rich idea of vector fields as hidden layers to perform nonlinear\ntransformations in the data. The data points are interpreted as particles\nmoving along a flow defined by the vector field which intuitively represents\nthe desired movement to enable classification. The architecture moves the data\npoints from their original configuration to anew one following the streamlines\nof the vector field with the objective of achieving a final configuration where\nclasses are separable. An optimization problem is solved through gradient\ndescent to learn this vector field.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:46:15 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Vieira", "Daniel", ""], ["Rangel", "Fabio", ""], ["Firmino", "Fabricio", ""], ["Paixao", "Joao", ""]]}, {"id": "1802.08254", "submitter": "Wanling Gao", "authors": "Wanling Gao, Jianfeng Zhan, Lei Wang, Chunjie Luo, Daoyi Zheng, Xu\n  Wen, Rui Ren, Chen Zheng, Xiwen He, Hainan Ye, Haoning Tang, Zheng Cao,\n  Shujie Zhang and Jiahui Dai", "title": "BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several fundamental changes in technology indicate domain-specific hardware\nand software co-design is the only path left. In this context, architecture,\nsystem, data management, and machine learning communities pay greater attention\nto innovative big data and AI algorithms, architecture, and systems.\nUnfortunately, complexity, diversity, frequently-changed workloads, and rapid\nevolution of big data and AI systems raise great challenges. First, the\ntraditional benchmarking methodology that creates a new benchmark or proxy for\nevery possible workload is not scalable, or even impossible for Big Data and AI\nbenchmarking. Second, it is prohibitively expensive to tailor the architecture\nto characteristics of one or more application or even a domain of applications.\nWe consider each big data and AI workload as a pipeline of one or more classes\nof units of computation performed on different initial or intermediate data\ninputs, each class of which we call a data motif. On the basis of our previous\nwork that identifies eight data motifs taking up most of the run time of a wide\nvariety of big data and AI workloads, we propose a scalable benchmarking\nmethodology that uses the combination of one or more data motifs---to represent\ndiversity of big data and AI workloads. Following this methodology, we present\na unified big data and AI benchmark suite---BigDataBench 4.0, publicly\navailable from~\\url{http://prof.ict.ac.cn/BigDataBench}. This unified benchmark\nsuite sheds new light on domain-specific hardware and software co-design:\ntailoring the system and architecture to characteristics of the unified eight\ndata motifs other than one or more application case by case. Also, for the\nfirst time, we comprehensively characterize the CPU pipeline efficiency using\nthe benchmarks of seven workload types in BigDataBench 4.0.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 01:28:44 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 05:52:50 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Gao", "Wanling", ""], ["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Luo", "Chunjie", ""], ["Zheng", "Daoyi", ""], ["Wen", "Xu", ""], ["Ren", "Rui", ""], ["Zheng", "Chen", ""], ["He", "Xiwen", ""], ["Ye", "Hainan", ""], ["Tang", "Haoning", ""], ["Cao", "Zheng", ""], ["Zhang", "Shujie", ""], ["Dai", "Jiahui", ""]]}, {"id": "1802.08311", "submitter": "Jian Zhang", "authors": "Mario Srouji, Jian Zhang, Ruslan Salakhutdinov", "title": "Structured Control Nets for Deep Reinforcement Learning", "comments": "First two authors contributed equally", "journal-ref": "PMLR 80:4742-4751, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Reinforcement Learning has made impressive advances in\nsolving several important benchmark problems for sequential decision making.\nMany control applications use a generic multilayer perceptron (MLP) for\nnon-vision parts of the policy network. In this work, we propose a new neural\nnetwork architecture for the policy network representation that is simple yet\neffective. The proposed Structured Control Net (SCN) splits the generic MLP\ninto two separate sub-modules: a nonlinear control module and a linear control\nmodule. Intuitively, the nonlinear control is for forward-looking and global\ncontrol, while the linear control stabilizes the local dynamics around the\nresidual of global control. We hypothesize that this will bring together the\nbenefits of both linear and nonlinear policies: improve training sample\nefficiency, final episodic reward, and generalization of learned policy, while\nrequiring a smaller network and being generally applicable to different\ntraining methods. We validated our hypothesis with competitive results on\nsimulations from OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban\ndriving environment, with various ablation and generalization tests, trained\nwith multiple black-box and policy gradient training methods. The proposed\narchitecture has the potential to improve upon broader control tasks by\nincorporating problem specific priors into the architecture. As a case study,\nwe demonstrate much improved performance for locomotion tasks by emulating the\nbiological central pattern generators (CPGs) as the nonlinear part of the\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:31:34 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Srouji", "Mario", ""], ["Zhang", "Jian", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1802.08314", "submitter": "Chao Zhang", "authors": "Chao Zhang, Philip Woodland", "title": "High Order Recurrent Neural Networks for Acoustic Modelling", "comments": "5 pages, 2 figures, 2 tables, to appear in 2018 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanishing long-term gradients are a major issue in training standard\nrecurrent neural networks (RNNs), which can be alleviated by long short-term\nmemory (LSTM) models with memory cells. However, the extra parameters\nassociated with the memory cells mean an LSTM layer has four times as many\nparameters as an RNN with the same hidden vector size. This paper addresses the\nvanishing gradient problem using a high order RNN (HORNN) which has additional\nconnections from multiple previous time steps. Speech recognition experiments\nusing British English multi-genre broadcast (MGB3) data showed that the\nproposed HORNN architectures for rectified linear unit and sigmoid activation\nfunctions reduced word error rates (WER) by 4.2% and 6.3% over the\ncorresponding RNNs, and gave similar WERs to a (projected) LSTM while using\nonly 20%--50% of the recurrent layer parameters and computation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:01:05 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1802.08328", "submitter": "Carlo Taticchi", "authors": "Stefano Bistarelli, Francesco Santini, Carlo Taticchi", "title": "On Looking for Local Expansion Invariants in Argumentation Semantics: a\n  Preliminary Report", "comments": null, "journal-ref": "Proceedings of the Thirty-First International Florida Artificial\n  Intelligence Research Society Conference, {FLAIRS} 2018, Melbourne, Florida,\n  {USA.} May 21-23 2018. Pages 537--540", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study invariant local expansion operators for conflict-free and admissible\nsets in Abstract Argumentation Frameworks (AFs). Such operators are directly\napplied on AFs, and are invariant with respect to a chosen \"semantics\" (that is\nw.r.t. each of the conflict free/admissible set of arguments). Accordingly, we\nderive a definition of robustness for AFs in terms of the number of times such\noperators can be applied without producing any change in the chosen semantics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 22:18:53 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 13:18:15 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Santini", "Francesco", ""], ["Taticchi", "Carlo", ""]]}, {"id": "1802.08352", "submitter": "Phi Vu Tran", "authors": "Phi Vu Tran", "title": "Learning to Make Predictions on Graphs with Autoencoders", "comments": "Published as a conference paper at IEEE DSAA 2018", "journal-ref": null, "doi": "10.1109/DSAA.2018.00034", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine two fundamental tasks associated with graph representation\nlearning: link prediction and semi-supervised node classification. We present a\nnovel autoencoder architecture capable of learning a joint representation of\nboth local graph structure and available node features for the multi-task\nlearning of link prediction and node classification. Our autoencoder\narchitecture is efficiently trained end-to-end in a single learning stage to\nsimultaneously perform link prediction and node classification, whereas\nprevious related methods require multiple training steps that are difficult to\noptimize. We provide a comprehensive empirical evaluation of our models on nine\nbenchmark graph-structured datasets and demonstrate significant improvement\nover related methods for graph representation learning. Reference code and data\nare available at https://github.com/vuptran/graph-representation-learning\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 00:02:59 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 12:02:52 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tran", "Phi Vu", ""]]}, {"id": "1802.08365", "submitter": "Xun Yang", "authors": "Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian\n  Xu, Kun Gai", "title": "Budget Constrained Bidding by Model-free Reinforcement Learning in\n  Display Advertising", "comments": "In The 27th ACM International Conference on Information and Knowledge\n  Management (CIKM 18), October 22-26, 2018, Torino, Italy. ACM, New York, NY,\n  USA, 9 pages", "journal-ref": null, "doi": "10.1145/3269206.3271748", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time bidding (RTB) is an important mechanism in online display\nadvertising, where a proper bid for each page view plays an essential role for\ngood marketing results. Budget constrained bidding is a typical scenario in RTB\nwhere the advertisers hope to maximize the total value of the winning\nimpressions under a pre-set budget constraint. However, the optimal bidding\nstrategy is hard to be derived due to the complexity and volatility of the\nauction environment. To address these challenges, in this paper, we formulate\nbudget constrained bidding as a Markov Decision Process and propose a\nmodel-free reinforcement learning framework to resolve the optimization\nproblem. Our analysis shows that the immediate reward from environment is\nmisleading under a critical resource constraint. Therefore, we innovate a\nreward function design methodology for the reinforcement learning problems with\nconstraints. Based on the new reward design, we employ a deep neural network to\nlearn the appropriate reward so that the optimal policy can be learned\neffectively. Different from the prior model-based work, which suffers from the\nscalability problem, our framework is easy to be deployed in large-scale\nindustrial applications. The experimental evaluations demonstrate the\neffectiveness of our framework on large-scale real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 02:29:06 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 05:10:15 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 05:15:08 GMT"}, {"version": "v4", "created": "Wed, 8 Aug 2018 07:44:56 GMT"}, {"version": "v5", "created": "Fri, 7 Sep 2018 03:05:00 GMT"}, {"version": "v6", "created": "Tue, 23 Oct 2018 15:20:56 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Wu", "Di", ""], ["Chen", "Xiujun", ""], ["Yang", "Xun", ""], ["Wang", "Hao", ""], ["Tan", "Qing", ""], ["Zhang", "Xiaoxun", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1802.08445", "submitter": "Carlo Taticchi", "authors": "Stefano Bistarelli, Alessandra Tappini, Carlo Taticchi", "title": "A Matrix Approach for Weighted Argumentation Frameworks: a Preliminary\n  Report", "comments": null, "journal-ref": "A Matrix Approach for Weighted Argumentation Frameworks. FLAIRS\n  Conference 2018: 507-512", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assignment of weights to attacks in a classical Argumentation Framework\nallows to compute semantics by taking into account the different importance of\neach argument. We represent a Weighted Argumentation Framework by a non-binary\nmatrix, and we characterize the basic extensions (such as w-admissible, w-\nstable, w-complete) by analysing sub-blocks of this matrix. Also, we show how\nto reduce the matrix into another one of smaller size, that is equivalent to\nthe original one for the determination of extensions. Furthermore, we provide\ntwo algorithms that allow to build incrementally w-grounded and w-preferred\nextensions starting from a w-admissible extension.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 09:00:09 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Bistarelli", "Stefano", ""], ["Tappini", "Alessandra", ""], ["Taticchi", "Carlo", ""]]}, {"id": "1802.08454", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller and Ali Farjami and Xavier Parent", "title": "Faithful Semantical Embedding of a Dyadic Deontic Logic in HOL", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A shallow semantical embedding of a dyadic deontic logic by Carmo and Jones\nin classical higher-order logic is presented. This embedding is proven sound\nand complete, that is, faithful.\n  The work presented here provides the theoretical foundation for the\nimplementation and automation of dyadic deontic logic within off-the-shelf\nhigher-order theorem provers and proof assistants.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 09:24:26 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 17:19:02 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Farjami", "Ali", ""], ["Parent", "Xavier", ""]]}, {"id": "1802.08478", "submitter": "Wlodzislaw Duch", "authors": "Wlodzislaw Duch", "title": "Coloring black boxes: visualization of neural network decisions", "comments": "9 pages, 33 figures. Proc. of International Joint Conference on\n  Neural Networks (IJCNN) 2003, Vol. I, pp. 1735-1740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are commonly regarded as black boxes performing\nincomprehensible functions. For classification problems networks provide maps\nfrom high dimensional feature space to K-dimensional image space. Images of\ntraining vector are projected on polygon vertices, providing visualization of\nnetwork function. Such visualization may show the dynamics of learning, allow\nfor comparison of different networks, display training vectors around which\npotential problems may arise, show differences due to regularization and\noptimization procedures, investigate stability of network classification under\nperturbation of original vectors, and place new data sample in relation to\ntraining data, allowing for estimation of confidence in classification of a\ngiven sample. An illustrative example for the three-class Wine data and\nfive-class Satimage data is described. The visualization method proposed here\nis applicable to any black box system that provides continuous outputs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 10:59:40 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Duch", "Wlodzislaw", ""]]}, {"id": "1802.08534", "submitter": "Yan Zheng", "authors": "Yan Zheng, Jianye Hao, Zongzhang Zhang", "title": "Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:03:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 16:34:29 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zheng", "Yan", ""], ["Hao", "Jianye", ""], ["Zhang", "Zongzhang", ""]]}, {"id": "1802.08535", "submitter": "Edward Grefenstette", "authors": "Richard Evans, David Saxton, David Amos, Pushmeet Kohli, Edward\n  Grefenstette", "title": "Can Neural Networks Understand Logical Entailment?", "comments": "Published at ICLR 2018 (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new dataset of logical entailments for the purpose of\nmeasuring models' ability to capture and exploit the structure of logical\nexpressions against an entailment prediction task. We use this task to compare\na series of architectures which are ubiquitous in the sequence-processing\nliterature, in addition to a new model class---PossibleWorldNets---which\ncomputes entailment as a \"convolution over possible worlds\". Results show that\nconvolutional networks present the wrong inductive bias for this class of\nproblems relative to LSTM RNNs, tree-structured neural networks outperform LSTM\nRNNs due to their enhanced ability to exploit the syntax of logic, and\nPossibleWorldNets outperform all benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:04:30 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Evans", "Richard", ""], ["Saxton", "David", ""], ["Amos", "David", ""], ["Kohli", "Pushmeet", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1802.08540", "submitter": "Suttinee Sawadsitang", "authors": "Suttinee Sawadsitang, Rakpong Kaewpuang, Siwei Jiang, Dusit Niyato,\n  Ping Wang", "title": "Optimal Stochastic Delivery Planning in Full-Truckload and\n  Less-Than-Truckload Delivery", "comments": "5 pages, 6 figures, Vehicular Technology Conference (VTC Spring),\n  2017 IEEE 85th", "journal-ref": null, "doi": "10.1109/VTCSpring.2017.8108576", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing demand from emerging logistics businesses, Vehicle Routing\nProblem with Private fleet and common Carrier (VRPPC) has been introduced to\nmanage package delivery services from a supplier to customers. However, almost\nall of existing studies focus on the deterministic problem that assumes all\nparameters are known perfectly at the time when the planning and routing\ndecisions are made. In reality, some parameters are random and unknown.\nTherefore, in this paper, we consider VRPPC with hard time windows and random\ndemand, called Optimal Delivery Planning (ODP). The proposed ODP aims to\nminimize the total package delivery cost while meeting the customer time window\nconstraints. We use stochastic integer programming to formulate the\noptimization problem incorporating the customer demand uncertainty. Moreover,\nwe evaluate the performance of the ODP using test data from benchmark dataset\nand from actual Singapore road map.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 08:45:19 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Sawadsitang", "Suttinee", ""], ["Kaewpuang", "Rakpong", ""], ["Jiang", "Siwei", ""], ["Niyato", "Dusit", ""], ["Wang", "Ping", ""]]}, {"id": "1802.08545", "submitter": "Lifeng Jin", "authors": "Lifeng Jin, Finale Doshi-Velez, Timothy Miller, William Schuler, Lane\n  Schwartz", "title": "Unsupervised Grammar Induction with Depth-bounded PCFG", "comments": "Accepted by Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been recent interest in applying cognitively or empirically\nmotivated bounds on recursion depth to limit the search space of grammar\ninduction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,\n2016). This work extends this depth-bounding approach to probabilistic\ncontext-free grammar induction (DB-PCFG), which has a smaller parameter space\nthan hierarchical sequence models, and therefore more fully exploits the space\nreductions of depth-bounding. Results for this model on grammar acquisition\nfrom transcribed child-directed speech and newswire text exceed or are\ncompetitive with those of other models when evaluated on parse accuracy.\nMoreover, gram- mars acquired from this model demonstrate a consistent use of\ncategory labels, something which has not been demonstrated by other acquisition\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:30:00 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 01:55:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jin", "Lifeng", ""], ["Doshi-Velez", "Finale", ""], ["Miller", "Timothy", ""], ["Schuler", "William", ""], ["Schwartz", "Lane", ""]]}, {"id": "1802.08554", "submitter": "Douglas Summers Stay", "authors": "Douglas Summers Stay", "title": "Semantic Vector Spaces for Broadening Consideration of Consequences", "comments": "A book chapter from Autonomy and Artificial Intelligence: A Threat or\n  Savior?", "journal-ref": "Autonomy and Artificial Intelligence: A Threat or Savior? Editors\n  W.F. Lawless, Ranjeev Mittu, Donald Sofge, Stephen Russell Springer, 2017", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning systems with too simple a model of the world and human intent are\nunable to consider potential negative side effects of their actions and modify\ntheir plans to avoid them (e.g., avoiding potential errors). However,\nhand-encoding the enormous and subtle body of facts that constitutes common\nsense into a knowledge base has proved too difficult despite decades of work.\nDistributed semantic vector spaces learned from large text corpora, on the\nother hand, can learn representations that capture shades of meaning of\ncommon-sense concepts and perform analogical and associational reasoning in\nways that knowledge bases are too rigid to perform, by encoding concepts and\nthe relations between them as geometric structures. These have, however, the\ndisadvantage of being unreliable, poorly understood, and biased in their view\nof the world by the source material. This chapter will discuss how these\napproaches may be combined in a way that combines the best properties of each\nfor understanding the world and human intentions in a richer way.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 14:41:33 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Stay", "Douglas Summers", ""]]}, {"id": "1802.08611", "submitter": "Sanjay Sahay", "authors": "Ashu Sharma and Sanjay K. Sahay", "title": "An investigation of the classifiers to detect android malicious apps", "comments": "8 Pages, 8 Figures", "journal-ref": "Springer, Information and Communication Technology, 625, p. 207 -\n  217, 2017", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Android devices are growing exponentially and are connected through the\ninternet accessing billion of online websites. The popularity of these devices\nencourages malware developer to penetrate the market with malicious apps to\nannoy and disrupt the victim. Although, for the detection of malicious apps\ndifferent approaches are discussed. However, proposed approaches are not\nsuffice to detect the advanced malware to limit/prevent the damages. In this,\nvery few approaches are based on opcode occurrence to classify the malicious\napps. Therefore, this paper investigates the five classifiers using opcodes\noccurrence as the prominent features for the detection of malicious apps. For\nthe analysis, we use WEKA tool and found that FT detection accuracy (79.27%) is\nbest among the investigated classifiers. However, true positives rate i.e.\nmalware detection rate is highest (99.91%) by RF and fluctuate least with the\ndifferent number of prominent features compared to other studied classifiers.\nThe analysis shows that overall accuracy is majorly affected by the false\npositives of the classifier.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:45:35 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sharma", "Ashu", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1802.08614", "submitter": "Baoxu Shi", "authors": "Baoxu Shi and Tim Weninger", "title": "Visualizing the Flow of Discourse with a Concept Ontology", "comments": "2 pages, accepted to WWW2018", "journal-ref": null, "doi": "10.1145/3184558.3186943", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and visualizing human discourse has long being a challenging\ntask. Although recent work on argument mining have shown success in classifying\nthe role of various sentences, the task of recognizing concepts and\nunderstanding the ways in which they are discussed remains challenging. Given\nan email thread or a transcript of a group discussion, our task is to extract\nthe relevant concepts and understand how they are referenced and re-referenced\nthroughout the discussion. In the present work, we present a preliminary\napproach for extracting and visualizing group discourse by adapting Wikipedia's\ncategory hierarchy to be an external concept ontology. From a user study, we\nfound that our method achieved better results than 4 strong alternative\napproaches, and we illustrate our visualization method based on the extracted\ndiscourse flows.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:56:07 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Shi", "Baoxu", ""], ["Weninger", "Tim", ""]]}, {"id": "1802.08674", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis, Sayash Kapoor, Farnood Salehi, and Nisheeth K. Vishnoi", "title": "An Algorithmic Framework to Control Bias in Bandit-based Personalization", "comments": "A short version of this paper appeared in FAT/ML 2017\n  (arXiv:1707.02260)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:44:01 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Celis", "L. Elisa", ""], ["Kapoor", "Sayash", ""], ["Salehi", "Farnood", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.08679", "submitter": "Onur Atan", "authors": "Onur Atan, William R. Zame, M van der Schaar", "title": "Learning Optimal Policies from Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing optimal (or at least better) policies is an important problem in\ndomains from medicine to education to finance and many others. One approach to\nthis problem is through controlled experiments/trials - but controlled\nexperiments are expensive. Hence it is important to choose the best policies on\nthe basis of observational data. This presents two difficult challenges: (i)\nmissing counterfactuals, and (ii) selection bias. This paper presents\ntheoretical bounds on estimation errors of counterfactuals from observational\ndata by making connections to domain adaptation theory. It also presents a\nprincipled way of choosing optimal policies using domain adversarial neural\nnetworks. We illustrate the effectiveness of domain adversarial training\ntogether with various features of our algorithm on a semi-synthetic breast\ncancer dataset and a supervised UCI dataset (Statlog).\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:56:32 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Atan", "Onur", ""], ["Zame", "William R.", ""], ["van der Schaar", "M", ""]]}, {"id": "1802.08705", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Tom\\'as Lozano-P\\'erez, Leslie Pack Kaelbling", "title": "PDDLStream: Integrating Symbolic Planners and Blackbox Samplers via\n  Optimistic Adaptive Planning", "comments": "International Conference on Automated Planning and Scheduling (ICAPS)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many planning applications involve complex relationships defined on\nhigh-dimensional, continuous variables. For example, robotic manipulation\nrequires planning with kinematic, collision, visibility, and motion constraints\ninvolving robot configurations, object poses, and robot trajectories. These\nconstraints typically require specialized procedures to sample satisfying\nvalues. We extend PDDL to support a generic, declarative specification for\nthese procedures that treats their implementation as black boxes. We provide\ndomain-independent algorithms that reduce PDDLStream problems to a sequence of\nfinite PDDL problems. We also introduce an algorithm that dynamically balances\nexploring new candidate plans and exploiting existing ones. This enables the\nalgorithm to greedily search the space of parameter bindings to more quickly\nsolve tightly-constrained problems as well as locally optimize to produce\nlow-cost solutions. We evaluate our algorithms on three simulated robotic\nplanning domains as well as several real-world robotic tasks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:26:46 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 14:38:26 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 15:45:18 GMT"}, {"version": "v4", "created": "Tue, 21 Jan 2020 20:27:13 GMT"}, {"version": "v5", "created": "Mon, 23 Mar 2020 15:14:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1802.08718", "submitter": "Sven Schmit", "authors": "Ramesh Johari and Sven Schmit", "title": "Learning with Abandonment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a platform that wants to learn a personalized policy for each user,\nbut the platform faces the risk of a user abandoning the platform if she is\ndissatisfied with the actions of the platform. For example, a platform is\ninterested in personalizing the number of newsletters it sends, but faces the\nrisk that the user unsubscribes forever. We propose a general thresholded\nlearning model for scenarios like this, and discuss the structure of optimal\npolicies. We describe salient features of optimal personalization algorithms\nand how feedback the platform receives impacts the results. Furthermore, we\ninvestigate how the platform can efficiently learn the heterogeneity across\nusers by interacting with a population and provide performance guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 19:59:39 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Johari", "Ramesh", ""], ["Schmit", "Sven", ""]]}, {"id": "1802.08737", "submitter": "Rajat Sen", "authors": "Rajat Sen, Karthikeyan Shanmugam, Nihal Sharma, Sanjay Shakkottai", "title": "Contextual Bandits with Stochastic Experts", "comments": "20 pages, 2 Figures, Accepted for publication in AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of contextual bandits with stochastic experts, which\nis a variation of the traditional stochastic contextual bandit with experts\nproblem. In our problem setting, we assume access to a class of stochastic\nexperts, where each expert is a conditional distribution over the arms given a\ncontext. We propose upper-confidence bound (UCB) algorithms for this problem,\nwhich employ two different importance sampling based estimators for the mean\nreward for each expert. Both these estimators leverage information leakage\namong the experts, thus using samples collected under all the experts to\nestimate the mean reward of any given expert. This leads to instance dependent\nregret bounds of $\\mathcal{O}\\left(\\lambda(\\pmb{\\mu})\\mathcal{M}\\log T/\\Delta\n\\right)$, where $\\lambda(\\pmb{\\mu})$ is a term that depends on the mean rewards\nof the experts, $\\Delta$ is the smallest gap between the mean reward of the\noptimal expert and the rest, and $\\mathcal{M}$ quantifies the information\nleakage among the experts. We show that under some assumptions\n$\\lambda(\\pmb{\\mu})$ is typically $\\mathcal{O}(\\log N)$, where $N$ is the\nnumber of experts. We implement our algorithm with stochastic experts generated\nfrom cost-sensitive classification oracles and show superior empirical\nperformance on real-world datasets, when compared to other state of the art\ncontextual bandit algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 21:03:49 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 04:58:01 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Sen", "Rajat", ""], ["Shanmugam", "Karthikeyan", ""], ["Sharma", "Nihal", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1802.08757", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Ba\\c{s}ar", "title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of \\emph{fully decentralized} multi-agent\nreinforcement learning (MARL), where the agents are located at the nodes of a\ntime-varying communication network. Specifically, we assume that the reward\nfunctions of the agents might correspond to different tasks, and are only known\nto the corresponding agent. Moreover, each agent makes individual decisions\nbased on both the information observed locally and the messages received from\nits neighbors over the network. Within this setting, the collective goal of the\nagents is to maximize the globally averaged return over the network through\nexchanging information with their neighbors. To this end, we propose two\ndecentralized actor-critic algorithms with function approximation, which are\napplicable to large-scale MARL problems where both the number of states and the\nnumber of agents are massively large. Under the decentralized structure, the\nactor step is performed individually by each agent with no need to infer the\npolicies of others. For the critic step, we propose a consensus update via\ncommunication over the network. Our algorithms are fully incremental and can be\nimplemented in an online fashion. Convergence analyses of the algorithms are\nprovided when the value functions are approximated within the class of linear\nfunctions. Extensive simulation results with both linear and nonlinear function\napproximations are presented to validate the proposed algorithms. Our work\nappears to be the first study of fully decentralized MARL algorithms for\nnetworked agents with function approximation, with provable convergence\nguarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 22:53:32 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 02:15:35 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Liu", "Han", ""], ["Zhang", "Tong", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1802.08760", "submitter": "Roman Novak", "authors": "Roman Novak, Yasaman Bahri, Daniel A. Abolafia, Jeffrey Pennington,\n  Jascha Sohl-Dickstein", "title": "Sensitivity and Generalization in Neural Networks: an Empirical Study", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice it is often found that large over-parameterized neural networks\ngeneralize better than their smaller counterparts, an observation that appears\nto conflict with classical notions of function complexity, which typically\nfavor smaller models. In this work, we investigate this tension between\ncomplexity and generalization through an extensive empirical exploration of two\nnatural metrics of complexity related to sensitivity to input perturbations.\nOur experiments survey thousands of models with various fully-connected\narchitectures, optimizers, and other hyper-parameters, as well as four\ndifferent image classification datasets.\n  We find that trained neural networks are more robust to input perturbations\nin the vicinity of the training data manifold, as measured by the norm of the\ninput-output Jacobian of the network, and that it correlates well with\ngeneralization. We further establish that factors associated with poor\ngeneralization $-$ such as full-batch training or using random labels $-$\ncorrespond to lower robustness, while factors associated with good\ngeneralization $-$ such as data augmentation and ReLU non-linearities $-$ give\nrise to more robust functions. Finally, we demonstrate how the input-output\nJacobian norm can be predictive of generalization at the level of individual\ntest points.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 23:11:07 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 23:45:21 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 18:01:43 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Novak", "Roman", ""], ["Bahri", "Yasaman", ""], ["Abolafia", "Daniel A.", ""], ["Pennington", "Jeffrey", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1802.08773", "submitter": "Rex Ying", "authors": "Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, Jure Leskovec", "title": "GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and generating graphs is fundamental for studying networks in\nbiology, engineering, and social sciences. However, modeling complex\ndistributions over graphs and then efficiently sampling from these\ndistributions is challenging due to the non-unique, high-dimensional nature of\ngraphs and the complex, non-local dependencies that exist between edges in a\ngiven graph. Here we propose GraphRNN, a deep autoregressive model that\naddresses the above challenges and approximates any distribution of graphs with\nminimal assumptions about their structure. GraphRNN learns to generate graphs\nby training on a representative set of graphs and decomposes the graph\ngeneration process into a sequence of node and edge formations, conditioned on\nthe graph structure generated so far.\n  In order to quantitatively evaluate the performance of GraphRNN, we introduce\na benchmark suite of datasets, baselines and novel evaluation metrics based on\nMaximum Mean Discrepancy, which measure distances between sets of graphs. Our\nexperiments show that GraphRNN significantly outperforms all baselines,\nlearning to generate diverse graphs that match the structural characteristics\nof a target set, while also scaling to graphs 50 times larger than previous\ndeep models.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 00:39:09 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 22:06:39 GMT"}, {"version": "v3", "created": "Sat, 23 Jun 2018 15:22:19 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["You", "Jiaxuan", ""], ["Ying", "Rex", ""], ["Ren", "Xiang", ""], ["Hamilton", "William L.", ""], ["Leskovec", "Jure", ""]]}, {"id": "1802.08802", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, Percy\n  Liang", "title": "Reinforcement Learning on Web Interfaces Using Workflow-Guided\n  Exploration", "comments": "International Conference on Learning Representations (ICLR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents improve through trial-and-error, but when\nreward is sparse and the agent cannot discover successful action sequences,\nlearning stagnates. This has been a notable problem in training deep RL agents\nto perform web-based tasks, such as booking flights or replying to emails,\nwhere a single mistake can ruin the entire sequence of actions. A common remedy\nis to \"warm-start\" the agent by pre-training it to mimic expert demonstrations,\nbut this is prone to overfitting. Instead, we propose to constrain exploration\nusing demonstrations. From each demonstration, we induce high-level \"workflows\"\nwhich constrain the allowable actions at each time step to be similar to those\nin the demonstration (e.g., \"Step 1: click on a textbox; Step 2: enter some\ntext\"). Our exploration policy then learns to identify successful workflows and\nsamples actions that satisfy these workflows. Workflows prune out bad\nexploration directions and accelerate the agent's ability to discover rewards.\nWe use our approach to train a novel neural policy designed to handle the\nsemi-structured nature of websites, and evaluate on a suite of web tasks,\nincluding the recent World of Bits benchmark. We achieve new state-of-the-art\nresults, and show that workflow-guided exploration improves sample efficiency\nover behavioral cloning by more than 100x.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 05:32:47 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Guu", "Kelvin", ""], ["Pasupat", "Panupong", ""], ["Shi", "Tianlin", ""], ["Liang", "Percy", ""]]}, {"id": "1802.08822", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Chi-Shiang Wang, Olivier Teytaud,\n  Jialin Liu, Su-Wei Lin, and Pi-Hsia Hung", "title": "PSO-based Fuzzy Markup Language for Student Learning Performance\n  Evaluation and Educational Application", "comments": "This paper is accepted in Feb. 2018 which will be published in IEEE\n  Transactions on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2018.2810814", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an agent with particle swarm optimization (PSO) based on\na Fuzzy Markup Language (FML) for students learning performance evaluation and\neducational applications, and the proposed agent is according to the response\ndata from a conventional test and an item response theory. First, we apply a\nGS-based parameter estimation mechanism to estimate the items parameters\naccording to the response data, and then to compare its results with those of\nan IRT-based Bayesian parameter estimation mechanism. In addition, we propose a\nstatic-IRT test assembly mechanism to assemble a form for the conventional\ntest. The presented FML-based dynamic assessment mechanism infers the\nprobability of making a correct response to the item for a student with various\nabilities. Moreover, this paper also proposes a novel PFML learning mechanism\nfor optimizing the parameters between items and students. Finally, we adopt a\nK-fold cross validation mechanism to evaluate the performance of the proposed\nagent. Experimental results show that the novel PFML learning mechanism for the\nparameter estimation and learning optimization performs favorably. We believe\nthe proposed PFML will be a reference for education research and pedagogy and\nan important co-learning mechanism for future human-machine educational\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 09:26:46 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Wang", "Chi-Shiang", ""], ["Teytaud", "Olivier", ""], ["Liu", "Jialin", ""], ["Lin", "Su-Wei", ""], ["Hung", "Pi-Hsia", ""]]}, {"id": "1802.08864", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "One Big Net For Everything", "comments": "17 pages, 107 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I apply recent work on \"learning to think\" (2015) and on PowerPlay (2011) to\nthe incremental training of an increasingly general problem solver, continually\nlearning to solve new tasks without forgetting previous skills. The problem\nsolver is a single recurrent neural network (or similar general purpose\ncomputer) called ONE. ONE is unusual in the sense that it is trained in various\nways, e.g., by black box optimization / reinforcement learning / artificial\nevolution as well as supervised / unsupervised learning. For example, ONE may\nlearn through neuroevolution to control a robot through environment-changing\nactions, and learn through unsupervised gradient descent to predict future\ninputs and vector-valued reward signals as suggested in 1990. User-given tasks\ncan be defined through extra goal-defining input patterns, also proposed in\n1990. Suppose ONE has already learned many skills. Now a copy of ONE can be\nre-trained to learn a new skill, e.g., through neuroevolution without a\nteacher. Here it may profit from re-using previously learned subroutines, but\nit may also forget previous skills. Then ONE is retrained in PowerPlay style\n(2011) on stored input/output traces of (a) ONE's copy executing the new skill\nand (b) previous instances of ONE whose skills are still considered worth\nmemorizing. Simultaneously, ONE is retrained on old traces (even those of\nunsuccessful trials) to become a better predictor, without additional expensive\ninteraction with the enviroment. More and more control and prediction skills\nare thus collapsed into ONE, like in the chunker-automatizer system of the\nneural history compressor (1991). This forces ONE to relate partially analogous\nskills (with shared algorithmic information) to each other, creating common\nsubroutines in form of shared subnetworks of ONE, to greatly speed up\nsubsequent learning of additional, novel but algorithmically related skills.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 15:23:46 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "1802.08925", "submitter": "Aaron Lee", "authors": "Cecilia S. Lee, Ariel J. Tyring, Yue Wu, Sa Xiao, Ariel S. Rokem,\n  Nicolaas P. Deruyter, Qinqin Zhang, Adnan Tufail, Ruikang K. Wang, Aaron Y.\n  Lee", "title": "Generating retinal flow maps from structural optical coherence\n  tomography with artificial intelligence", "comments": "Under revision at Nature Communications. Submitted on June 5th 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant advances in artificial intelligence (AI) for computer\nvision, its application in medical imaging has been limited by the burden and\nlimits of expert-generated labels. We used images from optical coherence\ntomography angiography (OCTA), a relatively new imaging modality that measures\nperfusion of the retinal vasculature, to train an AI algorithm to generate\nvasculature maps from standard structural optical coherence tomography (OCT)\nimages of the same retinae, both exceeding the ability and bypassing the need\nfor expert labeling. Deep learning was able to infer perfusion of\nmicrovasculature from structural OCT images with similar fidelity to OCTA and\nsignificantly better than expert clinicians (P < 0.00001). OCTA suffers from\nneed of specialized hardware, laborious acquisition protocols, and motion\nartifacts; whereas our model works directly from standard OCT which are\nubiquitous and quick to obtain, and allows unlocking of large volumes of\npreviously collected standard OCT data both in existing clinical trials and\nclinical practice. This finding demonstrates a novel application of AI to\nmedical imaging, whereby subtle regularities between different modalities are\nused to image the same body part and AI is used to generate detailed and\naccurate inferences of tissue function from structure imaging.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 22:51:43 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Lee", "Cecilia S.", ""], ["Tyring", "Ariel J.", ""], ["Wu", "Yue", ""], ["Xiao", "Sa", ""], ["Rokem", "Ariel S.", ""], ["Deruyter", "Nicolaas P.", ""], ["Zhang", "Qinqin", ""], ["Tufail", "Adnan", ""], ["Wang", "Ruikang K.", ""], ["Lee", "Aaron Y.", ""]]}, {"id": "1802.08938", "submitter": "Tianxiang Gao", "authors": "Tianxiang Gao, Chris Chu", "title": "DID: Distributed Incremental Block Coordinate Descent for Nonnegative\n  Matrix Factorization", "comments": "Accepted by AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has attracted much attention in the\nlast decade as a dimension reduction method in many applications. Due to the\nexplosion in the size of data, naturally the samples are collected and stored\ndistributively in local computational nodes. Thus, there is a growing need to\ndevelop algorithms in a distributed memory architecture. We propose a novel\ndistributed algorithm, called \\textit{distributed incremental block coordinate\ndescent} (DID), to solve the problem. By adapting the block coordinate descent\nframework, closed-form update rules are obtained in DID. Moreover, DID performs\nupdates incrementally based on the most recently updated residual matrix. As a\nresult, only one communication step per iteration is required. The correctness,\nefficiency, and scalability of the proposed algorithm are verified in a series\nof numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 01:23:23 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gao", "Tianxiang", ""], ["Chu", "Chris", ""]]}, {"id": "1802.08946", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Robert Nowak, Philippe Rigollet, Xuezhou Zhang, Xiaojin Zhu", "title": "Teacher Improves Learning by Selecting a Training Subset", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call a learner super-teachable if a teacher can trim down an iid training\nset while making the learner learn even better. We provide sharp super-teaching\nguarantees on two learners: the maximum likelihood estimator for the mean of a\nGaussian, and the large margin classifier in 1D. For general learners, we\nprovide a mixed-integer nonlinear programming-based algorithm to find a super\nteaching set. Empirical experiments show that our algorithm is able to find\ngood super-teaching sets for both regression and classification problems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 02:47:46 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Ma", "Yuzhe", ""], ["Nowak", "Robert", ""], ["Rigollet", "Philippe", ""], ["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "1802.08969", "submitter": "Xipeng Qiu", "authors": "Junkun Chen, Xipeng Qiu, Pengfei Liu, Xuanjing Huang", "title": "Meta Multi-Task Learning for Sequence Modeling", "comments": "published in The Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic composition functions have been playing a pivotal role in neural\nrepresentation learning of text sequences. In spite of their success, most\nexisting models suffer from the underfitting problem: they use the same shared\ncompositional function on all the positions in the sequence, thereby lacking\nexpressive power due to incapacity to capture the richness of compositionality.\nBesides, the composition functions of different tasks are independent and\nlearned from scratch. In this paper, we propose a new sharing scheme of\ncomposition function across multiple tasks. Specifically, we use a shared\nmeta-network to capture the meta-knowledge of semantic composition and generate\nthe parameters of the task-specific semantic composition models. We conduct\nextensive experiments on two types of tasks, text classification and sequence\ntagging, which demonstrate the benefits of our approach. Besides, we show that\nthe shared meta-knowledge learned by our proposed model can be regarded as\noff-the-shelf knowledge and easily transferred to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:01:25 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Chen", "Junkun", ""], ["Qiu", "Xipeng", ""], ["Liu", "Pengfei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1802.08974", "submitter": "Kun Hu", "authors": "Kun Hu, Zhe Li, Ying Liu, Luyin Cheng, Qi Yang, and Yan Li", "title": "A Framework in CRM Customer Lifecycle: Identify Downward Trend and\n  Potential Issues Detection", "comments": "14 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer retention is one of the primary goals in the area of customer\nrelationship management. A mass of work exists in which machine learning models\nor business rules are established to predict churn. However, targeting users at\nan early stage when they start to show a downward trend is a better strategy.\nIn downward trend prediction, the reasons why customers show a downward trend\nis of great interest in the industry as it helps the business to understand the\npain points that customers suffer and to take early action to prevent them from\nchurning. A commonly used method is to collect feedback from customers by\neither aggressively reaching out to them or by passively hearing from them.\nHowever, it is believed that there are a large number of customers who have\nunpleasant experiences and never speak out. In the literature, there is limited\nresearch work that provides a comprehensive and scientific approach to identify\nthese \"silent suffers\". In this study, we propose a novel two-part framework:\ndeveloping the downward prediction process and establishing the methodology to\nidentify the reasons why customers are in the downward trend. In the first\nprediction part, we focus on predicting the downward trend, which is an earlier\nstage of the customer lifecycle compared to churn. In the second part, we\npropose an approach to figuring out the cause (of the downward trend) based on\na causal inference method and semi-supervised learning. The proposed approach\nis capable of identifying potential silent sufferers. We take bad shopping\nexperiences as inputs to develop the framework and validate it via a marketing\nA/B test in the real world. The test readout demonstrates the effectiveness of\nthe framework by driving 88.5% incremental lift in purchase volume.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:28:52 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hu", "Kun", ""], ["Li", "Zhe", ""], ["Liu", "Ying", ""], ["Cheng", "Luyin", ""], ["Yang", "Qi", ""], ["Li", "Yan", ""]]}, {"id": "1802.09030", "submitter": "Uri Patish", "authors": "Uri Patish, Shimon Ullman", "title": "Cakewalk Sampling", "comments": "Accepted as a conference paper by AAAI-2020 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of finding good local optima in combinatorial optimization\nproblems. Although combinatorial optimization is NP-hard in general, locally\noptimal solutions are frequently used in practice. Local search methods however\ntypically converge to a limited set of optima that depend on their\ninitialization. Sampling methods on the other hand can access any valid\nsolution, and thus can be used either directly or alongside methods of the\nformer type as a way for finding good local optima. Since the effectiveness of\nthis strategy depends on the sampling distribution, we derive a robust learning\nalgorithm that adapts sampling distributions towards good local optima of\narbitrary objective functions. As a first use case, we empirically study the\nefficiency in which sampling methods can recover locally maximal cliques in\nundirected graphs. Not only do we show how our adaptive sampler outperforms\nrelated methods, we also show how it can even approach the performance of\nestablished clique algorithms. As a second use case, we consider how greedy\nalgorithms can be combined with our adaptive sampler, and we demonstrate how\nthis leads to superior performance in k-medoid clustering. Together, these\nfindings suggest that our adaptive sampler can provide an effective strategy to\ncombinatorial optimization problems that arise in practice.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 16:15:32 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 11:07:41 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Patish", "Uri", ""], ["Ullman", "Shimon", ""]]}, {"id": "1802.09089", "submitter": "Yisroel Mirsky Mr.", "authors": "Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, Asaf Shabtai", "title": "Kitsune: An Ensemble of Autoencoders for Online Network Intrusion\n  Detection", "comments": "Appears in Network and Distributed Systems Security Symposium (NDSS)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become an increasingly popular solution for network\nintrusion detection systems (NIDS). Their capability of learning complex\npatterns and behaviors make them a suitable solution for differentiating\nbetween normal traffic and network attacks. However, a drawback of neural\nnetworks is the amount of resources needed to train them. Many network gateways\nand routers devices, which could potentially host an NIDS, simply do not have\nthe memory or processing power to train and sometimes even execute such models.\nMore importantly, the existing neural network solutions are trained in a\nsupervised manner. Meaning that an expert must label the network traffic and\nupdate the model manually from time to time.\n  In this paper, we present Kitsune: a plug and play NIDS which can learn to\ndetect attacks on the local network, without supervision, and in an efficient\nonline manner. Kitsune's core algorithm (KitNET) uses an ensemble of neural\nnetworks called autoencoders to collectively differentiate between normal and\nabnormal traffic patterns. KitNET is supported by a feature extraction\nframework which efficiently tracks the patterns of every network channel. Our\nevaluations show that Kitsune can detect various attacks with a performance\ncomparable to offline anomaly detectors, even on a Raspberry PI. This\ndemonstrates that Kitsune can be a practical and economic NIDS.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 21:42:56 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 09:50:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Doitshman", "Tomer", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "1802.09100", "submitter": "Ahmed Fadhil", "authors": "Ahmed Fadhil", "title": "Can a Chatbot Determine My Diet?: Addressing Challenges of Chatbot\n  Application for Meal Recommendation", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Poor nutrition can lead to reduced immunity, increased susceptibility to\ndisease, impaired physical and mental development, and reduced productivity. A\nconversational agent can support people as a virtual coach, however building\nsuch systems still have its associated challenges and limitations. This paper\ndescribes the background and motivation for chatbot systems in the context of\nhealthy nutrition recommendation. We discuss current challenges associated with\nchatbot application, we tackled technical, theoretical, behavioural, and social\naspects of the challenges. We then propose a pipeline to be used as guidelines\nby developers to implement theoretically and technically robust chatbot\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 22:30:10 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Fadhil", "Ahmed", ""]]}, {"id": "1802.09119", "submitter": "Ruggiero Lovreglio", "authors": "Ruggiero Lovreglio, Vicente Gonzalez, Zhenan Feng, Robert Amor,\n  Michael Spearpoint, Jared Thomas, Margaret Trotter, Rafael Sacks", "title": "Prototyping Virtual Reality Serious Games for Building Earthquake\n  Preparedness: The Auckland City Hospital Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing evacuee safety is a key factor in reducing the number of injuries\nand deaths that result from earthquakes. One way this can be achieved is by\ntraining occupants. Virtual Reality (VR) and Serious Games (SGs), represent\nnovel techniques that may overcome the limitations of traditional training\napproaches. VR and SGs have been examined in the fire emergency context,\nhowever, their application to earthquake preparedness has not yet been\nextensively examined. We provide a theoretical discussion of the advantages and\nlimitations of using VR SGs to investigate how building occupants behave during\nearthquake evacuations and to train building occupants to cope with such\nemergencies. We explore key design components for developing a VR SG framework:\n(a) what features constitute an earthquake event, (b) which building types can\nbe selected and represented within the VR environment, (c) how damage to the\nbuilding can be determined and represented, (d) how non-player characters (NPC)\ncan be designed, and (e) what level of interaction there can be between NPC and\nthe human participants. We illustrate the above by presenting the Auckland City\nHospital, New Zealand as a case study, and propose a possible VR SG training\ntool to enhance earthquake preparedness in public buildings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 01:08:51 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Lovreglio", "Ruggiero", ""], ["Gonzalez", "Vicente", ""], ["Feng", "Zhenan", ""], ["Amor", "Robert", ""], ["Spearpoint", "Michael", ""], ["Thomas", "Jared", ""], ["Trotter", "Margaret", ""], ["Sacks", "Rafael", ""]]}, {"id": "1802.09129", "submitter": "Weifeng Ge", "authors": "Weifeng Ge, Sibei Yang, Yizhou Yu", "title": "Multi-Evidence Filtering and Fusion for Multi-Label Classification,\n  Object Detection and Semantic Segmentation Based on Weakly Supervised\n  Learning", "comments": "accepted by IEEE International Conference on Computer Vision and\n  Pattern Recognition (CVPR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised object detection and semantic segmentation require object or even\npixel level annotations. When there exist image level labels only, it is\nchallenging for weakly supervised algorithms to achieve accurate predictions.\nThe accuracy achieved by top weakly supervised algorithms is still\nsignificantly lower than their fully supervised counterparts. In this paper, we\npropose a novel weakly supervised curriculum learning pipeline for multi-label\nobject recognition, detection and semantic segmentation. In this pipeline, we\nfirst obtain intermediate object localization and pixel labeling results for\nthe training images, and then use such results to train task-specific deep\nnetworks in a fully supervised manner. The entire process consists of four\nstages, including object localization in the training images, filtering and\nfusing object instances, pixel labeling for the training images, and\ntask-specific network training. To obtain clean object instances in the\ntraining images, we propose a novel algorithm for filtering, fusing and\nclassifying object instances collected from multiple solution mechanisms. In\nthis algorithm, we incorporate both metric learning and density-based\nclustering to filter detected object instances. Experiments show that our\nweakly supervised pipeline achieves state-of-the-art results in multi-label\nimage classification as well as weakly supervised object detection and very\ncompetitive results in weakly supervised semantic segmentation on MS-COCO,\nPASCAL VOC 2007 and PASCAL VOC 2012.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 02:07:19 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Ge", "Weifeng", ""], ["Yang", "Sibei", ""], ["Yu", "Yizhou", ""]]}, {"id": "1802.09158", "submitter": "Juntao Wang Mr", "authors": "Yang Liu, Juntao Wang and Yiling Chen", "title": "Surrogate Scoring Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strictly proper scoring rules (SPSR) are incentive compatible for eliciting\ninformation about random variables from strategic agents when the principal can\nreward agents after the realization of the random variables. They also quantify\nthe quality of elicited information, with more accurate predictions receiving\nhigher scores in expectation. In this paper, we extend such scoring rules to\nsettings where a principal elicits private probabilistic beliefs but only has\naccess to agents' reports. We name our solution \\emph{Surrogate Scoring Rules}\n(SSR). SSR build on a bias correction step and an error rate estimation\nprocedure for a reference answer defined using agents' reports. We show that,\nwith a single bit of information about the prior distribution of the random\nvariables, SSR in a multi-task setting recover SPSR in expectation, as if\nhaving access to the ground truth. Therefore, a salient feature of SSR is that\nthey quantify the quality of information despite the lack of ground truth, just\nas SPSR do for the setting \\emph{with} ground truth. As a by-product, SSR\ninduce \\emph{dominant truthfulness} in reporting. Our method is verified both\ntheoretically and empirically using data collected from real human forecasters.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 04:52:48 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 22:52:04 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 19:04:15 GMT"}, {"version": "v4", "created": "Mon, 11 Mar 2019 17:57:26 GMT"}, {"version": "v5", "created": "Sat, 15 Feb 2020 05:47:30 GMT"}, {"version": "v6", "created": "Mon, 1 Jun 2020 12:56:55 GMT"}, {"version": "v7", "created": "Sun, 7 Jun 2020 01:40:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Liu", "Yang", ""], ["Wang", "Juntao", ""], ["Chen", "Yiling", ""]]}, {"id": "1802.09159", "submitter": "Ramamurthy Badrinath", "authors": "Anusha Mujumdar, Swarup Kumar Mohalik, Ramamurthy Badrinath", "title": "Antifragility for Intelligent Autonomous Systems", "comments": "Under Review. Consists of seven pages and four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Antifragile systems grow measurably better in the presence of hazards. This\nis in contrast to fragile systems which break down in the presence of hazards,\nrobust systems that tolerate hazards up to a certain degree, and resilient\nsystems that -- like self-healing systems -- revert to their earlier expected\nbehavior after a period of convalescence. The notion of antifragility was\nintroduced by Taleb for economics systems, but its applicability has been\nillustrated in biological and engineering domains as well. In this paper, we\npropose an architecture that imparts antifragility to intelligent autonomous\nsystems, specifically those that are goal-driven and based on AI-planning. We\nargue that this architecture allows the system to self-improve by uncovering\nnew capabilities obtained either through the hazards themselves (opportunistic)\nor through deliberation (strategic). An AI planning-based case study of an\nautonomous wheeled robot is presented. We show that with the proposed\narchitecture, the robot develops antifragile behaviour with respect to an oil\nspill hazard.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 04:58:55 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mujumdar", "Anusha", ""], ["Mohalik", "Swarup Kumar", ""], ["Badrinath", "Ramamurthy", ""]]}, {"id": "1802.09184", "submitter": "Lin Yang", "authors": "Sham Kakade, Mengdi Wang, Lin F. Yang", "title": "Variance Reduction Methods for Sublinear Reinforcement Learning", "comments": "There is a technical issue in the analysis that is not easily fixable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a technical issue in the analysis that is not easily fixable. We,\ntherefore, withdraw the submission. Sorry for the inconvenience.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 07:01:24 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 19:53:50 GMT"}, {"version": "v3", "created": "Sat, 25 Aug 2018 05:22:45 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 16:25:37 GMT"}, {"version": "v5", "created": "Sat, 27 Jun 2020 04:14:36 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kakade", "Sham", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""]]}, {"id": "1802.09296", "submitter": "Sherzod Hakimov", "authors": "Sherzod Hakimov, Soufian Jebbara, Philipp Cimiano", "title": "AMUSE: Multilingual Semantic Parsing for Question Answering over Linked\n  Data", "comments": "International Semantic Web Conference, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The task of answering natural language questions over RDF data has received\nwide interest in recent years, in particular in the context of the series of\nQALD benchmarks. The task consists of mapping a natural language question to an\nexecutable form, e.g. SPARQL, so that answers from a given KB can be extracted.\nSo far, most systems proposed are i) monolingual and ii) rely on a set of\nhard-coded rules to interpret questions and map them into a SPARQL query. We\npresent the first multilingual QALD pipeline that induces a model from training\ndata for mapping a natural language question into logical form as probabilistic\ninference. In particular, our approach learns to map universal syntactic\ndependency representations to a language-independent logical form based on\nDUDES (Dependency-based Underspecified Discourse Representation Structures)\nthat are then mapped to a SPARQL query as a deterministic second step. Our\nmodel builds on factor graphs that rely on features extracted from the\ndependency graph and corresponding semantic representations. We rely on\napproximate inference techniques, Markov Chain Monte Carlo methods in\nparticular, as well as Sample Rank to update parameters using a ranking\nobjective. Our focus lies on developing methods that overcome the lexical gap\nand present a novel combination of machine translation and word embedding\napproaches for this purpose. As a proof of concept for our approach, we\nevaluate our approach on the QALD-6 datasets for English, German & Spanish.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 13:50:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hakimov", "Sherzod", ""], ["Jebbara", "Soufian", ""], ["Cimiano", "Philipp", ""]]}, {"id": "1802.09317", "submitter": "Eric Sanchis", "authors": "Eric Sanchis", "title": "A Model of Free Will for Artificial Entities", "comments": "10th International Conference on Advanced Cognitive Technologies and\n  Applications, (COGNITIVE 2018), February 18-22, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impression of free will is the feeling according to which our choices are\nneither imposed from our inside nor from outside. It is the sense we are the\nultimate cause of our acts. In direct opposition with the universal\ndeterminism, the existence of free will continues to be discussed. In this\npaper, free will is linked to a decisional mechanism: an agent is provided with\nfree will if having performed a predictable choice Cp, it can immediately\nperform another choice Cr in a random way. The intangible feeling of free will\nis replaced by a decision-making process including a predictable\ndecision-making process immediately followed by an unpredictable decisional\none.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 14:29:03 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sanchis", "Eric", ""]]}, {"id": "1802.09355", "submitter": "Shaoshan Liu", "authors": "Jie Tang, Shaoshan Liu, Songwen Pei, Stephane Zuckerman, Chen Liu,\n  Weisong Shi, Jean-Luc Gaudiot", "title": "Teaching Autonomous Driving Using a Modular and Integrated Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving is not one single technology but rather a complex system\nintegrating many technologies, which means that teaching autonomous driving is\na challenging task. Indeed, most existing autonomous driving classes focus on\none of the technologies involved. This not only fails to provide a\ncomprehensive coverage, but also sets a high entry barrier for students with\ndifferent technology backgrounds. In this paper, we present a modular,\nintegrated approach to teaching autonomous driving. Specifically, we organize\nthe technologies used in autonomous driving into modules. This is described in\nthe textbook we have developed as well as a series of multimedia online\nlectures designed to provide technical overview for each module. Then, once the\nstudents have understood these modules, the experimental platforms for\nintegration we have developed allow the students to fully understand how the\nmodules interact with each other. To verify this teaching approach, we present\nthree case studies: an introductory class on autonomous driving for students\nwith only a basic technology background; a new session in an existing embedded\nsystems class to demonstrate how embedded system technologies can be applied to\nautonomous driving; and an industry professional training session to quickly\nbring up experienced engineers to work in autonomous driving. The results show\nthat students can maintain a high interest level and make great progress by\nstarting with familiar concepts before moving onto other modules.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:01:51 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 01:50:31 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Tang", "Jie", ""], ["Liu", "Shaoshan", ""], ["Pei", "Songwen", ""], ["Zuckerman", "Stephane", ""], ["Liu", "Chen", ""], ["Shi", "Weisong", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "1802.09442", "submitter": "Valentina Gliozzi", "authors": "Valentina Gliozzi and Kim Plunkett", "title": "Self-organizing maps and generalization: an algorithmic description of\n  Numerosity and Variability Effects", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Category, or property generalization is a central function in the human\ncognition. It plays a crucial role in a variety of domains, such as learning,\neveryday reasoning, specialized reasoning, and decision making. Judging the\ncontent of a dish as edible, a hormone level as healthy, a building as\nbelonging to the same architectural style as previously seen buildings, are\nexamples of category generalization. In this paper, we propose self-organizing\nmaps as candidates to explain the psychological mechanisms underlying category\ngeneralization. Self-organizing maps are psychologically and biologically\nplausible neural network models that learn after limited exposure to positive\ncategory examples, without any need of contrastive information. Just like\nhumans. They reproduce human behavior in category generalization, in particular\nfor what concerns the well-known Numerosity and Variability effects, which are\nusually explained with Bayesian tools. Where category generalization is\nconcerned, self-organizing maps are good candidates to bridge the gap between\nthe computational level of analysis in Marr's hierarchy (where Bayesian models\nare situated) and the algorithmic level of aanalysis in Marr's hierarchy (where\nBayesian models are situated) and the algorithmic level of analysis in which\nplausible mechanisms are described.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:38:42 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gliozzi", "Valentina", ""], ["Plunkett", "Kim", ""]]}, {"id": "1802.09464", "submitter": "Matthias Plappert", "authors": "Matthias Plappert, Marcin Andrychowicz, Alex Ray, Bob McGrew, Bowen\n  Baker, Glenn Powell, Jonas Schneider, Josh Tobin, Maciek Chociej, Peter\n  Welinder, Vikash Kumar, Wojciech Zaremba", "title": "Multi-Goal Reinforcement Learning: Challenging Robotics Environments and\n  Request for Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this technical report is two-fold. First of all, it introduces\na suite of challenging continuous control tasks (integrated with OpenAI Gym)\nbased on currently existing robotics hardware. The tasks include pushing,\nsliding and pick & place with a Fetch robotic arm as well as in-hand object\nmanipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards\nand follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent\nis told what to do using an additional input.\n  The second part of the paper presents a set of concrete research ideas for\nimproving RL algorithms, most of which are related to Multi-Goal RL and\nHindsight Experience Replay.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 17:20:14 GMT"}, {"version": "v2", "created": "Sat, 10 Mar 2018 18:11:25 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Plappert", "Matthias", ""], ["Andrychowicz", "Marcin", ""], ["Ray", "Alex", ""], ["McGrew", "Bob", ""], ["Baker", "Bowen", ""], ["Powell", "Glenn", ""], ["Schneider", "Jonas", ""], ["Tobin", "Josh", ""], ["Chociej", "Maciek", ""], ["Welinder", "Peter", ""], ["Kumar", "Vikash", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1802.09465", "submitter": "Dominik Wojtczak", "authors": "Dominik Wojtczak", "title": "On Strong NP-Completeness of Rational Problems", "comments": "to appear in Proc. of CSR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of the partition, 0-1 subset sum, unbounded\nsubset sum, 0-1 knapsack and unbounded knapsack problems and their multiple\nvariants were studied in numerous papers in the past where all the weights and\nprofits were assumed to be integers. We re-examine here the computational\ncomplexity of all these problems in the setting where the weights and profits\nare allowed to be any rational numbers. We show that all of these problems in\nthis setting become strongly NP-complete and, as a result, no pseudo-polynomial\nalgorithm can exist for solving them unless P=NP. Despite this result we show\nthat they all still admit a fully polynomial-time approximation scheme.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 17:23:02 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Wojtczak", "Dominik", ""]]}, {"id": "1802.09477", "submitter": "Scott Fujimoto", "authors": "Scott Fujimoto, Herke van Hoof, David Meger", "title": "Addressing Function Approximation Error in Actor-Critic Methods", "comments": "Accepted at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In value-based reinforcement learning methods such as deep Q-learning,\nfunction approximation errors are known to lead to overestimated value\nestimates and suboptimal policies. We show that this problem persists in an\nactor-critic setting and propose novel mechanisms to minimize its effects on\nboth the actor and the critic. Our algorithm builds on Double Q-learning, by\ntaking the minimum value between a pair of critics to limit overestimation. We\ndraw the connection between target networks and overestimation bias, and\nsuggest delaying policy updates to reduce per-update error and further improve\nperformance. We evaluate our method on the suite of OpenAI gym tasks,\noutperforming the state of the art in every environment tested.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 17:54:49 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 18:21:26 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 17:37:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Fujimoto", "Scott", ""], ["van Hoof", "Herke", ""], ["Meger", "David", ""]]}, {"id": "1802.09564", "submitter": "Yuke Zhu", "authors": "Yuke Zhu, Ziyu Wang, Josh Merel, Andrei Rusu, Tom Erez, Serkan Cabi,\n  Saran Tunyasuvunakool, J\\'anos Kram\\'ar, Raia Hadsell, Nando de Freitas,\n  Nicolas Heess", "title": "Reinforcement and Imitation Learning for Diverse Visuomotor Skills", "comments": "13 pages, 6 figures, Published in RSS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-free deep reinforcement learning method that leverages a\nsmall amount of demonstration data to assist a reinforcement learning agent. We\napply this approach to robotic manipulation tasks and train end-to-end\nvisuomotor policies that map directly from RGB camera inputs to joint\nvelocities. We demonstrate that our approach can solve a wide variety of\nvisuomotor tasks, for which engineering a scripted controller would be\nlaborious. In experiments, our reinforcement and imitation agent achieves\nsignificantly better performances than agents trained with reinforcement\nlearning or imitation learning alone. We also illustrate that these policies,\ntrained with large visual and dynamics variations, can achieve preliminary\nsuccesses in zero-shot sim2real transfer. A brief visual description of this\nwork can be viewed in https://youtu.be/EDl8SQUNjj0\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:25:25 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 22:41:09 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhu", "Yuke", ""], ["Wang", "Ziyu", ""], ["Merel", "Josh", ""], ["Rusu", "Andrei", ""], ["Erez", "Tom", ""], ["Cabi", "Serkan", ""], ["Tunyasuvunakool", "Saran", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["Hadsell", "Raia", ""], ["de Freitas", "Nando", ""], ["Heess", "Nicolas", ""]]}, {"id": "1802.09612", "submitter": "Jiongqian Liang", "authors": "Jiongqian Liang, Saket Gurukar, Srinivasan Parthasarathy", "title": "MILE: A Multi-Level Framework for Scalable Graph Embedding", "comments": "Accepted in ICWSM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a surge of interest in designing graph embedding\nmethods. Few, if any, can scale to a large-sized graph with millions of nodes\ndue to both computational complexity and memory requirements. In this paper, we\nrelax this limitation by introducing the MultI-Level Embedding (MILE) framework\n-- a generic methodology allowing contemporary graph embedding methods to scale\nto large graphs. MILE repeatedly coarsens the graph into smaller ones using a\nhybrid matching technique to maintain the backbone structure of the graph. It\nthen applies existing embedding methods on the coarsest graph and refines the\nembeddings to the original graph through a graph convolution neural network\nthat it learns. The proposed MILE framework is agnostic to the underlying graph\nembedding techniques and can be applied to many existing graph embedding\nmethods without modifying them. We employ our framework on several popular\ngraph embedding techniques and conduct embedding for real-world graphs.\nExperimental results on five large-scale datasets demonstrate that MILE\nsignificantly boosts the speed (order of magnitude) of graph embedding while\ngenerating embeddings of better quality, for the task of node classification.\nMILE can comfortably scale to a graph with 9 million nodes and 40 million\nedges, on which existing methods run out of memory or take too long to compute\non a modern workstation. Our code and data are publicly available with detailed\ninstructions for adding new base embedding methods:\n\\url{https://github.com/jiongqian/MILE}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 21:18:43 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 21:56:38 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Liang", "Jiongqian", ""], ["Gurukar", "Saket", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1802.09640", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu, Emily Denton, Arthur Szlam, Rob Fergus", "title": "Modeling Others using Oneself in Multi-Agent Reinforcement Learning", "comments": "10 pages, 16 figures, submitted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the multi-agent reinforcement learning setting with imperfect\ninformation in which each agent is trying to maximize its own utility. The\nreward function depends on the hidden state (or goal) of both agents, so the\nagents must infer the other players' hidden goals from their observed behavior\nin order to solve the tasks. We propose a new approach for learning in these\ndomains: Self Other-Modeling (SOM), in which an agent uses its own policy to\npredict the other agent's actions and update its belief of their hidden state\nin an online manner. We evaluate this approach on three different tasks and\nshow that the agents are able to learn better policies using their estimate of\nthe other players' hidden states, in both cooperative and adversarial settings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 23:27:53 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 17:07:38 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 21:53:13 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Raileanu", "Roberta", ""], ["Denton", "Emily", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1802.09647", "submitter": "Jiangjun Tang", "authors": "Jiangjun Tang, Eleni Petraki, and Hussein Abbass", "title": "Shaping Influence and Influencing Shaping: A Computational Red Teaming\n  Trust-based Swarm Intelligence Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sociotechnical systems are complex systems, where nonlinear interaction among\ndifferent players can obscure causal relationships. The absence of mechanisms\nto help us understand how to create a change in the system makes it hard to\nmanage these systems.\n  Influencing and shaping are social operators acting on sociotechnical systems\nto design a change. However, the two operators are usually discussed in an\nad-hoc manner, without proper guiding models and metrics which assist in\nadopting these models successfully. Moreover, both social operators rely on\naccurate understanding of the concept of trust. Without such understanding,\nneither of these operators can create the required level to create a change in\na desirable direction.\n  In this paper, we define these concepts in a concise manner suitable for\nmodelling the concepts and understanding their dynamics. We then introduce a\nmodel for influencing and shaping and use Computational Red Teaming principles\nto design and demonstrate how this model operates. We validate the results\ncomputationally through a simulation environment to show social influencing and\nshaping in an artificial society.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 23:53:40 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Tang", "Jiangjun", ""], ["Petraki", "Eleni", ""], ["Abbass", "Hussein", ""]]}, {"id": "1802.09669", "submitter": "George Leu", "authors": "George Leu and Hussein Abbass", "title": "A Multi-Disciplinary Review of Knowledge Acquisition Methods: From Human\n  to Autonomous Eliciting Agents", "comments": null, "journal-ref": "Knowledge-Based Systems, Volume 105, Elsevier, 2016", "doi": "10.1016/j.knosys.2016.02.012", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a multi-disciplinary review of knowledge acquisition\nmethods in human activity systems. The review captures the degree of\ninvolvement of various types of agencies in the knowledge acquisition process,\nand proposes a classification with three categories of methods: the human\nagent, the human-inspired agent, and the autonomous machine agent methods. In\nthe first two categories, the acquisition of knowledge is seen as a cognitive\ntask analysis exercise, while in the third category knowledge acquisition is\ntreated as an autonomous knowledge-discovery endeavour. The motivation for this\nclassification stems from the continuous change over time of the structure,\nmeaning and purpose of human activity systems, which are seen as the factor\nthat fuelled researchers' and practitioners' efforts in knowledge acquisition\nfor more than a century.\n  We show through this review that the KA field is increasingly active due to\nthe higher and higher pace of change in human activity, and conclude by\ndiscussing the emergence of a fourth category of knowledge acquisition methods,\nwhich are based on red-teaming and co-evolution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 01:21:46 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Leu", "George", ""], ["Abbass", "Hussein", ""]]}, {"id": "1802.09728", "submitter": "Farhad Zafari", "authors": "F. Zafari, I. Moser, T. Baarslag", "title": "Modelling and Analysis of Temporal Preference Drifts Using A\n  Component-Based Factorised Latent Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The changes in user preferences can originate from substantial reasons, like\npersonality shift, or transient and circumstantial ones, like seasonal changes\nin item popularities. Disregarding these temporal drifts in modelling user\npreferences can result in unhelpful recommendations. Moreover, different\ntemporal patterns can be associated with various preference domains, and\npreference components and their combinations. These components comprise\npreferences over features, preferences over feature values, conditional\ndependencies between features, socially-influenced preferences, and bias. For\nexample, in the movies domain, the user can change his rating behaviour (bias\nshift), her preference for genre over language (feature preference shift), or\nstart favouring drama over comedy (feature value preference shift). In this\npaper, we first propose a novel latent factor model to capture the\ndomain-dependent component-specific temporal patterns in preferences. The\ncomponent-based approach followed in modelling the aspects of preferences and\ntheir temporal effects enables us to arbitrarily switch components on and off.\nWe evaluate the proposed method on three popular recommendation datasets and\nshow that it significantly outperforms the most accurate state-of-the-art\nstatic models. The experiments also demonstrate the greater robustness and\nstability of the proposed dynamic model in comparison with the most successful\nmodels to date. We also analyse the temporal behaviour of different preference\ncomponents and their combinations and show that the dynamic behaviour of\npreference components is highly dependent on the preference dataset and domain.\nTherefore, the results also highlight the importance of modelling temporal\neffects but also underline the advantages of a component-based architecture\nthat is better suited to capture domain-specific balances in the contributions\nof the aspects.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 06:00:49 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 02:35:29 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Zafari", "F.", ""], ["Moser", "I.", ""], ["Baarslag", "T.", ""]]}, {"id": "1802.09751", "submitter": "Stephen Mussmann", "authors": "Stephen Mussmann and Percy Liang", "title": "Generalized Binary Search For Split-Neighborly Problems", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In sequential hypothesis testing, Generalized Binary Search (GBS) greedily\nchooses the test with the highest information gain at each step. It is known\nthat GBS obtains the gold standard query cost of $O(\\log n)$ for problems\nsatisfying the $k$-neighborly condition, which requires any two tests to be\nconnected by a sequence of tests where neighboring tests disagree on at most\n$k$ hypotheses. In this paper, we introduce a weaker condition,\nsplit-neighborly, which requires that for the set of hypotheses two neighbors\ndisagree on, any subset is splittable by some test. For four problems that are\nnot $k$-neighborly for any constant $k$, we prove that they are\nsplit-neighborly, which allows us to obtain the optimal $O(\\log n)$ worst-case\nquery cost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:30:32 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Mussmann", "Stephen", ""], ["Liang", "Percy", ""]]}, {"id": "1802.09756", "submitter": "Junqi Jin", "authors": "Junqi Jin, Chengru Song, Han Li, Kun Gai, Jun Wang, Weinan Zhang", "title": "Real-Time Bidding with Multi-Agent Reinforcement Learning in Display\n  Advertising", "comments": null, "journal-ref": "CIKM 2018, Turin, Italy", "doi": "10.1145/3269206.3272021", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time advertising allows advertisers to bid for each impression for a\nvisiting user. To optimize specific goals such as maximizing revenue and return\non investment (ROI) led by ad placements, advertisers not only need to estimate\nthe relevance between the ads and user's interests, but most importantly\nrequire a strategic response with respect to other advertisers bidding in the\nmarket. In this paper, we formulate bidding optimization with multi-agent\nreinforcement learning. To deal with a large number of advertisers, we propose\na clustering method and assign each cluster with a strategic bidding agent. A\npractical Distributed Coordinated Multi-Agent Bidding (DCMAB) has been proposed\nand implemented to balance the tradeoff between the competition and cooperation\namong advertisers. The empirical study on our industry-scaled real-world data\nhas demonstrated the effectiveness of our methods. Our results show\ncluster-based bidding would largely outperform single-agent and bandit\napproaches, and the coordinated bidding achieves better overall objectives than\npurely self-interested bidding agents.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 07:52:35 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 13:53:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Jin", "Junqi", ""], ["Song", "Chengru", ""], ["Li", "Han", ""], ["Gai", "Kun", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""]]}, {"id": "1802.09810", "submitter": "Nils Jansen", "authors": "Steven Carr, Nils Jansen, Ralf Wimmer, Jie Fu, Ufuk Topcu", "title": "Human-in-the-Loop Synthesis for Partially Observable Markov Decision\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study planning problems where autonomous agents operate inside\nenvironments that are subject to uncertainties and not fully observable.\nPartially observable Markov decision processes (POMDPs) are a natural formal\nmodel to capture such problems. Because of the potentially huge or even\ninfinite belief space in POMDPs, synthesis with safety guarantees is, in\ngeneral, computationally intractable. We propose an approach that aims to\ncircumvent this difficulty: in scenarios that can be partially or fully\nsimulated in a virtual environment, we actively integrate a human user to\ncontrol an agent. While the user repeatedly tries to safely guide the agent in\nthe simulation, we collect data from the human input. Via behavior cloning, we\ntranslate the data into a strategy for the POMDP. The strategy resolves all\nnondeterminism and non-observability of the POMDP, resulting in a discrete-time\nMarkov chain (MC). The efficient verification of this MC gives quantitative\ninsights into the quality of the inferred human strategy by proving or\ndisproving given system specifications. For the case that the quality of the\nstrategy is not sufficient, we propose a refinement method using\ncounterexamples presented to the human. Experiments show that by including\nhumans into the POMDP verification loop we improve the state of the art by\norders of magnitude in terms of scalability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:29:56 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Carr", "Steven", ""], ["Jansen", "Nils", ""], ["Wimmer", "Ralf", ""], ["Fu", "Jie", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1802.09816", "submitter": "Guillaume Charpiat", "authors": "Armand Zampieri (TITANE), Guillaume Charpiat (TAU), Yuliya Tarabalka\n  (TITANE)", "title": "Coarse to fine non-rigid registration: a chain of scale-specific neural\n  networks for multimodal image alignment with application to remote sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle here the problem of multimodal image non-rigid registration, which\nis of prime importance in remote sensing and medical imaging. The difficulties\nencountered by classical registration approaches include feature design and\nslow optimization by gradient descent. By analyzing these methods, we note the\nsignificance of the notion of scale. We design easy-to-train,\nfully-convolutional neural networks able to learn scale-specific features. Once\nchained appropriately, they perform global registration in linear time, getting\nrid of gradient descent schemes by predicting directly the deformation.We show\ntheir performance in terms of quality and speed through various tasks of remote\nsensing multimodal image alignment. In particular, we are able to register\ncorrectly cadastral maps of buildings as well as road polylines onto RGB\nimages, and outperform current keypoint matching methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:47:06 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Zampieri", "Armand", "", "TITANE"], ["Charpiat", "Guillaume", "", "TAU"], ["Tarabalka", "Yuliya", "", "TITANE"]]}, {"id": "1802.09904", "submitter": "Hector Zenil", "authors": "Hector Zenil, Narsis A. Kiani, Allan A. Zea, Jesper Tegn\\'er", "title": "Algorithmic Causal Deconvolution of Intertwined Programs and Networks by\n  Generative Mechanism", "comments": "29 pages + 7 Sup Inf. 9 figures in total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex data usually results from the interaction of objects produced by\ndifferent generating mechanisms. Here we introduce a universal, unsupervised\nand parameter-free model-oriented approach, based upon the seminal concept of\nalgorithmic probability, that decomposes an observation into its most likely\nalgorithmic generative sources. Our approach uses a causal calculus to infer\nmodel representations. We demonstrate its ability to deconvolve interacting\nmechanisms regardless of whether the resultant objects are strings, space-time\nevolution diagrams, images or networks. While this is mostly a conceptual\ncontribution and a novel framework, we provide numerical evidence evaluating\nthe ability of our methods to separate data from observations produced by\ndiscrete dynamical systems such as cellular automata and complex networks. We\nthink that these separating techniques can contribute to tackling the challenge\nof causation, thus complementing other statistically oriented approaches.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 08:06:13 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 17:39:22 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2018 20:59:33 GMT"}, {"version": "v4", "created": "Thu, 5 Apr 2018 19:50:26 GMT"}, {"version": "v5", "created": "Fri, 1 Jun 2018 14:06:06 GMT"}, {"version": "v6", "created": "Sat, 9 Jun 2018 07:49:55 GMT"}, {"version": "v7", "created": "Tue, 19 Jun 2018 20:48:58 GMT"}, {"version": "v8", "created": "Wed, 12 Sep 2018 23:26:16 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Zenil", "Hector", ""], ["Kiani", "Narsis A.", ""], ["Zea", "Allan A.", ""], ["Tegn\u00e9r", "Jesper", ""]]}, {"id": "1802.09911", "submitter": "Frank Z. Xing", "authors": "Frank Z. Xing and Erik Cambria and Lorenzo Malandri and Carlo\n  Vercellis", "title": "Discovering Bayesian Market Views for Intelligent Asset Allocation", "comments": "16 pages", "journal-ref": null, "doi": "10.1007/978-3-030-10997-4_8", "report-no": null, "categories": "q-fin.CP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the advance of opinion mining techniques, public mood has been\nfound to be a key element for stock market prediction. However, how market\nparticipants' behavior is affected by public mood has been rarely discussed.\nConsequently, there has been little progress in leveraging public mood for the\nasset allocation problem, which is preferred in a trusted and interpretable\nway. In order to address the issue of incorporating public mood analyzed from\nsocial media, we propose to formalize public mood into market views, because\nmarket views can be integrated into the modern portfolio theory. In our\nframework, the optimal market views will maximize returns in each period with a\nBayesian asset allocation model. We train two neural models to generate the\nmarket views, and benchmark the model performance on other popular asset\nallocation strategies. Our experimental results suggest that the formalization\nof market views significantly increases the profitability (5% to 10% annually)\nof the simulated portfolio at a given risk level.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 14:37:54 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 04:31:42 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Xing", "Frank Z.", ""], ["Cambria", "Erik", ""], ["Malandri", "Lorenzo", ""], ["Vercellis", "Carlo", ""]]}, {"id": "1802.09914", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "High-Dimensional Vector Semantics", "comments": "12 pages, 5 figures, Int. J. Mod. Phys. C, 2018", "journal-ref": null, "doi": "10.1142/S0129183118500158", "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the \"vector semantics\" problem from the perspective\nof \"almost orthogonal\" property of high-dimensional random vectors. We show\nthat this intriguing property can be used to \"memorize\" random vectors by\nsimply adding them, and we provide an efficient probabilistic solution to the\nset membership problem. Also, we discuss several applications to word context\nvector embeddings, document sentences similarity, and spam filtering.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 16:50:16 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1802.09924", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Introduction to the SP theory of intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a brief introduction to the \"Theory of Intelligence\"\nand its realisation in the \"SP Computer Model\". The overall goal of the SP\nprogramme of research, in accordance with long-established principles in\nscience, has been the simplification and integration of observations and\nconcepts across artificial intelligence, mainstream computing, mathematics, and\nhuman learning, perception, and cognition. In broad terms, the SP system is a\nbrain-like system that takes in \"New\" information through its senses and stores\nsome or all of it as \"Old\" information. A central idea in the system is the\npowerful concept of \"SP-multiple-alignment\", borrowed and adapted from\nbioinformatics. This the key to the system's versatility in aspects of\nintelligence, in the representation of diverse kinds of knowledge, and in the\nseamless integration of diverse aspects of intelligence and diverse kinds of\nknowledge, in any combination. There are many potential benefits and\napplications of the SP system. It is envisaged that the system will be\ndeveloped as the \"SP Machine\", which will initially be a software virtual\nmachine, hosted on a high-performance computer, a vehicle for further research\nand a step towards the development of an industrial-strength SP Machine.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 17:25:43 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1802.10026", "submitter": "Andrew Wilson", "authors": "Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry Vetrov,\n  Andrew Gordon Wilson", "title": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs", "comments": "Appears at Advances in Neural Information Processing Systems (NIPS),\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss functions of deep neural networks are complex and their geometric\nproperties are not well understood. We show that the optima of these complex\nloss functions are in fact connected by simple curves over which training and\ntest accuracy are nearly constant. We introduce a training procedure to\ndiscover these high-accuracy pathways between modes. Inspired by this new\ngeometric insight, we also propose a new ensembling method entitled Fast\nGeometric Ensembling (FGE). Using FGE we can train high-performing ensembles in\nthe time required to train a single model. We achieve improved performance\ncompared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10,\nCIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 17:13:28 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 13:53:29 GMT"}, {"version": "v3", "created": "Tue, 20 Mar 2018 00:16:34 GMT"}, {"version": "v4", "created": "Tue, 30 Oct 2018 11:39:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Garipov", "Timur", ""], ["Izmailov", "Pavel", ""], ["Podoprikhin", "Dmitrii", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1802.10054", "submitter": "Anthony Hunter", "authors": "Lisa Chalaguine and Emmanuel Hadoux and Fiona Hamilton and Andrew\n  Hayward and Anthony Hunter and Sylwia Polberg and Henry W. W. Potts", "title": "Domain Modelling in Computational Persuasion for Behaviour Change in\n  Healthcare", "comments": "32 pages, 9 figures, draft journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of behaviour change is to help people to change aspects of their\nbehaviour for the better (e.g., to decrease calorie intake, to drink in\nmoderation, to take more exercise, to complete a course of antibiotics once\nstarted, etc.). In current persuasion technology for behaviour change, the\nemphasis is on helping people to explore their issues (e.g., through\nquestionnaires or game playing) or to remember to follow a behaviour change\nplan (e.g., diaries and email reminders). However, recent developments in\ncomputational persuasion are leading to an argument-centric approach to\npersuasion that can potentially be harnessed in behaviour change applications.\nIn this paper, we review developments in computational persuasion, and then\nfocus on domain modelling as a key component. We present a multi-dimensional\napproach to domain modelling. At the core of this proposal is an ontology which\nprovides a representation of key factors, in particular kinds of belief, which\nwe have identified in the behaviour change literature as being important in\ndiverse behaviour change initiatives. Our proposal for domain modelling is\nintended to facilitate the acquisition and representation of the arguments that\ncan be used in persuasion dialogues, together with meta-level information about\nthem which can be used by the persuader to make strategic choices of argument\nto present.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 18:13:57 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Chalaguine", "Lisa", ""], ["Hadoux", "Emmanuel", ""], ["Hamilton", "Fiona", ""], ["Hayward", "Andrew", ""], ["Hunter", "Anthony", ""], ["Polberg", "Sylwia", ""], ["Potts", "Henry W. W.", ""]]}, {"id": "1802.10217", "submitter": "Rachit Dubey", "authors": "Rachit Dubey, Pulkit Agrawal, Deepak Pathak, Thomas L. Griffiths, and\n  Alexei A. Efros", "title": "Investigating Human Priors for Playing Video Games", "comments": "ICML 2018", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  What makes humans so good at solving seemingly complex video games? Unlike\ncomputers, humans bring in a great deal of prior knowledge about the world,\nenabling efficient decision making. This paper investigates the role of human\npriors for solving video games. Given a sample game, we conduct a series of\nablation studies to quantify the importance of various priors on human\nperformance. We do this by modifying the video game environment to\nsystematically mask different types of visual information that could be used by\nhumans as priors. We find that removal of some prior knowledge causes a drastic\ndegradation in the speed with which human players solve the game, e.g. from 2\nminutes to over 20 minutes. Furthermore, our results indicate that general\npriors, such as the importance of objects and visual consistency, are critical\nfor efficient game-play. Videos and the game manipulations are available at\nhttps://rach0012.github.io/humanRL_website/\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 00:26:44 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 20:32:21 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 02:33:41 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Dubey", "Rachit", ""], ["Agrawal", "Pulkit", ""], ["Pathak", "Deepak", ""], ["Griffiths", "Thomas L.", ""], ["Efros", "Alexei A.", ""]]}, {"id": "1802.10238", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Tyler J. Loftus, Lasith Adhikari, Tezcan\n  Ozrazgat-Baslanti, Azra Bihorac, and Parisa Rashidi", "title": "DeepSOFA: A Continuous Acuity Score for Critically Ill Patients using\n  Clinically Interpretable Deep Learning", "comments": null, "journal-ref": "Scientific Reports (2019) 9:1879", "doi": "10.1038/s41598-019-38491-0", "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for assessing illness severity and predicting in-hospital\nmortality among critically ill patients require time-consuming, error-prone\ncalculations using static variable thresholds. These methods do not capitalize\non the emerging availability of streaming electronic health record data or\ncapture time-sensitive individual physiological patterns, a critical task in\nthe intensive care unit. We propose a novel acuity score framework (DeepSOFA)\nthat leverages temporal measurements and interpretable deep learning models to\nassess illness severity at any point during an ICU stay. We compare DeepSOFA\nwith SOFA (Sequential Organ Failure Assessment) baseline models using the same\nmodel inputs and find that at any point during an ICU admission, DeepSOFA\nyields significantly more accurate predictions of in-hospital mortality. A\nDeepSOFA model developed in a public database and validated in a single\ninstitutional cohort had a mean AUC for the entire ICU stay of 0.90 (95% CI\n0.90-0.91) compared with baseline SOFA models with mean AUC 0.79 (95% CI\n0.79-0.80) and 0.85 (95% CI 0.85-0.86). Deep models are well-suited to identify\nICU patients in need of life-saving interventions prior to the occurrence of an\nunexpected adverse event and inform shared decision-making processes among\npatients, providers, and families regarding goals of care and optimal resource\nutilization.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 02:39:02 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 02:04:16 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 01:33:57 GMT"}, {"version": "v4", "created": "Wed, 13 Feb 2019 18:16:07 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Shickel", "Benjamin", ""], ["Loftus", "Tyler J.", ""], ["Adhikari", "Lasith", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1802.10269", "submitter": "Akansel Cosgun", "authors": "David Isele, Akansel Cosgun", "title": "Selective Experience Replay for Lifelong Learning", "comments": "Presented in 32nd Conference on Artificial Intelligence (AAAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has emerged as a powerful tool for a variety of\nlearning tasks, however deep nets typically exhibit forgetting when learning\nmultiple tasks in sequence. To mitigate forgetting, we propose an experience\nreplay process that augments the standard FIFO buffer and selectively stores\nexperiences in a long-term memory. We explore four strategies for selecting\nwhich experiences will be stored: favoring surprise, favoring reward, matching\nthe global training distribution, and maximizing coverage of the state space.\nWe show that distribution matching successfully prevents catastrophic\nforgetting, and is consistently the best approach on all domains tested. While\ndistribution matching has better and more consistent performance, we identify\none case in which coverage maximization is beneficial - when tasks that receive\nless trained are more important. Overall, our results show that selective\nexperience replay, when suitable selection algorithms are employed, can prevent\ncatastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 06:02:31 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Isele", "David", ""], ["Cosgun", "Akansel", ""]]}, {"id": "1802.10353", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Michael Chang, Klaus Greff, J\\\"urgen\n  Schmidhuber", "title": "Relational Neural Expectation Maximization: Unsupervised Discovery of\n  Objects and their Interactions", "comments": "Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Common-sense physical reasoning is an essential ingredient for any\nintelligent agent operating in the real-world. For example, it can be used to\nsimulate the environment, or to infer the state of parts of the world that are\ncurrently unobserved. In order to match real-world conditions this causal\nknowledge must be learned without access to supervised data. To address this\nproblem we present a novel method that learns to discover objects and model\ntheir physical interactions from raw visual images in a purely\n\\emph{unsupervised} fashion. It incorporates prior knowledge about the\ncompositional nature of human perception to factor interactions between\nobject-pairs and learn efficiently. On videos of bouncing balls we show the\nsuperior modelling capabilities of our method compared to other unsupervised\nneural approaches that do not incorporate such prior knowledge. We demonstrate\nits ability to handle occlusion and show that it can extrapolate learned\nknowledge to scenes with different numbers of objects.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 10:55:36 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Chang", "Michael", ""], ["Greff", "Klaus", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1802.10363", "submitter": "Jialin Liu Ph.D", "authors": "Diego Perez-Liebana, Jialin Liu, Ahmed Khalifa, Raluca D. Gaina,\n  Julian Togelius, Simon M. Lucas", "title": "General Video Game AI: a Multi-Track Framework for Evaluating Agents,\n  Games and Content Generation Algorithms", "comments": "20 pages, 1 figure, accepted by IEEE ToG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General Video Game Playing (GVGP) aims at designing an agent that is capable\nof playing multiple video games with no human intervention. In 2014, The\nGeneral Video Game AI (GVGAI) competition framework was created and released\nwith the purpose of providing researchers a common open-source and easy to use\nplatform for testing their AI methods with potentially infinity of games\ncreated using Video Game Description Language (VGDL). The framework has been\nexpanded into several tracks during the last few years to meet the demand of\ndifferent research directions. The agents are required either to play multiple\nunknown games with or without access to game simulations, or to design new game\nlevels or rules. This survey paper presents the VGDL, the GVGAI framework,\nexisting tracks, and reviews the wide use of GVGAI framework in research,\neducation and competitions five years after its birth. A future plan of\nframework improvements is also described.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 11:23:16 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 11:56:03 GMT"}, {"version": "v3", "created": "Wed, 26 Dec 2018 01:34:07 GMT"}, {"version": "v4", "created": "Fri, 22 Feb 2019 10:05:44 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Perez-Liebana", "Diego", ""], ["Liu", "Jialin", ""], ["Khalifa", "Ahmed", ""], ["Gaina", "Raluca D.", ""], ["Togelius", "Julian", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1802.10393", "submitter": "Guilherme Wachs-Lopes", "authors": "Henrique X. Goulart, Guilherme A. Wachs-Lopes", "title": "A Bayesian Model for Activities Recommendation and Event Structure\n  Optimization Using Visitors Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In events that are composed by many activities, there is a problem that\ninvolves retrieve and management the information of visitors that are visiting\nthe activities. This management is crucial to find some activities that are\ndrawing attention of visitors; identify an ideal positioning for activities;\nwhich path is more frequented by visitors. In this work, these features are\nstudied using Complex Network theory. For the beginning, an artificial database\nwas generated to study the mentioned features. Secondly, this work shows a\nmethod to optimize the event structure that is better than a random method and\na recommendation system that achieves ~95% of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 12:59:43 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Goulart", "Henrique X.", ""], ["Wachs-Lopes", "Guilherme A.", ""]]}, {"id": "1802.10446", "submitter": "Adam Derek Cobb", "authors": "Adam D. Cobb, Richard Everett, Andrew Markham, Stephen J. Roberts", "title": "Identifying Sources and Sinks in the Presence of Multiple Agents with\n  Gaussian Process Vector Calculus", "comments": "KDD '18 Proceedings of the 24th ACM SIGKDD International Conference\n  on Knowledge Discovery & Data Mining, Pages 1254-1262, 9 pages, 5 figures,\n  conference submission, University of Oxford. arXiv admin note: text overlap\n  with arXiv:1709.02357", "journal-ref": null, "doi": "10.1145/3219819.3220065", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems of multiple agents, identifying the cause of observed agent\ndynamics is challenging. Often, these agents operate in diverse, non-stationary\nenvironments, where models rely on hand-crafted environment-specific features\nto infer influential regions in the system's surroundings. To overcome the\nlimitations of these inflexible models, we present GP-LAPLACE, a technique for\nlocating sources and sinks from trajectories in time-varying fields. Using\nGaussian processes, we jointly infer a spatio-temporal vector field, as well as\ncanonical vector calculus operations on that field. Notably, we do this from\nonly agent trajectories without requiring knowledge of the environment, and\nalso obtain a metric for denoting the significance of inferred causal features\nin the environment by exploiting our probabilistic method. To evaluate our\napproach, we apply it to both synthetic and real-world GPS data, demonstrating\nthe applicability of our technique in the presence of multiple agents, as well\nas its superiority over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 21:14:46 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:13:01 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Cobb", "Adam D.", ""], ["Everett", "Richard", ""], ["Markham", "Andrew", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1802.10448", "submitter": "Massimiliano Sassoli de Bianchi", "authors": "Diederik Aerts, Massimiliano Sassoli de Bianchi, Sandro Sozzo and\n  Tomas Veloz", "title": "Quantum cognition goes beyond-quantum: modeling the collective\n  participant in psychological measurements", "comments": "19 pages, 1 figure", "journal-ref": "Probing the Meaning of Quantum Mechanics, World Scientific, pp.\n  355-382 (2019)", "doi": "10.1142/9789813276895_0017", "report-no": null, "categories": "q-bio.NC cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In psychological measurements, two levels should be distinguished: the\n'individual level', relative to the different participants in a given cognitive\nsituation, and the 'collective level', relative to the overall statistics of\ntheir outcomes, which we propose to associate with a notion of 'collective\nparticipant'. When the distinction between these two levels is properly\nformalized, it reveals why the modeling of the collective participant generally\nrequires beyond-quantum - non-Bornian - probabilistic models, when sequential\nmeasurements at the individual level are considered, and this though a pure\nquantum description remains valid for single measurement situations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 08:23:11 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Aerts", "Diederik", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1802.10463", "submitter": "Phaniteja S", "authors": "Parijat Dewangan, S Phaniteja, K Madhava Krishna, Abhishek Sarkar,\n  Balaraman Ravindran", "title": "DiGrad: Multi-Task Reinforcement Learning with Shared Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning algorithms are inefficient for learning multiple\ntasks in complex robotic systems, where different tasks share a set of actions.\nIn such environments a compound policy may be learnt with shared neural network\nparameters, which performs multiple tasks concurrently. However such compound\npolicy may get biased towards a task or the gradients from different tasks\nnegate each other, making the learning unstable and sometimes less data\nefficient. In this paper, we propose a new approach for simultaneous training\nof multiple tasks sharing a set of common actions in continuous action spaces,\nwhich we call as DiGrad (Differential Policy Gradient). The proposed framework\nis based on differential policy gradients and can accommodate multi-task\nlearning in a single actor-critic network. We also propose a simple heuristic\nin the differential policy gradient update to further improve the learning. The\nproposed architecture was tested on 8 link planar manipulator and 27 degrees of\nfreedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2\nend effectors respectively. We show that our approach supports efficient\nmulti-task learning in complex robotic systems, outperforming related methods\nin continuous action spaces.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 10:26:08 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Dewangan", "Parijat", ""], ["Phaniteja", "S", ""], ["Krishna", "K Madhava", ""], ["Sarkar", "Abhishek", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1802.10495", "submitter": "Yu-Siang Huang", "authors": "Yu-Siang Huang, Szu-Yu Chou, Yi-Hsuan Yang", "title": "Pop Music Highlighter: Marking the Emotion Keypoints", "comments": "Transactions of the ISMIR vol. 1, no. 1", "journal-ref": null, "doi": "10.5334/tismir.14", "report-no": null, "categories": "eess.AS cs.AI cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of music highlight extraction is to get a short consecutive segment\nof a piece of music that provides an effective representation of the whole\npiece. In a previous work, we introduced an attention-based convolutional\nrecurrent neural network that uses music emotion classification as a surrogate\ntask for music highlight extraction, for Pop songs. The rationale behind that\napproach is that the highlight of a song is usually the most emotional part.\nThis paper extends our previous work in the following two aspects. First,\nmethodology-wise we experiment with a new architecture that does not need any\nrecurrent layers, making the training process faster. Moreover, we compare a\nlate-fusion variant and an early-fusion variant to study which one better\nexploits the attention mechanism. Second, we conduct and report an extensive\nset of experiments comparing the proposed attention-based methods against a\nheuristic energy-based method, a structural repetition-based method, and a few\nother simple feature-based methods for this task. Due to the lack of\npublic-domain labeled data for highlight extraction, following our previous\nwork we use the RWC POP 100-song data set to evaluate how the detected\nhighlights overlap with any chorus sections of the songs. The experiments\ndemonstrate the effectiveness of our methods over competing methods. For\nreproducibility, we open source the code and pre-trained model at\nhttps://github.com/remyhuang/pop-music-highlighter/.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:02:47 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 18:34:47 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Huang", "Yu-Siang", ""], ["Chou", "Szu-Yu", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1802.10503", "submitter": "Paul Schydlo", "authors": "Paul Schydlo, Mirko Rakovic, Lorenzo Jamone and Jos\\'e Santos-Victor", "title": "Anticipation in Human-Robot Cooperation: A Recurrent Neural Network\n  Approach for Multiple Action Sequences Prediction", "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2018,\n  Accepted", "journal-ref": null, "doi": "10.1109/ICRA.2018.8460924", "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Close human-robot cooperation is a key enabler for new developments in\nadvanced manufacturing and assistive applications. Close cooperation require\nrobots that can predict human actions and intent, and understand human\nnon-verbal cues. Recent approaches based on neural networks have led to\nencouraging results in the human action prediction problem both in continuous\nand discrete spaces. Our approach extends the research in this direction. Our\ncontributions are three-fold. First, we validate the use of gaze and body pose\ncues as a means of predicting human action through a feature selection method.\nNext, we address two shortcomings of existing literature: predicting multiple\nand variable-length action sequences. This is achieved by introducing an\nencoder-decoder recurrent neural network topology in the discrete action\nprediction problem. In addition, we theoretically demonstrate the importance of\npredicting multiple action sequences as a means of estimating the stochastic\nreward in a human robot cooperation scenario. Finally, we show the ability to\neffectively train the prediction model on a action prediction dataset,\ninvolving human motion data, and explore the influence of the model's\nparameters on its performance. Source code repository:\nhttps://github.com/pschydlo/ActionAnticipation\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 16:10:20 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 23:54:08 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 10:37:01 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Schydlo", "Paul", ""], ["Rakovic", "Mirko", ""], ["Jamone", "Lorenzo", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1802.10546", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer", "title": "Computational Theories of Curiosity-Driven Learning", "comments": "To appear in \"The New Science of Curiosity\", ed. G. Gordon, Nova\n  Science Publishers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the functions of curiosity? What are the mechanisms of\ncuriosity-driven learning? We approach these questions about the living using\nconcepts and tools from machine learning and developmental robotics. We argue\nthat curiosity-driven learning enables organisms to make discoveries to solve\ncomplex problems with rare or deceptive rewards. By fostering exploration and\ndiscovery of a diversity of behavioural skills, and ignoring these rewards,\ncuriosity can be efficient to bootstrap learning when there is no information,\nor deceptive information, about local improvement towards these problems. We\nalso explain the key role of curiosity for efficient learning of world models.\nWe review both normative and heuristic computational frameworks used to\nunderstand the mechanisms of curiosity in humans, conceptualizing the child as\na sense-making organism. These frameworks enable us to discuss the\nbi-directional causal links between curiosity and learning, and to provide new\nhypotheses about the fundamental role of curiosity in self-organizing\ndevelopmental structures through curriculum learning. We present various\ndevelopmental robotics experiments that study these mechanisms in action, both\nsupporting these hypotheses to understand better curiosity in humans and\nopening new research avenues in machine learning and artificial intelligence.\nFinally, we discuss challenges for the design of experimental paradigms for\nstudying curiosity in psychology and cognitive neuroscience.\n  Keywords: Curiosity, intrinsic motivation, lifelong learning, predictions,\nworld model, rewards, free-energy principle, learning progress, machine\nlearning, AI, developmental robotics, development, curriculum learning,\nself-organization.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:28:25 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 10:29:41 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1802.10592", "submitter": "Thanard Kurutach", "authors": "Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, and Pieter\n  Abbeel", "title": "Model-Ensemble Trust-Region Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) methods are succeeding in a growing\nnumber of tasks, aided by recent advances in deep learning. However, they tend\nto suffer from high sample complexity, which hinders their use in real-world\ndomains. Alternatively, model-based reinforcement learning promises to reduce\nsample complexity, but tends to require careful tuning and to date have\nsucceeded mainly in restrictive domains where simple models are sufficient for\nlearning. In this paper, we analyze the behavior of vanilla model-based\nreinforcement learning methods when deep neural networks are used to learn both\nthe model and the policy, and show that the learned policy tends to exploit\nregions where insufficient data is available for the model to be learned,\ncausing instability in training. To overcome this issue, we propose to use an\nensemble of models to maintain the model uncertainty and regularize the\nlearning process. We further show that the use of likelihood ratio derivatives\nyields much more stable learning than backpropagation through time. Altogether,\nour approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO)\nsignificantly reduces the sample complexity compared to model-free deep RL\nmethods on challenging continuous control benchmark tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:58:22 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2018 05:08:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Kurutach", "Thanard", ""], ["Clavera", "Ignasi", ""], ["Duan", "Yan", ""], ["Tamar", "Aviv", ""], ["Abbeel", "Pieter", ""]]}]