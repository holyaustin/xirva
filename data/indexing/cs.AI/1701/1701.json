[{"id": "1701.00001", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Digital Advertising Traffic Operation: Machine Learning for Process\n  Discovery", "comments": "6 pages; for details see: this http://www.maxdalmas.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Web Advertising Traffic Operation it's necessary to manage the\nday-to-day trafficking, pacing and optimization of digital and paid social\ncampaigns. The data analyst on Traffic Operation can not only quickly provide\nanswers but also speaks the language of the Process Manager and visually\ndisplays the discovered process problems. In order to solve a growing number of\ncomplaints in the customer service process, the weaknesses in the process\nitself must be identified and communicated to the department. With the help of\nProcess Mining for the CRM data it is possible to identify unwanted loops and\ndelays in the process. With this paper we propose a process discovery based on\nMachine Learning technique to automatically discover variations and detect at\nfirst glance what the problem is, and undertake corrective measures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 21:04:22 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}, {"id": "1701.00016", "submitter": "Jeremy Kepner", "authors": "Connor Sell, Jeremy Kepner", "title": "Non-Negative Matrix Factorization Test Cases", "comments": "4 pages, 3 figures, to appear in the proceedings of the 2015 IEEE MIT\n  Undergraduate Research Conference", "journal-ref": null, "doi": "10.1109/URTC.2016.8284085", "report-no": null, "categories": "math.NA cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a prob- lem with many\napplications, ranging from facial recognition to document clustering. However,\ndue to the variety of algorithms that solve NMF, the randomness involved in\nthese algorithms, and the somewhat subjective nature of the problem, there is\nno clear \"correct answer\" to any particular NMF problem, and as a result, it\ncan be hard to test new algorithms. This paper suggests some test cases for NMF\nalgorithms derived from matrices with enumerable exact non-negative\nfactorizations and perturbations of these matrices. Three algorithms using\nwidely divergent approaches to NMF all give similar solutions over these test\ncases, suggesting that these test cases could be used as test cases for\nimplementations of these existing NMF algorithms as well as potentially new NMF\nalgorithms. This paper also describes how the proposed test cases could be used\nin practice.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 21:18:01 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sell", "Connor", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1701.00077", "submitter": "Pietro  Hiram Guzzi", "authors": "Pietro Hiram Guzzi, Giuseppe Agapito, Marianna Milano, Mario Cannataro", "title": "Learning Weighted Association Rules in Human Phenotype Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Human Phenotype Ontology (HPO) is a structured repository of concepts\n(HPO Terms) that are associated to one or more diseases. The process of\nassociation is referred to as annotation. The relevance and the specificity of\nboth HPO terms and annotations are evaluated by a measure defined as\nInformation Content (IC). The analysis of annotated data is thus an important\nchallenge for bioinformatics. There exist different approaches of analysis.\nFrom those, the use of Association Rules (AR) may provide useful knowledge, and\nit has been used in some applications, e.g. improving the quality of\nannotations. Nevertheless classical association rules algorithms do not take\ninto account the source of annotation nor the importance yielding to the\ngeneration of candidate rules with low IC. This paper presents HPO-Miner (Human\nPhenotype Ontology-based Weighted Association Rules) a methodology for\nextracting Weighted Association Rules. HPO-Miner can extract relevant rules\nfrom a biological point of view. A case study on using of HPO-Miner on publicly\navailable HPO annotation datasets is used to demonstrate the effectiveness of\nour methodology.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 09:19:52 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Guzzi", "Pietro Hiram", ""], ["Agapito", "Giuseppe", ""], ["Milano", "Marianna", ""], ["Cannataro", "Mario", ""]]}, {"id": "1701.00138", "submitter": "Jun Suzuki", "authors": "Jun Suzuki, Masaaki Nagata", "title": "Cutting-off Redundant Repeating Generations for Neural Abstractive\n  Summarization", "comments": "7 pages, a draft version of EACL-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the reduction of redundant repeating generation that is\noften observed in RNN-based encoder-decoder models. Our basic idea is to\njointly estimate the upper-bound frequency of each target vocabulary in the\nencoder and control the output words based on the estimation in the decoder.\nOur method shows significant improvement over a strong RNN-based\nencoder-decoder baseline and achieved its best results on an abstractive\nsummarization benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 16:41:43 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 23:40:09 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Suzuki", "Jun", ""], ["Nagata", "Masaaki", ""]]}, {"id": "1701.00178", "submitter": "Jan-Peter Calliess", "authors": "Jan-Peter Calliess", "title": "Lazily Adapted Constant Kinky Inference for Nonparametric Regression and\n  Model-Reference Adaptive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques known as Nonlinear Set Membership prediction, Lipschitz\nInterpolation or Kinky Inference are approaches to machine learning that\nutilise presupposed Lipschitz properties to compute inferences over unobserved\nfunction values. Provided a bound on the true best Lipschitz constant of the\ntarget function is known a priori they offer convergence guarantees as well as\nbounds around the predictions. Considering a more general setting that builds\non Hoelder continuity relative to pseudo-metrics, we propose an online method\nfor estimating the Hoelder constant online from function value observations\nthat possibly are corrupted by bounded observational errors. Utilising this to\ncompute adaptive parameters within a kinky inference rule gives rise to a\nnonparametric machine learning method, for which we establish strong universal\napproximation guarantees. That is, we show that our prediction rule can learn\nany continuous function in the limit of increasingly dense data to within a\nworst-case error bound that depends on the level of observational uncertainty.\nWe apply our method in the context of nonparametric model-reference adaptive\ncontrol (MRAC). Across a range of simulated aircraft roll-dynamics and\nperformance metrics our approach outperforms recently proposed alternatives\nthat were based on Gaussian processes and RBF-neural networks. For\ndiscrete-time systems, we provide guarantees on the tracking success of our\nlearning-based controllers both for the batch and the online learning setting.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 23:25:59 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 15:36:08 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 20:14:45 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Calliess", "Jan-Peter", ""]]}, {"id": "1701.00287", "submitter": "Caelan Garrett", "authors": "Caelan Reed Garrett, Tom\\'as Lozano-P\\'erez, and Leslie Pack Kaelbling", "title": "STRIPS Planning in Infinite Domains", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotic planning applications involve continuous actions with highly\nnon-linear constraints, which cannot be modeled using modern planners that\nconstruct a propositional representation. We introduce STRIPStream: an\nextension of the STRIPS language which can model these domains by supporting\nthe specification of blackbox generators to handle complex constraints. The\noutputs of these generators interact with actions through possibly infinite\nstreams of objects and static predicates. We provide two algorithms which both\nreduce STRIPStream problems to a sequence of finite-domain planning problems.\nThe representation and algorithms are entirely domain independent. We\ndemonstrate our framework on simple illustrative domains, and then on a\nhigh-dimensional, continuous robotic task and motion planning domain.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2017 20:37:51 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 01:08:00 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Garrett", "Caelan Reed", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1701.00349", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra", "title": "An affective computational model for machine consciousness", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past, several models of consciousness have become popular and have led\nto the development of models for machine consciousness with varying degrees of\nsuccess and challenges for simulation and implementations. Moreover, affective\ncomputing attributes that involve emotions, behavior and personality have not\nbeen the focus of models of consciousness as they lacked motivation for\ndeployment in software applications and robots. The affective attributes are\nimportant factors for the future of machine consciousness with the rise of\ntechnologies that can assist humans. Personality and affection hence can give\nan additional flavor for the computational model of consciousness in humanoid\nrobotics. Recent advances in areas of machine learning with a focus on deep\nlearning can further help in developing aspects of machine consciousness in\nareas that can better replicate human sensory perceptions such as speech\nrecognition and vision. With such advancements, one encounters further\nchallenges in developing models that can synchronize different aspects of\naffective computing. In this paper, we review some existing models of\nconsciousnesses and present an affective computational model that would enable\nthe human touch and feel for robotic systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 09:48:47 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Chandra", "Rohitash", ""]]}, {"id": "1701.00464", "submitter": "Antonio Lieto", "authors": "Antonio Lieto, Antonio Chella, Marcello Frixione", "title": "Conceptual Spaces for Cognitive Architectures: A Lingua Franca for\n  Different Levels of Representation", "comments": "31 pages, 3 figures in Biologically Inspired Cognitive Architectures,\n  2017", "journal-ref": null, "doi": "10.1016/j.bica.2016.10.005", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, many cognitive architectures (CAs) have been\nrealized adopting different assumptions about the organization and the\nrepresentation of their knowledge level. Some of them (e.g. SOAR [Laird\n(2012)]) adopt a classical symbolic approach, some (e.g. LEABRA [O'Reilly and\nMunakata (2000)]) are based on a purely connectionist model, while others (e.g.\nCLARION [Sun (2006)] adopt a hybrid approach combining connectionist and\nsymbolic representational levels. Additionally, some attempts (e.g. biSOAR)\ntrying to extend the representational capacities of CAs by integrating\ndiagrammatical representations and reasoning are also available [Kurup and\nChandrasekaran (2007)]. In this paper we propose a reflection on the role that\nConceptual Spaces, a framework developed by Peter G\u007f\\\"ardenfors [G\u007f\\\"ardenfors\n(2000)] more than fifteen years ago, can play in the current development of the\nKnowledge Level in Cognitive Systems and Architectures. In particular, we claim\nthat Conceptual Spaces offer a lingua franca that allows to unify and\ngeneralize many aspects of the symbolic, sub-symbolic and diagrammatic\napproaches (by overcoming some of their typical problems) and to integrate them\non a common ground. In doing so we extend and detail some of the arguments\nexplored by G\u007f\\\"ardenfors [G\u007f\\\"ardenfors (1997)] for defending the need of a\nconceptual, intermediate, representation level between the symbolic and the\nsub-symbolic one.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 17:35:34 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Lieto", "Antonio", ""], ["Chella", "Antonio", ""], ["Frixione", "Marcello", ""]]}, {"id": "1701.00529", "submitter": "Iddan Golomb", "authors": "Iddan Golomb and Christos Tzamos", "title": "Truthful Facility Location with Additive Errors", "comments": "16 pages (3 of which are in the appendix), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of locating facilities on the $[0,1]$ interval based\non reports from strategic agents. The cost of each agent is her distance to the\nclosest facility, and the global objective is to minimize either the maximum\ncost of an agent or the social cost.\n  As opposed to the extensive literature on facility location which considers\nthe multiplicative error, we focus on minimizing the worst-case additive error.\nMinimizing the additive error incentivizes mechanisms to adapt to the size of\nthe instance. I.e., mechanisms can sacrifice little efficiency in small\ninstances (location profiles in which all agents are relatively close to one\nanother), in order to gain more [absolute] efficiency in large instances. We\nargue that this measure is better suited for many manifestations of the\nfacility location problem in various domains.\n  We present tight bounds for mechanisms locating a single facility in both\ndeterministic and randomized cases. We further provide several extensions for\nlocating multiple facilities.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jan 2017 21:26:03 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Golomb", "Iddan", ""], ["Tzamos", "Christos", ""]]}, {"id": "1701.00622", "submitter": "EPTCS", "authors": "Dietmar Seipel (University of W\\\"urzburg)", "title": "Knowledge Engineering for Hybrid Deductive Databases", "comments": "In Proceedings WLP'15/'16/WFLP'16, arXiv:1701.00148", "journal-ref": "EPTCS 234, 2017, pp. 1-12", "doi": "10.4204/EPTCS.234.1", "report-no": null, "categories": "cs.DB cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern knowledge base systems frequently need to combine a collection of\ndatabases in different formats: e.g., relational databases, XML databases, rule\nbases, ontologies, etc. In the deductive database system DDBASE, we can manage\nthese different formats of knowledge and reason about them. Even the file\nsystems on different computers can be part of the knowledge base. Often, it is\nnecessary to handle different versions of a knowledge base. E.g., we might want\nto find out common parts or differences of two versions of a relational\ndatabase.\n  We will examine the use of abstractions of rule bases by predicate dependency\nand rule predicate graphs. Also the proof trees of derived atoms can help to\ncompare different versions of a rule base. Moreover, it might be possible to\nhave derivations joining rules with other formalisms of knowledge\nrepresentation.\n  Ontologies have shown their benefits in many applications of intelligent\nsystems, and there have been many proposals for rule languages compatible with\nthe semantic web stack, e.g., SWRL, the semantic web rule language. Recently,\nontologies are used in hybrid systems for specifying the provenance of the\ndifferent components.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 10:30:37 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Seipel", "Dietmar", "", "University of W\u00fcrzburg"]]}, {"id": "1701.00642", "submitter": "Paul Weng", "authors": "Dajian Li and Paul Weng and Orkun Karabasoglu", "title": "Finding Risk-Averse Shortest Path with Time-dependent Stochastic Costs", "comments": "accepted at MIWAI 2017", "journal-ref": null, "doi": "10.1007/978-3-319-49397-8_9", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of risk-averse route planning in a\ntransportation network with time-dependent and stochastic costs. To solve this\nproblem, we propose an adaptation of the A* algorithm that accommodates any\nrisk measure or decision criterion that is monotonic with first-order\nstochastic dominance. We also present a case study of our algorithm on the\nManhattan, NYC, transportation network.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 10:47:35 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Li", "Dajian", ""], ["Weng", "Paul", ""], ["Karabasoglu", "Orkun", ""]]}, {"id": "1701.00646", "submitter": "Paul Weng", "authors": "Paul Weng", "title": "From Preference-Based to Multiobjective Sequential Decision-Making", "comments": "accepted at MIWAI 2017", "journal-ref": null, "doi": "10.1007/978-3-319-49397-8_20", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a link between preference-based and multiobjective\nsequential decision-making. While transforming a multiobjective problem to a\npreference-based one is quite natural, the other direction is a bit less\nobvious. We present how this transformation (from preference-based to\nmultiobjective) can be done under the classic condition that preferences over\nhistories can be represented by additively decomposable utilities and that the\ndecision criterion to evaluate policies in a state is based on expectation.\nThis link yields a new source of multiobjective sequential decision-making\nproblems (i.e., when reward values are unknown) and justifies the use of\nsolving methods developed in one setting in the other one.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 10:57:06 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Weng", "Paul", ""]]}, {"id": "1701.00696", "submitter": "Karl Schlechta", "authors": "Karl Schlechta (LIF)", "title": "A pre-semantics for counterfactual conditionals and similar logics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The elegant Stalnaker/Lewis semantics for counterfactual conditonals works\nwith distances between models. But human beings certainly have no tables of\nmodels and distances in their head. We begin here an investigation using a more\nrealistic picture, based on findings in neuroscience. We call it a\npre-semantics, as its meaning is not a description of the world, but of the\nbrain, whose structure is (partly) determined by the world it reasons about. In\nthe final section, we reconsider the components, and postulate that there are\nno atomic pictures, we can always look inside.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 15:29:16 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 13:57:03 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 14:42:28 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Schlechta", "Karl", "", "LIF"]]}, {"id": "1701.00736", "submitter": "Hossein Hosseini", "authors": "S. Hossein Hosseini, Tohid Nouri, Afshin Ebrahimi, S. Ali Hosseini", "title": "Simulated Tornado Optimization", "comments": "6 pages, 15 figures, 1 table, IEEE International Conference on Signal\n  Processing and Intelligent System (ICSPIS16), Dec. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a swarm-based optimization algorithm inspired by air currents of a\ntornado. Two main air currents - spiral and updraft - are mimicked. Spiral\nmotion is designed for exploration of new search areas and updraft movements is\ndeployed for exploitation of a promising candidate solution. Assignment of just\none search direction to each particle at each iteration, leads to low\ncomputational complexity of the proposed algorithm respect to the conventional\nalgorithms. Regardless of the step size parameters, the only parameter of the\nproposed algorithm, called tornado diameter, can be efficiently adjusted by\nrandomization. Numerical results over six different benchmark cost functions\nindicate comparable and, in some cases, better performance of the proposed\nalgorithm respect to some other metaheuristics.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2016 11:28:23 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Hosseini", "S. Hossein", ""], ["Nouri", "Tohid", ""], ["Ebrahimi", "Afshin", ""], ["Hosseini", "S. Ali", ""]]}, {"id": "1701.00833", "submitter": "Tshilidzi Marwala", "authors": "I. Boulkaibet, T. Marwala, M.I. Friswell, H. Haddad Khodaparast and S.\n  Adhikari", "title": "Fuzzy finite element model updating using metaheuristic optimization\n  algorithms", "comments": "This article was accepted by the 2017 International Modal Analysis\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a non-probabilistic method based on fuzzy logic is used to\nupdate finite element models (FEMs). Model updating techniques use the measured\ndata to improve the accuracy of numerical models of structures. However, the\nmeasured data are contaminated with experimental noise and the models are\ninaccurate due to randomness in the parameters. This kind of aleatory\nuncertainty is irreducible, and may decrease the accuracy of the finite element\nmodel updating process. However, uncertainty quantification methods can be used\nto identify the uncertainty in the updating parameters. In this paper, the\nuncertainties associated with the modal parameters are defined as fuzzy\nmembership functions, while the model updating procedure is defined as an\noptimization problem at each {\\alpha}-cut level. To determine the membership\nfunctions of the updated parameters, an objective function is defined and\nminimized using two metaheuristic optimization algorithms: ant colony\noptimization (ACO) and particle swarm optimization (PSO). A structural example\nis used to investigate the accuracy of the fuzzy model updating strategy using\nthe PSO and ACO algorithms. Furthermore, the results obtained by the fuzzy\nfinite element model updating are compared with the Bayesian model updating\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 20:58:55 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Boulkaibet", "I.", ""], ["Marwala", "T.", ""], ["Friswell", "M. I.", ""], ["Khodaparast", "H. Haddad", ""], ["Adhikari", "S.", ""]]}, {"id": "1701.00867", "submitter": "Abhishek Mishra", "authors": "Nithyanand Kota, Abhishek Mishra, Sunil Srinivasa, Xi (Peter) Chen,\n  Pieter Abbeel", "title": "A K-fold Method for Baseline Estimation in Policy Gradient Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high variance issue in unbiased policy-gradient methods such as VPG and\nREINFORCE is typically mitigated by adding a baseline. However, the baseline\nfitting itself suffers from the underfitting or the overfitting problem. In\nthis paper, we develop a K-fold method for baseline estimation in policy\ngradient algorithms. The parameter K is the baseline estimation hyperparameter\nthat can adjust the bias-variance trade-off in the baseline estimates. We\ndemonstrate the usefulness of our approach via two state-of-the-art policy\ngradient algorithms on three MuJoCo locomotive control tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2017 23:29:04 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Kota", "Nithyanand", "", "Peter"], ["Mishra", "Abhishek", "", "Peter"], ["Srinivasa", "Sunil", "", "Peter"], ["Xi", "", "", "Peter"], ["Chen", "", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1701.00877", "submitter": "Tom Hanika", "authors": "Daniel Borchmann, Tom Hanika, Sergei Obiedkov", "title": "On the Usability of Probably Approximately Correct Implication Bases", "comments": "17 pages, 8 figures; typos added, corrected x-label on graphs", "journal-ref": null, "doi": "10.1007/978-3-319-59271-8_5", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the notion of probably approximately correct implication bases\nfrom the literature and present a first formulation in the language of formal\nconcept analysis, with the goal to investigate whether such bases represent a\nsuitable substitute for exact implication bases in practical use-cases. To this\nend, we quantitatively examine the behavior of probably approximately correct\nimplication bases on artificial and real-world data sets and compare their\nprecision and recall with respect to their corresponding exact implication\nbases. Using a small example, we also provide qualitative insight that\nimplications from probably approximately correct bases can still represent\nmeaningful knowledge from a given data set.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 00:45:37 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2017 23:39:05 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Borchmann", "Daniel", ""], ["Hanika", "Tom", ""], ["Obiedkov", "Sergei", ""]]}, {"id": "1701.01048", "submitter": "Roni Khardon", "authors": "Roni Khardon and Scott Sanner", "title": "Stochastic Planning and Lifted Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted probabilistic inference (Poole, 2003) and symbolic dynamic programming\nfor lifted stochastic planning (Boutilier et al, 2001) were introduced around\nthe same time as algorithmic efforts to use abstraction in stochastic systems.\nOver the years, these ideas evolved into two distinct lines of research, each\nsupported by a rich literature. Lifted probabilistic inference focused on\nefficient arithmetic operations on template-based graphical models under a\nfinite domain assumption while symbolic dynamic programming focused on\nsupporting sequential decision-making in rich quantified logical action models\nand on open domain reasoning. Given their common motivation but different focal\npoints, both lines of research have yielded highly complementary innovations.\nIn this chapter, we aim to help close the gap between these two research areas\nby providing an overview of lifted stochastic planning from the perspective of\nprobabilistic inference, showing strong connections to other chapters in this\nbook. This also allows us to define Generalized Lifted Inference as a paradigm\nthat unifies these areas and elucidates open problems for future research that\ncan benefit both lifted inference and stochastic planning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 15:37:29 GMT"}], "update_date": "2017-01-05", "authors_parsed": [["Khardon", "Roni", ""], ["Sanner", "Scott", ""]]}, {"id": "1701.01272", "submitter": "Weishan Dong", "authors": "Weishan Dong, Ting Yuan, Kai Yang, Changsheng Li, Shilei Zhang", "title": "Autoencoder Regularized Network For Driving Style Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study learning generalized driving style representations\nfrom automobile GPS trip data. We propose a novel Autoencoder Regularized deep\nneural Network (ARNet) and a trip encoding framework trip2vec to learn drivers'\ndriving styles directly from GPS records, by combining supervised and\nunsupervised feature learning in a unified architecture. Experiments on a\nchallenging driver number estimation problem and the driver identification\nproblem show that ARNet can learn a good generalized driving style\nrepresentation: It significantly outperforms existing methods and alternative\narchitectures by reaching the least estimation error on average (0.68, less\nthan one driver) and the highest identification accuracy (by at least 3%\nimprovement) compared with traditional supervised learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 10:38:07 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Dong", "Weishan", ""], ["Yuan", "Ting", ""], ["Yang", "Kai", ""], ["Li", "Changsheng", ""], ["Zhang", "Shilei", ""]]}, {"id": "1701.01302", "submitter": "Andrew Critch PhD", "authors": "Andrew Critch", "title": "Toward negotiable reinforcement learning: shifting priorities in Pareto\n  optimal sequential decision-making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-objective reinforcement learning (MORL) algorithms do not\naccount for objectives that arise from players with differing beliefs.\nConcretely, consider two players with different beliefs and utility functions\nwho may cooperate to build a machine that takes actions on their behalf. A\nrepresentation is needed for how much the machine's policy will prioritize each\nplayer's interests over time. Assuming the players have reached common\nknowledge of their situation, this paper derives a recursion that any Pareto\noptimal policy must satisfy. Two qualitative observations can be made from the\nrecursion: the machine must (1) use each player's own beliefs in evaluating how\nwell an action will serve that player's utility function, and (2) shift the\nrelative priority it assigns to each player's expected utilities over time, by\na factor proportional to how well that player's beliefs predict the machine's\ninputs. Observation (2) represents a substantial divergence from na\\\"{i}ve\nlinear utility aggregation (as in Harsanyi's utilitarian theorem, and existing\nMORL algorithms), which is shown here to be inadequate for Pareto optimal\nsequential decision-making on behalf of players with different beliefs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 13:00:05 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 16:06:30 GMT"}, {"version": "v3", "created": "Sat, 13 May 2017 08:33:46 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Critch", "Andrew", ""]]}, {"id": "1701.01329", "submitter": "Marwin Segler", "authors": "Marwin H.S. Segler, Thierry Kogej, Christian Tyrchan, Mark P. Waller", "title": "Generating Focussed Molecule Libraries for Drug Discovery with Recurrent\n  Neural Networks", "comments": "17 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In de novo drug design, computational strategies are used to generate novel\nmolecules with good affinity to the desired biological target. In this work, we\nshow that recurrent neural networks can be trained as generative models for\nmolecular structures, similar to statistical language models in natural\nlanguage processing. We demonstrate that the properties of the generated\nmolecules correlate very well with the properties of the molecules used to\ntrain the model. In order to enrich libraries with molecules active towards a\ngiven biological target, we propose to fine-tune the model with small sets of\nmolecules, which are known to be active against that target.\n  Against Staphylococcus aureus, the model reproduced 14% of 6051 hold-out test\nmolecules that medicinal chemists designed, whereas against Plasmodium\nfalciparum (Malaria) it reproduced 28% of 1240 test molecules. When coupled\nwith a scoring function, our model can perform the complete de novo drug design\ncycle to generate large sets of novel molecules for drug discovery.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 14:28:34 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Segler", "Marwin H. S.", ""], ["Kogej", "Thierry", ""], ["Tyrchan", "Christian", ""], ["Waller", "Mark P.", ""]]}, {"id": "1701.01461", "submitter": "Florent Capelli", "authors": "Florent Capelli", "title": "Understanding the complexity of #SAT using knowledge compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main techniques have been used so far to solve the #P-hard problem #SAT.\nThe first one, used in practice, is based on an extension of DPLL for model\ncounting called exhaustive DPLL. The second approach, more theoretical,\nexploits the structure of the input to compute the number of satisfying\nassignments by usually using a dynamic programming scheme on a decomposition of\nthe formula. In this paper, we make a first step toward the separation of these\ntwo techniques by exhibiting a family of formulas that can be solved in\npolynomial time with the first technique but needs an exponential time with the\nsecond one. We show this by observing that both techniques implicitely\nconstruct a very specific boolean circuit equivalent to the input formula. We\nthen show that every beta-acyclic formula can be represented by a polynomial\nsize circuit corresponding to the first method and exhibit a family of\nbeta-acyclic formulas which cannot be represented by polynomial size circuits\ncorresponding to the second method. This result shed a new light on the\ncomplexity of #SAT and related problems on beta-acyclic formulas. As a\nbyproduct, we give new handy tools to design algorithms on beta-acyclic\nhypergraphs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 19:48:01 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Capelli", "Florent", ""]]}, {"id": "1701.01487", "submitter": "Mark Muraven", "authors": "Mark Muraven", "title": "Designing a Safe Autonomous Artificial Intelligence Agent based on Human\n  Self-Regulation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing focus on how to design safe artificial intelligent (AI)\nagents. As systems become more complex, poorly specified goals or control\nmechanisms may cause AI agents to engage in unwanted and harmful outcomes. Thus\nit is necessary to design AI agents that follow initial programming intentions\nas the program grows in complexity. How to specify these initial intentions has\nalso been an obstacle to designing safe AI agents. Finally, there is a need for\nthe AI agent to have redundant safety mechanisms to ensure that any programming\nerrors do not cascade into major problems. Humans are autonomous intelligent\nagents that have avoided these problems and the present manuscript argues that\nby understanding human self-regulation and goal setting, we may be better able\nto design safe AI agents. Some general principles of human self-regulation are\noutlined and specific guidance for AI design is given.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 21:41:08 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Muraven", "Mark", ""]]}, {"id": "1701.01497", "submitter": "Joris Gu\\'erin", "authors": "Joris Guerin, Olivier Gibaru, Eric Nyiri and Stephane Thiery", "title": "Learning local trajectories for high precision robotic tasks :\n  application to KUKA LBR iiwa Cartesian positioning", "comments": "6 pages, double column, 6 figures and one table. Published in:\n  Industrial Electronics Society , IECON 2016 - 42nd Annual Conference of the\n  IEEE", "journal-ref": "Industrial Electronics Society, IECON 2016-42nd Annual Conference\n  of the IEEE Pages 5316--5321", "doi": "10.1109/IECON.2016.7793388", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ease the development of robot learning in industry, two conditions need to\nbe fulfilled. Manipulators must be able to learn high accuracy and precision\ntasks while being safe for workers in the factory. In this paper, we extend\npreviously submitted work which consists in rapid learning of local high\naccuracy behaviors. By exploration and regression, linear and quadratic models\nare learnt for respectively the dynamics and cost function. Iterative Linear\nQuadratic Gaussian Regulator combined with cost quadratic regression can\nconverge rapidly in the final stages towards high accuracy behavior as the cost\nfunction is modelled quite precisely. In this paper, both a different cost\nfunction and a second order improvement method are implemented within this\nframework. We also propose an analysis of the algorithm parameters through\nsimulation for a positioning task. Finally, an experimental validation on a\nKUKA LBR iiwa robot is carried out. This collaborative robot manipulator can be\neasily programmed into safety mode, which makes it qualified for the second\nindustry constraint stated above.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 23:01:08 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Guerin", "Joris", ""], ["Gibaru", "Olivier", ""], ["Nyiri", "Eric", ""], ["Thiery", "Stephane", ""]]}, {"id": "1701.01654", "submitter": "Rao Farhat Masood", "authors": "Rao Farhat Masood", "title": "Application of Fuzzy Logic in Design of Smart Washing Machine", "comments": "Fuzzy Washing Machine, Smart Washing Machine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Washing machine is of great domestic necessity as it frees us from the burden\nof washing our clothes and saves ample of our time. This paper will cover the\naspect of designing and developing of Fuzzy Logic based, Smart Washing Machine.\nThe regular washing machine (timer based) makes use of multi-turned timer based\nstart-stop mechanism which is mechanical as is prone to breakage. In addition\nto its starting and stopping issues, the mechanical timers are not efficient\nwith respect of maintenance and electricity usage. Recent developments have\nshown that merger of digital electronics in optimal functionality of this\nmachine is possible and nowadays in practice. A number of international\nrenowned companies have developed the machine with the introduction of smart\nartificial intelligence. Such a machine makes use of sensors and smartly\ncalculates the amount of run-time (washing time) for the main machine motor.\nRealtime calculations and processes are also catered in optimizing the run-time\nof the machine. The obvious result is smart time management, better economy of\nelectricity and efficiency of work. This paper deals with the indigenization of\nFLC (Fuzzy Logic Controller) based Washing Machine, which is capable of\nautomating the inputs and getting the desired output (wash-time).\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 08:41:07 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 06:46:55 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Masood", "Rao Farhat", ""]]}, {"id": "1701.01675", "submitter": "Ali Nassif", "authors": "Mohammad Azzeh, Ali Bou Nassif, Shadi Banitaan, Fadi Almasalha", "title": "Pareto Efficient Multi Objective Optimization for Local Tuning of\n  Analogy Based Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogy Based Effort Estimation (ABE) is one of the prominent methods for\nsoftware effort estimation. The fundamental concept of ABE is closer to the\nmentality of expert estimation but with an automated procedure in which the\nfinal estimate is generated by reusing similar historical projects. The main\nkey issue when using ABE is how to adapt the effort of the retrieved nearest\nneighbors. The adaptation process is an essential part of ABE to generate more\nsuccessful accurate estimation based on tuning the selected raw solutions,\nusing some adaptation strategy. In this study we show that there are three\ninterrelated decision variables that have great impact on the success of\nadaptation method: (1) number of nearest analogies (k), (2) optimum feature set\nneeded for adaptation, and (3) adaptation weights. To find the right decision\nregarding these variables, one need to study all possible combinations and\nevaluate them individually to select the one that can improve all prediction\nevaluation measures. The existing evaluation measures usually behave\ndifferently, presenting sometimes opposite trends in evaluating prediction\nmethods. This means that changing one decision variable could improve one\nevaluation measure while it is decreasing the others. Therefore, the main theme\nof this research is how to come up with best decision variables that improve\nadaptation strategy and thus, the overall evaluation measures without degrading\nthe others. The impact of these decisions together has not been investigated\nbefore, therefore we propose to view the building of adaptation procedure as a\nmulti-objective optimization problem. The Particle Swarm Optimization Algorithm\n(PSO) is utilized to find the optimum solutions for such decision variables\nbased on optimizing multiple evaluation measures\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 15:57:20 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Azzeh", "Mohammad", ""], ["Nassif", "Ali Bou", ""], ["Banitaan", "Shadi", ""], ["Almasalha", "Fadi", ""]]}, {"id": "1701.01724", "submitter": "Michael Bowling", "authors": "Matej Morav\\v{c}\\'ik, Martin Schmid, Neil Burch, Viliam Lis\\'y, Dustin\n  Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, Michael\n  Bowling", "title": "DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker", "comments": null, "journal-ref": null, "doi": "10.1126/science.aam6960", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has seen several breakthroughs in recent years, with\ngames often serving as milestones. A common feature of these games is that\nplayers have perfect information. Poker is the quintessential game of imperfect\ninformation, and a longstanding challenge problem in artificial intelligence.\nWe introduce DeepStack, an algorithm for imperfect information settings. It\ncombines recursive reasoning to handle information asymmetry, decomposition to\nfocus computation on the relevant decision, and a form of intuition that is\nautomatically learned from self-play using deep learning. In a study involving\n44,000 hands of poker, DeepStack defeated with statistical significance\nprofessional poker players in heads-up no-limit Texas hold'em. The approach is\ntheoretically sound and is shown to produce more difficult to exploit\nstrategies than prior approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2017 18:56:49 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 04:35:28 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 21:17:05 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Morav\u010d\u00edk", "Matej", ""], ["Schmid", "Martin", ""], ["Burch", "Neil", ""], ["Lis\u00fd", "Viliam", ""], ["Morrill", "Dustin", ""], ["Bard", "Nolan", ""], ["Davis", "Trevor", ""], ["Waugh", "Kevin", ""], ["Johanson", "Michael", ""], ["Bowling", "Michael", ""]]}, {"id": "1701.02025", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh and Hinrich Sch\\\"utze", "title": "Multi-level Representations for Fine-Grained Typing of Knowledge Base\n  Entities", "comments": "13 pages, in EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entities are essential elements of natural language. In this paper, we\npresent methods for learning multi-level representations of entities on three\ncomplementary levels: character (character patterns in entity names extracted,\ne.g., by neural networks), word (embeddings of words in entity names) and\nentity (entity embeddings). We investigate state-of-the-art learning methods on\neach level and find large differences, e.g., for deep learning models,\ntraditional ngram features and the subword model of fasttext (Bojanowski et\nal., 2016) on the character level; for word2vec (Mikolov et al., 2013) on the\nword level; and for the order-aware model wang2vec (Ling et al., 2015a) on the\nentity level. We confirm experimentally that each level of representation\ncontributes complementary information and a joint representation of all three\nlevels improves the existing embedding based baseline for fine-grained entity\ntyping by a large margin. Additionally, we show that adding information from\nentity descriptions further improves multi-level representations of entities.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2017 22:20:22 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 22:11:51 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1701.02058", "submitter": "Mehmet Basbug", "authors": "Mehmet E. Basbug, Barbara E. Engelhardt", "title": "Coupled Compound Poisson Factorization", "comments": "Under review at AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a general framework, the coupled compound Poisson factorization\n(CCPF), to capture the missing-data mechanism in extremely sparse data sets by\ncoupling a hierarchical Poisson factorization with an arbitrary data-generating\nmodel. We derive a stochastic variational inference algorithm for the resulting\nmodel and, as examples of our framework, implement three different\ndata-generating models---a mixture model, linear regression, and factor\nanalysis---to robustly model non-random missing data in the context of\nclustering, prediction, and matrix factorization. In all three cases, we test\nour framework against models that ignore the missing-data mechanism on large\nscale studies with non-random missing data, and we show that explicitly\nmodeling the missing-data mechanism substantially improves the quality of the\nresults, as measured using data log likelihood on a held-out test set.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 03:49:26 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Basbug", "Mehmet E.", ""], ["Engelhardt", "Barbara E.", ""]]}, {"id": "1701.02163", "submitter": "Valentina Franzoni", "authors": "Valentina Franzoni", "title": "Just an Update on PMING Distance for Web-based Semantic Similarity in\n  Artificial Intelligence and Data Mining", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.20531.22560", "report-no": null, "categories": "cs.AI cs.CL cs.IR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main problems that emerges in the classic approach to semantics is\nthe difficulty in acquisition and maintenance of ontologies and semantic\nannotations. On the other hand, the Internet explosion and the massive\ndiffusion of mobile smart devices lead to the creation of a worldwide system,\nwhich information is daily checked and fueled by the contribution of millions\nof users who interacts in a collaborative way. Search engines, continually\nexploring the Web, are a natural source of information on which to base a\nmodern approach to semantic annotation. A promising idea is that it is possible\nto generalize the semantic similarity, under the assumption that semantically\nsimilar terms behave similarly, and define collaborative proximity measures\nbased on the indexing information returned by search engines. The PMING\nDistance is a proximity measure used in data mining and information retrieval,\nwhich collaborative information express the degree of relationship between two\nterms, using only the number of documents returned as result for a query on a\nsearch engine. In this work, the PMINIG Distance is updated, providing a novel\nformal algebraic definition, which corrects previous works. The novel point of\nview underlines the features of the PMING to be a locally normalized linear\ncombination of the Pointwise Mutual Information and Normalized Google Distance.\nThe analyzed measure dynamically reflects the collaborative change made on the\nweb resources.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 13:02:35 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Franzoni", "Valentina", ""]]}, {"id": "1701.02272", "submitter": "Tom Portegys", "authors": "Thomas E. Portegys", "title": "Morphognosis: the shape of knowledge in space and time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence research to a great degree focuses on the brain and\nbehaviors that the brain generates. But the brain, an extremely complex\nstructure resulting from millions of years of evolution, can be viewed as a\nsolution to problems posed by an environment existing in space and time. The\nenvironment generates signals that produce sensory events within an organism.\nBuilding an internal spatial and temporal model of the environment allows an\norganism to navigate and manipulate the environment. Higher intelligence might\nbe the ability to process information coming from a larger extent of\nspace-time. In keeping with nature's penchant for extending rather than\nreplacing, the purpose of the mammalian neocortex might then be to record\nevents from distant reaches of space and time and render them, as though yet\nnear and present, to the older, deeper brain whose instinctual roles have\nchanged little over eons. Here this notion is embodied in a model called\nmorphognosis (morpho = shape and gnosis = knowledge). Its basic structure is a\npyramid of event recordings called a morphognostic. At the apex of the pyramid\nare the most recent and nearby events. Receding from the apex are less recent\nand possibly more distant events. A morphognostic can thus be viewed as a\nstructure of progressively larger chunks of space-time knowledge. A set of\nmorphognostics forms long-term memories that are learned by exposure to the\nenvironment. A cellular automaton is used as the platform to investigate the\nmorphognosis model, using a simulated organism that learns to forage in its\nworld for food, build a nest, and play the game of Pong.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 23:10:54 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 18:20:10 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Portegys", "Thomas E.", ""]]}, {"id": "1701.02343", "submitter": "Ehsan Jahangiri", "authors": "Ehsan Jahangiri, Erdem Yoruk, Rene Vidal, Laurent Younes, Donald Geman", "title": "Information Pursuit: A Bayesian Framework for Sequential Scene Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite enormous progress in object detection and classification, the problem\nof incorporating expected contextual relationships among object instances into\nmodern recognition systems remains a key challenge. In this work we propose\nInformation Pursuit, a Bayesian framework for scene parsing that combines prior\nmodels for the geometry of the scene and the spatial arrangement of objects\ninstances with a data model for the output of high-level image classifiers\ntrained to answer specific questions about the scene. In the proposed\nframework, the scene interpretation is progressively refined as evidence\naccumulates from the answers to a sequence of questions. At each step, we\nchoose the question to maximize the mutual information between the new answer\nand the full interpretation given the current evidence obtained from previous\ninquiries. We also propose a method for learning the parameters of the model\nfrom synthesized, annotated scenes obtained by top-down sampling from an\neasy-to-learn generative scene model. Finally, we introduce a database of\nannotated indoor scenes of dining room tables, which we use to evaluate the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 20:39:12 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Jahangiri", "Ehsan", ""], ["Yoruk", "Erdem", ""], ["Vidal", "Rene", ""], ["Younes", "Laurent", ""], ["Geman", "Donald", ""]]}, {"id": "1701.02359", "submitter": "Tapio Pahikkala", "authors": "Markus Viljanen, Antti Airola, Jukka Heikkonen, Tapio Pahikkala", "title": "Playtime Measurement with Survival Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing product use is a central goal of many businesses, which makes\nretention and monetization two central analytics metrics in games. Player\nretention may refer to various duration variables quantifying product use:\ntotal playtime or session playtime are popular research targets, and active\nplaytime is well-suited for subscription games. Such research often has the\ngoal of increasing player retention or conversely decreasing player churn.\nSurvival analysis is a framework of powerful tools well suited for retention\ntype data. This paper contributes new methods to game analytics on how playtime\ncan be analyzed using survival analysis without covariates. Survival and hazard\nestimates provide both a visual and an analytic interpretation of the playtime\nphenomena as a funnel type nonparametric estimate. Metrics based on the\nsurvival curve can be used to aggregate this playtime information into a single\nstatistic. Comparison of survival curves between cohorts provides a scientific\nAB-test. All these methods work on censored data and enable computation of\nconfidence intervals. This is especially important in time and sample limited\ndata which occurs during game development. Throughout this paper, we illustrate\nthe application of these methods to real world game development problems on the\nHipster Sheep mobile game.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jan 2017 10:25:04 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Viljanen", "Markus", ""], ["Airola", "Antti", ""], ["Heikkonen", "Jukka", ""], ["Pahikkala", "Tapio", ""]]}, {"id": "1701.02369", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson and Patrick M. Pilarski", "title": "Reinforcement Learning based Embodied Agents Modelling Human Users\n  Through Interaction and Multi-Sensory Perception", "comments": "4 pages, 2 figures, Accepted at the 2017 AAAI Spring Symposium on\n  Interactive Multi-Sensory Object Perception for Embodied Agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends recent work in interactive machine learning (IML) focused\non effectively incorporating human feedback. We show how control and feedback\nsignals complement each other in systems which model human reward. We\ndemonstrate that simultaneously incorporating human control and feedback\nsignals can improve interactive robotic systems' performance on a self-mirrored\nmovement control task where an RL-agent controlled right arm attempts to match\nthe preprogrammed movement pattern of the left arm. We illustrate the impact of\nvarying human feedback parameters on task performance by investigating the\nprobability of giving feedback on each time step and the likelihood of given\nfeedback being correct. We further illustrate that varying the temporal decay\nwith which the agent incorporates human feedback has a significant impact on\ntask performance. We found that smearing human feedback over time steps\nimproves performance and we show varying the probability of feedback at each\ntime step, and an increased likelihood of those feedbacks being 'correct' can\nimpact agent performance. We conclude that understanding latent variables in\nhuman feedback is crucial for learning algorithms acting in human-machine\ninteraction domains.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 22:03:18 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 17:44:52 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2017 18:37:52 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1701.02388", "submitter": "Gabriel Murray", "authors": "Gabriel Murray", "title": "Stoic Ethics for Artificial Agents", "comments": "Final accepted version submitted to Canadian A.I. 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a position paper advocating the notion that Stoic philosophy and\nethics can inform the development of ethical A.I. systems. This is in sharp\ncontrast to most work on building ethical A.I., which has focused on\nUtilitarian or Deontological ethical theories. We relate ethical A.I. to\nseveral core Stoic notions, including the dichotomy of control, the four\ncardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on\nemotion or affect. More generally, we put forward an ethical view of A.I. that\nfocuses more on internal states of the artificial agent rather than on external\nactions of the agent. We provide examples relating to near-term A.I. systems as\nwell as hypothetical superintelligent agents.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 23:25:43 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 23:59:25 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Murray", "Gabriel", ""]]}, {"id": "1701.02392", "submitter": "Tanmay Shankar", "authors": "Tanmay Shankar, Santosha K. Dwivedy, Prithwijit Guha", "title": "Reinforcement Learning via Recurrent Convolutional Neural Networks", "comments": "Accepted at the International Conference on Pattern Recognition, ICPR\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has enabled the learning of policies for complex\ntasks in partially observable environments, without explicitly learning the\nunderlying model of the tasks. While such model-free methods achieve\nconsiderable performance, they often ignore the structure of task. We present a\nnatural representation of to Reinforcement Learning (RL) problems using\nRecurrent Convolutional Neural Networks (RCNNs), to better exploit this\ninherent structure. We define 3 such RCNNs, whose forward passes execute an\nefficient Value Iteration, propagate beliefs of state in partially observable\nenvironments, and choose optimal actions respectively. Backpropagating\ngradients through these RCNNs allows the system to explicitly learn the\nTransition Model and Reward Function associated with the underlying MDP,\nserving as an elegant alternative to classical model-based RL. We evaluate the\nproposed algorithms in simulation, considering a robot planning problem. We\ndemonstrate the capability of our framework to reduce the cost of replanning,\nlearn accurate MDP models, and finally re-plan with learnt models to achieve\nnear-optimal policies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2017 23:36:05 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Shankar", "Tanmay", ""], ["Dwivedy", "Santosha K.", ""], ["Guha", "Prithwijit", ""]]}, {"id": "1701.02477", "submitter": "Abhinav Thanda", "authors": "Abhinav Thanda, Shankar M Venkatesan", "title": "Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (MTL) involves the simultaneous training of two or more\nrelated tasks over shared representations. In this work, we apply MTL to\naudio-visual automatic speech recognition(AV-ASR). Our primary task is to learn\na mapping between audio-visual fused features and frame labels obtained from\nacoustic GMM/HMM model. This is combined with an auxiliary task which maps\nvisual features to frame labels obtained from a separate visual GMM/HMM model.\nThe MTL model is tested at various levels of babble noise and the results are\ncompared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicate\nthat MTL is especially useful at higher level of noise. Compared to base-line,\nupto 7\\% relative improvement in WER is reported at -3 SNR dB\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 08:47:56 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Thanda", "Abhinav", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "1701.02490", "submitter": "Han Cai", "authors": "Han Cai, Kan Ren, Weinan Zhang, Kleanthis Malialis, Jun Wang, Yong Yu,\n  Defeng Guo", "title": "Real-Time Bidding by Reinforcement Learning in Display Advertising", "comments": "WSDM 2017", "journal-ref": null, "doi": "10.1145/3018661.3018702", "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The majority of online display ads are served through real-time bidding (RTB)\n--- each ad display impression is auctioned off in real-time when it is just\nbeing generated from a user visit. To place an ad automatically and optimally,\nit is critical for advertisers to devise a learning algorithm to cleverly bid\nan ad impression in real-time. Most previous works consider the bid decision as\na static optimization problem of either treating the value of each impression\nindependently or setting a bid price to each segment of ad volume. However, the\nbidding for a given ad campaign would repeatedly happen during its life span\nbefore the budget runs out. As such, each bid is strategically correlated by\nthe constrained budget and the overall effectiveness of the campaign (e.g., the\nrewards from generated clicks), which is only observed after the campaign has\ncompleted. Thus, it is of great interest to devise an optimal bidding strategy\nsequentially so that the campaign budget can be dynamically allocated across\nall the available impressions on the basis of both the immediate and future\nrewards. In this paper, we formulate the bid decision process as a\nreinforcement learning problem, where the state space is represented by the\nauction information and the campaign's real-time parameters, while an action is\nthe bid price to set. By modeling the state transition via auction competition,\nwe build a Markov Decision Process framework for learning the optimal bidding\npolicy to optimize the advertising performance in the dynamic real-time bidding\nenvironment. Furthermore, the scalability problem from the large real-world\nauction volume and campaign budget is well handled by state value approximation\nusing neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 09:30:29 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 01:37:39 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Cai", "Han", ""], ["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Malialis", "Kleanthis", ""], ["Wang", "Jun", ""], ["Yu", "Yong", ""], ["Guo", "Defeng", ""]]}, {"id": "1701.02543", "submitter": "Junbo Zhang", "authors": "Junbo Zhang, Yu Zheng, Dekang Qi, Ruiyuan Li, Xiuwen Yi, Tianrui Li", "title": "Predicting Citywide Crowd Flows Using Deep Spatio-Temporal Residual\n  Networks", "comments": "21 pages, 16 figures. arXiv admin note: substantial text overlap with\n  arXiv:1610.00081", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the flow of crowds is of great importance to traffic management\nand public safety, and very challenging as it is affected by many complex\nfactors, including spatial dependencies (nearby and distant), temporal\ndependencies (closeness, period, trend), and external conditions (e.g., weather\nand events). We propose a deep-learning-based approach, called ST-ResNet, to\ncollectively forecast two types of crowd flows (i.e. inflow and outflow) in\neach and every region of a city. We design an end-to-end structure of ST-ResNet\nbased on unique properties of spatio-temporal data. More specifically, we\nemploy the residual neural network framework to model the temporal closeness,\nperiod, and trend properties of crowd traffic. For each property, we design a\nbranch of residual convolutional units, each of which models the spatial\nproperties of crowd traffic. ST-ResNet learns to dynamically aggregate the\noutput of the three residual neural networks based on data, assigning different\nweights to different branches and regions. The aggregation is further combined\nwith external factors, such as weather and day of the week, to predict the\nfinal traffic of crowds in each and every region. We have developed a real-time\nsystem based on Microsoft Azure Cloud, called UrbanFlow, providing the crowd\nflow monitoring and forecasting in Guiyang City of China. In addition, we\npresent an extensive experimental evaluation using two types of crowd flows in\nBeijing and New York City (NYC), where ST-ResNet outperforms nine well-known\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 12:12:39 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Zhang", "Junbo", ""], ["Zheng", "Yu", ""], ["Qi", "Dekang", ""], ["Li", "Ruiyuan", ""], ["Yi", "Xiuwen", ""], ["Li", "Tianrui", ""]]}, {"id": "1701.02545", "submitter": "Daniel Meana-Llori\\'an", "authors": "Daniel Meana-Llori\\'an, Cristian Gonz\\'alez Garc\\'ia, B. Cristina\n  Pelayo G-Bustelo, Juan Manuel Cueva Lovelle, Nestor Garcia-Fernandez", "title": "IoFClime: The fuzzy logic and the Internet of Things to control indoor\n  temperature regarding the outdoor ambient conditions", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2016.11.020", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things is arriving to our homes or cities through fields\nalready known like Smart Homes, Smart Cities, or Smart Towns. The monitoring of\nenvironmental conditions of cities can help to adapt the indoor locations of\nthe cities in order to be more comfortable for people who stay there. A way to\nimprove the indoor conditions is an efficient temperature control, however, it\ndepends on many factors like the different combinations of outdoor temperature\nand humidity. Therefore, adjusting the indoor temperature is not setting a\nvalue according to other value. There are many more factors to take into\nconsideration, hence the traditional logic based in binary states cannot be\nused. Many problems cannot be solved with a set of binary solutions and we need\na new way of development. Fuzzy logic is able to interpret many states, more\nthan two states, giving to computers the capacity to react in a similar way to\npeople. In this paper we will propose a new approach to control the temperature\nusing the Internet of Things together its platforms and fuzzy logic regarding\nnot only the indoor temperature but also the outdoor temperature and humidity\nin order to save energy and to set a more comfortable environment for their\nusers. Finally, we will conclude that the fuzzy approach allows us to achieve\nan energy saving around 40% and thus, save money.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 12:15:59 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Meana-Llori\u00e1n", "Daniel", ""], ["Garc\u00eda", "Cristian Gonz\u00e1lez", ""], ["G-Bustelo", "B. Cristina Pelayo", ""], ["Lovelle", "Juan Manuel Cueva", ""], ["Garcia-Fernandez", "Nestor", ""]]}, {"id": "1701.02547", "submitter": "Hongseok Yang", "authors": "Chris Heunen and Ohad Kammar and Sam Staton and Hongseok Yang", "title": "A Convenient Category for Higher-Order Probability Theory", "comments": null, "journal-ref": "Logic in Computer Science 2017", "doi": "10.1109/LICS.2017.8005137", "report-no": null, "categories": "cs.PL cs.AI cs.LO math.CT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order probabilistic programming languages allow programmers to write\nsophisticated models in machine learning and statistics in a succinct and\nstructured way, but step outside the standard measure-theoretic formalization\nof probability theory. Programs may use both higher-order functions and\ncontinuous distributions, or even define a probability distribution on\nfunctions. But standard probability theory does not handle higher-order\nfunctions well: the category of measurable spaces is not cartesian closed.\n  Here we introduce quasi-Borel spaces. We show that these spaces: form a new\nformalization of probability theory replacing measurable spaces; form a\ncartesian closed category and so support higher-order functions; form a\nwell-pointed category and so support good proof principles for equational\nreasoning; and support continuous probability distributions. We demonstrate the\nuse of quasi-Borel spaces for higher-order functions and probability by:\nshowing that a well-known construction of probability theory involving random\nfunctions gains a cleaner expression; and generalizing de Finetti's theorem,\nthat is a crucial theorem in probability theory, to quasi-Borel spaces.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 12:19:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2017 11:02:46 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 20:02:24 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 08:56:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Heunen", "Chris", ""], ["Kammar", "Ohad", ""], ["Staton", "Sam", ""], ["Yang", "Hongseok", ""]]}, {"id": "1701.02593", "submitter": "Diego Marcheggiani", "authors": "Diego Marcheggiani, Anton Frolov, Ivan Titov", "title": "A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based\n  Semantic Role Labeling", "comments": "To appear in CoNLL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and accurate neural model for dependency-based semantic\nrole labeling. Our model predicts predicate-argument dependencies relying on\nstates of a bidirectional LSTM encoder. The semantic role labeler achieves\ncompetitive performance on English, even without any kind of syntactic\ninformation and only using local inference. However, when automatically\npredicted part-of-speech tags are provided as input, it substantially\noutperforms all previous local models and approaches the best reported results\non the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish\nwhere our approach also achieves competitive results. Syntactic parsers are\nunreliable on out-of-domain data, so standard (i.e., syntactically-informed)\nSRL models are hindered when tested in this setting. Our syntax-agnostic model\nappears more robust, resulting in the best reported results on standard\nout-of-domain test sets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 14:01:47 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 16:47:47 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Frolov", "Anton", ""], ["Titov", "Ivan", ""]]}, {"id": "1701.02810", "submitter": "Alexander M. Rush", "authors": "Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander M.\n  Rush", "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation", "comments": "Report for http://opennmt.net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an open-source toolkit for neural machine translation (NMT). The\ntoolkit prioritizes efficiency, modularity, and extensibility with the goal of\nsupporting NMT research into model architectures, feature representations, and\nsource modalities, while maintaining competitive performance and reasonable\ntraining requirements. The toolkit consists of modeling and translation\nsupport, as well as detailed pedagogical documentation about the underlying\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 23:32:43 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 15:54:27 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Klein", "Guillaume", ""], ["Kim", "Yoon", ""], ["Deng", "Yuntian", ""], ["Senellart", "Jean", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1701.02854", "submitter": "Cong Duy Vu Hoang Mr", "authors": "Cong Duy Vu Hoang (University of Melbourne), Gholamreza Haffari\n  (Monash University), Trevor Cohn (University of Melbourne)", "title": "Towards Decoding as Continuous Optimization in Neural Machine\n  Translation", "comments": "EMNLP 2017 Camera Ready Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel decoding approach for neural machine translation (NMT)\nbased on continuous optimisation. We convert decoding - basically a discrete\noptimization problem - into a continuous optimization problem. The resulting\nconstrained continuous optimisation problem is then tackled using\ngradient-based methods. Our powerful decoding framework enables decoding\nintractable models such as the intersection of left-to-right and right-to-left\n(bidirectional) as well as source-to-target and target-to-source (bilingual)\nNMT models. Our empirical results show that our decoding framework is\neffective, and leads to substantial improvements in translations generated from\nthe intersected models where the typical greedy or beam search is not feasible.\nWe also compare our framework against reranking, and analyse its advantages and\ndisadvantages.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 06:02:44 GMT"}, {"version": "v2", "created": "Wed, 8 Feb 2017 00:15:08 GMT"}, {"version": "v3", "created": "Thu, 9 Feb 2017 09:26:30 GMT"}, {"version": "v4", "created": "Sat, 22 Jul 2017 16:35:43 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Hoang", "Cong Duy Vu", "", "University of Melbourne"], ["Haffari", "Gholamreza", "", "Monash University"], ["Cohn", "Trevor", "", "University of Melbourne"]]}, {"id": "1701.02870", "submitter": "Ramakrishna Vedantam", "authors": "Ramakrishna Vedantam, Samy Bengio, Kevin Murphy, Devi Parikh, Gal\n  Chechik", "title": "Context-aware Captions from Context-agnostic Supervision", "comments": "Accepted to CVPR 2017 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an inference technique to produce discriminative context-aware\nimage captions (captions that describe differences between images or visual\nconcepts) using only generic context-agnostic training data (captions that\ndescribe a concept or an image in isolation). For example, given images and\ncaptions of \"siamese cat\" and \"tiger cat\", we generate language that describes\nthe \"siamese cat\" in a way that distinguishes it from \"tiger cat\". Our key\nnovelty is that we show how to do joint inference over a language model that is\ncontext-agnostic and a listener which distinguishes closely-related concepts.\nWe first apply our technique to a justification task, namely to describe why an\nimage contains a particular fine-grained category as opposed to another\nclosely-related category of the CUB-200-2011 dataset. We then study\ndiscriminative image captioning to generate language that uniquely refers to\none of two semantically-similar images in the COCO dataset. Evaluations with\ndiscriminative ground truth for justification and human studies for\ndiscriminative image captioning reveal that our approach outperforms baseline\ngenerative and speaker-listener approaches for discrimination.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 07:42:58 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 08:59:56 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 23:29:36 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Vedantam", "Ramakrishna", ""], ["Bengio", "Samy", ""], ["Murphy", "Kevin", ""], ["Parikh", "Devi", ""], ["Chechik", "Gal", ""]]}, {"id": "1701.03000", "submitter": "Athanasios Karapantelakis", "authors": "Aneta Vulgarakis Feljan, Athanasios Karapantelakis, Leonid Mokrushin,\n  Hongxin Liang, Rafia Inam, Elena Fersman, Carlos R.B. Azevedo, Klaus Raizer,\n  Ricardo S. Souza", "title": "A Framework for Knowledge Management and Automated Reasoning Applied on\n  Intelligent Transport Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems in general, and Intelligent Transport Systems (ITS) in\nparticular use heterogeneous data sources combined with problem solving\nexpertise in order to make critical decisions that may lead to some form of\nactions e.g., driver notifications, change of traffic light signals and braking\nto prevent an accident. Currently, a major part of the decision process is done\nby human domain experts, which is time-consuming, tedious and error-prone.\nAdditionally, due to the intrinsic nature of knowledge possession this decision\nprocess cannot be easily replicated or reused. Therefore, there is a need for\nautomating the reasoning processes by providing computational systems a formal\nrepresentation of the domain knowledge and a set of methods to process that\nknowledge. In this paper, we propose a knowledge model that can be used to\nexpress both declarative knowledge about the systems' components, their\nrelations and their current state, as well as procedural knowledge representing\npossible system behavior. In addition, we introduce a framework for knowledge\nmanagement and automated reasoning (KMARF). The idea behind KMARF is to\nautomatically select an appropriate problem solver based on formalized\nreasoning expertise in the knowledge base, and convert a problem definition to\nthe corresponding format. This approach automates reasoning, thus reducing\noperational costs, and enables reusability of knowledge and methods across\ndifferent domains. We illustrate the approach on a transportation planning use\ncase.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 15:03:18 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Feljan", "Aneta Vulgarakis", ""], ["Karapantelakis", "Athanasios", ""], ["Mokrushin", "Leonid", ""], ["Liang", "Hongxin", ""], ["Inam", "Rafia", ""], ["Fersman", "Elena", ""], ["Azevedo", "Carlos R. B.", ""], ["Raizer", "Klaus", ""], ["Souza", "Ricardo S.", ""]]}, {"id": "1701.03037", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Towards Smart Proof Search for Isabelle", "comments": "Accepted at AITP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent progress in automatic theorem provers, proof engineers are\nstill suffering from the lack of powerful proof automation. In this position\npaper we first report our proof strategy language based on a meta-tool\napproach. Then, we propose an AI-based approach to drastically improve proof\nautomation for Isabelle, while identifying three major challenges we plan to\naddress for this objective.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 08:52:31 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "1701.03102", "submitter": "Xiang Xiang", "authors": "Xiang Xiang, Trac D. Tran", "title": "Linear Disentangled Representation Learning for Facial Actions", "comments": "Codes available at https://github.com/eglxiang/icassp15_emotion and\n  https://github.com/eglxiang/FacialAU. arXiv admin note: text overlap with\n  arXiv:1410.1606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited annotated data available for the recognition of facial expression and\naction units embarrasses the training of deep networks, which can learn\ndisentangled invariant features. However, a linear model with just several\nparameters normally is not demanding in terms of training data. In this paper,\nwe propose an elegant linear model to untangle confounding factors in\nchallenging realistic multichannel signals such as 2D face videos. The simple\nyet powerful model does not rely on huge training data and is natural for\nrecognizing facial actions without explicitly disentangling the identity. Base\non well-understood intuitive linear models such as Sparse Representation based\nClassification (SRC), previous attempts require a prepossessing of explicit\ndecoupling which is practically inexact. Instead, we exploit the low-rank\nproperty across frames to subtract the underlying neutral faces which are\nmodeled jointly with sparse representation on the action components with group\nsparsity enforced. On the extended Cohn-Kanade dataset (CK+), our one-shot\nautomatic method on raw face videos performs as competitive as SRC applied on\nmanually prepared action components and performs even better than SRC in terms\nof true positive rate. We apply the model to the even more challenging task of\nfacial action unit recognition, verified on the MPI Face Video Database\n(MPI-VDB) achieving a decent performance. All the programs and data have been\nmade publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2017 16:34:29 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Xiang", "Xiang", ""], ["Tran", "Trac D.", ""]]}, {"id": "1701.03162", "submitter": "Yifan Yang", "authors": "Yifan Yang and Tian Qin and Yu-Heng Lei", "title": "Real-time eSports Match Result Prediction", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to predict the winning team of a match in the\nmultiplayer eSports game Dota 2. To address the weaknesses of previous work, we\nconsider more aspects of prior (pre-match) features from individual players'\nmatch history, as well as real-time (during-match) features at each minute as\nthe match progresses. We use logistic regression, the proposed Attribute\nSequence Model, and their combinations as the prediction models. In a dataset\nof 78362 matches where 20631 matches contain replay data, our experiments show\nthat adding more aspects of prior features improves accuracy from 58.69% to\n71.49%, and introducing real-time features achieves up to 93.73% accuracy when\npredicting at the 40th minute.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 06:30:25 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Yang", "Yifan", ""], ["Qin", "Tian", ""], ["Lei", "Yu-Heng", ""]]}, {"id": "1701.03322", "submitter": "Yi Zhou Dr.", "authors": "Yi Zhou", "title": "From First-Order Logic to Assertional Logic", "comments": "arXiv admin note: text overlap with arXiv:1603.03511", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-Order Logic (FOL) is widely regarded as one of the most important\nfoundations for knowledge representation. Nevertheless, in this paper, we argue\nthat FOL has several critical issues for this purpose. Instead, we propose an\nalternative called assertional logic, in which all syntactic objects are\ncategorized as set theoretic constructs including individuals, concepts and\noperators, and all kinds of knowledge are formalized by equality assertions. We\nfirst present a primitive form of assertional logic that uses minimal assumed\nknowledge and constructs. Then, we show how to extend it by definitions, which\nare special kinds of knowledge, i.e., assertions. We argue that assertional\nlogic, although simpler, is more expressive and extensible than FOL. As a case\nstudy, we show how assertional logic can be used to unify logic and\nprobability, and more building blocks in AI.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 12:25:42 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 06:09:21 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Zhou", "Yi", ""]]}, {"id": "1701.03360", "submitter": "Jaeyoung Kim", "authors": "Jaeyoung Kim, Mostafa El-Khamy, and Jungwon Lee", "title": "Residual LSTM: Design of a Deep Recurrent Architecture for Distant\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel architecture for a deep recurrent neural network,\nresidual LSTM is introduced. A plain LSTM has an internal memory cell that can\nlearn long term dependencies of sequential data. It also provides a temporal\nshortcut path to avoid vanishing or exploding gradients in the temporal domain.\nThe residual LSTM provides an additional spatial shortcut path from lower\nlayers for efficient training of deep networks with multiple LSTM layers.\nCompared with the previous work, highway LSTM, residual LSTM separates a\nspatial shortcut path with temporal one by using output layers, which can help\nto avoid a conflict between spatial and temporal-domain gradient flows.\nFurthermore, residual LSTM reuses the output projection matrix and the output\ngate of LSTM to control the spatial information flow instead of additional gate\nnetworks, which effectively reduces more than 10% of network parameters. An\nexperiment for distant speech recognition on the AMI SDM corpus shows that\n10-layer plain and highway LSTM networks presented 13.7% and 6.2% increase in\nWER over 3-layer aselines, respectively. On the contrary, 10-layer residual\nLSTM networks provided the lowest WER 41.0%, which corresponds to 3.3% and 2.8%\nWER reduction over plain and highway LSTM networks, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2017 20:03:37 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 00:23:45 GMT"}, {"version": "v3", "created": "Mon, 5 Jun 2017 18:51:08 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Kim", "Jaeyoung", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1701.03500", "submitter": "Grant Molnar", "authors": "Grant Molnar", "title": "A Savage-Like Axiomatization for Nonstandard Expected Utility", "comments": "The alleged result of this paper is incorrect, the transfer principle\n  applies only to first-order statements over standard structures, but I\n  attempted to apply it over second-order statements as well. I believe a proof\n  in the same vein as the one in this paper could be developed, but much\n  greater care would need to be taken to respect the difference between\n  internal and external sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Leonard Savage's epoch-making \"Foundations of Statistics\", Subjective\nExpected Utility Theory has been the presumptive model for decision-making.\nSavage provided an act-based axiomatization of standard expected utility\ntheory. In this article, we provide a Savage-like axiomatization of nonstandard\nexpected utility theory. It corresponds to a weakening of Savage's 6th axiom.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2017 20:39:03 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 00:27:55 GMT"}, {"version": "v3", "created": "Mon, 30 Jan 2017 01:18:29 GMT"}, {"version": "v4", "created": "Fri, 3 Mar 2017 16:48:00 GMT"}, {"version": "v5", "created": "Sun, 22 Oct 2017 22:55:38 GMT"}, {"version": "v6", "created": "Mon, 13 Nov 2017 16:32:00 GMT"}, {"version": "v7", "created": "Thu, 8 Feb 2018 20:54:04 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Molnar", "Grant", ""]]}, {"id": "1701.03571", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko, Viktoriia\n  O. Samitova", "title": "Fuzzy Clustering Data Given in the Ordinal Scale", "comments": null, "journal-ref": "I.J. Intelligent Systems and Applications, 2017, Vol. 9, No. 1,\n  pp. 67-74", "doi": "10.5815/ijisa.2017.01.07", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fuzzy clustering algorithm for multidimensional data is proposed in this\narticle. The data is described by vectors whose components are linguistic\nvariables defined in an ordinal scale. The obtained results confirm the\nefficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 06:32:14 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Samitova", "Viktoriia O.", ""]]}, {"id": "1701.03577", "submitter": "Avner May", "authors": "Avner May, Alireza Bagheri Garakani, Zhiyun Lu, Dong Guo, Kuan Liu,\n  Aur\\'elien Bellet, Linxi Fan, Michael Collins, Daniel Hsu, Brian Kingsbury,\n  Michael Picheny, Fei Sha", "title": "Kernel Approximation Methods for Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study large-scale kernel methods for acoustic modeling in speech\nrecognition and compare their performance to deep neural networks (DNNs). We\nperform experiments on four speech recognition datasets, including the TIMIT\nand Broadcast News benchmark tasks, and compare these two types of models on\nframe-level performance metrics (accuracy, cross-entropy), as well as on\nrecognition metrics (word/character error rate). In order to scale kernel\nmethods to these large datasets, we use the random Fourier feature method of\nRahimi and Recht (2007). We propose two novel techniques for improving the\nperformance of kernel acoustic models. First, in order to reduce the number of\nrandom features required by kernel models, we propose a simple but effective\nmethod for feature selection. The method is able to explore a large number of\nnon-linear features while maintaining a compact model more efficiently than\nexisting approaches. Second, we present a number of frame-level metrics which\ncorrelate very strongly with recognition performance when computed on the\nheldout set; we take advantage of these correlations by monitoring these\nmetrics during training in order to decide when to stop learning. This\ntechnique can noticeably improve the recognition performance of both DNN and\nkernel models, while narrowing the gap between them. Additionally, we show that\nthe linear bottleneck method of Sainath et al. (2013) improves the performance\nof our kernel models significantly, in addition to speeding up training and\nmaking the models more compact. Together, these three methods dramatically\nimprove the performance of kernel acoustic models, making their performance\ncomparable to DNNs on the tasks we explored.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 07:24:18 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["May", "Avner", ""], ["Garakani", "Alireza Bagheri", ""], ["Lu", "Zhiyun", ""], ["Guo", "Dong", ""], ["Liu", "Kuan", ""], ["Bellet", "Aur\u00e9lien", ""], ["Fan", "Linxi", ""], ["Collins", "Michael", ""], ["Hsu", "Daniel", ""], ["Kingsbury", "Brian", ""], ["Picheny", "Michael", ""], ["Sha", "Fei", ""]]}, {"id": "1701.03578", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Hyeongu Yun, Yuna Kim, Gyu-tae Park, Kyomin Jung", "title": "Efficient Transfer Learning Schemes for Personalized Language Modeling\n  using Recurrent Neural Network", "comments": "AAAI workshop on Crowdsourcing, Deep Learning and Artificial\n  Intelligence Agents, Feb 2017, San Francisco CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an efficient transfer leaning methods for training\na personalized language model using a recurrent neural network with long\nshort-term memory architecture. With our proposed fast transfer learning\nschemes, a general language model is updated to a personalized language model\nwith a small amount of user data and a limited computing resource. These\nmethods are especially useful for a mobile device environment while the data is\nprevented from transferring out of the device for privacy purposes. Through\nexperiments on dialogue data in a drama, it is verified that our transfer\nlearning methods have successfully generated the personalized language model,\nwhose output is more similar to the personal language style in both qualitative\nand quantitative aspects.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 07:26:00 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Yun", "Hyeongu", ""], ["Kim", "Yuna", ""], ["Park", "Gyu-tae", ""], ["Jung", "Kyomin", ""]]}, {"id": "1701.03714", "submitter": "Nir Oren", "authors": "Zimi Li and Nir Oren and Simon Parsons", "title": "On the links between argumentation-based reasoning and nonmonotonic\n  reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the links between instantiated argumentation\nsystems and the axioms for non-monotonic reasoning described in [9] with the\naim of characterising the nature of argument based reasoning. In doing so, we\nconsider two possible interpretations of the consequence relation, and describe\nwhich axioms are met by ASPIC+ under each of these interpretations. We then\nconsider the links between these axioms and the rationality postulates. Our\nresults indicate that argument based reasoning as characterised by ASPIC+ is -\naccording to the axioms of [9] - non-cumulative and non-monotonic, and\ntherefore weaker than the weakest non-monotonic reasoning systems they\nconsidered possible. This weakness underpins ASPIC+'s success in modelling\nother reasoning systems, and we conclude by considering the relationship\nbetween ASPIC+ and other weak logical systems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 16:33:52 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Li", "Zimi", ""], ["Oren", "Nir", ""], ["Parsons", "Simon", ""]]}, {"id": "1701.03757", "submitter": "Dustin Tran", "authors": "Dustin Tran, Matthew D. Hoffman, Rif A. Saurous, Eugene Brevdo, Kevin\n  Murphy, David M. Blei", "title": "Deep Probabilistic Programming", "comments": "Appears in International Conference on Learning Representations,\n  2017. A companion webpage for this paper is available at\n  http://edwardlib.org/iclr2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.PL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Edward, a Turing-complete probabilistic programming language.\nEdward defines two compositional representations---random variables and\ninference. By treating inference as a first class citizen, on a par with\nmodeling, we show that probabilistic programming can be as flexible and\ncomputationally efficient as traditional deep learning. For flexibility, Edward\nmakes it easy to fit the same model using a variety of composable inference\nmethods, ranging from point estimation to variational inference to MCMC. In\naddition, Edward can reuse the modeling representation as part of inference,\nfacilitating the design of rich variational models and generative adversarial\nnetworks. For efficiency, Edward is integrated into TensorFlow, providing\nsignificant speedups over existing probabilistic systems. For example, we show\non a benchmark logistic regression task that Edward is at least 35x faster than\nStan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it\nis as fast as handwritten TensorFlow.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2017 17:52:07 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 18:41:45 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Tran", "Dustin", ""], ["Hoffman", "Matthew D.", ""], ["Saurous", "Rif A.", ""], ["Brevdo", "Eugene", ""], ["Murphy", "Kevin", ""], ["Blei", "David M.", ""]]}, {"id": "1701.03866", "submitter": "Steven Hansen", "authors": "Steven Stenberg Hansen", "title": "Long Timescale Credit Assignment in NeuralNetworks with External Memory", "comments": "Accepted into the NIPS 2016 workshop on Continual Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit assignment in traditional recurrent neural networks usually involves\nback-propagating through a long chain of tied weight matrices. The length of\nthis chain scales linearly with the number of time-steps as the same network is\nrun at each time-step. This creates many problems, such as vanishing gradients,\nthat have been well studied. In contrast, a NNEM's architecture recurrent\nactivity doesn't involve a long chain of activity (though some architectures\nsuch as the NTM do utilize a traditional recurrent architecture as a\ncontroller). Rather, the externally stored embedding vectors are used at each\ntime-step, but no messages are passed from previous time-steps. This means that\nvanishing gradients aren't a problem, as all of the necessary gradient paths\nare short. However, these paths are extremely numerous (one per embedding\nvector in memory) and reused for a very long time (until it leaves the memory).\nThus, the forward-pass information of each memory must be stored for the entire\nduration of the memory. This is problematic as this additional storage far\nsurpasses that of the actual memories, to the extent that large memories on\ninfeasible to back-propagate through in high dimensional settings. One way to\nget around the need to hold onto forward-pass information is to recalculate the\nforward-pass whenever gradient information is available. However, if the\nobservations are too large to store in the domain of interest, direct\nreinstatement of a forward pass cannot occur. Instead, we rely on a learned\nautoencoder to reinstate the observation, and then use the embedding network to\nrecalculate the forward-pass. Since the recalculated embedding vector is\nunlikely to perfectly match the one stored in memory, we try out 2\napproximations to utilize error gradient w.r.t. the vector in memory.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 01:47:54 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Hansen", "Steven Stenberg", ""]]}, {"id": "1701.03868", "submitter": "Steven Hansen", "authors": "Steven Stenberg Hansen", "title": "Minimally Naturalistic Artificial Intelligence", "comments": "Accepted into the NIPS 2016 Workshop on Machine Intelligence\n  (M.A.I.N.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advancement of machine learning techniques has re-energized\nresearch into general artificial intelligence. While the idea of\ndomain-agnostic meta-learning is appealing, this emerging field must come to\nterms with its relationship to human cognition and the statistics and structure\nof the tasks humans perform. The position of this article is that only by\naligning our agents' abilities and environments with those of humans do we\nstand a chance at developing general artificial intelligence (GAI). A broad\nreading of the famous 'No Free Lunch' theorem is that there is no universally\noptimal inductive bias or, equivalently, bias-free learning is impossible. This\nfollows from the fact that there are an infinite number of ways to extrapolate\ndata, any of which might be the one used by the data generating environment; an\ninductive bias prefers some of these extrapolations to others, which lowers\nperformance in environments using these adversarial extrapolations. We may\nposit that the optimal GAI is the one that maximally exploits the statistics of\nits environment to create its inductive bias; accepting the fact that this\nagent is guaranteed to be extremely sub-optimal for some alternative\nenvironments. This trade-off appears benign when thinking about the environment\nas being the physical universe, as performance on any fictive universe is\nobviously irrelevant. But, we should expect a sharper inductive bias if we\nfurther constrain our environment. Indeed, we implicitly do so by defining GAI\nin terms of accomplishing that humans consider useful. One common version of\nthis is need the for 'common-sense reasoning', which implicitly appeals to the\nstatistics of physical universe as perceived by humans.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 01:57:31 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Hansen", "Steven Stenberg", ""]]}, {"id": "1701.03891", "submitter": "Ali Mousavi", "authors": "Ali Mousavi, Richard G. Baraniuk", "title": "Learning to Invert: Signal Recovery via Deep Convolutional Networks", "comments": "Accepted at The 42nd IEEE International Conference on Acoustics,\n  Speech and Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The promise of compressive sensing (CS) has been offset by two significant\nchallenges. First, real-world data is not exactly sparse in a fixed basis.\nSecond, current high-performance recovery algorithms are slow to converge,\nwhich limits CS to either non-real-time applications or scenarios where massive\nback-end computing is available. In this paper, we attack both of these\nchallenges head-on by developing a new signal recovery framework we call {\\em\nDeepInverse} that learns the inverse transformation from measurement vectors to\nsignals using a {\\em deep convolutional network}. When trained on a set of\nrepresentative images, the network learns both a representation for the signals\n(addressing challenge one) and an inverse map approximating a greedy or convex\nrecovery algorithm (addressing challenge two). Our experiments indicate that\nthe DeepInverse network closely approximates the solution produced by\nstate-of-the-art CS recovery algorithms yet is hundreds of times faster in run\ntime. The tradeoff for the ultrafast run time is a computationally intensive,\noff-line training procedure typical to deep networks. However, the training\nneeds to be completed only once, which makes the approach attractive for a host\nof sparse recovery problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 08:42:19 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Mousavi", "Ali", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1701.03937", "submitter": "Tuan Tran", "authors": "Tuan Tran, Tu Ngoc Nguyen", "title": "Hedera: Scalable Indexing and Exploring Entities in Wikipedia Revision\n  History", "comments": "Pubished via CEUR-WS.org/Vol-1272", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of work in semantic web relying on Wikipedia as the main source of\nknowledge often work on static snapshots of the dataset. The full history of\nWikipedia revisions, while contains much more useful information, is still\ndifficult to access due to its exceptional volume. To enable further research\non this collection, we developed a tool, named Hedera, that efficiently\nextracts semantic information from Wikipedia revision history datasets. Hedera\nexploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle\none entire Wikipedia articles revision history within a day in a medium-scale\ncluster, and supports flexible data structures for various kinds of semantic\nweb study.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2017 15:47:06 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Tran", "Tuan", ""], ["Nguyen", "Tu Ngoc", ""]]}, {"id": "1701.04024", "submitter": "Mihail Eric", "authors": "Mihail Eric and Christopher D. Manning", "title": "A Copy-Augmented Sequence-to-Sequence Architecture Gives Good\n  Performance on Task-Oriented Dialogue", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Task-oriented dialogue focuses on conversational agents that participate in\nuser-initiated dialogues on domain-specific topics. In contrast to chatbots,\nwhich simply seek to sustain open-ended meaningful discourse, existing\ntask-oriented agents usually explicitly model user intent and belief states.\nThis paper examines bypassing such an explicit representation by depending on a\nlatent neural embedding of state and learning selective attention to dialogue\nhistory together with copying to incorporate relevant prior context. We\ncomplement recent work by showing the effectiveness of simple\nsequence-to-sequence neural architectures with a copy mechanism. Our model\noutperforms more complex memory-augmented models by 7% in per-response\ngeneration and is on par with the current state-of-the-art on DSTC2.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 10:38:17 GMT"}, {"version": "v2", "created": "Sat, 4 Feb 2017 09:31:18 GMT"}, {"version": "v3", "created": "Mon, 14 Aug 2017 22:18:38 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Eric", "Mihail", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1701.04079", "submitter": "David Abel", "authors": "David Abel, John Salvatier, Andreas Stuhlm\\\"uller, Owain Evans", "title": "Agent-Agnostic Human-in-the-Loop Reinforcement Learning", "comments": "Presented at the NIPS Workshop on the Future of Interactive Learning\n  Machines, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing Reinforcement Learning agents with expert advice can dramatically\nimprove various aspects of learning. Prior work has developed teaching\nprotocols that enable agents to learn efficiently in complex environments; many\nof these methods tailor the teacher's guidance to agents with a particular\nrepresentation or underlying learning scheme, offering effective but\nspecialized teaching procedures. In this work, we explore protocol programs, an\nagent-agnostic schema for Human-in-the-Loop Reinforcement Learning. Our goal is\nto incorporate the beneficial properties of a human teacher into Reinforcement\nLearning without making strong assumptions about the inner workings of the\nagent. We show how to represent existing approaches such as action pruning,\nreward shaping, and training in simulation as special cases of our schema and\nconduct preliminary experiments on simple domains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 17:14:40 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Abel", "David", ""], ["Salvatier", "John", ""], ["Stuhlm\u00fcller", "Andreas", ""], ["Evans", "Owain", ""]]}, {"id": "1701.04113", "submitter": "David Abel", "authors": "David Abel, D. Ellis Hershkowitz, Michael L. Littman", "title": "Near Optimal Behavior via Approximate State Abstraction", "comments": "Earlier version published at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combinatorial explosion that plagues planning and reinforcement learning\n(RL) algorithms can be moderated using state abstraction. Prohibitively large\ntask representations can be condensed such that essential information is\npreserved, and consequently, solutions are tractably computable. However, exact\nabstractions, which treat only fully-identical situations as equivalent, fail\nto present opportunities for abstraction in environments where no two\nsituations are exactly alike. In this work, we investigate approximate state\nabstractions, which treat nearly-identical situations as equivalent. We present\ntheoretical guarantees of the quality of behaviors derived from four types of\napproximate abstractions. Additionally, we empirically demonstrate that\napproximate abstractions lead to reduction in task complexity and bounded loss\nof optimality of behavior in a variety of environments.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 21:24:45 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Abel", "David", ""], ["Hershkowitz", "D. Ellis", ""], ["Littman", "Michael L.", ""]]}, {"id": "1701.04128", "submitter": "Wenjie Luo", "authors": "Wenjie Luo and Yujia Li and Raquel Urtasun and Richard Zemel", "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study characteristics of receptive fields of units in deep convolutional\nnetworks. The receptive field size is a crucial issue in many visual tasks, as\nthe output must respond to large enough areas in the image to capture\ninformation about large objects. We introduce the notion of an effective\nreceptive field, and show that it both has a Gaussian distribution and only\noccupies a fraction of the full theoretical receptive field. We analyze the\neffective receptive field in several architecture designs, and the effect of\nnonlinear activations, dropout, sub-sampling and skip connections on it. This\nleads to suggestions for ways to address its tendency to be too small.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jan 2017 23:52:49 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 06:32:29 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Luo", "Wenjie", ""], ["Li", "Yujia", ""], ["Urtasun", "Raquel", ""], ["Zemel", "Richard", ""]]}, {"id": "1701.04143", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan and Arslan Munir", "title": "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks", "comments": "14 pages, 5 figures, pre-print of submission to MLDM '17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are known to be inherently vulnerable to\nmanipulation by intentionally perturbed inputs, named adversarial examples. In\nthis work, we establish that reinforcement learning techniques based on Deep\nQ-Networks (DQNs) are also vulnerable to adversarial input perturbations, and\nverify the transferability of adversarial examples across different DQN models.\nFurthermore, we present a novel class of attacks based on this vulnerability\nthat enable policy manipulation and induction in the learning process of DQNs.\nWe propose an attack mechanism that exploits the transferability of adversarial\nexamples to implement policy induction attacks on DQNs, and demonstrate its\nefficacy and impact through experimental study of a game-learning scenario.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 02:39:01 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""]]}, {"id": "1701.04222", "submitter": "Aristide Tossou", "authors": "Aristide C. Y. Tossou and Christos Dimitrakakis", "title": "Achieving Privacy in the Adversarial Multi-Armed Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we improve the previously best known regret bound to achieve\n$\\epsilon$-differential privacy in oblivious adversarial bandits from\n$\\mathcal{O}{(T^{2/3}/\\epsilon)}$ to $\\mathcal{O}{(\\sqrt{T} \\ln T /\\epsilon)}$.\nThis is achieved by combining a Laplace Mechanism with EXP3. We show that\nthough EXP3 is already differentially private, it leaks a linear amount of\ninformation in $T$. However, we can improve this privacy by relying on its\nintrinsic exponential mechanism for selecting actions. This allows us to reach\n$\\mathcal{O}{(\\sqrt{\\ln T})}$-DP, with a regret of $\\mathcal{O}{(T^{2/3})}$\nthat holds against an adaptive adversary, an improvement from the best known of\n$\\mathcal{O}{(T^{3/4})}$. This is done by using an algorithm that run EXP3 in a\nmini-batch loop. Finally, we run experiments that clearly demonstrate the\nvalidity of our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 10:04:05 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Tossou", "Aristide C. Y.", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1701.04238", "submitter": "Aristide Charles Yedia Tossou", "authors": "Aristide C. Y. Tossou, Christos Dimitrakakis, Devdatt Dubhashi", "title": "Thompson Sampling For Stochastic Bandits with Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel extension of Thompson Sampling for stochastic sequential\ndecision problems with graph feedback, even when the graph structure itself is\nunknown and/or changing. We provide theoretical guarantees on the Bayesian\nregret of the algorithm, linking its performance to the underlying properties\nof the graph. Thompson Sampling has the advantage of being applicable without\nthe need to construct complicated upper confidence bounds for different\nproblems. We illustrate its performance through extensive experimental results\non real and simulated networks with graph feedback. More specifically, we\ntested our algorithms on power law, planted partitions and Erdo's-Renyi graphs,\nas well as on graphs derived from Facebook and Flixster data. These all show\nthat our algorithms clearly outperform related methods that employ upper\nconfidence bounds, even if the latter use more information about the graph.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 10:52:51 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Tossou", "Aristide C. Y.", ""], ["Dimitrakakis", "Christos", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "1701.04503", "submitter": "Garrett Goh", "authors": "Garrett B. Goh, Nathan O. Hodas, Abhinav Vishnu", "title": "Deep Learning for Computational Chemistry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CE cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise and fall of artificial neural networks is well documented in the\nscientific literature of both computer science and computational chemistry. Yet\nalmost two decades later, we are now seeing a resurgence of interest in deep\nlearning, a machine learning algorithm based on multilayer neural networks.\nWithin the last few years, we have seen the transformative impact of deep\nlearning in many domains, particularly in speech recognition and computer\nvision, to the extent that the majority of expert practitioners in those field\nare now regularly eschewing prior established models in favor of deep learning\nmodels. In this review, we provide an introductory overview into the theory of\ndeep neural networks and their unique properties that distinguish them from\ntraditional machine learning algorithms used in cheminformatics. By providing\nan overview of the variety of emerging applications of deep neural networks, we\nhighlight its ubiquity and broad applicability to a wide range of challenges in\nthe field, including QSAR, virtual screening, protein structure prediction,\nquantum chemistry, materials design and property prediction. In reviewing the\nperformance of deep neural networks, we observed a consistent outperformance\nagainst non-neural networks state-of-the-art models across disparate research\ntopics, and deep neural network based models often exceeded the \"glass ceiling\"\nexpectations of their respective tasks. Coupled with the maturity of\nGPU-accelerated computing for training deep neural networks and the exponential\ngrowth of chemical data on which to train these networks on, we anticipate that\ndeep learning algorithms will be a valuable tool for computational chemistry.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 01:15:14 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Goh", "Garrett B.", ""], ["Hodas", "Nathan O.", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1701.04528", "submitter": "Vincent Zheng", "authors": "Hongyun Cai, and Vincent W. Zheng, and Fanwei Zhu, and Kevin\n  Chen-Chuan Chang, and Zi Huang", "title": "From Community Detection to Community Profiling", "comments": "Technical report of a PVLDB 2017 paper", "journal-ref": null, "doi": null, "report-no": "Technical Report ADSC-2017", "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing community-related studies focus on detection, which aim to find\nthe community membership for each user from user friendship links. However,\nmembership alone, without a complete profile of what a community is and how it\ninteracts with other communities, has limited applications. This motivates us\nto consider systematically profiling the communities and thereby developing\nuseful community-level applications. In this paper, we for the first time\nformalize the concept of community profiling. With rich user information on the\nnetwork, such as user published content and user diffusion links, we\ncharacterize a community in terms of both its internal content profile and\nexternal diffusion profile. The difficulty of community profiling is often\nunderestimated. We novelly identify three unique challenges and propose a joint\nCommunity Profiling and Detection (CPD) model to address them accordingly. We\nalso contribute a scalable inference algorithm, which scales linearly with the\ndata size and it is easily parallelizable. We evaluate CPD on large-scale\nreal-world data sets, and show that it is significantly better than the\nstate-of-the-art baselines in various tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 04:56:40 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Cai", "Hongyun", ""], ["Zheng", "Vincent W.", ""], ["Zhu", "Fanwei", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Huang", "Zi", ""]]}, {"id": "1701.04569", "submitter": "Timothy Ganesan PhD", "authors": "T.Ganesan, P.Vasant, I.Elamvazuthi", "title": "Multiobjective Optimization of Solar Powered Irrigation System with\n  Fuzzy Type-2 Noise Modelling", "comments": "27 pages, 12 Figures", "journal-ref": "2016, Emerging Research on Applied Fuzzy Sets and Intuitionistic\n  Fuzzy Matrices, IGI Global, 189 pages", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is becoming a crucial element in industrial applications\ninvolving sustainable alternative energy systems. During the design of such\nsystems, the engineer/decision maker would often encounter noise factors (e.g.\nsolar insolation and ambient temperature fluctuations) when their system\ninteracts with the environment. In this chapter, the sizing and design\noptimization of the solar powered irrigation system was considered. This\nproblem is multivariate, noisy, nonlinear and multiobjective. This design\nproblem was tackled by first using the Fuzzy Type II approach to model the\nnoise factors. Consequently, the Bacterial Foraging Algorithm (BFA) (in the\ncontext of a weighted sum framework) was employed to solve this multiobjective\nfuzzy design problem. This method was then used to construct the approximate\nPareto frontier as well as to identify the best solution option in a fuzzy\nsetting. Comprehensive analyses and discussions were performed on the generated\nnumerical results with respect to the implemented solution methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 08:52:48 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Ganesan", "T.", ""], ["Vasant", "P.", ""], ["Elamvazuthi", "I.", ""]]}, {"id": "1701.04645", "submitter": "Arnaud Martin", "authors": "Hosna Ouni (IRISA, DRUID), Arnaud Martin (IRISA, UR1, DRUID), Laetitia\n  Gros, Mouloud Kharoune (IRISA, DRUID), Zoltan Miklos (IRISA, DRUID)", "title": "Une mesure d'expertise pour le crowdsourcing", "comments": "in French", "journal-ref": "Extraction et Gestion des Connaissances (EGC), Jan 2017, Grenoble,\n  France. Extraction et Gestion de Connaisasnces, 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing, a major economic issue, is the fact that the firm outsources\ninternal task to the crowd. It is a form of digital subcontracting for the\ngeneral public. The evaluation of the participants work quality is a major\nissue in crowdsourcing. Indeed, contributions must be controlled to ensure the\neffectiveness and relevance of the campaign. We are particularly interested in\nsmall, fast and not automatable tasks. Several methods have been proposed to\nsolve this problem, but they are applicable when the \"golden truth\" is not\nalways known. This work has the particularity to propose a method for\ncalculating the degree of expertise in the presence of gold data in\ncrowdsourcing. This method is based on the belief function theory and proposes\na structuring of data using graphs. The proposed approach will be assessed and\napplied to the data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 12:35:36 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Ouni", "Hosna", "", "IRISA, DRUID"], ["Martin", "Arnaud", "", "IRISA, UR1, DRUID"], ["Gros", "Laetitia", "", "IRISA, DRUID"], ["Kharoune", "Mouloud", "", "IRISA, DRUID"], ["Miklos", "Zoltan", "", "IRISA, DRUID"]]}, {"id": "1701.04663", "submitter": "Varun Raj Kompella", "authors": "Varun Raj Kompella and Laurenz Wiskott", "title": "Intrinsically Motivated Acquisition of Modular Slow Features for\n  Humanoids in Continuous and Non-Stationary Environments", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compact information-rich representation of the environment, also called a\nfeature abstraction, can simplify a robot's task of mapping its raw sensory\ninputs to useful action sequences. However, in environments that are\nnon-stationary and only partially observable, a single abstraction is probably\nnot sufficient to encode most variations. Therefore, learning multiple sets of\nspatially or temporally local, modular abstractions of the inputs would be\nbeneficial. How can a robot learn these local abstractions without a teacher?\nMore specifically, how can it decide from where and when to start learning a\nnew abstraction? A recently proposed algorithm called Curious Dr. MISFA\naddresses this problem. The algorithm is based on two underlying learning\nprinciples called artificial curiosity and slowness. The former is used to make\nthe robot self-motivated to explore by rewarding itself whenever it makes\nprogress learning an abstraction; the later is used to update the abstraction\nby extracting slowly varying components from raw sensory inputs. Curious Dr.\nMISFA's application is, however, limited to discrete domains constrained by a\npre-defined state space and has design limitations that make it unstable in\ncertain situations. This paper presents a significant improvement that is\napplicable to continuous environments, is computationally less expensive,\nsimpler to use with fewer hyper parameters, and stable in certain\nnon-stationary environments. We demonstrate the efficacy and stability of our\nmethod in a vision-based robot simulator.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 13:24:37 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Kompella", "Varun Raj", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1701.04895", "submitter": "Samuel Albanie", "authors": "Samuel Albanie, Hillary Shakespeare and Tom Gunter", "title": "Unknowable Manipulators: Social Network Curator Algorithms", "comments": "NIPS Symposium 2016: Machine Learning and the Law", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a social networking service to acquire and retain users, it must find\nways to keep them engaged. By accurately gauging their preferences, it is able\nto serve them with the subset of available content that maximises revenue for\nthe site. Without the constraints of an appropriate regulatory framework, we\nargue that a sufficiently sophisticated curator algorithm tasked with\nperforming this process may choose to explore curation strategies that are\ndetrimental to users. In particular, we suggest that such an algorithm is\ncapable of learning to manipulate its users, for several qualitative reasons:\n1. Access to vast quantities of user data combined with ongoing breakthroughs\nin the field of machine learning are leading to powerful but uninterpretable\nstrategies for decision making at scale. 2. The availability of an effective\nfeedback mechanism for assessing the short and long term user responses to\ncuration strategies. 3. Techniques from reinforcement learning have allowed\nmachines to learn automated and highly successful strategies at an abstract\nlevel, often resulting in non-intuitive yet nonetheless highly appropriate\naction selection. In this work, we consider the form that these strategies for\nuser manipulation might take and scrutinise the role that regulation should\nplay in the design of such systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2017 22:52:24 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Albanie", "Samuel", ""], ["Shakespeare", "Hillary", ""], ["Gunter", "Tom", ""]]}, {"id": "1701.05004", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan Salehi Nobandegani, Thomas R. Shultz", "title": "Converting Cascade-Correlation Neural Nets into Probabilistic Generative\n  Models", "comments": null, "journal-ref": "Proceedings of the 39th Annual Conference of the Cognitive Science\n  Society (2017) (pp. 1029-1034). Austin, TX: Cognitive Science Society", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are not only adept in recognizing what class an input instance belongs\nto (i.e., classification task), but perhaps more remarkably, they can imagine\n(i.e., generate) plausible instances of a desired class with ease, when\nprompted. Inspired by this, we propose a framework which allows transforming\nCascade-Correlation Neural Networks (CCNNs) into probabilistic generative\nmodels, thereby enabling CCNNs to generate samples from a category of interest.\nCCNNs are a well-known class of deterministic, discriminative NNs, which\nautonomously construct their topology, and have been successful in giving\naccounts for a variety of psychological phenomena. Our proposed framework is\nbased on a Markov Chain Monte Carlo (MCMC) method, called the\nMetropolis-adjusted Langevin algorithm, which capitalizes on the gradient\ninformation of the target distribution to direct its explorations towards\nregions of high probability, thereby achieving good mixing properties. Through\nextensive simulations, we demonstrate the efficacy of our proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 10:51:58 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nobandegani", "Ardavan Salehi", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1701.05059", "submitter": "Abir M'Baya", "authors": "Abir M 'Baya (DISP), Jannik Laval (DISP), Nejib Moalla (DISP), Yacine\n  Ouzrout (DISP), Abdelaziz Bouras", "title": "Ontology based system to guide internship assignment process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internship assignment is a complicated process for universities since it is\nnecessary to take into account a multiplicity of variables to establish a\ncompromise between companies' requirements and student competencies acquired\nduring the university training. These variables build up a complex relations\nmap that requires the formulation of an exhaustive and rigorous conceptual\nscheme. In this research a domain ontological model is presented as support to\nthe student's decision making for opportunities of University studies level of\nthe University Lumiere Lyon 2 (ULL) education system. The ontology is designed\nand created using methodological approach offering the possibility of improving\nthe progressive creation, capture and knowledge articulation. In this paper, we\ndraw a balance taking the demands of the companies across the capabilities of\nthe students. This will be done through the establishment of an ontological\nmodel of an educational learners' profile and the internship postings which are\nwritten in a free text and using uncontrolled vocabulary. Furthermore, we\noutline the process of semantic matching which improves the quality of query\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 13:38:36 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["'Baya", "Abir M", "", "DISP"], ["Laval", "Jannik", "", "DISP"], ["Moalla", "Nejib", "", "DISP"], ["Ouzrout", "Yacine", "", "DISP"], ["Bouras", "Abdelaziz", ""]]}, {"id": "1701.05130", "submitter": "Rendani Mbuvha", "authors": "Ludvig Ericson, Rendani Mbuvha", "title": "On the Performance of Network Parallel Training in Artificial Neural\n  Networks", "comments": "4 Pages, 4 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) have received increasing attention in\nrecent years with applications that span a wide range of disciplines including\nvital domains such as medicine, network security and autonomous transportation.\nHowever, neural network architectures are becoming increasingly complex and\nwith an increasing need to obtain real-time results from such models, it has\nbecome pivotal to use parallelization as a mechanism for speeding up network\ntraining and deployment. In this work we propose an implementation of Network\nParallel Training through Cannon's Algorithm for matrix multiplication. We show\nthat increasing the number of processes speeds up training until the point\nwhere process communication costs become prohibitive; this point varies by\nnetwork complexity. We also show through empirical efficiency calculations that\nthe speedup obtained is superlinear.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 16:17:35 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Ericson", "Ludvig", ""], ["Mbuvha", "Rendani", ""]]}, {"id": "1701.05131", "submitter": "Lucas Lamata", "authors": "Lucas Lamata", "title": "Basic protocols in quantum reinforcement learning with superconducting\n  circuits", "comments": "Published version", "journal-ref": "Scientific Reports 7, 1609 (2017)", "doi": "10.1038/s41598-017-01711-6", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cond-mat.supr-con cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superconducting circuit technologies have recently achieved quantum protocols\ninvolving closed feedback loops. Quantum artificial intelligence and quantum\nmachine learning are emerging fields inside quantum technologies which may\nenable quantum devices to acquire information from the outer world and improve\nthemselves via a learning process. Here we propose the implementation of basic\nprotocols in quantum reinforcement learning, with superconducting circuits\nemploying feedback-loop control. We introduce diverse scenarios for\nproof-of-principle experiments with state-of-the-art superconducting circuit\ntechnologies and analyze their feasibility in presence of imperfections. The\nfield of quantum artificial intelligence implemented with superconducting\ncircuits paves the way for enhanced quantum control and quantum computation\nprotocols.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 16:18:22 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 07:48:33 GMT"}, {"version": "v3", "created": "Tue, 9 May 2017 09:50:14 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Lamata", "Lucas", ""]]}, {"id": "1701.05221", "submitter": "Nikolaos Fragoulis Dr", "authors": "I. Theodorakopoulos, V. Pothos, D. Kastaniotis and N. Fragoulis", "title": "Parsimonious Inference on Convolutional Neural Networks: Learning and\n  applying on-line kernel activation rules", "comments": "17 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new, radical CNN design approach is presented in this paper, considering\nthe reduction of the total computational load during inference. This is\nachieved by a new holistic intervention on both the CNN architecture and the\ntraining procedure, which targets to the parsimonious inference by learning to\nexploit or remove the redundant capacity of a CNN architecture. This is\naccomplished, by the introduction of a new structural element that can be\ninserted as an add-on to any contemporary CNN architecture, whilst preserving\nor even improving its recognition accuracy. Our approach formulates a\nsystematic and data-driven method for developing CNNs that are trained to\neventually change size and form in real-time during inference, targeting to the\nsmaller possible computational footprint. Results are provided for the optimal\nimplementation on a few modern, high-end mobile computing platforms indicating\na significant speed-up of up to x3 times.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 20:03:12 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 06:43:02 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2017 08:57:29 GMT"}, {"version": "v4", "created": "Thu, 26 Jan 2017 08:58:52 GMT"}, {"version": "v5", "created": "Tue, 31 Jan 2017 12:15:43 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Theodorakopoulos", "I.", ""], ["Pothos", "V.", ""], ["Kastaniotis", "D.", ""], ["Fragoulis", "N.", ""]]}, {"id": "1701.05226", "submitter": "Tarek Richard Besold", "authors": "Tarek R. Besold, Artur d'Avila Garcez, Keith Stenning, Leendert van\n  der Torre, Michiel van Lambalgen", "title": "Reasoning in Non-Probabilistic Uncertainty: Logic Programming and\n  Neural-Symbolic Computing as Examples", "comments": "Forthcoming with DOI 10.1007/s11023-017-9428-3 in the Special Issue\n  \"Reasoning with Imperfect Information and Knowledge\" of Minds and Machines\n  (2017). The final publication will be available at http://link.springer.com.\n  --- Changes to previous version: Fixed some typos and a broken reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to achieve two goals: to show that probability is not the\nonly way of dealing with uncertainty (and even more, that there are kinds of\nuncertainty which are for principled reasons not addressable with probabilistic\nmeans); and to provide evidence that logic-based methods can well support\nreasoning with uncertainty. For the latter claim, two paradigmatic examples are\npresented: Logic Programming with Kleene semantics for modelling reasoning from\ninformation in a discourse, to an interpretation of the state of affairs of the\nintended model, and a neural-symbolic implementation of Input/Output logic for\ndealing with uncertainty in dynamic normative contexts.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 20:38:55 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 15:36:37 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Besold", "Tarek R.", ""], ["Garcez", "Artur d'Avila", ""], ["Stenning", "Keith", ""], ["van der Torre", "Leendert", ""], ["van Lambalgen", "Michiel", ""]]}, {"id": "1701.05291", "submitter": "Zhipeng Huang", "authors": "Zhipeng Huang and Nikos Mamoulis", "title": "Heterogeneous Information Network Embedding for Meta Path based\n  Proximity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network embedding is a representation of a large graph in a low-dimensional\nspace, where vertices are modeled as vectors. The objective of a good embedding\nis to preserve the proximity between vertices in the original graph. This way,\ntypical search and mining methods can be applied in the embedded space with the\nhelp of off-the-shelf multidimensional indexing approaches. Existing network\nembedding techniques focus on homogeneous networks, where all vertices are\nconsidered to belong to a single class.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 04:00:46 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Huang", "Zhipeng", ""], ["Mamoulis", "Nikos", ""]]}, {"id": "1701.05311", "submitter": "Valentina Franzoni", "authors": "Valentina Franzoni, Yuanxi Li, Clement H.C.Leung and Alfredo Milani", "title": "Semantic Evolutionary Concept Distances for Effective Information\n  Retrieval in Query Expansion", "comments": "author's copy of publication in NLCS ICCSA 2013 proceedings:\n  Collective Evolutionary Concept Distance Based Query Expansion for Effective\n  Web Document Retrieval", "journal-ref": "Chapter Computational Science and Its Applications, ICCSA 2013,\n  Volume 7974 of the series Lecture Notes in Computer Science, pp 657-672", "doi": "10.1007/978-3-642-39649-6_47", "report-no": null, "categories": "cs.IR cs.AI cs.CL math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work several semantic approaches to concept-based query expansion and\nreranking schemes are studied and compared with different ontology-based\nexpansion methods in web document search and retrieval. In particular, we focus\non concept-based query expansion schemes, where, in order to effectively\nincrease the precision of web document retrieval and to decrease the users\nbrowsing time, the main goal is to quickly provide users with the most suitable\nquery expansion. Two key tasks for query expansion in web document retrieval\nare to find the expansion candidates, as the closest concepts in web document\ndomain, and to rank the expanded queries properly. The approach we propose aims\nat improving the expansion phase for better web document retrieval and\nprecision. The basic idea is to measure the distance between candidate concepts\nusing the PMING distance, a collaborative semantic proximity measure, i.e. a\nmeasure which can be computed by using statistical results from web search\nengine. Experiments show that the proposed technique can provide users with\nmore satisfying expansion results and improve the quality of web document\nretrieval.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 06:38:33 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Franzoni", "Valentina", ""], ["Li", "Yuanxi", ""], ["Leung", "Clement H. C.", ""], ["Milani", "Alfredo", ""]]}, {"id": "1701.05334", "submitter": "S.M. Riazul Islam PhD", "authors": "Farman Ali, D. Kwak, Pervez Khan, S.M. Riazul Islam, K.H. Kim, and\n  K.S. Kwak", "title": "Fuzzy Ontology-Based Sentiment Analysis of Transportation and City\n  Feature Reviews for Safe Traveling", "comments": "24 pages, 7 figures, Transportation Research Part C", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion is rapidly increasing in urban areas, particularly in mega\ncities. To date, there exist a few sensor network based systems to address this\nproblem. However, these techniques are not suitable enough in terms of\nmonitoring an entire transportation system and delivering emergency services\nwhen needed. These techniques require real-time data and intelligent ways to\nquickly determine traffic activity from useful information. In addition, these\nexisting systems and websites on city transportation and travel rely on rating\nscores for different factors (e.g., safety, low crime rate, cleanliness, etc.).\nThese rating scores are not efficient enough to deliver precise information,\nwhereas reviews or tweets are significant, because they help travelers and\ntransportation administrators to know about each aspect of the city. However,\nit is difficult for travelers to read, and for transportation systems to\nprocess, all reviews and tweets to obtain expressive sentiments regarding the\nneeds of the city. The optimum solution for this kind of problem is analyzing\nthe information available on social network platforms and performing sentiment\nanalysis. On the other hand, crisp ontology-based frameworks cannot extract\nblurred information from tweets and reviews; therefore, they produce inadequate\nresults. In this regard, this paper proposes fuzzy ontology-based sentiment\nanalysis and SWRL rule-based decision-making to monitor transportation\nactivities and to make a city- feature polarity map for travelers. This system\nretrieves reviews and tweets related to city features and transportation\nactivities. The feature opinions are extracted from these retrieved data, and\nthen fuzzy ontology is used to determine the transportation and city-feature\npolarity. A fuzzy ontology and an intelligent system prototype are developed by\nusing Prot\\'eg\\'e OWL and Java, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 08:50:37 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Ali", "Farman", ""], ["Kwak", "D.", ""], ["Khan", "Pervez", ""], ["Islam", "S. M. Riazul", ""], ["Kim", "K. H.", ""], ["Kwak", "K. S.", ""]]}, {"id": "1701.05498", "submitter": "Tomas Hodan", "authors": "Tomas Hodan, Pavel Haluza, Stepan Obdrzalek, Jiri Matas, Manolis\n  Lourakis, Xenophon Zabulis", "title": "T-LESS: An RGB-D Dataset for 6D Pose Estimation of Texture-less Objects", "comments": "WACV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce T-LESS, a new public dataset for estimating the 6D pose, i.e.\ntranslation and rotation, of texture-less rigid objects. The dataset features\nthirty industry-relevant objects with no significant texture and no\ndiscriminative color or reflectance properties. The objects exhibit symmetries\nand mutual similarities in shape and/or size. Compared to other datasets, a\nunique property is that some of the objects are parts of others. The dataset\nincludes training and test images that were captured with three synchronized\nsensors, specifically a structured-light and a time-of-flight RGB-D sensor and\na high-resolution RGB camera. There are approximately 39K training and 10K test\nimages from each sensor. Additionally, two types of 3D models are provided for\neach object, i.e. a manually created CAD model and a semi-automatically\nreconstructed one. Training images depict individual objects against a black\nbackground. Test images originate from twenty test scenes having varying\ncomplexity, which increases from simple scenes with several isolated objects to\nvery challenging ones with multiple instances of several objects and with a\nhigh amount of clutter and occlusion. The images were captured from a\nsystematically sampled view sphere around the object/scene, and are annotated\nwith accurate ground truth 6D poses of all modeled objects. Initial evaluation\nresults indicate that the state of the art in 6D object pose estimation has\nample room for improvement, especially in difficult cases with significant\nocclusion. The T-LESS dataset is available online at cmp.felk.cvut.cz/t-less.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 16:16:36 GMT"}], "update_date": "2017-01-20", "authors_parsed": [["Hodan", "Tomas", ""], ["Haluza", "Pavel", ""], ["Obdrzalek", "Stepan", ""], ["Matas", "Jiri", ""], ["Lourakis", "Manolis", ""], ["Zabulis", "Xenophon", ""]]}, {"id": "1701.05724", "submitter": "Vinh Nguyen", "authors": "Vinh Nguyen and Amit Sheth", "title": "Logical Inferences with Contexts of RDF Triples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical inference, an integral feature of the Semantic Web, is the process of\nderiving new triples by applying entailment rules on knowledge bases. The\nentailment rules are determined by the model-theoretic semantics. Incorporating\ncontext of an RDF triple (e.g., provenance, time, and location) into the\ninferencing process requires the formal semantics to be capable of describing\nthe context of RDF triples also in the form of triples, or in other words, RDF\ncontextual triples about triples. The formal semantics should also provide the\nrules that could entail new contextual triples about triples. In this paper, we\npropose the first inferencing mechanism that allows context of RDF triples,\nrepresented in the form of RDF triples about triples, to be the first-class\ncitizens in the model-theoretic semantics and in the logical rules. Our\ninference mechanism is well-formalized with all new concepts being captured in\nthe model-theoretic semantics. This formal semantics also allows us to derive a\nnew set of entailment rules that could entail new contextual triples about\ntriples. To demonstrate the feasibility and the scalability of the proposed\nmechanism, we implement a new tool in which we transform the existing knowledge\nbases to our representation of RDF triples about triples and provide the option\nfor this tool to compute the inferred triples for the proposed rules. We\nevaluate the computation of the proposed rules on a large scale using various\nreal-world knowledge bases such as Bio2RDF NCBI Genes and DBpedia. The results\nshow that the computation of the inferred triples can be highly scalable. On\naverage, one billion inferred triples adds 5-6 minutes to the overall\ntransformation process. NCBI Genes, with 20 billion triples in total, took only\n232 minutes for the transformation of 12 billion triples and added 42 minutes\nfor inferring 8 billion triples to the overall process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 08:51:41 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Nguyen", "Vinh", ""], ["Sheth", "Amit", ""]]}, {"id": "1701.06049", "submitter": "James MacGlashan", "authors": "James MacGlashan, Mark K Ho, Robert Loftin, Bei Peng, David Roberts,\n  Matthew E. Taylor, Michael L. Littman", "title": "Interactive Learning from Policy-Dependent Human Feedback", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For agents and robots to become more useful, they must be able to quickly\nlearn from non-technical users. This paper investigates the problem of\ninteractively learning behaviors communicated by a human teacher using positive\nand negative feedback. Much previous work on this problem has made the\nassumption that people provide feedback for decisions that is dependent on the\nbehavior they are teaching and is independent from the learner's current\npolicy. We present empirical results that show this assumption to be\nfalse---whether human trainers give a positive or negative feedback for a\ndecision is influenced by the learner's current policy. We argue that\npolicy-dependent feedback, in addition to being commonplace, enables useful\ntraining strategies from which agents should benefit. Based on this insight, we\nintroduce Convergent Actor-Critic by Humans (COACH), an algorithm for learning\nfrom policy-dependent feedback that converges to a local optimum. Finally, we\ndemonstrate that COACH can successfully learn multiple behaviors on a physical\nrobot, even with noisy image features.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 16:37:41 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["MacGlashan", "James", ""], ["Ho", "Mark K", ""], ["Loftin", "Robert", ""], ["Peng", "Bei", ""], ["Roberts", "David", ""], ["Taylor", "Matthew E.", ""], ["Littman", "Michael L.", ""]]}, {"id": "1701.06075", "submitter": "Linhong Zhu", "authors": "Dingxiong Deng, Fan Bai, Yiqi Tang, Shuigeng Zhou, Cyrus Shahabi,\n  Linhong Zhu", "title": "Label Propagation on K-partite Graphs with Heterophily", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, for the first time, we study label propagation in\nheterogeneous graphs under heterophily assumption. Homophily label propagation\n(i.e., two connected nodes share similar labels) in homogeneous graph (with\nsame types of vertices and relations) has been extensively studied before.\nUnfortunately, real-life networks are heterogeneous, they contain different\ntypes of vertices (e.g., users, images, texts) and relations (e.g.,\nfriendships, co-tagging) and allow for each node to propagate both the same and\nopposite copy of labels to its neighbors. We propose a $\\mathcal{K}$-partite\nlabel propagation model to handle the mystifying combination of heterogeneous\nnodes/relations and heterophily propagation. With this model, we develop a\nnovel label inference algorithm framework with update rules in near-linear time\ncomplexity. Since real networks change over time, we devise an incremental\napproach, which supports fast updates for both new data and evidence (e.g.,\nground truth labels) with guaranteed efficiency. We further provide a utility\nfunction to automatically determine whether an incremental or a re-modeling\napproach is favored. Extensive experiments on real datasets have verified the\neffectiveness and efficiency of our approach, and its superiority over the\nstate-of-the-art label propagation methods.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 19:47:38 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Deng", "Dingxiong", ""], ["Bai", "Fan", ""], ["Tang", "Yiqi", ""], ["Zhou", "Shuigeng", ""], ["Shahabi", "Cyrus", ""], ["Zhu", "Linhong", ""]]}, {"id": "1701.06078", "submitter": "Sungkyun Chang", "authors": "Sungkyun Chang, Kyogu Lee", "title": "Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive\n  Patterns in Vowel Acoustics", "comments": "13 pages", "journal-ref": "IEEE Access, Vol. 5, (2017) 16635-16648", "doi": "10.1109/ACCESS.2017.2738558", "report-no": null, "categories": "cs.SD cs.AI cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the previous approaches to lyrics-to-audio alignment used a\npre-developed automatic speech recognition (ASR) system that innately suffered\nfrom several difficulties to adapt the speech model to individual singers. A\nsignificant aspect missing in previous works is the self-learnability of\nrepetitive vowel patterns in the singing voice, where the vowel part used is\nmore consistent than the consonant part. Based on this, our system first learns\na discriminative subspace of vowel sequences, based on weighted symmetric\nnon-negative matrix factorization (WS-NMF), by taking the self-similarity of a\nstandard acoustic feature as an input. Then, we make use of canonical time\nwarping (CTW), derived from a recent computer vision technique, to find an\noptimal spatiotemporal transformation between the text and the acoustic\nsequences. Experiments with Korean and English data sets showed that deploying\nthis method after a pre-developed, unsupervised, singing source separation\nachieved more promising results than other state-of-the-art unsupervised\napproaches and an existing ASR-based system.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2017 20:15:08 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 16:25:15 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chang", "Sungkyun", ""], ["Lee", "Kyogu", ""]]}, {"id": "1701.06106", "submitter": "Sahil Garg", "authors": "Sahil Garg, Irina Rish, Guillermo Cecchi, Aurelie Lozano", "title": "Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a\n  Changing World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on online representation learning in non-stationary\nenvironments which may require continuous adaptation of model architecture. We\npropose a novel online dictionary-learning (sparse-coding) framework which\nincorporates the addition and deletion of hidden units (dictionary elements),\nand is inspired by the adult neurogenesis phenomenon in the dentate gyrus of\nthe hippocampus, known to be associated with improved cognitive function and\nadaptation to new environments. In the online learning setting, where new input\ninstances arrive sequentially in batches, the neuronal-birth is implemented by\nadding new units with random initial weights (random dictionary elements); the\nnumber of new units is determined by the current performance (representation\nerror) of the dictionary, higher error causing an increase in the birth rate.\nNeuronal-death is implemented by imposing l1/l2-regularization (group sparsity)\non the dictionary within the block-coordinate descent optimization at each\niteration of our online alternating minimization scheme, which iterates between\nthe code and dictionary updates. Finally, hidden unit connectivity adaptation\nis facilitated by introducing sparsity in dictionary elements. Our empirical\nevaluation on several real-life datasets (images and language) as well as on\nsynthetic data demonstrates that the proposed approach can considerably\noutperform the state-of-art fixed-size (nonadaptive) online sparse coding of\nMairal et al. (2009) in the presence of nonstationary data. Moreover, we\nidentify certain properties of the data (e.g., sparse inputs with nearly\nnon-overlapping supports) and of the model (e.g., dictionary sparsity)\nassociated with such improvements.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 00:35:24 GMT"}, {"version": "v2", "created": "Sun, 19 Feb 2017 08:15:55 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Garg", "Sahil", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Lozano", "Aurelie", ""]]}, {"id": "1701.06167", "submitter": "\\c{C}a\\u{g}r{\\i} Latifo\\u{g}lu", "authors": "\\c{C}a\\u{g}r{\\i} Latifo\\u{g}lu", "title": "Binary Matrix Guessing Problem", "comments": "9 pages, 4 tables reason for withdrawal: Paper will be rewritten with\n  experiments replicated on verified and validated hardware and software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Binary Matrix Guessing Problem and provide two algorithms to\nsolve this problem. The first algorithm we introduce is Elementwise Probing\nAlgorithm (EPA) which is very fast under a score which utilizes Frobenius\nDistance. The second algorithm is Additive Reinforcement Learning Algorithm\nwhich combines ideas from perceptron algorithm and reinforcement learning\nalgorithm. This algorithm is significantly slower compared to first one, but\nless restrictive and generalizes better. We compare computational performance\nof both algorithms and provide numerical results.\n  reason for withdrawal: Paper will be rewritten with experiments replicated on\nverified and validated hardware and software.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 14:19:25 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 10:33:17 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Latifo\u011flu", "\u00c7a\u011fr\u0131", ""]]}, {"id": "1701.06233", "submitter": "Tianran Hu", "authors": "Tianran Hu, Haoyuan Xiao, Thuy-vy Thi Nguyen, Jiebo Luo", "title": "What the Language You Tweet Says About Your Occupation", "comments": "Published at the 10th International AAAI Conference on Web and Social\n  Media (ICWSM-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many aspects of people's lives are proven to be deeply connected to their\njobs. In this paper, we first investigate the distinct characteristics of major\noccupation categories based on tweets. From multiple social media platforms, we\ngather several types of user information. From users' LinkedIn webpages, we\nlearn their proficiencies. To overcome the ambiguity of self-reported\ninformation, a soft clustering approach is applied to extract occupations from\ncrowd-sourced data. Eight job categories are extracted, including Marketing,\nAdministrator, Start-up, Editor, Software Engineer, Public Relation, Office\nClerk, and Designer. Meanwhile, users' posts on Twitter provide cues for\nunderstanding their linguistic styles, interests, and personalities. Our\nresults suggest that people of different jobs have unique tendencies in certain\nlanguage styles and interests. Our results also clearly reveal distinctive\nlevels in terms of Big Five Traits for different jobs. Finally, a classifier is\nbuilt to predict job types based on the features extracted from tweets. A high\naccuracy indicates a strong discrimination power of language features for job\nprediction task.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2017 23:03:11 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Hu", "Tianran", ""], ["Xiao", "Haoyuan", ""], ["Nguyen", "Thuy-vy Thi", ""], ["Luo", "Jiebo", ""]]}, {"id": "1701.06247", "submitter": "Hongjie Shi", "authors": "Hongjie Shi, Takashi Ushio, Mitsuru Endo, Katsuyoshi Yamagami, Noriaki\n  Horii", "title": "A Multichannel Convolutional Neural Network For Cross-language Dialog\n  State Tracking", "comments": "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken\n  Language Technology (SLT 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth Dialog State Tracking Challenge (DSTC5) introduces a new\ncross-language dialog state tracking scenario, where the participants are asked\nto build their trackers based on the English training corpus, while evaluating\nthem with the unlabeled Chinese corpus. Although the computer-generated\ntranslations for both English and Chinese corpus are provided in the dataset,\nthese translations contain errors and careless use of them can easily hurt the\nperformance of the built trackers. To address this problem, we propose a\nmultichannel Convolutional Neural Networks (CNN) architecture, in which we\ntreat English and Chinese language as different input channels of one single\nCNN model. In the evaluation of DSTC5, we found that such multichannel\narchitecture can effectively improve the robustness against translation errors.\nAdditionally, our method for DSTC5 is purely machine learning based and\nrequires no prior knowledge about the target language. We consider this a\ndesirable property for building a tracker in the cross-language context, as not\nevery developer will be familiar with both languages.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 01:36:10 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Shi", "Hongjie", ""], ["Ushio", "Takashi", ""], ["Endo", "Mitsuru", ""], ["Yamagami", "Katsuyoshi", ""], ["Horii", "Noriaki", ""]]}, {"id": "1701.06388", "submitter": "Emmanuel Hebrard", "authors": "Emmanuel H\\'ebrard (LAAS-ROC), Marie-Jos\\'e Huguet (LAAS-ROC), Daniel\n  Veysseire (LAAS-ROC), Ludivine Sauvan (LAAS-ROC), Bertrand Cabon", "title": "Constraint programming for planning test campaigns of communications\n  satellites", "comments": null, "journal-ref": "Constraints, Springer Verlag, 2017, 22, pp.73 - 89", "doi": "10.1007/s10601-016-9254-x", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The payload of communications satellites must go through a series of tests to\nassert their ability to survive in space. Each test involves some equipment of\nthe payload to be active, which has an impact on the temperature of the\npayload. Sequencing these tests in a way that ensures the thermal stability of\nthe payload and minimizes the overall duration of the test campaign is a very\nimportant objective for satellite manufacturers. The problem can be decomposed\nin two sub-problems corresponding to two objectives: First, the number of\ndistinct configurations necessary to run the tests must be minimized. This can\nbe modeled as packing the tests into configurations, and we introduce a set of\nimplied constraints to improve the lower bound of the model. Second, tests must\nbe sequenced so that the number of times an equipment unit has to be switched\non or off is minimized. We model this aspect using the constraint Switch, where\na buffer with limited capacity represents the currently active equipment units,\nand we introduce an improvement of the propagation algorithm for this\nconstraint. We then introduce a search strategy in which we sequentially solve\nthe sub-problems (packing and sequencing). Experiments conducted on real and\nrandom instances show the respective interest of our contributions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 13:48:35 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["H\u00e9brard", "Emmanuel", "", "LAAS-ROC"], ["Huguet", "Marie-Jos\u00e9", "", "LAAS-ROC"], ["Veysseire", "Daniel", "", "LAAS-ROC"], ["Sauvan", "Ludivine", "", "LAAS-ROC"], ["Cabon", "Bertrand", ""]]}, {"id": "1701.06450", "submitter": "Andrea Baisero", "authors": "Andrea Baisero, Stefan Otte, Peter Englert and Marc Toussaint", "title": "Identification of Unmodeled Objects from Symbolic Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful human-robot cooperation hinges on each agent's ability to process\nand exchange information about the shared environment and the task at hand.\nHuman communication is primarily based on symbolic abstractions of object\nproperties, rather than precise quantitative measures. A comprehensive robotic\nframework thus requires an integrated communication module which is able to\nestablish a link and convert between perceptual and abstract information.\n  The ability to interpret composite symbolic descriptions enables an\nautonomous agent to a) operate in unstructured and cluttered environments, in\ntasks which involve unmodeled or never seen before objects; and b) exploit the\naggregation of multiple symbolic properties as an instance of ensemble\nlearning, to improve identification performance even when the individual\npredicates encode generic information or are imprecisely grounded.\n  We propose a discriminative probabilistic model which interprets symbolic\ndescriptions to identify the referent object contextually w.r.t.\\ the structure\nof the environment and other objects. The model is trained using a collected\ndataset of identifications, and its performance is evaluated by quantitative\nmeasures and a live demo developed on the PR2 robot platform, which integrates\nelements of perception, object extraction, object identification and grasping.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 15:26:01 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Baisero", "Andrea", ""], ["Otte", "Stefan", ""], ["Englert", "Peter", ""], ["Toussaint", "Marc", ""]]}, {"id": "1701.06532", "submitter": "Jan Jakubuv", "authors": "Jan Jakub\\r{u}v, Josef Urban", "title": "ENIGMA: Efficient Learning-based Inference Guiding Machine", "comments": "Submitted to LPAR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ENIGMA is a learning-based method for guiding given clause selection in\nsaturation-based theorem provers. Clauses from many proof searches are\nclassified as positive and negative based on their participation in the proofs.\nAn efficient classification model is trained on this data, using fast\nfeature-based characterization of the clauses . The learned model is then\ntightly linked with the core prover and used as a basis of a new parameterized\nevaluation heuristic that provides fast ranking of all generated clauses. The\napproach is evaluated on the E prover and the CASC 2016 AIM benchmark, showing\na large increase of E's performance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 18:03:52 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Urban", "Josef", ""]]}, {"id": "1701.06635", "submitter": "Abhinav Jauhri", "authors": "Abhinav Jauhri, Brian Foo, Jerome Berclaz, Chih Chi Hu, Radek\n  Grzeszczuk, Vasu Parameswaran, John Paul Shen", "title": "Space-Time Graph Modeling of Ride Requests Based on Real-World Data", "comments": "Accepted at AAAI-17 Workshop on AI and OR for Social Good\n  (AIORSocGood-17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on modeling ride requests and their variations over\nlocation and time, based on analyzing extensive real-world data from a\nride-sharing service. We introduce a graph model that captures the spatial and\ntemporal variability of ride requests and the potentials for ride pooling. We\ndiscover these ride request graphs exhibit a well known property called\ndensification power law often found in real graphs modelling human behaviors.\nWe show the pattern of ride requests and the potential of ride pooling for a\ncity can be characterized by the densification factor of the ride request\ngraphs. Previous works have shown that it is possible to automatically generate\nsynthetic versions of these graphs that exhibit a given densification factor.\nWe present an algorithm for automatic generation of synthetic ride request\ngraphs that match quite well the densification factor of ride request graphs\nfrom actual ride request data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 21:18:33 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Jauhri", "Abhinav", ""], ["Foo", "Brian", ""], ["Berclaz", "Jerome", ""], ["Hu", "Chih Chi", ""], ["Grzeszczuk", "Radek", ""], ["Parameswaran", "Vasu", ""], ["Shen", "John Paul", ""]]}, {"id": "1701.06641", "submitter": "Valero Laparra", "authors": "Valero Laparra, Alex Berardino, Johannes Ball\\'e, and Eero P.\n  Simoncelli", "title": "Perceptually Optimized Image Rendering", "comments": null, "journal-ref": "J. Optical Society of America, A. 34(9):1511-1525. Sep 2017", "doi": "10.1364/JOSAA.34.001511", "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for rendering photographic images, taking into account\ndisplay limitations, so as to optimize perceptual similarity between the\nrendered image and the original scene. We formulate this as a constrained\noptimization problem, in which we minimize a measure of perceptual\ndissimilarity, the Normalized Laplacian Pyramid Distance (NLPD), which mimics\nthe early stage transformations of the human visual system. When rendering\nimages acquired with higher dynamic range than that of the display, we find\nthat the optimized solution boosts the contrast of low-contrast features\nwithout introducing significant artifacts, yielding results of comparable\nvisual quality to current state-of-the art methods with no manual intervention\nor parameter settings. We also examine a variety of other display constraints,\nincluding limitations on minimum luminance (black point), mean luminance (as a\nproxy for energy consumption), and quantized luminance levels (halftoning).\nFinally, we show that the method may be used to enhance details and contrast of\nimages degraded by optical scattering (e.g. fog).\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 21:38:52 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Laparra", "Valero", ""], ["Berardino", "Alex", ""], ["Ball\u00e9", "Johannes", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1701.06699", "submitter": "Jeremy Morton", "authors": "Alex Kuefler, Jeremy Morton, Tim Wheeler, Mykel Kochenderfer", "title": "Imitating Driver Behavior with Generative Adversarial Networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict and simulate human driving behavior is\ncritical for the development of intelligent transportation systems. Traditional\nmodeling methods have employed simple parametric models and behavioral cloning.\nThis paper adopts a method for overcoming the problem of cascading errors\ninherent in prior approaches, resulting in realistic behavior that is robust to\ntrajectory perturbations. We extend Generative Adversarial Imitation Learning\nto the training of recurrent policies, and we demonstrate that our model\noutperforms rule-based controllers and maximum likelihood models in realistic\nhighway simulations. Our model both reproduces emergent behavior of human\ndrivers, such as lane change rate, while maintaining realistic control over\nlong time horizons.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 00:59:42 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Kuefler", "Alex", ""], ["Morton", "Jeremy", ""], ["Wheeler", "Tim", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1701.06745", "submitter": "EPTCS", "authors": "Serge Autexier, Pedro Quaresma", "title": "Proceedings of the 12th Workshop on User Interfaces for Theorem Provers", "comments": null, "journal-ref": "EPTCS 239, 2017", "doi": "10.4204/EPTCS.239", "report-no": null, "categories": "cs.HC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The UITP workshop series brings together researchers interested in designing,\ndeveloping and evaluating user interfaces for automated reasoning tools, such\nas interactive proof assistants, automated theorem provers, model finders,\ntools for formal methods, and tools for visualising and manipulating logical\nformulas and proofs. The twelth edition of UITP took place in Coimbra,\nPortugal, and was part of the International Joint Conference on Automated\nReasoning (IJCAR'16). The workshop consisted of an invited talk, six\npresentations of submitted papers and lively hands-on session for reasoning\ntools and their user-interface. These post-proceedings contain four contributed\npapers accepted for publication after a second round of reviewing after the\nworkshop as well as the invited paper.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 06:26:01 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Autexier", "Serge", ""], ["Quaresma", "Pedro", ""]]}, {"id": "1701.06852", "submitter": "Huynh Van Luong", "authors": "Huynh Van Luong, Nikos Deligiannis, Jurgen Seiler, Soren Forchhammer,\n  and Andre Kaup", "title": "Incorporating Prior Information in Compressive Online Robust Principal\n  Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online version of the robust Principle Component Analysis\n(PCA), which arises naturally in time-varying source separations such as video\nforeground-background separation. This paper proposes a compressive online\nrobust PCA with prior information for recursively separating a sequences of\nframes into sparse and low-rank components from a small set of measurements. In\ncontrast to conventional batch-based PCA, which processes all the frames\ndirectly, the proposed method processes measurements taken from each frame.\nMoreover, this method can efficiently incorporate multiple prior information,\nnamely previous reconstructed frames, to improve the separation and thereafter,\nupdate the prior information for the next frame. We utilize multiple prior\ninformation by solving $n\\text{-}\\ell_{1}$ minimization for incorporating the\nprevious sparse components and using incremental singular value decomposition\n($\\mathrm{SVD}$) for exploiting the previous low-rank components. We also\nestablish theoretical bounds on the number of measurements required to\nguarantee successful separation under assumptions of static or slowly-changing\nlow-rank components. Using numerical experiments, we evaluate our bounds and\nthe performance of the proposed algorithm. In addition, we apply the proposed\nalgorithm to online video foreground and background separation from compressive\nmeasurements. Experimental results show that the proposed method outperforms\nthe existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 13:02:27 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 14:36:22 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Van Luong", "Huynh", ""], ["Deligiannis", "Nikos", ""], ["Seiler", "Jurgen", ""], ["Forchhammer", "Soren", ""], ["Kaup", "Andre", ""]]}, {"id": "1701.06972", "submitter": "Sarah Loos", "authors": "Sarah Loos, Geoffrey Irving, Christian Szegedy, Cezary Kaliszyk", "title": "Deep Network Guided Proof Search", "comments": null, "journal-ref": "In Thomas Eiter and David Sands, editors, 21st International\n  Conference on Logic for Programming, Artificial Intelligence and Reasoning\n  (LPAR-21). EPiC Series in Computing, vol. 46, pages 85-105, EasyChair, 2017.\n  ISSN 2398-7340", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques lie at the heart of several significant AI advances\nin recent years including object recognition and detection, image captioning,\nmachine translation, speech recognition and synthesis, and playing the game of\nGo. Automated first-order theorem provers can aid in the formalization and\nverification of mathematical theorems and play a crucial role in program\nanalysis, theory reasoning, security, interpolation, and system verification.\nHere we suggest deep learning based guidance in the proof search of the theorem\nprover E. We train and compare several deep neural network models on the traces\nof existing ATP proofs of Mizar statements and use them to select processed\nclauses during proof search. We give experimental evidence that with a hybrid,\ntwo-phase approach, deep learning based guidance can significantly reduce the\naverage number of proof search steps while increasing the number of theorems\nproved. Using a few proof guidance strategies that leverage deep neural\nnetworks, we have found first-order proofs of 7.36% of the first-order logic\ntranslations of the Mizar Mathematical Library theorems that did not previously\nhave ATP generated proofs. This increases the ratio of statements in the corpus\nwith ATP generated proofs from 56% to 59%.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 16:39:05 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Loos", "Sarah", ""], ["Irving", "Geoffrey", ""], ["Szegedy", "Christian", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1701.07103", "submitter": "Amir Husain", "authors": "Amir Husain (1), Bruce Porter (2) ((1) SparkCognition Inc. (2)\n  Department of Computer Science, University of Texas at Austin)", "title": "Artificial Intelligence Approaches To UCAV Autonomy", "comments": "12 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper covers a number of approaches that leverage Artificial\nIntelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle\n(UCAV) autonomy. An analysis of current approaches to autonomous control is\nprovided followed by an exploration of how these techniques can be extended and\nenriched with AI techniques including Artificial Neural Networks (ANN),\nEnsembling and Reinforcement Learning (RL) to evolve control strategies for\nUCAVs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 23:11:15 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Husain", "Amir", ""], ["Porter", "Bruce", ""]]}, {"id": "1701.07123", "submitter": "EPTCS", "authors": "Guillermo Vigueras (IMDEA Software Institute), Manuel Carro (IMDEA\n  Software Institute and Universidad Polit\\'ecnica de Madrid), Salvador Tamarit\n  (Universidad Polit\\'ecnica de Madrid), Julio Mari\\~no (Universidad\n  Polit\\'ecnica de Madrid)", "title": "Towards Automatic Learning of Heuristics for Mechanical Transformations\n  of Procedural Code", "comments": "In Proceedings PROLE 2016, arXiv:1701.03069. This paper is based on\n  arXiv:1603.03022, and has a thorough description of the proposed approach", "journal-ref": "EPTCS 237, 2017, pp. 52-67", "doi": "10.4204/EPTCS.237.4", "report-no": "EPTCS 1701", "categories": "cs.PL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current trends in next-generation exascale systems go towards integrating\na wide range of specialized (co-)processors into traditional supercomputers.\nDue to the efficiency of heterogeneous systems in terms of Watts and FLOPS per\nsurface unit, opening the access of heterogeneous platforms to a wider range of\nusers is an important problem to be tackled. However, heterogeneous platforms\nlimit the portability of the applications and increase development complexity\ndue to the programming skills required. Program transformation can help make\nprogramming heterogeneous systems easier by defining a step-wise transformation\nprocess that translates a given initial code into a semantically equivalent\nfinal code, but adapted to a specific platform. Program transformation systems\nrequire the definition of efficient transformation strategies to tackle the\ncombinatorial problem that emerges due to the large set of transformations\napplicable at each step of the process. In this paper we propose a machine\nlearning-based approach to learn heuristics to define program transformation\nstrategies. Our approach proposes a novel combination of reinforcement learning\nand classification methods to efficiently tackle the problems inherent to this\ntype of systems. Preliminary results demonstrate the suitability of this\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 01:20:34 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Vigueras", "Guillermo", "", "IMDEA Software Institute"], ["Carro", "Manuel", "", "IMDEA\n  Software Institute and Universidad Polit\u00e9cnica de Madrid"], ["Tamarit", "Salvador", "", "Universidad Polit\u00e9cnica de Madrid"], ["Mari\u00f1o", "Julio", "", "Universidad\n  Polit\u00e9cnica de Madrid"]]}, {"id": "1701.07204", "submitter": "Kasper Green Larsen", "authors": "Allan Gr{\\o}nlund and Kasper Green Larsen and Alexander Mathiasen and\n  Jesper Sindahl Nielsen and Stefan Schneider and Mingzhou Song", "title": "Fast Exact k-Means, k-Medians and Bregman Divergence Clustering in 1D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $k$-Means clustering problem on $n$ points is NP-Hard for any dimension\n$d\\ge 2$, however, for the 1D case there exists exact polynomial time\nalgorithms. Previous literature reported an $O(kn^2)$ time dynamic programming\nalgorithm that uses $O(kn)$ space. It turns out that the problem has been\nconsidered under a different name more than twenty years ago. We present all\nthe existing work that had been overlooked and compare the various solutions\ntheoretically. Moreover, we show how to reduce the space usage for some of\nthem, as well as generalize them to data structures that can quickly report an\noptimal $k$-Means clustering for any $k$. Finally we also generalize all the\nalgorithms to work for the absolute distance and to work for any Bregman\nDivergence. We complement our theoretical contributions by experiments that\ncompare the practical performance of the various algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 08:44:04 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 20:40:50 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 10:37:16 GMT"}, {"version": "v4", "created": "Wed, 25 Apr 2018 10:36:08 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Larsen", "Kasper Green", ""], ["Mathiasen", "Alexander", ""], ["Nielsen", "Jesper Sindahl", ""], ["Schneider", "Stefan", ""], ["Song", "Mingzhou", ""]]}, {"id": "1701.07232", "submitter": "Rishabh Singh", "authors": "Patrice Godefroid, Hila Peleg, Rishabh Singh", "title": "Learn&Fuzz: Machine Learning for Input Fuzzing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing consists of repeatedly testing an application with modified, or\nfuzzed, inputs with the goal of finding security vulnerabilities in\ninput-parsing code. In this paper, we show how to automate the generation of an\ninput grammar suitable for input fuzzing using sample inputs and\nneural-network-based statistical machine-learning techniques. We present a\ndetailed case study with a complex input format, namely PDF, and a large\ncomplex security-critical parser for this format, namely, the PDF parser\nembedded in Microsoft's new Edge browser. We discuss (and measure) the tension\nbetween conflicting learning and fuzzing goals: learning wants to capture the\nstructure of well-formed inputs, while fuzzing wants to break that structure in\norder to cover unexpected code paths and find bugs. We also present a new\nalgorithm for this learn&fuzz challenge which uses a learnt input probability\ndistribution to intelligently guide where to fuzz inputs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2017 10:01:39 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Godefroid", "Patrice", ""], ["Peleg", "Hila", ""], ["Singh", "Rishabh", ""]]}, {"id": "1701.07396", "submitter": "Christian Reul", "authors": "Christian Reul, Uwe Springmann, and Frank Puppe", "title": "LAREX - A semi-automatic open-source Tool for Layout Analysis and Region\n  Extraction on Early Printed Books", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-automatic open-source tool for layout analysis on early printed books\nis presented. LAREX uses a rule based connected components approach which is\nvery fast, easily comprehensible for the user and allows an intuitive manual\ncorrection if necessary. The PageXML format is used to support integration into\nexisting OCR workflows. Evaluations showed that LAREX provides an efficient and\nflexible way to segment pages of early printed books.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2017 09:48:59 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Reul", "Christian", ""], ["Springmann", "Uwe", ""], ["Puppe", "Frank", ""]]}, {"id": "1701.07398", "submitter": "Alon Hazan", "authors": "Alon Hazan, Yuval Harel and Ron Meir", "title": "Learning an attention model in an artificial visual system", "comments": null, "journal-ref": "IEEE International Conference on the Science of Electrical\n  Engineering (ICSEE) (2016)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Human visual perception of the world is of a large fixed image that is\nhighly detailed and sharp. However, receptor density in the retina is not\nuniform: a small central region called the fovea is very dense and exhibits\nhigh resolution, whereas a peripheral region around it has much lower spatial\nresolution. Thus, contrary to our perception, we are only able to observe a\nvery small region around the line of sight with high resolution. The perception\nof a complete and stable view is aided by an attention mechanism that directs\nthe eyes to the numerous points of interest within the scene. The eyes move\nbetween these targets in quick, unconscious movements, known as \"saccades\".\nOnce a target is centered at the fovea, the eyes fixate for a fraction of a\nsecond while the visual system extracts the necessary information. An\nartificial visual system was built based on a fully recurrent neural network\nset within a reinforcement learning protocol, and learned to attend to regions\nof interest while solving a classification task. The model is consistent with\nseveral experimentally observed phenomena, and suggests novel predictions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 09:07:59 GMT"}], "update_date": "2017-01-26", "authors_parsed": [["Hazan", "Alon", ""], ["Harel", "Yuval", ""], ["Meir", "Ron", ""]]}, {"id": "1701.07657", "submitter": "Giovanni Sileno", "authors": "Giovanni Sileno", "title": "Operationalizing Declarative and Procedural Knowledge: a Benchmark on\n  Logic Programming Petri Nets (LPPNs)", "comments": "draft version -- updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling, specifying and reasoning about complex systems requires to process\nin an integrated fashion declarative and procedural aspects of the target\ndomain. The paper reports on an experiment conducted with a propositional\nversion of Logic Programming Petri Nets (LPPNs), a notation extending Petri\nNets with logic programming constructs. Two semantics are presented: a\ndenotational semantics that fully maps the notation to ASP via Event Calculus;\nand a hybrid operational semantics that process separately the causal\nmechanisms via Petri nets, and the constraints associated to objects and to\nevents via Answer Set Programming (ASP). These two alternative specifications\nenable an empirical evaluation in terms of computational efficiency.\nExperimental results show that the hybrid semantics is more efficient w.r.t.\nsequences, whereas the two semantics follows the same behaviour w.r.t.\nbranchings (although the denotational one performs better in absolute terms).\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 11:21:50 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 23:08:48 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sileno", "Giovanni", ""]]}, {"id": "1701.07696", "submitter": "Mario Boley", "authors": "Mario Boley and Bryan R. Goldsmith and Luca M. Ghiringhelli and Jilles\n  Vreeken", "title": "Identifying Consistent Statements about Numerical Data with\n  Dispersion-Corrected Subgroup Discovery", "comments": "significance of empirical results tested; additional illustrations;\n  table of used notations", "journal-ref": null, "doi": "10.1007/s10618-017-0520-3", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing algorithms for subgroup discovery with numerical targets do not\noptimize the error or target variable dispersion of the groups they find. This\noften leads to unreliable or inconsistent statements about the data, rendering\npractical applications, especially in scientific domains, futile. Therefore, we\nhere extend the optimistic estimator framework for optimal subgroup discovery\nto a new class of objective functions: we show how tight estimators can be\ncomputed efficiently for all functions that are determined by subgroup size\n(non-decreasing dependence), the subgroup median value, and a dispersion\nmeasure around the median (non-increasing dependence). In the important special\ncase when dispersion is measured using the average absolute deviation from the\nmedian, this novel approach yields a linear time algorithm. Empirical\nevaluation on a wide range of datasets shows that, when used within\nbranch-and-bound search, this approach is highly efficient and indeed discovers\nsubgroups with much smaller errors.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 13:36:43 GMT"}, {"version": "v2", "created": "Sun, 23 Apr 2017 09:34:35 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Boley", "Mario", ""], ["Goldsmith", "Bryan R.", ""], ["Ghiringhelli", "Luca M.", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1701.07756", "submitter": "Siwar Jendoubi", "authors": "Siwar Jendoubi, Arnaud Martin, Ludovic Li\\'etard, Boutheina Ben\n  Yaghlane, Hend Ben Hadji", "title": "Dynamic time warping distance for message propagation classification in\n  Twitter", "comments": "10 pages, 1 figure ECSQARU 2015, Proceedings of the 13th European\n  Conferences on Symbolic and Quantitative Approaches to Reasoning with\n  Uncertainty, 2015", "journal-ref": null, "doi": "10.1007/978-3-319-20807-7_38", "report-no": null, "categories": "cs.AI cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social messages classification is a research domain that has attracted the\nattention of many researchers in these last years. Indeed, the social message\nis different from ordinary text because it has some special characteristics\nlike its shortness. Then the development of new approaches for the processing\nof the social message is now essential to make its classification more\nefficient. In this paper, we are mainly interested in the classification of\nsocial messages based on their spreading on online social networks (OSN). We\nproposed a new distance metric based on the Dynamic Time Warping distance and\nwe use it with the probabilistic and the evidential k Nearest Neighbors (k-NN)\nclassifiers to classify propagation networks (PrNets) of messages. The\npropagation network is a directed acyclic graph (DAG) that is used to record\npropagation traces of the message, the traversed links and their types. We\ntested the proposed metric with the chosen k-NN classifiers on real world\npropagation traces that were collected from Twitter social network and we got\ngood classification accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 16:14:40 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Jendoubi", "Siwar", ""], ["Martin", "Arnaud", ""], ["Li\u00e9tard", "Ludovic", ""], ["Yaghlane", "Boutheina Ben", ""], ["Hadji", "Hend Ben", ""]]}, {"id": "1701.07769", "submitter": "Nicholas Mattei", "authors": "Emanuelle Burton, Judy Goldsmith, Sven Koenig, Benjamin Kuipers,\n  Nicholas Mattei, and Toby Walsh", "title": "Ethical Considerations in Artificial Intelligence Courses", "comments": "29 pages including all case studies and links to video media on\n  YouTube", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge in interest in ethics in artificial intelligence may leave\nmany educators wondering how to address moral, ethical, and philosophical\nissues in their AI courses. As instructors we want to develop curriculum that\nnot only prepares students to be artificial intelligence practitioners, but\nalso to understand the moral, ethical, and philosophical impacts that\nartificial intelligence will have on society. In this article we provide\npractical case studies and links to resources for use by AI educators. We also\nprovide concrete suggestions on how to integrate AI ethics into a general\nartificial intelligence course and how to teach a stand-alone artificial\nintelligence ethics course.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 16:52:22 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Burton", "Emanuelle", ""], ["Goldsmith", "Judy", ""], ["Koenig", "Sven", ""], ["Kuipers", "Benjamin", ""], ["Mattei", "Nicholas", ""], ["Walsh", "Toby", ""]]}, {"id": "1701.08096", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Jilles Vreeken", "title": "Efficiently Summarising Event Sequences with Rich Interleaving Patterns", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611974973", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the key structure of a database is one of the main goals of data\nmining. In pattern set mining we do so by discovering a small set of patterns\nthat together describe the data well. The richer the class of patterns we\nconsider, and the more powerful our description language, the better we will be\nable to summarise the data. In this paper we propose \\ourmethod, a novel greedy\nMDL-based method for summarising sequential data using rich patterns that are\nallowed to interleave. Experiments show \\ourmethod is orders of magnitude\nfaster than the state of the art, results in better models, as well as\ndiscovers meaningful semantics in the form patterns that identify multiple\nchoices of values.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 16:02:54 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1701.08100", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan Salehi Nobandegani, Ioannis N. Psaromiligkos", "title": "The Causal Frame Problem: An Algorithmic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frame Problem (FP) is a puzzle in philosophy of mind and epistemology,\narticulated by the Stanford Encyclopedia of Philosophy as follows: \"How do we\naccount for our apparent ability to make decisions on the basis only of what is\nrelevant to an ongoing situation without having explicitly to consider all that\nis not relevant?\" In this work, we focus on the causal variant of the FP, the\nCausal Frame Problem (CFP). Assuming that a reasoner's mental causal model can\nbe (implicitly) represented by a causal Bayes net, we first introduce a notion\ncalled Potential Level (PL). PL, in essence, encodes the relative position of a\nnode with respect to its neighbors in a causal Bayes net. Drawing on the\npsychological literature on causal judgment, we substantiate the claim that PL\nmay bear on how time is encoded in the mind. Using PL, we propose an inference\nframework, called the PL-based Inference Framework (PLIF), which permits a\nboundedly-rational approach to the CFP to be formally articulated at Marr's\nalgorithmic level of analysis. We show that our proposed framework, PLIF, is\nconsistent with a wide range of findings in causal judgment literature, and\nthat PL and PLIF make a number of predictions, some of which are already\nsupported by existing findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jan 2017 16:42:29 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Nobandegani", "Ardavan Salehi", ""], ["Psaromiligkos", "Ioannis N.", ""]]}, {"id": "1701.08125", "submitter": "Sven Tomforde", "authors": "Sven Tomforde and Bernhard Sick and Christian M\\\"uller-Schloer", "title": "Organic Computing in the Spotlight", "comments": "10 pages, one figure, article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organic Computing is an initiative in the field of systems engineering that\nproposed to make use of concepts such as self-adaptation and self-organisation\nto increase the robustness of technical systems. Based on the observation that\ntraditional design and operation concepts reach their limits, transferring more\nautonomy to the systems themselves should result in a reduction of complexity\nfor users, administrators, and developers. However, there seems to be a need\nfor an updated definition of the term \"Organic Computing\", of desired\nproperties of technical, organic systems, and the objectives of the Organic\nComputing initiative. With this article, we will address these points.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 17:35:56 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Tomforde", "Sven", ""], ["Sick", "Bernhard", ""], ["M\u00fcller-Schloer", "Christian", ""]]}, {"id": "1701.08190", "submitter": "Mohamed Anis Bach Tobji Dr.", "authors": "Mohamed Anis Bach Tobji", "title": "Comparative Study Of Data Mining Query Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since formulation of Inductive Database (IDB) problem, several Data Mining\n(DM) languages have been proposed, confirming that KDD process could be\nsupported via inductive queries (IQ) answering. This paper reviews the existing\nDM languages. We are presenting important primitives of the DM language and\nclassifying our languages according to primitives' satisfaction. In addition,\nwe presented languages' syntaxes and tried to apply each one to a database\nsample to test a set of KDD operations. This study allows us to highlight\nlanguages capabilities and limits, which is very useful for future work and\nperspectives.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 21:00:19 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Tobji", "Mohamed Anis Bach", ""]]}, {"id": "1701.08191", "submitter": "Mohamed Anis Bach Tobji Dr.", "authors": "Mohamed Anis Bach Tobji, Mohamed Salah Gouider", "title": "Incremental Maintenance Of Association Rules Under Support Threshold\n  Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Maintenance of association rules is an interesting problem. Several\nincremental maintenance algorithms were proposed since the work of (Cheung et\nal, 1996). The majority of these algorithms maintain rule bases assuming that\nsupport threshold doesn't change. In this paper, we present incremental\nmaintenance algorithm under support threshold change. This solution allows user\nto maintain its rule base under any support threshold.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 21:02:52 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Tobji", "Mohamed Anis Bach", ""], ["Gouider", "Mohamed Salah", ""]]}, {"id": "1701.08251", "submitter": "Nasrin Mostafazadeh", "authors": "Nasrin Mostafazadeh, Chris Brockett, Bill Dolan, Michel Galley,\n  Jianfeng Gao, Georgios P. Spithourakis, Lucy Vanderwende", "title": "Image-Grounded Conversations: Multimodal Context for Natural Question\n  and Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of image sharing on social media and the engagement it creates\nbetween users reflects the important role that visual context plays in everyday\nconversations. We present a novel task, Image-Grounded Conversations (IGC), in\nwhich natural-sounding conversations are generated about a shared image. To\nbenchmark progress, we introduce a new multiple-reference dataset of\ncrowd-sourced, event-centric conversations on images. IGC falls on the\ncontinuum between chit-chat and goal-directed conversation models, where visual\ngrounding constrains the topic of conversation to event-driven utterances.\nExperiments with models trained on social media data show that the combination\nof visual and textual context enhances the quality of generated conversational\nturns. In human evaluation, the gap between human performance and that of both\nneural and retrieval architectures suggests that multi-modal IGC presents an\ninteresting challenge for dialogue research.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 05:06:11 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 00:36:35 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Mostafazadeh", "Nasrin", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Spithourakis", "Georgios P.", ""], ["Vanderwende", "Lucy", ""]]}, {"id": "1701.08254", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Alexandros G. Dimakis, Sriram Vishwanath, Babak\n  Hassibi", "title": "Entropic Causality and Greedy Minimum Entropy Coupling", "comments": "Submitted to ISIT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of identifying the causal relationship between two\ndiscrete random variables from observational data. We recently proposed a novel\nframework called entropic causality that works in a very general functional\nmodel but makes the assumption that the unobserved exogenous variable has small\nentropy in the true causal direction.\n  This framework requires the solution of a minimum entropy coupling problem:\nGiven marginal distributions of m discrete random variables, each on n states,\nfind the joint distribution with minimum entropy, that respects the given\nmarginals. This corresponds to minimizing a concave function of nm variables\nover a convex polytope defined by nm linear constraints, called a\ntransportation polytope. Unfortunately, it was recently shown that this minimum\nentropy coupling problem is NP-hard, even for 2 variables with n states. Even\nrepresenting points (joint distributions) over this space can require\nexponential complexity (in n, m) if done naively.\n  In our recent work we introduced an efficient greedy algorithm to find an\napproximate solution for this problem. In this paper we analyze this algorithm\nand establish two results: that our algorithm always finds a local minimum and\nalso is within an additive approximation error from the unknown global optimum.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 05:17:25 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""], ["Hassibi", "Babak", ""]]}, {"id": "1701.08269", "submitter": "Rui Liu", "authors": "Rui Liu, Xiaoli Zhang", "title": "Systems of natural-language-facilitated human-robot cooperation: A\n  review", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural-language-facilitated human-robot cooperation (NLC), in which natural\nlanguage (NL) is used to share knowledge between a human and a robot for\nconducting intuitive human-robot cooperation (HRC), is continuously developing\nin the recent decade. Currently, NLC is used in several robotic domains such as\nmanufacturing, daily assistance and health caregiving. It is necessary to\nsummarize current NLC-based robotic systems and discuss the future developing\ntrends, providing helpful information for future NLC research. In this review,\nwe first analyzed the driving forces behind the NLC research. Regarding to a\nrobot s cognition level during the cooperation, the NLC implementations then\nwere categorized into four types {NL-based control, NL-based robot training,\nNL-based task execution, NL-based social companion} for comparison and\ndiscussion. Last based on our perspective and comprehensive paper review, the\nfuture research trends were discussed.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 08:32:35 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 20:27:17 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Liu", "Rui", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "1701.08301", "submitter": "A Mani", "authors": "A. Mani", "title": "Pure Rough Mereology and Counting", "comments": "IEEE Women in Engineering Conference, WIECON-ECE'2017 (Accepted for\n  IEEEXplore)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LO math.IT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of mereology (parts and wholes) in the context of formal approaches\nto vagueness can be approached in a number of ways. In the context of rough\nsets, mereological concepts with a set-theoretic or valuation based ontology\nacquire complex and diverse behavior. In this research a general rough set\nframework called granular operator spaces is extended and the nature of\nparthood in it is explored from a minimally intrusive point of view. This is\nused to develop counting strategies that help in classifying the framework. The\ndeveloped methodologies would be useful for drawing involved conclusions about\nthe nature of data (and validity of assumptions about it) from antichains\nderived from context. The problem addressed is also about whether counting\nprocedures help in confirming that the approximations involved in formation of\ndata are indeed rough approximations?\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 16:38:39 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1701.08302", "submitter": "A Mani", "authors": "Mani A and Rebeka Mukherjee", "title": "A Study of FOSS'2013 Survey Data Using Clustering Techniques", "comments": "IEEE Women in Engineering Conference Paper: WIECON-ECE'2016\n  (Scheduled to appear in IEEE Xplore )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FOSS is an acronym for Free and Open Source Software. The FOSS 2013 survey\nprimarily targets FOSS contributors and relevant anonymized dataset is publicly\navailable under CC by SA license. In this study, the dataset is analyzed from a\ncritical perspective using statistical and clustering techniques (especially\nmultiple correspondence analysis) with a strong focus on women contributors\ntowards discovering hidden trends and facts. Important inferences are drawn\nabout development practices and other facets of the free software and OSS\nworlds.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 16:52:13 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 17:18:01 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["A", "Mani", ""], ["Mukherjee", "Rebeka", ""]]}, {"id": "1701.08305", "submitter": "Pan Li", "authors": "Pan Li and Olgica Milenkovic", "title": "Multiclass MinMax Rank Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new family of minmax rank aggregation problems under two\ndistance measures, the Kendall {\\tau} and the Spearman footrule. As the\nproblems are NP-hard, we proceed to describe a number of constant-approximation\nalgorithms for solving them. We conclude with illustrative applications of the\naggregation methods on the Mallows model and genomic data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 17:45:58 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Li", "Pan", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1701.08306", "submitter": "Zohreh Shams", "authors": "Zohreh Shams, Marina De Vos, Julian Padget and Wamberto W. Vasconcelos", "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full\n  Edition)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous software agents operating in dynamic environments need to\nconstantly reason about actions in pursuit of their goals, while taking into\nconsideration norms which might be imposed on those actions. Normative\npractical reasoning supports agents making decisions about what is best for\nthem to (not) do in a given situation. What makes practical reasoning\nchallenging is the interplay between goals that agents are pursuing and the\nnorms that the agents are trying to uphold. We offer a formalisation to allow\nagents to plan for multiple goals and norms in the presence of durative actions\nthat can be executed concurrently. We compare plans based on decision-theoretic\nnotions (i.e. utility) such that the utility gain of goals and utility loss of\nnorm violations are the basis for this comparison. The set of optimal plans\nconsists of plans that maximise the overall utility, each of which can be\nchosen by the agent to execute. We provide an implementation of our proposal in\nAnswer Set Programming, thus allowing us to state the original problem in terms\nof a logic program that can be queried for solutions with specific properties.\nThe implementation is proven to be sound and complete.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 17:55:04 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Shams", "Zohreh", ""], ["De Vos", "Marina", ""], ["Padget", "Julian", ""], ["Vasconcelos", "Wamberto W.", ""]]}, {"id": "1701.08317", "submitter": "Sarath Sreedharan", "authors": "Tathagata Chakraborti, Sarath Sreedharan, Yu Zhang and Subbarao\n  Kambhampati", "title": "Plan Explanations as Model Reconciliation: Moving Beyond Explanation as\n  Soliloquy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When AI systems interact with humans in the loop, they are often called on to\nprovide explanations for their plans and behavior. Past work on plan\nexplanations primarily involved the AI system explaining the correctness of its\nplan and the rationale for its decision in terms of its own model. Such\nsoliloquy is wholly inadequate in most realistic scenarios where the humans\nhave domain and task models that differ significantly from that used by the AI\nsystem. We posit that the explanations are best studied in light of these\ndiffering models. In particular, we show how explanation can be seen as a\n\"model reconciliation problem\" (MRP), where the AI system in effect suggests\nchanges to the human's model, so as to make its plan be optimal with respect to\nthat changed human model. We will study the properties of such explanations,\npresent algorithms for automatically computing them, and evaluate the\nperformance of the algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 19:22:52 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 22:39:38 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 15:54:37 GMT"}, {"version": "v4", "created": "Sun, 28 May 2017 03:24:37 GMT"}, {"version": "v5", "created": "Tue, 30 May 2017 21:31:24 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Sreedharan", "Sarath", ""], ["Zhang", "Yu", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1701.08343", "submitter": "Eita Nakamura", "authors": "Eita Nakamura, Kazuyoshi Yoshii and Shigeki Sagayama", "title": "Rhythm Transcription of Polyphonic Piano Music Based on Merged-Output\n  HMM for Multiple Voices", "comments": "13 pages, 13 figures, version accepted to IEEE/ACM TASLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent conference paper, we have reported a rhythm transcription method\nbased on a merged-output hidden Markov model (HMM) that explicitly describes\nthe multiple-voice structure of polyphonic music. This model solves a major\nproblem of conventional methods that could not properly describe the nature of\nmultiple voices as in polyrhythmic scores or in the phenomenon of loose\nsynchrony between voices. In this paper we present a complete description of\nthe proposed model and develop an inference technique, which is valid for any\nmerged-output HMMs for which output probabilities depend on past events. We\nalso examine the influence of the architecture and parameters of the method in\nterms of accuracies of rhythm transcription and voice separation and perform\ncomparative evaluations with six other algorithms. Using MIDI recordings of\nclassical piano pieces, we found that the proposed model outperformed other\nmethods by more than 12 points in the accuracy for polyrhythmic performances\nand performed almost as good as the best one for non-polyrhythmic performances.\nThis reveals the state-of-the-art methods of rhythm transcription for the first\ntime in the literature. Publicly available source codes are also provided for\nfuture comparisons.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 01:25:57 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""], ["Sagayama", "Shigeki", ""]]}, {"id": "1701.08374", "submitter": "Habib Ghaffari Hadigheh", "authors": "Habib Ghaffari Hadigheh and Ghazali bin sulong", "title": "Feature base fusion for splicing forgery detection based on neuro fuzzy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of researches on image forensics have been mainly focused on detection\nof artifacts introduced by a single processing tool. They lead in the\ndevelopment of many specialized algorithms looking for one or more particular\nfootprints under specific settings. Naturally, the performance of such\nalgorithms are not perfect, and accordingly the provided output might be noisy,\ninaccurate and only partially correct. Furthermore, a forged image in practical\nscenarios is often the result of utilizing several tools available by\nimage-processing software systems. Therefore, reliable tamper detection\nrequires developing more poweful tools to deal with various tempering\nscenarios. Fusion of forgery detection tools based on Fuzzy Inference System\nhas been used before for addressing this problem. Adjusting the membership\nfunctions and defining proper fuzzy rules for attaining to better results are\ntime-consuming processes. This can be accounted as main disadvantage of fuzzy\ninference systems. In this paper, a Neuro-Fuzzy inference system for fusion of\nforgery detection tools is developed. The neural network characteristic of\nthese systems provides appropriate tool for automatically adjusting the\nmembership functions. Moreover, initial fuzzy inference system is generated\nbased on fuzzy clustering techniques. The proposed framework is implemented and\nvalidated on a benchmark image splicing data set in which three forgery\ndetection tools are fused based on adaptive Neuro-Fuzzy inference system. The\noutcome of the proposed method reveals that applying Neuro Fuzzy inference\nsystems could be a better approach for fusion of forgery detection tools.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 13:19:07 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Hadigheh", "Habib Ghaffari", ""], ["sulong", "Ghazali bin", ""]]}, {"id": "1701.08546", "submitter": "Marc Sol\\'e Sim\\'o", "authors": "Marc Sol\\'e, Victor Munt\\'es-Mulero, Annie Ibrahim Rana, Giovani\n  Estrada", "title": "Survey on Models and Techniques for Root-Cause Analysis", "comments": "18 pages, 222 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automation and computer intelligence to support complex human decisions\nbecomes essential to manage large and distributed systems in the Cloud and IoT\nera. Understanding the root cause of an observed symptom in a complex system\nhas been a major problem for decades. As industry dives into the IoT world and\nthe amount of data generated per year grows at an amazing speed, an important\nquestion is how to find appropriate mechanisms to determine root causes that\ncan handle huge amounts of data or may provide valuable feedback in real-time.\nWhile many survey papers aim at summarizing the landscape of techniques for\nmodelling system behavior and infering the root cause of a problem based in the\nresulting models, none of those focuses on analyzing how the different\ntechniques in the literature fit growing requirements in terms of performance\nand scalability. In this survey, we provide a review of root-cause analysis,\nfocusing on these particular aspects. We also provide guidance to choose the\nbest root-cause analysis strategy depending on the requirements of a particular\nsystem and application.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 11:17:14 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 13:01:07 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Sol\u00e9", "Marc", ""], ["Munt\u00e9s-Mulero", "Victor", ""], ["Rana", "Annie Ibrahim", ""], ["Estrada", "Giovani", ""]]}, {"id": "1701.08567", "submitter": "Lamb Wubin", "authors": "Lamb Wubin, Naixin Ren", "title": "Decision structure of risky choice", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we know, there is a controversy about the decision making under risk\nbetween economists and psychologists. We discuss to build a unified theory of\nrisky choice, which would explain both of compensatory and non-compensatory\ntheories. For risky choice, according to cognition ability, we argue that\npeople could not build a continuous and accurate subjective probability world,\nbut several order concepts, such as small, middle and large probability. People\nmake decisions based on information, experience, imagination and other things.\nAll of these things are so huge that people have to prepare some strategies.\nThat is, people have different strategies when facing to different situations.\nThe distributions of these things have different decision structures. More\nprecisely, decision making is a process of simplifying the decision structure.\nHowever, the process of decision structure simplifying is not stuck in a rut,\nbut through different path when facing problems repeatedly. It is why\npreference reversal always happens when making decisions. The most efficient\nway to simplify the decision structure is calculating expected value or making\ndecisions based on one or two dimensions. We also argue that the deliberation\ntime at least has four parts, which are consist of substitution time, first\norder time, second order time and calculation time. Decision structure also can\nsimply explain the phenomenon of paradoxes and anomalies. JEL Codes: C10, D03,\nD81\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 12:18:30 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 20:01:00 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Wubin", "Lamb", ""], ["Ren", "Naixin", ""]]}, {"id": "1701.08661", "submitter": "Jasper De Bock", "authors": "Jasper De Bock", "title": "Credal Networks under Epistemic Irrelevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A credal network under epistemic irrelevance is a generalised type of\nBayesian network that relaxes its two main building blocks. On the one hand,\nthe local probabilities are allowed to be partially specified. On the other\nhand, the assessments of independence do not have to hold exactly.\nConceptually, these two features turn credal networks under epistemic\nirrelevance into a powerful alternative to Bayesian networks, offering a more\nflexible approach to graph-based multivariate uncertainty modelling. However,\nin practice, they have long been perceived as very hard to work with, both\ntheoretically and computationally.\n  The aim of this paper is to demonstrate that this perception is no longer\njustified. We provide a general introduction to credal networks under epistemic\nirrelevance, give an overview of the state of the art, and present several new\ntheoretical results. Most importantly, we explain how these results can be\ncombined to allow for the design of recursive inference methods. We provide\nnumerous concrete examples of how this can be achieved, and use these to\ndemonstrate that computing with credal networks under epistemic irrelevance is\nmost definitely feasible, and in some cases even highly efficient. We also\ndiscuss several philosophical aspects, including the lack of symmetry, how to\ndeal with probability zero, the interpretation of lower expectations, the\naxiomatic status of graphoid properties, and the difference between updating\nand conditioning.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 08:57:40 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 15:00:19 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["De Bock", "Jasper", ""]]}, {"id": "1701.08665", "submitter": "Xiaodong Pan", "authors": "Xiaodong Pan, Yang Xu", "title": "Redefinition of the concept of fuzzy set based on vague partition from\n  the perspective of axiomatization", "comments": "25 pages. arXiv admin note: substantial text overlap with\n  arXiv:1506.07821", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Based on the in-depth analysis of the essence and features of vague\nphenomena, this paper focuses on establishing the axiomatical foundation of\nmembership degree theory for vague phenomena, presents an axiomatic system to\ngovern membership degrees and their interconnections. On this basis, the\nconcept of vague partition is introduced, further, the concept of fuzzy set\nintroduced by Zadeh in 1965 is redefined based on vague partition from the\nperspective of axiomatization. The thesis defended in this paper is that the\nrelationship among vague attribute values should be the starting point to\nrecognize and model vague phenomena from a quantitative view.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2017 11:27:45 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Pan", "Xiaodong", ""], ["Xu", "Yang", ""]]}, {"id": "1701.08709", "submitter": "Fred Glover", "authors": "Fred Glover", "title": "Diversification Methods for Zero-One Optimization", "comments": "28 pages, 7 illustrations, 4 pseudocodes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new diversification methods for zero-one optimization that\nsignificantly extend strategies previously introduced in the setting of\nmetaheuristic search. Our methods incorporate easily implemented strategies for\npartitioning assignments of values to variables, accompanied by processes\ncalled augmentation and shifting which create greater flexibility and\ngenerality. We then show how the resulting collection of diversified solutions\ncan be further diversified by means of permutation mappings, which equally can\nbe used to generate diversified collections of permutations for applications\nsuch as scheduling and routing. These methods can be applied to non-binary\nvectors by the use of binarization procedures and by Diversification-Based\nLearning (DBL) procedures which also provide connections to applications in\nclustering and machine learning. Detailed pseudocode and numerical\nillustrations are provided to show the operation of our methods and the\ncollections of solutions they create.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 17:01:31 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 04:19:25 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Glover", "Fred", ""]]}, {"id": "1701.08744", "submitter": "Junaid Effendi", "authors": "Muhammad Junaid Effendi and Syed Abbas Ali", "title": "Click Through Rate Prediction for Contextual Advertisment Using Linear\n  Regression", "comments": "8 pages, 13 Figures, 11 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This research presents an innovative and unique way of solving the\nadvertisement prediction problem which is considered as a learning problem over\nthe past several years. Online advertising is a multi-billion-dollar industry\nand is growing every year with a rapid pace. The goal of this research is to\nenhance click through rate of the contextual advertisements using Linear\nRegression. In order to address this problem, a new technique propose in this\npaper to predict the CTR which will increase the overall revenue of the system\nby serving the advertisements more suitable to the viewers with the help of\nfeature extraction and displaying the advertisements based on context of the\npublishers. The important steps include the data collection, feature\nextraction, CTR prediction and advertisement serving. The statistical results\nobtained from the dynamically used technique show an efficient outcome by\nfitting the data close to perfection for the LR technique using optimized\nfeature selection.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 18:32:59 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Effendi", "Muhammad Junaid", ""], ["Ali", "Syed Abbas", ""]]}, {"id": "1701.08756", "submitter": "Rui Liu", "authors": "Rui Liu, Xiaoli Zhang", "title": "A Review of Methodologies for Natural-Language-Facilitated Human-Robot\n  Cooperation", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural-language-facilitated human-robot cooperation (NLC) refers to using\nnatural language (NL) to facilitate interactive information sharing and task\nexecutions with a common goal constraint between robots and humans. Recently,\nNLC research has received increasing attention. Typical NLC scenarios include\nrobotic daily assistance, robotic health caregiving, intelligent manufacturing,\nautonomous navigation, and robot social accompany. However, a thorough review,\nthat can reveal latest methodologies to use NL to facilitate human-robot\ncooperation, is missing. In this review, a comprehensive summary about\nmethodologies for NLC is presented. NLC research includes three main research\nfocuses: NL instruction understanding, NL-based execution plan generation, and\nknowledge-world mapping. In-depth analyses on theoretical methods,\napplications, and model advantages and disadvantages are made. Based on our\npaper review and perspective, potential research directions of NLC are\nsummarized.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 18:59:04 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 19:20:07 GMT"}, {"version": "v3", "created": "Thu, 17 Aug 2017 19:52:20 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Liu", "Rui", ""], ["Zhang", "Xiaoli", ""]]}, {"id": "1701.08761", "submitter": "Rupam Bhattacharyya", "authors": "Rupam Bhattacharyya, Adity Saikia and Shyamanta M. Hazarika", "title": "C3A: A Cognitive Collaborative Control Architecture For an Intelligent\n  Wheelchair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retention of residual skills for persons who partially lose their cognitive\nor physical ability is of utmost importance. Research is focused on developing\nsystems that provide need-based assistance for retention of such residual\nskills. This paper describes a novel cognitive collaborative control\narchitecture C3A, designed to address the challenges of developing need- based\nassistance for wheelchair navigation. Organization of C3A is detailed and\nresults from simulation of the proposed architecture is presented. For\nsimulation of our proposed architecture, we have used ROS (Robot Operating\nSystem) as a control framework and a 3D robotic simulator called USARSim\n(Unified System for Automation and Robot Simulation).\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 11:53:59 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Bhattacharyya", "Rupam", ""], ["Saikia", "Adity", ""], ["Hazarika", "Shyamanta M.", ""]]}, {"id": "1701.08810", "submitter": "Romain Laroche", "authors": "Romain Laroche and Raphael Feraud", "title": "Reinforcement Learning Algorithm Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formalises the problem of online algorithm selection in the\ncontext of Reinforcement Learning. The setup is as follows: given an episodic\ntask and a finite number of off-policy RL algorithms, a meta-algorithm has to\ndecide which RL algorithm is in control during the next episode so as to\nmaximize the expected return. The article presents a novel meta-algorithm,\ncalled Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is\nto freeze the policy updates at each epoch, and to leave a rebooted stochastic\nbandit in charge of the algorithm selection. Under some assumptions, a thorough\ntheoretical analysis demonstrates its near-optimality considering the\nstructural sampling budget limitations. ESBAS is first empirically evaluated on\na dialogue task where it is shown to outperform each individual algorithm in\nmost configurations. ESBAS is then adapted to a true online setting where\nalgorithms update their policies after each transition, which we call SSBAS.\nSSBAS is evaluated on a fruit collection task where it is shown to adapt the\nstepsize parameter more efficiently than the classical hyperbolic decay, and on\nan Atari game, where it improves the performance by a wide margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 20:13:17 GMT"}, {"version": "v2", "created": "Fri, 2 Jun 2017 19:20:40 GMT"}, {"version": "v3", "created": "Tue, 14 Nov 2017 21:08:17 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Laroche", "Romain", ""], ["Feraud", "Raphael", ""]]}, {"id": "1701.08832", "submitter": "Francois Belletti", "authors": "Francois Belletti, Daniel Haziza, Gabriel Gomes, Alexandre M. Bayen", "title": "Expert Level control of Ramp Metering based on Multi-task Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article shows how the recent breakthroughs in Reinforcement Learning\n(RL) that have enabled robots to learn to play arcade video games, walk or\nassemble colored bricks, can be used to perform other tasks that are currently\nat the core of engineering cyberphysical systems. We present the first use of\nRL for the control of systems modeled by discretized non-linear Partial\nDifferential Equations (PDEs) and devise a novel algorithm to use\nnon-parametric control techniques for large multi-agent systems. We show how\nneural network based RL enables the control of discretized PDEs whose\nparameters are unknown, random, and time-varying. We introduce an algorithm of\nMutual Weight Regularization (MWR) which alleviates the curse of dimensionality\nof multi-agent control schemes by sharing experience between agents while\ngiving each agent the opportunity to specialize its action policy so as to\ntailor it to the local parameters of the part of the system it is located in.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 21:27:14 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Belletti", "Francois", ""], ["Haziza", "Daniel", ""], ["Gomes", "Gabriel", ""], ["Bayen", "Alexandre M.", ""]]}, {"id": "1701.08868", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami and Negar Kiyavash", "title": "Interaction Information for Causal Inference: The Case of Directed\n  Triangle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction information is one of the multivariate generalizations of mutual\ninformation, which expresses the amount information shared among a set of\nvariables, beyond the information, which is shared in any proper subset of\nthose variables. Unlike (conditional) mutual information, which is always\nnon-negative, interaction information can be negative. We utilize this property\nto find the direction of causal influences among variables in a triangle\ntopology under some mild assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 23:01:15 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1701.08878", "submitter": "Smruti Amarjyoti", "authors": "Smruti Amarjyoti", "title": "Deep Reinforcement Learning for Robotic Manipulation-The state of the\n  art", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this work is to enumerate the various approaches and algorithms\nthat center around application of reinforcement learning in robotic ma-\n]]nipulation tasks. Earlier methods utilized specialized policy representations\nand human demonstrations to constrict the policy. Such methods worked well with\ncontinuous state and policy space of robots but failed to come up with\ngeneralized policies. Subsequently, high dimensional non-linear function\napproximators like neural networks have been used to learn policies from\nscratch. Several novel and recent approaches have also embedded control policy\nwith efficient perceptual representation using deep learning. This has led to\nthe emergence of a new branch of dynamic robot control system called deep r\ninforcement learning(DRL). This work embodies a survey of the most recent\nalgorithms, architectures and their implementations in simulations and real\nworld robotic platforms. The gamut of DRL architectures are partitioned into\ntwo different branches namely, discrete action space algorithms(DAS) and\ncontinuous action space algorithms(CAS). Further, the CAS algorithms are\ndivided into stochastic continuous action space(SCAS) and deterministic\ncontinuous action space(DCAS) algorithms. Along with elucidating an organ-\nisation of the DRL algorithms this work also manifests some of the state of the\nart applications of these approaches in robotic manipulation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 00:16:15 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Amarjyoti", "Smruti", ""]]}, {"id": "1701.08888", "submitter": "Guangneng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai", "title": "Integrating Reviews into Personalized Ranking for Cold Start\n  Recommendation", "comments": "TextBPR", "journal-ref": "PAKDD 2017", "doi": "10.1007/978-3-319-57529-2_55", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item recommendation task predicts a personalized ranking over a set of items\nfor each individual user. One paradigm is the rating-based methods that\nconcentrate on explicit feedbacks and hence face the difficulties in collecting\nthem. Meanwhile, the ranking-based methods are presented with rated items and\nthen rank the rated above the unrated. This paradigm takes advantage of widely\navailable implicit feedback. It, however, usually ignores a kind of important\ninformation: item reviews. Item reviews not only justify the preferences of\nusers, but also help alleviate the cold-start problem that fails the\ncollaborative filtering. In this paper, we propose two novel and simple models\nto integrate item reviews into Bayesian personalized ranking. In each model, we\nmake use of text features extracted from item reviews using word embeddings. On\ntop of text features we uncover the review dimensions that explain the\nvariation in users' feedback and these review factors represent a prior\npreference of users. Experiments on six real-world data sets show the benefits\nof leveraging item reviews on ranking prediction. We also conduct analyses to\nunderstand the proposed models.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 02:13:57 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 08:50:40 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""]]}, {"id": "1701.08954", "submitter": "Marco Baroni", "authors": "Marco Baroni, Armand Joulin, Allan Jabri, Germ\\`an Kruszewski,\n  Angeliki Lazaridou, Klemen Simonic, Tomas Mikolov", "title": "CommAI: Evaluating the first steps towards a useful general AI", "comments": "Published in ICLR 2017 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning successfully applied to new daunting problems almost\nevery day, general AI starts looking like an attainable goal. However, most\ncurrent research focuses instead on important but narrow applications, such as\nimage classification or machine translation. We believe this to be largely due\nto the lack of objective ways to measure progress towards broad machine\nintelligence. In order to fill this gap, we propose here a set of concrete\ndesiderata for general AI, together with a platform to test machines on how\nwell they satisfy such desiderata, while keeping all further complexities to a\nminimum.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 09:20:17 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 18:47:01 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Baroni", "Marco", ""], ["Joulin", "Armand", ""], ["Jabri", "Allan", ""], ["Kruszewski", "Germ\u00e0n", ""], ["Lazaridou", "Angeliki", ""], ["Simonic", "Klemen", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1701.09000", "submitter": "Fabio Cozman", "authors": "Fabio Gagliardi Cozman, Denis Deratani Mau\\'a", "title": "On the Semantics and Complexity of Probabilistic Logic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the meaning and the complexity of probabilistic logic programs\nthat consist of a set of rules and a set of independent probabilistic facts\n(that is, programs based on Sato's distribution semantics). We focus on two\nsemantics, respectively based on stable and on well-founded models. We show\nthat the semantics based on stable models (referred to as the \"credal\nsemantics\") produces sets of probability models that dominate infinitely\nmonotone Choquet capacities, we describe several useful consequences of this\nresult. We then examine the complexity of inference with probabilistic logic\nprograms. We distinguish between the complexity of inference when a\nprobabilistic program and a query are given (the inferential complexity), and\nthe complexity of inference when the probabilistic program is fixed and the\nquery is given (the query complexity, akin to data complexity as used in\ndatabase theory). We obtain results on the inferential and query complexity for\nacyclic, stratified, and cyclic propositional and relational programs,\ncomplexity reaches various levels of the counting hierarchy and even\nexponential levels.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 11:54:15 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Cozman", "Fabio Gagliardi", ""], ["Mau\u00e1", "Denis Deratani", ""]]}, {"id": "1701.09042", "submitter": "Jeff Heaton", "authors": "Jeff Heaton", "title": "Comparing Dataset Characteristics that Favor the Apriori, Eclat or\n  FP-Growth Frequent Itemset Mining Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent itemset mining is a popular data mining technique. Apriori, Eclat,\nand FP-Growth are among the most common algorithms for frequent itemset mining.\nConsiderable research has been performed to compare the relative performance\nbetween these three algorithms, by evaluating the scalability of each algorithm\nas the dataset size increases. While scalability as data size increases is\nimportant, previous papers have not examined the performance impact of\nsimilarly sized datasets that contain different itemset characteristics. This\npaper explores the effects that two dataset characteristics can have on the\nperformance of these three frequent itemset algorithms. To perform this\nempirical analysis, a dataset generator is created to measure the effects of\nfrequent item density and the maximum transaction size on performance. The\ngenerated datasets contain the same number of rows. This provides some insight\ninto dataset characteristics that are conducive to each algorithm. The results\nof this paper's research demonstrate Eclat and FP-Growth both handle increases\nin maximum transaction size and frequent itemset density considerably better\nthan the Apriori algorithm.\n  This paper explores the effects that two dataset characteristics can have on\nthe performance of these three frequent itemset algorithms. To perform this\nempirical analysis, a dataset generator is created to measure the effects of\nfrequent item density and the maximum transaction size on performance. The\ngenerated datasets contain the same number of rows. This provides some insight\ninto dataset characteristics that are conducive to each algorithm. The results\nof this paper's research demonstrate Eclat and FP-Growth both handle increases\nin maximum transaction size and frequent itemset density considerably better\nthan the Apriori algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2017 12:34:02 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Heaton", "Jeff", ""]]}, {"id": "1701.09083", "submitter": "Pan Li", "authors": "Pan Li, Arya Mazumdar and Olgica Milenkovic", "title": "Efficient Rank Aggregation via Lehmer Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel rank aggregation method based on converting permutations\ninto their corresponding Lehmer codes or other subdiagonal images. Lehmer\ncodes, also known as inversion vectors, are vector representations of\npermutations in which each coordinate can take values not restricted by the\nvalues of other coordinates. This transformation allows for decoupling of the\ncoordinates and for performing aggregation via simple scalar median or mode\ncomputations. We present simulation results illustrating the performance of\nthis completely parallelizable approach and analytically prove that both the\nmode and median aggregation procedure recover the correct centroid aggregate\nwith small sample complexity when the permutations are drawn according to the\nwell-known Mallows models. The proposed Lehmer code approach may also be used\non partial rankings, with similar performance guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jan 2017 19:28:29 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Li", "Pan", ""], ["Mazumdar", "Arya", ""], ["Milenkovic", "Olgica", ""]]}, {"id": "1701.09123", "submitter": "Rodrigo Agerri", "authors": "Rodrigo Agerri and German Rigau", "title": "Robust Multilingual Named Entity Recognition with Shallow\n  Semi-Supervised Features", "comments": "26 pages, 19 tables (submitted for publication on September 2015),\n  Artificial Intelligence (2016)", "journal-ref": "Artificial Intelligence, 238, 63-82 (2016)", "doi": "10.1016/j.artint.2016.05.003", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a multilingual Named Entity Recognition approach based on a robust\nand general set of features across languages and datasets. Our system combines\nshallow local information with clustering semi-supervised features induced on\nlarge amounts of unlabeled text. Understanding via empirical experimentation\nhow to effectively combine various types of clustering features allows us to\nseamlessly export our system to other datasets and languages. The result is a\nsimple but highly competitive system which obtains state of the art results\nacross five languages and twelve datasets. The results are reported on standard\nshared task evaluation data such as CoNLL for English, Spanish and Dutch.\nFurthermore, and despite the lack of linguistically motivated features, we also\nreport best results for languages such as Basque and German. In addition, we\ndemonstrate that our method also obtains very competitive results even when the\namount of supervised data is cut by half, alleviating the dependency on\nmanually annotated data. Finally, the results show that our emphasis on\nclustering features is crucial to develop robust out-of-domain models. The\nsystem and models are freely available to facilitate its use and guarantee the\nreproducibility of results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2017 16:36:06 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Agerri", "Rodrigo", ""], ["Rigau", "German", ""]]}]