[{"id": "1509.00061", "submitter": "Hao Yi Ong", "authors": "Hao Yi Ong", "title": "Value function approximation via low-rank models", "comments": "arXiv admin note: substantial text overlap with arXiv:0912.3599 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel value function approximation technique for Markov decision\nprocesses. We consider the problem of compactly representing the state-action\nvalue function using a low-rank and sparse matrix model. The problem is to\ndecompose a matrix that encodes the true value function into low-rank and\nsparse components, and we achieve this using Robust Principal Component\nAnalysis (PCA). Under minimal assumptions, this Robust PCA problem can be\nsolved exactly via the Principal Component Pursuit convex optimization problem.\nWe experiment the procedure on several examples and demonstrate that our method\nyields approximations essentially identical to the true function.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 20:46:23 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Ong", "Hao Yi", ""]]}, {"id": "1509.00190", "submitter": "Alex Stolz", "authors": "Alex Stolz and Martin Hepp", "title": "GR2RSS: Publishing Linked Open Commerce Data as RSS and Atom Feeds", "comments": "Technical report, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "TR-2014-1", "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Linked Open Data (LOD) content in Web pages is a\nchallenging and sometimes tedious task for Web developers. At the same moment,\nmost software packages for blogs, content management systems (CMS), and shop\napplications support the consumption of feed formats, namely RSS and Atom. In\nthis technical report, we demonstrate an on-line tool that fetches e-commerce\ndata from a SPARQL endpoint and syndicates obtained results as RSS or Atom\nfeeds. Our approach combines (1) the popularity and broad tooling support of\nexisting feed formats, (2) the precision of queries against structured data\nbuilt upon common Web vocabularies like schema.org, GoodRelations, FOAF, VCard,\nand WGS 84, and (3) the ease of integrating content from a large number of Web\nsites and other data sources in RDF in general.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 09:25:07 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Stolz", "Alex", ""], ["Hepp", "Martin", ""]]}, {"id": "1509.00584", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "Norbert B\\'atfai", "title": "Turing's Imitation Game has been Improved", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the recently introduced universal computing model, called orchestrated\nmachine, that represents computations in a dissipative environment, we consider\na new kind of interpretation of Turing's Imitation Game. In addition we raise\nthe question whether the intelligence may show fractal properties. Then we\nsketch a vision of what robotic cars are going to do in the future. Finally we\ngive the specification of an artificial life game based on the concept of\norchestrated machines. The purpose of this paper is to start the search for\npossible relationships between these different topics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 07:18:20 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["B\u00e1tfai", "Norbert", ""]]}, {"id": "1509.00685", "submitter": "Alexander M. Rush", "authors": "Alexander M. Rush, Sumit Chopra and Jason Weston", "title": "A Neural Attention Model for Abstractive Sentence Summarization", "comments": "Proceedings of EMNLP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarization based on text extraction is inherently limited, but\ngeneration-style abstractive methods have proven challenging to build. In this\nwork, we propose a fully data-driven approach to abstractive sentence\nsummarization. Our method utilizes a local attention-based model that generates\neach word of the summary conditioned on the input sentence. While the model is\nstructurally simple, it can easily be trained end-to-end and scales to a large\namount of training data. The model shows significant performance gains on the\nDUC-2004 shared task compared with several strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 13:20:40 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2015 19:55:45 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Rush", "Alexander M.", ""], ["Chopra", "Sumit", ""], ["Weston", "Jason", ""]]}, {"id": "1509.00690", "submitter": "Zahid Ansari", "authors": "Zahid Ansari, M.F.Azeem, A. Vinaya Babu and Waseem Ahmed", "title": "A Fuzzy Approach for Feature Evaluation and Dimensionality Reduction to\n  Improve the Quality of Web Usage Mining Results", "comments": null, "journal-ref": "International Journal on Advanced Science Engineering and\n  Information Technology, pp. 67-73 Vol. 2 No. 6, 2012. (ISSN: 2088-5334,\n  INSIGHT Publishers, Indonesia)", "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web Usage Mining is the application of data mining techniques to web usage\nlog repositories in order to discover the usage patterns that can be used to\nanalyze the users navigational behavior. During the preprocessing stage, raw\nweb log data is transformed into a set of user profiles. Each user profile\ncaptures a set of URLs representing a user session. Clustering can be applied\nto this sessionized data in order to capture similar interests and trends among\nusers navigational patterns. Since the sessionized data may contain thousands\nof user sessions and each user session may consist of hundreds of URL accesses,\ndimensionality reduction is achieved by eliminating the low support URLs. Very\nsmall sessions are also removed in order to filter out the noise from the data.\nBut direct elimination of low support URLs and small sized sessions may results\nin loss of a significant amount of information especially when the count of low\nsupport URLs and small sessions is large. We propose a fuzzy solution to deal\nwith this problem by assigning weights to URLs and user sessions based on a\nfuzzy membership function. After assigning the weights we apply a Fuzzy c-Mean\nClustering algorithm to discover the clusters of user profiles. In this paper,\nwe describe our fuzzy set theoretic approach to perform feature selection (or\ndimensionality reduction) and session weight assignment. Finally we compare our\nsoft computing based approach of dimensionality reduction with the traditional\napproach of direct elimination of small sessions and low support count URLs.\nOur results show that fuzzy feature evaluation and dimensionality reduction\nresults in better performance and validity indices for the discovered clusters.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 09:56:02 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Ansari", "Zahid", ""], ["Azeem", "M. F.", ""], ["Babu", "A. Vinaya", ""], ["Ahmed", "Waseem", ""]]}, {"id": "1509.00838", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei and Mohit Bansal and Matthew R. Walter", "title": "What to talk about and how? Selective Generation using LSTMs with\n  Coarse-to-Fine Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end, domain-independent neural encoder-aligner-decoder\nmodel for selective generation, i.e., the joint task of content selection and\nsurface realization. Our model first encodes a full set of over-determined\ndatabase event records via an LSTM-based recurrent neural network, then\nutilizes a novel coarse-to-fine aligner to identify the small subset of salient\nrecords to talk about, and finally employs a decoder to generate free-form\ndescriptions of the aligned, selected records. Our model achieves the best\nselection and generation results reported to-date (with 59% relative\nimprovement in generation) on the benchmark WeatherGov dataset, despite using\nno specialized features or linguistic resources. Using an improved k-nearest\nneighbor beam filter helps further. We also perform a series of ablations and\nvisualizations to elucidate the contributions of our key model components.\nLastly, we evaluate the generalizability of our model on the RoboCup dataset,\nand get results that are competitive with or better than the state-of-the-art,\ndespite being severely data-starved.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 19:52:56 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 23:07:32 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Mei", "Hongyuan", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1509.01023", "submitter": "Ibrahim Adeyanju", "authors": "Ibrahim Adeyanju", "title": "Generating Weather Forecast Texts with Case Based Reasoning", "comments": "6 pages", "journal-ref": "International Journal of Computer Applications 45(10) (2012) 35-40", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several techniques have been used to generate weather forecast texts. In this\npaper, case based reasoning (CBR) is proposed for weather forecast text\ngeneration because similar weather conditions occur over time and should have\nsimilar forecast texts. CBR-METEO, a system for generating weather forecast\ntexts was developed using a generic framework (jCOLIBRI) which provides modules\nfor the standard components of the CBR architecture. The advantage in a CBR\napproach is that systems can be built in minimal time with far less human\neffort after initial consultation with experts. The approach depends heavily on\nthe goodness of the retrieval and revision components of the CBR process. We\nevaluated CBRMETEO with NIST, an automated metric which has been shown to\ncorrelate well with human judgements for this domain. The system shows\ncomparable performance with other NLG systems that perform the same task.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 10:21:16 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Adeyanju", "Ibrahim", ""]]}, {"id": "1509.01040", "submitter": "Ibrahim Adeyanju", "authors": "Ibrahim Adeyanju", "title": "Building a Truly Distributed Constraint Solver with JADE", "comments": "7 pages", "journal-ref": "International Journal of Computer Applications (IJCA) 46 (8)\n  (2012) 5-7", "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real life problems such as scheduling meeting between people at different\nlocations can be modelled as distributed Constraint Satisfaction Problems\n(CSPs). Suitable and satisfactory solutions can then be found using constraint\nsatisfaction algorithms which can be exhaustive (backtracking) or otherwise\n(local search). However, most research in this area tested their algorithms by\nsimulation on a single PC with a single program entry point. The main\ncontribution of our work is the design and implementation of a truly\ndistributed constraint solver based on a local search algorithm using Java\nAgent DEvelopment framework (JADE) to enable communication between agents on\ndifferent machines. Particularly, we discuss design and implementation issues\nrelated to truly distributed constraint solver which might not be critical when\nsimulated on a single machine. Evaluation results indicate that our truly\ndistributed constraint solver works well within the observed limitations when\ntested with various distributed CSPs. Our application can also incorporate any\nconstraint solving algorithm with little modifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 11:41:45 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Adeyanju", "Ibrahim", ""]]}, {"id": "1509.01168", "submitter": "Andreas Damianou Dr", "authors": "Andreas Damianou, Neil D. Lawrence", "title": "Semi-described and semi-supervised learning with Gaussian processes", "comments": "Published in the proceedings for Uncertainty in Artificial\n  Intelligence (UAI), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propagating input uncertainty through non-linear Gaussian process (GP)\nmappings is intractable. This hinders the task of training GPs using uncertain\nand partially observed inputs. In this paper we refer to this task as\n\"semi-described learning\". We then introduce a GP framework that solves both,\nthe semi-described and the semi-supervised learning problems (where missing\nvalues occur in the outputs). Auto-regressive state space simulation is also\nrecognised as a special case of semi-described learning. To achieve our goal we\ndevelop variational methods for handling semi-described inputs in GPs, and\ncouple them with algorithms that allow for imputing the missing values while\ntreating the uncertainty in a principled, Bayesian manner. Extensive\nexperiments on simulated and real-world data study the problems of iterative\nforecasting and regression/classification with missing values. The results\nsuggest that the principled propagation of uncertainty stemming from our\nframework can significantly improve performance in these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 17:22:15 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Damianou", "Andreas", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1509.01379", "submitter": "Balubaid Mohammed", "authors": "Mohammed A. Balubaid and Umar Manzoor", "title": "Ontology Based SMS Controller for Smart Phones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text analysis includes lexical analysis of the text and has been widely\nstudied and used in diverse applications. In the last decade, researchers have\nproposed many efficient solutions to analyze / classify large text dataset,\nhowever, analysis / classification of short text is still a challenge because\n1) the data is very sparse 2) It contains noise words and 3) It is difficult to\nunderstand the syntactical structure of the text. Short Messaging Service (SMS)\nis a text messaging service for mobile/smart phone and this service is\nfrequently used by all mobile users. Because of the popularity of SMS service,\nmarketing companies nowadays are also using this service for direct marketing\nalso known as SMS marketing.In this paper, we have proposed Ontology based SMS\nController which analyze the text message and classify it using ontology\naslegitimate or spam. The proposed system has been tested on different\nscenarios and experimental results shows that the proposed solution is\neffective both in terms of efficiency and time.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 09:29:47 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Balubaid", "Mohammed A.", ""], ["Manzoor", "Umar", ""]]}, {"id": "1509.01469", "submitter": "Ruiqi Guo", "authors": "Ruiqi Guo, Sanjiv Kumar, Krzysztof Choromanski and David Simcha", "title": "Quantization based Fast Inner Product Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a quantization based approach for fast approximate Maximum Inner\nProduct Search (MIPS). Each database vector is quantized in multiple subspaces\nvia a set of codebooks, learned directly by minimizing the inner product\nquantization error. Then, the inner product of a query to a database vector is\napproximated as the sum of inner products with the subspace quantizers.\nDifferent from recently proposed LSH approaches to MIPS, the database vectors\nand queries do not need to be augmented in a higher dimensional feature space.\nWe also provide a theoretical analysis of the proposed approach, consisting of\nthe concentration results under mild assumptions. Furthermore, if a small\nsample of example queries is given at the training time, we propose a modified\ncodebook learning procedure which further improves the accuracy. Experimental\nresults on a variety of datasets including those arising from deep neural\nnetworks show that the proposed approach significantly outperforms the existing\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 14:43:11 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Guo", "Ruiqi", ""], ["Kumar", "Sanjiv", ""], ["Choromanski", "Krzysztof", ""], ["Simcha", "David", ""]]}, {"id": "1509.01549", "submitter": "Matthew Lai", "authors": "Matthew Lai", "title": "Giraffe: Using Deep Reinforcement Learning to Play Chess", "comments": "MSc Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents Giraffe, a chess engine that uses self-play to discover\nall its domain-specific knowledge, with minimal hand-crafted knowledge given by\nthe programmer. Unlike previous attempts using machine learning only to perform\nparameter-tuning on hand-crafted evaluation functions, Giraffe's learning\nsystem also performs automatic feature extraction and pattern recognition. The\ntrained evaluation function performs comparably to the evaluation functions of\nstate-of-the-art chess engines - all of which containing thousands of lines of\ncarefully hand-crafted pattern recognizers, tuned over many years by both\ncomputer chess experts and human chess masters. Giraffe is the most successful\nattempt thus far at using end-to-end machine learning to play chess.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 18:21:52 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 15:42:35 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Lai", "Matthew", ""]]}, {"id": "1509.01599", "submitter": "Jacob Eisenstein", "authors": "Parminder Bhatia and Yangfeng Ji and Jacob Eisenstein", "title": "Better Document-level Sentiment Analysis from RST Discourse Parsing", "comments": "Published at Empirical Methods in Natural Language Processing (EMNLP\n  2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse structure is the hidden link between surface features and\ndocument-level properties, such as sentiment polarity. We show that the\ndiscourse analyses produced by Rhetorical Structure Theory (RST) parsers can\nimprove document-level sentiment analysis, via composition of local information\nup the discourse tree. First, we show that reweighting discourse units\naccording to their position in a dependency representation of the rhetorical\nstructure can yield substantial improvements on lexicon-based sentiment\nanalysis. Next, we present a recursive neural network over the RST structure,\nwhich offers significant improvements over classification-based methods.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 20:28:12 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2015 15:41:53 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Bhatia", "Parminder", ""], ["Ji", "Yangfeng", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1509.01644", "submitter": "Warwick Masson", "authors": "Warwick Masson, Pravesh Ranchod, George Konidaris", "title": "Reinforcement Learning with Parameterized Actions", "comments": "Accepted for AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model-free algorithm for learning in Markov decision processes\nwith parameterized actions-discrete actions with continuous parameters. At each\nstep the agent must select both which action to use and which parameters to use\nwith that action. We introduce the Q-PAMDP algorithm for learning in these\ndomains, show that it converges to a local optimum, and compare it to direct\npolicy search in the goal-scoring and Platform domains.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 00:17:35 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 20:44:11 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2015 14:48:21 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2015 12:00:42 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Masson", "Warwick", ""], ["Ranchod", "Pravesh", ""], ["Konidaris", "George", ""]]}, {"id": "1509.01815", "submitter": "Valery Vilisov", "authors": "Valery Vilisov", "title": "Research: Analysis of Transport Model that Approximates Decision Taker's\n  Preferences", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.5085.6166", "report-no": null, "categories": "cs.LG cs.AI math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper provides a method for solving the reverse Monge-Kantorovich transport\nproblem (TP). It allows to accumulate positive decision-taking experience made\nby decision-taker in situations that can be presented in the form of TP. The\ninitial data for the solution of the inverse TP is the information on orders,\ninventories and effective decisions take by decision-taker. The result of\nsolving the inverse TP contains evaluations of the TPs payoff matrix elements.\nIt can be used in new situations to select the solution corresponding to the\npreferences of the decision-taker. The method allows to gain decision-taker\nexperience, so it can be used by others. The method allows to build the model\nof decision-taker preferences in a specific application area. The model can be\nupdated regularly to ensure its relevance and adequacy to the decision-taker\nsystem of preferences. This model is adaptive to the current preferences of the\ndecision taker.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 14:25:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Vilisov", "Valery", ""]]}, {"id": "1509.01920", "submitter": "Daniel R. Jiang", "authors": "Daniel R. Jiang and Warren B. Powell", "title": "Risk-Averse Approximate Dynamic Programming with Quantile-Based Risk\n  Measures", "comments": "39 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a finite-horizon Markov decision process (MDP) for\nwhich the objective at each stage is to minimize a quantile-based risk measure\n(QBRM) of the sequence of future costs; we call the overall objective a dynamic\nquantile-based risk measure (DQBRM). In particular, we consider optimizing\ndynamic risk measures where the one-step risk measures are QBRMs, a class of\nrisk measures that includes the popular value at risk (VaR) and the conditional\nvalue at risk (CVaR). Although there is considerable theoretical development of\nrisk-averse MDPs in the literature, the computational challenges have not been\nexplored as thoroughly. We propose data-driven and simulation-based approximate\ndynamic programming (ADP) algorithms to solve the risk-averse sequential\ndecision problem. We address the issue of inefficient sampling for risk\napplications in simulated settings and present a procedure, based on importance\nsampling, to direct samples toward the \"risky region\" as the ADP algorithm\nprogresses. Finally, we show numerical results of our algorithms in the context\nof an application involving risk-averse bidding for energy storage.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 06:32:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 07:48:50 GMT"}, {"version": "v3", "created": "Wed, 4 Jan 2017 16:41:54 GMT"}, {"version": "v4", "created": "Tue, 9 May 2017 02:28:50 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Jiang", "Daniel R.", ""], ["Powell", "Warren B.", ""]]}, {"id": "1509.01978", "submitter": "Alessia Amelio Dr.", "authors": "Darko Brodic, Alessia Amelio, Zoran N. Milivojevic", "title": "An Approach to the Analysis of the South Slavic Medieval Labels Using\n  Image Texture", "comments": "15 pages, 9 figures, 3rd Workshop on Recognition and Action for Scene\n  Understanding (REACTS 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a new script classification method for the discrimination\nof the South Slavic medieval labels. It consists in the textural analysis of\nthe script types. In the first step, each letter is coded by the equivalent\nscript type, which is defined by its typographical features. Obtained coded\ntext is subjected to the run-length statistical analysis and to the adjacent\nlocal binary pattern analysis in order to extract the features. The result\nshows a diversity between the extracted features of the scripts, which makes\nthe feature classification more effective. It is the basis for the\nclassification process of the script identification by using an extension of a\nstate-of-the-art approach for document clustering. The proposed method is\nevaluated on an example of hand-engraved in stone and hand-printed in paper\nlabels in old Cyrillic, angular and round Glagolitic. Experiments demonstrate\nvery positive results, which prove the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 10:39:20 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Brodic", "Darko", ""], ["Amelio", "Alessia", ""], ["Milivojevic", "Zoran N.", ""]]}, {"id": "1509.02012", "submitter": "Fabio Patrizi", "authors": "Giuseppe De Giacomo (1), Yves Lesp\\'erance (2), Fabio Patrizi (3) ((1)\n  Sapienza University of Rome, Italy, (2) York University, Toronto, ON, Canada,\n  (3) Free University of Bozen-Bolzano, Italy)", "title": "Bounded Situation Calculus Action Theories", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate bounded action theories in the situation\ncalculus. A bounded action theory is one which entails that, in every\nsituation, the number of object tuples in the extension of fluents is bounded\nby a given constant, although such extensions are in general different across\nthe infinitely many situations. We argue that such theories are common in\napplications, either because facts do not persist indefinitely or because the\nagent eventually forgets some facts, as new ones are learnt. We discuss various\nclasses of bounded action theories. Then we show that verification of a\npowerful first-order variant of the mu-calculus is decidable for such theories.\nNotably, this variant supports a controlled form of quantification across\nsituations. We also show that through verification, we can actually check\nwhether an arbitrary action theory maintains boundedness.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 12:42:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["De Giacomo", "Giuseppe", ""], ["Lesp\u00e9rance", "Yves", ""], ["Patrizi", "Fabio", ""]]}, {"id": "1509.02151", "submitter": "Daniel Ritchie", "authors": "Daniel Ritchie, Andreas Stuhlm\\\"uller, Noah D. Goodman", "title": "C3: Lightweight Incrementalized MCMC for Probabilistic Programs using\n  Continuations and Callsite Caching", "comments": "Fix typo in author name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight, source-to-source transformation approaches to implementing MCMC\nfor probabilistic programming languages are popular for their simplicity,\nsupport of existing deterministic code, and ability to execute on existing fast\nruntimes. However, they are also slow, requiring a complete re-execution of the\nprogram on every Metropolis Hastings proposal. We present a new extension to\nthe lightweight approach, C3, which enables efficient, incrementalized\nre-execution of MH proposals. C3 is based on two core ideas: transforming\nprobabilistic programs into continuation passing style (CPS), and caching the\nresults of function calls. We show that on several common models, C3 reduces\nproposal runtime by 20-100x, in some cases reducing runtime complexity from\nlinear in model size to constant. We also demonstrate nearly an order of\nmagnitude speedup on a complex inverse procedural modeling application.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 19:35:42 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2015 17:53:35 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Ritchie", "Daniel", ""], ["Stuhlm\u00fcller", "Andreas", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1509.02384", "submitter": "Anand Subramanian D.Sc.", "authors": "Arthur Kramer, Anand Subramanian", "title": "A unified heuristic and an annotated bibliography for a large class of\n  earliness-tardiness scheduling problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a unified heuristic algorithm for a large class of\nearliness-tardiness (E-T) scheduling problems. We consider single/parallel\nmachine E-T problems that may or may not consider some additional features such\nas idle time, setup times and release dates. In addition, we also consider\nthose problems whose objective is to minimize either the total (average)\nweighted completion time or the total (average) weighted flow time, which arise\nas particular cases when the due dates of all jobs are either set to zero or to\ntheir associated release dates, respectively. The developed local search based\nmetaheuristic framework is quite simple, but at the same time relies on\nsophisticated procedures for efficiently performing local search according to\nthe characteristics of the problem. We present efficient move evaluation\napproaches for some parallel machine problems that generalize the existing ones\nfor single machine problems. The algorithm was tested in hundreds of instances\nof several E-T problems and particular cases. The results obtained show that\nour unified heuristic is capable of producing high quality solutions when\ncompared to the best ones available in the literature that were obtained by\nspecific methods. Moreover, we provide an extensive annotated bibliography on\nthe problems related to those considered in this work, where we not only\nindicate the approach(es) used in each publication, but we also point out the\ncharacteristics of the problem(s) considered. Beyond that, we classify the\nexisting methods in different categories so as to have a better idea of the\npopularity of each type of solution procedure.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 14:26:31 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 16:43:51 GMT"}, {"version": "v3", "created": "Tue, 10 Jan 2017 17:12:00 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Kramer", "Arthur", ""], ["Subramanian", "Anand", ""]]}, {"id": "1509.02413", "submitter": "Yanping Huang", "authors": "Yanping Huang", "title": "Learning Efficient Representations for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are a well studied framework for solving\nsequential decision making problems under uncertainty. Exact methods for\nsolving MDPs based on dynamic programming such as policy iteration and value\niteration are effective on small problems. In problems with a large discrete\nstate space or with continuous state spaces, a compact representation is\nessential for providing an efficient approximation solutions to MDPs. Commonly\nused approximation algorithms involving constructing basis functions for\nprojecting the value function onto a low dimensional subspace, and building a\nfactored or hierarchical graphical model to decompose the transition and reward\nfunctions. However, hand-coding a good compact representation for a given\nreinforcement learning (RL) task can be quite difficult and time consuming.\nRecent approaches have attempted to automatically discover efficient\nrepresentations for RL.\n  In this thesis proposal, we discuss the problems of automatically\nconstructing structured kernel for kernel based RL, a popular approach to\nlearning non-parametric approximations for value function. We explore a space\nof kernel structures which are built compositionally from base kernels using a\ncontext-free grammar. We examine a greedy algorithm for searching over the\nstructure space. To demonstrate how the learned structure can represent and\napproximate the original RL problem in terms of compactness and efficiency, we\nplan to evaluate our method on a synthetic problem and compare it to other RL\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 06:01:56 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Huang", "Yanping", ""]]}, {"id": "1509.02458", "submitter": "Yeounoh Chung", "authors": "Yeounoh Chung, Chang-yong Park, Noo-ri Kim, Hana Cho, Taebok Yoon,\n  Hunjoo Lee and Jee-Hyong Lee", "title": "A Behavior Analysis-Based Game Bot Detection Approach Considering\n  Various Play Styles", "comments": null, "journal-ref": "ETRI Journal 35.6 (2013): 1058-1067", "doi": "10.4218/etrij.13.2013.0049", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach for game bot detection in MMORPGs is proposed based on the\nanalysis of game playing behavior. Since MMORPGs are large scale games, users\ncan play in various ways. This variety in playing behavior makes it hard to\ndetect game bots based on play behaviors. In order to cope with this problem,\nthe proposed approach observes game playing behaviors of users and groups them\nby their behavioral similarities. Then, it develops a local bot detection model\nfor each player group. Since the locally optimized models can more accurately\ndetect game bots within each player group, the combination of those models\nbrings about overall improvement. For a practical purpose of reducing the\nworkloads of the game servers in service, the game data is collected at a low\nresolution in time. Behavioral features are selected and developed to\naccurately detect game bots with the low resolution data, considering common\naspects of MMORPG playing. Through the experiment with the real data from a\ngame currently in service, it is shown that the proposed local model approach\nyields more accurate results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:36:31 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Chung", "Yeounoh", ""], ["Park", "Chang-yong", ""], ["Kim", "Noo-ri", ""], ["Cho", "Hana", ""], ["Yoon", "Taebok", ""], ["Lee", "Hunjoo", ""], ["Lee", "Jee-Hyong", ""]]}, {"id": "1509.02459", "submitter": "Mihai Oltean", "authors": "Mihai Oltean, D. Dumitrescu", "title": "Evolving TSP heuristics using Multi Expression Programming", "comments": "International Conference on Computational Sciences, ICCS'04, 6-9\n  June, Krakow, Poland, Edited by M. Bubak, G.van Albada, P. Sloot, and J.\n  Dongarra, Vol II, pp. 670-673, Springer-Verlag, Berlin, 2004. Source code\n  available for download at:\n  http://www.cs.ubbcluj.ro/~moltean/evolve_heuristics.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi Expression Programming (MEP) is an evolutionary technique that may be\nused for solving computationally difficult problems. MEP uses a linear solution\nrepresentation. Each MEP individual is a string encoding complex expressions\n(computer programs). A MEP individual may encode multiple solutions of the\ncurrent problem. In this paper MEP is used for evolving a Traveling Salesman\nProblem (TSP) heuristic for graphs satisfying triangle inequality. Evolved MEP\nheuristic is compared with Nearest Neighbor Heuristic (NN) and Minimum Spanning\nTree Heuristic (MST) on some difficult problems in TSPLIB. For most of the\nconsidered problems the evolved MEP heuristic outperforms NN and MST. The\nobtained algorithm was tested against some problems in TSPLIB. The results\nemphasizes that evolved MEP heuristic is a powerful tool for solving difficult\nTSP instances.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:37:01 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Oltean", "Mihai", ""], ["Dumitrescu", "D.", ""]]}, {"id": "1509.02709", "submitter": "Tom Everitt", "authors": "Tom Everitt, Marcus Hutter", "title": "A Topological Approach to Meta-heuristics: Analytical Results on the BFS\n  vs. DFS Algorithm Selection Problem", "comments": "Main results published in 28th Australian Joint Conference on\n  Artificial Intelligence, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is a central problem in artificial intelligence, and breadth-first\nsearch (BFS) and depth-first search (DFS) are the two most fundamental ways to\nsearch. In this paper we derive estimates for average BFS and DFS runtime. The\naverage runtime estimates can be used to allocate resources or judge the\nhardness of a problem. They can also be used for selecting the best graph\nrepresentation, and for selecting the faster algorithm out of BFS and DFS. They\nmay also form the basis for an analysis of more advanced search methods. The\npaper treats both tree search and graph search. For tree search, we employ a\nprobabilistic model of goal distribution; for graph search, the analysis\ndepends on an additional statistic of path redundancy and average branching\nfactor. As an application, we use the results to predict BFS and DFS runtime on\ntwo concrete grammar problems and on the N-puzzle. Experimental verification\nshows that our analytical approximations come close to empirical reality.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 10:30:48 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 06:40:49 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Everitt", "Tom", ""], ["Hutter", "Marcus", ""]]}, {"id": "1509.02962", "submitter": "Andreas Stuhlm\\\"uller", "authors": "Andreas Stuhlm\\\"uller, Robert X.D. Hawkins, N. Siddharth, Noah D.\n  Goodman", "title": "Coarse-to-Fine Sequential Monte Carlo for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical techniques for probabilistic inference require a sequence of\ndistributions that interpolate between a tractable distribution and an\nintractable distribution of interest. Usually, the sequences used are simple,\ne.g., based on geometric averages between distributions. When models are\nexpressed as probabilistic programs, the models themselves are highly\nstructured objects that can be used to derive annealing sequences that are more\nsensitive to domain structure. We propose an algorithm for transforming\nprobabilistic programs to coarse-to-fine programs which have the same marginal\ndistribution as the original programs, but generate the data at increasing\nlevels of detail, from coarse to fine. We apply this algorithm to an Ising\nmodel, its depth-from-disparity variation, and a factorial hidden Markov model.\nWe show preliminary evidence that the use of coarse-to-fine models can make\nexisting generic inference algorithms more efficient.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 21:48:22 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Stuhlm\u00fcller", "Andreas", ""], ["Hawkins", "Robert X. D.", ""], ["Siddharth", "N.", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1509.03005", "submitter": "David Balduzzi", "authors": "David Balduzzi, Muhammad Ghifary", "title": "Compatible Value Gradients for Reinforcement Learning of Continuous Deep\n  Policies", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes GProp, a deep reinforcement learning algorithm for\ncontinuous policies with compatible function approximation. The algorithm is\nbased on two innovations. Firstly, we present a temporal-difference based\nmethod for learning the gradient of the value-function. Secondly, we present\nthe deviator-actor-critic (DAC) model, which comprises three neural networks\nthat estimate the value function, its gradient, and determine the actor's\npolicy respectively. We evaluate GProp on two challenging tasks: a contextual\nbandit problem constructed from nonparametric regression datasets that is\ndesigned to probe the ability of reinforcement learning algorithms to\naccurately estimate gradients; and the octopus arm, a challenging reinforcement\nlearning benchmark. GProp is competitive with fully supervised methods on the\nbandit task and achieves the best performance to date on the octopus arm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 04:14:54 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Balduzzi", "David", ""], ["Ghifary", "Muhammad", ""]]}, {"id": "1509.03044", "submitter": "Xiujun Li", "authors": "Xiujun Li, Lihong Li, Jianfeng Gao, Xiaodong He, Jianshu Chen, Li\n  Deng, Ji He", "title": "Recurrent Reinforcement Learning: A Hybrid Approach", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful applications of reinforcement learning in real-world problems\noften require dealing with partially observable states. It is in general very\nchallenging to construct and infer hidden states as they often depend on the\nagent's entire interaction history and may require substantial domain\nknowledge. In this work, we investigate a deep-learning approach to learning\nthe representation of states in partially observable tasks, with minimal prior\nknowledge of the domain. In particular, we propose a new family of hybrid\nmodels that combines the strength of both supervised learning (SL) and\nreinforcement learning (RL), trained in a joint fashion: The SL component can\nbe a recurrent neural networks (RNN) or its long short-term memory (LSTM)\nversion, which is equipped with the desired property of being able to capture\nlong-term dependency on history, thus providing an effective way of learning\nthe representation of hidden states. The RL component is a deep Q-network (DQN)\nthat learns to optimize the control for maximizing long-term rewards. Extensive\nexperiments in a direct mailing campaign problem demonstrate the effectiveness\nand advantages of the proposed approach, which performs the best among a set of\nprevious state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 07:45:30 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 19:32:08 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Li", "Xiujun", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["He", "Xiaodong", ""], ["Chen", "Jianshu", ""], ["Deng", "Li", ""], ["He", "Ji", ""]]}, {"id": "1509.03057", "submitter": "Tomoyuki Yamakami", "authors": "Tomoyuki Yamakami", "title": "The World of Combinatorial Fuzzy Problems and the Efficiency of Fuzzy\n  Approximation Algorithms", "comments": "A4, 10pt, 10 pages. This extended abstract already appeared in the\n  Proceedings of the Joint 7th International Conference on Soft Computing and\n  Intelligent Systems (SCIS 2014) and 15th International Symposium on Advanced\n  Intelligent Systems (ISIS 2014), December 3-6, 2014, Institute of Electrical\n  and Electronics Engineers (IEEE), pp. 29-35, 2014", "journal-ref": null, "doi": "10.1109/SCIS-ISIS.2014.7044695", "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We re-examine a practical aspect of combinatorial fuzzy problems of various\ntypes, including search, counting, optimization, and decision problems. We are\nfocused only on those fuzzy problems that take series of fuzzy input objects\nand produce fuzzy values. To solve such problems efficiently, we design fast\nfuzzy algorithms, which are modeled by polynomial-time deterministic fuzzy\nTuring machines equipped with read-only auxiliary tapes and write-only output\ntapes and also modeled by polynomial-size fuzzy circuits composed of fuzzy\ngates. We also introduce fuzzy proof verification systems to model the\nfuzzification of nondeterminism. Those models help us identify four complexity\nclasses: Fuzzy-FPA of fuzzy functions, Fuzzy-PA and Fuzzy-NPA of fuzzy decision\nproblems, and Fuzzy-NPAO of fuzzy optimization problems. Based on a relative\napproximation scheme targeting fuzzy membership degree, we formulate two\nnotions of \"reducibility\" in order to compare the computational complexity of\ntwo fuzzy problems. These reducibility notions make it possible to locate the\nmost difficult fuzzy problems in Fuzzy-NPA and in Fuzzy-NPAO.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 09:07:31 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Yamakami", "Tomoyuki", ""]]}, {"id": "1509.03221", "submitter": "Sudip Mandal", "authors": "Sudip Mandal, Goutam Saha and Rajat K. Pal", "title": "Recurrent Neural Network Based Modeling of Gene Regulatory Network Using\n  Bat Algorithm", "comments": "14 pages, 4 figure. arXiv admin note: text overlap with\n  arXiv:1004.4170 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Correct inference of genetic regulations inside a cell is one of the greatest\nchallenges in post genomic era for the biologist and researchers. Several\nintelligent techniques and models were already proposed to identify the\nregulatory relations among genes from the biological database like time series\nmicroarray data. Recurrent Neural Network (RNN) is one of the most popular and\nsimple approach to model the dynamics as well as to infer correct dependencies\namong genes. In this paper, Bat Algorithm (BA) is applied to optimize the model\nparameters of RNN model of Gene Regulatory Network (GRN). Initially the\nproposed method is tested against small artificial network without any noise\nand the efficiency is observed in term of number of iteration, number of\npopulation and BA optimization parameters. The model is also validated in\npresence of different level of random noise for the small artificial network\nand that proved its ability to infer the correct inferences in presence of\nnoise like real world dataset. In the next phase of this research, BA based RNN\nis applied to real world benchmark time series microarray dataset of E. coli.\nThe results prove that it can able to identify the maximum number of true\npositive regulation but also include some false positive regulations.\nTherefore, BA is very suitable for identifying biological plausible GRN with\nthe help RNN model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 10:20:44 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 08:25:40 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Mandal", "Sudip", ""], ["Saha", "Goutam", ""], ["Pal", "Rajat K.", ""]]}, {"id": "1509.03247", "submitter": "Arindam Chaudhuri AC", "authors": "Arindam Chaudhuri", "title": "An Epsilon Hierarchical Fuzzy Twin Support Vector Regression", "comments": "Research work at Samsung Research and Development Institute Delhi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research presents epsilon hierarchical fuzzy twin support vector\nregression based on epsilon fuzzy twin support vector regression and epsilon\ntwin support vector regression. Epsilon FTSVR is achieved by incorporating\ntrapezoidal fuzzy numbers to epsilon TSVR which takes care of uncertainty\nexisting in forecasting problems. Epsilon FTSVR determines a pair of epsilon\ninsensitive proximal functions by solving two related quadratic programming\nproblems. The structural risk minimization principle is implemented by\nintroducing regularization term in primal problems of epsilon FTSVR. This\nyields dual stable positive definite problems which improves regression\nperformance. Epsilon FTSVR is then reformulated as epsilon HFTSVR consisting of\na set of hierarchical layers each containing epsilon FTSVR. Experimental\nresults on both synthetic and real datasets reveal that epsilon HFTSVR has\nremarkable generalization performance with minimum training time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 17:37:20 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Chaudhuri", "Arindam", ""]]}, {"id": "1509.03371", "submitter": "Fabian Tschopp", "authors": "Fabian Tschopp", "title": "Efficient Convolutional Neural Networks for Pixelwise Classification on\n  Heterogeneous Hardware Systems", "comments": "92 pages, project source code available at\n  https://github.com/naibaf7/, technical report written at ETH Z\\\"urich, in\n  collaboration with AMD, UZH INI and HHMI Janelia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents and analyzes three convolutional neural network (CNN)\nmodels for efficient pixelwise classification of images. When using\nconvolutional neural networks to classify single pixels in patches of a whole\nimage, a lot of redundant computations are carried out when using sliding\nwindow networks. This set of new architectures solve this issue by either\nremoving redundant computations or using fully convolutional architectures that\ninherently predict many pixels at once.\n  The implementations of the three models are accessible through a new utility\non top of the Caffe library. The utility provides support for a wide range of\nimage input and output formats, pre-processing parameters and methods to\nequalize the label histogram during training. The Caffe library has been\nextended by new layers and a new backend for availability on a wider range of\nhardware such as CPUs and GPUs through OpenCL.\n  On AMD GPUs, speedups of $54\\times$ (SK-Net), $437\\times$ (U-Net) and\n$320\\times$ (USK-Net) have been observed, taking the SK equivalent SW (sliding\nwindow) network as the baseline. The label throughput is up to one megapixel\nper second.\n  The analyzed neural networks have distinctive characteristics that apply\nduring training or processing, and not every data set is suitable to every\narchitecture. The quality of the predictions is assessed on two neural tissue\ndata sets, of which one is the ISBI 2012 challenge data set. Two different loss\nfunctions, Malis loss and Softmax loss, were used during training.\n  The whole pipeline, consisting of models, interface and modified Caffe\nlibrary, is available as Open Source software under the working title Project\nGreentea.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 01:20:46 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Tschopp", "Fabian", ""]]}, {"id": "1509.03389", "submitter": "Piotr Skowron", "authors": "Jerome Lang and Piotr Skowron", "title": "Multi-Attribute Proportional Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem in which a given number of items has to be\nchosen from a predefined set. Each item is described by a vector of attributes\nand for each attribute there is a desired distribution that the selected set\nshould have. We look for a set that fits as much as possible the desired\ndistributions on all attributes. Examples of applications include choosing\nmembers of a representative committee, where candidates are described by\nattributes such as sex, age and profession, and where we look for a committee\nthat for each attribute offers a certain representation, i.e., a single\ncommittee that contains a certain number of young and old people, certain\nnumber of men and women, certain number of people with different professions,\netc. With a single attribute the problem collapses to the apportionment problem\nfor party-list proportional representation systems (in such case the value of\nthe single attribute would be a political affiliation of a candidate). We study\nthe properties of the associated subset selection rules, as well as their\ncomputation complexity.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 05:01:17 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 22:04:34 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Lang", "Jerome", ""], ["Skowron", "Piotr", ""]]}, {"id": "1509.03390", "submitter": "Robert Sloan", "authors": "Stellan Ohlsson, Robert H. Sloan, Gy\\\"orgy Tur\\'an, Aaron Urasky", "title": "Measuring an Artificial Intelligence System's Performance on a Verbal IQ\n  Test For Young Children", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We administered the Verbal IQ (VIQ) part of the Wechsler Preschool and\nPrimary Scale of Intelligence (WPPSI-III) to the ConceptNet 4 AI system. The\ntest questions (e.g., \"Why do we shake hands?\") were translated into ConceptNet\n4 inputs using a combination of the simple natural language processing tools\nthat come with ConceptNet together with short Python programs that we wrote.\nThe question answering used a version of ConceptNet based on spectral methods.\nThe ConceptNet system scored a WPPSI-III VIQ that is average for a\nfour-year-old child, but below average for 5 to 7 year-olds. Large variations\namong subtests indicate potential areas of improvement. In particular, results\nwere strongest for the Vocabulary and Similarities subtests, intermediate for\nthe Information subtest, and lowest for the Comprehension and Word Reasoning\nsubtests. Comprehension is the subtest most strongly associated with common\nsense. The large variations among subtests and ordinary common sense strongly\nsuggest that the WPPSI-III VIQ results do not show that \"ConceptNet has the\nverbal abilities a four-year-old.\" Rather, children's IQ tests offer one\nobjective metric for the evaluation and comparison of AI systems. Also, this\nwork continues previous research on Psychometric AI.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 05:14:51 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Ohlsson", "Stellan", ""], ["Sloan", "Robert H.", ""], ["Tur\u00e1n", "Gy\u00f6rgy", ""], ["Urasky", "Aaron", ""]]}, {"id": "1509.03527", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk", "title": "Sharing HOL4 and HOL Light proof knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New proof assistant developments often involve concepts similar to already\nformalized ones. When proving their properties, a human can often take\ninspiration from the existing formalized proofs available in other provers or\nlibraries. In this paper we propose and evaluate a number of methods, which\nstrengthen proof automation by learning from proof libraries of different\nprovers. Certain conjectures can be proved directly from the dependencies\ninduced by similar proofs in the other library. Even if exact correspondences\nare not found, learning-reasoning systems can make use of the association\nbetween proved theorems and their characteristics to predict the relevant\npremises. Such external help can be further combined with internal advice. We\nevaluate the proposed knowledge-sharing methods by reproving the HOL Light and\nHOL4 standard libraries. The learning-reasoning system HOL(y)Hammer, whose\nsingle best strategy could automatically find proofs for 30% of the HOL Light\nproblems, can prove 40% with the knowledge from HOL4.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 14:18:04 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1509.03534", "submitter": "Thibault Gauthier", "authors": "Thibault Gauthier, Cezary Kaliszyk", "title": "Premise Selection and External Provers for HOL4", "comments": null, "journal-ref": null, "doi": "10.1145/2676724.2693173", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-assisted automated reasoning has recently gained popularity among\nthe users of Isabelle/HOL, HOL Light, and Mizar. In this paper, we present an\nadd-on to the HOL4 proof assistant and an adaptation of the HOLyHammer system\nthat provides machine learning-based premise selection and automated reasoning\nalso for HOL4. We efficiently record the HOL4 dependencies and extract features\nfrom the theorem statements, which form a basis for premise selection.\nHOLyHammer transforms the HOL4 statements in the various TPTP-ATP proof\nformats, which are then processed by the ATPs. We discuss the different\nevaluation settings: ATPs, accessible lemmas, and premise numbers. We measure\nthe performance of HOLyHammer on the HOL4 standard library. The results are\ncombined accordingly and compared with the HOL Light experiments, showing a\ncomparably high quality of predictions. The system directly benefits HOL4 users\nby automatically finding proofs dependencies that can be reconstructed by\nMetis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 14:31:05 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Gauthier", "Thibault", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1509.03564", "submitter": "Brian Ruttenberg", "authors": "Avi Pfeffer, Brian Ruttenberg, Amy Sliva, Michael Howard, Glenn Takata", "title": "Lazy Factored Inference for Functional Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming provides the means to represent and reason about\ncomplex probabilistic models using programming language constructs. Even simple\nprobabilistic programs can produce models with infinitely many variables.\nFactored inference algorithms are widely used for probabilistic graphical\nmodels, but cannot be applied to these programs because all the variables and\nfactors have to be enumerated. In this paper, we present a new inference\nframework, lazy factored inference (LFI), that enables factored algorithms to\nbe used for models with infinitely many variables. LFI expands the model to a\nbounded depth and uses the structure of the program to precisely quantify the\neffect of the unexpanded part of the model, producing lower and upper bounds to\nthe probability of the query.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 15:45:39 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Pfeffer", "Avi", ""], ["Ruttenberg", "Brian", ""], ["Sliva", "Amy", ""], ["Howard", "Michael", ""], ["Takata", "Glenn", ""]]}, {"id": "1509.03585", "submitter": "Fuan Pu", "authors": "Fuan Pu, Jian Luo and Guiming Luo", "title": "Some Supplementaries to The Counting Semantics for Abstract\n  Argumentation", "comments": "8 pages, 3 figures, ICTAI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dung's abstract argumentation framework consists of a set of interacting\narguments and a series of semantics for evaluating them. Those semantics\npartition the powerset of the set of arguments into two classes: extensions and\nnon-extensions. In order to reason with a specific semantics, one needs to take\na credulous or skeptical approach, i.e. an argument is eventually accepted, if\nit is accepted in one or all extensions, respectively. In our previous work\n\\cite{ref-pu2015counting}, we have proposed a novel semantics, called\n\\emph{counting semantics}, which allows for a more fine-grained assessment to\narguments by counting the number of their respective attackers and defenders\nbased on argument graph and argument game. In this paper, we continue our\nprevious work by presenting some supplementaries about how to choose the\ndamaging factor for the counting semantics, and what relationships with some\nexisting approaches, such as Dung's classical semantics, generic gradual\nvaluations. Lastly, an axiomatic perspective on the ranking semantics induced\nby our counting semantics are presented.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 17:23:54 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Pu", "Fuan", ""], ["Luo", "Jian", ""], ["Luo", "Guiming", ""]]}, {"id": "1509.03789", "submitter": "Bardia Yousefi", "authors": "Bardia Yousefi, Chu Kiong Loo", "title": "Bio-Inspired Human Action Recognition using Hybrid Max-Product\n  Neuro-Fuzzy Classifier and Quantum-Behaved PSO", "comments": "author's version, SWJ 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on computational neuroscience through functional magnetic resonance\nimaging (fMRI) and following biological inspired system stated that human\naction recognition in the brain of mammalian leads two distinct pathways in the\nmodel, which are specialized for analysis of motion (optic flow) and form\ninformation. Principally, we have defined a novel and robust form features\napplying active basis model as form extractor in form pathway in the biological\ninspired model. An unbalanced synergetic neural net-work classifies shapes and\nstructures of human objects along with tuning its attention parameter by\nquantum particle swarm optimization (QPSO) via initiation of Centroidal Voronoi\nTessellations. These tools utilized and justified as strong tools for following\nbiological system model in form pathway. But the final decision has done by\ncombination of ultimate outcomes of both pathways via fuzzy inference which\nincreases novality of proposed model. Combination of these two brain pathways\nis done by considering each feature sets in Gaussian membership functions with\nfuzzy product inference method. Two configurations have been proposed for form\npathway: applying multi-prototype human action templates using two time\nsynergetic neural network for obtaining uniform template regarding each\nactions, and second scenario that it uses abstracting human action in four\nkey-frames. Experimental results showed promising accuracy performance on\ndifferent datasets (KTH and Weizmann).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 00:34:18 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2016 00:04:24 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Yousefi", "Bardia", ""], ["Loo", "Chu Kiong", ""]]}, {"id": "1509.03970", "submitter": "Fernando Soler-Toscano", "authors": "Nicolas Gauvrit, Fernando Soler-Toscano and Hector Zenil", "title": "Natural scene statistics mediate the perception of image complexity", "comments": null, "journal-ref": "Visual Cognition 22 (8), 2014, pages 1084-1091", "doi": "10.1080/13506285.2014.950365", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans are sensitive to complexity and regularity in patterns. The subjective\nperception of pattern complexity is correlated to algorithmic\n(Kolmogorov-Chaitin) complexity as defined in computer science, but also to the\nfrequency of naturally occurring patterns. However, the possible mediational\nrole of natural frequencies in the perception of algorithmic complexity remains\nunclear. Here we reanalyze Hsu et al. (2010) through a mediational analysis,\nand complement their results in a new experiment. We conclude that human\nperception of complexity seems partly shaped by natural scenes statistics,\nthereby establishing a link between the perception of complexity and the effect\nof natural scene statistics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 07:34:46 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Gauvrit", "Nicolas", ""], ["Soler-Toscano", "Fernando", ""], ["Zenil", "Hector", ""]]}, {"id": "1509.03977", "submitter": "Pablo Escandell-Montero", "authors": "Pablo Escandell-Montero, Milena Chermisi, Jos\\'e M.\n  Mart\\'inez-Mart\\'inez, Juan G\\'omez-Sanchis, Carlo Barbieri, Emilio\n  Soria-Olivas, Flavio Mari, Joan Vila-Franc\\'es, Andrea Stopper, Emanuele\n  Gatti and Jos\\'e D. Mart\\'in-Guerrero", "title": "Optimization of anemia treatment in hemodialysis patients via\n  reinforcement learning", "comments": "17 pages, 10 figures", "journal-ref": "Artificial Intelligence in Medicine, Volume 62, Issue 1, September\n  2014, Pages 47-60", "doi": "10.1016/j.artmed.2014.07.004", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Anemia is a frequent comorbidity in hemodialysis patients that can\nbe successfully treated by administering erythropoiesis-stimulating agents\n(ESAs). ESAs dosing is currently based on clinical protocols that often do not\naccount for the high inter- and intra-individual variability in the patient's\nresponse. As a result, the hemoglobin level of some patients oscillates around\nthe target range, which is associated with multiple risks and side-effects.\nThis work proposes a methodology based on reinforcement learning (RL) to\noptimize ESA therapy.\n  Methods: RL is a data-driven approach for solving sequential decision-making\nproblems that are formulated as Markov decision processes (MDPs). Computing\noptimal drug administration strategies for chronic diseases is a sequential\ndecision-making problem in which the goal is to find the best sequence of drug\ndoses. MDPs are particularly suitable for modeling these problems due to their\nability to capture the uncertainty associated with the outcome of the treatment\nand the stochastic nature of the underlying process. The RL algorithm employed\nin the proposed methodology is fitted Q iteration, which stands out for its\nability to make an efficient use of data.\n  Results: The experiments reported here are based on a computational model\nthat describes the effect of ESAs on the hemoglobin level. The performance of\nthe proposed method is evaluated and compared with the well-known Q-learning\nalgorithm and with a standard protocol. Simulation results show that the\nperformance of Q-learning is substantially lower than FQI and the protocol.\n  Conclusion: Although prospective validation is required, promising results\ndemonstrate the potential of RL to become an alternative to current protocols.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 07:52:00 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Escandell-Montero", "Pablo", ""], ["Chermisi", "Milena", ""], ["Mart\u00ednez-Mart\u00ednez", "Jos\u00e9 M.", ""], ["G\u00f3mez-Sanchis", "Juan", ""], ["Barbieri", "Carlo", ""], ["Soria-Olivas", "Emilio", ""], ["Mari", "Flavio", ""], ["Vila-Franc\u00e9s", "Joan", ""], ["Stopper", "Andrea", ""], ["Gatti", "Emanuele", ""], ["Mart\u00edn-Guerrero", "Jos\u00e9 D.", ""]]}, {"id": "1509.04064", "submitter": "Michael Castronovo", "authors": "Michael Castronovo, Damien Ernst, Adrien Couetoux, Raphael Fonteneau", "title": "Benchmarking for Bayesian Reinforcement Learning", "comments": "37 pages", "journal-ref": null, "doi": "10.1371/journal.pone.0157088", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Bayesian Reinforcement Learning (BRL) setting, agents try to maximise\nthe collected rewards while interacting with their environment while using some\nprior knowledge that is accessed beforehand. Many BRL algorithms have already\nbeen proposed, but even though a few toy examples exist in the literature,\nthere are still no extensive or rigorous benchmarks to compare them. The paper\naddresses this problem, and provides a new BRL comparison methodology along\nwith the corresponding open source library. In this methodology, a comparison\ncriterion that measures the performance of algorithms on large sets of Markov\nDecision Processes (MDPs) drawn from some probability distributions is defined.\nIn order to enable the comparison of non-anytime algorithms, our methodology\nalso includes a detailed analysis of the computation time requirement of each\nalgorithm. Our library is released with all source code and documentation: it\nincludes three test problems, each of which has two different prior\ndistributions, and seven state-of-the-art RL algorithms. Finally, our library\nis illustrated by comparing all the available algorithms and the results are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 12:47:52 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Castronovo", "Michael", ""], ["Ernst", "Damien", ""], ["Couetoux", "Adrien", ""], ["Fonteneau", "Raphael", ""]]}, {"id": "1509.04265", "submitter": "Gabriel Prat", "authors": "Gabriel Prat Masramon and Llu\\'is A. Belanche Mu\\~noz", "title": "Double Relief with progressive weighting function", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.03755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature weighting algorithms try to solve a problem of great importance\nnowadays in machine learning: The search of a relevance measure for the\nfeatures of a given domain. This relevance is primarily used for feature\nselection as feature weighting can be seen as a generalization of it, but it is\nalso useful to better understand a problem's domain or to guide an inductor in\nits learning process. Relief family of algorithms are proven to be very\neffective in this task.\n  On previous work, a new extension was proposed that aimed for improving the\nalgorithm's performance and it was shown that in certain cases it improved the\nweights' estimation accuracy. However, it also seemed to be sensible to some\ncharacteristics of the data. An improvement of that previously presented\nextension is presented in this work that aims to make it more robust to problem\nspecific characteristics. An experimental design is proposed to test its\nperformance. Results of the tests prove that it indeed increase the robustness\nof the previously proposed extension.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 15:28:08 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 12:09:28 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Masramon", "Gabriel Prat", ""], ["Mu\u00f1oz", "Llu\u00eds A. Belanche", ""]]}, {"id": "1509.04513", "submitter": "Vinh Nguyen", "authors": "Vinh Nguyen, Olivier Bodenreider, Krishnaprasad Thirunarayan, Gang Fu,\n  Evan Bolton, N\\'uria Queralt Rosinach, Laura I. Furlong, Michel Dumontier,\n  Amit Sheth", "title": "On Reasoning with RDF Statements about Statements using Singleton\n  Property Triples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Singleton Property (SP) approach has been proposed for representing and\nquerying metadata about RDF triples such as provenance, time, location, and\nevidence. In this approach, one singleton property is created to uniquely\nrepresent a relationship in a particular context, and in general, generates a\nlarge property hierarchy in the schema. It has become the subject of important\nquestions from Semantic Web practitioners. Can an existing reasoner recognize\nthe singleton property triples? And how? If the singleton property triples\ndescribe a data triple, then how can a reasoner infer this data triple from the\nsingleton property triples? Or would the large property hierarchy affect the\nreasoners in some way? We address these questions in this paper and present our\nstudy about the reasoning aspects of the singleton properties. We propose a\nsimple mechanism to enable existing reasoners to recognize the singleton\nproperty triples, as well as to infer the data triples described by the\nsingleton property triples. We evaluate the effect of the singleton property\ntriples in the reasoning processes by comparing the performance on RDF datasets\nwith and without singleton properties. Our evaluation uses as benchmark the\nLUBM datasets and the LUBM-SP datasets derived from LUBM with temporal\ninformation added through singleton properties.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 12:10:37 GMT"}], "update_date": "2016-08-07", "authors_parsed": [["Nguyen", "Vinh", ""], ["Bodenreider", "Olivier", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Fu", "Gang", ""], ["Bolton", "Evan", ""], ["Rosinach", "N\u00faria Queralt", ""], ["Furlong", "Laura I.", ""], ["Dumontier", "Michel", ""], ["Sheth", "Amit", ""]]}, {"id": "1509.04581", "submitter": "Zhen Liu", "authors": "Zhen Liu", "title": "Kernelized Deep Convolutional Neural Network for Describing Complex\n  Images", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the impressive capability to capture visual content, deep convolutional\nneural networks (CNN) have demon- strated promising performance in various\nvision-based ap- plications, such as classification, recognition, and objec- t\ndetection. However, due to the intrinsic structure design of CNN, for images\nwith complex content, it achieves lim- ited capability on invariance to\ntranslation, rotation, and re-sizing changes, which is strongly emphasized in\nthe s- cenario of content-based image retrieval. In this paper, to address this\nproblem, we proposed a new kernelized deep convolutional neural network. We\nfirst discuss our motiva- tion by an experimental study to demonstrate the\nsensitivi- ty of the global CNN feature to the basic geometric trans-\nformations. Then, we propose to represent visual content with approximate\ninvariance to the above geometric trans- formations from a kernelized\nperspective. We extract CNN features on the detected object-like patches and\naggregate these patch-level CNN features to form a vectorial repre- sentation\nwith the Fisher vector model. The effectiveness of our proposed algorithm is\ndemonstrated on image search application with three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 14:35:11 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Liu", "Zhen", ""]]}, {"id": "1509.04771", "submitter": "Moo K. Chung", "authors": "Moo K. Chung, Victoria Vilalta-Gil, Paul J. Rathouz, Benjamin B.\n  Lahey, David H. Zald", "title": "Mapping Heritability of Large-Scale Brain Networks with a Billion\n  Connections {\\em via} Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many human brain network studies, we do not have sufficient number (n) of\nimages relative to the number (p) of voxels due to the prohibitively expensive\ncost of scanning enough subjects. Thus, brain network models usually suffer the\nsmall-n large-p problem. Such a problem is often remedied by sparse network\nmodels, which are usually solved numerically by optimizing L1-penalties.\nUnfortunately, due to the computational bottleneck associated with optimizing\nL1-penalties, it is not practical to apply such methods to construct\nlarge-scale brain networks at the voxel-level. In this paper, we propose a new\nscalable sparse network model using cross-correlations that bypass the\ncomputational bottleneck. Our model can build sparse brain networks at the\nvoxel level with p > 25000. Instead of using a single sparse parameter that may\nnot be optimal in other studies and datasets, the computational speed gain\nenables us to analyze the collection of networks at every possible sparse\nparameter in a coherent mathematical framework via persistent homology. The\nmethod is subsequently applied in determining the extent of heritability on a\nfunctional brain network at the voxel-level for the first time using twin fMRI.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 23:54:12 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 13:28:31 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Chung", "Moo K.", ""], ["Vilalta-Gil", "Victoria", ""], ["Rathouz", "Paul J.", ""], ["Lahey", "Benjamin B.", ""], ["Zald", "David H.", ""]]}, {"id": "1509.04904", "submitter": "Tshilidzi Marwala", "authors": "Pramod Kumar Parida, Tshilidzi Marwala and Snehashish Chakraverty", "title": "Causal Model Analysis using Collider v-structure with Negative\n  Percentage Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem of causal inference is the arrangement of dependent nodes in\na directed acyclic graph (DAG) with path coefficients and observed confounders.\nPath coefficients do not provide the units to measure the strength of\ninformation flowing from one node to the other. Here we proposed the method of\ncausal structure learning using collider v-structures (CVS) with Negative\nPercentage Mapping (NPM) to get selective thresholds of information strength,\nto direct the edges and subjective confounders in a DAG. The NPM is used to\nscale the strength of information passed through nodes in units of percentage\nfrom interval from 0 to 1. The causal structures are constructed by bottom up\napproach using path coefficients, causal directions and confounders, derived\nimplementing collider v-structure and NPM. The method is self-sufficient to\nobserve all the latent confounders present in the causal model and capable of\ndetecting every responsible causal direction. The results are tested for\nsimulated datasets of non-Gaussian distributions and compared with DirectLiNGAM\nand ICA-LiNGAM to check efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 12:37:30 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Parida", "Pramod Kumar", ""], ["Marwala", "Tshilidzi", ""], ["Chakraverty", "Snehashish", ""]]}, {"id": "1509.05016", "submitter": "Ashesh Jain", "authors": "Ashesh Jain, Avi Singh, Hema S Koppula, Shane Soh, Ashutosh Saxena", "title": "Recurrent Neural Networks for Driver Activity Anticipation via\n  Sensory-Fusion Architecture", "comments": "Follow-up of ICCV 2015 Brain4Cars http://www.brain4cars.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipating the future actions of a human is a widely studied problem in\nrobotics that requires spatio-temporal reasoning. In this work we propose a\ndeep learning approach for anticipation in sensory-rich robotics applications.\nWe introduce a sensory-fusion architecture which jointly learns to anticipate\nand fuse information from multiple sensory streams. Our architecture consists\nof Recurrent Neural Networks (RNNs) that use Long Short-Term Memory (LSTM)\nunits to capture long temporal dependencies. We train our architecture in a\nsequence-to-sequence prediction manner, and it explicitly learns to predict the\nfuture given only a partial temporal context. We further introduce a novel loss\nlayer for anticipation which prevents over-fitting and encourages early\nanticipation. We use our architecture to anticipate driving maneuvers several\nseconds before they happen on a natural driving data set of 1180 miles. The\ncontext for maneuver anticipation comes from multiple sensors installed on the\nvehicle. Our approach shows significant improvement over the state-of-the-art\nin maneuver anticipation by increasing the precision from 77.4% to 90.5% and\nrecall from 71.2% to 87.4%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 19:49:24 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Jain", "Ashesh", ""], ["Singh", "Avi", ""], ["Koppula", "Hema S", ""], ["Soh", "Shane", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1509.05181", "submitter": "Dengji Zhao", "authors": "Dengji Zhao, Sarvapali D. Ramchurn, Nicholas R. Jennings", "title": "Efficient Task Collaboration with Execution Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general task allocation problem, involving multiple agents that\ncollaboratively accomplish tasks and where agents may fail to successfully\ncomplete the tasks assigned to them (known as execution uncertainty). The goal\nis to choose an allocation that maximises social welfare while taking their\nexecution uncertainty into account. We show that this can be achieved by using\nthe post-execution verification (PEV)-based mechanism if and only if agents'\nvaluations satisfy a multilinearity condition. We then consider a more complex\nsetting where an agent's execution uncertainty is not completely predictable by\nthe agent alone but aggregated from all agents' private opinions (known as\ntrust). We show that PEV-based mechanism with trust is still truthfully\nimplementable if and only if the trust aggregation is multilinear.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 09:34:24 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Zhao", "Dengji", ""], ["Ramchurn", "Sarvapali D.", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "1509.05209", "submitter": "Anthony Hunter", "authors": "Antonio Trenta and Anthony Hunter and Sebastian Riedel", "title": "Extraction of evidence tables from abstracts of randomized clinical\n  trials using a maximum entropy classifier and global constraints", "comments": "27 pages, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic use of the published results of randomized clinical trials is\nincreasingly important in evidence-based medicine. In order to collate and\nanalyze the results from potentially numerous trials, evidence tables are used\nto represent trials concerning a set of interventions of interest. An evidence\ntable has columns for the patient group, for each of the interventions being\ncompared, for the criterion for the comparison (e.g. proportion who survived\nafter 5 years from treatment), and for each of the results. Currently, it is a\nlabour-intensive activity to read each published paper and extract the\ninformation for each field in an evidence table. There have been some NLP\nstudies investigating how some of the features from papers can be extracted, or\nat least the relevant sentences identified. However, there is a lack of an NLP\nsystem for the systematic extraction of each item of information required for\nan evidence table. We address this need by a combination of a maximum entropy\nclassifier, and integer linear programming. We use the later to handle\nconstraints on what is an acceptable classification of the features to be\nextracted. With experimental results, we demonstrate substantial advantages in\nusing global constraints (such as the features describing the patient group,\nand the interventions, must occur before the features describing the results of\nthe comparison).\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 11:20:35 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Trenta", "Antonio", ""], ["Hunter", "Anthony", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1509.05257", "submitter": "Ernesto Diaz-Aviles", "authors": "Hoang Thanh Lam and Ernesto Diaz-Aviles and Alessandra Pascale and\n  Yiannis Gkoufas and Bei Chen", "title": "(Blue) Taxi Destination and Trip Time Prediction from Partial\n  Trajectories", "comments": "ECML/PKDD Discovery Challenge 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time estimation of destination and travel time for taxis is of great\nimportance for existing electronic dispatch systems. We present an approach\nbased on trip matching and ensemble learning, in which we leverage the patterns\nobserved in a dataset of roughly 1.7 million taxi journeys to predict the\ncorresponding final destination and travel time for ongoing taxi trips, as a\nsolution for the ECML/PKDD Discovery Challenge 2015 competition. The results of\nour empirical evaluation show that our approach is effective and very robust,\nwhich led our team -- BlueTaxi -- to the 3rd and 7th position of the final\nrankings for the trip time and destination prediction tasks, respectively.\nGiven the fact that the final rankings were computed using a very small test\nset (with only 320 trips) we believe that our approach is one of the most\nrobust solutions for the challenge based on the consistency of our good results\nacross the test sets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 13:51:55 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Lam", "Hoang Thanh", ""], ["Diaz-Aviles", "Ernesto", ""], ["Pascale", "Alessandra", ""], ["Gkoufas", "Yiannis", ""], ["Chen", "Bei", ""]]}, {"id": "1509.05315", "submitter": "Carlo Albert", "authors": "Carlo Albert", "title": "A Simulated Annealing Approach to Bayesian Inference", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generic algorithm for the extraction of probabilistic (Bayesian)\ninformation about model parameters from data is presented. The algorithm\npropagates an ensemble of particles in the product space of model parameters\nand outputs. Each particle update consists of a random jump in parameter space\nfollowed by a simulation of a model output and a Metropolis\nacceptance/rejection step based on a comparison of the simulated output to the\ndata. The distance of a particle to the data is interpreted as an energy and\nthe algorithm is reducing the associated temperature of the ensemble such that\nentropy production is minimized. If this simulated annealing is not too fast\ncompared to the mixing speed in parameter space, the parameter marginal of the\nensemble approaches the Bayesian posterior distribution. Annealing is adaptive\nand depends on certain extensive thermodynamic quantities that can easily be\nmeasured throughout run-time. In the general case, we propose annealing with a\nconstant entropy production rate, which is optimal as long as annealing is not\ntoo fast. For the practically relevant special case of no prior knowledge, we\nderive an optimal fast annealing schedule with a non-constant entropy\nproduction rate. The algorithm does not require the calculation of the density\nof the model likelihood, which makes it interesting for Bayesian parameter\ninference with stochastic models, whose likelihood functions are typically very\nhigh dimensional integrals.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 16:17:58 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Albert", "Carlo", ""]]}, {"id": "1509.05434", "submitter": "Thabet Slimani", "authors": "Thabet Slimani", "title": "A Study Investigating Typical Concepts and Guidelines for Ontology\n  Building", "comments": "8 pages, 2 figures", "journal-ref": "Journal of Emerging Trends in Computing and Information\n  Sciences.Vol. 5, No. 12 December 2014, ISSN 2079-8407, pp.886-893", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In semantic technologies, the shared common understanding of the structure of\ninformation among artifacts (people or software agents) can be realized by\nbuilding an ontology. To do this, it is imperative for an ontology builder to\nanswer several questions: a) what are the main components of an ontology? b)\nHow an ontology look likes and how it works? c) Verify if it is required to\nconsider reusing existing ontologies or not? c) What is the complexity of the\nontology to be developed? d) What are the principles of ontology design and\ndevelopment? e) How to evaluate an ontology? This paper answers all the key\nquestions above. The aim of this paper is to present a set of guiding\nprinciples to help ontology developers and also inexperienced users to answer\nsuch questions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 20:27:31 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Slimani", "Thabet", ""]]}, {"id": "1509.05437", "submitter": "Thabet Slimani", "authors": "Thabet Slimani", "title": "Class Association Rules Mining based Rough Set Method", "comments": "10 pages, 2 figures", "journal-ref": "International Journal of Engineering and Technology (IJET), Vol 6\n  No 6 Dec 2014-Jan 2015, ISSN : 0975-4024, PP. 2786-2794", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper investigates the mining of class association rules with rough set\napproach. In data mining, an association occurs between two set of elements\nwhen one element set happen together with another. A class association rule set\n(CARs) is a subset of association rules with classes specified as their\nconsequences. We present an efficient algorithm for mining the finest class\nrule set inspired form Apriori algorithm, where the support and confidence are\ncomputed based on the elementary set of lower approximation included in the\nproperty of rough set theory. Our proposed approach has been shown very\neffective, where the rough set approach for class association discovery is much\nsimpler than the classic association method.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 20:42:19 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Slimani", "Thabet", ""]]}, {"id": "1509.05463", "submitter": "Xi Zhang", "authors": "Xi Zhang and Yanwei Fu and Shanshan Jiang and Leonid Sigal and Gady\n  Agam", "title": "Learning from Synthetic Data Using a Stacked Multichannel Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from synthetic data has many important and practical applications.\nAn example of application is photo-sketch recognition. Using synthetic data is\nchallenging due to the differences in feature distributions between synthetic\nand real data, a phenomenon we term synthetic gap. In this paper, we\ninvestigate and formalize a general framework-Stacked Multichannel Autoencoder\n(SMCAE) that enables bridging the synthetic gap and learning from synthetic\ndata more efficiently. In particular, we show that our SMCAE can not only\ntransform and use synthetic data on the challenging face-sketch recognition\ntask, but that it can also help simulate real images, which can be used for\ntraining classifiers for recognition. Preliminary experiments validate the\neffectiveness of the framework.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 22:26:30 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 19:28:12 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Zhang", "Xi", ""], ["Fu", "Yanwei", ""], ["Jiang", "Shanshan", ""], ["Sigal", "Leonid", ""], ["Agam", "Gady", ""]]}, {"id": "1509.05526", "submitter": "EPTCS", "authors": "Matt Kaufmann, David L. Rager", "title": "Proceedings Thirteenth International Workshop on the ACL2 Theorem Prover\n  and Its Applications", "comments": "Celebrating the 25th anniversary of ACL2", "journal-ref": "EPTCS 192, 2015", "doi": "10.4204/EPTCS.192", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Thirteenth International Workshop\non the ACL2 Theorem Prover and Its Applications, ACL2 2015, a two-day workshop\nheld in Austin, Texas, USA, on October 1-2, 2015. ACL2 workshops occur at\napproximately 18-month intervals and provide a major technical forum for\nresearchers to present and discuss improvements and extensions to the theorem\nprover, comparisons of ACL2 with other systems, and applications of ACL2 in\nformal verification.\n  ACL2 is a state-of-the-art automated reasoning system that has been\nsuccessfully applied in academia, government, and industry for specification\nand verification of computing systems and in teaching computer science courses.\nIn 2005, Boyer, Kaufmann, and Moore were awarded the 2005 ACM Software System\nAward for their work on ACL2 and the other theorem provers in the Boyer-Moore\nfamily.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 07:40:46 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Kaufmann", "Matt", ""], ["Rager", "David L.", ""]]}, {"id": "1509.05636", "submitter": "Seetha Ramaiah M", "authors": "M. Seetha Ramaiah, Amitabha Mukerjee, Arindam Chakraborty, Sadbodh\n  Sharma", "title": "Visual Generalized Coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem in robotics is that of using vision to identify a robot's own\nbody and the world around it. Many models attempt to recover the traditional\nC-space parameters. Instead, we propose an alternative C-space by deriving\ngeneralized coordinates from $n$ images of the robot. We show that the space of\nsuch images is bijective to the motion space, so these images lie on a manifold\n$\\mathcal{V}$ homeomorphic to the canonical C-space. We now approximate this\nmanifold as a set of $n$ neighbourhood tangent spaces that result in a graph,\nwhich we call the Visual Roadmap (VRM). Given a new robot image, we perform\ninverse kinematics visually by interpolating between nearby images in the image\nspace. Obstacles are projected onto the VRM in $O(n)$ time by superimposition\nof images, leading to the identification of collision poses. The edges joining\nthe free nodes can now be checked with a visual local planner, and free-space\nmotions computed in $O(nlogn)$ time. This enables us to plan paths in the image\nspace for a robot manipulator with unknown link geometries, DOF, kinematics,\nobstacles, and camera pose. We sketch the proofs for the main theoretical\nideas, identify the assumptions, and demonstrate the approach for both\narticulated and mobile robots. We also investigate the feasibility of the\nprocess by investigating various metrics and image sampling densities, and\ndemonstrate it on simulated and real robots.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 14:17:57 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Ramaiah", "M. Seetha", ""], ["Mukerjee", "Amitabha", ""], ["Chakraborty", "Arindam", ""], ["Sharma", "Sadbodh", ""]]}, {"id": "1509.05722", "submitter": "Miguel Angel Rodriguez Marquez", "authors": "Michael Zehnder, Holger Wache, Hans-Friedrich Witschel, Danilo\n  Zanatta, Miguel Rodriguez", "title": "Energy saving in smart homes based on consumer behaviour: A case study", "comments": "To be presented on IEEE International Smart Cities Conference 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a case study of a recommender system that can be used to\nsave energy in smart homes without lowering the comfort of the inhabitants. We\npresent an algorithm that uses consumer behavior data only and uses machine\nlearning to suggest actions for inhabitants to reduce the energy consumption of\ntheir homes. The system mines for frequent and periodic patterns in the event\ndata provided by the Digitalstrom home automation system. These patterns are\nconverted into association rules, prioritized and compared with the current\nbehavior of the inhabitants. If the system detects an opportunities to save\nenergy without decreasing the comfort level it sends a recommendation to the\nresidents.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 17:31:25 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Zehnder", "Michael", ""], ["Wache", "Holger", ""], ["Witschel", "Hans-Friedrich", ""], ["Zanatta", "Danilo", ""], ["Rodriguez", "Miguel", ""]]}, {"id": "1509.05725", "submitter": "Sebastian Ordyniak", "authors": "Serge Gaspers, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider,\n  and Stanislav \\v{Z}ivn\\'y", "title": "Backdoors into Heterogeneous Classes of SAT and CSP", "comments": "to appear in JCSS, full version of an AAAI 2014 paper", "journal-ref": "Journal of Computer and System Sciences 85 38-56 (2017)", "doi": "10.1016/j.jcss.2016.10.007", "report-no": null, "categories": "cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the classical notion of strong and weak backdoor sets\nfor SAT and CSP by allowing that different instantiations of the backdoor\nvariables result in instances that belong to different base classes; the union\nof the base classes forms a heterogeneous base class. Backdoor sets to\nheterogeneous base classes can be much smaller than backdoor sets to\nhomogeneous ones, hence they are much more desirable but possibly harder to\nfind. We draw a detailed complexity landscape for the problem of detecting\nstrong and weak backdoor sets into heterogeneous base classes for SAT and CSP.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 17:39:33 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 09:49:56 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Gaspers", "Serge", ""], ["Misra", "Neeldhara", ""], ["Ordyniak", "Sebastian", ""], ["Szeider", "Stefan", ""], ["\u017divn\u00fd", "Stanislav", ""]]}, {"id": "1509.05742", "submitter": "Haohan Wang", "authors": "Haohan Wang, Madhavi K. Ganapathiraju", "title": "Evaluation of Protein-protein Interaction Predictors with Noisy\n  Partially Labeled Data Sets", "comments": "preprint version, 9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein-protein interaction (PPI) prediction is an important problem in\nmachine learning and computational biology. However, there is no data set for\ntraining or evaluation purposes, where all the instances are accurately\nlabeled. Instead, what is available are instances of positive class (with\npossibly noisy labels) and no instances of negative class. The non-availability\nof negative class data is typically handled with the observation that randomly\nchosen protein-pairs have a nearly 100% chance of being negative class, as only\n1 in 1,500 protein pairs expected is expected to be an interacting pair. In\nthis paper, we focused on the problem that non-availability of accurately\nlabeled testing data sets in the domain of protein-protein interaction (PPI)\nprediction may lead to biased evaluation results. We first showed that not\nacknowledging the inherent skew in the interactome (i.e. rare occurrence of\npositive instances) leads to an over-estimated accuracy of the predictor. Then\nwe show that, with the belief that positive interactions are a rare category,\nsampling random pairs of proteins excluding known interacting proteins set as\nthe negative testing data set could lead to an under-estimated evaluation\nresult. We formalized those two problems to validate the above claim, and based\non the formalization, we proposed a balancing method to cancel out the\nover-estimation with under-estimation. Finally, our experiments validated the\ntheoretical aspects and showed that this balancing evaluation could evaluate\nthe exact performance without availability of golden standard data sets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 18:45:49 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Wang", "Haohan", ""], ["Ganapathiraju", "Madhavi K.", ""]]}, {"id": "1509.05870", "submitter": "Yi Fan", "authors": "Yi Fan, Chengqian Li, Zongjie Ma, LjiLjana Brankovic, Vladimir\n  Estivill-Castro, Abdul Sattar", "title": "Exploiting Reduction Rules and Data Structures: Local Search for Minimum\n  Vertex Cover in Massive Graphs", "comments": "7 pages, 3 figures, 2 tables, 6 algorithms, submitted to AAAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Vertex Cover (MinVC) problem is a well-known NP-hard problem.\nRecently there has been great interest in solving this problem on real-world\nmassive graphs. For such graphs, local search is a promising approach to\nfinding optimal or near-optimal solutions. In this paper we propose a local\nsearch algorithm that exploits reduction rules and data structures to solve the\nMinVC problem in such graphs. Experimental results on a wide range of real-word\nmassive graphs show that our algorithm finds better covers than\nstate-of-the-art local search algorithms for MinVC. Also we present interesting\nresults about the complexities of some well-known heuristics.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 10:48:31 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Fan", "Yi", ""], ["Li", "Chengqian", ""], ["Ma", "Zongjie", ""], ["Brankovic", "LjiLjana", ""], ["Estivill-Castro", "Vladimir", ""], ["Sattar", "Abdul", ""]]}, {"id": "1509.05962", "submitter": "Rakesh Achanta", "authors": "Rakesh Achanta, Trevor Hastie", "title": "Telugu OCR Framework using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the task of Optical Character Recognition(OCR) for\nthe Telugu script. We present an end-to-end framework that segments the text\nimage, classifies the characters and extracts lines using a language model. The\nsegmentation is based on mathematical morphology. The classification module,\nwhich is the most challenging task of the three, is a deep convolutional neural\nnetwork. The language is modelled as a third degree markov chain at the glyph\nlevel. Telugu script is a complex alphasyllabary and the language is\nagglutinative, making the problem hard. In this paper we apply the latest\nadvances in neural networks to achieve state-of-the-art error rates. We also\nreview convolutional neural networks in great detail and expound the\nstatistical justification behind the many tricks needed to make Deep Learning\nwork.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 03:35:05 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 02:29:04 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Achanta", "Rakesh", ""], ["Hastie", "Trevor", ""]]}, {"id": "1509.06254", "submitter": "Pablo Rodriguez-Mier", "authors": "Pablo Rodriguez-Mier, Manuel Mucientes, Manuel Lama", "title": "Hybrid Optimization Algorithm for Large-Scale QoS-Aware Service\n  Composition", "comments": "Preprint accepted to appear in IEEE Transactions on Services\n  Computing 2015", "journal-ref": null, "doi": "10.1109/TSC.2015.2480396", "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a hybrid approach for automatic composition of Web\nservices that generates semantic input-output based compositions with optimal\nend-to-end QoS, minimizing the number of services of the resulting composition.\nThe proposed approach has four main steps: 1) generation of the composition\ngraph for a request; 2) computation of the optimal composition that minimizes a\nsingle objective QoS function; 3) multi-step optimizations to reduce the search\nspace by identifying equivalent and dominated services; and 4) hybrid\nlocal-global search to extract the optimal QoS with the minimum number of\nservices. An extensive validation with the datasets of the Web Service\nChallenge 2009-2010 and randomly generated datasets shows that: 1) the\ncombination of local and global optimization is a general and powerful\ntechnique to extract optimal compositions in diverse scenarios; and 2) the\nhybrid strategy performs better than the state-of-the-art, obtaining solutions\nwith less services and optimal QoS.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 14:56:28 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Rodriguez-Mier", "Pablo", ""], ["Mucientes", "Manuel", ""], ["Lama", "Manuel", ""]]}, {"id": "1509.06279", "submitter": "Anant Baijal", "authors": "Anant Baijal, Jaeyoun Cho, Woojung Lee and Byeong-Seob Ko", "title": "Sports highlights generation based on acoustic events detection: A rugby\n  case study", "comments": "IEEE International Conference on Consumer Electronics (IEEE ICCE\n  2015)", "journal-ref": null, "doi": "10.1109/ICCE.2015.7066303", "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the challenging problem of generating highlights from sports\nbroadcasts utilizing audio information only. A language-independent,\nmulti-stage classification approach is employed for detection of key acoustic\nevents which then act as a platform for summarization of highlight scenes.\nObjective results and human experience indicate that our system is highly\nefficient.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 12:47:09 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Baijal", "Anant", ""], ["Cho", "Jaeyoun", ""], ["Lee", "Woojung", ""], ["Ko", "Byeong-Seob", ""]]}, {"id": "1509.06589", "submitter": "Nicol\\`o Navarin", "authors": "Giovanni Da San Martino, Nicol\\`o Navarin, and Alessandro Sperduti", "title": "Graph Kernels exploiting Weisfeiler-Lehman Graph Isomorphism Test\n  Extensions", "comments": null, "journal-ref": "Neural Information Processing, Volume 8835 of the series Lecture\n  Notes in Computer Science pp 93-100, 2014 Springer International Publishing", "doi": "10.1007/978-3-319-12640-1_12", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel graph kernel framework inspired the by the\nWeisfeiler-Lehman (WL) isomorphism tests. Any WL test comprises a relabelling\nphase of the nodes based on test-specific information extracted from the graph,\nfor example the set of neighbours of a node. We defined a novel relabelling and\nderived two kernels of the framework from it. The novel kernels are very fast\nto compute and achieve state-of-the-art results on five real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 13:21:08 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Navarin", "Nicol\u00f2", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "1509.06594", "submitter": "Martha Lewis", "authors": "Bob Coecke and Martha Lewis", "title": "A Compositional Explanation of the Pet Fish Phenomenon", "comments": "QI2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `pet fish' phenomenon is often cited as a paradigm example of the\n`non-compositionality' of human concept use. We show here how this phenomenon\nis naturally accommodated within a compositional distributional model of\nmeaning. This model describes the meaning of a composite concept by accounting\nfor interaction between its constituents via their grammatical roles. We give\ntwo illustrative examples to show how the qualitative phenomena are exhibited.\nWe go on to apply the model to experimental data, and finally discuss\nextensions of the formalism.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 13:33:34 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Coecke", "Bob", ""], ["Lewis", "Martha", ""]]}, {"id": "1509.06664", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel, Edward Grefenstette, Karl Moritz Hermann,\n  Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Phil Blunsom", "title": "Reasoning about Entailment with Neural Attention", "comments": "ICLR 2016 camera-ready, 9 pages, 10 figures (incl. subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 16:08:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 22:12:52 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2016 17:28:30 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 10:32:06 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""], ["Hermann", "Karl Moritz", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Blunsom", "Phil", ""]]}, {"id": "1509.06731", "submitter": "Liangliang Cao", "authors": "Nikolai Yakovenko, Liangliang Cao, Colin Raffel and James Fan", "title": "Poker-CNN: A Pattern Learning Strategy for Making Draws and Bets in\n  Poker Games", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poker is a family of card games that includes many variations. We hypothesize\nthat most poker games can be solved as a pattern matching problem, and propose\ncreating a strong poker playing system based on a unified poker representation.\nOur poker player learns through iterative self-play, and improves its\nunderstanding of the game by training on the results of its previous actions\nwithout sophisticated domain knowledge. We evaluate our system on three poker\ngames: single player video poker, two-player Limit Texas Hold'em, and finally\ntwo-player 2-7 triple draw poker. We show that our model can quickly learn\npatterns in these very different poker games while it improves from zero\nknowledge to a competitive player against human experts.\n  The contributions of this paper include: (1) a novel representation for poker\ngames, extendable to different poker variations, (2) a CNN based learning model\nthat can effectively learn the patterns in three different games, and (3) a\nself-trained system that significantly beats the heuristic-based program on\nwhich it is trained, and our system is competitive against human expert\nplayers.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 19:05:39 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Yakovenko", "Nikolai", ""], ["Cao", "Liangliang", ""], ["Raffel", "Colin", ""], ["Fan", "James", ""]]}, {"id": "1509.06842", "submitter": "Shayan Poursoltan Mr", "authors": "Shayan Poursoltan, Frank Neumann", "title": "A Feature-Based Comparison of Evolutionary Computing Techniques for\n  Constrained Continuous Optimisation", "comments": "16 Pagesm 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have been frequently applied to constrained\ncontinuous optimisation problems. We carry out feature based comparisons of\ndifferent types of evolutionary algorithms such as evolution strategies,\ndifferential evolution and particle swarm optimisation for constrained\ncontinuous optimisation. In our study, we examine how sets of constraints\ninfluence the difficulty of obtaining close to optimal solutions. Using a\nmulti-objective approach, we evolve constrained continuous problems having a\nset of linear and/or quadratic constraints where the different evolutionary\napproaches show a significant difference in performance. Afterwards, we discuss\nthe features of the constraints that exhibit a difference in performance of the\ndifferent evolutionary approaches under consideration.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 04:30:05 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Poursoltan", "Shayan", ""], ["Neumann", "Frank", ""]]}, {"id": "1509.06849", "submitter": "Sungsoo Ahn", "authors": "Sungsoo Ahn (1), Sejun Park (1), Michael Chertkov (2), Jinwoo Shin (1)\n  ((1) Korea Advanced Institute of Science and Technology (2) Los Alamos\n  National Laboratory)", "title": "Minimum Weight Perfect Matching via Blossom Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-product Belief Propagation (BP) is a popular message-passing algorithm\nfor computing a Maximum-A-Posteriori (MAP) assignment over a distribution\nrepresented by a Graphical Model (GM). It has been shown that BP can solve a\nnumber of combinatorial optimization problems including minimum weight\nmatching, shortest path, network flow and vertex cover under the following\ncommon assumption: the respective Linear Programming (LP) relaxation is tight,\ni.e., no integrality gap is present. However, when LP shows an integrality gap,\nno model has been known which can be solved systematically via sequential\napplications of BP. In this paper, we develop the first such algorithm, coined\nBlossom-BP, for solving the minimum weight matching problem over arbitrary\ngraphs. Each step of the sequential algorithm requires applying BP over a\nmodified graph constructed by contractions and expansions of blossoms, i.e.,\nodd sets of vertices. Our scheme guarantees termination in O(n^2) of BP runs,\nwhere n is the number of vertices in the original graph. In essence, the\nBlossom-BP offers a distributed version of the celebrated Edmonds' Blossom\nalgorithm by jumping at once over many sub-steps with a single BP. Moreover,\nour result provides an interpretation of the Edmonds' algorithm as a sequence\nof LPs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 05:49:53 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Park", "Sejun", ""], ["Chertkov", "Michael", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1509.07035", "submitter": "David Sousa-Rodrigues", "authors": "Cristian Jimenez-Romero and David Sousa-Rodrigues and Jeffrey H.\n  Johnson", "title": "Designing Behaviour in Bio-inspired Robots Using Associative Topologies\n  of Spiking-Neural-Networks", "comments": "Paper submitted to the BICT 2015 Conference in New York City, United\n  States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the design and control of the behaviour of agents and\nrobots using simple circuits of spiking neurons and Spike Timing Dependent\nPlasticity (STDP) as a mechanism of associative and unsupervised learning.\nBased on a \"reward and punishment\" classical conditioning, it is demonstrated\nthat these robots learnt to identify and avoid obstacles as well as to identify\nand look for rewarding stimuli. Using the simulation and programming\nenvironment NetLogo, a software engine for the Integrate and Fire model was\ndeveloped, which allowed us to monitor in discrete time steps the dynamics of\neach single neuron, synapse and spike in the proposed neural networks. These\nspiking neural networks (SNN) served as simple brains for the experimental\nrobots. The Lego Mindstorms robot kit was used for the embodiment of the\nsimulated agents. In this paper the topological building blocks are presented\nas well as the neural parameters required to reproduce the experiments. This\npaper summarizes the resulting behaviour as well as the observed dynamics of\nthe neural circuits. The Internet-link to the NetLogo code is included in the\nannex.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 15:40:30 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 14:29:14 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Jimenez-Romero", "Cristian", ""], ["Sousa-Rodrigues", "David", ""], ["Johnson", "Jeffrey H.", ""]]}, {"id": "1509.07062", "submitter": "Paul Harrenstein", "authors": "Haris Aziz, Paul Harrenstein, J\\'er\\^ome Lang, and Michael Wooldridge", "title": "Boolean Hedonic Games", "comments": "This paper was orally presented at the Eleventh Conference on Logic\n  and the Foundations of Game and Decision Theory (LOFT 2014) in Bergen,\n  Norway, July 27-30, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study hedonic games with dichotomous preferences. Hedonic games are\ncooperative games in which players desire to form coalitions, but only care\nabout the makeup of the coalitions of which they are members; they are\nindifferent about the makeup of other coalitions. The assumption of dichotomous\npreferences means that, additionally, each player's preference relation\npartitions the set of coalitions of which that player is a member into just two\nequivalence classes: satisfactory and unsatisfactory. A player is indifferent\nbetween satisfactory coalitions, and is indifferent between unsatisfactory\ncoalitions, but strictly prefers any satisfactory coalition over any\nunsatisfactory coalition. We develop a succinct representation for such games,\nin which each player's preference relation is represented by a propositional\nformula. We show how solution concepts for hedonic games with dichotomous\npreferences are characterised by propositional formulas.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 17:07:54 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Aziz", "Haris", ""], ["Harrenstein", "Paul", ""], ["Lang", "J\u00e9r\u00f4me", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1509.07074", "submitter": "Soumi Chaki", "authors": "Akhilesh K Verma, Soumi Chaki, Aurobinda Routray, William K Mohanty,\n  Mamata Jenamani", "title": "Quantification of sand fraction from seismic attributes using\n  Neuro-Fuzzy approach", "comments": "Journal of Applied Geophysics, volume 111, page 141-155", "journal-ref": null, "doi": "10.1016/j.jappgeo.2014.10.005", "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we illustrate the modeling of a reservoir property (sand\nfraction) from seismic attributes namely seismic impedance, seismic amplitude,\nand instantaneous frequency using Neuro-Fuzzy (NF) approach. Input dataset\nincludes 3D post-stacked seismic attributes and six well logs acquired from a\nhydrocarbon field located in the western coast of India. Presence of thin sand\nand shale layers in the basin area makes the modeling of reservoir\ncharacteristic a challenging task. Though seismic data is helpful in\nextrapolation of reservoir properties away from boreholes; yet, it could be\nchallenging to delineate thin sand and shale reservoirs using seismic data due\nto its limited resolvability. Therefore, it is important to develop\nstate-of-art intelligent methods for calibrating a nonlinear mapping between\nseismic data and target reservoir variables. Neural networks have shown its\npotential to model such nonlinear mappings; however, uncertainties associated\nwith the model and datasets are still a concern. Hence, introduction of Fuzzy\nLogic (FL) is beneficial for handling these uncertainties. More specifically,\nhybrid variants of Artificial Neural Network (ANN) and fuzzy logic, i.e., NF\nmethods, are capable for the modeling reservoir characteristics by integrating\nthe explicit knowledge representation power of FL with the learning ability of\nneural networks. The documented results in this study demonstrate acceptable\nresemblance between target and predicted variables, and hence, encourage the\napplication of integrated machine learning approaches such as Neuro-Fuzzy in\nreservoir characterization domain. Furthermore, visualization of the variation\nof sand probability in the study area would assist in identifying placement of\npotential wells for future drilling operations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 17:48:24 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Verma", "Akhilesh K", ""], ["Chaki", "Soumi", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K", ""], ["Jenamani", "Mamata", ""]]}, {"id": "1509.07175", "submitter": "Jaimie Murdock", "authors": "Jaimie Murdock and Colin Allen and Simon DeDeo", "title": "Exploration and Exploitation of Victorian Science in Darwin's Reading\n  Notebooks", "comments": "Cognition pre-print, published February 2017; 22 pages, plus 17 pages\n  supporting information, 7 pages references", "journal-ref": "Cognition 159 (2017) 117-126", "doi": "10.1016/j.cognition.2016.11.012", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Search in an environment with an uncertain distribution of resources involves\na trade-off between exploitation of past discoveries and further exploration.\nThis extends to information foraging, where a knowledge-seeker shifts between\nreading in depth and studying new domains. To study this decision-making\nprocess, we examine the reading choices made by one of the most celebrated\nscientists of the modern era: Charles Darwin. From the full-text of books\nlisted in his chronologically-organized reading journals, we generate topic\nmodels to quantify his local (text-to-text) and global (text-to-past) reading\ndecisions using Kullback-Liebler Divergence, a cognitively-validated,\ninformation-theoretic measure of relative surprise. Rather than a pattern of\nsurprise-minimization, corresponding to a pure exploitation strategy, Darwin's\nbehavior shifts from early exploitation to later exploration, seeking unusually\nhigh levels of cognitive surprise relative to previous eras. These shifts,\ndetected by an unsupervised Bayesian model, correlate with major intellectual\nepochs of his career as identified both by qualitative scholarship and Darwin's\nown self-commentary. Our methods allow us to compare his consumption of texts\nwith their publication order. We find Darwin's consumption more exploratory\nthan the culture's production, suggesting that underneath gradual societal\nchanges are the explorations of individual synthesis and discovery. Our\nquantitative methods advance the study of cognitive search through a framework\nfor testing interactions between individual and collective behavior and between\nshort- and long-term consumption choices. This novel application of topic\nmodeling to characterize individual reading complements widespread studies of\ncollective scientific behavior.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 22:41:46 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 03:43:07 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2016 21:47:35 GMT"}, {"version": "v4", "created": "Mon, 22 Aug 2016 21:52:56 GMT"}, {"version": "v5", "created": "Thu, 2 Feb 2017 15:51:17 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Murdock", "Jaimie", ""], ["Allen", "Colin", ""], ["DeDeo", "Simon", ""]]}, {"id": "1509.07266", "submitter": "Smita Roy", "authors": "Smita Roy, Samrat Mondal and Asif Ekbal", "title": "CRDT: Correlation Ratio Based Decision Tree Model for Healthcare Data\n  Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenal growth in the healthcare data has inspired us in investigating\nrobust and scalable models for data mining. For classification problems\nInformation Gain(IG) based Decision Tree is one of the popular choices.\nHowever, depending upon the nature of the dataset, IG based Decision Tree may\nnot always perform well as it prefers the attribute with more number of\ndistinct values as the splitting attribute. Healthcare datasets generally have\nmany attributes and each attribute generally has many distinct values. In this\npaper, we have tried to focus on this characteristics of the datasets while\nanalysing the performance of our proposed approach which is a variant of\nDecision Tree model and uses the concept of Correlation Ratio(CR). Unlike IG\nbased approach, this CR based approach has no biasness towards the attribute\nwith more number of distinct values. We have applied our model on some\nbenchmark healthcare datasets to show the effectiveness of the proposed\ntechnique.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 07:57:27 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Roy", "Smita", ""], ["Mondal", "Samrat", ""], ["Ekbal", "Asif", ""]]}, {"id": "1509.07582", "submitter": "George  Konidaris", "authors": "George Konidaris", "title": "Constructing Abstraction Hierarchies Using a Skill-Symbol Loop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework for building abstraction hierarchies whereby an agent\nalternates skill- and representation-acquisition phases to construct a sequence\nof increasingly abstract Markov decision processes. Our formulation builds on\nrecent results showing that the appropriate abstract representation of a\nproblem is specified by the agent's skills. We describe how such a hierarchy\ncan be used for fast planning, and illustrate the construction of an\nappropriate hierarchy for the Taxi domain.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 04:07:22 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Konidaris", "George", ""]]}, {"id": "1509.07627", "submitter": "Hirokatsu Kataoka", "authors": "Hirokatsu Kataoka, Kenji Iwata, Yutaka Satoh", "title": "Feature Evaluation of Deep Convolutional Neural Networks for Object\n  Recognition and Detection", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we evaluate convolutional neural network (CNN) features using\nthe AlexNet architecture and very deep convolutional network (VGGNet)\narchitecture. To date, most CNN researchers have employed the last layers\nbefore output, which were extracted from the fully connected feature layers.\nHowever, since it is unlikely that feature representation effectiveness is\ndependent on the problem, this study evaluates additional convolutional layers\nthat are adjacent to fully connected layers, in addition to executing simple\ntuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) and\ntransformation, using tools such as principal component analysis. In our\nexperiments, we carried out detection and classification tasks using the\nCaltech 101 and Daimler Pedestrian Benchmark Datasets.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 08:26:53 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Kataoka", "Hirokatsu", ""], ["Iwata", "Kenji", ""], ["Satoh", "Yutaka", ""]]}, {"id": "1509.07831", "submitter": "Jaeyong Sung", "authors": "Jaeyong Sung, Ian Lenz, Ashutosh Saxena", "title": "Deep Multimodal Embedding: Manipulating Novel Objects with Point-clouds,\n  Language and Trajectories", "comments": "IEEE International Conference on Robotics and Automation (ICRA), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot operating in a real-world environment needs to perform reasoning over\na variety of sensor modalities such as vision, language and motion\ntrajectories. However, it is extremely challenging to manually design features\nrelating such disparate modalities. In this work, we introduce an algorithm\nthat learns to embed point-cloud, natural language, and manipulation trajectory\ndata into a shared embedding space with a deep neural network. To learn\nsemantically meaningful spaces throughout our network, we use a loss-based\nmargin to bring embeddings of relevant pairs closer together while driving\nless-relevant cases from different modalities further apart. We use this both\nto pre-train its lower layers and fine-tune our final embedding space, leading\nto a more robust representation. We test our algorithm on the task of\nmanipulating novel objects and appliances based on prior experience with other\nobjects. On a large dataset, we achieve significant improvements in both\naccuracy and inference time over the previous state of the art. We also perform\nend-to-end experiments on a PR2 robot utilizing our learned embedding space.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 18:55:45 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 15:12:33 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Sung", "Jaeyong", ""], ["Lenz", "Ian", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1509.07838", "submitter": "Catalin Ionescu", "authors": "Catalin Ionescu, Orestis Vantzos and Cristian Sminchisescu", "title": "Training Deep Networks with Structured Layers by Matrix Backpropagation", "comments": "This is an extended version of our ICCV 2015 article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network architectures have recently produced excellent results in\na variety of areas in artificial intelligence and visual recognition, well\nsurpassing traditional shallow architectures trained using hand-designed\nfeatures. The power of deep networks stems both from their ability to perform\nlocal computations followed by pointwise non-linearities over increasingly\nlarger receptive fields, and from the simplicity and scalability of the\ngradient-descent training procedure based on backpropagation. An open problem\nis the inclusion of layers that perform global, structured matrix computations\nlike segmentation (e.g. normalized cuts) or higher-order pooling (e.g.\nlog-tangent space metrics defined over the manifold of symmetric positive\ndefinite matrices) while preserving the validity and efficiency of an\nend-to-end deep training framework. In this paper we propose a sound\nmathematical apparatus to formally integrate global structured computation into\ndeep computation architectures. At the heart of our methodology is the\ndevelopment of the theory and practice of backpropagation that generalizes to\nthe calculus of adjoint matrix variations. The proposed matrix backpropagation\nmethodology applies broadly to a variety of problems in machine learning or\ncomputational perception. Here we illustrate it by performing visual\nsegmentation experiments using the BSDS and MSCOCO benchmarks, where we show\nthat deep networks relying on second-order pooling and normalized cuts layers,\ntrained end-to-end using matrix backpropagation, outperform counterparts that\ndo not take advantage of such global layers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 19:14:27 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2015 21:02:43 GMT"}, {"version": "v3", "created": "Tue, 12 Apr 2016 18:39:01 GMT"}, {"version": "v4", "created": "Thu, 14 Apr 2016 11:30:39 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Ionescu", "Catalin", ""], ["Vantzos", "Orestis", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1509.07897", "submitter": "Evgenii D. Vol", "authors": "E. D. Vol", "title": "Quantum Look at two Common Logics: the Logic of Primitive Thinking and\n  the Logic of Everyday Human Reasoning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on ideas of quantum theory of open systems and psychological dual\nsystem theory we propose two novel versions of Non-Boolean logic. The first\nversion can be interpreted in our opinion as simplified description of\nprimitive (mythological) thinking and the second one as the toy model of\neveryday human reasoning in which aside from logical deduction, heuristic\nelements and beliefs also play the considerable role. Several arguments in\nfavor of the interpretations proposed are adduced and discussed in the paper as\nwell.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 06:02:26 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Vol", "E. D.", ""]]}, {"id": "1509.08056", "submitter": "Kun Zhang", "authors": "Kun Zhang, Biwei Huang, Jiji Zhang, Bernhard Sch\\\"olkopf, Clark\n  Glymour", "title": "Discovery and Visualization of Nonstationary Causal Models", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonplace to encounter nonstationary data, of which the underlying\ngenerating process may change over time or across domains. The nonstationarity\npresents both challenges and opportunities for causal discovery. In this paper\nwe propose a principled framework to handle nonstationarity, and develop some\nmethods to address three important questions. First, we propose an enhanced\nconstraint-based method to detect variables whose local mechanisms are\nnonstationary and recover the skeleton of the causal structure over observed\nvariables. Second, we present a way to determine some causal directions by\ntaking advantage of information carried by changing distributions. Third, we\ndevelop a method for visualizing the nonstationarity of causal modules.\nExperimental results on various synthetic and real-world data sets are\npresented to demonstrate the efficacy of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 06:22:01 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 17:54:26 GMT"}, {"version": "v3", "created": "Sat, 18 Jun 2016 09:36:50 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Zhang", "Kun", ""], ["Huang", "Biwei", ""], ["Zhang", "Jiji", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Glymour", "Clark", ""]]}, {"id": "1509.08086", "submitter": "Arvind Kumar", "authors": "Arvind Kumar, Adarsh Anand, Pankaj Kumar Garg and Mohini Agarwal", "title": "Optimal Release Time Decision from Fuzzy Mathematical Programming\n  Perspective", "comments": "10 Pages. arXiv admin note: substantial overlap with text by other\n  authors\n  http://archive.org/stream/Software_Reliability_Assessment_with_OR_Applications/Software_Reliability_Assessment_with_OR_Applications_djvu.txt", "journal-ref": "International Journal of Pure and Applied Mathematics, Volume 103\n  No. 2 2015, 359-376", "doi": "10.12732/ijpam.v103i2.19", "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand for high software reliability requires rigorous testing followed by\nrequirement of robust modeling techniques for software quality prediction. On\none side, firms have to steadily manage the reliability by testing it\nvigorously, the optimal release time determination is their biggest concern. In\npast many models have been developed and much research has been devoted towards\nassessment of release time of software. However, majority of the work deals in\ncrisp study. This paper addresses the problem of release time prediction using\nfuzzy Logic. Here we have formulated a Fuzzy release time problem considering\nthe cost of testing under the impact of warranty period. Results show that\nfuzzy model has good adaptability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 11:41:05 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Kumar", "Arvind", ""], ["Anand", "Adarsh", ""], ["Garg", "Pankaj Kumar", ""], ["Agarwal", "Mohini", ""]]}, {"id": "1509.08088", "submitter": "Noam Hazon", "authors": "Noam Hazon, Mira Gonen, Max Kleb", "title": "Approximation and Heuristic Algorithms for Probabilistic Physical Search\n  on General Graphs", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an agent seeking to obtain an item, potentially available at\ndifferent locations in a physical environment. The traveling costs between\nlocations are known in advance, but there is only probabilistic knowledge\nregarding the possible prices of the item at any given location. Given such a\nsetting, the problem is to find a plan that maximizes the probability of\nacquiring the good while minimizing both travel and purchase costs. Sample\napplications include agents in search-and-rescue or exploration missions, e.g.,\na rover on Mars seeking to mine a specific mineral. These probabilistic\nphysical search problems have been previously studied, but we present the first\napproximation and heuristic algorithms for solving such problems on general\ngraphs. We establish an interesting connection between these problems and\nclassical graph-search problems, which led us to provide the approximation\nalgorithms and hardness of approximation results for our settings. We further\nsuggest several heuristics for practical use, and demonstrate their\neffectiveness with simulation on real graph structure and synthetic graphs.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 11:56:00 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Hazon", "Noam", ""], ["Gonen", "Mira", ""], ["Kleb", "Max", ""]]}, {"id": "1509.08255", "submitter": "Fergal Byrne", "authors": "Fergal Byrne", "title": "Encoding Reality: Prediction-Assisted Cortical Learning Algorithm in\n  Hierarchical Temporal Memory", "comments": "Updated reference to unofficial revision of Hawkins and Ahmad, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the decade since Jeff Hawkins proposed Hierarchical Temporal Memory (HTM)\nas a model of neocortical computation, the theory and the algorithms have\nevolved dramatically. This paper presents a detailed description of HTM's\nCortical Learning Algorithm (CLA), including for the first time a rigorous\nmathematical formulation of all aspects of the computations. Prediction\nAssisted CLA (paCLA), a refinement of the CLA is presented, which is both\ncloser to the neuroscience and adds significantly to the computational power.\nFinally, we summarise the key functions of neocortex which are expressed in\npaCLA implementations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 09:54:08 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 16:13:44 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Byrne", "Fergal", ""]]}, {"id": "1509.08329", "submitter": "Alberto N. Escalante-B.", "authors": "Alberto N. Escalante-B., Laurenz Wiskott", "title": "Theoretical Analysis of the Optimal Free Responses of Graph-Based SFA\n  for the Design of Training Graphs", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slow feature analysis (SFA) is an unsupervised learning algorithm that\nextracts slowly varying features from a time series. Graph-based SFA (GSFA) is\na supervised extension that can solve regression problems if followed by a\npost-processing regression algorithm. A training graph specifies arbitrary\nconnections between the training samples. The connections in current graphs,\nhowever, only depend on the rank of the involved labels. Exploiting the exact\nlabel values makes further improvements in estimation accuracy possible.\n  In this article, we propose the exact label learning (ELL) method to create a\ngraph that codes the desired label explicitly, so that GSFA is able to extract\na normalized version of it directly. The ELL method is used for three tasks:\n(1) We estimate gender from artificial images of human faces (regression) and\nshow the advantage of coding additional labels, particularly skin color. (2) We\nanalyze two existing graphs for regression. (3) We extract compact\ndiscriminative features to classify traffic sign images. When the number of\noutput features is limited, a higher classification rate is obtained compared\nto a graph equivalent to nonlinear Fisher discriminant analysis. The method is\nversatile, directly supports multiple labels, and provides higher accuracy\ncompared to current graphs for the problems considered.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 14:19:59 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Escalante-B.", "Alberto N.", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1509.08396", "submitter": "Jai Manral", "authors": "Jai Manral and Mohammed Alamgir Hossain", "title": "An Innovative Approach for online Meta Search Engine Optimization", "comments": "The 6th Conference on Software, Knowledge, Information Management and\n  Applications, Chengdu, China, September 9-11 2012, #57", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach to identify efficient techniques used in Web\nSearch Engine Optimization (SEO). Understanding SEO factors which can influence\npage ranking in search engine is significant for webmasters who wish to attract\nlarge number of users to their website. Different from previous relevant\nresearch, in this study we developed an intelligent Meta search engine which\naggregates results from various search engines and ranks them based on several\nimportant SEO parameters. The research tries to establish that using more SEO\nparameters in ranking algorithms helps in retrieving better search results thus\nincreasing user satisfaction. Initial results generated from Meta search engine\noutperformed existing search engines in terms of better retrieved search\nresults with high precision.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 17:08:28 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Manral", "Jai", ""], ["Hossain", "Mohammed Alamgir", ""]]}, {"id": "1509.08434", "submitter": "Sayyed Ali Mirsoleimani", "authors": "S. Ali Mirsoleimani, Aske Plaat and Jaap van den Herik", "title": "Ensemble UCT Needs High Exploitation", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results have shown that the MCTS algorithm (a new, adaptive,\nrandomized optimization algorithm) is effective in a remarkably diverse set of\napplications in Artificial Intelligence, Operations Research, and High Energy\nPhysics. MCTS can find good solutions without domain dependent heuristics,\nusing the UCT formula to balance exploitation and exploration. It has been\nsuggested that the optimum in the exploitation- exploration balance differs for\ndifferent search tree sizes: small search trees needs more exploitation; large\nsearch trees need more exploration. Small search trees occur in variations of\nMCTS, such as parallel and ensemble approaches. This paper investigates the\npossibility of improving the performance of Ensemble UCT by increasing the\nlevel of exploitation. As the search trees becomes smaller we achieve an\nimproved performance. The results are important for improving the performance\nof large scale parallelism of MCTS.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 19:14:43 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Mirsoleimani", "S. Ali", ""], ["Plaat", "Aske", ""], ["Herik", "Jaap van den", ""]]}, {"id": "1509.08535", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh, Barnabas Poczos, Russell Greiner", "title": "Boolean Matrix Factorization and Noisy Completion via Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.DM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix factorization and Boolean matrix completion from noisy\nobservations are desirable unsupervised data-analysis methods due to their\ninterpretability, but hard to perform due to their NP-hardness. We treat these\nproblems as maximum a posteriori inference problems in a graphical model and\npresent a message passing approach that scales linearly with the number of\nobservations and factors. Our empirical study demonstrates that message passing\nis able to recover low-rank Boolean matrices, in the boundaries of\ntheoretically possible recovery and compares favorably with state-of-the-art in\nreal-world applications, such collaborative filtering with large-scale Boolean\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 23:11:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 19:27:13 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 21:05:32 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Poczos", "Barnabas", ""], ["Greiner", "Russell", ""]]}, {"id": "1509.08634", "submitter": "Takayuki Osogami", "authors": "Takayuki Osogami and Makoto Otsuka", "title": "Learning dynamic Boltzmann machines with spike-timing dependent\n  plasticity", "comments": "Preliminary and substantially different version of the paper appeared\n  in http://www.nature.com/articles/srep14149", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a particularly structured Boltzmann machine, which we refer to as\na dynamic Boltzmann machine (DyBM), as a stochastic model of a\nmulti-dimensional time-series. The DyBM can have infinitely many layers of\nunits but allows exact and efficient inference and learning when its parameters\nhave a proposed structure. This proposed structure is motivated by postulates\nand observations, from biological neural networks, that the synaptic weight is\nstrengthened or weakened, depending on the timing of spikes (i.e., spike-timing\ndependent plasticity or STDP). We show that the learning rule of updating the\nparameters of the DyBM in the direction of maximizing the likelihood of given\ntime-series can be interpreted as STDP with long term potentiation and long\nterm depression. The learning rule has a guarantee of convergence and can be\nperformed in a distributed matter (i.e., local in space) with limited memory\n(i.e., local in time).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 08:30:12 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Osogami", "Takayuki", ""], ["Otsuka", "Makoto", ""]]}, {"id": "1509.08639", "submitter": "Krzysztof Wo{\\l}k", "authors": "Krzysztof Wo{\\l}k, Krzysztof Marasek", "title": "Tuned and GPU-accelerated parallel data mining from comparable corpora", "comments": "Machine translation, comparable corpora, Machine learning, NLP,\n  Knowledge-free learning, Unsupervised bi-lingual data mining", "journal-ref": "Lecture Notes in Artificial Intelligence, p. 32-40, ISBN:\n  978-3-319-24032-9, Springer, 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multilingual nature of the world makes translation a crucial requirement\ntoday. Parallel dictionaries constructed by humans are a widely-available\nresource, but they are limited and do not provide enough coverage for good\nquality translation purposes, due to out-of-vocabulary words and neologisms.\nThis motivates the use of statistical translation systems, which are\nunfortunately dependent on the quantity and quality of training data. Such has\na very limited availability especially for some languages and very narrow text\ndomains. Is this research we present our improvements to Yalign mining\nmethodology by reimplementing the comparison algorithm, introducing a tuning\nscripts and by improving performance using GPU computing acceleration. The\nexperiments are conducted on various text domains and bi-data is extracted from\nthe Wikipedia dumps.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 08:44:14 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Wo\u0142k", "Krzysztof", ""], ["Marasek", "Krzysztof", ""]]}, {"id": "1509.08717", "submitter": "Nourh\\`ene Alaya", "authors": "Nourh\\`ene Alaya and Sadok Ben Yahia and Myriam Lamolle", "title": "Towards Unveiling the Ontology Key Features Altering Reasoner\n  Performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with ontologies is one of the core fields of research in\nDescription Logics. A variety of efficient reasoner with highly optimized\nalgorithms have been developed to allow inference tasks on expressive ontology\nlanguages such as OWL(DL). However, reasoner reported computing times have\nexceeded and sometimes fall behind the expected theoretical values. From an\nempirical perspective, it is not yet well understood, which particular aspects\nin the ontology are reasoner performance degrading factors. In this paper, we\nconducted an investigation about state of art works that attempted to portray\npotential correlation between reasoner empirical behaviour and particular\nontological features. These works were analysed and then broken down into\ncategories. Further, we proposed a set of ontology features covering a broad\nrange of structural and syntactic ontology characteristics. We claim that these\nfeatures are good indicators of the ontology hardness level against reasoning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 12:31:03 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Alaya", "Nourh\u00e8ne", ""], ["Yahia", "Sadok Ben", ""], ["Lamolle", "Myriam", ""]]}, {"id": "1509.08731", "submitter": "Shakir Mohamed", "authors": "Shakir Mohamed and Danilo Jimenez Rezende", "title": "Variational Information Maximisation for Intrinsically Motivated\n  Reinforcement Learning", "comments": "Proceedings of the 29th Conference on Neural Information Processing\n  Systems (NIPS 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mutual information is a core statistical quantity that has applications\nin all areas of machine learning, whether this is in training of density models\nover multiple data modalities, in maximising the efficiency of noisy\ntransmission channels, or when learning behaviour policies for exploration by\nartificial agents. Most learning algorithms that involve optimisation of the\nmutual information rely on the Blahut-Arimoto algorithm --- an enumerative\nalgorithm with exponential complexity that is not suitable for modern machine\nlearning applications. This paper provides a new approach for scalable\noptimisation of the mutual information by merging techniques from variational\ninference and deep learning. We develop our approach by focusing on the problem\nof intrinsically-motivated learning, where the mutual information forms the\ndefinition of a well-known internal drive known as empowerment. Using a\nvariational lower bound on the mutual information, combined with convolutional\nnetworks for handling visual input streams, we develop a stochastic\noptimisation algorithm that allows for scalable information maximisation and\nempowerment-based reasoning directly from pixels to actions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 13:04:03 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Mohamed", "Shakir", ""], ["Rezende", "Danilo Jimenez", ""]]}, {"id": "1509.08761", "submitter": "Rafael Pe\\~naloza", "authors": "Stefan Borgwardt and Rafael Pe\\~naloza", "title": "Reasoning in Infinitely Valued G-IALCQ", "comments": "Workshop on Weighted Logics for Artificial Intelligence, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy Description Logics (FDLs) are logic-based formalisms used to represent\nand reason with vague or imprecise knowledge. It has been recently shown that\nreasoning in most FDLs using truth values from the interval [0,1] becomes\nundecidable in the presence of a negation constructor and general concept\ninclusion axioms. One exception to this negative result are FDLs whose\nsemantics is based on the infinitely valued G\\\"odel t-norm (G). In this paper,\nwe extend previous decidability results for G-IALC to deal also with qualified\nnumber restrictions. Our novel approach is based on a combination of the known\ncrispification technique for finitely valued FDLs and the automata-based\nprocedure originally developed for reasoning in G-IALC. The proposed approach\ncombines the advantages of these two methods, while removing their respective\ndrawbacks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 14:18:09 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Borgwardt", "Stefan", ""], ["Pe\u00f1aloza", "Rafael", ""]]}, {"id": "1509.08764", "submitter": "Quang Minh Ha", "authors": "Quang Minh Ha, Yves Deville, Quang Dung Pham, Minh Ho\\`ang H\\`a", "title": "On the Min-cost Traveling Salesman Problem with Drone", "comments": "57 pages, technical report, latest work", "journal-ref": null, "doi": "10.1016/j.trc.2017.11.015", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, unmanned aerial vehicles (UAV), also known as\ndrones, have been adopted as part of a new logistic method in the commercial\nsector called \"last-mile delivery\". In this novel approach, they are deployed\nalongside trucks to deliver goods to customers to improve the quality of\nservice and reduce the transportation cost. This approach gives rise to a new\nvariant of the traveling salesman problem (TSP), called TSP with drone (TSP-D).\nA variant of this problem that aims to minimize the time at which truck and\ndrone finish the service (or, in other words, to maximize the quality of\nservice) was studied in the work of Murray and Chu (2015). In contrast, this\npaper considers a new variant of TSP-D in which the objective is to minimize\noperational costs including total transportation cost and one created by waste\ntime a vehicle has to wait for the other. The problem is first formulated\nmathematically. Then, two algorithms are proposed for the solution. The first\nalgorithm (TSP-LS) was adapted from the approach proposed by Murray and Chu\n(2015), in which an optimal TSP solution is converted to a feasible TSP-D\nsolution by local searches. The second algorithm, a Greedy Randomized Adaptive\nSearch Procedure (GRASP), is based on a new split procedure that optimally\nsplits any TSP tour into a TSP-D solution. After a TSP-D solution has been\ngenerated, it is then improved through local search operators. Numerical\nresults obtained on various instances of both objective functions with\ndifferent sizes and characteristics are presented. The results show that GRASP\noutperforms TSP-LS in terms of solution quality under an acceptable running\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 14:19:47 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 06:58:52 GMT"}, {"version": "v3", "created": "Sat, 29 Jul 2017 18:08:35 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Ha", "Quang Minh", ""], ["Deville", "Yves", ""], ["Pham", "Quang Dung", ""], ["H\u00e0", "Minh Ho\u00e0ng", ""]]}, {"id": "1509.08792", "submitter": "Sergio Consoli", "authors": "Sergio Consoli, Jos\\`e Andr\\`es Moreno P\\`erez", "title": "An intelligent extension of Variable Neighbourhood Search for labelling\n  graph problems", "comments": "MIC 2015: The XI Metaheuristics International Conference, 3 pages,\n  Agadir, June 7-10, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an extension of the Variable Neighbourhood Search\n(VNS) which integrates the basic VNS with other complementary approaches from\nmachine learning, statistics and experimental algorithmic, in order to produce\nhigh-quality performance and to completely automate the resulting optimization\nstrategy. The resulting intelligent VNS has been successfully applied to a\ncouple of optimization problems where the solution space consists of the\nsubsets of a finite reference set. These problems are the labelled spanning\ntree and forest problems that are formulated on an undirected labelled graph; a\ngraph where each edge has a label in a finite set of labels L. The problems\nconsist on selecting the subset of labels such that the subgraph generated by\nthese labels has an optimal spanning tree or forest, respectively. These\nproblems have several applications in the real-world, where one aims to ensure\nconnectivity by means of homogeneous connections.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 22:12:42 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Consoli", "Sergio", ""], ["P\u00e8rez", "Jos\u00e8 Andr\u00e8s Moreno", ""]]}, {"id": "1509.08891", "submitter": "Hao Wu", "authors": "Hao Wu", "title": "The Computational Principles of Learning Ability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been quite a long time since AI researchers in the field of computer\nscience stop talking about simulating human intelligence or trying to explain\nhow brain works. Recently, represented by deep learning techniques, the field\nof machine learning is experiencing unprecedented prosperity and some\napplications with near human-level performance bring researchers confidence to\nimply that their approaches are the promising candidate for understanding the\nmechanism of human brain. However apart from several ancient philological\ncriteria and some imaginary black box tests (Turing test, Chinese room) there\nis no computational level explanation, definition or criteria about\nintelligence or any of its components. Base on the common sense that learning\nability is one critical component of intelligence and inspect from the\nviewpoint of mapping relations, this paper presents two laws which explains\nwhat is the \"learning ability\" as we familiar with and under what conditions a\nmapping relation can be acknowledged as \"Learning Model\".\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 04:25:44 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Wu", "Hao", ""]]}, {"id": "1509.08932", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Jia Yuan Yu and Marco Pavone", "title": "Two Phase $Q-$learning for Bidding-based Vehicle Sharing", "comments": "Submitted to AISTATS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider one-way vehicle sharing systems where customers can rent a car at\none station and drop it off at another. The problem we address is to optimize\nthe distribution of cars, and quality of service, by pricing rentals\nappropriately. We propose a bidding approach that is inspired from auctions and\ntakes into account the significant uncertainty inherent in the problem data\n(e.g., pick-up and drop-off locations, time of requests, and duration of\ntrips). Specifically, in contrast to current vehicle sharing systems, the\noperator does not set prices. Instead, customers submit bids and the operator\ndecides whether to rent or not. The operator can even accept negative bids to\nmotivate drivers to rebalance available cars to unpopular destinations within a\ncity. We model the operator's sequential decision-making problem as a\n\\emph{constrained Markov decision problem} (CMDP) and propose and rigorously\nanalyze a novel two phase $Q$-learning algorithm for its solution. Numerical\nexperiments are presented and discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 20:14:48 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2015 19:09:50 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2015 01:50:43 GMT"}], "update_date": "2015-10-21", "authors_parsed": [["Chow", "Yinlam", ""], ["Yu", "Jia Yuan", ""], ["Pavone", "Marco", ""]]}, {"id": "1509.08973", "submitter": "Tadahiro Taniguchi", "authors": "Tadahiro Taniguchi, Takayuki Nagai, Tomoaki Nakamura, Naoto Iwahashi,\n  Tetsuya Ogata, and Hideki Asoh", "title": "Symbol Emergence in Robotics: A Survey", "comments": "submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn the use of language through physical interaction with their\nenvironment and semiotic communication with other people. It is very important\nto obtain a computational understanding of how humans can form a symbol system\nand obtain semiotic skills through their autonomous mental development.\nRecently, many studies have been conducted on the construction of robotic\nsystems and machine-learning methods that can learn the use of language through\nembodied multimodal interaction with their environment and other systems.\nUnderstanding human social interactions and developing a robot that can\nsmoothly communicate with human users in the long term, requires an\nunderstanding of the dynamics of symbol systems and is crucially important. The\nembodied cognition and social interaction of participants gradually change a\nsymbol system in a constructive manner. In this paper, we introduce a field of\nresearch called symbol emergence in robotics (SER). SER is a constructive\napproach towards an emergent symbol system. The emergent symbol system is\nsocially self-organized through both semiotic communications and physical\ninteractions with autonomous cognitive developmental agents, i.e., humans and\ndevelopmental robots. Specifically, we describe some state-of-art research\ntopics concerning SER, e.g., multimodal categorization, word discovery, and a\ndouble articulation analysis, that enable a robot to obtain words and their\nembodied meanings from raw sensory--motor information, including visual\ninformation, haptic information, auditory information, and acoustic speech\nsignals, in a totally unsupervised manner. Finally, we suggest future\ndirections of research in SER.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 23:16:48 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Taniguchi", "Tadahiro", ""], ["Nagai", "Takayuki", ""], ["Nakamura", "Tomoaki", ""], ["Iwahashi", "Naoto", ""], ["Ogata", "Tetsuya", ""], ["Asoh", "Hideki", ""]]}, {"id": "1509.09149", "submitter": "Frederick Benaben", "authors": "Frederick Benaben, Vatcharaphun Rajsiri, Jean-Pierre Lorr\\'e, Herv\\'e\n  Pingaud", "title": "Knowledge-based system for collaborative process specification", "comments": "\\&lt;10.1016/j.compind.2009.10.012\\&gt", "journal-ref": "Computers and Industrial Engineering, Elsevier, 2010, 61 (2),\n  pp.161-175", "doi": "10.1016/j.compind.2009.10.012", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an ontology-based approach for the design of a\ncollaborative business process model (CBP). This CBP is considered as a\nspecification of needs in order to build a collaboration information system\n(CIS) for a network of organisations. The study is a part of a model driven\nengineering approach of the CIS in a specific enterprise interoperability\nframework that will be summarised. An adaptation of the Business Process\nModeling Notation (BPMN) is used to represent the CBP model. We develop a\nknowledge-based system (KbS) which is composed of three main parts: knowledge\ngathering, knowledge representation and reasoning, and collaborative business\nprocess modelling. The first part starts from a high abstraction level where\nknowledge from business partners is captured. A collaboration ontology is\ndefined in order to provide a structure to store and use the knowledge\ncaptured. In parallel, we try to reuse generic existing knowledge about\nbusiness processes from the MIT Process Handbook repository. This results in a\ncollaboration process ontology that is also described. A set of rules is\ndefined in order to extract knowledge about fragments of the CBP model from the\ntwo previous ontologies. These fragments are finally assembled in the third\npart of the KbS. A prototype of the KbS has been developed in order to\nimplement and support this approach. The prototype is a computer-aided design\ntool of the CBP. In this paper, we will present the theoretical aspects of each\npart of this KbS as well as the tools that we developed and used in order to\nsupport its functionalities.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 12:28:14 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Benaben", "Frederick", ""], ["Rajsiri", "Vatcharaphun", ""], ["Lorr\u00e9", "Jean-Pierre", ""], ["Pingaud", "Herv\u00e9", ""]]}, {"id": "1509.09152", "submitter": "Frederick Benaben", "authors": "Frederick Benaben, Wenxin Mu, Nicolas Boissel-Dallier, Anne-Marie\n  Barthe-Delano\\\"e, Sarah Zribi, Herve Pingaud", "title": "Supporting interoperability of collaborative networks through\n  engineering of a service-based Mediation Information System (MISE 2.0)", "comments": "\\&lt;10.1080/17517575.2014.928949\\&gt", "journal-ref": "Enterprise Information Systems, Taylor \\& Francis: STM,\n  Behavioural Science and Public Health Titles, 2015, 9 (5-6), pp.556-582", "doi": "10.1080/17517575.2014.928949", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mediation Information System Engineering project is currently finishing\nits second iteration (MISE 2.0). The main objective of this scientific project\nis to provide any emerging collaborative situation with methods and tools to\ndeploy a Mediation Information System (MIS). MISE 2.0 aims at defining and\ndesigning a service-based platform, dedicated to initiating and supporting the\ninteroperability of collaborative situations among potential partners. This\nMISE 2.0 platform implements a model-driven engineering approach to the design\nof a service-oriented MIS dedicated to supporting the collaborative situation.\nThis approach is structured in three layers, each providing their own key\ninnovative points: (i) the gathering of individual and collaborative knowledge\nto provide appropriate collaborative business behaviour (key point: knowledge\nmanagement, including semantics, exploitation and capitalization), (ii)\ndeployment of a mediation information system able to computerize the previously\ndeduced collaborative processes (key point: the automatic generation of\ncollaborative workflows, including connection with existing devices or\nservices) (iii) the management of the agility of the obtained collaborative\nnetwork of organizations (key point: supervision of collaborative situations\nand relevant exploitation of the gathered data). MISE covers business issues\n(through BPM), technical issues (through an SOA) and agility issues of\ncollaborative situations (through EDA).\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 12:35:39 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Benaben", "Frederick", ""], ["Mu", "Wenxin", ""], ["Boissel-Dallier", "Nicolas", ""], ["Barthe-Delano\u00eb", "Anne-Marie", ""], ["Zribi", "Sarah", ""], ["Pingaud", "Herve", ""]]}, {"id": "1509.09240", "submitter": "Chu Luo", "authors": "Chu Luo", "title": "Solving a Mathematical Problem in Square War: a Go-like Board Game", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a board game: Square War. The game definition of\nSquare War is similar to the classic Chinese board game Go. Then we propose a\nmathematical problem of the game Square War. Finally, we show that the problem\ncan be solved by using a method of mixed mathematics and computer science.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2015 08:09:24 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2015 09:15:36 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Luo", "Chu", ""]]}]