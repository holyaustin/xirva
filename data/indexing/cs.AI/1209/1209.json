[{"id": "1209.0056", "submitter": "Brendan Juba", "authors": "Brendan Juba", "title": "Learning implicitly in reasoning in PAC-Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of answering queries about formulas of propositional\nlogic based on background knowledge partially represented explicitly as other\nformulas, and partially represented as partially obscured examples\nindependently drawn from a fixed probability distribution, where the queries\nare answered with respect to a weaker semantics than usual -- PAC-Semantics,\nintroduced by Valiant (2000) -- that is defined using the distribution of\nexamples. We describe a fairly general, efficient reduction to limited versions\nof the decision problem for a proof system (e.g., bounded space treelike\nresolution, bounded degree polynomial calculus, etc.) from corresponding\nversions of the reasoning problem where some of the background knowledge is not\nexplicitly given as formulas, only learnable from the examples. Crucially, we\ndo not generate an explicit representation of the knowledge extracted from the\nexamples, and so the \"learning\" of the background knowledge is only done\nimplicitly. As a consequence, this approach can utilize formulas as background\nknowledge that are not perfectly valid over the distribution---essentially the\nanalogue of agnostic learning here.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2012 05:13:00 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Juba", "Brendan", ""]]}, {"id": "1209.0308", "submitter": "Muneendra Ojha", "authors": "Muneendra Ojha", "title": "Optimizing Supply Chain Management using Gravitational Search Algorithm\n  and Multi Agent System", "comments": "11 pages, 3 figures, \"Published in Conference of Soft Computing and\n  Problem Solving 2011, Springer\"", "journal-ref": "Proceedings of the International Conference on SocProS 2011, AISC\n  130, pp. 481", "doi": "10.1007/978-81-322-0487-9_47", "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain management is a very dynamic operation research problem where\none has to quickly adapt according to the changes perceived in environment in\norder to maximize the benefit or minimize the loss. Therefore we require a\nsystem which changes as per the changing requirements. Multi agent system\ntechnology in recent times has emerged as a possible way of efficient solution\nimplementation for many such complex problems. Our research here focuses on\nbuilding a Multi Agent System (MAS), which implements a modified version of\nGravitational Search swarm intelligence Algorithm (GSA) to find out an optimal\nstrategy in managing the demand supply chain. We target the grains distribution\nsystem among various centers of Food Corporation of India (FCI) as application\ndomain. We assume centers with larger stocks as objects of greater mass and\nvice versa. Applying Newtonian law of gravity as suggested in GSA, larger\nobjects attract objects of smaller mass towards itself, creating a virtual\ngrain supply source. As heavier object sheds its mass by supplying some to the\none in demand, it loses its gravitational pull and thus keeps the whole system\nof supply chain per-fectly in balance. The multi agent system helps in\ncontinuous updation of the whole system with the help of autonomous agents\nwhich react to the change in environment and act accordingly. This model also\nreduces the communication bottleneck to greater extents.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 11:20:57 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Ojha", "Muneendra", ""]]}, {"id": "1209.0852", "submitter": "Ehsan Saboori Mr.", "authors": "Ehsan Saboori, Shafigh Parsazad, Yasaman Sanatkhani", "title": "Automatic firewall rules generator for anomaly detection systems with\n  Apriori algorithm", "comments": "4 Pages", "journal-ref": "2010 3rd International Conference on Advanced Computer Theory and\n  Engineering (ICACTE), vol.6, no., pp.V6-57-V6-60, 2010", "doi": "10.1109/ICACTE.2010.5579365", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network intrusion detection systems have become a crucial issue for computer\nsystems security infrastructures. Different methods and algorithms are\ndeveloped and proposed in recent years to improve intrusion detection systems.\nThe most important issue in current systems is that they are poor at detecting\nnovel anomaly attacks. These kinds of attacks refer to any action that\nsignificantly deviates from the normal behaviour which is considered intrusion.\nThis paper proposed a model to improve this problem based on data mining\ntechniques. Apriori algorithm is used to predict novel attacks and generate\nreal-time rules for firewall. Apriori algorithm extracts interesting\ncorrelation relationships among large set of data items. This paper illustrates\nhow to use Apriori algorithm in intrusion detection systems to cerate a\nautomatic firewall rules generator to detect novel anomaly attack. Apriori is\nthe best-known algorithm to mine association rules. This is an innovative way\nto find association rules on large scale.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 02:58:13 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Saboori", "Ehsan", ""], ["Parsazad", "Shafigh", ""], ["Sanatkhani", "Yasaman", ""]]}, {"id": "1209.0880", "submitter": "Christian Blum", "authors": "Christian Blum and Verena Schmid and Lukas Baumgartner", "title": "On Solving the Oriented Two-Dimensional Bin Packing Problem under Free\n  Guillotine Cutting: Exploiting the Power of Probabilistic Solution\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-dimensional bin packing problems are highly relevant combinatorial\noptimization problems. They find a large number of applications, for example,\nin the context of transportation or warehousing, and for the cutting of\ndifferent materials such as glass, wood or metal. In this work we deal with the\noriented two-dimensional bin packing problem under free guillotine cutting. In\nthis specific problem a set of oriented rectangular items is given which must\nbe packed into a minimum number of bins of equal size. The first algorithm\nproposed in this work is a randomized multi-start version of a constructive\none-pass heuristic from the literature. Additionally we propose the use of this\nrandomized one-pass heuristic within an evolutionary algorithm. The results of\nthe two proposed algorithms are compared to the best approaches from the\nliterature. In particular the evolutionary algorithm compares very favorably to\ncurrent state-of-the-art approaches. The optimal solution for 4 previously\nunsolved instances could be found.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 07:38:58 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Blum", "Christian", ""], ["Schmid", "Verena", ""], ["Baumgartner", "Lukas", ""]]}, {"id": "1209.0911", "submitter": "Junming Huang Junming Huang", "authors": "Junming Huang, Xue-Qi Cheng, Hua-Wei Shen, Xiaoming Sun, Tao Zhou,\n  Xiaolong Jin", "title": "Conquering the rating bound problem in neighborhood-based collaborative\n  filtering: a function recovery approach", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important tool for information filtering in the era of socialized web,\nrecommender systems have witnessed rapid development in the last decade. As\nbenefited from the better interpretability, neighborhood-based collaborative\nfiltering techniques, such as item-based collaborative filtering adopted by\nAmazon, have gained a great success in many practical recommender systems.\nHowever, the neighborhood-based collaborative filtering method suffers from the\nrating bound problem, i.e., the rating on a target item that this method\nestimates is bounded by the observed ratings of its all neighboring items.\nTherefore, it cannot accurately estimate the unobserved rating on a target\nitem, if its ground truth rating is actually higher (lower) than the highest\n(lowest) rating over all items in its neighborhood. In this paper, we address\nthis problem by formalizing rating estimation as a task of recovering a scalar\nrating function. With a linearity assumption, we infer all the ratings by\noptimizing the low-order norm, e.g., the $l_1/2$-norm, of the second derivative\nof the target scalar function, while remaining its observed ratings unchanged.\nExperimental results on three real datasets, namely Douban, Goodreads and\nMovieLens, demonstrate that the proposed approach can well overcome the rating\nbound problem. Particularly, it can significantly improve the accuracy of\nrating estimation by 37% than the conventional neighborhood-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 09:55:27 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Huang", "Junming", ""], ["Cheng", "Xue-Qi", ""], ["Shen", "Hua-Wei", ""], ["Sun", "Xiaoming", ""], ["Zhou", "Tao", ""], ["Jin", "Xiaolong", ""]]}, {"id": "1209.0997", "submitter": "Kostyantyn Shchekotykhin", "authors": "Kostyantyn Shchekotykhin, Philipp Fleiss, Patrick Rodler, Gerhard\n  Friedrich", "title": "Direct computation of diagnoses for ontology debugging", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern ontology debugging methods allow efficient identification and\nlocalization of faulty axioms defined by a user while developing an ontology.\nThe ontology development process in this case is characterized by rather\nfrequent and regular calls to a reasoner resulting in an early user awareness\nof modeling errors. In such a scenario an ontology usually includes only a\nsmall number of conflict sets, i.e. sets of axioms preserving the faults. This\nproperty allows efficient use of standard model-based diagnosis techniques\nbased on the application of hitting set algorithms to a number of given\nconflict sets. However, in many use cases such as ontology alignment the\nontologies might include many more conflict sets than in usual ontology\ndevelopment settings, thus making precomputation of conflict sets and\nconsequently ontology diagnosis infeasible. In this paper we suggest a\ndebugging approach based on a direct computation of diagnoses that omits\ncalculation of conflict sets. Embedded in an ontology debugger, the proposed\nalgorithm is able to identify diagnoses for an ontology which includes a large\nnumber of faults and for which application of standard diagnosis methods fails.\nThe evaluation results show that the approach is practicable and is able to\nidentify a fault in adequate time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 14:41:57 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Shchekotykhin", "Kostyantyn", ""], ["Fleiss", "Philipp", ""], ["Rodler", "Patrick", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "1209.1086", "submitter": "Aur\\'elien Bellet", "authors": "Aur\\'elien Bellet and Amaury Habrard", "title": "Robustness and Generalization for Metric Learning", "comments": "16 pages, to appear in Neurocomputing", "journal-ref": "Neurocomputing,151(1):259-267, 2015", "doi": "10.1016/j.neucom.2014.09.044", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning has attracted a lot of interest over the last decade, but the\ngeneralization ability of such methods has not been thoroughly studied. In this\npaper, we introduce an adaptation of the notion of algorithmic robustness\n(previously introduced by Xu and Mannor) that can be used to derive\ngeneralization bounds for metric learning. We further show that a weak notion\nof robustness is in fact a necessary and sufficient condition for a metric\nlearning algorithm to generalize. To illustrate the applicability of the\nproposed framework, we derive generalization results for a large family of\nexisting metric learning algorithms, including some sparse formulations that\nare not covered by previous results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 19:48:59 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2013 20:25:54 GMT"}, {"version": "v3", "created": "Mon, 29 Sep 2014 09:27:31 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Bellet", "Aur\u00e9lien", ""], ["Habrard", "Amaury", ""]]}, {"id": "1209.1885", "submitter": "Simon Kramer", "authors": "Simon Kramer and Joshua Sack", "title": "Parametric Constructive Kripke-Semantics for Standard Multi-Agent Belief\n  and Knowledge (Knowledge As Unbiased Belief)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose parametric constructive Kripke-semantics for multi-agent\nKD45-belief and S5-knowledge in terms of elementary set-theoretic constructions\nof two basic functional building blocks, namely bias (or viewpoint) and\nvisibility, functioning also as the parameters of the doxastic and epistemic\naccessibility relation. The doxastic accessibility relates two possible worlds\nwhenever the application of the composition of bias with visibility to the\nfirst world is equal to the application of visibility to the second world. The\nepistemic accessibility is the transitive closure of the union of our doxastic\naccessibility and its converse. Therefrom, accessibility relations for common\nand distributed belief and knowledge can be constructed in a standard way. As a\nresult, we obtain a general definition of knowledge in terms of belief that\nenables us to view S5-knowledge as accurate (unbiased and thus true)\nKD45-belief, negation-complete belief and knowledge as exact KD45-belief and\nS5-knowledge, respectively, and perfect S5-knowledge as precise (exact and\naccurate) KD45-belief, and all this generically for arbitrary functions of bias\nand visibility. Our results can be seen as a semantic complement to previous\nfoundational results by Halpern et al. about the (un)definability and\n(non-)reducibility of knowledge in terms of and to belief, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 06:48:19 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Kramer", "Simon", ""], ["Sack", "Joshua", ""]]}, {"id": "1209.1899", "submitter": "Yuming Xu", "authors": "Xu Yuming", "title": "A matrix approach for computing extensions of argumentation frameworks", "comments": "arXiv admin note: substantial text overlap with arXiv:1110.1416", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The matrices and their sub-blocks are introduced into the study of\ndetermining various extensions in the sense of Dung's theory of argumentation\nframeworks. It is showed that each argumentation framework has its matrix\nrepresentations, and the core semantics defined by Dung can be characterized by\nspecific sub-blocks of the matrix. Furthermore, the elementary permutations of\na matrix are employed by which an efficient matrix approach for finding out all\nextensions under a given semantics is obtained. Different from several\nestablished approaches, such as the graph labelling algorithm, Constraint\nSatisfaction Problem algorithm, the matrix approach not only put the mathematic\nidea into the investigation for finding out various extensions, but also\ncompletely achieve the goal to compute all the extensions needed.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 08:09:05 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Yuming", "Xu", ""]]}, {"id": "1209.2204", "submitter": "Henk van Elst", "authors": "Ekaterina Svetlova and Henk van Elst (Karlshochschule International\n  University)", "title": "How is non-knowledge represented in economic theory?", "comments": "18 pages, LaTeX2e, hyperlinked references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we address the question of how non-knowledge about future\nevents that influence economic agents' decisions in choice settings has been\nformally represented in economic theory up to date. To position our discussion\nwithin the ongoing debate on uncertainty, we provide a brief review of\nhistorical developments in economic theory and decision theory on the\ndescription of economic agents' choice behaviour under conditions of\nuncertainty, understood as either (i) ambiguity, or (ii) unawareness.\nAccordingly, we identify and discuss two approaches to the formalisation of\nnon-knowledge: one based on decision-making in the context of a state space\nrepresenting the exogenous world, as in Savage's axiomatisation and some\nsuccessor concepts (ambiguity as situations with unknown probabilities), and\none based on decision-making over a set of menus of potential future\nopportunities, providing the possibility of derivation of agents' subjective\nstate spaces (unawareness as situation with imperfect subjective knowledge of\nall future events possible). We also discuss impeding challenges of the\nformalisation of non-knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 19:55:46 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Svetlova", "Ekaterina", "", "Karlshochschule International\n  University"], ["van Elst", "Henk", "", "Karlshochschule International\n  University"]]}, {"id": "1209.2295", "submitter": "Davide Eynard", "authors": "Davide Eynard, Klaus Glashoff, Michael M. Bronstein, Alexander M.\n  Bronstein", "title": "Multimodal diffusion geometry by joint diagonalization of Laplacians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct an extension of diffusion geometry to multiple modalities\nthrough joint approximate diagonalization of Laplacian matrices. This naturally\nextends classical data analysis tools based on spectral geometry, such as\ndiffusion maps and spectral clustering. We provide several synthetic and real\nexamples of manifold learning, retrieval, and clustering demonstrating that the\njoint diffusion geometry frequently better captures the inherent structure of\nmulti-modal data. We also show that many previous attempts to construct\nmultimodal spectral clustering can be seen as particular cases of joint\napproximate diagonalization of the Laplacians.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 12:01:08 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 07:31:14 GMT"}], "update_date": "2012-09-13", "authors_parsed": [["Eynard", "Davide", ""], ["Glashoff", "Klaus", ""], ["Bronstein", "Michael M.", ""], ["Bronstein", "Alexander M.", ""]]}, {"id": "1209.2322", "submitter": "Fernando Gascon", "authors": "Javier Puente, David de la Fuente, Jesus Lozano and Fernando Gascon", "title": "On firm specific characteristics of pharmaceutical generics and\n  incentives to permanence under fuzzy conditions", "comments": null, "journal-ref": "International Journal of Applications of Fuzzy Sets(ISSN\n  2241-1240) Vol. 1 (2011), 19-37", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to develop a methodology that is useful for\nanalysing from a microeconomic perspective the incentives to entry, permanence\nand exit in the market for pharmaceutical generics under fuzzy conditions. In\nan empirical application of our proposed methodology, the potential towards\npermanence of labs with different characteristics has been estimated. The case\nwe deal with is set in an open market where global players diversify into\ndifferent national markets of pharmaceutical generics. Risk issues are\nsignificantly important in deterring decision makers from expanding in the\ngeneric pharmaceutical business. However, not all players are affected in the\nsame way and/or to the same extent. Small, non-diversified generics labs are in\nthe worse position. We have highlighted that the expected NPV and the number of\ngenerics in the portfolio of a pharmaceutical lab are important variables, but\nthat it is also important to consider the degree of diversification. Labs with\na higher potential for diversification across markets have an advantage over\nsmaller labs. We have described a fuzzy decision support system based on the\nMamdani model in order to determine the incentives for a laboratory to remain\nin the market both when it is stable and when it is growing.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 14:03:13 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Puente", "Javier", ""], ["de la Fuente", "David", ""], ["Lozano", "Jesus", ""], ["Gascon", "Fernando", ""]]}, {"id": "1209.2355", "submitter": "L\\'eon Bottou", "authors": "L\\'eon Bottou, Jonas Peters, Joaquin Qui\\~nonero-Candela, Denis X.\n  Charles, D. Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, Ed\n  Snelson", "title": "Counterfactual Reasoning and Learning Systems", "comments": "revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows how to leverage causal inference to understand the behavior\nof complex learning systems interacting with their environment and predict the\nconsequences of changes to the system. Such predictions allow both humans and\nalgorithms to select changes that improve both the short-term and long-term\nperformance of such systems. This work is illustrated by experiments carried\nout on the ad placement system associated with the Bing search engine.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 15:47:43 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2012 16:47:55 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2012 21:36:18 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2013 03:09:16 GMT"}, {"version": "v5", "created": "Sat, 27 Jul 2013 18:02:46 GMT"}], "update_date": "2013-07-30", "authors_parsed": [["Bottou", "L\u00e9on", ""], ["Peters", "Jonas", ""], ["Qui\u00f1onero-Candela", "Joaquin", ""], ["Charles", "Denis X.", ""], ["Chickering", "D. Max", ""], ["Portugaly", "Elon", ""], ["Ray", "Dipankar", ""], ["Simard", "Patrice", ""], ["Snelson", "Ed", ""]]}, {"id": "1209.2548", "submitter": "Sudarshan Nandy", "authors": "Sudarshan Nandy, Partha Pratim Sarkar and Achintya Das", "title": "Training a Feed-forward Neural Network with Artificial Bee Colony Based\n  Backpropagation Method", "comments": "14 Pages, 11 figures", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 4, No 4, 2012, 33-46", "doi": "10.5121/ijcsit.2012.4404", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-propagation algorithm is one of the most widely used and popular\ntechniques to optimize the feed forward neural network training. Nature\ninspired meta-heuristic algorithms also provide derivative-free solution to\noptimize complex problem. Artificial bee colony algorithm is a nature inspired\nmeta-heuristic algorithm, mimicking the foraging or food source searching\nbehaviour of bees in a bee colony and this algorithm is implemented in several\napplications for an improved optimized outcome. The proposed method in this\npaper includes an improved artificial bee colony algorithm based\nback-propagation neural network training method for fast and improved\nconvergence rate of the hybrid neural network learning method. The result is\nanalysed with the genetic algorithm based back-propagation method, and it is\nanother hybridized procedure of its kind. Analysis is performed over standard\ndata sets, reflecting the light of efficiency of proposed method in terms of\nconvergence speed and rate.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 10:25:51 GMT"}], "update_date": "2012-09-13", "authors_parsed": [["Nandy", "Sudarshan", ""], ["Sarkar", "Partha Pratim", ""], ["Das", "Achintya", ""]]}, {"id": "1209.2620", "submitter": "Marcus Hutter", "authors": "Marcus Hutter and John W. Lloyd and Kee Siong Ng and William T. B.\n  Uther", "title": "Probabilities on Sentences in an Expressive Logic", "comments": "52 LaTeX pages, 64 definiton/theorems/etc, presented at conference\n  Progic 2011 in New York", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated reasoning about uncertain knowledge has many applications. One\ndifficulty when developing such systems is the lack of a completely\nsatisfactory integration of logic and probability. We address this problem\ndirectly. Expressive languages like higher-order logic are ideally suited for\nrepresenting and reasoning about structured knowledge. Uncertain knowledge can\nbe modeled by using graded probabilities rather than binary truth-values. The\nmain technical problem studied in this paper is the following: Given a set of\nsentences, each having some probability of being true, what probability should\nbe ascribed to other (query) sentences? A natural wish-list, among others, is\nthat the probability distribution (i) is consistent with the knowledge base,\n(ii) allows for a consistent inference procedure and in particular (iii)\nreduces to deductive logic in the limit of probabilities being 0 and 1, (iv)\nallows (Bayesian) inductive reasoning and (v) learning in the limit and in\nparticular (vi) allows confirmation of universally quantified\nhypotheses/sentences. We translate this wish-list into technical requirements\nfor a prior probability and show that probabilities satisfying all our criteria\nexist. We also give explicit constructions and several general\ncharacterizations of probabilities that satisfy some or all of the criteria and\nvarious (counter) examples. We also derive necessary and sufficient conditions\nfor extending beliefs about finitely many sentences to suitable probabilities\nover all sentences, and in particular least dogmatic or least biased ones. We\nconclude with a brief outlook on how the developed theory might be used and\napproximated in autonomous reasoning agents. Our theory is a step towards a\nglobally consistent and empirically satisfactory unification of probability and\nlogic.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 14:17:09 GMT"}], "update_date": "2012-09-13", "authors_parsed": [["Hutter", "Marcus", ""], ["Lloyd", "John W.", ""], ["Ng", "Kee Siong", ""], ["Uther", "William T. B.", ""]]}, {"id": "1209.2948", "submitter": "Sujatha Srinivasan", "authors": "Sujatha Srinivasan, Sivakumar Ramakrishnan", "title": "Cultural Algorithm Toolkit for Multi-objective Rule Mining", "comments": "arXiv admin note: substantial text overlap with arXiv:1207.2630", "journal-ref": "International Journal on Computational Sciences & Applications\n  (IJCSA) Vo2, No.4, 2012, 9-23", "doi": "10.5121/ijcsa.2012.2402", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cultural algorithm is a kind of evolutionary algorithm inspired from societal\nevolution and is composed of a belief space, a population space and a protocol\nthat enables exchange of knowledge between these sources. Knowledge created in\nthe population space is accepted into the belief space while this collective\nknowledge from these sources is combined to influence the decisions of the\nindividual agents in solving problems. Classification rules comes under\ndescriptive knowledge discovery in data mining and are the most sought out by\nusers since they represent highly comprehensible form of knowledge. The rules\nhave certain properties which make them useful forms of actionable knowledge to\nusers. The rules are evaluated using these properties namely the rule metrics.\nIn the current study a Cultural Algorithm Toolkit for Classification Rule\nMining (CAT-CRM) is proposed which allows the user to control three different\nset of parameters namely the evolutionary parameters, the rule parameters as\nwell as agent parameters and hence can be used for experimenting with an\nevolutionary system, a rule mining system or an agent based social system.\nResults of experiments conducted to observe the effect of different number and\ntype of metrics on the performance of the algorithm on bench mark data sets is\nreported.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 12:39:01 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Srinivasan", "Sujatha", ""], ["Ramakrishnan", "Sivakumar", ""]]}, {"id": "1209.3419", "submitter": "Francesco Scarcello", "authors": "Georg Gottlob and Gianluigi Greco and Francesco Scarcello", "title": "Tractable Optimization Problems through Hypergraph-Based Structural\n  Restrictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Several variants of the Constraint Satisfaction Problem have been proposed\nand investigated in the literature for modelling those scenarios where\nsolutions are associated with some given costs. Within these frameworks\ncomputing an optimal solution is an NP-hard problem in general; yet, when\nrestricted over classes of instances whose constraint interactions can be\nmodelled via (nearly-)acyclic graphs, this problem is known to be solvable in\npolynomial time. In this paper, larger classes of tractable instances are\nsingled out, by discussing solution approaches based on exploiting hypergraph\nacyclicity and, more generally, structural decomposition methods, such as\n(hyper)tree decompositions.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2012 16:40:19 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Gottlob", "Georg", ""], ["Greco", "Gianluigi", ""], ["Scarcello", "Francesco", ""]]}, {"id": "1209.3487", "submitter": "Tom Kelsey", "authors": "Lars Kotthoff, Tom Kelsey and Martin McCaffery", "title": "A framework for large-scale distributed AI search across disconnected\n  heterogeneous infrastructures", "comments": "18 pages plus references. arXiv admin note: substantial text overlap\n  with arXiv:1008.4328", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for a large-scale distributed eScience Artificial\nIntelligence search. Our approach is generic and can be used for many different\nproblems. Unlike many other approaches, we do not require dedicated machines,\nhomogeneous infrastructure or the ability to communicate between nodes. We give\nspecial consideration to the robustness of the framework, minimising the loss\nof effort even after total loss of infrastructure, and allowing easy\nverification of every step of the distribution process. In contrast to most\neScience applications, the input data and specification of the problem is very\nsmall, being easily given in a paragraph of text. The unique challenges our\nframework tackles are related to the combinatorial explosion of the space that\ncontains the possible solutions and the robustness of long-running\ncomputations. Not only is the time required to finish the computations unknown,\nbut also the resource requirements may change during the course of the\ncomputation. We demonstrate the applicability of our framework by using it to\nsolve a challenging and hitherto open problem in computational mathematics. The\nresults demonstrate that our approach easily scales to computations of a size\nthat would have been impossible to tackle in practice just a decade ago.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2012 14:12:49 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Kotthoff", "Lars", ""], ["Kelsey", "Tom", ""], ["McCaffery", "Martin", ""]]}, {"id": "1209.3694", "submitter": "Yifei Ma", "authors": "Yifei Ma, Roman Garnett, Jeff Schneider", "title": "Submodularity in Batch Active Learning and Survey Problems on Gaussian\n  Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world datasets can be represented in the form of a graph whose edge\nweights designate similarities between instances. A discrete Gaussian random\nfield (GRF) model is a finite-dimensional Gaussian process (GP) whose prior\ncovariance is the inverse of a graph Laplacian. Minimizing the trace of the\npredictive covariance Sigma (V-optimality) on GRFs has proven successful in\nbatch active learning classification problems with budget constraints. However,\nits worst-case bound has been missing. We show that the V-optimality on GRFs as\na function of the batch query set is submodular and hence its greedy selection\nalgorithm guarantees an (1-1/e) approximation ratio. Moreover, GRF models have\nthe absence-of-suppressor (AofS) condition. For active survey problems, we\npropose a similar survey criterion which minimizes 1'(Sigma)1. In practice,\nV-optimality criterion performs better than GPs with mutual information gain\ncriteria and allows nonuniform costs for different nodes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 15:43:11 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Ma", "Yifei", ""], ["Garnett", "Roman", ""], ["Schneider", "Jeff", ""]]}, {"id": "1209.3734", "submitter": "Patrick Rodler", "authors": "Patrick Rodler and Kostyantyn Shchekotykhin and Philipp Fleiss and\n  Gerhard Friedrich", "title": "RIO: Minimizing User Interaction in Ontology Debugging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Efficient ontology debugging is a cornerstone for many activities in the\ncontext of the Semantic Web, especially when automatic tools produce (parts of)\nontologies such as in the field of ontology matching. The best currently known\ninteractive debugging systems rely upon some meta information in terms of fault\nprobabilities, which can speed up the debugging procedure in the good case, but\ncan also have negative impact on the performance in the bad case. The problem\nis that assessment of the meta information is only possible a-posteriori.\nConsequently, as long as the actual fault is unknown, there is always some risk\nof suboptimal interactive diagnoses discrimination. As an alternative, one\nmight prefer to rely on a tool which pursues a no-risk strategy. In this case,\nhowever, possibly well-chosen meta information cannot be exploited, resulting\nagain in inefficient debugging actions. In this work we present a reinforcement\nlearning strategy that continuously adapts its behavior depending on the\nperformance achieved and minimizes the risk of using low-quality meta\ninformation. Therefore, this method is suitable for application scenarios where\nreliable a-priori fault estimates are difficult to obtain. Using problematic\nontologies in the field of ontology matching, we show that the proposed\nrisk-aware query strategy outperforms both active learning approaches and\nno-risk strategies on average in terms of required amount of user interaction.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 18:02:50 GMT"}], "update_date": "2012-09-18", "authors_parsed": [["Rodler", "Patrick", ""], ["Shchekotykhin", "Kostyantyn", ""], ["Fleiss", "Philipp", ""], ["Friedrich", "Gerhard", ""]]}, {"id": "1209.3811", "submitter": "Aditya Menon", "authors": "Aditya Krishna Menon, Omer Tamuz, Sumit Gulwani, Butler Lampson, Adam\n  Tauman Kalai", "title": "Textual Features for Programming by Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Programming by Example, a system attempts to infer a program from input\nand output examples, generally by searching for a composition of certain base\nfunctions. Performing a naive brute force search is infeasible for even mildly\ninvolved tasks. We note that the examples themselves often present clues as to\nwhich functions to compose, and how to rank the resulting programs. In text\nprocessing, which is our domain of interest, clues arise from simple textual\nfeatures: for example, if parts of the input and output strings are\npermutations of one another, this suggests that sorting may be useful. We\ndescribe a system that learns the reliability of such clues, allowing for\nfaster search and a principled ranking over programs. Experiments on a\nprototype of this system show that this learning scheme facilitates efficient\ninference on a range of text processing tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2012 22:56:19 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["Tamuz", "Omer", ""], ["Gulwani", "Sumit", ""], ["Lampson", "Butler", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1209.3818", "submitter": "Alok Raj", "authors": "Alok Raj", "title": "Evolution and the structure of learning agents", "comments": "total 4 pages. Submitted to IEEE Congress on Evolutionary Computation\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the thesis that all learning agents of finite information\nsize are limited by their informational structure in what goals they can\nefficiently learn to achieve in a complex environment. Evolutionary change is\ncritical for creating the required structure for all learning agents in any\ncomplex environment. The thesis implies that there is no efficient universal\nlearning algorithm. An agent can go past the learning limits imposed by its\nstructure only by slow evolutionary change or blind search which in a very\ncomplex environment can only give an agent an inefficient universal learning\ncapability that can work only in evolutionary timescales or improbable luck.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 00:13:53 GMT"}, {"version": "v2", "created": "Sat, 2 Feb 2013 01:51:50 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2013 21:32:11 GMT"}, {"version": "v4", "created": "Mon, 1 Apr 2013 23:58:47 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Raj", "Alok", ""]]}, {"id": "1209.3869", "submitter": "Poonam Tanwar", "authors": "Poonam Tanwar, T. V. Prasad, Dr. Kamlesh Datta", "title": "Hybrid technique for effective knowledge representation & a comparative\n  study", "comments": "15 pages,9 figures, 1 table, Pablished in IJCSES,International\n  Journal of Computer Science & Engineering Survey Vol.3, No.4, August 2012", "journal-ref": "Pablished in IJCSES,International Journal of Computer Science &\n  Engineering Survey Vol.3, No.4, August 2012", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation (KR) and inference mechanism are most desirable\nthing to make the system intelligent. System is known to an intelligent if its\nintelligence is equivalent to the intelligence of human being for a particular\ndomain or general. Because of incomplete ambiguous and uncertain information\nthe task of making intelligent system is very difficult. The objective of this\npaper is to present the hybrid KR technique for making the system effective &\nOptimistic. The requirement for (effective & optimistic) is because the system\nmust be able to reply the answer with a confidence of some factor. This paper\nalso presents the comparison between various hybrid KR techniques with the\nproposed one.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 08:19:37 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Tanwar", "Poonam", ""], ["Prasad", "T. V.", ""], ["Datta", "Dr. Kamlesh", ""]]}, {"id": "1209.3914", "submitter": "Josef Urban", "authors": "Josef Urban and Jiri Vyskocil", "title": "Theorem Proving in Large Formal Mathematics as an Emerging AI Field", "comments": null, "journal-ref": null, "doi": null, "report-no": "DPA-12271", "categories": "cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, we have linked a large corpus of formal mathematics with\nautomated theorem proving (ATP) tools, and started to develop combined AI/ATP\nsystems working in this setting. In this paper we first relate this project to\nthe earlier large-scale automated developments done by Quaife with McCune's\nOtter system, and to the discussions of the QED project about formalizing a\nsignificant part of mathematics. Then we summarize our adventure so far, argue\nthat the QED dreams were right in anticipating the creation of a very\ninteresting semantic AI field, and discuss its further research directions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 11:46:17 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2012 22:48:13 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Urban", "Josef", ""], ["Vyskocil", "Jiri", ""]]}, {"id": "1209.3916", "submitter": "Tom Kelsey", "authors": "Thomas W. Kelsey, Lars Kotthoff, Christoffer A. Jefferson, Stephen A.\n  Linton, Ian Miguel, Peter Nightingale, Ian P. Gent", "title": "Qualitative Modelling via Constraint Programming: Past, Present and\n  Future", "comments": "15 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI math.DS q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative modelling is a technique integrating the fields of theoretical\ncomputer science, artificial intelligence and the physical and biological\nsciences. The aim is to be able to model the behaviour of systems without\nestimating parameter values and fixing the exact quantitative dynamics.\nTraditional applications are the study of the dynamics of physical and\nbiological systems at a higher level of abstraction than that obtained by\nestimation of numerical parameter values for a fixed quantitative model.\nQualitative modelling has been studied and implemented to varying degrees of\nsophistication in Petri nets, process calculi and constraint programming. In\nthis paper we reflect on the strengths and weaknesses of existing frameworks,\nwe demonstrate how recent advances in constraint programming can be leveraged\nto produce high quality qualitative models, and we describe the advances in\ntheory and technology that would be needed to make constraint programming the\nbest option for scientific investigation in the broadest sense.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 11:57:44 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Kelsey", "Thomas W.", ""], ["Kotthoff", "Lars", ""], ["Jefferson", "Christoffer A.", ""], ["Linton", "Stephen A.", ""], ["Miguel", "Ian", ""], ["Nightingale", "Peter", ""], ["Gent", "Ian P.", ""]]}, {"id": "1209.4275", "submitter": "Prabhu Natarajan", "authors": "Prabhu Natarajan, Trong Nghia Hoang, Kian Hsiang Low, Mohan\n  Kankanhalli", "title": "Decision-Theoretic Coordination and Control for Active Multi-Camera\n  Surveillance in Uncertain, Partially Observable Environments", "comments": "6th ACM/IEEE International Conference on Distributed Smart Cameras\n  (ICDSC 2012), Extended version with proofs, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem of surveillance is to monitor multiple targets moving in a\nlarge-scale, obstacle-ridden environment with occlusions. This paper presents a\nnovel principled Partially Observable Markov Decision Process-based approach to\ncoordinating and controlling a network of active cameras for tracking and\nobserving multiple mobile targets at high resolution in such surveillance\nenvironments. Our proposed approach is capable of (a) maintaining a belief over\nthe targets' states (i.e., locations, directions, and velocities) to track\nthem, even when they may not be observed directly by the cameras at all times,\n(b) coordinating the cameras' actions to simultaneously improve the belief over\nthe targets' states and maximize the expected number of targets observed with a\nguaranteed resolution, and (c) exploiting the inherent structure of our\nsurveillance problem to improve its scalability (i.e., linear time) in the\nnumber of targets to be observed. Quantitative comparisons with\nstate-of-the-art multi-camera coordination and control techniques show that our\napproach can achieve higher surveillance quality in real time. The practical\nfeasibility of our approach is also demonstrated using real AXIS 214 PTZ\ncameras\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 15:15:08 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2012 12:19:53 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2012 08:44:59 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Natarajan", "Prabhu", ""], ["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1209.4290", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov, Andrew Myasnikov, Galymzhan Begimov", "title": "Cognitive Bias for Universal Algorithmic Intelligence", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing theoretical universal algorithmic intelligence models are not\npractically realizable. More pragmatic approach to artificial general\nintelligence is based on cognitive architectures, which are, however,\nnon-universal in sense that they can construct and use models of the\nenvironment only from Turing-incomplete model spaces. We believe that the way\nto the real AGI consists in bridging the gap between these two approaches. This\nis possible if one considers cognitive functions as a \"cognitive bias\" (priors\nand search heuristics) that should be incorporated into the models of universal\nalgorithmic intelligence without violating their universality. Earlier reported\nresults suiting this approach and its overall feasibility are discussed on the\nexample of perception, planning, knowledge representation, attention, theory of\nmind, language, and some others.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 16:01:31 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""], ["Myasnikov", "Andrew", ""], ["Begimov", "Galymzhan", ""]]}, {"id": "1209.4330", "submitter": "Sanjay Singh", "authors": "Supriya D'Souza, Abhishek Rao, Amit Sharma and Sanjay Singh", "title": "Modeling and Verification of a Multi-Agent Argumentation System using\n  NuSMV", "comments": "8 pages, 4 figures; 20092012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous intelligent agent research is a domain situated at the forefront\nof artificial intelligence. Interest-based negotiation (IBN) is a form of\nnegotiation in which agents exchange information about their underlying goals,\nwith a view to improve the likelihood and quality of a offer. In this paper we\nmodel and verify a multi-agent argumentation scenario of resource sharing\nmechanism to enable resource sharing in a distributed system. We use IBN in our\nmodel wherein agents express their interests to the others in the society to\ngain certain resources.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 18:56:33 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["D'Souza", "Supriya", ""], ["Rao", "Abhishek", ""], ["Sharma", "Amit", ""], ["Singh", "Sanjay", ""]]}, {"id": "1209.4445", "submitter": "Sachin Lakra", "authors": "Sachin Lakra, T.V. Prasad and G. Ramakrishna", "title": "Speech Signal Filters based on Soft Computing Techniques: A Comparison", "comments": "5 pages", "journal-ref": "The 2010 International Congress on Computer Applications and\n  Computational Science (CACS 2010), 4-6 December, 2010, Singapore", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a comparison of various soft computing techniques used for\nfiltering and enhancing speech signals. The three major techniques that fall\nunder soft computing are neural networks, fuzzy systems and genetic algorithms.\nOther hybrid techniques such as neuro-fuzzy systems are also available. In\ngeneral, soft computing techniques have been experimentally observed to give\nfar superior performance as compared to non-soft computing techniques in terms\nof robustness and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 08:10:07 GMT"}], "update_date": "2012-09-21", "authors_parsed": [["Lakra", "Sachin", ""], ["Prasad", "T. V.", ""], ["Ramakrishna", "G.", ""]]}, {"id": "1209.4532", "submitter": "Sachin Lakra", "authors": "T.V. Prasad, Sachin Lakra, G. Ramakrishna", "title": "Applicability of Crisp and Fuzzy Logic in Intelligent Response\n  Generation", "comments": "4 pages, 1 table", "journal-ref": "Published in proceedings of National Conference on Information,\n  Computational Technologies and e-Governance 2010, Alwar, Rajasthan, India,\n  19-20 November, 2010, pp. 137-139", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the merits and demerits of crisp logic and fuzzy logic\nwith respect to their applicability in intelligent response generation by a\nhuman being and by a robot. Intelligent systems must have the capability of\ntaking decisions that are wise and handle situations intelligently. A direct\nrelationship exists between the level of perfection in handling a situation and\nthe level of completeness of the available knowledge or information or data\nrequired to handle the situation. The paper concludes that the use of crisp\nlogic with complete knowledge leads to perfection in handling situations\nwhereas fuzzy logic can handle situations imperfectly only. However, in the\nlight of availability of incomplete knowledge fuzzy theory is more effective\nbut may be disadvantageous as compared to crisp logic.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 14:00:06 GMT"}], "update_date": "2012-09-21", "authors_parsed": [["Prasad", "T. V.", ""], ["Lakra", "Sachin", ""], ["Ramakrishna", "G.", ""]]}, {"id": "1209.4535", "submitter": "Sachin Lakra", "authors": "Sachin Lakra, T.V. Prasad, Deepak Kumar Sharma, Shree Harsh Atrey,\n  Anubhav Kumar Sharma", "title": "Application of Fuzzy Mathematics to Speech-to-Text Conversion by\n  Elimination of Paralinguistic Content", "comments": "6 pages, 3 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1001.2267 by other authors", "journal-ref": "Published in proceedings of National Conference on Soft Computing\n  and Artificial Intelligence 2009, Faridabad, Haryana, India, Jan 2009", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past few decades, man has been trying to create an intelligent\ncomputer which can talk and respond like he can. The task of creating a system\nthat can talk like a human being is the primary objective of Automatic Speech\nRecognition. Various Speech Recognition techniques have been developed in\ntheory and have been applied in practice. This paper discusses the problems\nthat have been encountered in developing Speech Recognition, the techniques\nthat have been applied to automate the task, and a representation of the core\nproblems of present day Speech Recognition by using Fuzzy Mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 14:06:32 GMT"}], "update_date": "2012-09-21", "authors_parsed": [["Lakra", "Sachin", ""], ["Prasad", "T. V.", ""], ["Sharma", "Deepak Kumar", ""], ["Atrey", "Shree Harsh", ""], ["Sharma", "Anubhav Kumar", ""]]}, {"id": "1209.4838", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Formal Definition of AI", "comments": null, "journal-ref": "International Journal \"Information Theories & Applications\",\n  vol.12, Number 3, 2005, pp.277-285", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A definition of Artificial Intelligence was proposed in [1] but this\ndefinition was not absolutely formal at least because the word \"Human\" was\nused. In this paper we will formalize the definition from [1]. The biggest\nproblem in this definition was that the level of intelligence of AI is compared\nto the intelligence of a human being. In order to change this we will introduce\nsome parameters to which AI will depend. One of this parameters will be the\nlevel of intelligence and we will define one AI to each level of intelligence.\nWe assume that for some level of intelligence the respective AI will be more\nintelligent than a human being. Nevertheless, we cannot say which is this level\nbecause we cannot calculate its exact value.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2012 14:58:33 GMT"}], "update_date": "2012-09-24", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1209.4975", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Parametric matroid of rough set", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough set is mainly concerned with the approximations of objects through an\nequivalence relation on a universe. Matroid is a combinatorial generalization\nof linear independence in vector spaces. In this paper, we define a parametric\nset family, with any subset of a universe as its parameter, to connect rough\nsets and matroids. On the one hand, for a universe and an equivalence relation\non the universe, a parametric set family is defined through the lower\napproximation operator. This parametric set family is proved to satisfy the\nindependent set axiom of matroids, therefore it can generate a matroid, called\na parametric matroid of the rough set. Three equivalent representations of the\nparametric set family are obtained. Moreover, the parametric matroid of the\nrough set is proved to be the direct sum of a partition-circuit matroid and a\nfree matroid. On the other hand, since partition-circuit matroids were well\nstudied through the lower approximation number, we use it to investigate the\nparametric matroid of the rough set. Several characteristics of the parametric\nmatroid of the rough set, such as independent sets, bases, circuits, the rank\nfunction and the closure operator, are expressed by the lower approximation\nnumber.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 09:19:54 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1209.4976", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Matroidal structure of rough sets based on serial and transitive\n  relations", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of rough sets is concerned with the lower and upper approximations\nof objects through a binary relation on a universe. It has been applied to\nmachine learning, knowledge discovery and data mining. The theory of matroids\nis a generalization of linear independence in vector spaces. It has been used\nin combinatorial optimization and algorithm design. In order to take advantages\nof both rough sets and matroids, in this paper we propose a matroidal structure\nof rough sets based on a serial and transitive relation on a universe. We\ndefine the family of all minimal neighborhoods of a relation on a universe, and\nprove it satisfy the circuit axioms of matroids when the relation is serial and\ntransitive. In order to further study this matroidal structure, we investigate\nthe inverse of this construction: inducing a relation by a matroid. The\nrelationships between the upper approximation operators of rough sets based on\nrelations and the closure operators of matroids in the above two constructions\nare studied. Moreover, we investigate the connections between the above two\nconstructions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 09:25:50 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 10:39:19 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1209.4978", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Covering matroid", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new type of matroids, namely covering matroids,\nand investigate the connections with the second type of covering-based rough\nsets and some existing special matroids. Firstly, as an extension of\npartitions, coverings are more natural combinatorial objects and can sometimes\nbe more efficient to deal with problems in the real world. Through extending\npartitions to coverings, we propose a new type of matroids called covering\nmatroids and prove them to be an extension of partition matroids. Secondly,\nsince some researchers have successfully applied partition matroids to\nclassical rough sets, we study the relationships between covering matroids and\ncovering-based rough sets which are an extension of classical rough sets.\nThirdly, in matroid theory, there are many special matroids, such as\ntransversal matroids, partition matroids, 2-circuit matroid and\npartition-circuit matroids. The relationships among several special matroids\nand covering matroids are studied.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2012 09:34:10 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 02:42:55 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1209.5245", "submitter": "Tarek Behi Mr", "authors": "Tarek Behi, Najet Arous and Noureddine Ellouze", "title": "Spike Timing Dependent Competitive Learning in Recurrent Self Organizing\n  Pulsed Neural Networks Case Study: Phoneme and Word Recognition", "comments": "10 pages, 15 tables", "journal-ref": "International Journal of Computer Science Issues, Vol. 9, Issue 4,\n  No 2, (2012)328-337", "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic plasticity seems to be a capital aspect of the dynamics of neural\nnetworks. It is about the physiological modifications of the synapse, which\nhave like consequence a variation of the value of the synaptic weight. The\ninformation encoding is based on the precise timing of single spike events that\nis based on the relative timing of the pre- and post-synaptic spikes, local\nsynapse competitions within a single neuron and global competition via lateral\nconnections. In order to classify temporal sequences, we present in this paper\nhow to use a local hebbian learning, spike-timing dependent plasticity for\nunsupervised competitive learning, preserving self-organizing maps of spiking\nneurons. In fact we present three variants of self-organizing maps (SOM) with\nspike-timing dependent Hebbian learning rule, the Leaky Integrators Neurons\n(LIN), the Spiking_SOM and the recurrent Spiking_SOM (RSSOM) models. The case\nstudy of the proposed SOM variants is phoneme classification and word\nrecognition in continuous speech and speaker independent.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 12:28:16 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Behi", "Tarek", ""], ["Arous", "Najet", ""], ["Ellouze", "Noureddine", ""]]}, {"id": "1209.5251", "submitter": "Josef Moudrik", "authors": "Petr Baudi\\v{s}, Josef Moud\\v{r}\\'ik", "title": "On Move Pattern Trends in a Large Go Games Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We process a large corpus of game records of the board game of Go and propose\na way of extracting summary information on played moves. We then apply several\nbasic data-mining methods on the summary information to identify the most\ndifferentiating features within the summary information, and discuss their\ncorrespondence with traditional Go knowledge. We show statistically significant\nmappings of the features to player attributes such as playing strength or\ninformally perceived \"playing style\" (e.g. territoriality or aggressivity),\ndescribe accurate classifiers for these attributes, and propose applications\nincluding seeding real-work ranks of internet players, aiding in Go study and\ntuning of Go-playing programs, or contribution to Go-theoretical discussion on\nthe scope of \"playing style\".\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 12:54:18 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Baudi\u0161", "Petr", ""], ["Moud\u0159\u00edk", "Josef", ""]]}, {"id": "1209.5345", "submitter": "Muhammad Rahman M.Sc", "authors": "Muhammad Mahbubur Rahman", "title": "Mining Social Data to Extract Intellectual Knowledge", "comments": "8 pages, 19 figures, 4 tables, 3 equations, ISSN: 2074-904X (Print),\n  ISSN: 2074-9058 (Online)", "journal-ref": "International Journal of Intelligent Systems and\n  Applications(IJISA), vol.4, no.10, pp.15-24, 2012", "doi": "10.5815/ijisa.2012.10.02", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social data mining is an interesting phe-nomenon which colligates different\nsources of social data to extract information. This information can be used in\nrelationship prediction, decision making, pat-tern recognition, social mapping,\nresponsibility distri-bution and many other applications. This paper presents a\nsystematical data mining architecture to mine intellectual knowledge from\nsocial data. In this research, we use social networking site facebook as\nprimary data source. We collect different attributes such as about me,\ncomments, wall post and age from facebook as raw data and use advanced data\nmining approaches to excavate intellectual knowledge. We also analyze our mined\nknowledge with comparison for possible usages like as human behavior\nprediction, pattern recognition, job responsibility distribution, decision\nmaking and product promoting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 17:39:11 GMT"}], "update_date": "2012-09-25", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""]]}, {"id": "1209.5456", "submitter": "Yanfang Liu", "authors": "Yanfang Liu and William Zhu", "title": "Relation matroid and its relationship with generalized rough set based\n  on relation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the relationship between matroids and generalized rough sets based\non relations has been studied from the viewpoint of linear independence of\nmatrices. In this paper, we reveal more relationships by the predecessor and\nsuccessor neighborhoods from relations. First, through these two neighborhoods,\nwe propose a pair of matroids, namely predecessor relation matroid and\nsuccessor relation matroid, respectively. Basic characteristics of this pair of\nmatroids, such as dependent sets, circuits, the rank function and the closure\noperator, are described by the predecessor and successor neighborhoods from\nrelations. Second, we induce a relation from a matroid through the circuits of\nthe matroid. We prove that the induced relation is always an equivalence\nrelation. With these two inductions, a relation induces a relation matroid, and\nthe relation matroid induces an equivalence relation, then the connection\nbetween the original relation and the induced equivalence relation is studied.\nMoreover, the relationships between the upper approximation operator in\ngeneralized rough sets and the closure operator in matroids are investigated.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 23:42:09 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 10:43:02 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Liu", "Yanfang", ""], ["Zhu", "William", ""]]}, {"id": "1209.5470", "submitter": "Bin Yang", "authors": "Bin Yang and William Zhu", "title": "Matroidal structure of generalized rough sets based on symmetric and\n  transitive relations", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough sets are efficient for data pre-process in data mining. Lower and upper\napproximations are two core concepts of rough sets. This paper studies\ngeneralized rough sets based on symmetric and transitive relations from the\noperator-oriented view by matroidal approaches. We firstly construct a\nmatroidal structure of generalized rough sets based on symmetric and transitive\nrelations, and provide an approach to study the matroid induced by a symmetric\nand transitive relation. Secondly, this paper establishes a close relationship\nbetween matroids and generalized rough sets. Approximation quality and\nroughness of generalized rough sets can be computed by the circuit of matroid\ntheory. At last, a symmetric and transitive relation can be constructed by a\nmatroid with some special properties.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 02:14:19 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 02:30:43 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Yang", "Bin", ""], ["Zhu", "William", ""]]}, {"id": "1209.5473", "submitter": "Lirun Su", "authors": "Lirun Su and William Zhu", "title": "Some characteristics of matroids through rough sets", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, practical application and theoretical discussion of rough sets\nare two hot problems in computer science. The core concepts of rough set theory\nare upper and lower approximation operators based on equivalence relations.\nMatroid, as a branch of mathematics, is a structure that generalizes linear\nindependence in vector spaces. Further, matroid theory borrows extensively from\nthe terminology of linear algebra and graph theory. We can combine rough set\ntheory with matroid theory through using rough sets to study some\ncharacteristics of matroids. In this paper, we apply rough sets to matroids\nthrough defining a family of sets which are constructed from the upper\napproximation operator with respect to an equivalence relation. First, we prove\nthe family of sets satisfies the support set axioms of matroids, and then we\nobtain a matroid. We say the matroids induced by the equivalence relation and a\ntype of matroid, namely support matroid, is induced. Second, through rough\nsets, some characteristics of matroids such as independent sets, support sets,\nbases, hyperplanes and closed sets are investigated.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 02:35:13 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Su", "Lirun", ""], ["Zhu", "William", ""]]}, {"id": "1209.5480", "submitter": "Hua Yao", "authors": "Hua Yao and William Zhu", "title": "Condition for neighborhoods in covering based rough sets to form a\n  partition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighborhood is an important concept in covering based rough sets. That under\nwhat condition neighborhoods form a partition is a meaningful issue induced by\nthis concept. Many scholars have paid attention to this issue and presented\nsome necessary and sufficient conditions. However, there exists one common\ntrait among these conditions, that is they are established on the basis of all\nneighborhoods have been obtained. In this paper, we provide a necessary and\nsufficient condition directly based on the covering itself. First, we\ninvestigate the influence of that there are reducible elements in the covering\non neighborhoods. Second, we propose the definition of uniform block and obtain\na sufficient condition from it. Third, we propose the definitions of repeat\ndegree and excluded number. By means of the two concepts, we obtain a necessary\nand sufficient condition for neighborhoods to form a partition. In a word, we\nhave gained a deeper and more direct understanding of the essence over that\nneighborhoods form a partition.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 03:03:41 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Yao", "Hua", ""], ["Zhu", "William", ""]]}, {"id": "1209.5482", "submitter": "Jingqian Wang", "authors": "Jingqian Wang and William Zhu", "title": "Rough sets and matroidal contraction", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough sets are efficient for data pre-processing in data mining. As a\ngeneralization of the linear independence in vector spaces, matroids provide\nwell-established platforms for greedy algorithms. In this paper, we apply rough\nsets to matroids and study the contraction of the dual of the corresponding\nmatroid. First, for an equivalence relation on a universe, a matroidal\nstructure of the rough set is established through the lower approximation\noperator. Second, the dual of the matroid and its properties such as\nindependent sets, bases and rank function are investigated. Finally, the\nrelationships between the contraction of the dual matroid to the complement of\na single point set and the contraction of the dual matroid to the complement of\nthe equivalence class of this point are studied.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 03:07:31 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Wang", "Jingqian", ""], ["Zhu", "William", ""]]}, {"id": "1209.5484", "submitter": "Hua Yao", "authors": "Hua Yao and William Zhu", "title": "Condition for neighborhoods induced by a covering to be equal to the\n  covering itself", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a meaningful issue that under what condition neighborhoods induced by a\ncovering are equal to the covering itself. A necessary and sufficient condition\nfor this issue has been provided by some scholars. In this paper, through a\ncounter-example, we firstly point out the necessary and sufficient condition is\nfalse. Second, we present a necessary and sufficient condition for this issue.\nThird, we concentrate on the inverse issue of computing neighborhoods by a\ncovering, namely giving an arbitrary covering, whether or not there exists\nanother covering such that the neighborhoods induced by it is just the former\ncovering. We present a necessary and sufficient condition for this issue as\nwell. In a word, through the study on the two fundamental issues induced by\nneighborhoods, we have gained a deeper understanding of the relationship\nbetween neighborhoods and the covering which induce the neighborhoods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 03:14:39 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Yao", "Hua", ""], ["Zhu", "William", ""]]}, {"id": "1209.5567", "submitter": "Qingyin Li", "authors": "Qingyin Li and William Zhu", "title": "Closed-set lattice of regular sets based on a serial and transitive\n  relation through matroids", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rough sets are efficient for data pre-processing in data mining. Matroids are\nbased on linear algebra and graph theory, and have a variety of applications in\nmany fields. Both rough sets and matroids are closely related to lattices. For\na serial and transitive relation on a universe, the collection of all the\nregular sets of the generalized rough set is a lattice. In this paper, we use\nthe lattice to construct a matroid and then study relationships between the\nlattice and the closed-set lattice of the matroid. First, the collection of all\nthe regular sets based on a serial and transitive relation is proved to be a\nsemimodular lattice. Then, a matroid is constructed through the height function\nof the semimodular lattice. Finally, we propose an approach to obtain all the\nclosed sets of the matroid from the semimodular lattice. Borrowing from\nmatroids, results show that lattice theory provides an interesting view to\ninvestigate rough sets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 10:36:27 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2013 14:53:48 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Li", "Qingyin", ""], ["Zhu", "William", ""]]}, {"id": "1209.5569", "submitter": "Qingyin Li", "authors": "Qingyin Li and William Zhu", "title": "Lattice structures of fixed points of the lower approximations of two\n  types of covering-based rough sets", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering is a common type of data structure and covering-based rough set\ntheory is an efficient tool to process this data. Lattice is an important\nalgebraic structure and used extensively in investigating some types of\ngeneralized rough sets. In this paper, we propose two family of sets and study\nthe conditions that these two sets become some lattice structures. These two\nsets are consisted by the fixed point of the lower approximations of the first\ntype and the sixth type of covering-based rough sets, respectively. These two\nsets are called the fixed point set of neighborhoods and the fixed point set of\ncovering, respectively. First, for any covering, the fixed point set of\nneighborhoods is a complete and distributive lattice, at the same time, it is\nalso a double p-algebra. Especially, when the neighborhood forms a partition of\nthe universe, the fixed point set of neighborhoods is both a boolean lattice\nand a double Stone algebra. Second, for any covering, the fixed point set of\ncovering is a complete lattice.When the covering is unary, the fixed point set\nof covering becomes a distributive lattice and a double p-algebra. a\ndistributive lattice and a double p-algebra when the covering is unary.\nEspecially, when the reduction of the covering forms a partition of the\nuniverse, the fixed point set of covering is both a boolean lattice and a\ndouble Stone algebra.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 10:41:45 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Li", "Qingyin", ""], ["Zhu", "William", ""]]}, {"id": "1209.5571", "submitter": "Vladislav Ryzhikov Dr", "authors": "Alessandro Artale, Roman Kontchakov, Vladislav Ryzhikov, Michael\n  Zakharyaschev", "title": "A Cookbook for Temporal Conceptual Data Modelling with Description\n  Logics", "comments": "Accepted for the ACM Transaction on Computational Logic, (TOCL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design temporal description logics suitable for reasoning about temporal\nconceptual data models and investigate their computational complexity. Our\nformalisms are based on DL-Lite logics with three types of concept inclusions\n(ranging from atomic concept inclusions and disjointness to the full Booleans),\nas well as cardinality constraints and role inclusions. In the temporal\ndimension, they capture future and past temporal operators on concepts,\nflexible and rigid roles, the operators `always' and `some time' on roles, data\nassertions for particular moments of time and global concept inclusions. The\nlogics are interpreted over the Cartesian products of object domains and the\nflow of time (Z,<), satisfying the constant domain assumption. We prove that\nthe most expressive of our temporal description logics (which can capture\nlifespan cardinalities and either qualitative or quantitative evolution\nconstraints) turn out to be undecidable. However, by omitting some of the\ntemporal operators on concepts/roles or by restricting the form of concept\ninclusions we obtain logics whose complexity ranges between PSpace and\nNLogSpace. These positive results were obtained by reduction to various clausal\nfragments of propositional temporal logic, which opens a way to employ\npropositional or first-order temporal provers for reasoning about temporal data\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 10:48:13 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2013 09:03:28 GMT"}, {"version": "v3", "created": "Fri, 2 May 2014 08:29:40 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Artale", "Alessandro", ""], ["Kontchakov", "Roman", ""], ["Ryzhikov", "Vladislav", ""], ["Zakharyaschev", "Michael", ""]]}, {"id": "1209.5601", "submitter": "Fan Min", "authors": "Fan Min, Qinghua Hu, William Zhu", "title": "Feature selection with test cost constraint", "comments": "23 pages", "journal-ref": null, "doi": "10.1016/j.ijar.2013.04.003", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important preprocessing step in machine learning and\ndata mining. In real-world applications, costs, including money, time and other\nresources, are required to acquire the features. In some cases, there is a test\ncost constraint due to limited resources. We shall deliberately select an\ninformative and cheap feature subset for classification. This paper proposes\nthe feature selection with test cost constraint problem for this issue. The new\nproblem has a simple form while described as a constraint satisfaction problem\n(CSP). Backtracking is a general algorithm for CSP, and it is efficient in\nsolving the new problem on medium-sized data. As the backtracking algorithm is\nnot scalable to large datasets, a heuristic algorithm is also developed.\nExperimental results show that the heuristic algorithm can find the optimal\nsolution in most cases. We also redefine some existing feature selection\nproblems in rough sets, especially in decision-theoretic rough sets, from the\nviewpoint of CSP. These new definitions provide insight to some new research\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 13:21:40 GMT"}], "update_date": "2013-05-22", "authors_parsed": [["Min", "Fan", ""], ["Hu", "Qinghua", ""], ["Zhu", "William", ""]]}, {"id": "1209.5663", "submitter": "Valmi Dufour-Lussier", "authors": "Valmi Dufour-Lussier (INRIA Lorraine - LORIA), Florence Le Ber (INRIA\n  Lorraine - LORIA, LHyGeS), Jean Lieber (INRIA Lorraine - LORIA), Thomas\n  Meilender (INRIA Lorraine - LORIA), Emmanuel Nauer (INRIA Lorraine - LORIA)", "title": "Semi-automatic annotation process for procedural texts: An application\n  on cooking recipes", "comments": null, "journal-ref": "Cooking with Computers workshop (ECAI 2012) (2012)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taaable is a case-based reasoning system that adapts cooking recipes to user\nconstraints. Within it, the preparation part of recipes is formalised as a\ngraph. This graph is a semantic representation of the sequence of instructions\ncomposing the cooking process and is used to compute the procedure adaptation,\nconjointly with the textual adaptation. It is composed of cooking actions and\ningredients, among others, represented as vertices, and semantic relations\nbetween those, shown as arcs, and is built automatically thanks to natural\nlanguage processing. The results of the automatic annotation process is often a\ndisconnected graph, representing an incomplete annotation, or may contain\nerrors. Therefore, a validating and correcting step is required. In this paper,\nwe present an existing graphic tool named \\kcatos, conceived for representing\nand editing decision trees, and show how it has been adapted and integrated in\nWikiTaaable, the semantic wiki in which the knowledge used by Taaable is\nstored. This interface provides the wiki users with a way to correct the case\nrepresentation of the cooking process, improving at the same time the quality\nof the knowledge about cooking procedures stored in WikiTaaable.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 16:13:14 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Dufour-Lussier", "Valmi", "", "INRIA Lorraine - LORIA"], ["Ber", "Florence Le", "", "INRIA\n  Lorraine - LORIA, LHyGeS"], ["Lieber", "Jean", "", "INRIA Lorraine - LORIA"], ["Meilender", "Thomas", "", "INRIA Lorraine - LORIA"], ["Nauer", "Emmanuel", "", "INRIA Lorraine - LORIA"]]}, {"id": "1209.5664", "submitter": "Valmi Dufour-Lussier", "authors": "Valmi Dufour-Lussier (INRIA Lorraine - LORIA), Florence Le Ber (INRIA\n  Lorraine - LORIA, LHyGeS), Jean Lieber (INRIA Lorraine - LORIA)", "title": "Extension du formalisme des flux op\\'erationnels par une alg\\`ebre\n  temporelle", "comments": null, "journal-ref": "Sixi\\`emes Journ\\'ees de l'Intelligence Artificielle Fondamentale\n  (JIAF) (2012) 133-142", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workflows constitute an important language to represent knowledge about\nprocesses, but also increasingly to reason on such knowledge. On the other\nhand, there is a limit to which time constraints between activities can be\nexpressed. Qualitative interval algebras can model processes using finer\ntemporal relations, but they cannot reproduce all workflow patterns. This paper\ndefines a common ground model-theoretical semantics for both workflows and\ninterval algebras, making it possible for reasoning systems working with either\nto interoperate. Thanks to this, interesting properties and inferences can be\ndefined, both on workflows and on an extended formalism combining workflows\nwith interval algebras. Finally, similar formalisms proposing a sound formal\nbasis for workflows and extending them are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 16:14:33 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Dufour-Lussier", "Valmi", "", "INRIA Lorraine - LORIA"], ["Ber", "Florence Le", "", "INRIA\n  Lorraine - LORIA, LHyGeS"], ["Lieber", "Jean", "", "INRIA Lorraine - LORIA"]]}, {"id": "1209.5853", "submitter": "Yi Sun", "authors": "Yi Sun and Daan Wierstra and Tom Schaul and Juergen Schmidhuber", "title": "Efficient Natural Evolution Strategies", "comments": "Puslished in GECCO'2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Natural Evolution Strategies (eNES) is a novel alternative to\nconventional evolutionary algorithms, using the natural gradient to adapt the\nmutation distribution. Unlike previous methods based on natural gradients, eNES\nuses a fast algorithm to calculate the inverse of the exact Fisher information\nmatrix, thus increasing both robustness and performance of its evolution\ngradient estimation, even in higher dimensions. Additional novel aspects of\neNES include optimal fitness baselines and importance mixing (a procedure for\nupdating the population with very few fitness evaluations). The algorithm\nyields competitive results on both unimodal and multimodal benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2012 07:42:06 GMT"}], "update_date": "2012-09-27", "authors_parsed": [["Sun", "Yi", ""], ["Wierstra", "Daan", ""], ["Schaul", "Tom", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1209.6195", "submitter": "Nicolaie Popescu-Bodorin", "authors": "Cristina M. Noaica, Robert Badea, Iulia M. Motoc, Claudiu G. Ghica,\n  Alin C. Rosoiu, Nicolaie Popescu-Bodorin", "title": "Examples of Artificial Perceptions in Optical Character Recognition and\n  Iris Recognition", "comments": "5th Int. Conf. on Soft Computing and Applications (Szeged, HU), 22-24\n  Aug 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assumes the hypothesis that human learning is perception based,\nand consequently, the learning process and perceptions should not be\nrepresented and investigated independently or modeled in different simulation\nspaces. In order to keep the analogy between the artificial and human learning,\nthe former is assumed here as being based on the artificial perception. Hence,\ninstead of choosing to apply or develop a Computational Theory of (human)\nPerceptions, we choose to mirror the human perceptions in a numeric\n(computational) space as artificial perceptions and to analyze the\ninterdependence between artificial learning and artificial perception in the\nsame numeric space, using one of the simplest tools of Artificial Intelligence\nand Soft Computing, namely the perceptrons. As practical applications, we\nchoose to work around two examples: Optical Character Recognition and Iris\nRecognition. In both cases a simple Turing test shows that artificial\nperceptions of the difference between two characters and between two irides are\nfuzzy, whereas the corresponding human perceptions are, in fact, crisp.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2012 11:39:58 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Noaica", "Cristina M.", ""], ["Badea", "Robert", ""], ["Motoc", "Iulia M.", ""], ["Ghica", "Claudiu G.", ""], ["Rosoiu", "Alin C.", ""], ["Popescu-Bodorin", "Nicolaie", ""]]}, {"id": "1209.6299", "submitter": "Jason Williams", "authors": "Jason L. Williams and Roslyn A. Lau", "title": "Approximate evaluation of marginal association probabilities with belief\n  propagation", "comments": "http://dx.doi.org/10.1109/TAES.2014.120568. appears in IEEE\n  Transactions on Aerospace and Electronic Systems, vol. 50, no. 4, October\n  2014", "journal-ref": "IEEE Transactions on Aerospace and Electronic Systems, vol 50, no\n  4, pp 2942-2959, October 2014", "doi": "10.1109/TAES.2014.120568", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data association, the problem of reasoning over correspondence between\ntargets and measurements, is a fundamental problem in tracking. This paper\npresents a graphical model formulation of data association and applies an\napproximate inference method, belief propagation (BP), to obtain estimates of\nmarginal association probabilities. We prove that BP is guaranteed to converge,\nand bound the number of iterations necessary. Experiments reveal a favourable\ncomparison to prior methods in terms of accuracy and computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 06:45:25 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2014 00:47:06 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Williams", "Jason L.", ""], ["Lau", "Roslyn A.", ""]]}, {"id": "1209.6395", "submitter": "Zouhair Abdelhamid", "authors": "Abdelhamid Zouhair, El Mokhtar En-Naimi, Benaissa Amami, Hadhoum\n  Boukachour, Patrick Person, Cyrille Bertelle", "title": "Multi-Agents Dynamic Case Based Reasoning and The Inverse Longest Common\n  Sub-Sequence And Individualized Follow-up of Learners in The CEHL", "comments": "International Journal of Computer Science Issues, Volume 9, Issue 4,\n  No 2, July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-learning, there is still the problem of knowing how to ensure an\nindividualized and continuous learner's follow-up during learning process,\nindeed among the numerous tools proposed, very few systems concentrate on a\nreal time learner's follow-up. Our work in this field develops the design and\nimplementation of a Multi-Agents System Based on Dynamic Case Based Reasoning\nwhich can initiate learning and provide an individualized follow-up of learner.\nWhen interacting with the platform, every learner leaves his/her traces in the\nmachine. These traces are stored in a basis under the form of scenarios which\nenrich collective past experience. The system monitors, compares and analyses\nthese traces to keep a constant intelligent watch and therefore detect\ndifficulties hindering progress and/or avoid possible dropping out. The system\ncan support any learning subject. The success of a case-based reasoning system\ndepends critically on the performance of the retrieval step used and, more\nspecifically, on similarity measure used to retrieve scenarios that are similar\nto the course of the learner (traces in progress). We propose a complementary\nsimilarity measure, named Inverse Longest Common Sub-Sequence (ILCSS). To help\nand guide the learner, the system is equipped with combined virtual and human\ntutors.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2012 23:22:48 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Zouhair", "Abdelhamid", ""], ["En-Naimi", "El Mokhtar", ""], ["Amami", "Benaissa", ""], ["Boukachour", "Hadhoum", ""], ["Person", "Patrick", ""], ["Bertelle", "Cyrille", ""]]}, {"id": "1209.6561", "submitter": "Giorgos Borboudakis", "authors": "Giorgos Borboudakis and Ioannis Tsamardinos", "title": "Scoring and Searching over Bayesian Networks with Causal and Associative\n  Priors", "comments": "Accepted for publication to the 29th Conference on Uncertainty in\n  Artificial Intelligence (UAI-2013). The content of the paper is identical to\n  the published one, but the compiler at arXiv produces a 11 page long paper,\n  whereas the compiler we used produces a 10 page long paper (page limit for\n  the conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant theoretical advantage of search-and-score methods for learning\nBayesian Networks is that they can accept informative prior beliefs for each\npossible network, thus complementing the data. In this paper, a method is\npresented for assigning priors based on beliefs on the presence or absence of\ncertain paths in the true network. Such beliefs correspond to knowledge about\nthe possible causal and associative relations between pairs of variables. This\ntype of knowledge naturally arises from prior experimental and observational\ndata, among others. In addition, a novel search-operator is proposed to take\nadvantage of such prior knowledge. Experiments show that, using path beliefs\nimproves the learning of the skeleton, as well as the edge directions in the\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 16:06:09 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2013 19:57:02 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Borboudakis", "Giorgos", ""], ["Tsamardinos", "Ioannis", ""]]}]