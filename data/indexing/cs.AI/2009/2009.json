[{"id": "2009.00081", "submitter": "Afaf Ta\\\"ik", "authors": "Afaf Ta\\\"ik and Soumaya Cherkaoui", "title": "Federated Edge Learning : Design Issues and Challenges", "comments": "Submitted to IEEE Network Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed machine learning technique, where\neach device contributes to the learning model by independently computing the\ngradient based on its local training data. It has recently become a hot\nresearch topic, as it promises several benefits related to data privacy and\nscalability. However, implementing FL at the network edge is challenging due to\nsystem and data heterogeneity and resources constraints. In this article, we\nexamine the existing challenges and trade-offs in Federated Edge Learning\n(FEEL). The design of FEEL algorithms for resources-efficient learning raises\nseveral challenges. These challenges are essentially related to the\nmultidisciplinary nature of the problem. As the data is the key component of\nthe learning, this article advocates a new set of considerations for data\ncharacteristics in wireless scheduling algorithms in FEEL. Hence, we propose a\ngeneral framework for the data-aware scheduling as a guideline for future\nresearch directions. We also discuss the main axes and requirements for data\nevaluation and some exploitable techniques and metrics.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 19:56:36 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ta\u00efk", "Afaf", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2009.00106", "submitter": "Debayan Banerjee", "authors": "Debayan Banerjee, Debanjan Chaudhuri, Mohnish Dubey, Jens Lehmann", "title": "PNEL: Pointer Network based End-To-End Entity Linking over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering systems are generally modelled as a pipeline consisting of\na sequence of steps. In such a pipeline, Entity Linking (EL) is often the first\nstep. Several EL models first perform span detection and then entity\ndisambiguation. In such models errors from the span detection phase cascade to\nlater steps and result in a drop of overall accuracy. Moreover, lack of gold\nentity spans in training data is a limiting factor for span detector training.\nHence the movement towards end-to-end EL models began where no separate span\ndetection step is involved. In this work we present a novel approach to\nend-to-end EL by applying the popular Pointer Network model, which achieves\ncompetitive performance. We demonstrate this in our evaluation over three\ndatasets on the Wikidata Knowledge Graph.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:15:28 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Banerjee", "Debayan", ""], ["Chaudhuri", "Debanjan", ""], ["Dubey", "Mohnish", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.00145", "submitter": "Zihao Zhu", "authors": "Jing Yu, Zihao Zhu, Yujing Wang, Weifeng Zhang, Yue Hu, Jianlong Tan", "title": "Cross-modal Knowledge Reasoning for Knowledge-based Visual Question\n  Answering", "comments": "Accepted at Pattern Recognition. arXiv admin note: substantial text\n  overlap with arXiv:2006.09073", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107563", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge-based Visual Question Answering (KVQA) requires external knowledge\nbeyond the visible content to answer questions about an image. This ability is\nchallenging but indispensable to achieve general VQA. One limitation of\nexisting KVQA solutions is that they jointly embed all kinds of information\nwithout fine-grained selection, which introduces unexpected noises for\nreasoning the correct answer. How to capture the question-oriented and\ninformation-complementary evidence remains a key challenge to solve the\nproblem. Inspired by the human cognition theory, in this paper, we depict an\nimage by multiple knowledge graphs from the visual, semantic and factual views.\nThereinto, the visual graph and semantic graph are regarded as\nimage-conditioned instantiation of the factual graph. On top of these new\nrepresentations, we re-formulate Knowledge-based Visual Question Answering as a\nrecurrent reasoning process for obtaining complementary evidence from\nmultimodal information. To this end, we decompose the model into a series of\nmemory-based reasoning steps, each performed by a G raph-based R ead, U pdate,\nand C ontrol ( GRUC ) module that conducts parallel reasoning over both visual\nand semantic information. By stacking the modules multiple times, our model\nperforms transitive reasoning and obtains question-oriented concept\nrepresentations under the constrain of different modalities. Finally, we\nperform graph neural networks to infer the global-optimal answer by jointly\nconsidering all the concepts. We achieve a new state-of-the-art performance on\nthree popular benchmark datasets, including FVQA, Visual7W-KB and OK-VQA, and\ndemonstrate the effectiveness and interpretability of our model with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 23:25:01 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Yu", "Jing", ""], ["Zhu", "Zihao", ""], ["Wang", "Yujing", ""], ["Zhang", "Weifeng", ""], ["Hu", "Yue", ""], ["Tan", "Jianlong", ""]]}, {"id": "2009.00149", "submitter": "Timo Bolkart", "authors": "Partha Ghosh, Pravir Singh Gupta, Roy Uziel, Anurag Ranjan, Michael\n  Black, Timo Bolkart", "title": "GIF: Generative Interpretable Faces", "comments": "International Conference on 3D Vision (3DV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo-realistic visualization and animation of expressive human faces have\nbeen a long standing challenge. 3D face modeling methods provide parametric\ncontrol but generates unrealistic images, on the other hand, generative 2D\nmodels like GANs (Generative Adversarial Networks) output photo-realistic face\nimages, but lack explicit control. Recent methods gain partial control, either\nby attempting to disentangle different factors in an unsupervised manner, or by\nadding control post hoc to a pre-trained model. Unconditional GANs, however,\nmay entangle factors that are hard to undo later. We condition our generative\nmodel on pre-defined control parameters to encourage disentanglement in the\ngeneration process. Specifically, we condition StyleGAN2 on FLAME, a generative\n3D face model. While conditioning on FLAME parameters yields unsatisfactory\nresults, we find that conditioning on rendered FLAME geometry and photometric\ndetails works well. This gives us a generative 2D face model named GIF\n(Generative Interpretable Faces) that offers FLAME's parametric control. Here,\ninterpretable refers to the semantic meaning of different parameters. Given\nFLAME parameters for shape, pose, expressions, parameters for appearance,\nlighting, and an additional style vector, GIF outputs photo-realistic face\nimages. We perform an AMT based perceptual study to quantitatively and\nqualitatively evaluate how well GIF follows its conditioning. The code, data,\nand trained model are publicly available for research purposes at\nhttp://gif.is.tue.mpg.de.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 23:40:26 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 13:37:01 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ghosh", "Partha", ""], ["Gupta", "Pravir Singh", ""], ["Uziel", "Roy", ""], ["Ranjan", "Anurag", ""], ["Black", "Michael", ""], ["Bolkart", "Timo", ""]]}, {"id": "2009.00163", "submitter": "Binghui Wang", "authors": "Houxiang Fan, Binghui Wang, Pan Zhou, Ang Li, Meng Pang, Zichuan Xu,\n  Cai Fu, Hai Li, Yiran Chen", "title": "Reinforcement Learning-based Black-Box Evasion Attacks to Link\n  Prediction in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in dynamic graphs (LPDG) is an important research problem\nthat has diverse applications such as online recommendations, studies on\ndisease contagion, organizational studies, etc. Various LPDG methods based on\ngraph embedding and graph neural networks have been recently proposed and\nachieved state-of-the-art performance. In this paper, we study the\nvulnerability of LPDG methods and propose the first practical black-box evasion\nattack. Specifically, given a trained LPDG model, our attack aims to perturb\nthe graph structure, without knowing to model parameters, model architecture,\netc., such that the LPDG model makes as many wrong predicted links as possible.\nWe design our attack based on a stochastic policy-based RL algorithm. Moreover,\nwe evaluate our attack on three real-world graph datasets from different\napplication domains. Experimental results show that our attack is both\neffective and efficient.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:04:49 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 20:58:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Fan", "Houxiang", ""], ["Wang", "Binghui", ""], ["Zhou", "Pan", ""], ["Li", "Ang", ""], ["Pang", "Meng", ""], ["Xu", "Zichuan", ""], ["Fu", "Cai", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2009.00219", "submitter": "Zhuochen Jin", "authors": "Zhuochen Jin, Shunan Guo, Nan Chen, Daniel Weiskopf, David Gotz, Nan\n  Cao", "title": "Visual Causality Analysis of Event Sequence Data", "comments": null, "journal-ref": null, "doi": "10.1109/TVCG.2020.3030465", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality is crucial to understanding the mechanisms behind complex systems\nand making decisions that lead to intended outcomes. Event sequence data is\nwidely collected from many real-world processes, such as electronic health\nrecords, web clickstreams, and financial transactions, which transmit a great\ndeal of information reflecting the causal relations among event types.\nUnfortunately, recovering causalities from observational event sequences is\nchallenging, as the heterogeneous and high-dimensional event variables are\noften connected to rather complex underlying event excitation mechanisms that\nare hard to infer from limited observations. Many existing automated causal\nanalysis techniques suffer from poor explainability and fail to include an\nadequate amount of human knowledge. In this paper, we introduce a visual\nanalytics method for recovering causalities in event sequence data. We extend\nthe Granger causality analysis algorithm on Hawkes processes to incorporate\nuser feedback into causal model refinement. The visualization system includes\nan interactive causal analysis framework that supports bottom-up causal\nexploration, iterative causal verification and refinement, and causal\ncomparison through a set of novel visualizations and interactions. We report\ntwo forms of evaluation: a quantitative evaluation of the model improvements\nresulting from the user-feedback mechanism, and a qualitative evaluation\nthrough case studies in different application domains to demonstrate the\nusefulness of the system.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 04:28:28 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Jin", "Zhuochen", ""], ["Guo", "Shunan", ""], ["Chen", "Nan", ""], ["Weiskopf", "Daniel", ""], ["Gotz", "David", ""], ["Cao", "Nan", ""]]}, {"id": "2009.00249", "submitter": "Tan Tang", "authors": "Tan Tang, Renzhong Li, Xinke Wu, Shuhan Liu, Johannes Knittel, Steffen\n  Koch, Thomas Ertl, Lingyun Yu, Peiran Ren, and Yingcai Wu", "title": "PlotThread: Creating Expressive Storyline Visualizations using\n  Reinforcement Learning", "comments": "to be published in IEEE VIS InfoVis 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storyline visualizations are an effective means to present the evolution of\nplots and reveal the scenic interactions among characters. However, the design\nof storyline visualizations is a difficult task as users need to balance\nbetween aesthetic goals and narrative constraints. Despite that the\noptimization-based methods have been improved significantly in terms of\nproducing aesthetic and legible layouts, the existing (semi-) automatic methods\nare still limited regarding 1) efficient exploration of the storyline design\nspace and 2) flexible customization of storyline layouts. In this work, we\npropose a reinforcement learning framework to train an AI agent that assists\nusers in exploring the design space efficiently and generating well-optimized\nstorylines. Based on the framework, we introduce PlotThread, an authoring tool\nthat integrates a set of flexible interactions to support easy customization of\nstoryline visualizations. To seamlessly integrate the AI agent into the\nauthoring process, we employ a mixed-initiative approach where both the agent\nand designers work on the same canvas to boost the collaborative design of\nstorylines. We evaluate the reinforcement learning model through qualitative\nand quantitative experiments and demonstrate the usage of PlotThread using a\ncollection of use cases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 06:01:54 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Tang", "Tan", ""], ["Li", "Renzhong", ""], ["Wu", "Xinke", ""], ["Liu", "Shuhan", ""], ["Knittel", "Johannes", ""], ["Koch", "Steffen", ""], ["Ertl", "Thomas", ""], ["Yu", "Lingyun", ""], ["Ren", "Peiran", ""], ["Wu", "Yingcai", ""]]}, {"id": "2009.00318", "submitter": "Heiko Paulheim", "authors": "Andreea Iana and Heiko Paulheim", "title": "More is not Always Better: The Negative Impact of A-box Materialization\n  on RDF2vec Knowledge Graph Embeddings", "comments": "Accepted at the Workshop on Combining Symbolic and Sub-symbolic\n  methods and their Applications (CSSA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RDF2vec is an embedding technique for representing knowledge graph entities\nin a continuous vector space. In this paper, we investigate the effect of\nmaterializing implicit A-box axioms induced by subproperties, as well as\nsymmetric and transitive properties. While it might be a reasonable assumption\nthat such a materialization before computing embeddings might lead to better\nembeddings, we conduct a set of experiments on DBpedia which demonstrate that\nthe materialization actually has a negative effect on the performance of\nRDF2vec. In our analysis, we argue that despite the huge body of work devoted\non completing missing information in knowledge graphs, such missing implicit\ninformation is actually a signal, not a defect, and we show examples\nillustrating that assumption.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 09:52:33 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Iana", "Andreea", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2009.00326", "submitter": "Christophe Lecoutre", "authors": "Christophe Lecoutre and Nicolas Szczepanski", "title": "PYCSP3: Modeling Combinatorial Constrained Problems in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we introduce PYCSP$3$, a Python library that allows us to\nwrite models of combinatorial constrained problems in a simple and declarative\nway. Currently, with PyCSP$3$, you can write models of constraint satisfaction\nand optimization problems. More specifically, you can build CSP (Constraint\nSatisfaction Problem) and COP (Constraint Optimization Problem) models.\nImportantly, there is a complete separation between modeling and solving\nphases: you write a model, you compile it (while providing some data) in order\nto generate an XCSP3 instance (file), and you solve that problem instance by\nmeans of a constraint solver. In this document, you will find all that you need\nto know about PYCSP$3$, with more than 40 illustrative models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:11:31 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 16:29:31 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Lecoutre", "Christophe", ""], ["Szczepanski", "Nicolas", ""]]}, {"id": "2009.00335", "submitter": "Vivek Nallur", "authors": "Vivek Nallur", "title": "Landscape of Machine Implemented Ethics", "comments": "25 pages", "journal-ref": "Science and Engineering Ethics (2020)", "doi": "10.1007/s11948-020-00236-y", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the state-of-the-art in machine ethics, that is,\nconsiderations of how to implement ethical behaviour in robots, unmanned\nautonomous vehicles, or software systems. The emphasis is on covering the\nbreadth of ethical theories being considered by implementors, as well as the\nimplementation techniques being used. There is no consensus on which ethical\ntheory is best suited for any particular domain, nor is there any agreement on\nwhich technique is best placed to implement a particular theory. Another\nunresolved problem in these implementations of ethical theories is how to\nobjectively validate the implementations. The paper discusses the dilemmas\nbeing used as validating 'whetstones' and whether any alternative validation\nmechanism exists. Finally, it speculates that an intermediate step of creating\ndomain-specific ethics might be a possible stepping stone towards creating\nmachines that exhibit ethical behaviour.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:34:59 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Nallur", "Vivek", ""]]}, {"id": "2009.00351", "submitter": "Haining Zheng", "authors": "Haining Zheng and Antonio R. Paiva and Chris S. Gurciullo", "title": "Advancing from Predictive Maintenance to Intelligent Maintenance with AI\n  and IIoT", "comments": "The 3rd International Workshop on Artificial Intelligence of Things\n  (AIoT) In conjunction with the 26th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Artificial Intelligent (AI) technology advances and increasingly large\namounts of data become readily available via various Industrial Internet of\nThings (IIoT) projects, we evaluate the state of the art of predictive\nmaintenance approaches and propose our innovative framework to improve the\ncurrent practice. The paper first reviews the evolution of reliability\nmodelling technology in the past 90 years and discusses major technologies\ndeveloped in industry and academia. We then introduce the next generation\nmaintenance framework - Intelligent Maintenance, and discuss its key\ncomponents. This AI and IIoT based Intelligent Maintenance framework is\ncomposed of (1) latest machine learning algorithms including probabilistic\nreliability modelling with deep learning, (2) real-time data collection,\ntransfer, and storage through wireless smart sensors, (3) Big Data\ntechnologies, (4) continuously integration and deployment of machine learning\nmodels, (5) mobile device and AR/VR applications for fast and better\ndecision-making in the field. Particularly, we proposed a novel probabilistic\ndeep learning reliability modelling approach and demonstrate it in the Turbofan\nEngine Degradation Dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:10:13 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Zheng", "Haining", ""], ["Paiva", "Antonio R.", ""], ["Gurciullo", "Chris S.", ""]]}, {"id": "2009.00363", "submitter": "Kun Xiao", "authors": "Kun Xiao, Junqi Lu, Ying Nie, Lan Ma, Xiangke Wang, Guohui Wang", "title": "A Benchmark for Multi-UAV Task Assignment of an Extended Team\n  Orienteering Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A benchmark for multi-UAV task assignment is presented in order to evaluate\ndifferent algorithms. An extended Team Orienteering Problem is modeled for a\nkind of multi-UAV task assignment problem. Three intelligent algorithms, i.e.,\nGenetic Algorithm, Ant Colony Optimization and Particle Swarm Optimization are\nimplemented to solve the problem. A series of experiments with different\nsettings are conducted to evaluate three algorithms. The modeled problem and\nthe evaluation results constitute a benchmark, which can be used to evaluate\nother algorithms used for multi-UAV task assignment problems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 11:35:37 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Xiao", "Kun", ""], ["Lu", "Junqi", ""], ["Nie", "Ying", ""], ["Ma", "Lan", ""], ["Wang", "Xiangke", ""], ["Wang", "Guohui", ""]]}, {"id": "2009.00394", "submitter": "Fatemeh Jahedpari", "authors": "Fatemeh Jahedpari", "title": "Continuous Artificial Prediction Markets as a Syndromic Surveillance\n  Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of syndromic surveillance systems is early detection of an\noutbreak in a society using available data sources. In this paper, we discuss\nwhat are the challenges of syndromic surveillance systems and how continuous\nArtificial Prediction Market [Jahedpari et al., 2017] can effectively be\napplied to the problem of syndromic surveillance.\n  We use two well-known models of (i) Google Flu Trends, and (ii) the latest\nimprovement of Google Flu Trends model, named as GP [Lampos et al., 2015], as\nour case study and we show how c-APM can improve upon their performance. Our\nresults demonstrate that c-APM typically has a lower MAE to that of Google Flu\nTrends in each year. Though this difference is relatively small in some years\nlike 2004 and 2007, it is relatively large in most years and very large between\n2011 and 2013.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 12:51:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Jahedpari", "Fatemeh", ""]]}, {"id": "2009.00418", "submitter": "Kristijonas \\v{C}yras", "authors": "Kristijonas Cyras, Ramamurthy Badrinath, Swarup Kumar Mohalik, Anusha\n  Mujumdar, Alexandros Nikou, Alessandro Previti, Vaishnavi Sundararajan, Aneta\n  Vulgarakis Feljan", "title": "Machine Reasoning Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a field of AI, Machine Reasoning (MR) uses largely symbolic means to\nformalize and emulate abstract reasoning. Studies in early MR have notably\nstarted inquiries into Explainable AI (XAI) -- arguably one of the biggest\nconcerns today for the AI community. Work on explainable MR as well as on MR\napproaches to explainability in other areas of AI has continued ever since. It\nis especially potent in modern MR branches, such as argumentation, constraint\nand logic programming, planning. We hereby aim to provide a selective overview\nof MR explainability techniques and studies in hopes that insights from this\nlong track of research will complement well the current XAI landscape. This\ndocument reports our work in-progress on MR explainability.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:45:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:09:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Cyras", "Kristijonas", ""], ["Badrinath", "Ramamurthy", ""], ["Mohalik", "Swarup Kumar", ""], ["Mujumdar", "Anusha", ""], ["Nikou", "Alexandros", ""], ["Previti", "Alessandro", ""], ["Sundararajan", "Vaishnavi", ""], ["Feljan", "Aneta Vulgarakis", ""]]}, {"id": "2009.00433", "submitter": "Giorgio Grani", "authors": "Valerio Agasucci, Giorgio Grani, Leonardo Lamorgese", "title": "Solving the single-track train scheduling problem via Deep Reinforcement\n  Learning", "comments": "12 pages, 4 figures (2 b&w)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every day, railways experience small inconveniences, both on the network and\nthe fleet side, affecting the stability of rail traffic. When a disruption\noccurs, delays propagate through the network, resulting in demand mismatching\nand, in the long run, demand loss. When a critical situation arises, human\ndispatchers distributed over the line have the duty to do their best to\nminimize the impact of the disruptions. Unfortunately, human operators have a\nlimited depth of perception of how what happens in distant areas of the network\nmay affect their control zone. In recent years, decision science has focused on\ndeveloping methods to solve the problem automatically, to improve the\ncapabilities of human operators. In this paper, machine learning-based methods\nare investigated when dealing with the train dispatching problem. In\nparticular, two different Deep Q-Learning methods are proposed. Numerical\nresults show the superiority of these techniques respect to the classical\nlinear Q-Learning based on matrices.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:03:56 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Agasucci", "Valerio", ""], ["Grani", "Giorgio", ""], ["Lamorgese", "Leonardo", ""]]}, {"id": "2009.00502", "submitter": "James Wright", "authors": "James Wright", "title": "Suspect AI: Vibraimage, Emotion Recognition Technology, and Algorithmic\n  Opacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vibraimage is a digital system that quantifies a subject's mental and\nemotional state by analysing video footage of the movements of their head.\nVibraimage is used by police, nuclear power station operators, airport security\nand psychiatrists in Russia, China, Japan and South Korea, and has been\ndeployed at an Olympic Games, FIFA World Cup, and G7 Summit. Yet there is no\nreliable evidence that the technology is actually effective; indeed, many\nclaims made about its effects seem unprovable. What exactly does vibraimage\nmeasure, and how has it acquired the power to penetrate the highest profile and\nmost sensitive security infrastructure across Russia and Asia? I first trace\nthe development of the emotion recognition industry, before examining attempts\nby vibraimage's developers and affiliates scientifically to legitimate the\ntechnology, concluding that the disciplining power and corporate value of\nvibraimage is generated through its very opacity, in contrast to increasing\ndemands across the social sciences for transparency. I propose the term\n'suspect AI' to describe the growing number of systems like vibraimage that\nalgorithmically classify suspects / non-suspects, yet are themselves deeply\nsuspect. Popularising this term may help resist such technologies' reductivist\napproaches to 'reading' -- and exerting authority over -- emotion,\nintentionality and agency.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:03:52 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wright", "James", ""]]}, {"id": "2009.00505", "submitter": "Firas Laakom", "authors": "Firas Laakom, Jenni Raitoharju, Nikolaos Passalis, Alexandros\n  Iosifidis, Moncef Gabbouj", "title": "Graph Embedding with Data Uncertainty", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  spectral-based subspace learning is a common data preprocessing step in many\nmachine learning pipelines. The main aim is to learn a meaningful low\ndimensional embedding of the data. However, most subspace learning methods do\nnot take into consideration possible measurement inaccuracies or artifacts that\ncan lead to data with high uncertainty. Thus, learning directly from raw data\ncan be misleading and can negatively impact the accuracy. In this paper, we\npropose to model artifacts in training data using probability distributions;\neach data point is represented by a Gaussian distribution centered at the\noriginal data point and having a variance modeling its uncertainty. We\nreformulate the Graph Embedding framework to make it suitable for learning from\ndistributions and we study as special cases the Linear Discriminant Analysis\nand the Marginal Fisher Analysis techniques. Furthermore, we propose two\nschemes for modeling data uncertainty based on pair-wise distances in an\nunsupervised and a supervised contexts.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:08:23 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Laakom", "Firas", ""], ["Raitoharju", "Jenni", ""], ["Passalis", "Nikolaos", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2009.00514", "submitter": "Christophe Lecoutre", "authors": "Fr\\'ed\\'eric Boussemart and Christophe Lecoutre and Gilles Audemard\n  and C\\'edric Piette", "title": "XCSP3-core: A Format for Representing Constraint\n  Satisfaction/Optimization Problems", "comments": "arXiv admin note: substantial text overlap with arXiv:1611.03398", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we introduce XCSP3-core, a subset of XCSP3 that allows us\nto represent constraint satisfaction/optimization problems. The interest of\nXCSP3-core is multiple: (i) focusing on the most popular frameworks (CSP and\nCOP) and constraints, (ii) facilitating the parsing process by means of\ndedicated XCSP3-core parsers written in Java and C++ (using callback\nfunctions), (iii) and defining a core format for comparisons (competitions) of\nconstraint solvers.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 15:24:49 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 12:00:45 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Boussemart", "Fr\u00e9d\u00e9ric", ""], ["Lecoutre", "Christophe", ""], ["Audemard", "Gilles", ""], ["Piette", "C\u00e9dric", ""]]}, {"id": "2009.00519", "submitter": "Andrew Collins", "authors": "Daniele Vernon-Bido, Andrew J. Collins", "title": "Finding Core Members of Cooperative Games using Agent-Based Modeling", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based modeling (ABM) is a powerful paradigm to gain insight into social\nphenomena. One area that ABM has rarely been applied is coalition formation.\nTraditionally, coalition formation is modeled using cooperative game theory. In\nthis paper, a heuristic algorithm is developed that can be embedded into an ABM\nto allow the agents to find coalition. The resultant coalition structures are\ncomparable to those found by cooperative game theory solution approaches,\nspecifically, the core. A heuristic approach is required due to the\ncomputational complexity of finding a cooperative game theory solution which\nlimits its application to about only a score of agents. The ABM paradigm\nprovides a platform in which simple rules and interactions between agents can\nproduce a macro-level effect without the large computational requirements. As\nsuch, it can be an effective means for approximating cooperative game solutions\nfor large numbers of agents. Our heuristic algorithm combines agent-based\nmodeling and cooperative game theory to help find agent partitions that are\nmembers of a games' core solution. The accuracy of our heuristic algorithm can\nbe determined by comparing its outcomes to the actual core solutions. This\ncomparison achieved by developing an experiment that uses a specific example of\na cooperative game called the glove game. The glove game is a type of exchange\neconomy game. Finding the traditional cooperative game theory solutions is\ncomputationally intensive for large numbers of players because each possible\npartition must be compared to each possible coalition to determine the core\nset; hence our experiment only considers games of up to nine players. The\nresults indicate that our heuristic approach achieves a core solution over 90%\nof the time for the games considered in our experiment.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 17:38:43 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Vernon-Bido", "Daniele", ""], ["Collins", "Andrew J.", ""]]}, {"id": "2009.00541", "submitter": "Mikhail Jacob", "authors": "Mikhail Jacob, Sam Devlin, Katja Hofmann", "title": "\"It's Unwieldy and It Takes a Lot of Time.\" Challenges and Opportunities\n  for Creating Agents in Commercial Games", "comments": "7 pages, 3 figures, to be published in the 16th AAAI Conference on\n  Artificial Intelligence and Interactive Digital Entertainment (AIIDE-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game agents such as opponents, non-player characters, and teammates are\ncentral to player experiences in many modern games. As the landscape of AI\ntechniques used in the games industry evolves to adopt machine learning (ML)\nmore widely, it is vital that the research community learn from the best\npractices cultivated within the industry over decades creating agents. However,\nalthough commercial game agent creation pipelines are more mature than those\nbased on ML, opportunities for improvement still abound. As a foundation for\nshared progress identifying research opportunities between researchers and\npractitioners, we interviewed seventeen game agent creators from AAA studios,\nindie studios, and industrial research labs about the challenges they\nexperienced with their professional workflows. Our study revealed several open\nchallenges ranging from design to implementation and evaluation. We compare\nwith literature from the research community that address the challenges\nidentified and conclude by highlighting promising directions for future\nresearch supporting agent creation in the games industry.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:21:19 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Jacob", "Mikhail", ""], ["Devlin", "Sam", ""], ["Hofmann", "Katja", ""]]}, {"id": "2009.00563", "submitter": "Yunlong Song", "authors": "Yunlong Song, Selim Naji, Elia Kaufmann, Antonio Loquercio, Davide\n  Scaramuzza", "title": "Flightmare: A Flexible Quadrotor Simulator", "comments": "Accepted for publication at 4th Conference on Robot Learning (CoRL),\n  Cambridge MA, USA. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art quadrotor simulators have a rigid and highly-specialized\nstructure: either are they really fast, physically accurate, or\nphoto-realistic. In this work, we propose a novel quadrotor simulator:\nFlightmare. Flightmare is composed of two main components: a configurable\nrendering engine built on Unity and a flexible physics engine for dynamics\nsimulation. Those two components are totally decoupled and can run\nindependently of each other. This makes our simulator extremely fast: rendering\nachieves speeds of up to 230 Hz, while physics simulation of up to 200,000 Hz\non a laptop. In addition, Flightmare comes with several desirable features: (i)\na large multi-modal sensor suite, including an interface to extract the 3D\npoint-cloud of the scene; (ii) an API for reinforcement learning which can\nsimulate hundreds of quadrotors in parallel; and (iii) integration with a\nvirtual-reality headset for interaction with the simulated environment. We\ndemonstrate the flexibility of Flightmare by using it for two different robotic\ntasks: quadrotor control using deep reinforcement learning and collision-free\npath planning in a complex 3D environment.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 16:50:45 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 17:08:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Song", "Yunlong", ""], ["Naji", "Selim", ""], ["Kaufmann", "Elia", ""], ["Loquercio", "Antonio", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "2009.00581", "submitter": "Matthew Evanusa", "authors": "Matthew Evanusa and Cornelia Fermuller and Yiannis Aloimonos", "title": "A Deep 2-Dimensional Dynamical Spiking Neuronal Network for Temporal\n  Encoding trained with STDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The brain is known to be a highly complex, asynchronous dynamical system that\nis highly tailored to encode temporal information. However, recent deep\nlearning approaches to not take advantage of this temporal coding. Spiking\nNeural Networks (SNNs) can be trained using biologically-realistic learning\nmechanisms, and can have neuronal activation rules that are biologically\nrelevant. This type of network is also structured fundamentally around\naccepting temporal information through a time-decaying voltage update, a kind\nof input that current rate-encoding networks have difficulty with. Here we show\nthat a large, deep layered SNN with dynamical, chaotic activity mimicking the\nmammalian cortex with biologically-inspired learning rules, such as STDP, is\ncapable of encoding information from temporal data. We argue that the\nrandomness inherent in the network weights allow the neurons to form groups\nthat encode the temporal data being inputted after self-organizing with STDP.\nWe aim to show that precise timing of input stimulus is critical in forming\nsynchronous neural groups in a layered network. We analyze the network in terms\nof network entropy as a metric of information transfer. We hope to tackle two\nproblems at once: the creation of artificial temporal neural systems for\nartificial intelligence, as well as solving coding mechanisms in the brain.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:12:18 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Evanusa", "Matthew", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2009.00655", "submitter": "Henry Ward", "authors": "Henry N. Ward, Daniel J. Brooks, Dan Troha, Bobby Mills, Arseny S.\n  Khakhalin", "title": "AI solutions for drafting in Magic: the Gathering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drafting in Magic the Gathering is a sub-game within a larger trading card\ngame, where several players progressively build decks by picking cards from a\ncommon pool. Drafting poses an interesting problem for game and AI research due\nto its large search space, mechanical complexity, multiplayer nature, and\nhidden information. Despite this, drafting remains understudied, in part due to\na lack of high-quality, public datasets. To rectify this problem, we present a\ndataset of over 100,000 simulated, anonymized human drafts collected from\nDraftsim.com. We also propose four diverse strategies for drafting agents,\nincluding a primitive heuristic agent, an expert-tuned complex heuristic agent,\na Naive Bayes agent, and a deep neural network agent. We benchmark their\nability to emulate human drafting, and show that the deep neural network agent\noutperforms other agents, while the Naive Bayes and expert-tuned agents\noutperform simple heuristics. We analyze the accuracy of AI agents across the\ntimeline of a draft, and describe unique strengths and weaknesses for each\napproach. This work helps to identify next steps in the creation of humanlike\ndrafting agents, and can serve as a benchmark for the next generation of\ndrafting bots.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 18:44:10 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 00:51:54 GMT"}, {"version": "v3", "created": "Sun, 4 Apr 2021 19:13:53 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Ward", "Henry N.", ""], ["Brooks", "Daniel J.", ""], ["Troha", "Dan", ""], ["Mills", "Bobby", ""], ["Khakhalin", "Arseny S.", ""]]}, {"id": "2009.00679", "submitter": "Mohammed Alsuwaiket", "authors": "Mohammed Alsuwaiket, Christian Dawson, Firat Batmaz", "title": "Measuring the Credibility of Student Attendance Data in Higher Education\n  for Data Mining", "comments": "7 pages, 2 figures, 6 tables", "journal-ref": null, "doi": "10.18178/ijiet.2018.8.2.1020", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educational Data Mining (EDM) is a developing discipline, concerned with\nexpanding the classical Data Mining (DM) methods and developing new methods for\ndiscovering the data that originate from educational systems. Student\nattendance in higher education has always been dealt with in a classical way,\neducators rely on counting the occurrence of attendance or absence building\ntheir knowledge about students as well as modules based on this count. This\nmethod is neither credible nor does it necessarily provide a real indication of\na student performance. This study tries to formulate the extracted knowledge in\na way that guarantees achieving accurate and credible results. Student\nattendance data, gathered from the educational system, were first cleaned in\norder to remove any randomness and noise, then various attributes were studied\nso as to highlight the most significant ones that affect the real attendance of\nstudents. The next step was to derive an equation that measures the Student\nAttendance Credibility (SAC) considering the attributes chosen in the previous\nstep. The reliability of the newly developed measure was then evaluated in\norder to examine its consistency. Finally, the J48 DM classification technique\nwas utilized in order to classify modules based on the strength of their SAC\nvalues. Results of this study were promising, and credibility values achieved\nusing the newly derived formula gave accurate, credible, and real indicators of\nstudent attendance, as well as accurate classification of modules based on the\ncredibility of student attendance on those modules.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:21:46 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Alsuwaiket", "Mohammed", ""], ["Dawson", "Christian", ""], ["Batmaz", "Firat", ""]]}, {"id": "2009.00681", "submitter": "Yutong Ban", "authors": "Yutong Ban, Guy Rosman, Thomas Ward, Daniel Hashimoto, Taisei Kondo,\n  Hidekazu Iwaki, Ozanan Meireles, Daniela Rus", "title": "Aggregating Long-Term Context for Learning Laparoscopic and\n  Robot-Assisted Surgical Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing surgical workflow is crucial for surgical assistance robots to\nunderstand surgeries. With the understanding of the complete surgical workflow,\nthe robots are able to assist the surgeons in intra-operative events, such as\nby giving a warning when the surgeon is entering specific keys or high-risk\nphases. Deep learning techniques have recently been widely applied to\nrecognizing surgical workflows. Many of the existing temporal neural network\nmodels are limited in their capability to handle long-term dependencies in the\ndata, instead, relying upon the strong performance of the underlying per-frame\nvisual models. We propose a new temporal network structure that leverages\ntask-specific network representation to collect long-term sufficient statistics\nthat are propagated by a sufficient statistics model (SSM). We implement our\napproach within an LSTM backbone for the task of surgical phase recognition and\nexplore several choices for propagated statistics. We demonstrate superior\nresults over existing and novel state-of-the-art segmentation techniques on two\nlaparoscopic cholecystectomy datasets: the publicly available Cholec80 dataset\nand MGH100, a novel dataset with more challenging and clinically meaningful\nsegment labels.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:29:14 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:05:26 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 18:58:43 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 20:02:18 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ban", "Yutong", ""], ["Rosman", "Guy", ""], ["Ward", "Thomas", ""], ["Hashimoto", "Daniel", ""], ["Kondo", "Taisei", ""], ["Iwaki", "Hidekazu", ""], ["Meireles", "Ozanan", ""], ["Rus", "Daniela", ""]]}, {"id": "2009.00690", "submitter": "Junyi Li", "authors": "Junyi Li, Bin Gu, Heng Huang", "title": "Improved Bilevel Model: Fast and Optimal Algorithm with Theoretical\n  Guarantee", "comments": "submitted to ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the hierarchical structure of many machine learning problems, bilevel\nprogramming is becoming more and more important recently, however, the\ncomplicated correlation between the inner and outer problem makes it extremely\nchallenging to solve. Although several intuitive algorithms based on the\nautomatic differentiation have been proposed and obtained success in some\napplications, not much attention has been paid to finding the optimal\nformulation of the bilevel model. Whether there exists a better formulation is\nstill an open problem. In this paper, we propose an improved bilevel model\nwhich converges faster and better compared to the current formulation. We\nprovide theoretical guarantee and evaluation results over two tasks: Data\nHyper-Cleaning and Hyper Representation Learning. The empirical results show\nthat our model outperforms the current bilevel model with a great margin.\n\\emph{This is a concurrent work with \\citet{liu2020generic} and we submitted to\nICML 2020. Now we put it on the arxiv for record.}\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:52:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Li", "Junyi", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2009.00712", "submitter": "Kyungeun Lee", "authors": "Kyungeun Lee, Moonjung Eo, Euna Jung, Yoonjin Yoon, and Wonjong Rhee", "title": "Short-term Traffic Prediction with Deep Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern transportation systems, an enormous amount of traffic data is\ngenerated every day. This has led to rapid progress in short-term traffic\nprediction (STTP), in which deep learning methods have recently been applied.\nIn traffic networks with complex spatiotemporal relationships, deep neural\nnetworks (DNNs) often perform well because they are capable of automatically\nextracting the most important features and patterns. In this study, we survey\nrecent STTP studies applying deep networks from four perspectives. 1) We\nsummarize input data representation methods according to the number and type of\nspatial and temporal dependencies involved. 2) We briefly explain a wide range\nof DNN techniques from the earliest networks, including Restricted Boltzmann\nMachines, to the most recent, including graph-based and meta-learning networks.\n3) We summarize previous STTP studies in terms of the type of DNN techniques,\napplication area, dataset and code availability, and the type of the\nrepresented spatiotemporal dependencies. 4) We compile public traffic datasets\nthat are popular and can be used as the standard benchmarks. Finally, we\nsuggest challenging issues and possible future research directions in STTP.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:06:06 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lee", "Kyungeun", ""], ["Eo", "Moonjung", ""], ["Jung", "Euna", ""], ["Yoon", "Yoonjin", ""], ["Rhee", "Wonjong", ""]]}, {"id": "2009.00717", "submitter": "Zhi Wang", "authors": "Zhi Wang, Xueying Tang, Jingchen Liu and Zhiliang Ying", "title": "Subtask Analysis of Process Data Through a Predictive Model", "comments": "34 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response process data collected from human-computer interactive items contain\nrich information about respondents' behavioral patterns and cognitive\nprocesses. Their irregular formats as well as their large sizes make standard\nstatistical tools difficult to apply. This paper develops a computationally\nefficient method for exploratory analysis of such process data. The new\napproach segments a lengthy individual process into a sequence of short\nsubprocesses to achieve complexity reduction, easy clustering and meaningful\ninterpretation. Each subprocess is considered a subtask. The segmentation is\nbased on sequential action predictability using a parsimonious predictive model\ncombined with the Shannon entropy. Simulation studies are conducted to assess\nperformance of the new methods. We use the process data from PIAAC 2012 to\ndemonstrate how exploratory analysis of process data can be done with the new\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 21:11:01 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Wang", "Zhi", ""], ["Tang", "Xueying", ""], ["Liu", "Jingchen", ""], ["Ying", "Zhiliang", ""]]}, {"id": "2009.00725", "submitter": "Davide Rigoni", "authors": "Davide Rigoni, Nicol\\`o Navarin and Alessandro Sperduti", "title": "Conditional Constrained Graph Variational Autoencoders for Molecule\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep generative models for graphs have been used to generate\nnew molecules. These models have produced good results, leading to several\nproposals in the literature. However, these models may have troubles learning\nsome of the complex laws governing the chemical world. In this work, we explore\nthe usage of the histogram of atom valences to drive the generation of\nmolecules in such models. We present Conditional Constrained Graph Variational\nAutoencoder (CCGVAE), a model that implements this key-idea in a\nstate-of-the-art model, and shows improved results on several evaluation\nmetrics on two commonly adopted datasets for molecule generation.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 21:58:07 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Rigoni", "Davide", ""], ["Navarin", "Nicol\u00f2", ""], ["Sperduti", "Alessandro", ""]]}, {"id": "2009.00735", "submitter": "Markus K\\\"uhbach", "authors": "Markus K\\\"uhbach and Matthew Kasemer and Baptiste Gault and Andrew\n  Breen", "title": "On Open and Strong-Scaling Tools for Atom Probe Crystallography:\n  High-Throughput Methods for Indexing Crystal Structure and Orientation", "comments": "36 pages, 19 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volumetric crystal structure indexing and orientation mapping are key data\nprocessing steps for virtually any quantitative study of spatial correlations\nbetween the local chemistry and the microstructure of a material. For electron\nand X-ray diffraction methods it is possible to develop indexing tools which\ncompare measured and analytically computed patterns to decode the structure and\nrelative orientation within local regions of interest. Consequently, a number\nof numerically efficient and automated software tools exist to solve the above\ncharacterisation tasks.\n  For atom probe tomography (APT) experiments, however, the strategy of making\ncomparisons between measured and analytically computed patterns is less robust\nbecause many APT datasets may contain substantial noise. Given that general\nenough predictive models for such noise remain elusive, crystallography tools\nfor APT face several limitations: Their robustness to noise, and therefore,\ntheir capability to identify and distinguish different crystal structures and\norientation is limited. In addition, the tools are sequential and demand\nsubstantial manual interaction. In combination, this makes robust uncertainty\nquantifying with automated high-throughput studies of the latent\ncrystallographic information a difficult task with APT data.\n  To improve the situation, we review the existent methods and discuss how they\nlink to those in the diffraction communities. With this we modify some of the\nAPT methods to yield more robust descriptors of the atomic arrangement. We\nreport how this enables the development of an open-source software tool for\nstrong-scaling and automated identifying of crystal structure and mapping\ncrystal orientation in nanocrystalline APT datasets with multiple phases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 22:50:03 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["K\u00fchbach", "Markus", ""], ["Kasemer", "Matthew", ""], ["Gault", "Baptiste", ""], ["Breen", "Andrew", ""]]}, {"id": "2009.00751", "submitter": "Tushar Khot", "authors": "Tushar Khot and Daniel Khashabi and Kyle Richardson and Peter Clark\n  and Ashish Sabharwal", "title": "Text Modular Networks: Learning to Decompose Tasks in the Language of\n  Existing Models", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework called Text Modular Networks(TMNs) for\nbuilding interpretable systems that learn to solve complex tasks by decomposing\nthem into simpler ones solvable by existing models. To ensure solvability of\nsimpler tasks, TMNs learn the textual input-output behavior (i.e., language) of\nexisting models through their datasets. This differs from prior\ndecomposition-based approaches which, besides being designed specifically for\neach complex task, produce decompositions independent of existing sub-models.\nSpecifically, we focus on Question Answering (QA) and show how to train a\nnext-question generator to sequentially produce sub-questions targeting\nappropriate sub-models, without additional human annotation. These\nsub-questions and answers provide a faithful natural language explanation of\nthe model's reasoning. We use this framework to build ModularQA, a system that\ncan answer multi-hop reasoning questions by decomposing them into sub-questions\nanswerable by a neural factoid single-span QA model and a symbolic calculator.\nOur experiments show that ModularQA is more versatile than existing explainable\nsystems for DROP and HotpotQA datasets, is more robust than state-of-the-art\nblackbox (uninterpretable) systems, and generates more understandable and\ntrustworthy explanations compared to prior work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 23:45:42 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 21:58:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Khot", "Tushar", ""], ["Khashabi", "Daniel", ""], ["Richardson", "Kyle", ""], ["Clark", "Peter", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2009.00802", "submitter": "Andrew Lohn", "authors": "Andrew J. Lohn", "title": "Estimating the Brittleness of AI: Safety Integrity Levels and the Need\n  for Testing Out-Of-Distribution Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test, Evaluation, Verification, and Validation (TEVV) for Artificial\nIntelligence (AI) is a challenge that threatens to limit the economic and\nsocietal rewards that AI researchers have devoted themselves to producing. A\ncentral task of TEVV for AI is estimating brittleness, where brittleness\nimplies that the system functions well within some bounds and poorly outside of\nthose bounds. This paper argues that neither of those criteria are certain of\nDeep Neural Networks. First, highly touted AI successes (eg. image\nclassification and speech recognition) are orders of magnitude more\nfailure-prone than are typically certified in critical systems even within\ndesign bounds (perfectly in-distribution sampling). Second, performance falls\noff only gradually as inputs become further Out-Of-Distribution (OOD). Enhanced\nemphasis is needed on designing systems that are resilient despite\nfailure-prone AI components as well as on evaluating and improving OOD\nperformance in order to get AI to where it can clear the challenging hurdles of\nTEVV and certification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:33:40 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Lohn", "Andrew J.", ""]]}, {"id": "2009.00803", "submitter": "Saad Wazir", "authors": "Hamza Ali Imran, Usama Mujahid, Saad Wazir, Usama Latif, Kiran Mehmood", "title": "Embedded Development Boards for Edge-AI: A Comprehensive Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of Deep Learning and Machine Learning is becoming pervasive day by\nday which is opening doors to new opportunities in every aspect of technology.\nIts application Ranges from Health-care to Self-driving Cars, Home Automation\nto Smart-agriculture, and Industry 4.0. Traditionally the majority of the\nprocessing for IoT applications is being done on a central cloud but that has\nits issues; which include latency, security, bandwidth, and privacy, etc. It is\nestimated that there will be around 20 Million IoT devices by 2020 which will\nincrease problems with sending data to the cloud and doing the processing\nthere. A new trend of processing the data on the edge of the network is\nemerging. The idea is to do processing as near the point of data production as\npossible. Doing processing on the nodes generating the data is called Edge\nComputing and doing processing on a layer between the cloud and the point of\ndata production is called Fog computing. There are no standard definitions for\nany of these, hence they are usually used interchangeably. In this paper, we\nhave reviewed the development boards available for running Artificial\nIntelligence algorithms on the Edge\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 03:34:05 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Imran", "Hamza Ali", ""], ["Mujahid", "Usama", ""], ["Wazir", "Saad", ""], ["Latif", "Usama", ""], ["Mehmood", "Kiran", ""]]}, {"id": "2009.00814", "submitter": "Rui Shao", "authors": "Rui Shao and Pramuditha Perera and Pong C. Yuen and Vishal M. Patel", "title": "Open-set Adversarial Defense", "comments": "Accepted by ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-set recognition and adversarial defense study two key aspects of deep\nlearning that are vital for real-world deployment. The objective of open-set\nrecognition is to identify samples from open-set classes during testing, while\nadversarial defense aims to defend the network against images with\nimperceptible adversarial perturbations. In this paper, we show that open-set\nrecognition systems are vulnerable to adversarial attacks. Furthermore, we show\nthat adversarial defense mechanisms trained on known classes do not generalize\nwell to open-set samples. Motivated by this observation, we emphasize the need\nof an Open-Set Adversarial Defense (OSAD) mechanism. This paper proposes an\nOpen-Set Defense Network (OSDN) as a solution to the OSAD problem. The proposed\nnetwork uses an encoder with feature-denoising layers coupled with a classifier\nto learn a noise-free latent feature representation. Two techniques are\nemployed to obtain an informative latent feature space with the objective of\nimproving open-set performance. First, a decoder is used to ensure that clean\nimages can be reconstructed from the obtained latent features. Then,\nself-supervision is used to ensure that the latent features are informative\nenough to carry out an auxiliary task. We introduce a testing protocol to\nevaluate OSAD performance and show the effectiveness of the proposed method in\nmultiple object classification datasets. The implementation code of the\nproposed method is available at: https://github.com/rshaojimmy/ECCV2020-OSAD.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 04:35:33 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Shao", "Rui", ""], ["Perera", "Pramuditha", ""], ["Yuen", "Pong C.", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2009.00821", "submitter": "Meet Gandhi Mr", "authors": "Meet Gandhi, Atreyee Kundu, Shalabh Bhatnagar", "title": "A reinforcement learning approach to hybrid control design", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we design hybrid control policies for hybrid systems whose\nmathematical models are unknown. Our contributions are threefold. First, we\npropose a framework for modelling the hybrid control design problem as a single\nMarkov Decision Process (MDP). This result facilitates the application of\noff-the-shelf algorithms from Reinforcement Learning (RL) literature towards\ndesigning optimal control policies. Second, we model a set of benchmark\nexamples of hybrid control design problem in the proposed MDP framework. Third,\nwe adapt the recently proposed Proximal Policy Optimisation (PPO) algorithm for\nthe hybrid action space and apply it to the above set of problems. It is\nobserved that in each case the algorithm converges and finds the optimal\npolicy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:06:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Gandhi", "Meet", ""], ["Kundu", "Atreyee", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "2009.00822", "submitter": "Vikas Singh", "authors": "Vikas Singh, Homanga Bharadhwaj, Nishchal K Verma", "title": "A Bayesian Approach with Type-2 Student-tMembership Function for T-S\n  Model Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering techniques have been proved highly suc-cessful for Takagi-Sugeno\n(T-S) fuzzy model identification. Inparticular, fuzzyc-regression clustering\nbased on type-2 fuzzyset has been shown the remarkable results on non-sparse\ndatabut their performance degraded on sparse data. In this paper, aninnovative\narchitecture for fuzzyc-regression model is presentedand a novel\nstudent-tdistribution based membership functionis designed for sparse data\nmodelling. To avoid the overfitting,we have adopted a Bayesian approach for\nincorporating aGaussian prior on the regression coefficients. Additional\nnoveltyof our approach lies in type-reduction where the final output iscomputed\nusing Karnik Mendel algorithm and the consequentparameters of the model are\noptimized using Stochastic GradientDescent method. As detailed experimentation,\nthe result showsthat proposed approach outperforms on standard datasets\nincomparison of various state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:10:13 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Singh", "Vikas", ""], ["Bharadhwaj", "Homanga", ""], ["Verma", "Nishchal K", ""]]}, {"id": "2009.00829", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Wesley Cheung, William Broniec, Mark O. Riedl", "title": "Automated Storytelling via Causal, Commonsense Plot Ordering", "comments": "AAAI-21 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated story plot generation is the task of generating a coherent sequence\nof plot events. Causal relations between plot events are believed to increase\nthe perception of story and plot coherence. In this work, we introduce the\nconcept of soft causal relations as causal relations inferred from commonsense\nreasoning. We demonstrate C2PO, an approach to narrative generation that\noperationalizes this concept through Causal, Commonsense Plot Ordering. Using\nhuman-participant protocols, we evaluate our system against baseline systems\nwith different commonsense reasoning reasoning and inductive biases to\ndetermine the role of soft causal relations in perceived story quality. Through\nthese studies we also probe the interplay of how changes in commonsense norms\nacross storytelling genres affect perceptions of story quality.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:37:03 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 18:39:22 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Cheung", "Wesley", ""], ["Broniec", "William", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2009.00859", "submitter": "Ishani Mondal", "authors": "Ishani Mondal and Debasis Ganguly", "title": "ALEX: Active Learning based Enhancement of a Model's Explainability", "comments": "CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An active learning (AL) algorithm seeks to construct an effective classifier\nwith a minimal number of labeled examples in a bootstrapping manner. While\nstandard AL heuristics, such as selecting those points for annotation for which\na classification model yields least confident predictions, there has been no\nempirical investigation to see if these heuristics lead to models that are more\ninterpretable to humans. In the era of data-driven learning, this is an\nimportant research direction to pursue. This paper describes our\nwork-in-progress towards developing an AL selection function that in addition\nto model effectiveness also seeks to improve on the interpretability of a model\nduring the bootstrapping steps. Concretely speaking, our proposed selection\nfunction trains an `explainer' model in addition to the classifier model, and\nfavours those instances where a different part of the data is used, on an\naverage, to explain the predicted class. Initial experiments exhibited\nencouraging trends in showing that such a heuristic can lead to developing more\neffective and more explainable end-to-end data-driven classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 07:15:39 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mondal", "Ishani", ""], ["Ganguly", "Debasis", ""]]}, {"id": "2009.00901", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Lijie Wang, Ke Sun, Xinyan Xiao", "title": "A Practical Chinese Dependency Parser Based on A Large-scale Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing is a longstanding natural language processing task, with\nits outputs crucial to various downstream tasks. Recently, neural network based\n(NN-based) dependency parsing has achieved significant progress and obtained\nthe state-of-the-art results. As we all know, NN-based approaches require\nmassive amounts of labeled training data, which is very expensive because it\nrequires human annotation by experts. Thus few industrial-oriented dependency\nparser tools are publicly available. In this report, we present Baidu\nDependency Parser (DDParser), a new Chinese dependency parser trained on a\nlarge-scale manually labeled dataset called Baidu Chinese Treebank (DuCTB).\nDuCTB consists of about one million annotated sentences from multiple sources\nincluding search logs, Chinese newswire, various forum discourses, and\nconversation programs. DDParser is extended on the graph-based biaffine parser\nto accommodate to the characteristics of Chinese dataset. We conduct\nexperiments on two test sets: the standard test set with the same distribution\nas the training set and the random test set sampled from other sources, and the\nlabeled attachment scores (LAS) of them are 92.9% and 86.9% respectively.\nDDParser achieves the state-of-the-art results, and is released at\nhttps://github.com/baidu/DDParser.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 08:41:46 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 02:42:29 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhang", "Shuai", ""], ["Wang", "Lijie", ""], ["Sun", "Ke", ""], ["Xiao", "Xinyan", ""]]}, {"id": "2009.00914", "submitter": "Manish Pandey", "authors": "Sina J. Semnani, Manish Pandey", "title": "Revisiting the Open-Domain Question Answering Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering (QA) is the tasl of identifying answers to\nnatural questions from a large corpus of documents. The typical open-domain QA\nsystem starts with information retrieval to select a subset of documents from\nthe corpus, which are then processed by a machine reader to select the answer\nspans. This paper describes Mindstone, an open-domain QA system that consists\nof a new multi-stage pipeline that employs a traditional BM25-based information\nretriever, RM3-based neural relevance feedback, neural ranker, and a machine\nreading comprehension stage. This paper establishes a new baseline for\nend-to-end performance on question answering for Wikipedia/SQuAD dataset\n(EM=58.1, F1=65.8), with substantial gains over the previous state of the art\n(Yang et al., 2019b). We also show how the new pipeline enables the use of\nlow-resolution labels, and can be easily tuned to meet various timing\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:34:14 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Semnani", "Sina J.", ""], ["Pandey", "Manish", ""]]}, {"id": "2009.00919", "submitter": "Matthias De Lange", "authors": "Matthias De Lange, Tinne Tuytelaars", "title": "Continual Prototype Evolution: Learning Online from Non-Stationary Data\n  Streams", "comments": "10 pages, code publicly available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attaining prototypical features to represent class distributions is well\nestablished in representation learning. However, learning prototypes online\nfrom streaming data proves a challenging endeavor as they rapidly become\noutdated, caused by an ever-changing parameter space during the learning\nprocess. Additionally, continual learning does not assume the data stream to be\nstationary, typically resulting in catastrophic forgetting of previous\nknowledge. As a first, we introduce a system addressing both problems, where\nprototypes evolve continually in a shared latent space, enabling learning and\nprediction at any point in time. In contrast to the major body of work in\ncontinual learning, data streams are processed in an online fashion, without\nadditional task-information, and an efficient memory scheme provides robustness\nto imbalanced data streams. Besides nearest neighbor based prediction, learning\nis facilitated by a novel objective function, encouraging cluster density about\nthe class prototype and increased inter-class variance. Furthermore, the latent\nspace quality is elevated by pseudo-prototypes in each batch, constituted by\nreplay of exemplars from memory. As an additional contribution, we generalize\nthe existing paradigms in continual learning to incorporate data incremental\nlearning from data streams by formalizing a two-agent learner-evaluator\nframework. We obtain state-of-the-art performance by a significant margin on\neight benchmarks, including three highly imbalanced data streams.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:39:26 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 14:21:18 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 09:22:40 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 10:40:42 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["De Lange", "Matthias", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "2009.00964", "submitter": "Laura Giordano", "authors": "Laura Giordano, Daniele Theseider Dupr\\'e", "title": "A framework for a modular multi-concept lexicographic closure semantics", "comments": "18 pages. Accepted for presentation at NMR2020 (18th International\n  Workshop on Non-Monotonic Reasoning, September 12th - 14th - Rhodes, Greece", "journal-ref": null, "doi": null, "report-no": "TR-INF-2020-09-03-UNIPMN", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a modular multi-concept extension of the lexicographic closure\nsemantics for defeasible description logics with typicality. The idea is that\nof distributing the defeasible properties of concepts into different modules,\naccording to their subject, and of defining a notion of preference for each\nmodule based on the lexicographic closure semantics. The preferential semantics\nof the knowledge base can then be defined as a combination of the preferences\nof the single modules. The range of possibilities, from fine grained to coarse\ngrained modules, provides a spectrum of alternative semantics.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:41:38 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 05:19:53 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Giordano", "Laura", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2009.01027", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Xiaoxing Wang, Bo Zhang, Shun Lu, Xiaolin Wei, Junchi\n  Yan", "title": "DARTS-: Robustly Stepping out of Performance Collapse Without Indicators", "comments": "Accepted to ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fast development of differentiable architecture search (DARTS),\nit suffers from long-standing performance instability, which extremely limits\nits application. Existing robustifying methods draw clues from the resulting\ndeteriorated behavior instead of finding out its causing factor. Various\nindicators such as Hessian eigenvalues are proposed as a signal to stop\nsearching before the performance collapses. However, these indicator-based\nmethods tend to easily reject good architectures if the thresholds are\ninappropriately set, let alone the searching is intrinsically noisy. In this\npaper, we undertake a more subtle and direct approach to resolve the collapse.\nWe first demonstrate that skip connections have a clear advantage over other\ncandidate operations, where it can easily recover from a disadvantageous state\nand become dominant. We conjecture that this privilege is causing degenerated\nperformance. Therefore, we propose to factor out this benefit with an auxiliary\nskip connection, ensuring a fairer competition for all operations. We call this\napproach DARTS-. Extensive experiments on various datasets verify that it can\nsubstantially improve robustness. Our code is available at\nhttps://github.com/Meituan-AutoML/DARTS- .\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:54:13 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 07:58:11 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Wang", "Xiaoxing", ""], ["Zhang", "Bo", ""], ["Lu", "Shun", ""], ["Wei", "Xiaolin", ""], ["Yan", "Junchi", ""]]}, {"id": "2009.01067", "submitter": "Jingyi Hou", "authors": "Jingyi Hou, Yunde Jia, Xinxiao wu, Yayun Qi", "title": "Video Captioning Using Weak Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video captioning has shown impressive progress in recent years. One key\nreason of the performance improvements made by existing methods lie in massive\npaired video-sentence data, but collecting such strong annotation, i.e.,\nhigh-quality sentences, is time-consuming and laborious. It is the fact that\nthere now exist an amazing number of videos with weak annotation that only\ncontains semantic concepts such as actions and objects. In this paper, we\ninvestigate using weak annotation instead of strong annotation to train a video\ncaptioning model. To this end, we propose a progressive visual reasoning method\nthat progressively generates fine sentences from weak annotations by inferring\nmore semantic concepts and their dependency relationships for video captioning.\nTo model concept relationships, we use dependency trees that are spanned by\nexploiting external knowledge from large sentence corpora. Through traversing\nthe dependency trees, the sentences are generated to train the captioning\nmodel. Accordingly, we develop an iterative refinement algorithm that refines\nsentences via spanning dependency trees and fine-tunes the captioning model\nusing the refined sentences in an alternative training manner. Experimental\nresults demonstrate that our method using weak annotation is very competitive\nto the state-of-the-art methods using strong annotation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:45:01 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Hou", "Jingyi", ""], ["Jia", "Yunde", ""], ["wu", "Xinxiao", ""], ["Qi", "Yayun", ""]]}, {"id": "2009.01076", "submitter": "Simon Jaxy", "authors": "Simon Jaxy", "title": "Teaching a Machine to Diagnose a Heart Disease; Beginning from\n  digitizing scanned ECGs to detecting the Brugada Syndrome (BrS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical diagnoses can shape and change the life of a person drastically.\nTherefore, it is always best advised to collect as much evidence as possible to\nbe certain about the diagnosis. Unfortunately, in the case of the Brugada\nSyndrome (BrS), a rare and inherited heart disease, only one diagnostic\ncriterion exists, namely, a typical pattern in the Electrocardiogram (ECG). In\nthe following treatise, we question whether the investigation of ECG strips by\nthe means of machine learning methods improves the detection of BrS positive\ncases and hence, the diagnostic process. We propose a pipeline that reads in\nscanned images of ECGs, and transforms the encaptured signals to digital\ntime-voltage data after several processing steps. Then, we present a long\nshort-term memory (LSTM) classifier that is built based on the previously\nextracted data and that makes the diagnosis. The proposed pipeline\ndistinguishes between three major types of ECG images and recreates each\nrecorded lead signal. Features and quality are retained during the digitization\nof the data, albeit some encountered issues are not fully removed (Part I).\nNevertheless, the results of the aforesaid program are suitable for further\ninvestigation of the ECG by a computational method such as the proposed\nclassifier which proves the concept and could be the architectural basis for\nfuture research (Part II). This thesis is divided into two parts as they are\npart of the same process but conceptually different. It is hoped that this work\nbuilds a new foundation for computational investigations in the case of the BrS\nand its diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:12:50 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Jaxy", "Simon", ""]]}, {"id": "2009.01110", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Bingli Liao, Takahiro Kanzaki", "title": "Perceptual Deep Neural Networks: Adversarial Robustness through Input\n  Recreation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have shown that albeit highly accurate, models learned\nby machines, differently from humans, have many weaknesses. However, humans'\nperception is also fundamentally different from machines, because we do not see\nthe signals which arrive at the retina but a rather complex recreation of them.\nIn this paper, we explore how machines could recreate the input as well as\ninvestigate the benefits of such an augmented perception. In this regard, we\npropose Perceptual Deep Neural Networks ($\\varphi$DNN) which also recreate\ntheir own input before further processing. The concept is formalized\nmathematically and two variations of it are developed (one based on inpainting\nthe whole image and the other based on a noisy resized super resolution\nrecreation). Experiments reveal that $\\varphi$DNNs and their adversarial\ntraining variations can increase the robustness substantially, surpassing both\nstate-of-the-art defenses and pre-processing types of defenses in 100% of the\ntests. $\\varphi$DNNs are shown to scale well to bigger image sizes, keeping a\nsimilar high accuracy throughout; while the state-of-the-art worsen up to 35%.\nMoreover, the recreation process intentionally corrupts the input image.\nInterestingly, we show by ablation tests that corrupting the input is, although\ncounter-intuitive, beneficial. Thus, $\\varphi$DNNs reveal that input recreation\nhas strong benefits for artificial neural networks similar to biological ones,\nshedding light into the importance of purposely corrupting the input as well as\npioneering an area of perception models based on GANs and autoencoders for\nrobust recognition in artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:36:36 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 09:39:09 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 08:58:13 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 10:36:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Liao", "Bingli", ""], ["Kanzaki", "Takahiro", ""]]}, {"id": "2009.01119", "submitter": "Tilo Wiklund", "authors": "Juozas Vaicenavicius and Tilo Wiklund and Aust\\.e Grigait\\.e and\n  Antanas Kalkauskas and Ignas Vysniauskas and Steven Keen", "title": "Self-driving car safety quantification via component-level analysis", "comments": "Various minor linguistic, typographical, and notational improvements.\n  To appear in the SAE International Journal of Connected and Automated\n  Vehicles, 4(1):2021, doi:10.4271/12-04-01-0004", "journal-ref": "SAE Intl. J CAV 4(1):35-45, 2021", "doi": "10.4271/12-04-01-0004", "report-no": null, "categories": "stat.AP cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a rigorous modular statistical approach for arguing\nsafety or its insufficiency of an autonomous vehicle through a concrete\nillustrative example. The methodology relies on making appropriate quantitative\nstudies of the performance of constituent components. We explain the importance\nof sufficient and necessary conditions at the component level for the overall\nsafety of the vehicle as well as the cost-saving benefits of the approach. A\nsimple concrete automated braking example studied illustrates how separate\nperception system and operational design domain statistical analyses can be\nused to prove or disprove safety at the vehicle level.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 14:51:19 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 11:27:11 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 12:08:48 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 14:52:46 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Vaicenavicius", "Juozas", ""], ["Wiklund", "Tilo", ""], ["Grigait\u0117", "Aust\u0117", ""], ["Kalkauskas", "Antanas", ""], ["Vysniauskas", "Ignas", ""], ["Keen", "Steven", ""]]}, {"id": "2009.01168", "submitter": "Elizabeth Ricci", "authors": "Elizabeth A. Ricci, Madeleine Udell, Ross A. Knepper", "title": "An Information-Theoretic Approach to Persistent Environment Monitoring\n  Through Low Rank Model Based Planning and Prediction", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots can be used to collect environmental data in regions that are\ndifficult for humans to traverse. However, limitations remain in the size of\nregion that a robot can directly observe per unit time. We introduce a method\nfor selecting a limited number of observation points in a large region, from\nwhich we can predict the state of unobserved points in the region. We combine a\nlow rank model of a target attribute with an information-maximizing path\nplanner to predict the state of the attribute throughout a region. Our approach\nis agnostic to the choice of target attribute and robot monitoring platform. We\nevaluate our method in simulation on two real-world environment datasets, each\ncontaining observations from one to two million possible sampling locations. We\ncompare against a random sampler and four variations of a baseline sampler from\nthe ecology literature. Our method outperforms the baselines in terms of\naverage Fisher information gain per samples taken and performs comparably for\naverage reconstruction error in most trials.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:19:55 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Ricci", "Elizabeth A.", ""], ["Udell", "Madeleine", ""], ["Knepper", "Ross A.", ""]]}, {"id": "2009.01181", "submitter": "Sagar Kora Venu", "authors": "Sagar Kora Venu", "title": "Evaluation of Deep Convolutional Generative Adversarial Networks for\n  data augmentation of chest X-ray images", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.3390/fi13010008", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Medical image datasets are usually imbalanced, due to the high costs of\nobtaining the data and time-consuming annotations. Training deep neural network\nmodels on such datasets to accurately classify the medical condition does not\nyield desired results and often over-fits the data on majority class samples.\nIn order to address this issue, data augmentation is often performed on\ntraining data by position augmentation techniques such as scaling, cropping,\nflipping, padding, rotation, translation, affine transformation, and color\naugmentation techniques such as brightness, contrast, saturation, and hue to\nincrease the dataset sizes. These augmentation techniques are not guaranteed to\nbe advantageous in domains with limited data, especially medical image data,\nand could lead to further overfitting. In this work, we performed data\naugmentation on the Chest X-rays dataset through generative modeling (deep\nconvolutional generative adversarial network) which creates artificial\ninstances retaining similar characteristics to the original data and evaluation\nof the model resulted in Fr\\'echet Distance of Inception (FID) score of 1.289.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:43:55 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Venu", "Sagar Kora", ""]]}, {"id": "2009.01196", "submitter": "Marcus Pereira", "authors": "Marcus Aloysius Pereira and Ziyi Wang and Ioannis Exarchos and\n  Evangelos A. Theodorou", "title": "Safe Optimal Control Using Stochastic Barrier Functions and Deep\n  Forward-Backward SDEs", "comments": null, "journal-ref": "Conference on Robot Learning 2020", "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new formulation for stochastic optimal control and\nstochastic dynamic optimization that ensures safety with respect to state and\ncontrol constraints. The proposed methodology brings together concepts such as\nForward-Backward Stochastic Differential Equations, Stochastic Barrier\nFunctions, Differentiable Convex Optimization and Deep Learning. Using the\naforementioned concepts, a Neural Network architecture is designed for safe\ntrajectory optimization in which learning can be performed in an end-to-end\nfashion. Simulations are performed on three systems to show the efficacy of the\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:10:07 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Pereira", "Marcus Aloysius", ""], ["Wang", "Ziyi", ""], ["Exarchos", "Ioannis", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2009.01197", "submitter": "Rafael Melo", "authors": "Willian C. S. Martinho, Rafael A. Melo, Kenneth S\\\"orensen", "title": "An enhanced simulation-based iterated local search metaheuristic for\n  gravity fed water distribution network design optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gravity fed water distribution network design (WDND) optimization problem\nconsists in determining the pipe diameters of a water network such that\nhydraulic constraints are satisfied and the total cost is minimized.\nTraditionally, such design decisions are made on the basis of expert\nexperience. When networks increase in size, however, rules of thumb will rarely\nlead to near optimal decisions. Over the past thirty years, a large number of\ntechniques have been developed to tackle the problem of optimally designing a\nwater distribution network. In this paper, we tackle the NP-hard water\ndistribution network design (WDND) optimization problem in a multi-period\nsetting where time varying demand patterns occur. We propose a new\nsimulation-based iterated local search metaheuristic which further explores the\nstructure of the problem in an attempt to obtain high quality solutions.\nComputational experiments show that our approach is very competitive as it is\nable to improve over a state-of-the-art metaheuristic for most of the performed\ntests. Furthermore, it converges much faster to low cost solutions and\ndemonstrates a more robust performance in that it obtains smaller deviations\nfrom the best known solutions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:12:46 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 11:29:27 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 10:38:52 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Martinho", "Willian C. S.", ""], ["Melo", "Rafael A.", ""], ["S\u00f6rensen", "Kenneth", ""]]}, {"id": "2009.01210", "submitter": "Biswanath Dutta Dr.", "authors": "B. Dutta, M. DeBellis", "title": "CODO: An Ontology for Collection and Analysis of Covid-19 Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COviD-19 Ontology for cases and patient information (CODO) provides a\nmodel for the collection and analysis of data about the COVID-19 pandemic. The\nontology provides a standards-based open-source model that facilitates the\nintegration of data from heterogeneous data sources. The ontology was designed\nby analysing disparate COVID-19 data sources such as datasets, literature,\nservices, etc. The ontology follows the best practices for vocabularies by\nre-using concepts from other leading vocabularies and by using the W3C\nstandards RDF, OWL, SWRL, and SPARQL. The ontology already has one independent\nuser and has incorporated real-world data from the government of India.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:32:37 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Dutta", "B.", ""], ["DeBellis", "M.", ""]]}, {"id": "2009.01215", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "Excavating \"Excavating AI\": The Elephant in the Gallery", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": "10.5281/zenodo.4037538", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two art exhibitions, \"Training Humans\" and \"Making Faces,\" and the\naccompanying essay \"Excavating AI: The politics of images in machine learning\ntraining sets\" by Kate Crawford and Trevor Paglen, are making substantial\nimpact on discourse taking place in the social and mass media networks, and\nsome scholarly circles. Critical scrutiny reveals, however, a\nself-contradictory stance regarding informed consent for the use of facial\nimages, as well as serious flaws in their critique of ML training sets. Our\nanalysis underlines the non-negotiability of informed consent when using human\ndata in artistic and other contexts, and clarifies issues relating to the\ndescription of ML training sets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:42:06 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 17:07:10 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 01:27:53 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2009.01270", "submitter": "Amogh Gudi", "authors": "Amogh Gudi, Xin Li, Jan van Gemert", "title": "Efficiency in Real-time Webcam Gaze Tracking", "comments": "Awarded Best Paper at European Conference on Computer Vision (ECCV)\n  Workshop on Eye Gaze in AR, VR, and in the Wild (OpenEyes) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency and ease of use are essential for practical applications of camera\nbased eye/gaze-tracking. Gaze tracking involves estimating where a person is\nlooking on a screen based on face images from a computer-facing camera. In this\npaper we investigate two complementary forms of efficiency in gaze tracking: 1.\nThe computational efficiency of the system which is dominated by the inference\nspeed of a CNN predicting gaze-vectors; 2. The usability efficiency which is\ndetermined by the tediousness of the mandatory calibration of the gaze-vector\nto a computer screen. To do so, we evaluate the computational speed/accuracy\ntrade-off for the CNN and the calibration effort/accuracy trade-off for screen\ncalibration. For the CNN, we evaluate the full face, two-eyes, and single eye\ninput. For screen calibration, we measure the number of calibration points\nneeded and evaluate three types of calibration: 1. pure geometry, 2. pure\nmachine learning, and 3. hybrid geometric regression. Results suggest that a\nsingle eye input and geometric regression calibration achieve the best\ntrade-off.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:07:41 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gudi", "Amogh", ""], ["Li", "Xin", ""], ["van Gemert", "Jan", ""]]}, {"id": "2009.01309", "submitter": "Jordi Luque", "authors": "Guillermo C\\'ambara, Jordi Luque and Mireia Farr\\'us", "title": "Convolutional Speech Recognition with Pitch and Voice Quality Features", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effects of adding pitch and voice quality features such as jitter and\nshimmer to a state-of-the-art CNN model for Automatic Speech Recognition are\nstudied in this work. Pitch features have been previously used for improving\nclassical HMM and DNN baselines, while jitter and shimmer parameters have\nproven to be useful for tasks like speaker or emotion recognition. Up to our\nknowledge, this is the first work combining such pitch and voice quality\nfeatures with modern convolutional architectures, showing improvements up to 7%\nand 3% relative WER points, for the publicly available Spanish Common Voice and\nLibriSpeech 100h datasets, respectively. Particularly, our work combines these\nfeatures with mel-frequency spectral coefficients (MFSCs) to train a\nconvolutional architecture with Gated Linear Units (Conv GLUs). Such models\nhave shown to yield small word error rates, while being very suitable for\nparallel processing for online streaming recognition use cases. We have added\npitch and voice quality functionality to Facebook's wav2letter speech\nrecognition framework, and we provide with such code and recipes to the\ncommunity, to carry on with further experiments. Besides, to the best of our\nknowledge, our Spanish Common Voice recipe is the first public Spanish recipe\nfor wav2letter.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:25:50 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 11:37:09 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["C\u00e1mbara", "Guillermo", ""], ["Luque", "Jordi", ""], ["Farr\u00fas", "Mireia", ""]]}, {"id": "2009.01325", "submitter": "Ryan Lowe T.", "authors": "Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,\n  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano", "title": "Learning to summarize from human feedback", "comments": "NeurIPS 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As language models become more powerful, training and evaluation are\nincreasingly bottlenecked by the data and metrics used for a particular task.\nFor example, summarization models are often trained to predict human reference\nsummaries and evaluated using ROUGE, but both of these metrics are rough\nproxies for what we really care about---summary quality. In this work, we show\nthat it is possible to significantly improve summary quality by training a\nmodel to optimize for human preferences. We collect a large, high-quality\ndataset of human comparisons between summaries, train a model to predict the\nhuman-preferred summary, and use that model as a reward function to fine-tune a\nsummarization policy using reinforcement learning. We apply our method to a\nversion of the TL;DR dataset of Reddit posts and find that our models\nsignificantly outperform both human reference summaries and much larger models\nfine-tuned with supervised learning alone. Our models also transfer to CNN/DM\nnews articles, producing summaries nearly as good as the human reference\nwithout any news-specific fine-tuning. We conduct extensive analyses to\nunderstand our human feedback dataset and fine-tuned models We establish that\nour reward model generalizes to new datasets, and that optimizing our reward\nmodel results in better summaries than optimizing ROUGE according to humans. We\nhope the evidence from our paper motivates machine learning researchers to pay\ncloser attention to how their training loss affects the model behavior they\nactually want.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:54:41 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 22:19:53 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Stiennon", "Nisan", ""], ["Ouyang", "Long", ""], ["Wu", "Jeff", ""], ["Ziegler", "Daniel M.", ""], ["Lowe", "Ryan", ""], ["Voss", "Chelsea", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""]]}, {"id": "2009.01438", "submitter": "Lei Zhang", "authors": "Lei Zhang and Zhenwei He and Yi Yang and Liang Wang and Xinbo Gao", "title": "Tasks Integrated Networks: Joint Detection and Retrieval for Image\n  Search", "comments": "To appear in IEEE TPAMI, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional object retrieval task aims to learn a discriminative feature\nrepresentation with intra-similarity and inter-dissimilarity, which supposes\nthat the objects in an image are manually or automatically pre-cropped exactly.\nHowever, in many real-world searching scenarios (e.g., video surveillance), the\nobjects (e.g., persons, vehicles, etc.) are seldom accurately detected or\nannotated. Therefore, object-level retrieval becomes intractable without\nbounding-box annotation, which leads to a new but challenging topic, i.e.\nimage-level search. In this paper, to address the image search issue, we first\nintroduce an end-to-end Integrated Net (I-Net), which has three merits: 1) A\nSiamese architecture and an on-line pairing strategy for similar and dissimilar\nobjects in the given images are designed. 2) A novel on-line pairing (OLP) loss\nis introduced with a dynamic feature dictionary, which alleviates the\nmulti-task training stagnation problem, by automatically generating a number of\nnegative pairs to restrict the positives. 3) A hard example priority (HEP)\nbased softmax loss is proposed to improve the robustness of classification task\nby selecting hard categories. With the philosophy of divide and conquer, we\nfurther propose an improved I-Net, called DC-I-Net, which makes two new\ncontributions: 1) two modules are tailored to handle different tasks separately\nin the integrated framework, such that the task specification is guaranteed. 2)\nA class-center guided HEP loss (C2HEP) by exploiting the stored class centers\nis proposed, such that the intra-similarity and inter-dissimilarity can be\ncaptured for ultimate retrieval. Extensive experiments on famous image-level\nsearch oriented benchmark datasets demonstrate that the proposed DC-I-Net\noutperforms the state-of-the-art tasks-integrated and tasks-separated image\nsearch models.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 03:57:50 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhang", "Lei", ""], ["He", "Zhenwei", ""], ["Yang", "Yi", ""], ["Wang", "Liang", ""], ["Gao", "Xinbo", ""]]}, {"id": "2009.01440", "submitter": "Zhang Jian", "authors": "Bin Huang, Yuanyang Du, Shuai Zhang, Wenfei Li, Jun Wang, Jian Zhang", "title": "Computational prediction of RNA tertiary structures using machine\n  learning methods", "comments": "20 pages, 2 figures. Chinese Physics B, Aug. 2020", "journal-ref": "Chinese Physics B, Sept. 2020", "doi": "10.1088/1674-1056/abb303", "report-no": null, "categories": "physics.bio-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RNAs play crucial and versatile roles in biological processes. Computational\nprediction approaches can help to understand RNA structures and their\nstabilizing factors, thus providing information on their functions, and\nfacilitating the design of new RNAs. Machine learning (ML) techniques have made\ntremendous progress in many fields in the past few years. Although their usage\nin protein-related fields has a long history, the use of ML methods in\npredicting RNA tertiary structures is new and rare. Here, we review the recent\nadvances of using ML methods on RNA structure predictions and discuss the\nadvantages and limitation, the difficulties and potentials of these approaches\nwhen applied in the field.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 04:01:43 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Huang", "Bin", ""], ["Du", "Yuanyang", ""], ["Zhang", "Shuai", ""], ["Li", "Wenfei", ""], ["Wang", "Jun", ""], ["Zhang", "Jian", ""]]}, {"id": "2009.01442", "submitter": "Srinivasan Ravichandran", "authors": "Srinivasan Ravichandran, Drona Khurana, Bharath Venkatesh, Narayanan\n  Unny Edakunni", "title": "FairXGBoost: Fairness-aware Classification in XGBoost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly regulated domains such as finance have long favoured the use of\nmachine learning algorithms that are scalable, transparent, robust and yield\nbetter performance. One of the most prominent examples of such an algorithm is\nXGBoost. Meanwhile, there is also a growing interest in building fair and\nunbiased models in these regulated domains and numerous bias-mitigation\nalgorithms have been proposed to this end. However, most of these\nbias-mitigation methods are restricted to specific model families such as\nlogistic regression or support vector machine models, thus leaving modelers\nwith a difficult decision of choosing between fairness from the bias-mitigation\nalgorithms and scalability, transparency, performance from algorithms such as\nXGBoost. We aim to leverage the best of both worlds by proposing a fair variant\nof XGBoost that enjoys all the advantages of XGBoost, while also matching the\nlevels of fairness from the state-of-the-art bias-mitigation algorithms.\nFurthermore, the proposed solution requires very little in terms of changes to\nthe original XGBoost library, thus making it easy for adoption. We provide an\nempirical analysis of our proposed method on standard benchmark datasets used\nin the fairness community.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 04:08:23 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 05:14:38 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ravichandran", "Srinivasan", ""], ["Khurana", "Drona", ""], ["Venkatesh", "Bharath", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2009.01449", "submitter": "Long Chen", "authors": "Long Chen, Wenbo Ma, Jun Xiao, Hanwang Zhang, Shih-Fu Chang", "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression\n  Grounding", "comments": "Camera ready version at AAAI 2021, Codes are available at:\n  https://github.com/ChopinSharp/ref-nms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevailing framework for solving referring expression grounding is based\non a two-stage process: 1) detecting proposals with an object detector and 2)\ngrounding the referent to one of the proposals. Existing two-stage solutions\nmostly focus on the grounding step, which aims to align the expressions with\nthe proposals. In this paper, we argue that these methods overlook an obvious\nmismatch between the roles of proposals in the two stages: they generate\nproposals solely based on the detection confidence (i.e., expression-agnostic),\nhoping that the proposals contain all right instances in the expression (i.e.,\nexpression-aware). Due to this mismatch, current two-stage methods suffer from\na severe performance drop between detected and ground-truth proposals. To this\nend, we propose Ref-NMS, which is the first method to yield expression-aware\nproposals at the first stage. Ref-NMS regards all nouns in the expression as\ncritical objects, and introduces a lightweight module to predict a score for\naligning each box with a critical object. These scores can guide the NMS\noperation to filter out the boxes irrelevant to the expression, increasing the\nrecall of critical objects, resulting in a significantly improved grounding\nperformance. Since Ref- NMS is agnostic to the grounding step, it can be easily\nintegrated into any state-of-the-art two-stage method. Extensive ablation\nstudies on several backbones, benchmarks, and tasks consistently demonstrate\nthe superiority of Ref-NMS. Codes are available at:\nhttps://github.com/ChopinSharp/ref-nms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:04:12 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:19:22 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:25:59 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chen", "Long", ""], ["Ma", "Wenbo", ""], ["Xiao", "Jun", ""], ["Zhang", "Hanwang", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2009.01453", "submitter": "Zhaoqing Peng", "authors": "Zhaoqing Peng, Junqi Jin, Lan Luo, Yaodong Yang, Rui Luo, Jun Wang,\n  Weinan Zhang, Haiyang Xu, Miao Xu, Chuan Yu, Tiejian Luo, Han Li, Jian Xu,\n  Kun Gai", "title": "Learning to Infer User Hidden States for Online Sequential Advertising", "comments": "to be published in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412721", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To drive purchase in online advertising, it is of the advertiser's great\ninterest to optimize the sequential advertising strategy whose performance and\ninterpretability are both important. The lack of interpretability in existing\ndeep reinforcement learning methods makes it not easy to understand, diagnose\nand further optimize the strategy. In this paper, we propose our Deep Intents\nSequential Advertising (DISA) method to address these issues. The key part of\ninterpretability is to understand a consumer's purchase intent which is,\nhowever, unobservable (called hidden states). In this paper, we model this\nintention as a latent variable and formulate the problem as a Partially\nObservable Markov Decision Process (POMDP) where the underlying intents are\ninferred based on the observable behaviors. Large-scale industrial offline and\nonline experiments demonstrate our method's superior performance over several\nbaselines. The inferred hidden states are analyzed, and the results prove the\nrationality of our inference.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:12:26 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Peng", "Zhaoqing", ""], ["Jin", "Junqi", ""], ["Luo", "Lan", ""], ["Yang", "Yaodong", ""], ["Luo", "Rui", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""], ["Xu", "Haiyang", ""], ["Xu", "Miao", ""], ["Yu", "Chuan", ""], ["Luo", "Tiejian", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "2009.01462", "submitter": "Qi Sun", "authors": "Qi Sun, Hexin Dong, Zewei Chen, Weizhen Dian, Jiacheng Sun, Yitong\n  Sun, Zhenguo Li, Bin Dong", "title": "A Practical Layer-Parallel Training Algorithm for Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based algorithms for training ResNets typically require a forward\npass of the input data, followed by back-propagating the objective gradient to\nupdate parameters, which are time-consuming for deep ResNets. To break the\ndependencies between modules in both the forward and backward modes,\nauxiliary-variable methods such as the penalty and augmented Lagrangian (AL)\napproaches have attracted much interest lately due to their ability to exploit\nlayer-wise parallelism. However, we observe that large communication overhead\nand lacking data augmentation are two key challenges of these methods, which\nmay lead to low speedup ratio and accuracy drop across multiple compute\ndevices. Inspired by the optimal control formulation of ResNets, we propose a\nnovel serial-parallel hybrid training strategy to enable the use of data\naugmentation, together with downsampling filters to reduce the communication\ncost. The proposed strategy first trains the network parameters by solving a\nsuccession of independent sub-problems in parallel and then corrects the\nnetwork parameters through a full serial forward-backward propagation of data.\nSuch a strategy can be applied to most of the existing layer-parallel training\nmethods using auxiliary variables. As an example, we validate the proposed\nstrategy using penalty and AL methods on ResNet and WideResNet across MNIST,\nCIFAR-10 and CIFAR-100 datasets, achieving significant speedup over the\ntraditional layer-serial training methods while maintaining comparable\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:03:30 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:25:56 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Sun", "Qi", ""], ["Dong", "Hexin", ""], ["Chen", "Zewei", ""], ["Dian", "Weizhen", ""], ["Sun", "Jiacheng", ""], ["Sun", "Yitong", ""], ["Li", "Zhenguo", ""], ["Dong", "Bin", ""]]}, {"id": "2009.01485", "submitter": "Pinkesh Badjatiya", "authors": "Surgan Jandial, Ayush Chopra, Pinkesh Badjatiya, Pranit Chawla,\n  Mausoom Sarkar, Balaji Krishnamurthy", "title": "TRACE: Transform Aggregate and Compose Visiolinguistic Representations\n  for Image Search with Text Feedback", "comments": "Surgan Jandial, Ayush Chopra and Pinkesh Badjatiya contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to efficiently search for images over an indexed database is the\ncornerstone for several user experiences. Incorporating user feedback, through\nmulti-modal inputs provide flexible and interaction to serve fine-grained\nspecificity in requirements. We specifically focus on text feedback, through\ndescriptive natural language queries. Given a reference image and textual user\nfeedback, our goal is to retrieve images that satisfy constraints specified by\nboth of these input modalities. The task is challenging as it requires\nunderstanding the textual semantics from the text feedback and then applying\nthese changes to the visual representation. To address these challenges, we\npropose a novel architecture TRACE which contains a hierarchical feature\naggregation module to learn the composite visio-linguistic representations.\nTRACE achieves the SOTA performance on 3 benchmark datasets: FashionIQ, Shoes,\nand Birds-to-Words, with an average improvement of at least ~5.7%, ~3%, and ~5%\nrespectively in R@K metric. Our extensive experiments and ablation studies show\nthat TRACE consistently outperforms the existing techniques by significant\nmargins both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 06:55:23 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Jandial", "Surgan", ""], ["Chopra", "Ayush", ""], ["Badjatiya", "Pinkesh", ""], ["Chawla", "Pranit", ""], ["Sarkar", "Mausoom", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2009.01509", "submitter": "Junrui Tian", "authors": "Junrui Tian, Zhiying Tu, Zhongjie Wang, Xiaofei Xu, Min Liu", "title": "User Intention Recognition and Requirement Elicitation Method for\n  Conversational AI Services", "comments": "accepted as a full paper at IEEE ICWS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, chat-bot has become a new type of intelligent terminal to\nguide users to consume services. However, it is criticized most that the\nservices it provides are not what users expect or most expect. This defect\nmostly dues to two problems, one is that the incompleteness and uncertainty of\nuser's requirement expression caused by the information asymmetry, the other is\nthat the diversity of service resources leads to the difficulty of service\nselection. Conversational bot is a typical mesh device, so the guided\nmulti-rounds Q$\\&$A is the most effective way to elicit user requirements.\nObviously, complex Q$\\&$A with too many rounds is boring and always leads to\nbad user experience. Therefore, we aim to obtain user requirements as\naccurately as possible in as few rounds as possible. To achieve this, a user\nintention recognition method based on Knowledge Graph (KG) was developed for\nfuzzy requirement inference, and a requirement elicitation method based on\nGranular Computing was proposed for dialog policy generation. Experimental\nresults show that these two methods can effectively reduce the number of\nconversation rounds, and can quickly and accurately identify the user\nintention.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 08:26:39 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Tian", "Junrui", ""], ["Tu", "Zhiying", ""], ["Wang", "Zhongjie", ""], ["Xu", "Xiaofei", ""], ["Liu", "Min", ""]]}, {"id": "2009.01534", "submitter": "Yossi Adi", "authors": "Shahar Segal, Yossi Adi, Benny Pinkas, Carsten Baum, Chaya Ganesh,\n  Joseph Keshet", "title": "Fairness in the Eyes of the Data: Certifying Machine-Learning Models", "comments": "Accepted to AIES-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows to certify the fairness degree of a model\nbased on an interactive and privacy-preserving test. The framework verifies any\ntrained model, regardless of its training process and architecture. Thus, it\nallows us to evaluate any deep learning model on multiple fairness definitions\nempirically. We tackle two scenarios, where either the test data is privately\navailable only to the tester or is publicly known in advance, even to the model\ncreator. We investigate the soundness of the proposed approach using\ntheoretical analysis and present statistical guarantees for the interactive\ntest. Finally, we provide a cryptographic technique to automate fairness\ntesting and certified inference with only black-box access to the model at hand\nwhile hiding the participants' sensitive data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 09:22:39 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 09:03:42 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 07:57:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Segal", "Shahar", ""], ["Adi", "Yossi", ""], ["Pinkas", "Benny", ""], ["Baum", "Carsten", ""], ["Ganesh", "Chaya", ""], ["Keshet", "Joseph", ""]]}, {"id": "2009.01606", "submitter": "Attila Egri-Nagy", "authors": "Attila Egri-Nagy and Antti T\\\"orm\\\"anen", "title": "Derived metrics for the game of Go -- intrinsic network strength\n  assessment and cheat-detection", "comments": "16 pages, 12 figures, accepted for CANDAR 2020, The Eighth\n  International Symposium on Computing and Networking, Naha, Okinawa, Japan,\n  November 24-27, 2020; final version will be published in IEEE Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread availability of superhuman AI engines is changing how we play\nthe ancient game of Go. The open-source software packages developed after the\nAlphaGo series shifted focus from producing strong playing entities to\nproviding tools for analyzing games. Here we describe two ways of how the\ninnovations of the second generation engines (e.g.~score estimates, variable\nkomi) can be used for defining new metrics that help deepen our understanding\nof the game. First, we study how much information the search component\ncontributes in addition to the raw neural network policy output. This gives an\nintrinsic strength measurement for the neural network. Second, we define the\neffect of a move by the difference in score estimates. This gives a\nfine-grained, move-by-move performance evaluation of a player. We use this in\ncombating the new challenge of detecting online cheating.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 12:25:02 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 05:15:19 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 12:11:36 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Egri-Nagy", "Attila", ""], ["T\u00f6rm\u00e4nen", "Antti", ""]]}, {"id": "2009.01607", "submitter": "Shun Zhang", "authors": "Shunbo Zhang, Shun Zhang, Feifei Gao, Jianpeng Ma, Octavia A. Dobre", "title": "Deep Learning Optimized Sparse Antenna Activation for Reconfigurable\n  Intelligent Surface Assisted Communication", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To capture the communications gain of the massive radiating elements with low\npower cost, the conventional reconfigurable intelligent surface (RIS) usually\nworks in passive mode. However, due to the cascaded channel structure and the\nlack of signal processing ability, it is difficult for RIS to obtain the\nindividual channel state information and optimize the beamforming vector. In\nthis paper, we add signal processing units for a few antennas at RIS to\npartially acquire the channels. To solve the crucial active antenna selection\nproblem, we construct an active antenna selection network that utilizes the\nprobabilistic sampling theory to select the optimal locations of these active\nantennas. With this active antenna selection network, we further design two\ndeep learning (DL) based schemes, i.e., the channel extrapolation scheme and\nthe beam searching scheme, to enable the RIS communication system. The former\nutilizes the selection network and a convolutional neural network to\nextrapolate the full channels from the partial channels received by the active\nRIS antennas, while the latter adopts a fully-connected neural network to\nachieve the direct mapping between the partial channels and the optimal\nbeamforming vector with maximal transmission rate. Simulation results are\nprovided to demonstrate the effectiveness of the designed DL-based schemes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 12:27:22 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhang", "Shunbo", ""], ["Zhang", "Shun", ""], ["Gao", "Feifei", ""], ["Ma", "Jianpeng", ""], ["Dobre", "Octavia A.", ""]]}, {"id": "2009.01625", "submitter": "Saaduddin Mahmud", "authors": "Saaduddin Mahmud, Md. Mosaddek Khan, Nicholas R. Jennings", "title": "On Population-Based Algorithms for Distributed Constraint Optimization\n  Problems", "comments": "7 Figures. arXiv admin note: text overlap with arXiv:1909.06254,\n  arXiv:2002.12001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nclass of optimization problems in which interaction between a set of\ncooperative agents are modeled as a set of constraints. DCOPs are NP-hard and\nsignificant effort has been devoted to developing methods for finding\nincomplete solutions. In this paper, we study an emerging class of such\nincomplete algorithms that are broadly termed as population-based algorithms.\nThe main characteristic of these algorithms is that they maintain a population\nof candidate solutions of a given problem and use this population to cover a\nlarge area of the search space and to avoid local-optima. In recent years, this\nclass of algorithms has gained significant attention due to their ability to\nproduce high-quality incomplete solutions. With the primary goal of further\nimproving the quality of solutions compared to the state-of-the-art incomplete\nDCOP algorithms, we present two new population-based algorithms in this paper.\nOur first approach, Anytime Evolutionary DCOP or AED, exploits evolutionary\noptimization meta-heuristics to solve DCOPs. We also present a novel anytime\nupdate mechanism that gives AED its anytime property. While in our second\ncontribution, we show that population-based approaches can be combined with\nlocal search approaches. Specifically, we develop an algorithm called DPSA\nbased on the Simulated Annealing meta-heuristic. We empirically evaluate these\ntwo algorithms to illustrate their respective effectiveness in different\nsettings against the state-of-the-art incomplete DCOP algorithms including all\nexisting population-based algorithms in a wide variety of benchmarks. Our\nevaluation shows AED and DPSA markedly outperform the state-of-the-art and\nproduce up to 75% improved solutions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 06:39:30 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Mahmud", "Saaduddin", ""], ["Khan", "Md. Mosaddek", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "2009.01653", "submitter": "Shun Zhang", "authors": "Yindi Yang, Shun Zhang, Feifei Gao, Chao Xu, Jianpeng Ma, Octavia A.\n  Dobre", "title": "Deep Learning Based Antenna Selection for Channel Extrapolation in FDD\n  Massive MIMO", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In massive multiple-input multiple-output (MIMO) systems, the large number of\nantennas would bring a great challenge for the acquisition of the accurate\nchannel state information, especially in the frequency division duplex mode. To\novercome the bottleneck of the limited number of radio links in hybrid\nbeamforming, we utilize the neural networks (NNs) to capture the inherent\nconnection between the uplink and downlink channel data sets and extrapolate\nthe downlink channels from a subset of the uplink channel state information. We\nstudy the antenna subset selection problem in order to achieve the best channel\nextrapolation and decrease the data size of NNs. The probabilistic sampling\ntheory is utilized to approximate the discrete antenna selection as a\ncontinuous and differentiable function, which makes the back propagation of the\ndeep learning feasible. Then, we design the proper off-line training strategy\nto optimize both the antenna selection pattern and the extrapolation NNs.\nFinally, numerical results are presented to verify the effectiveness of our\nproposed massive MIMO channel extrapolation algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 13:38:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Yang", "Yindi", ""], ["Zhang", "Shun", ""], ["Gao", "Feifei", ""], ["Xu", "Chao", ""], ["Ma", "Jianpeng", ""], ["Dobre", "Octavia A.", ""]]}, {"id": "2009.01675", "submitter": "Zihao Wang", "authors": "Zihao Wang, Herv\\'e Delingette", "title": "Quasi-symplectic Langevin Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a very popular and well-investigated\ngenerative model in neural learning research. To leverage VAE in practical\ntasks dealing with a massive dataset of large dimensions, it is required to\ndeal with the difficulty of building low variance evidence lower bounds (ELBO).\nMarkov Chain Monte Carlo (MCMC) is an effective approach to tighten the ELBO\nfor approximating the posterior distribution and Hamiltonian Variational\nAutoencoder (HVAE) is an effective MCMC inspired approach for constructing a\nlow-variance ELBO that is amenable to the reparameterization trick. The HVAE\nadapted the Hamiltonian dynamic flow into variational inference that\nsignificantly improves the performance of the posterior estimation. We propose\nin this work a Langevin dynamic flow-based inference approach by incorporating\nthe gradients information in the inference process through the Langevin dynamic\nwhich is a kind of MCMC based method similar to HVAE. Specifically, we employ a\nquasi-symplectic integrator to cope with the prohibit problem of the Hessian\ncomputing in naive Langevin flow. We show the theoretical and practical\neffectiveness of the proposed framework with other gradient flow-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 12:13:27 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:28:54 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 18:50:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 09:05:17 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Zihao", ""], ["Delingette", "Herv\u00e9", ""]]}, {"id": "2009.01717", "submitter": "Rick Groenendijk", "authors": "Rick Groenendijk, Sezer Karaoglu, Theo Gevers, Thomas Mensink", "title": "Multi-Loss Weighting with Coefficient of Variations", "comments": "Paper was accepted at the IEEE Winter Conference on Applications of\n  Computer Vision 2021 (WACV2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting tasks in machine learning and computer vision are learned by\noptimising an objective function defined as a weighted linear combination of\nmultiple losses. The final performance is sensitive to choosing the correct\n(relative) weights for these losses. Finding a good set of weights is often\ndone by adopting them into the set of hyper-parameters, which are set using an\nextensive grid search. This is computationally expensive. In this paper, we\npropose a weighting scheme based on the coefficient of variations and set the\nweights based on properties observed while training the model. The proposed\nmethod incorporates a measure of uncertainty to balance the losses, and as a\nresult the loss weights evolve during training without requiring another\n(learning based) optimisation. In contrast to many loss weighting methods in\nliterature, we focus on single-task multi-loss problems, such as monocular\ndepth estimation and semantic segmentation, and show that multi-task approaches\nfor loss weighting do not work on those single-tasks. The validity of the\napproach is shown empirically for depth estimation and semantic segmentation on\nmultiple datasets.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:51:19 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 10:41:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Groenendijk", "Rick", ""], ["Karaoglu", "Sezer", ""], ["Gevers", "Theo", ""], ["Mensink", "Thomas", ""]]}, {"id": "2009.01719", "submitter": "Felix Hill Mr", "authors": "Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza\n  Merzic, Stephen Clark", "title": "Grounded Language Learning Fast and Slow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that large text-based neural language models, trained\nwith conventional supervised learning objectives, acquire a surprising\npropensity for few- and one-shot learning. Here, we show that an embodied agent\nsituated in a simulated 3D world, and endowed with a novel dual-coding external\nmemory, can exhibit similar one-shot word learning when trained with\nconventional reinforcement learning algorithms. After a single introduction to\na novel object via continuous visual perception and a language prompt (\"This is\na dax\"), the agent can re-identify the object and manipulate it as instructed\n(\"Put the dax on the bed\"). In doing so, it seamlessly integrates short-term,\nwithin-episode knowledge of the appropriate referent for the word \"dax\" with\nlong-term lexical and motor knowledge acquired across episodes (i.e. \"bed\" and\n\"putting\"). We find that, under certain training conditions and with a\nparticular memory writing mechanism, the agent's one-shot word-object binding\ngeneralizes to novel exemplars within the same ShapeNet category, and is\neffective in settings with unfamiliar numbers of objects. We further show how\ndual-coding memory can be exploited as a signal for intrinsic motivation,\nstimulating the agent to seek names for objects that may be useful for later\nexecuting instructions. Together, the results demonstrate that deep neural\nnetworks can exploit meta-learning, episodic memory and an explicitly\nmulti-modal environment to account for 'fast-mapping', a fundamental pillar of\nhuman cognitive development and a potentially transformative capacity for\nagents that interact with human users.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:52:03 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:25:12 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 10:56:08 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 14:38:58 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hill", "Felix", ""], ["Tieleman", "Olivier", ""], ["von Glehn", "Tamara", ""], ["Wong", "Nathaniel", ""], ["Merzic", "Hamza", ""], ["Clark", "Stephen", ""]]}, {"id": "2009.01721", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Max-value Entropy Search for Multi-Objective Bayesian Optimization with\n  Constraints", "comments": "2 figure, 1 table. arXiv admin note: text overlap with\n  arXiv:2008.07029", "journal-ref": "Third Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of constrained multi-objective blackbox optimization\nusing expensive function evaluations, where the goal is to approximate the true\nPareto set of solutions satisfying a set of constraints while minimizing the\nnumber of function evaluations. For example, in aviation power system design\napplications, we need to find the designs that trade-off total energy and the\nmass while satisfying specific thresholds for motor temperature and voltage of\ncells. This optimization requires performing expensive computational\nsimulations to evaluate designs. In this paper, we propose a new approach\nreferred as {\\em Max-value Entropy Search for Multi-objective Optimization with\nConstraints (MESMOC)} to solve this problem. MESMOC employs an output-space\nentropy based acquisition function to efficiently select the sequence of inputs\nfor evaluation to uncover high-quality pareto-set solutions while satisfying\nconstraints.\n  We apply MESMOC to two real-world engineering design applications to\ndemonstrate its effectiveness over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 05:00:01 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 02:20:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.01766", "submitter": "Wu Weijia", "authors": "Weijia Wu and Ning Lu and Enze Xie", "title": "Synthetic-to-Real Unsupervised Domain Adaptation for Scene Text\n  Detection in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning-based scene text detection can achieve preferable performance,\npowered with sufficient labeled training data. However, manual labeling is time\nconsuming and laborious. At the extreme, the corresponding annotated data are\nunavailable. Exploiting synthetic data is a very promising solution except for\ndomain distribution mismatches between synthetic datasets and real datasets. To\naddress the severe domain distribution mismatch, we propose a synthetic-to-real\ndomain adaptation method for scene text detection, which transfers knowledge\nfrom synthetic data (source domain) to real data (target domain). In this\npaper, a text self-training (TST) method and adversarial text instance\nalignment (ATA) for domain adaptive scene text detection are introduced. ATA\nhelps the network learn domain-invariant features by training a domain\nclassifier in an adversarial manner. TST diminishes the adverse effects of\nfalse positives~(FPs) and false negatives~(FNs) from inaccurate pseudo-labels.\nTwo components have positive effects on improving the performance of scene text\ndetectors when adapting from synthetic-to-real scenes. We evaluate the proposed\nmethod by transferring from SynthText, VISD to ICDAR2015, ICDAR2013. The\nresults demonstrate the effectiveness of the proposed method with up to 10%\nimprovement, which has important exploration significance for domain adaptive\nscene text detection. Code is available at\nhttps://github.com/weijiawu/SyntoReal_STD\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:16:34 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Wu", "Weijia", ""], ["Lu", "Ning", ""], ["Xie", "Enze", ""]]}, {"id": "2009.01769", "submitter": "Davide Mario Longo", "authors": "Wolfgang Fischl, Georg Gottlob, Davide Mario Longo, Reinhard Pichler", "title": "HyperBench: A Benchmark and Tool for Hypergraphs and Empirical Findings", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.08181", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the intractability of answering Conjunctive Queries (CQs) and\nsolving Constraint Satisfaction Problems (CSPs), several notions of hypergraph\ndecompositions have been proposed -- giving rise to different notions of width,\nnoticeably, plain, generalized, and fractional hypertree width (hw, ghw, and\nfhw). Given the increasing interest in using such decomposition methods in\npractice, a publicly accessible repository of decomposition software, as well\nas a large set of benchmarks, and a web-accessible workbench for inserting,\nanalyzing, and retrieving hypergraphs are called for.\n  We address this need by providing (i) concrete implementations of hypergraph\ndecompositions (including new practical algorithms), (ii) a new, comprehensive\nbenchmark of hypergraphs stemming from disparate CQ and CSP collections, and\n(iii) HyperBench, our new web-inter\\-face for accessing the benchmark and the\nresults of our analyses. In addition, we describe a number of actual\nexperiments we carried out with this new infrastructure.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:08:55 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Fischl", "Wolfgang", ""], ["Gottlob", "Georg", ""], ["Longo", "Davide Mario", ""], ["Pichler", "Reinhard", ""]]}, {"id": "2009.01791", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston,\n  Nicolas Heess", "title": "Action and Perception as Divergence Minimization", "comments": "14 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a unified objective for action and perception of intelligent\nagents. Extending representation learning and control, we minimize the joint\ndivergence between the combined system of agent and environment and a target\ndistribution. Intuitively, such agents use perception to align their beliefs\nwith the world, and use actions to align the world with their beliefs.\nMinimizing the joint divergence to an expressive target maximizes the mutual\ninformation between the agent's representations and inputs, thus inferring\nrepresentations that are informative of past inputs and exploring future inputs\nthat are informative of the representations. This lets us explain intrinsic\nobjectives, such as representation learning, information gain, empowerment, and\nskill discovery from minimal assumptions. Moreover, interpreting the target\ndistribution as a latent variable model suggests powerful world models as a\npath toward highly adaptive agents that seek large niches in their\nenvironments, rendering task rewards optional. The framework provides a common\nlanguage for comparing a wide range of objectives, advances the understanding\nof latent variables for decision making, and offers a recipe for designing\nnovel objectives. We recommend deriving future agent objectives the joint\ndivergence to facilitate comparison, to point out the agent's target\ndistribution, and to identify the intrinsic objective terms needed to reach\nthat distribution.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:52:46 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:52:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hafner", "Danijar", ""], ["Ortega", "Pedro A.", ""], ["Ba", "Jimmy", ""], ["Parr", "Thomas", ""], ["Friston", "Karl", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.01798", "submitter": "John Mitros", "authors": "John Mitros and Arjun Pakrashi and Brian Mac Namee", "title": "Ramifications of Approximate Posterior Inference for Bayesian Deep\n  Learning in Adversarial and Out-of-Distribution Settings", "comments": "AROW@ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successful in diverse discriminative\nclassification tasks, although, they are poorly calibrated often assigning high\nprobability to misclassified predictions. Potential consequences could lead to\ntrustworthiness and accountability of the models when deployed in real\napplications, where predictions are evaluated based on their confidence scores.\nExisting solutions suggest the benefits attained by combining deep neural\nnetworks and Bayesian inference to quantify uncertainty over the models'\npredictions for ambiguous datapoints. In this work we propose to validate and\ntest the efficacy of likelihood based models in the task of out of distribution\ndetection (OoD). Across different datasets and metrics we show that Bayesian\ndeep learning models on certain occasions marginally outperform conventional\nneural networks and in the event of minimal overlap between in/out distribution\nclasses, even the best models exhibit a reduction in AUC scores in detecting\nOoD data. Preliminary investigations indicate the potential inherent role of\nbias due to choices of initialisation, architecture or activation functions. We\nhypothesise that the sensitivity of neural networks to unseen inputs could be a\nmulti-factor phenomenon arising from the different architectural design choices\noften amplified by the curse of dimensionality. Furthermore, we perform a study\nto find the effect of the adversarial noise resistance methods on in and\nout-of-distribution performance, as well as, also investigate adversarial noise\nrobustness of Bayesian deep learners.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:58:15 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 14:46:06 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Mitros", "John", ""], ["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "2009.01803", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai", "title": "Sparse Meta Networks for Sequential Adaptation and its Application to\n  Adaptive Language Modelling", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network requires a large amount of single-task data\nand involves a long time-consuming optimization phase. This is not scalable to\ncomplex, realistic environments with new unexpected changes. Humans can perform\nfast incremental learning on the fly and memory systems in the brain play a\ncritical role. We introduce Sparse Meta Networks -- a meta-learning approach to\nlearn online sequential adaptation algorithms for deep neural networks, by\nusing deep neural networks. We augment a deep neural network with a\nlayer-specific fast-weight memory. The fast-weights are generated sparsely at\neach time step and accumulated incrementally through time providing a useful\ninductive bias for online continual adaptation. We demonstrate strong\nperformance on a variety of sequential adaptation scenarios, from a simple\nonline reinforcement learning to a large scale adaptive language modelling.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:06:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""]]}, {"id": "2009.01810", "submitter": "Deokgun Park", "authors": "Aishwarya Pothula, Md Ashaduzzaman Rubel Mondol, Sanath Narasimhan, Sm\n  Mazharul Islam, Deokgun Park", "title": "SEDRo: A Simulated Environment for Developmental Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even with impressive advances in application-specific models, we still lack\nknowledge about how to build a model that can learn in a human-like way and do\nmultiple tasks. To learn in a human-like way, we need to provide a diverse\nexperience that is comparable to humans. In this paper, we introduce our\nongoing effort to build a simulated environment for developmental robotics\n(SEDRo). SEDRo provides diverse human experiences ranging from those of a fetus\nto a 12th-month-old. A series of simulated tests based on developmental\npsychology will be used to evaluate the progress of a learning model. We\nanticipate SEDRo to lower the cost of entry and facilitate research in the\ndevelopmental robotics community.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:16:54 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Pothula", "Aishwarya", ""], ["Mondol", "Md Ashaduzzaman Rubel", ""], ["Narasimhan", "Sanath", ""], ["Islam", "Sm Mazharul", ""], ["Park", "Deokgun", ""]]}, {"id": "2009.01953", "submitter": "Gustavo Polleti", "authors": "Gustavo Padilha Polleti, Douglas Luan de Souza, Fabio Cozman", "title": "Why should I not follow you? Reasons For and Reasons Against in\n  Responsible Recommender Systems", "comments": "6 pages, 4 figures, ACM Recsys 2020, 3rd FAccTRec Workshop:\n  Responsible Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A few Recommender Systems (RS) resort to explanations so as to enhance trust\nin recommendations. However, current techniques for explanation generation tend\nto strongly uphold the recommended products instead of presenting both reasons\nfor and reasons against them. We argue that an RS can better enhance overall\ntrust and transparency by frankly displaying both kinds of reasons to users.We\nhave developed such an RS by exploiting knowledge graphs and by applying\nSnedegar's theory of practical reasoning. We show that our implemented RS has\nexcellent performance and we report on an experiment with human subjects that\nshows the value of presenting both reasons for and against, with significant\nimprovements in trust, engagement, and persuasion.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:16:04 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:15:41 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Polleti", "Gustavo Padilha", ""], ["de Souza", "Douglas Luan", ""], ["Cozman", "Fabio", ""]]}, {"id": "2009.02043", "submitter": "Fredrik Olsson", "authors": "Fredrik Olsson, Magnus Sahlgren", "title": "Data Readiness for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document concerns data readiness in the context of machine learning and\nNatural Language Processing. It describes how an organization may proceed to\nidentify, make available, validate, and prepare data to facilitate automated\nanalysis methods. The contents of the document is based on the practical\nchallenges and frequently asked questions we have encountered in our work as an\napplied research institute with helping organizations and companies, both in\nthe public and private sectors, to use data in their business processes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:53:43 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:03:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Olsson", "Fredrik", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2009.02083", "submitter": "Seiji Ishihara", "authors": "Seiji Ishihara and Harukazu Igarashi", "title": "Policy Gradient Reinforcement Learning for Policy Represented by Fuzzy\n  Rules: Application to Simulations of Speed Control of an Automobile", "comments": null, "journal-ref": "Journal of Japan Society for Fuzzy Theory and Intelligent\n  Informatics, Vol. 32, No. 4, pp. 801-810, 2020 (in Japanese)", "doi": "10.3156/jsoft.32.4_801", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method of a fusion of fuzzy inference and policy gradient reinforcement\nlearning has been proposed that directly learns, as maximizes the expected\nvalue of the reward per episode, parameters in a policy function represented by\nfuzzy rules with weights. A study has applied this method to a task of speed\ncontrol of an automobile and has obtained correct policies, some of which\ncontrol speed of the automobile appropriately but many others generate\ninappropriate vibration of speed. In general, the policy is not desirable that\ncauses sudden time change or vibration in the output value, and there would be\nmany cases where the policy giving smooth time change in the output value is\ndesirable. In this paper, we propose a fusion method using the objective\nfunction, that introduces defuzzification with the center of gravity model\nweighted stochastically and a constraint term for smoothness of time change, as\nan improvement measure in order to suppress sudden change of the output value\nof the fuzzy controller. Then we show the learning rule in the fusion, and also\nconsider the effect by reward functions on the fluctuation of the output value.\nAs experimental results of an application of our method on speed control of an\nautomobile, it was confirmed that the proposed method has the effect of\nsuppressing the undesirable fluctuation in time-series of the output value.\nMoreover, it was also showed that the difference between reward functions might\nadversely affect the results of learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 09:30:13 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Ishihara", "Seiji", ""], ["Igarashi", "Harukazu", ""]]}, {"id": "2009.02098", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Explainable Artificial Intelligence for Process Mining: A General\n  Overview and Application of a Novel Local Explanation Approach for Predictive\n  Process Monitoring", "comments": "Manuscript submitted (10.07.2020) to the edited volume \"Interpretable\n  Artificial Intelligence: A perspective of Granular Computing\" (published by\n  Springer)", "journal-ref": null, "doi": "10.1007/978-3-030-64949-4_1", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contemporary process-aware information systems possess the capabilities\nto record the activities generated during the process execution. To leverage\nthese process specific fine-granular data, process mining has recently emerged\nas a promising research discipline. As an important branch of process mining,\npredictive business process management, pursues the objective to generate\nforward-looking, predictive insights to shape business processes. In this\nstudy, we propose a conceptual framework sought to establish and promote\nunderstanding of decision-making environment, underlying business processes and\nnature of the user characteristics for developing explainable business process\nprediction solutions. Consequently, with regard to the theoretical and\npractical implications of the framework, this study proposes a novel local\npost-hoc explanation approach for a deep learning classifier that is expected\nto facilitate the domain experts in justifying the model decisions. In contrary\nto alternative popular perturbation-based local explanation approaches, this\nstudy defines the local regions from the validation dataset by using the\nintermediate latent space representations learned by the deep neural networks.\nTo validate the applicability of the proposed explanation method, the real-life\nprocess log data delivered by the Volvo IT Belgium's incident management system\nare used.The adopted deep learning classifier achieves a good performance with\nthe Area Under the ROC Curve of 0.94. The generated local explanations are also\nvisualized and presented with relevant evaluation measures that are expected to\nincrease the users' trust in the black-box-model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:28:56 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 07:24:36 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.02164", "submitter": "Joni Pajarinen", "authors": "Joni Pajarinen", "title": "Technical Report: The Policy Graph Improvement Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing a partially observable Markov decision process (POMDP) policy is\nchallenging. The policy graph improvement (PGI) algorithm for POMDPs represents\nthe policy as a fixed size policy graph and improves the policy monotonically.\nDue to the fixed policy size, computation time for each improvement iteration\nis known in advance. Moreover, the method allows for compact understandable\npolicies. This report describes the technical details of the PGI [1] and\nparticle based PGI [2] algorithms for POMDPs in a more accessible way than [1]\nor [2] allowing practitioners and students to understand and implement the\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:00:37 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Pajarinen", "Joni", ""]]}, {"id": "2009.02165", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Kei Uchizawa", "title": "A Generalization of Spatial Monte Carlo Integration", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01365", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Monte Carlo integration (SMCI) is an extension of standard Monte\nCarlo integration and can approximate expectations on Markov random fields with\nhigh accuracy. SMCI was applied to pairwise Boltzmann machine (PBM) learning,\nwith superior results to those from some existing methods. The approximation\nlevel of SMCI can be changed, and it was proved that a higher-order\napproximation of SMCI is statistically more accurate than a lower-order\napproximation. However, SMCI as proposed in the previous studies suffers from a\nlimitation that prevents the application of a higher-order method to dense\nsystems.\n  This study makes two different contributions as follows. A generalization of\nSMCI (called generalized SMCI (GSMCI)) is proposed, which allows relaxation of\nthe above-mentioned limitation; moreover, a statistical accuracy bound of GSMCI\nis proved. This is the first contribution of this study. A new PBM learning\nmethod based on SMCI is proposed, which is obtained by combining SMCI and the\npersistent contrastive divergence. The proposed learning method greatly\nimproves the accuracy of learning. This is the second contribution of this\nstudy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:02:58 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:02:56 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yasuda", "Muneki", ""], ["Uchizawa", "Kei", ""]]}, {"id": "2009.02185", "submitter": "Tomer Barak", "authors": "Tomer Barak, Yehonatan Avidan and Yonatan Loewenstein", "title": "Naive Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the cognitive sciences, it is common to distinguish between crystal\nintelligence, the ability to utilize knowledge acquired through past learning\nor experience and fluid intelligence, the ability to solve novel problems\nwithout relying on prior knowledge. Using this cognitive distinction between\nthe two types of intelligence, extensively-trained deep networks that can play\nchess or Go exhibit crystal but not fluid intelligence. In humans, fluid\nintelligence is typically studied and quantified using intelligence tests.\nPrevious studies have shown that deep networks can solve some forms of\nintelligence tests, but only after extensive training. Here we present a\ncomputational model that solves intelligence tests without any prior training.\nThis ability is based on continual inductive reasoning, and is implemented by\ndeep unsupervised latent-prediction networks. Our work demonstrates the\npotential fluid intelligence of deep networks. Finally, we propose that the\ncomputational principles underlying our approach can be used to model fluid\nintelligence in the cognitive sciences.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:40:10 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Barak", "Tomer", ""], ["Avidan", "Yehonatan", ""], ["Loewenstein", "Yonatan", ""]]}, {"id": "2009.02188", "submitter": "Mohamed Ghalwash", "authors": "Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, James Codella,\n  Daby Sow", "title": "Phenotypical Ontology Driven Framework for Multi-Task Learning", "comments": "To be appear on ACM CHIL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the large number of patients in Electronic Health Records (EHRs), the\nsubset of usable data for modeling outcomes of specific phenotypes are often\nimbalanced and of modest size. This can be attributed to the uneven coverage of\nmedical concepts in EHRs. In this paper, we propose OMTL, an Ontology-driven\nMulti-Task Learning framework, that is designed to overcome such data\nlimitations. The key contribution of our work is the effective use of knowledge\nfrom a predefined well-established medical relationship graph (ontology) to\nconstruct a novel deep learning network architecture that mirrors this\nontology. It can effectively leverage knowledge from a well-established medical\nrelationship graph (ontology) by constructing a deep learning network\narchitecture that mirrors this graph. This enables common representations to be\nshared across related phenotypes, and was found to improve the learning\nperformance. The proposed OMTL naturally allows for multitask learning of\ndifferent phenotypes on distinct predictive tasks. These phenotypes are tied\ntogether by their semantic distance according to the external medical ontology.\nUsing the publicly available MIMIC-III database, we evaluate OMTL and\ndemonstrate its efficacy on several real patient outcome predictions over\nstate-of-the-art multi-task learning schemes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 13:46:07 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ghalwash", "Mohamed", ""], ["Yao", "Zijun", ""], ["Chakraborty", "Prithwish", ""], ["Codella", "James", ""], ["Sow", "Daby", ""]]}, {"id": "2009.02240", "submitter": "Cornelis Jan Van Leeuwen", "authors": "Cornelis Jan van Leeuwen and Przemyz{\\l}aw Pawe{\\l}czak", "title": "Hybrid DCOP Solvers: Boosting Performance of Local Search Algorithms", "comments": "16 pages, 6 figures, 2 tables, 2 algorithms with pseudocode.\n  Presented at the International Workshop on Optimization in Multiagent Systems\n  (OptMAS-18), during the AAMAS conference 2018 in Stockholm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for expediting both symmetric and asymmetric\nDistributed Constraint Optimization Problem (DCOP) solvers. The core idea is\nbased on initializing DCOP solvers with greedy fast non-iterative DCOP solvers.\nThis is contrary to existing methods where initialization is always achieved\nusing a random value assignment. We empirically show that changing the starting\nconditions of existing DCOP solvers not only reduces the algorithm convergence\ntime by up to 50\\%, but also reduces the communication overhead and leads to a\nbetter solution quality. We show that this effect is due to structural\nimprovements in the variable assignment, which is caused by the spreading\npattern of DCOP algorithm activation.) /Subject (Hybrid DCOPs)\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:17:24 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["van Leeuwen", "Cornelis Jan", ""], ["Pawe\u0142czak", "Przemyz\u0142aw", ""]]}, {"id": "2009.02243", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Robustness and Overcoming Brittleness of AI-Enabled Legal\n  Micro-Directives: The Role of Autonomous Levels of AI Legal Reasoning", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research by legal scholars suggests that the law might inevitably be\ntransformed into legal micro-directives consisting of legal rules that are\nderived from legal standards or that are otherwise produced automatically or\nvia the consequent derivations of legal goals and then propagated via\nautomation for everyday use as readily accessible lawful directives throughout\nsociety. This paper examines and extends the legal micro-directives theories in\nthree crucial respects: (1) By indicating that legal micro-directives are\nlikely to be AI-enabled and evolve over time in scope and velocity across the\nautonomous levels of AI Legal Reasoning, (2) By exploring the trade-offs\nbetween legal standards and legal rules as the imprinters of the\nmicro-directives, and (3) By illuminating a set of brittleness exposures that\ncan undermine legal micro-directives and proffering potential mitigating\nremedies to seek greater robustness in the instantiation and promulgation of\nsuch AI-powered lawful directives.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 05:09:03 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.02252", "submitter": "Fabio Petroni", "authors": "Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid\n  Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin,\n  Jean Maillard, Vassilis Plachouras, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks", "comments": "accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging problems such as open-domain question answering, fact checking,\nslot filling and entity linking require access to large, external knowledge\nsources. While some models do well on individual tasks, developing general\nmodels is difficult as each task might require computationally expensive\nindexing of custom knowledge sources, in addition to dedicated infrastructure.\nTo catalyze research on models that condition on specific information in large\ntextual resources, we present a benchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia,\nreducing engineering turnaround through the re-use of components, as well as\naccelerating research into task-agnostic memory architectures. We test both\ntask-specific and general baselines, evaluating downstream performance in\naddition to the ability of the models to provide provenance. We find that a\nshared dense vector index coupled with a seq2seq model is a strong baseline,\noutperforming more tailor-made approaches for fact checking, open-domain\nquestion answering and dialogue, and yielding competitive results on entity\nlinking and slot filling, by generating disambiguated text. KILT data and code\nare available at https://github.com/facebookresearch/KILT.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:32:19 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 08:59:41 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 09:27:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 15:20:59 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Petroni", "Fabio", ""], ["Piktus", "Aleksandra", ""], ["Fan", "Angela", ""], ["Lewis", "Patrick", ""], ["Yazdani", "Majid", ""], ["De Cao", "Nicola", ""], ["Thorne", "James", ""], ["Jernite", "Yacine", ""], ["Karpukhin", "Vladimir", ""], ["Maillard", "Jean", ""], ["Plachouras", "Vassilis", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2009.02353", "submitter": "Gianni Antichi", "authors": "Giuseppe Siracusano, Salvator Galea, Davide Sanvito, Mohammad\n  Malekzadeh, Hamed Haddadi, Gianni Antichi, Roberto Bifulco", "title": "Running Neural Networks on the NIC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that the data plane of commodity programmable (Network\nInterface Cards) NICs can run neural network inference tasks required by packet\nmonitoring applications, with low overhead. This is particularly important as\nthe data transfer costs to the host system and dedicated machine learning\naccelerators, e.g., GPUs, can be more expensive than the processing task\nitself. We design and implement our system -- N3IC -- on two different NICs and\nwe show that it can greatly benefit three different network monitoring use\ncases that require machine learning inference as first-class-primitive. N3IC\ncan perform inference for millions of network flows per second, while\nforwarding traffic at 40Gb/s. Compared to an equivalent solution implemented on\na general purpose CPU, N3IC can provide 100x lower processing latency, with\n1.5x increase in throughput.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 18:35:58 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Siracusano", "Giuseppe", ""], ["Galea", "Salvator", ""], ["Sanvito", "Davide", ""], ["Malekzadeh", "Mohammad", ""], ["Haddadi", "Hamed", ""], ["Antichi", "Gianni", ""], ["Bifulco", "Roberto", ""]]}, {"id": "2009.02358", "submitter": "Mina Naghshnejad", "authors": "Mina Naghshnejad, Tarun Joshi, and Vijayan N. Nair", "title": "Recent Trends in the Use of Deep Learning Models for Grammar Error\n  Handling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar error handling (GEH) is an important topic in natural language\nprocessing (NLP). GEH includes both grammar error detection and grammar error\ncorrection. Recent advances in computation systems have promoted the use of\ndeep learning (DL) models for NLP problems such as GEH. In this survey we focus\non two main DL approaches for GEH: neural machine translation models and editor\nmodels. We describe the three main stages of the pipeline for these models:\ndata preparation, training, and inference. Additionally, we discuss different\ntechniques to improve the performance of these models at each stage of the\npipeline. We compare the performance of different models and conclude with\nproposed future directions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 18:50:13 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Naghshnejad", "Mina", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "2009.02383", "submitter": "Bonifaz Stuhr", "authors": "Bonifaz Stuhr, J\\\"urgen Brauer", "title": "Don't miss the Mismatch: Investigating the Objective Function Mismatch\n  for Unsupervised Representation Learning", "comments": "21 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding general evaluation metrics for unsupervised representation learning\ntechniques is a challenging open research question, which recently has become\nmore and more necessary due to the increasing interest in unsupervised methods.\nEven though these methods promise beneficial representation characteristics,\nmost approaches currently suffer from the objective function mismatch. This\nmismatch states that the performance on a desired target task can decrease when\nthe unsupervised pretext task is learned too long - especially when both tasks\nare ill-posed. In this work, we build upon the widely used linear evaluation\nprotocol and define new general evaluation metrics to quantitatively capture\nthe objective function mismatch and the more generic metrics mismatch. We\ndiscuss the usability and stability of our protocols on a variety of pretext\nand target tasks and study mismatches in a wide range of experiments. Thereby\nwe disclose dependencies of the objective function mismatch across several\npretext and target tasks with respect to the pretext model's representation\nsize, target model complexity, pretext and target augmentations as well as\npretext and target task types.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:21:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Stuhr", "Bonifaz", ""], ["Brauer", "J\u00fcrgen", ""]]}, {"id": "2009.02406", "submitter": "Xinli Yu T", "authors": "Xinli Yu, Mohsen Malmir, Cynthia He, Yue Liu, Rex Wu", "title": "Video Moment Retrieval via Natural Language Queries", "comments": "needs internal approval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for video moment retrieval (VMR)\nthat achieves state of the arts (SOTA) performance on R@1 metrics and\nsurpassing the SOTA on the high IoU metric (R@1, IoU=0.7).\n  First, we propose to use a multi-head self-attention mechanism, and further a\ncross-attention scheme to capture video/query interaction and long-range query\ndependencies from video context. The attention-based methods can develop\nframe-to-query interaction and query-to-frame interaction at arbitrary\npositions and the multi-head setting ensures the sufficient understanding of\ncomplicated dependencies. Our model has a simple architecture, which enables\nfaster training and inference while maintaining .\n  Second, We also propose to use multiple task training objective consists of\nmoment segmentation task, start/end distribution prediction and start/end\nlocation regression task. We have verified that start/end prediction are noisy\ndue to annotator disagreement and joint training with moment segmentation task\ncan provide richer information since frames inside the target clip are also\nutilized as positive training examples.\n  Third, we propose to use an early fusion approach, which achieves better\nperformance at the cost of inference time. However, the inference time will not\nbe a problem for our model since our model has a simple architecture which\nenables efficient training and inference.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 22:06:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:49:04 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Yu", "Xinli", ""], ["Malmir", "Mohsen", ""], ["He", "Cynthia", ""], ["Liu", "Yue", ""], ["Wu", "Rex", ""]]}, {"id": "2009.02423", "submitter": "Harshal Chaudhari", "authors": "Harshal A. Chaudhari, Sangdi Lin, Ondrej Linda", "title": "A General Framework for Fairness in Multistakeholder Recommendations", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary recommender systems act as intermediaries on multi-sided\nplatforms serving high utility recommendations from sellers to buyers. Such\nsystems attempt to balance the objectives of multiple stakeholders including\nsellers, buyers, and the platform itself. The difficulty in providing\nrecommendations that maximize the utility for a buyer, while simultaneously\nrepresenting all the sellers on the platform has lead to many interesting\nresearch problems.Traditionally, they have been formulated as integer linear\nprograms which compute recommendations for all the buyers together in an\n\\emph{offline} fashion, by incorporating coverage constraints so that the\nindividual sellers are proportionally represented across all the recommended\nitems. Such approaches can lead to unforeseen biases wherein certain buyers\nconsistently receive low utility recommendations in order to meet the global\nseller coverage constraints. To remedy this situation, we propose a general\nformulation that incorporates seller coverage objectives alongside individual\nbuyer objectives in a real-time personalized recommender system. In addition,\nwe leverage highly scalable submodular optimization algorithms to provide\nrecommendations to each buyer with provable theoretical quality bounds.\nFurthermore, we empirically evaluate the efficacy of our approach using data\nfrom an online real-estate marketplace.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 23:54:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Chaudhari", "Harshal A.", ""], ["Lin", "Sangdi", ""], ["Linda", "Ondrej", ""]]}, {"id": "2009.02455", "submitter": "Ashwin Raju", "authors": "Ashwin Raju, Zhanghexuan Ji, Chi Tung Cheng, Jinzheng Cai, Junzhou\n  Huang, Jing Xiao, Le Lu, ChienHung Liao, Adam P. Harrison", "title": "User-Guided Domain Adaptation for Rapid Annotation from User\n  Interactions: A Study on Pathological Liver Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mask-based annotation of medical images, especially for 3D data, is a\nbottleneck in developing reliable machine learning models. Using minimal-labor\nuser interactions (UIs) to guide the annotation is promising, but challenges\nremain on best harmonizing the mask prediction with the UIs. To address this,\nwe propose the user-guided domain adaptation (UGDA) framework, which uses\nprediction-based adversarial domain adaptation (PADA) to model the combined\ndistribution of UIs and mask predictions. The UIs are then used as anchors to\nguide and align the mask prediction. Importantly, UGDA can both learn from\nunlabelled data and also model the high-level semantic meaning behind different\nUIs. We test UGDA on annotating pathological livers using a clinically\ncomprehensive dataset of 927 patient studies. Using only extreme-point UIs, we\nachieve a mean (worst-case) performance of 96.1%(94.9%), compared to 93.0%\n(87.0%) for deep extreme points (DEXTR). Furthermore, we also show UGDA can\nretain this state-of-the-art performance even when only seeing a fraction of\navailable UIs, demonstrating an ability for robust and reliable UI-guided\nsegmentation with extremely minimal labor demands.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:24:58 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Raju", "Ashwin", ""], ["Ji", "Zhanghexuan", ""], ["Cheng", "Chi Tung", ""], ["Cai", "Jinzheng", ""], ["Huang", "Junzhou", ""], ["Xiao", "Jing", ""], ["Lu", "Le", ""], ["Liao", "ChienHung", ""], ["Harrison", "Adam P.", ""]]}, {"id": "2009.02476", "submitter": "Yun-Shiuan Chuang", "authors": "Yun-Shiuan Chuang, Xuezhou Zhang, Yuzhe Ma, Mark K. Ho, Joseph L.\n  Austerweil, Xiaojin Zhu", "title": "Using Machine Teaching to Investigate Human Assumptions when Teaching\n  Reinforcement Learners", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful teaching requires an assumption of how the learner learns - how\nthe learner uses experiences from the world to update their internal states. We\ninvestigate what expectations people have about a learner when they teach them\nin an online manner using rewards and punishment. We focus on a common\nreinforcement learning method, Q-learning, and examine what assumptions people\nhave using a behavioral experiment. To do so, we first establish a normative\nstandard, by formulating the problem as a machine teaching optimization\nproblem. To solve the machine teaching optimization problem, we use a deep\nlearning approximation method which simulates learners in the environment and\nlearns to predict how feedback affects the learner's internal states. What do\npeople assume about a learner's learning and discount rates when they teach\nthem an idealized exploration-exploitation task? In a behavioral experiment, we\nfind that people can teach the task to Q-learners in a relatively efficient and\neffective manner when the learner uses a small value for its discounting rate\nand a large value for its learning rate. However, they still are suboptimal. We\nalso find that providing people with real-time updates of how possible feedback\nwould affect the Q-learner's internal states weakly helps them teach. Our\nresults reveal how people teach using evaluative feedback and provide guidance\nfor how engineers should design machine agents in a manner that is intuitive\nfor people.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 06:32:38 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 21:54:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chuang", "Yun-Shiuan", ""], ["Zhang", "Xuezhou", ""], ["Ma", "Yuzhe", ""], ["Ho", "Mark K.", ""], ["Austerweil", "Joseph L.", ""], ["Zhu", "Xiaojin", ""]]}, {"id": "2009.02516", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Guan Cuntai", "title": "Generalization on the Enhancement of Layerwise Relevance\n  Interpretability of Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical application of deep neural networks are still limited by their\nlack of transparency. One of the efforts to provide explanation for decisions\nmade by artificial intelligence (AI) is the use of saliency or heat maps\nhighlighting relevant regions that contribute significantly to its prediction.\nA layer-wise amplitude filtering method was previously introduced to improve\nthe quality of heatmaps, performing error corrections by noise-spike\nsuppression. In this study, we generalize the layerwise error correction by\nconsidering any identifiable error and assuming there exists a groundtruth\ninterpretable information. The forms of errors propagated through layerwise\nrelevance methods are studied and we propose a filtering technique for\ninterpretability signal rectification taylored to the trend of signal amplitude\nof the particular neural network used. Finally, we put forth arguments for the\nuse of groundtruth interpretable information.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 11:26:53 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 10:01:52 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tjoa", "Erico", ""], ["Cuntai", "Guan", ""]]}, {"id": "2009.02557", "submitter": "Hui Chen", "authors": "Pei Fang, Zhendong Cai, Hui Chen and QingJiang Shi", "title": "FLFE: A Communication-Efficient and Privacy-Preserving Federated Feature\n  Engineering Framework", "comments": "11pages, multi-party feature engineering problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is the process of using domain knowledge to extract\nfeatures from raw data via data mining techniques and is a key step to improve\nthe performance of machine learning algorithms. In the multi-party feature\nengineering scenario (features are stored in many different IoT devices),\ndirect and unlimited multivariate feature transformations will quickly exhaust\nmemory, power, and bandwidth of devices, not to mention the security of\ninformation threatened. Given this, we present a framework called FLFE to\nconduct privacy-preserving and communication-preserving multi-party feature\ntransformations. The framework pre-learns the pattern of the feature to\ndirectly judge the usefulness of the transformation on a feature. Explored the\nnew useful feature, the framework forsakes the encryption-based algorithm for\nthe well-designed feature exchange mechanism, which largely decreases the\ncommunication overhead under the premise of confidentiality. We made\nexperiments on datasets of both open-sourced and real-world thus validating the\ncomparable effectiveness of FLFE to evaluation-based approaches, along with the\nfar more superior efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:08:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Fang", "Pei", ""], ["Cai", "Zhendong", ""], ["Chen", "Hui", ""], ["Shi", "QingJiang", ""]]}, {"id": "2009.02569", "submitter": "Haochuan Jiang", "authors": "Haochuan Jiang, Chengjia Wang, Agisilaos Chartsias, Sotirios A.\n  Tsaftaris", "title": "Max-Fusion U-Net for Multi-Modal Pathology Segmentation with Attention\n  and Dynamic Resampling", "comments": "13 pages, 7 figures, conference paper", "journal-ref": "MICCAI-2020 MyoPS Challenge Paper", "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation of multi-sequence (multi-modal) cardiac MR (CMR)\nimages plays a significant role in diagnosis and management for a variety of\ncardiac diseases. However, the performance of relevant algorithms is\nsignificantly affected by the proper fusion of the multi-modal information.\nFurthermore, particular diseases, such as myocardial infarction, display\nirregular shapes on images and occupy small regions at random locations. These\nfacts make pathology segmentation of multi-modal CMR images a challenging task.\nIn this paper, we present the Max-Fusion U-Net that achieves improved pathology\nsegmentation performance given aligned multi-modal images of LGE, T2-weighted,\nand bSSFP modalities. Specifically, modality-specific features are extracted by\ndedicated encoders. Then they are fused with the pixel-wise maximum operator.\nTogether with the corresponding encoding features, these representations are\npropagated to decoding layers with U-Net skip-connections. Furthermore, a\nspatial-attention module is applied in the last decoding layer to encourage the\nnetwork to focus on those small semantically meaningful pathological regions\nthat trigger relatively high responses by the network neurons. We also use a\nsimple image patch extraction strategy to dynamically resample training\nexamples with varying spacial and batch sizes. With limited GPU memory, this\nstrategy reduces the imbalance of classes and forces the model to focus on\nregions around the interested pathology. It further improves segmentation\naccuracy and reduces the mis-classification of pathology. We evaluate our\nmethods using the Myocardial pathology segmentation (MyoPS) combining the\nmulti-sequence CMR dataset which involves three modalities. Extensive\nexperiments demonstrate the effectiveness of the proposed model which\noutperforms the related baselines.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 17:24:23 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Jiang", "Haochuan", ""], ["Wang", "Chengjia", ""], ["Chartsias", "Agisilaos", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "2009.02590", "submitter": "Nasim Sonboli", "authors": "Nasim Sonboli, Robin Burke, Nicholas Mattei, Farzad Eskandanian, Tian\n  Gao", "title": "\"And the Winner Is...\": Dynamic Lotteries for Multi-group Fairness-Aware\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As recommender systems are being designed and deployed for an increasing\nnumber of socially-consequential applications, it has become important to\nconsider what properties of fairness these systems exhibit. There has been\nconsiderable research on recommendation fairness. However, we argue that the\nprevious literature has been based on simple, uniform and often uni-dimensional\nnotions of fairness assumptions that do not recognize the real-world\ncomplexities of fairness-aware applications. In this paper, we explicitly\nrepresent the design decisions that enter into the trade-off between accuracy\nand fairness across multiply-defined and intersecting protected groups,\nsupporting multiple fairness metrics. The framework also allows the recommender\nto adjust its performance based on the historical view of recommendations that\nhave been delivered over a time horizon, dynamically rebalancing between\nfairness concerns. Within this framework, we formulate lottery-based mechanisms\nfor choosing between fairness concerns, and demonstrate their performance in\ntwo recommendation domains.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 20:15:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Sonboli", "Nasim", ""], ["Burke", "Robin", ""], ["Mattei", "Nicholas", ""], ["Eskandanian", "Farzad", ""], ["Gao", "Tian", ""]]}, {"id": "2009.02625", "submitter": "Zifeng Wang", "authors": "Zifeng Wang and Rui Wen and Xi Chen and Shilei Cao and Shao-Lun Huang\n  and Buyue Qian and Yefeng Zheng", "title": "Online Disease Self-diagnosis with Inductive Heterogeneous Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3449795", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Healthcare Graph Convolutional Network (HealGCN) to offer\ndisease self-diagnosis service for online users based on Electronic Healthcare\nRecords (EHRs). Two main challenges are focused in this paper for online\ndisease diagnosis: (1) serving cold-start users via graph convolutional\nnetworks and (2) handling scarce clinical description via a symptom retrieval\nsystem. To this end, we first organize the EHR data into a heterogeneous graph\nthat is capable of modeling complex interactions among users, symptoms and\ndiseases, and tailor the graph representation learning towards disease\ndiagnosis with an inductive learning paradigm. Then, we build a disease\nself-diagnosis system with a corresponding EHR Graph-based Symptom Retrieval\nSystem (GraphRet) that can search and provide a list of relevant alternative\nsymptoms by tracing the predefined meta-paths. GraphRet helps enrich the seed\nsymptom set through the EHR graph when confronting users with scarce\ndescriptions, hence yield better diagnosis accuracy. At last, we validate the\nsuperiority of our model on a large-scale EHR dataset.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 01:32:14 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 01:47:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Wang", "Zifeng", ""], ["Wen", "Rui", ""], ["Chen", "Xi", ""], ["Cao", "Shilei", ""], ["Huang", "Shao-Lun", ""], ["Qian", "Buyue", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.02645", "submitter": "Liu Pai", "authors": "Pai Liu", "title": "QiaoNing at SemEval-2020 Task 4: Commonsense Validation and Explanation\n  system based on ensemble of language model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present language model system submitted to SemEval-2020\nTask 4 competition: \"Commonsense Validation and Explanation\". We participate in\ntwo subtasks for subtask A: validation and subtask B: Explanation. We\nimplemented with transfer learning using pretrained language models (BERT,\nXLNet, RoBERTa, and ALBERT) and fine-tune them on this task. Then we compared\ntheir characteristics in this task to help future researchers understand and\nuse these models more properly. The ensembled model better solves this problem,\nmaking the model's accuracy reached 95.9% on subtask A, which just worse than\nhuman's by only 3% accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:12:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Pai", ""]]}, {"id": "2009.02647", "submitter": "Qihang Zhao", "authors": "Qihang Zhao", "title": "Utilizing Citation Network Structure to Predict Citation Counts: A Deep\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of science and technology, the number of academic papers\npublished in the world each year has increased almost exponentially. While a\nlarge number of research papers highlight the prosperity of science and\ntechnology, they also give rise to some problems. As we all know, academic\npapers are the most intuitive embodiment of the research results of scholars,\nwhich can reflect the level of researchers. It is also the evaluation standard\nfor decision-making such as promotion and allocation of funds. Therefore, how\nto measure the quality of an academic paper is very important. The most common\nstandard for measuring academic papers is the number of citation counts of\npapers, because this indicator is widely used in the evaluation of scientific\npublications, and it also serves as the basis for many other indicators (such\nas the h-index). Therefore, it is very important to be able to accurately\npredict the citation counts of academic papers.\n  This paper proposes an end-to-end deep learning network, DeepCCP, which\ncombines the effect of information cascade and looks at the citation counts\nprediction problem from the perspective of information cascade prediction.\nDeepCCP directly uses the citation network formed in the early stage of the\npaper as the input, and the output is the citation counts of the corresponding\npaper after a period of time. DeepCCP only uses the structure and temporal\ninformation of the citation network, and does not require other additional\ninformation, but it can still achieve outstanding performance. According to\nexperiments on 6 real data sets, DeepCCP is superior to the state-of-the-art\nmethods in terms of the accuracy of citation count prediction.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:27:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhao", "Qihang", ""]]}, {"id": "2009.02672", "submitter": "Ke Wang", "authors": "Ke Wang, Sai Ma, Junlan Chen, Fan Ren", "title": "Approaches, Challenges, and Applications for Deep Visual Odometry:\n  Toward to Complicated and Emerging Areas", "comments": null, "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems. 2020", "doi": "10.1109/TCDS.2020.3038898", "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual odometry (VO) is a prevalent way to deal with the relative\nlocalization problem, which is becoming increasingly mature and accurate, but\nit tends to be fragile under challenging environments. Comparing with classical\ngeometry-based methods, deep learning-based methods can automatically learn\neffective and robust representations, such as depth, optical flow, feature,\nego-motion, etc., from data without explicit computation. Nevertheless, there\nstill lacks a thorough review of the recent advances of deep learning-based VO\n(Deep VO). Therefore, this paper aims to gain a deep insight on how deep\nlearning can profit and optimize the VO systems. We first screen out a number\nof qualifications including accuracy, efficiency, scalability, dynamicity,\npracticability, and extensibility, and employ them as the criteria. Then, using\nthe offered criteria as the uniform measurements, we detailedly evaluate and\ndiscuss how deep learning improves the performance of VO from the aspects of\ndepth estimation, feature extraction and matching, pose estimation. We also\nsummarize the complicated and emerging areas of Deep VO, such as mobile robots,\nmedical robots, augmented reality and virtual reality, etc. Through the\nliterature decomposition, analysis, and comparison, we finally put forward a\nnumber of open issues and raise some future research directions in this field.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:25:23 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wang", "Ke", ""], ["Ma", "Sai", ""], ["Chen", "Junlan", ""], ["Ren", "Fan", ""]]}, {"id": "2009.02707", "submitter": "Bryan M. Li", "authors": "Bryan M. Li, Theoklitos Amvrosiadis, Nathalie Rochefort, Arno Onken", "title": "CalciumGAN: A Generative Adversarial Network Model for Synthesising\n  Realistic Calcium Imaging Data of Neuronal Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging has become a powerful and popular technique to monitor the\nactivity of large populations of neurons in vivo. However, for ethical\nconsiderations and despite recent technical developments, recordings are still\nconstrained to a limited number of trials and animals. This limits the amount\nof data available from individual experiments and hinders the development of\nanalysis techniques and models for more realistic size of neuronal populations.\nThe ability to artificially synthesize realistic neuronal calcium signals could\ngreatly alleviate this problem by scaling up the number of trials. Here we\npropose a Generative Adversarial Network (GAN) model to generate realistic\ncalcium signals as seen in neuronal somata with calcium imaging. To this end,\nwe adapt the WaveGAN architecture and train it with the Wasserstein distance.\nWe test the model on artificial data with known ground-truth and show that the\ndistribution of the generated signals closely resembles the underlying data\ndistribution. Then, we train the model on real calcium signals recorded from\nthe primary visual cortex of behaving mice and confirm that the deconvolved\nspike trains match the statistics of the recorded data. Together, these results\ndemonstrate that our model can successfully generate realistic calcium imaging\ndata, thereby providing the means to augment existing datasets of neuronal\nactivity for enhanced data exploration and modeling.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:58:11 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 03:58:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Li", "Bryan M.", ""], ["Amvrosiadis", "Theoklitos", ""], ["Rochefort", "Nathalie", ""], ["Onken", "Arno", ""]]}, {"id": "2009.02728", "submitter": "Kailash Budhathoki", "authors": "Kailash Budhathoki, Mario Boley and Jilles Vreeken", "title": "Discovering Reliable Causal Rules", "comments": "Poster presented in NeurIPS 2018 Workshop on Causal Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of deriving policies, or rules, that when enacted on a\ncomplex system, cause a desired outcome. Absent the ability to perform\ncontrolled experiments, such rules have to be inferred from past observations\nof the system's behaviour. This is a challenging problem for two reasons:\nFirst, observational effects are often unrepresentative of the underlying\ncausal effect because they are skewed by the presence of confounding factors.\nSecond, naive empirical estimations of a rule's effect have a high variance,\nand, hence, their maximisation can lead to random results.\n  To address these issues, first we measure the causal effect of a rule from\nobservational data---adjusting for the effect of potential confounders.\nImportantly, we provide a graphical criteria under which causal rule discovery\nis possible. Moreover, to discover reliable causal rules from a sample, we\npropose a conservative and consistent estimator of the causal effect, and\nderive an efficient and exact algorithm that maximises the estimator. On\nsynthetic data, the proposed estimator converges faster to the ground truth\nthan the naive estimator and recovers relevant causal rules even at small\nsample sizes. Extensive experiments on a variety of real-world datasets show\nthat the proposed algorithm is efficient and discovers meaningful rules.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:08:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 07:53:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Budhathoki", "Kailash", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "2009.02731", "submitter": "Nghi D. Q. Bui", "authors": "Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang", "title": "Self-Supervised Contrastive Learning for Code Retrieval and\n  Summarization via Semantic-Preserving Transformations", "comments": "Accepted at SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462840", "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Corder, a self-supervised contrastive learning framework for\nsource code model. Corder is designed to alleviate the need of labeled data for\ncode retrieval and code summarization tasks. The pre-trained model of Corder\ncan be used in two ways: (1) it can produce vector representation of code which\ncan be applied to code retrieval tasks that do not have labeled data; (2) it\ncan be used in a fine-tuning process for tasks that might still require label\ndata such as code summarization. The key innovation is that we train the source\ncode model by asking it to recognize similar and dissimilar code snippets\nthrough a contrastive learning objective. To do so, we use a set of\nsemantic-preserving transformation operators to generate code snippets that are\nsyntactically diverse but semantically equivalent. Through extensive\nexperiments, we have shown that the code models pretrained by Corder\nsubstantially outperform the other baselines for code-to-code retrieval,\ntext-to-code retrieval, and code-to-text summarization tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:31:16 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 05:38:39 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 12:12:51 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 11:46:56 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 09:49:11 GMT"}, {"version": "v6", "created": "Sun, 2 May 2021 19:25:45 GMT"}, {"version": "v7", "created": "Mon, 17 May 2021 18:01:27 GMT"}, {"version": "v8", "created": "Sun, 23 May 2021 12:10:55 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "2009.02742", "submitter": "Quan-Lin Li", "authors": "Heng-Li Liu, Quan-Lin Li, Chi Zhang", "title": "Matched Queues with Matching Batch Pair (m, n)", "comments": "52 Pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2001.00946", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.AI cs.DC cs.NI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss an interesting but challenging bilateral\nstochastically matching problem: A more general matched queue with matching\nbatch pair (m, n) and two types (i.e., types A and B) of impatient customers,\nwhere the arrivals of A- and B-customers are both Poisson processes, m\nA-customers and n B-customers are matched as a group which leaves the system\nimmediately, and the customers' impatient behavior is to guarantee the\nstability of the system. We show that this matched queue can be expressed as a\nnovel bidirectional level-dependent quasi-birth-and-death (QBD) process. Based\non this, we provide a detailed analysis for this matched queue, including the\nsystem stability, the average stationary queue lengthes, and the average\nsojourn time of any A-customer or B-customer. We believe that the methodology\nand results developed in this paper can be applicable to dealing with more\ngeneral matched queueing systems, which are widely encountered in various\npractical areas, for example, sharing economy, ridesharing platform, bilateral\nmarket, organ transplantation, taxi services, assembly systems, and so on.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 14:14:47 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:51:22 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:03:29 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 07:23:08 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Liu", "Heng-Li", ""], ["Li", "Quan-Lin", ""], ["Zhang", "Chi", ""]]}, {"id": "2009.02759", "submitter": "Yongxiang Huang", "authors": "Yongxiang Huang and Albert C. S. Chung", "title": "Edge-variational Graph Convolutional Networks for Uncertainty-aware\n  Disease Prediction", "comments": "Accepted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rising need for computational models that can complementarily\nleverage data of different modalities while investigating associations between\nsubjects for population-based disease analysis. Despite the success of\nconvolutional neural networks in representation learning for imaging data, it\nis still a very challenging task. In this paper, we propose a generalizable\nframework that can automatically integrate imaging data with non-imaging data\nin populations for uncertainty-aware disease prediction. At its core is a\nlearnable adaptive population graph with variational edges, which we\nmathematically prove that it is optimizable in conjunction with graph\nconvolutional neural networks. To estimate the predictive uncertainty related\nto the graph topology, we propose the novel concept of Monte-Carlo edge\ndropout. Experimental results on four databases show that our method can\nconsistently and significantly improve the diagnostic accuracy for Autism\nspectrum disorder, Alzheimer's disease, and ocular diseases, indicating its\ngeneralizability in leveraging multimodal data for computer-aided diagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:53:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Huang", "Yongxiang", ""], ["Chung", "Albert C. S.", ""]]}, {"id": "2009.02762", "submitter": "Yue Yang", "authors": "Yue Yang, Wencang Bao, Mohsen Ramezani, Zhe Xu", "title": "Real-time and Large-scale Fleet Allocation of Autonomous Taxis: A Case\n  Study in New York Manhattan Island", "comments": "Double-check the formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous taxis become a highly promising transportation mode,\nwhich helps relieve traffic congestion and avoid road accidents. However, it\nhinders the wide implementation of this service that traditional models fail to\nefficiently allocate the available fleet to deal with the imbalance of supply\n(autonomous taxis) and demand (trips), the poor cooperation of taxis, hardly\nsatisfied resource constraints, and on-line platform's requirements. To figure\nout such urgent problems from a global and more farsighted view, we employ a\nConstrained Multi-agent Markov Decision Processes (CMMDP) to model fleet\nallocation decisions, which can be easily split into sub-problems formulated as\na 'Dynamic assignment problem' combining both immediate rewards and future\ngains. We also leverage a Column Generation algorithm to guarantee the\nefficiency and optimality in a large scale. Through extensive experiments, the\nproposed approach not only achieves remarkable improvements over the\nstate-of-the-art benchmarks in terms of the individual's efficiency (arriving\nat 12.40%, 6.54% rise of income and utilization, respectively) and the\nplatform's profit (reaching 4.59% promotion) but also reveals a time-varying\nfleet adjustment policy to minimize the operation cost of the platform.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:00:15 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 01:46:34 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Yang", "Yue", ""], ["Bao", "Wencang", ""], ["Ramezani", "Mohsen", ""], ["Xu", "Zhe", ""]]}, {"id": "2009.02763", "submitter": "Hao Li", "authors": "Chang Wang, Jian Liang, Mingkai Huang, Bing Bai, Kun Bai, Hao Li", "title": "Hybrid Differentially Private Federated Learning on Vertically\n  Partitioned Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HDP-VFL, the first hybrid differentially private (DP) framework\nfor vertical federated learning (VFL) to demonstrate that it is possible to\njointly learn a generalized linear model (GLM) from vertically partitioned data\nwith only a negligible cost, w.r.t. training time, accuracy, etc., comparing to\nidealized non-private VFL. Our work builds on the recent advances in VFL-based\ncollaborative training among different organizations which rely on protocols\nlike Homomorphic Encryption (HE) and Secure Multi-Party Computation (MPC) to\nsecure computation and training. In particular, we analyze how VFL's\nintermediate result (IR) can leak private information of the training data\nduring communication and design a DP-based privacy-preserving algorithm to\nensure the data confidentiality of VFL participants. We mathematically prove\nthat our algorithm not only provides utility guarantees for VFL, but also\noffers multi-level privacy, i.e. DP w.r.t. IR and joint differential privacy\n(JDP) w.r.t. model weights. Experimental results demonstrate that our work,\nunder adequate privacy budgets, is quantitatively and qualitatively similar to\nGLMs, learned in idealized non-private VFL setting, rather than the increased\ncost in memory and processing time in most prior works based on HE or MPC. Our\ncodes will be released if this paper is accepted.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 16:06:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Wang", "Chang", ""], ["Liang", "Jian", ""], ["Huang", "Mingkai", ""], ["Bai", "Bing", ""], ["Bai", "Kun", ""], ["Li", "Hao", ""]]}, {"id": "2009.02807", "submitter": "Kourosh Darvish", "authors": "Kourosh Darvish, Enrico Simetti, Fulvio Mastrogiovanni, Giuseppe\n  Casalino", "title": "A Hierarchical Architecture for Human-Robot Cooperation Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose FlexHRC+, a hierarchical human-robot cooperation\narchitecture designed to provide collaborative robots with an extended degree\nof autonomy when supporting human operators in high-variability shop-floor\ntasks. The architecture encompasses three levels, namely for perception,\nrepresentation, and action. Building up on previous work, here we focus on (i)\nan in-the-loop decision making process for the operations of collaborative\nrobots coping with the variability of actions carried out by human operators,\nand (ii) the representation level, integrating a hierarchical AND/OR graph\nwhose online behaviour is formally specified using First Order Logic. The\narchitecture is accompanied by experiments including collaborative furniture\nassembly and object positioning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 19:55:32 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Darvish", "Kourosh", ""], ["Simetti", "Enrico", ""], ["Mastrogiovanni", "Fulvio", ""], ["Casalino", "Giuseppe", ""]]}, {"id": "2009.02835", "submitter": "Denghui Zhang", "authors": "Denghui Zhang, Zixuan Yuan, Yanchi Liu, Zuohui Fu, Fuzhen Zhuang,\n  Pengyang Wang, Haifeng Chen, Hui Xiong", "title": "E-BERT: A Phrase and Product Knowledge Enhanced Language Model for\n  E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have achieved great success in a\nbroad range of natural language processing tasks. However, BERT cannot well\nsupport E-commerce related tasks due to the lack of two levels of domain\nknowledge, i.e., phrase-level and product-level. On one hand, many E-commerce\ntasks require an accurate understanding of domain phrases, whereas such\nfine-grained phrase-level knowledge is not explicitly modeled by BERT's\ntraining objective. On the other hand, product-level knowledge like product\nassociations can enhance the language modeling of E-commerce, but they are not\nfactual knowledge thus using them indiscriminately may introduce noise. To\ntackle the problem, we propose a unified pre-training framework, namely,\nE-BERT. Specifically, to preserve phrase-level knowledge, we introduce Adaptive\nHybrid Masking, which allows the model to adaptively switch from learning\npreliminary word knowledge to learning complex phrases, based on the fitting\nprogress of two modes. To utilize product-level knowledge, we introduce\nNeighbor Product Reconstruction, which trains E-BERT to predict a product's\nassociated neighbors with a denoising cross attention layer. Our investigation\nreveals promising results in four downstream tasks, i.e., review-based question\nanswering, aspect extraction, aspect sentiment classification, and product\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 00:15:36 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 23:00:16 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Zhang", "Denghui", ""], ["Yuan", "Zixuan", ""], ["Liu", "Yanchi", ""], ["Fu", "Zuohui", ""], ["Zhuang", "Fuzhen", ""], ["Wang", "Pengyang", ""], ["Chen", "Haifeng", ""], ["Xiong", "Hui", ""]]}, {"id": "2009.02899", "submitter": "Erico Tjoa", "authors": "Erico Tjoa, Cuntai Guan", "title": "Quantifying Explainability of Saliency Methods in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to achieve eXplainable artificial intelligence (XAI) is through the\nuse of post-hoc analysis methods. In particular, methods that generate heatmaps\nhave been used to explain black-box models, such as deep neural network. In\nsome cases, heatmaps are appealing due to the intuitive and visual ways to\nunderstand them. However, quantitative analysis that demonstrates the actual\npotential of heatmaps have been lacking, and comparison between different\nmethods are not standardized as well. In this paper, we introduce a synthetic\ndataset that can be generated adhoc along with the ground-truth heatmaps for\nbetter quantitative assessment. Each sample data is an image of a cell with\neasily distinguishable features, facilitating a more transparent assessment of\ndifferent XAI methods. Comparison and recommendations are made, shortcomings\nare clarified along with suggestions for future research directions to handle\nthe finer details of select post-hoc analysis methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 05:55:24 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:27:57 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 05:45:01 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Tjoa", "Erico", ""], ["Guan", "Cuntai", ""]]}, {"id": "2009.02963", "submitter": "Armand Boschin", "authors": "Armand Boschin", "title": "TorchKGE: Knowledge Graph Embedding in Python and PyTorch", "comments": "Paper presented at KDD-IWKG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TorchKGE is a Python module for knowledge graph (KG) embedding relying solely\non PyTorch. This package provides researchers and engineers with a clean and\nefficient API to design and test new models. It features a KG data structure,\nsimple model interfaces and modules for negative sampling and model evaluation.\nIts main strength is a very fast evaluation module for the link prediction\ntask, a central application of KG embedding. Various KG embedding models are\nalso already implemented. Special attention has been paid to code efficiency\nand simplicity, documentation and API consistency. It is distributed using PyPI\nunder BSD license. Source code and pointers to documentation and deployment can\nbe found at https://github.com/torchkge-team/torchkge.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:21:34 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Boschin", "Armand", ""]]}, {"id": "2009.02980", "submitter": "Guillaume Perez", "authors": "Guillaume Perez, Sebastian Ament, Carla Gomes, Michel Barlaud", "title": "Efficient Projection Algorithms onto the Weighted l1 Ball", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projected gradient descent has been proved efficient in many optimization and\nmachine learning problems. The weighted $\\ell_1$ ball has been shown effective\nin sparse system identification and features selection. In this paper we\npropose three new efficient algorithms for projecting any vector of finite\nlength onto the weighted $\\ell_1$ ball. The first two algorithms have a linear\nworst case complexity. The third one has a highly competitive performances in\npractice but the worst case has a quadratic complexity. These new algorithms\nare efficient tools for machine learning methods based on projected gradient\ndescent such as compress sensing, feature selection. We illustrate this\neffectiveness by adapting an efficient compress sensing algorithm to weighted\nprojections. We demonstrate the efficiency of our new algorithms on benchmarks\nusing very large vectors. For instance, it requires only 8 ms, on an Intel I7\n3rd generation, for projecting vectors of size $10^7$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:48:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Perez", "Guillaume", ""], ["Ament", "Sebastian", ""], ["Gomes", "Carla", ""], ["Barlaud", "Michel", ""]]}, {"id": "2009.02995", "submitter": "Markus Iser", "authors": "Markus Iser, Luca Springer, Carsten Sinz", "title": "Collaborative Management of Benchmark Instances and their Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LO cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evaluation is an integral part in the design process of\nalgorithms. Publicly available benchmark instances are widely used to evaluate\nmethods in SAT solving. For the interpretation of results and the design of\nalgorithm portfolios their attributes are crucial. Capturing the interrelation\nof benchmark instances and their attributes is considerably simplified through\nour specification of a benchmark instance identifier. Thus, our tool increases\nthe availability of both by providing means to manage and retrieve benchmark\ninstances by their attributes and vice versa. Like this, it facilitates the\ndesign and analysis of SAT experiments and the exchange of results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:23:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Iser", "Markus", ""], ["Springer", "Luca", ""], ["Sinz", "Carsten", ""]]}, {"id": "2009.02997", "submitter": "Filippo Bistaffa", "authors": "Filippo Bistaffa, Juan A. Rodr\\'iguez-Aguilar, Jes\\'us Cerquides", "title": "Predicting Requests in Large-Scale Online P2P Ridesharing", "comments": "Presented at the 1st International Workshop on Optimization and\n  Learning in Multiagent Systems (OptLearnMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer ridesharing (P2P-RS) enables people to arrange one-time rides\nwith their own private cars, without the involvement of professional drivers.\nIt is a prominent collective intelligence application producing significant\nbenefits both for individuals (reduced costs) and for the entire community\n(reduced pollution and traffic), as we showed in a recent publication where we\nproposed an online approximate solution algorithm for large-scale P2P-RS. In\nthis paper we tackle the fundamental question of assessing the benefit of\npredicting ridesharing requests in the context of P2P-RS optimisation. Results\non a public real-world show that, by employing a perfect predictor, the total\nreward can be improved by 5.27% with a forecast horizon of 1 minute. On the\nother hand, a vanilla long short-term memory neural network cannot improve upon\na baseline predictor that simply replicates the previous day's requests, whilst\nachieving an almost-double accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:27:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bistaffa", "Filippo", ""], ["Rodr\u00edguez-Aguilar", "Juan A.", ""], ["Cerquides", "Jes\u00fas", ""]]}, {"id": "2009.03005", "submitter": "Mohammed Al-Rawi", "authors": "Mohammed Al-Rawi and Joeran Beel", "title": "Towards an Interoperable Data Protocol Aimed at Linking the Fashion\n  Industry with AI Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fashion industry is looking forward to use artificial intelligence\ntechnologies to enhance their processes, services, and applications. Although\nthe amount of fashion data currently in use is increasing, there is a large gap\nin data exchange between the fashion industry and the related AI companies, not\nto mention the different structure used for each fashion dataset. As a result,\nAI companies are relying on manually annotated fashion data to build different\napplications. Furthermore, as of this writing, the terminology, vocabulary and\nmethods of data representation used to denote fashion items are still ambiguous\nand confusing. Hence, it is clear that the fashion industry and AI companies\nwill benefit from a protocol that allows them to exchange and organise fashion\ninformation in a unified way. To achieve this goal we aim (1) to define a\nprotocol called DDOIF that will allow interoperability of fashion data; (2) for\nDDOIF to contain diverse entities including extensive information on clothing\nand accessories attributes in the form of text and various media formats; and\n(3)To design and implement an API that includes, among other things, functions\nfor importing and exporting a file built according to the DDOIF protocol that\nstores all information about a single item of clothing. To this end, we\nidentified over 1000 class and subclass names used to name fashion items and\nuse them to build the DDOIF dictionary. We make DDOIF publicly available to all\ninterested users and developers and look forward to engaging more collaborators\nto improve and enrich it.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:40:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Al-Rawi", "Mohammed", ""], ["Beel", "Joeran", ""]]}, {"id": "2009.03009", "submitter": "Matin Hashemi", "authors": "Amir Amirinezhad, Saber Salehkaleybar, Matin Hashemi", "title": "Active Learning of Causal Structures with Deep Reinforcement Learning", "comments": "submitted for peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of experiment design to learn causal structures from\ninterventional data. We consider an active learning setting in which the\nexperimenter decides to intervene on one of the variables in the system in each\nstep and uses the results of the intervention to recover further causal\nrelationships among the variables. The goal is to fully identify the causal\nstructures with minimum number of interventions. We present the first deep\nreinforcement learning based solution for the problem of experiment design. In\nthe proposed method, we embed input graphs to vectors using a graph neural\nnetwork and feed them to another neural network which outputs a variable for\nperforming intervention in each step. Both networks are trained jointly via a\nQ-iteration algorithm. Experimental results show that the proposed method\nachieves competitive performance in recovering causal structures with respect\nto previous works, while significantly reducing execution time in dense graphs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:49:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Amirinezhad", "Amir", ""], ["Salehkaleybar", "Saber", ""], ["Hashemi", "Matin", ""]]}, {"id": "2009.03016", "submitter": "Luis Carlos Garcia-Peraza-Herrera", "authors": "Luis C. Garc\\'ia-Peraza-Herrera, Wenqi Li, Caspar Gruijthuijsen, Alain\n  Devreker, George Attilakos, Jan Deprest, Emmanuel Vander Poorten, Danail\n  Stoyanov, Tom Vercauteren, S\\'ebastien Ourselin", "title": "Real-Time Segmentation of Non-Rigid Surgical Tools based on Deep\n  Learning and Tracking", "comments": "Accepted in CARE Workshop, held in conjunction with MICCAI 2016", "journal-ref": null, "doi": "10.1007/978-3-319-54057-3_8", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time tool segmentation is an essential component in computer-assisted\nsurgical systems. We propose a novel real-time automatic method based on Fully\nConvolutional Networks (FCN) and optical flow tracking. Our method exploits the\nability of deep neural networks to produce accurate segmentations of highly\ndeformable parts along with the high speed of optical flow. Furthermore, the\npre-trained FCN can be fine-tuned on a small amount of medical images without\nthe need to hand-craft features. We validated our method using existing and new\nbenchmark datasets, covering both ex vivo and in vivo real clinical cases where\ndifferent surgical instruments are employed. Two versions of the method are\npresented, non-real-time and real-time. The former, using only deep learning,\nachieves a balanced accuracy of 89.6% on a real clinical dataset, outperforming\nthe (non-real-time) state of the art by 3.8% points. The latter, a combination\nof deep learning with optical flow tracking, yields an average balanced\naccuracy of 78.2% across all the validated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:06:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Garc\u00eda-Peraza-Herrera", "Luis C.", ""], ["Li", "Wenqi", ""], ["Gruijthuijsen", "Caspar", ""], ["Devreker", "Alain", ""], ["Attilakos", "George", ""], ["Deprest", "Jan", ""], ["Poorten", "Emmanuel Vander", ""], ["Stoyanov", "Danail", ""], ["Vercauteren", "Tom", ""], ["Ourselin", "S\u00e9bastien", ""]]}, {"id": "2009.03034", "submitter": "Minyoung Kim", "authors": "Minyoung Kim and Vladimir Pavlovic", "title": "Ordinal-Content VAE: Isolating Ordinal-Valued Content Factors in Deep\n  Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep representational learning, it is often desired to isolate a\nparticular factor (termed {\\em content}) from other factors (referred to as\n{\\em style}). What constitutes the content is typically specified by users\nthrough explicit labels in the data, while all unlabeled/unknown factors are\nregarded as style. Recently, it has been shown that such content-labeled data\ncan be effectively exploited by modifying the deep latent factor models (e.g.,\nVAE) such that the style and content are well separated in the latent\nrepresentations. However, the approach assumes that the content factor is\ncategorical-valued (e.g., subject ID in face image data, or digit class in the\nMNIST dataset). In certain situations, the content is ordinal-valued, that is,\nthe values the content factor takes are {\\em ordered} rather than categorical,\nmaking content-labeled VAEs, including the latent space they infer, suboptimal.\nIn this paper, we propose a novel extension of VAE that imposes a partially\nordered set (poset) structure in the content latent space, while simultaneously\nmaking it aligned with the ordinal content values. To this end, instead of the\niid Gaussian latent prior adopted in prior approaches, we introduce a\nconditional Gaussian spacing prior model. This model admits a tractable joint\nGaussian prior, but also effectively places negligible density values on the\ncontent latent configurations that violate the poset constraint. To evaluate\nthis model, we consider two specific ordinal structured problems: estimating a\nsubject's age in a face image and elucidating the calorie amount in a food meal\nimage. We demonstrate significant improvements in content-style separation over\nprevious non-ordinal approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:59:27 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kim", "Minyoung", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2009.03088", "submitter": "Liadh Kelly", "authors": "Liadh Kelly and Simone van der Burg and Aine Regan and Peter Mooney", "title": "Report on the 2019 Workshop on Smart Farming and Data Analytics (SFDAI)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 1st National workshop on Smart Farming and Data Analytics took place at\nMaynooth University in Ireland on June 12, 2019. The workshop included two\ninvited keynote presentations, invited talks and breakout group discussions.\nThe workshop attracted in the order of 50 participants, consisting of a mixture\nof computer scientists, general scientists, farmers, farm advisors, and\nagricultural business representatives. This allowed for lively discussion and\ncross-fertilization of ideas. And showed the significant interest in the smart\nfarming domain, the many research challenges faced in the space and the\npotential for data analytics and information retrieval here.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:17:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kelly", "Liadh", ""], ["van der Burg", "Simone", ""], ["Regan", "Aine", ""], ["Mooney", "Peter", ""]]}, {"id": "2009.03095", "submitter": "Su Zhu", "authors": "Chen Liu, Su Zhu, Lu Chen and Kai Yu", "title": "Robust Spoken Language Understanding with RL-based Value Error Recovery", "comments": "Accepted to NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) aims to extract structured semantic\nrepresentations (e.g., slot-value pairs) from speech recognized texts, which\nsuffers from errors of Automatic Speech Recognition (ASR). To alleviate the\nproblem caused by ASR-errors, previous works may apply input adaptations to the\nspeech recognized texts, or correct ASR errors in predicted values by searching\nthe most similar candidates in pronunciation. However, these two methods are\napplied separately and independently. In this work, we propose a new robust SLU\nframework to guide the SLU input adaptation with a rule-based value error\nrecovery module. The framework consists of a slot tagging model and a\nrule-based value error recovery module. We pursue on an adapted slot tagging\nmodel which can extract potential slot-value pairs mentioned in ASR hypotheses\nand is suitable for the existing value error recovery module. After the value\nerror recovery, we can achieve a supervision signal (reward) by comparing\nrefined slot-value pairs with annotations. Since operations of the value error\nrecovery are non-differentiable, we exploit policy gradient based Reinforcement\nLearning (RL) to optimize the SLU model. Extensive experiments on the public\nCATSLU dataset show the effectiveness of our proposed approach, which can\nimprove the robustness of SLU and outperform the baselines by significant\nmargins.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:32:07 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Chen", ""], ["Zhu", "Su", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2009.03098", "submitter": "Min Cao", "authors": "Min Cao, Chen Chen, Hao Dou, Xiyuan Hu, Silong Peng and Arjan Kuijper", "title": "Progressive Bilateral-Context Driven Model for Post-Processing Person\n  Re-Identification", "comments": null, "journal-ref": "Transactions on Multimedia 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing person re-identification methods compute pairwise similarity by\nextracting robust visual features and learning the discriminative metric. Owing\nto visual ambiguities, these content-based methods that determine the pairwise\nrelationship only based on the similarity between them, inevitably produce a\nsuboptimal ranking list. Instead, the pairwise similarity can be estimated more\naccurately along the geodesic path of the underlying data manifold by exploring\nthe rich contextual information of the sample. In this paper, we propose a\nlightweight post-processing person re-identification method in which the\npairwise measure is determined by the relationship between the sample and the\ncounterpart's context in an unsupervised way. We translate the point-to-point\ncomparison into the bilateral point-to-set comparison. The sample's context is\ncomposed of its neighbor samples with two different definition ways: the first\norder context and the second order context, which are used to compute the\npairwise similarity in sequence, resulting in a progressive post-processing\nmodel. The experiments on four large-scale person re-identification benchmark\ndatasets indicate that (1) the proposed method can consistently achieve higher\naccuracies by serving as a post-processing procedure after the content-based\nperson re-identification methods, showing its state-of-the-art results, (2) the\nproposed lightweight method only needs about 6 milliseconds for optimizing the\nranking results of one sample, showing its high-efficiency. Code is available\nat: https://github.com/123ci/PBCmodel.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:35:09 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Cao", "Min", ""], ["Chen", "Chen", ""], ["Dou", "Hao", ""], ["Hu", "Xiyuan", ""], ["Peng", "Silong", ""], ["Kuijper", "Arjan", ""]]}, {"id": "2009.03107", "submitter": "Tong Liu", "authors": "Tong Liu, Roberto Amadini, Jacopo Mauro, Maurizio Gabbrielli", "title": "sunny-as2: Enhancing SUNNY for Algorithm Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SUNNY is an Algorithm Selection (AS) technique originally tailored for\nConstraint Programming (CP). SUNNY enables to schedule, from a portfolio of\nsolvers, a subset of solvers to be run on a given CP problem. This approach has\nproved to be effective for CP problems, and its parallel version won many gold\nmedals in the Open category of the MiniZinc Challenge -- the yearly\ninternational competition for CP solvers. In 2015, the ASlib benchmarks were\nreleased for comparing AS systems coming from disparate fields (e.g., ASP, QBF,\nand SAT) and SUNNY was extended to deal with generic AS problems. This led to\nthe development of sunny-as2, an algorithm selector based on SUNNY for ASlib\nscenarios. A preliminary version of sunny-as2 was submitted to the Open\nAlgorithm Selection Challenge (OASC) in 2017, where it turned out to be the\nbest approach for the runtime minimization of decision problems. In this work,\nwe present the technical advancements of sunny-as2, including: (i)\nwrapper-based feature selection; (ii) a training approach combining feature\nselection and neighbourhood size configuration; (iii) the application of nested\ncross-validation. We show how sunny-as2 performance varies depending on the\nconsidered AS scenarios, and we discuss its strengths and weaknesses. Finally,\nwe also show how sunny-as2 improves on its preliminary version submitted to\nOASC.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:55:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Tong", ""], ["Amadini", "Roberto", ""], ["Mauro", "Jacopo", ""], ["Gabbrielli", "Maurizio", ""]]}, {"id": "2009.03137", "submitter": "Qingyong Hu", "authors": "Qingyong Hu, Bo Yang, Sheikh Khalid, Wen Xiao, Niki Trigoni, Andrew\n  Markham", "title": "Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset,\n  Benchmarks and Challenges", "comments": "CVPR 2021, Code: https://github.com/QingyongHu/SensatUrban", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential prerequisite for unleashing the potential of supervised deep\nlearning algorithms in the area of 3D scene understanding is the availability\nof large-scale and richly annotated datasets. However, publicly available\ndatasets are either in relative small spatial scales or have limited semantic\nannotations due to the expensive cost of data acquisition and data annotation,\nwhich severely limits the development of fine-grained semantic understanding in\nthe context of 3D point clouds. In this paper, we present an urban-scale\nphotogrammetric point cloud dataset with nearly three billion richly annotated\npoints, which is three times the number of labeled points than the existing\nlargest photogrammetric point cloud dataset. Our dataset consists of large\nareas from three UK cities, covering about 7.6 km^2 of the city landscape. In\nthe dataset, each 3D point is labeled as one of 13 semantic classes. We\nextensively evaluate the performance of state-of-the-art algorithms on our\ndataset and provide a comprehensive analysis of the results. In particular, we\nidentify several key challenges towards urban-scale point cloud understanding.\nThe dataset is available at https://github.com/QingyongHu/SensatUrban.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:47:07 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 06:36:14 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 04:19:34 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Hu", "Qingyong", ""], ["Yang", "Bo", ""], ["Khalid", "Sheikh", ""], ["Xiao", "Wen", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "2009.03183", "submitter": "Vincent Grari", "authors": "Vincent Grari, Oualid El Hajouji, Sylvain Lamprier, Marcin Detyniecki", "title": "Learning Unbiased Representations via R\\'enyi Minimization", "comments": "23 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant work has been done to include fairness\nconstraints in the training objective of machine learning algorithms. Many\nstate-of the-art algorithms tackle this challenge by learning a fair\nrepresentation which captures all the relevant information to predict the\noutput Y while not containing any information about a sensitive attribute S. In\nthis paper, we propose an adversarial algorithm to learn unbiased\nrepresentations via the Hirschfeld-Gebelein-Renyi (HGR) maximal correlation\ncoefficient. We leverage recent work which has been done to estimate this\ncoefficient by learning deep neural network transformations and use it as a\nminmax game to penalize the intrinsic bias in a multi dimensional latent\nrepresentation. Compared to other dependence measures, the HGR coefficient\ncaptures more information about the non-linear dependencies with the sensitive\nvariable, making the algorithm more efficient in mitigating bias in the\nrepresentation. We empirically evaluate and compare our approach and\ndemonstrate significant improvements over existing works in the field.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:48:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Grari", "Vincent", ""], ["Hajouji", "Oualid El", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2009.03193", "submitter": "Azlan Iqbal", "authors": "Azlan Iqbal", "title": "An Algorithm for Automatically Updating a Forsyth-Edwards Notation\n  String Without an Array Board Representation", "comments": "6 pages, 6 figures, 4 tables, 1 appendix section; presented at the\n  8th International Conference on Information Technology and Multimedia on 24th\n  August 2020 (final version published by IEEE Xplore)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that correctly updates the Forsyth-Edwards Notation\n(FEN) chessboard character string after any move is made without the need for\nan intermediary array representation of the board. In particular, this relates\nto software that have to do with chess, certain chess variants and possibly\neven similar board games with comparable position representation. Even when\nperformance may be equal or inferior to using arrays, the algorithm still\nprovides an accurate and viable alternative to accomplishing the same thing, or\nwhen there may be a need for additional or side processing in conjunction with\narrays. Furthermore, the end result (i.e. an updated FEN string) is immediately\nready for export to any other internal module or external program, unlike with\nan intermediary array which needs to be first converted into a FEN string for\nexport purposes. The algorithm is especially useful when there are no existing\narray-based modules to represent a visual board as it can do without them\nentirely. We provide examples that demonstrate the correctness of the algorithm\ngiven a variety of positions involving castling, en passant and pawn promotion.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:13:58 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 04:26:35 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Iqbal", "Azlan", ""]]}, {"id": "2009.03228", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias and Francisco J. R. Ruiz and Sotirios\n  Nikoloutsopoulos and Alexandre Galashov", "title": "Information Theoretic Meta Learning with Gaussian Processes", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate meta learning using information theoretic concepts; namely,\nmutual information and the information bottleneck. The idea is to learn a\nstochastic representation or encoding of the task description, given by a\ntraining set, that is highly informative about predicting the validation set.\nBy making use of variational approximations to the mutual information, we\nderive a general and tractable framework for meta learning. This framework\nunifies existing gradient-based algorithms and also allows us to derive new\nalgorithms. In particular, we develop a memory-based algorithm that uses\nGaussian processes to obtain non-parametric encoding representations. We\ndemonstrate our method on a few-shot regression problem and on four few-shot\nclassification problems, obtaining competitive accuracy when compared to\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:47:30 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 13:40:54 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 12:26:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Ruiz", "Francisco J. R.", ""], ["Nikoloutsopoulos", "Sotirios", ""], ["Galashov", "Alexandre", ""]]}, {"id": "2009.03231", "submitter": "Samyak Datta", "authors": "Samyak Datta, Oleksandr Maksymets, Judy Hoffman, Stefan Lee, Dhruv\n  Batra, Devi Parikh", "title": "Integrating Egocentric Localization for More Realistic Point-Goal\n  Navigation Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has presented embodied agents that can navigate to point-goal\ntargets in novel indoor environments with near-perfect accuracy. However, these\nagents are equipped with idealized sensors for localization and take\ndeterministic actions. This setting is practically sterile by comparison to the\ndirty reality of noisy sensors and actuations in the real world -- wheels can\nslip, motion sensors have error, actuations can rebound. In this work, we take\na step towards this noisy reality, developing point-goal navigation agents that\nrely on visual estimates of egomotion under noisy action dynamics. We find\nthese agents outperform naive adaptions of current point-goal agents to this\nsetting as well as those incorporating classic localization baselines. Further,\nour model conceptually divides learning agent dynamics or odometry (where am\nI?) from task-specific navigation policy (where do I want to go?). This enables\na seamless adaption to changing dynamics (a different robot or floor type) by\nsimply re-calibrating the visual odometry model -- circumventing the expense of\nre-training of the navigation policy. Our agent was the runner-up in the\nPointNav track of CVPR 2020 Habitat Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:52:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Datta", "Samyak", ""], ["Maksymets", "Oleksandr", ""], ["Hoffman", "Judy", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "2009.03268", "submitter": "Teng Liu", "authors": "Hong Shu, Teng Liu, Xingyu Mu, Dongpu Cao", "title": "Driving Tasks Transfer in Deep Reinforcement Learning for\n  Decision-making of Autonomous Vehicles", "comments": "10 pages 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge transfer is a promising concept to achieve real-time\ndecision-making for autonomous vehicles. This paper constructs a transfer deep\nreinforcement learning framework to transform the driving tasks in\ninter-section environments. The driving missions at the un-signalized\nintersection are cast into a left turn, right turn, and running straight for\nautomated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive\nthrough the intersection situation efficiently and safely. This objective\npromotes the studied vehicle to increase its speed and avoid crashing other\nvehicles. The decision-making pol-icy learned from one driving task is\ntransferred and evaluated in another driving mission. Simulation results reveal\nthat the decision-making strategies related to similar tasks are transferable.\nIt indicates that the presented control framework could reduce the time\nconsumption and realize online implementation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:34:01 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 14:16:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Shu", "Hong", ""], ["Liu", "Teng", ""], ["Mu", "Xingyu", ""], ["Cao", "Dongpu", ""]]}, {"id": "2009.03289", "submitter": "Teng Liu", "authors": "Teng Liu, Bo Wang, Wenhao Tan, Shaobo Lu, Yalian Yang", "title": "Data-Driven Transferred Energy Management Strategy for Hybrid Electric\n  Vehicles via Deep Reinforcement Learning", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time applications of energy management strategies (EMSs) in hybrid\nelectric vehicles (HEVs) are the harshest requirements for researchers and\nengineers. Inspired by the excellent problem-solving capabilities of deep\nreinforcement learning (DRL), this paper proposes a real-time EMS via\nincorporating the DRL method and transfer learning (TL). The related EMSs are\nderived from and evaluated on the real-world collected driving cycle dataset\nfrom Transportation Secure Data Center (TSDC). The concrete DRL algorithm is\nproximal policy optimization (PPO) belonging to the policy gradient (PG)\ntechniques. For specification, many source driving cycles are utilized for\ntraining the parameters of deep network based on PPO. The learned parameters\nare transformed into the target driving cycles under the TL framework. The EMSs\nrelated to the target driving cycles are estimated and compared in different\ntraining conditions. Simulation results indicate that the presented transfer\nDRL-based EMS could effectively reduce time consumption and guarantee control\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:53:07 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 16:24:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Teng", ""], ["Wang", "Bo", ""], ["Tan", "Wenhao", ""], ["Lu", "Shaobo", ""], ["Yang", "Yalian", ""]]}, {"id": "2009.03300", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika,\n  Dawn Song, Jacob Steinhardt", "title": "Measuring Massive Multitask Language Understanding", "comments": "ICLR 2021; the test and code is available at\n  https://github.com/hendrycks/test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new test to measure a text model's multitask accuracy. The test\ncovers 57 tasks including elementary mathematics, US history, computer science,\nlaw, and more. To attain high accuracy on this test, models must possess\nextensive world knowledge and problem solving ability. We find that while most\nrecent models have near random-chance accuracy, the very largest GPT-3 model\nimproves over random chance by almost 20 percentage points on average. However,\non every one of the 57 tasks, the best models still need substantial\nimprovements before they can reach expert-level accuracy. Models also have\nlopsided performance and frequently do not know when they are wrong. Worse,\nthey still have near-random accuracy on some socially important subjects such\nas morality and law. By comprehensively evaluating the breadth and depth of a\nmodel's academic and professional understanding, our test can be used to\nanalyze models across many tasks and to identify important shortcomings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:59:25 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 05:06:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:11 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Zou", "Andy", ""], ["Mazeika", "Mantas", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2009.03301", "submitter": "Maria Elli", "authors": "Jack Weast", "title": "Sensors, Safety Models and A System-Level Approach to Safe and Scalable\n  Automated Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering the accuracy of sensors in an automated vehicle (AV), it is\nnot sufficient to evaluate the performance of any given sensor in isolation.\nRather, the performance of any individual sensor must be considered in the\ncontext of the overall system design. Techniques like redundancy and different\nsensing modalities can reduce the chances of a sensing failure. Additionally,\nthe use of safety models is essential to understanding whether any particular\nsensing failure is relevant. Only when the entire system design is taken into\naccount can one properly understand the meaning of safety-relevant sensing\nfailures in an AV. In this paper, we will consider what should actually\nconstitute a sensing failure, how safety models play an important role in\nmitigating potential failures, how a system-level approach to safety will\ndeliver a safe and scalable AV, and what an acceptable sensing failure rate\nshould be considering the full picture of an AV's architecture.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 20:14:59 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Weast", "Jack", ""]]}, {"id": "2009.03352", "submitter": "Jin Cao", "authors": "Jin Cao and Dewei Zhong", "title": "A Fast Randomized Algorithm for Finding the Maximal Common Subsequences", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the common subsequences of $L$ multiple strings has many applications\nin the area of bioinformatics, computational linguistics, and information\nretrieval. A well-known result states that finding a Longest Common Subsequence\n(LCS) for $L$ strings is NP-hard, e.g., the computational complexity is\nexponential in $L$. In this paper, we develop a randomized algorithm, referred\nto as {\\em Random-MCS}, for finding a random instance of Maximal Common\nSubsequence ($MCS$) of multiple strings. A common subsequence is {\\em maximal}\nif inserting any character into the subsequence no longer yields a common\nsubsequence. A special case of MCS is LCS where the length is the longest. We\nshow the complexity of our algorithm is linear in $L$, and therefore is\nsuitable for large $L$. Furthermore, we study the occurrence probability for a\nsingle instance of MCS and demonstrate via both theoretical and experimental\nstudies that the longest subsequence from multiple runs of {\\em Random-MCS}\noften yields a solution to $LCS$.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:12:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Cao", "Jin", ""], ["Zhong", "Dewei", ""]]}, {"id": "2009.03393", "submitter": "Stanislas Polu", "authors": "Stanislas Polu, Ilya Sutskever", "title": "Generative Language Modeling for Automated Theorem Proving", "comments": "15+5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of transformer-based language models to automated\ntheorem proving. This work is motivated by the possibility that a major\nlimitation of automated theorem provers compared to humans -- the generation of\noriginal mathematical terms -- might be addressable via generation from\nlanguage models. We present an automated prover and proof assistant, GPT-f, for\nthe Metamath formalization language, and analyze its performance. GPT-f found\nnew short proofs that were accepted into the main Metamath library, which is to\nour knowledge, the first time a deep-learning based system has contributed\nproofs that were adopted by a formal mathematics community.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:50:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Polu", "Stanislas", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2009.03397", "submitter": "Jason Angel", "authors": "Jason Angel, Segun Taofeek Aroyehun, Antonio Tamayo and Alexander\n  Gelbukh", "title": "NLP-CIC at SemEval-2020 Task 9: Analysing sentiment in code-switching\n  language using a simple deep-learning classifier", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code-switching is a phenomenon in which two or more languages are used in the\nsame message. Nowadays, it is quite common to find messages with languages\nmixed in social media. This phenomenon presents a challenge for sentiment\nanalysis. In this paper, we use a standard convolutional neural network model\nto predict the sentiment of tweets in a blend of Spanish and English languages.\nOur simple approach achieved a F1-score of 0.71 on test set on the competition.\nWe analyze our best model capabilities and perform error analysis to expose\nimportant difficulties for classifying sentiment in a code-switching setting.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:57:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Angel", "Jason", ""], ["Aroyehun", "Segun Taofeek", ""], ["Tamayo", "Antonio", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "2009.03420", "submitter": "Federico Cerutti", "authors": "Marc Roig Vilamala, Harrison Taylor, Tianwei Xing, Luis Garcia, Mani\n  Srivastava, Lance Kaplan, Alun Preece, Angelika Kimmig, Federico Cerutti", "title": "A Hybrid Neuro-Symbolic Approach for Complex Event Processing", "comments": "Accepted as extended abstract at ICLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a model to detect patterns of interrelated events that form\nsituations of interest can be a complex problem: such situations tend to be\nuncommon, and only sparse data is available. We propose a hybrid neuro-symbolic\narchitecture based on Event Calculus that can perform Complex Event Processing\n(CEP). It leverages both a neural network to interpret inputs and logical rules\nthat express the pattern of the complex event. Our approach is capable of\ntraining with much fewer labelled data than a pure neural network approach, and\nto learn to classify individual events even when training in an end-to-end\nmanner. We demonstrate this comparing our approach against a pure neural\nnetwork approach on a dataset based on Urban Sounds 8K.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 21:05:51 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 09:56:50 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 21:08:17 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Vilamala", "Marc Roig", ""], ["Taylor", "Harrison", ""], ["Xing", "Tianwei", ""], ["Garcia", "Luis", ""], ["Srivastava", "Mani", ""], ["Kaplan", "Lance", ""], ["Preece", "Alun", ""], ["Kimmig", "Angelika", ""], ["Cerutti", "Federico", ""]]}, {"id": "2009.03456", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Yezhen Wang, Bo Li, Bichen Wu, Yang Gao, Pengfei Xu,\n  Trevor Darrell, Kurt Keutzer", "title": "ePointDA: An End-to-End Simulation-to-Real Domain Adaptation Framework\n  for LiDAR Point Cloud Segmentation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its robust and precise distance measurements, LiDAR plays an important\nrole in scene understanding for autonomous driving. Training deep neural\nnetworks (DNNs) on LiDAR data requires large-scale point-wise annotations,\nwhich are time-consuming and expensive to obtain. Instead, simulation-to-real\ndomain adaptation (SRDA) trains a DNN using unlimited synthetic data with\nautomatically generated labels and transfers the learned model to real\nscenarios. Existing SRDA methods for LiDAR point cloud segmentation mainly\nemploy a multi-stage pipeline and focus on feature-level alignment. They\nrequire prior knowledge of real-world statistics and ignore the pixel-level\ndropout noise gap and the spatial feature gap between different domains. In\nthis paper, we propose a novel end-to-end framework, named ePointDA, to address\nthe above issues. Specifically, ePointDA consists of three modules:\nself-supervised dropout noise rendering, statistics-invariant and\nspatially-adaptive feature alignment, and transferable segmentation learning.\nThe joint optimization enables ePointDA to bridge the domain shift at the\npixel-level by explicitly rendering dropout noise for synthetic LiDAR and at\nthe feature-level by spatially aligning the features between different domains,\nwithout requiring the real-world statistics. Extensive experiments adapting\nfrom synthetic GTA-LiDAR to real KITTI and SemanticKITTI demonstrate the\nsuperiority of ePointDA for LiDAR point cloud segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:46:08 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 16:52:41 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhao", "Sicheng", ""], ["Wang", "Yezhen", ""], ["Li", "Bo", ""], ["Wu", "Bichen", ""], ["Gao", "Yang", ""], ["Xu", "Pengfei", ""], ["Darrell", "Trevor", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2009.03457", "submitter": "Jianfeng Gao", "authors": "Jianfeng Gao, Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh,\n  Lars Liden, Heung-Yeung Shum", "title": "Robust Conversational AI with Grounded Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a hybrid approach based on a Grounded Text Generation\n(GTG) model to building robust task bots at scale. GTG is a hybrid model which\nuses a large-scale Transformer neural network as its backbone, combined with\nsymbol-manipulation modules for knowledge base inference and prior knowledge\nencoding, to generate responses grounded in dialog belief state and real-world\nknowledge for task completion. GTG is pre-trained on large amounts of raw text\nand human conversational data, and can be fine-tuned to complete a wide range\nof tasks.\n  The hybrid approach and its variants are being developed simultaneously by\nmultiple research teams. The primary results reported on task-oriented dialog\nbenchmarks are very promising, demonstrating the big potential of this\napproach. This article provides an overview of this progress and discusses\nrelated methods and technologies that can be incorporated for building robust\nconversational AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:49:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gao", "Jianfeng", ""], ["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Li", "Jinchao", ""], ["Shayandeh", "Shahin", ""], ["Liden", "Lars", ""], ["Shum", "Heung-Yeung", ""]]}, {"id": "2009.03488", "submitter": "Jintang Li", "authors": "Jintang Li, Tao Xie, Liang Chen, Fenfang Xie, Xiangnan He, Zibin Zheng", "title": "Adversarial Attack on Large Scale Graph", "comments": "Accepted by TKDE, the codes are availiable at\n  https://github.com/EdisonLeeeee/SGAttack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that graph neural networks (GNNs) are vulnerable\nagainst perturbations due to lack of robustness and can therefore be easily\nfooled. Currently, most works on attacking GNNs are mainly using gradient\ninformation to guide the attack and achieve outstanding performance. However,\nthe high complexity of time and space makes them unmanageable for large scale\ngraphs and becomes the major bottleneck that prevents the practical usage. We\nargue that the main reason is that they have to use the whole graph for\nattacks, resulting in the increasing time and space complexity as the data\nscale grows. In this work, we propose an efficient Simplified Gradient-based\nAttack (SGA) method to bridge this gap. SGA can cause the GNNs to misclassify\nspecific target nodes through a multi-stage attack framework, which needs only\na much smaller subgraph. In addition, we present a practical metric named\nDegree Assortativity Change (DAC) to measure the impacts of adversarial attacks\non graph data. We evaluate our attack method on four real-world graph networks\nby attacking several commonly used GNNs. The experimental results demonstrate\nthat SGA can achieve significant time and memory efficiency improvements while\nmaintaining competitive attack performance compared to state-of-art attack\ntechniques. Codes are available via: https://github.com/EdisonLeeeee/SGAttack.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 02:17:55 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 14:15:27 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Li", "Jintang", ""], ["Xie", "Tao", ""], ["Chen", "Liang", ""], ["Xie", "Fenfang", ""], ["He", "Xiangnan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2009.03534", "submitter": "Hyungjun Kim", "authors": "Eunho Koo and Hyungjun Kim", "title": "Empirical Strategy for Stretching Probability Distribution in\n  Neural-network-based Regression", "comments": "13 pages, 4 figures, to be submitted to Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis under artificial neural networks, the prediction\nperformance depends on determining the appropriate weights between layers. As\nrandomly initialized weights are updated during back-propagation using the\ngradient descent procedure under a given loss function, the loss function\nstructure can affect the performance significantly. In this study, we\nconsidered the distribution error, i.e., the inconsistency of two distributions\n(those of the predicted values and label), as the prediction error, and\nproposed weighted empirical stretching (WES) as a novel loss function to\nincrease the overlap area of the two distributions. The function depends on the\ndistribution of a given label, thus, it is applicable to any distribution\nshape. Moreover, it contains a scaling hyperparameter such that the appropriate\nparameter value maximizes the common section of the two distributions. To test\nthe function capability, we generated ideal distributed curves (unimodal,\nskewed unimodal, bimodal, and skewed bimodal) as the labels, and used the\nFourier-extracted input data from the curves under a feedforward neural\nnetwork. In general, WES outperformed loss functions in wide use, and the\nperformance was robust to the various noise levels. The improved results in\nRMSE for the extreme domain (i.e., both tail regions of the distribution) are\nexpected to be utilized for prediction of abnormal events in non-linear complex\nsystems such as natural disaster and financial crisis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 06:08:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Koo", "Eunho", ""], ["Kim", "Hyungjun", ""]]}, {"id": "2009.03558", "submitter": "Zhiyu Xue", "authors": "Zhiyu Xue, Lixin Duan, Wen Li, Lin Chen and Jiebo Luo", "title": "Region Comparison Network for Interpretable Few-shot Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has been successfully applied to many real-world computer\nvision tasks, training robust classifiers usually requires a large amount of\nwell-labeled data. However, the annotation is often expensive and\ntime-consuming. Few-shot image classification has thus been proposed to\neffectively use only a limited number of labeled examples to train models for\nnew classes. Recent works based on transferable metric learning methods have\nachieved promising classification performance through learning the similarity\nbetween the features of samples from the query and support sets. However, rare\nof them explicitly considers the model interpretability, which can actually be\nrevealed during the training phase.\n  For that, in this work, we propose a metric learning based method named\nRegion Comparison Network (RCN), which is able to reveal how few-shot learning\nworks as in a neural network as well as to find out specific regions that are\nrelated to each other in images coming from the query and support sets.\nMoreover, we also present a visualization strategy named Region Activation\nMapping (RAM) to intuitively explain what our method has learned by visualizing\nintermediate variables in our network. We also present a new way to generalize\nthe interpretability from the level of tasks to categories, which can also be\nviewed as a method to find the prototypical parts for supporting the final\ndecision of our RCN. Extensive experiments on four benchmark datasets clearly\nshow the effectiveness of our method over existing baselines.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 07:29:05 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Xue", "Zhiyu", ""], ["Duan", "Lixin", ""], ["Li", "Wen", ""], ["Chen", "Lin", ""], ["Luo", "Jiebo", ""]]}, {"id": "2009.03561", "submitter": "Emiliano De Cristofaro", "authors": "Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro", "title": "Toward Robustness and Privacy in Federated Learning: Experimenting with\n  Local and Central Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) allows multiple participants to train machine\nlearning models collaboratively by keeping their datasets local and only\nexchanging model updates. Alas, recent work highlighted several privacy and\nrobustness weaknesses in FL, presenting, respectively, membership/property\ninference and backdoor attacks. In this paper, we investigate to what extent\nDifferential Privacy (DP) can be used to protect not only privacy but also\nrobustness in FL.\n  We present a first-of-its-kind empirical evaluation of Local and Central\nDifferential Privacy (LDP/CDP) techniques in FL, assessing their feasibility\nand effectiveness. We show that both DP variants do defend against backdoor\nattacks, with varying levels of protection and utility, and overall much more\neffectively than previously proposed defenses. They also mitigate white-box\nmembership inference attacks in FL, and our work is the first to show how\neffectively; neither, however, provides viable defenses against property\ninference. Our work also provides a re-usable measurement framework to quantify\nthe trade-offs between robustness/privacy and utility in differentially private\nFL.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 07:37:23 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 15:13:53 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 08:37:16 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Naseri", "Mohammad", ""], ["Hayes", "Jamie", ""], ["De Cristofaro", "Emiliano", ""]]}, {"id": "2009.03567", "submitter": "Manuel Camargo", "authors": "Manuel Camargo, Marlon Dumas, Oscar Gonzalez-Rojas", "title": "Discovering Generative Models from Event Logs: Data-driven Simulation vs\n  Deep Learning", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generative model is a statistical model that is able to generate new data\ninstances from previously observed ones. In the context of business processes,\na generative model creates new execution traces from a set of historical\ntraces, also known as an event log. Two families of generative process\nsimulation models have been developed in previous work: data-driven simulation\nmodels and deep learning models. Until now, these two approaches have evolved\nindependently and their relative performance has not been studied. This paper\nfills this gap by empirically comparing a data-driven simulation technique with\nmultiple deep learning techniques, which construct models are capable of\ngenerating execution traces with timestamped events. The study sheds light into\nthe relative strengths of both approaches and raises the prospect of developing\nhybrid approaches that combine these strengths.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:04:06 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Camargo", "Manuel", ""], ["Dumas", "Marlon", ""], ["Gonzalez-Rojas", "Oscar", ""]]}, {"id": "2009.03587", "submitter": "Franck Delaplace", "authors": "Sara Sadat Aghamiri, Franck Delaplace", "title": "TaBooN -- Boolean Network Synthesis Based on Tabu Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Omics-technologies revolutionized the investigation of\nbiology by producing molecular data in multiple dimensions and scale. This\nbreakthrough in biology raises the crucial issue of their interpretation based\non modelling. In this undertaking, network provides a suitable framework for\nmodelling the interactions between molecules. Basically a Biological network is\ncomposed of nodes referring to the components such as genes or proteins, and\nthe edges/arcs formalizing interactions between them. The evolution of the\ninteractions is then modelled by the definition of a dynamical system. Among\nthe different categories of network, the Boolean network offers a reliable\nqualitative framework for the modelling. Automatically synthesizing a Boolean\nnetwork from experimental data therefore remains a necessary but challenging\nissue. In this study, we present taboon, an original work-flow for synthesizing\nBoolean Networks from biological data. The methodology uses the data in the\nform of Boolean profiles for inferring all the potential local formula\ninference. They combine to form the model space from which the most truthful\nmodel with regards to biological knowledge and experiments must be found. In\nthe taboon work-flow the selection of the fittest model is achieved by a\nTabu-search algorithm. taboon is an automated method for Boolean Network\ninference from experimental data that can also assist to evaluate and optimize\nthe dynamic behaviour of the biological networks providing a reliable platform\nfor further modelling and predictions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:56:14 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Aghamiri", "Sara Sadat", ""], ["Delaplace", "Franck", ""]]}, {"id": "2009.03622", "submitter": "Pablo Lanillos", "authors": "Otto van der Himst, Pablo Lanillos", "title": "Deep Active Inference for Partially Observable MDPs", "comments": "1st International Workshop on Active inference, European Conference\n  on Machine Learning (ECML/PCKDD 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-64919-7_8", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep active inference has been proposed as a scalable approach to perception\nand action that deals with large policy and state spaces. However, current\nmodels are limited to fully observable domains. In this paper, we describe a\ndeep active inference model that can learn successful policies directly from\nhigh-dimensional sensory inputs. The deep learning architecture optimizes a\nvariant of the expected free energy and encodes the continuous state\nrepresentation by means of a variational autoencoder. We show, in the OpenAI\nbenchmark, that our approach has comparable or better performance than deep\nQ-learning, a state-of-the-art deep reinforcement learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:02:40 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["van der Himst", "Otto", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2009.03630", "submitter": "Caijun Ren", "authors": "Caijun Ren, Xiangyu Wang, Jian Gao and Huanhuan Chen", "title": "Unsupervised Change Detection in Satellite Images with Generative\n  Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting changed regions in paired satellite images plays a key role in many\nremote sensing applications. The evolution of recent techniques could provide\nsatellite images with very high spatial resolution (VHR) but made it\nchallenging to apply image coregistration, and many change detection methods\nare dependent on its accuracy.Two images of the same scene taken at different\ntime or from different angle would introduce unregistered objects and the\nexistence of both unregistered areas and actual changed areas would lower the\nperformance of many change detection algorithms in unsupervised condition.To\nalleviate the effect of unregistered objects in the paired images, we propose a\nnovel change detection framework utilizing a special neural network\narchitecture -- Generative Adversarial Network (GAN) to generate many better\ncoregistered images. In this paper, we show that GAN model can be trained upon\na pair of images through using the proposed expanding strategy to create a\ntraining set and optimizing designed objective functions. The optimized GAN\nmodel would produce better coregistered images where changes can be easily\nspotted and then the change map can be presented through a comparison strategy\nusing these generated images explicitly.Compared to other deep learning-based\nmethods, our method is less sensitive to the problem of unregistered images and\nmakes most of the deep learning structure.Experimental results on synthetic\nimages and real data with many different scenes could demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:26:04 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 03:28:27 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ren", "Caijun", ""], ["Wang", "Xiangyu", ""], ["Gao", "Jian", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2009.03632", "submitter": "Chris Dongjoo Kim", "authors": "Chris Dongjoo Kim, Jinseo Jeong, and Gunhee Kim", "title": "Imbalanced Continual Learning with Partitioning Reservoir Sampling", "comments": "Published to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning from a sequential stream of data is a crucial challenge\nfor machine learning research. Most studies have been conducted on this topic\nunder the single-label classification setting along with an assumption of\nbalanced label distribution. This work expands this research horizon towards\nmulti-label classification. In doing so, we identify unanticipated adversity\ninnately existent in many multi-label datasets, the long-tailed distribution.\nWe jointly address the two independently solved problems, Catastropic\nForgetting and the long-tailed label distribution by first empirically showing\na new challenge of destructive forgetting of the minority concepts on the tail.\nThen, we curate two benchmark datasets, COCOseq and NUS-WIDEseq, that allow the\nstudy of both intra- and inter-task imbalances. Lastly, we propose a new\nsampling strategy for replay-based approach named Partitioning Reservoir\nSampling (PRS), which allows the model to maintain a balanced knowledge of both\nhead and tail classes. We publicly release the dataset and the code in our\nproject page.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 10:28:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kim", "Chris Dongjoo", ""], ["Jeong", "Jinseo", ""], ["Kim", "Gunhee", ""]]}, {"id": "2009.03645", "submitter": "Mohammad Sayad Haghighi", "authors": "Mohammad Sadegh Sadeghi Garmaroodi, Faezeh Farivar, Mohammad Sayad\n  Haghighi, Mahdi Aliyari Shoorehdeli, Alireza Jolfaei", "title": "Detection of Anomalies and Faults in Industrial IoT Systems by Data\n  Mining: Study of CHRIST Osmotron Water Purification System", "comments": "this paper is under review in IEEE IoTJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 will make manufacturing processes smarter but this smartness\nrequires more environmental awareness, which in case of Industrial Internet of\nThings, is realized by the help of sensors. This article is about industrial\npharmaceutical systems and more specifically, water purification systems.\nPurified water which has certain conductivity is an important ingredient in\nmany pharmaceutical products. Almost every pharmaceutical company has a water\npurifying unit as a part of its interdependent systems. Early detection of\nfaults right at the edge can significantly decrease maintenance costs and\nimprove safety and output quality, and as a result, lead to the production of\nbetter medicines. In this paper, with the help of a few sensors and data mining\napproaches, an anomaly detection system is built for CHRIST Osmotron water\npurifier. This is a practical research with real-world data collected from\nSinaDarou Labs Co. Data collection was done by using six sensors over two-week\nintervals before and after system overhaul. This gave us normal and faulty\noperation samples. Given the data, we propose two anomaly detection approaches\nto build up our edge fault detection system. The first approach is based on\nsupervised learning and data mining e.g. by support vector machines. However,\nsince we cannot collect all possible faults data, an anomaly detection approach\nis proposed based on normal system identification which models the system\ncomponents by artificial neural networks. Extensive experiments are conducted\nwith the dataset generated in this study to show the accuracy of the\ndata-driven and model-based anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:31:43 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Garmaroodi", "Mohammad Sadegh Sadeghi", ""], ["Farivar", "Faezeh", ""], ["Haghighi", "Mohammad Sayad", ""], ["Shoorehdeli", "Mahdi Aliyari", ""], ["Jolfaei", "Alireza", ""]]}, {"id": "2009.03648", "submitter": "Maxime Caniot", "authors": "Maxime Caniot, Vincent Bonnet, Maxime Busy, Thierry Labaye, Michel\n  Besombes, Sebastien Courtois and Edouard Lagrue", "title": "Adapted Pepper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main issue in robotics is the lack of embedded computational\npower. Recently, state of the art algorithms providing a better understanding\nof the surroundings (Object detection, skeleton tracking, etc.) are requiring\nmore and more computational power. The lack of embedded computational power is\nmore significant in mass-produced robots because of the difficulties to follow\nthe increasing computational requirements of state of the art algorithms. The\nintegration of an additional GPU allows to overcome this lack of embedded\ncomputational power. We introduce in this paper a prototype of Pepper with an\nembedded GPU, but also with an additional 3D camera on the head of the robot\nand plugged to the late GPU. This prototype, called Adapted Pepper, was built\nfor the European project called MuMMER (MultiModal Mall Entertainment Robot) in\norder to embed algorithms like OpenPose, YOLO or to process sensors information\nand, in all cases, avoid network dependency for deported computation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:36:37 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Caniot", "Maxime", ""], ["Bonnet", "Vincent", ""], ["Busy", "Maxime", ""], ["Labaye", "Thierry", ""], ["Besombes", "Michel", ""], ["Courtois", "Sebastien", ""], ["Lagrue", "Edouard", ""]]}, {"id": "2009.03651", "submitter": "Sasho Nedelkoski", "authors": "Sasho Nedelkoski, Mihail Bogojeski, Odej Kao", "title": "Learning more expressive joint distributions in multimodal variational\n  methods", "comments": "12 pages, Accepted and presented at LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data often are formed of multiple modalities, which jointly describe the\nobserved phenomena. Modeling the joint distribution of multimodal data requires\nlarger expressive power to capture high-level concepts and provide better data\nrepresentations. However, multimodal generative models based on variational\ninference are limited due to the lack of flexibility of the approximate\nposterior, which is obtained by searching within a known parametric family of\ndistributions. We introduce a method that improves the representational\ncapacity of multimodal variational methods using normalizing flows. It\napproximates the joint posterior with a simple parametric distribution and\nsubsequently transforms into a more complex one. Through several experiments,\nwe demonstrate that the model improves on state-of-the-art multimodal methods\nbased on variational inference on various computer vision tasks such as\ncolorization, edge and mask detection, and weakly supervised learning. We also\nshow that learning more powerful approximate joint distributions improves the\nquality of the generated samples. The code of our model is publicly available\nat https://github.com/SashoNedelkoski/BPFDMVM.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:45:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nedelkoski", "Sasho", ""], ["Bogojeski", "Mihail", ""], ["Kao", "Odej", ""]]}, {"id": "2009.03681", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Hamdi Amroun, Mehdi Ammi", "title": "Energy Expenditure Estimation Through Daily Activity Recognition Using a\n  Smart-phone", "comments": null, "journal-ref": "2018 IEEE 4th World Forum on Internet of Things (WF-IoT)", "doi": "10.1109/WF-IoT.2018.8355097", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a 3-step system that estimates the real-time energy\nexpenditure of an individual in a non-intrusive way. First, using the user's\nsmart-phone's sensors, we build a Decision Tree model to recognize his physical\nactivity (\\textit{running}, \\textit{standing}, ...). Then, we use the detected\nphysical activity, the time and the user's speed to infer his daily activity\n(\\textit{watching TV}, \\textit{going to the bathroom}, ...) through the use of\na reinforcement learning environment, the Partially Observable Markov Decision\nProcess framework. Once the daily activities are recognized, we translate this\ninformation into energy expenditure using the compendium of physical\nactivities. By successfully detecting 8 physical activities at 90\\%, we reached\nan overall accuracy of 80\\% in recognizing 17 different daily activities. This\nresult leads us to estimate the energy expenditure of the user with a mean\nerror of 26\\% of the expected estimation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:26:18 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Amroun", "Hamdi", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03696", "submitter": "Matteo Polsinelli", "authors": "Giuseppe Placidi, Luigi Cinque, Matteo Polsinelli", "title": "Convolutional Neural Networks for Automatic Detection of Artifacts from\n  Independent Components Represented in Scalp Topographies of EEG Signals", "comments": null, "journal-ref": "Computers in Biology and Medicine. 132 (2021) 104347", "doi": "10.1016/j.compbiomed.2021.104347", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) measures the electrical brain activity in\nreal-time by using sensors placed on the scalp. Artifacts, due to eye movements\nand blink, muscular/cardiac activity and generic electrical disturbances, have\nto be recognized and eliminated to allow a correct interpretation of the useful\nbrain signals (UBS) of EEG. Independent Component Analysis (ICA) is effective\nto split the signal into independent components (ICs) whose re-projections on\n2D scalp topographies (images), also called topoplots, allow to\nrecognize/separate artifacts and by UBS. Until now, IC topoplot analysis, a\ngold standard in EEG, has been carried on visually by human experts and, hence,\nnot usable in automatic, fast-response EEG. We present a completely automatic\nand effective framework for EEG artifact recognition by IC topoplots, based on\n2D Convolutional Neural Networks (CNNs), capable to divide topoplots in 4\nclasses: 3 types of artifacts and UBS. The framework setup is described and\nresults are presented, discussed and compared with those obtained by other\ncompetitive strategies. Experiments, carried on public EEG datasets, have shown\nan overall accuracy of above 98%, employing 1.4 sec on a standard PC to\nclassify 32 topoplots, that is to drive an EEG system of 32 sensors. Though not\nreal-time, the proposed framework is efficient enough to be used in\nfast-response EEG-based Brain-Computer Interfaces (BCI) and faster than other\nautomatic methods based on ICs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:40:10 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Placidi", "Giuseppe", ""], ["Cinque", "Luigi", ""], ["Polsinelli", "Matteo", ""]]}, {"id": "2009.03722", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Prediction-Coherent LSTM-based Recurrent Neural Network for Safer\n  Glucose Predictions in Diabetic People", "comments": null, "journal-ref": "ICONIP 2019: Neural Information Processing pp 510-521", "doi": "10.1007/978-3-030-36718-3_43", "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of time-series forecasting, we propose a LSTM-based recurrent\nneural network architecture and loss function that enhance the stability of the\npredictions. In particular, the loss function penalizes the model, not only on\nthe prediction error (mean-squared error), but also on the predicted variation\nerror.\n  We apply this idea to the prediction of future glucose values in diabetes,\nwhich is a delicate task as unstable predictions can leave the patient in doubt\nand make him/her take the wrong action, threatening his/her life. The study is\nconducted on type 1 and type 2 diabetic people, with a focus on predictions\nmade 30-minutes ahead of time.\n  First, we confirm the superiority, in the context of glucose prediction, of\nthe LSTM model by comparing it to other state-of-the-art models (Extreme\nLearning Machine, Gaussian Process regressor, Support Vector Regressor).\n  Then, we show the importance of making stable predictions by smoothing the\npredictions made by the models, resulting in an overall improvement of the\nclinical acceptability of the models at the cost in a slight loss in prediction\naccuracy.\n  Finally, we show that the proposed approach, outperforms all baseline\nresults. More precisely, it trades a loss of 4.3\\% in the prediction accuracy\nfor an improvement of the clinical acceptability of 27.1\\%. When compared to\nthe moving average post-processing method, we show that the trade-off is more\nefficient with our approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:14:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03732", "submitter": "Maxime De Bois", "authors": "Maxime De Bois, Moun\\^im A. El Yacoubi, Mehdi Ammi", "title": "Enhancing the Interpretability of Deep Models in Heathcare Through\n  Attention: Application to Glucose Forecasting for Diabetic People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of deep learning in healthcare is hindered by their \"black box\"\nnature. In this paper, we explore the RETAIN architecture for the task of\nglusose forecasting for diabetic people. By using a two-level attention\nmechanism, the recurrent-neural-network-based RETAIN model is interpretable. We\nevaluate the RETAIN model on the type-2 IDIAB and the type-1 OhioT1DM datasets\nby comparing its statistical and clinical performances against two deep models\nand three models based on decision trees. We show that the RETAIN model offers\na very good compromise between accuracy and interpretability, being almost as\naccurate as the LSTM and FCN models while remaining interpretable. We show the\nusefulness of its interpretable nature by analyzing the contribution of each\nvariable to the final prediction. It revealed that signal values older than one\nhour are not used by the RETAIN model for the 30-minutes ahead of time\nprediction of glucose. Also, we show how the RETAIN model changes its behavior\nupon the arrival of an event such as carbohydrate intakes or insulin infusions.\nIn particular, it showed that the patient's state before the event is\nparticularily important for the prediction. Overall the RETAIN model, thanks to\nits interpretability, seems to be a very promissing model for regression or\nclassification tasks in healthcare.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:27:52 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["De Bois", "Maxime", ""], ["Yacoubi", "Moun\u00eem A. El", ""], ["Ammi", "Mehdi", ""]]}, {"id": "2009.03733", "submitter": "Junhong Xu", "authors": "Junhong Xu, Kai Yin, Lantao Liu", "title": "Online Planning in Uncertain and Dynamic Environment in the Presence of\n  Multiple Mobile Vehicles", "comments": "7 pages, 4 figures, accepted by IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the autonomous navigation of a mobile robot in the presence of\nother moving vehicles under time-varying uncertain environmental disturbances.\nWe first predict the future state distributions of other vehicles to account\nfor their uncertain behaviors affected by the time-varying disturbances. We\nthen construct a dynamic-obstacle-aware reachable space that contains states\nwith high probabilities to be reached by the robot, within which the optimal\npolicy is searched. Since, in general, the dynamics of both the vehicle and the\nenvironmental disturbances are nonlinear, we utilize a nonlinear Gaussian\nfilter -- the unscented transform -- to approximate the future state\ndistributions. Finally, the forward reachable space computation and backward\npolicy search are iterated until convergence. Extensive simulation evaluations\nhave revealed significant advantages of this proposed method in terms of\ncomputation time, decision accuracy, and planning reliability.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 13:27:57 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Xu", "Junhong", ""], ["Yin", "Kai", ""], ["Liu", "Lantao", ""]]}, {"id": "2009.03793", "submitter": "Amirhoshang Hoseinpour Dehkordi", "authors": "Amirhoshang Hoseinpour Dehkordi, Majid Alizadeh, Ali Movaghar", "title": "Linear Temporal Public Announcement Logic: a new perspective for\n  reasoning the knowledge of multi-classifiers", "comments": "11 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current applied intelligent systems have crucial shortcomings either in\nreasoning the gathered knowledge, or representation of comprehensive integrated\ninformation. To address these limitations, we develop a formal transition\nsystem which is applied to the common artificial intelligence (AI) systems, to\nreason about the findings. The developed model was created by combining the\nPublic Announcement Logic (PAL) and the Linear Temporal Logic (LTL), which will\nbe done to analyze both single-framed data and the following time-series data.\nTo do this, first, the achieved knowledge by an AI-based system (i.e.,\nclassifiers) for an individual time-framed data, will be taken, and then, it\nwould be modeled by a PAL. This leads to developing a unified representation of\nknowledge, and the smoothness in the integration of the gathered and external\nexperiences. Therefore, the model could receive the classifier's predefined --\nor any external -- knowledge, to assemble them in a unified manner. Alongside\nthe PAL, all the timed knowledge changes will be modeled, using a temporal\nlogic transition system. Later, following by the translation of natural\nlanguage questions into the temporal formulas, the satisfaction leads the model\nto answer that question. This interpretation integrates the information of the\nrecognized input data, rules, and knowledge. Finally, we suggest a mechanism to\nreduce the investigated paths for the performance improvements, which results\nin a partial correction for an object-detection system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 14:38:59 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 17:19:40 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Dehkordi", "Amirhoshang Hoseinpour", ""], ["Alizadeh", "Majid", ""], ["Movaghar", "Ali", ""]]}, {"id": "2009.03816", "submitter": "Qing Ye", "authors": "Qing Ye, Yuxuan Han, Yanan sun and JIancheng Lv", "title": "PSO-PS: Parameter Synchronization with Particle Swarm Optimization for\n  Distributed Training of Deep Neural Networks", "comments": "7pages", "journal-ref": "IJCNN2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter updating is an important stage in parallelism-based distributed\ndeep learning. Synchronous methods are widely used in distributed training the\nDeep Neural Networks (DNNs). To reduce the communication and synchronization\noverhead of synchronous methods, decreasing the synchronization frequency\n(e.g., every $n$ mini-batches) is a straightforward approach. However, it often\nsuffers from poor convergence. In this paper, we propose a new algorithm of\nintegrating Particle Swarm Optimization (PSO) into the distributed training\nprocess of DNNs to automatically compute new parameters. In the proposed\nalgorithm, a computing work is encoded by a particle, the weights of DNNs and\nthe training loss are modeled by the particle attributes. At each\nsynchronization stage, the weights are updated by PSO from the sub weights\ngathered from all workers, instead of averaging the weights or the gradients.\nTo verify the performance of the proposed algorithm, the experiments are\nperformed on two commonly used image classification benchmarks: MNIST and\nCIFAR10, and compared with the peer competitors at multiple different\nsynchronization configurations. The experimental results demonstrate the\ncompetitiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:18:32 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Ye", "Qing", ""], ["Han", "Yuxuan", ""], ["sun", "Yanan", ""], ["Lv", "JIancheng", ""]]}, {"id": "2009.03820", "submitter": "Niall O' Mahony", "authors": "Niall O' Mahony, Sean Campbell, Anderson Carvalho, Lenka Krpalkova,\n  Gustavo Velasco-Hernandez, Daniel Riordan, Joseph Walsh", "title": "Understanding and Exploiting Dependent Variables with Deep Metric\n  Learning", "comments": null, "journal-ref": "Proceedings of the 2020 Intelligent Systems Conference\n  (IntelliSys) Volume 1, B. R. Arai K., Kapoor S., Ed. Springer, Cham, 2020,\n  pp. 97 to 113", "doi": "10.1007/978-3-030-55180-3_8", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep Metric Learning (DML) approaches learn to represent inputs to a\nlower-dimensional latent space such that the distance between representations\nin this space corresponds with a predefined notion of similarity. This paper\ninvestigates how the mapping element of DML may be exploited in situations\nwhere the salient features in arbitrary classification problems vary over time\nor due to changing underlying variables. Examples of such variable features\ninclude seasonal and time-of-day variations in outdoor scenes in place\nrecognition tasks for autonomous navigation and age/gender variations in\nhuman/animal subjects in classification tasks for medical/ethological studies.\nThrough the use of visualisation tools for observing the distribution of DML\nrepresentations per each query variable for which prior information is\navailable, the influence of each variable on the classification task may be\nbetter understood. Based on these relationships, prior information on these\nsalient background variables may be exploited at the inference stage of the DML\napproach by using a clustering algorithm to improve classification performance.\nThis research proposes such a methodology establishing the saliency of query\nbackground variables and formulating clustering algorithms for better\nseparating latent-space representations at run-time. The paper also discusses\nonline management strategies to preserve the quality and diversity of data and\nthe representation of each class in the gallery of embeddings in the DML\napproach. We also discuss latent works towards understanding the relevance of\nunderlying/multiple variables with DML.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:30:45 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Mahony", "Niall O'", ""], ["Campbell", "Sean", ""], ["Carvalho", "Anderson", ""], ["Krpalkova", "Lenka", ""], ["Velasco-Hernandez", "Gustavo", ""], ["Riordan", "Daniel", ""], ["Walsh", "Joseph", ""]]}, {"id": "2009.03821", "submitter": "Pratheek Upadhyaya", "authors": "Pratheek S. Upadhyaya, Vijay K. Shah, and Jeffrey H. Reed", "title": "Cross-layer Band Selection and Routing Design for Diverse Band-aware DSA\n  Networks", "comments": "To be published in the proceedings of IEEE GLOBECOM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As several new spectrum bands are opening up for shared use, a new paradigm\nof \\textit{Diverse Band-aware Dynamic Spectrum Access} (d-DSA) has emerged.\nd-DSA equips a secondary device with software defined radios (SDRs) and utilize\nwhitespaces (or idle channels) in \\textit{multiple bands}, including but not\nlimited to TV, LTE, Citizen Broadband Radio Service (CBRS), unlicensed ISM. In\nthis paper, we propose a decentralized, online multi-agent reinforcement\nlearning based cross-layer BAnd selection and Routing Design (BARD) for such\nd-DSA networks. BARD not only harnesses whitespaces in multiple spectrum bands,\nbut also accounts for unique electro-magnetic characteristics of those bands to\nmaximize the desired quality of service (QoS) requirements of heterogeneous\nmessage packets; while also ensuring no harmful interference to the primary\nusers in the utilized band. Our extensive experiments demonstrate that BARD\noutperforms the baseline dDSAaR algorithm in terms of message delivery ratio,\nhowever, at a relatively higher network latency, for varying number of primary\nand secondary users. Furthermore, BARD greatly outperforms its single-band DSA\nvariants in terms of both the metrics in all considered scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:33:08 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Upadhyaya", "Pratheek S.", ""], ["Shah", "Vijay K.", ""], ["Reed", "Jeffrey H.", ""]]}, {"id": "2009.03855", "submitter": "Daniel Furelos-Blanco", "authors": "Daniel Furelos-Blanco, Mark Law, Anders Jonsson, Krysia Broda and\n  Alessandra Russo", "title": "Induction and Exploitation of Subgoal Automata for Reinforcement\n  Learning", "comments": "Published in the Journal of Artificial Intelligence Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research, 70, 1031-1116 (2021)", "doi": "10.1613/jair.1.12372", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present ISA, an approach for learning and exploiting\nsubgoals in episodic reinforcement learning (RL) tasks. ISA interleaves\nreinforcement learning with the induction of a subgoal automaton, an automaton\nwhose edges are labeled by the task's subgoals expressed as propositional logic\nformulas over a set of high-level events. A subgoal automaton also consists of\ntwo special states: a state indicating the successful completion of the task,\nand a state indicating that the task has finished without succeeding. A\nstate-of-the-art inductive logic programming system is used to learn a subgoal\nautomaton that covers the traces of high-level events observed by the RL agent.\nWhen the currently exploited automaton does not correctly recognize a trace,\nthe automaton learner induces a new automaton that covers that trace. The\ninterleaving process guarantees the induction of automata with the minimum\nnumber of states, and applies a symmetry breaking mechanism to shrink the\nsearch space whilst remaining complete. We evaluate ISA in several gridworld\nand continuous state space problems using different RL algorithms that leverage\nthe automaton structures. We provide an in-depth empirical analysis of the\nautomaton learning performance in terms of the traces, the symmetry breaking\nand specific restrictions imposed on the final learnable automaton. For each\nclass of RL problem, we show that the learned automata can be successfully\nexploited to learn policies that reach the goal, achieving an average reward\ncomparable to the case where automata are not learned but handcrafted and given\nbeforehand.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:42:55 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 15:25:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Furelos-Blanco", "Daniel", ""], ["Law", "Mark", ""], ["Jonsson", "Anders", ""], ["Broda", "Krysia", ""], ["Russo", "Alessandra", ""]]}, {"id": "2009.03863", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey", "title": "TanhSoft -- a family of activation functions combining Tanh and Softplus", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning at its core, contains functions that are composition of a\nlinear transformation with a non-linear function known as activation function.\nIn past few years, there is an increasing interest in construction of novel\nactivation functions resulting in better learning. In this work, we propose a\nfamily of novel activation functions, namely TanhSoft, with four undetermined\nhyper-parameters of the form\ntanh({\\alpha}x+{\\beta}e^{{\\gamma}x})ln({\\delta}+e^x) and tune these\nhyper-parameters to obtain activation functions which are shown to outperform\nseveral well known activation functions. For instance, replacing ReLU with\nxtanh(0.6e^x)improves top-1 classification accuracy on CIFAR-10 by 0.46% for\nDenseNet-169 and 0.7% for Inception-v3 while with tanh(0.87x)ln(1 +e^x) top-1\nclassification accuracy on CIFAR-100 improves by 1.24% for DenseNet-169 and\n2.57% for SimpleNet model.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:59:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Banerjee", "Shilpak", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2009.03873", "submitter": "Joshua Cardosi", "authors": "Joshua D. Cardosi, Herman Shen, Jonathan I. Groner, Megan Armstrong,\n  Henry Xiang", "title": "Machine Intelligence for Outcome Predictions of Trauma Patients During\n  Emergency Department Care", "comments": "23 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trauma mortality results from a multitude of non-linear dependent risk\nfactors including patient demographics, injury characteristics, medical care\nprovided, and characteristics of medical facilities; yet traditional approach\nattempted to capture these relationships using rigid regression models. We\nhypothesized that a transfer learning based machine learning algorithm could\ndeeply understand a trauma patient's condition and accurately identify\nindividuals at high risk for mortality without relying on restrictive\nregression model criteria. Anonymous patient visit data were obtained from\nyears 2007-2014 of the National Trauma Data Bank. Patients with incomplete\nvitals, unknown outcome, or missing demographics data were excluded. All\npatient visits occurred in U.S. hospitals, and of the 2,007,485 encounters that\nwere retrospectively examined, 8,198 resulted in mortality (0.4%). The machine\nintelligence model was evaluated on its sensitivity, specificity, positive and\nnegative predictive value, and Matthews Correlation Coefficient. Our model\nachieved similar performance in age-specific comparison models and generalized\nwell when applied to all ages simultaneously. While testing for confounding\nfactors, we discovered that excluding fall-related injuries boosted performance\nfor adult trauma patients; however, it reduced performance for children. The\nmachine intelligence model described here demonstrates similar performance to\ncontemporary machine intelligence models without requiring restrictive\nregression model criteria or extensive medical expertise.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 17:26:34 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:50:57 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cardosi", "Joshua D.", ""], ["Shen", "Herman", ""], ["Groner", "Jonathan I.", ""], ["Armstrong", "Megan", ""], ["Xiang", "Henry", ""]]}, {"id": "2009.03993", "submitter": "Michel Gr\\'ediac", "authors": "S. Boukhtache, K. Abdelouahab, F. Berry, B. Blaysat, M. Grediac, F.\n  Sur", "title": "When Deep Learning Meets Digital Image Correlation", "comments": "35 pages, 25 figures. Accepted for publication in Optics and Lasers\n  in Engineering on July 9, 2020", "journal-ref": null, "doi": "10.1016/j.optlaseng.2020.106308", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) constitute a class of Deep Learning\nmodels which have been used in the recent past to resolve many problems in\ncomputer vision, in particular optical flow estimation. Measuring displacement\nand strain fields can be regarded as a particular case of this problem.\nHowever, it seems that CNNs have never been used so far to perform such\nmeasurements. This work is aimed at implementing a CNN able to retrieve\ndisplacement and strain fields from pairs of reference and deformed images of a\nflat speckled surface, as Digital Image Correlation (DIC) does. This paper\nexplains how a CNN called StrainNet can be developed to reach this goal, and\nhow specific ground truth datasets are elaborated to train this CNN. The main\nresult is that StrainNet successfully performs such measurements, and that it\nachieves competing results in terms of metrological performance and computing\ntime. The conclusion is that CNNs like StrainNet offer a viable alternative to\nDIC, especially for real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:26:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Boukhtache", "S.", ""], ["Abdelouahab", "K.", ""], ["Berry", "F.", ""], ["Blaysat", "B.", ""], ["Grediac", "M.", ""], ["Sur", "F.", ""]]}, {"id": "2009.04120", "submitter": "SeongUk Park", "authors": "SeongUk Park, KiYoon Yoo, Nojun Kwak", "title": "On the Orthogonality of Knowledge Distillation with Other Techniques:\n  From an Ensemble Perspective", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To put a state-of-the-art neural network to practical use, it is necessary to\ndesign a model that has a good trade-off between the resource consumption and\nperformance on the test set. Many researchers and engineers are developing\nmethods that enable training or designing a model more efficiently. Developing\nan efficient model includes several strategies such as network architecture\nsearch, pruning, quantization, knowledge distillation, utilizing cheap\nconvolution, regularization, and also includes any craft that leads to a better\nperformance-resource trade-off. When combining these technologies together, it\nwould be ideal if one source of performance improvement does not conflict with\nothers. We call this property as the orthogonality in model efficiency. In this\npaper, we focus on knowledge distillation and demonstrate that knowledge\ndistillation methods are orthogonal to other efficiency-enhancing methods both\nanalytically and empirically. Analytically, we claim that knowledge\ndistillation functions analogous to a ensemble method, bootstrap aggregating.\nThis analytical explanation is provided from the perspective of implicit data\naugmentation property of knowledge distillation. Empirically, we verify\nknowledge distillation as a powerful apparatus for practical deployment of\nefficient neural network, and also introduce ways to integrate it with other\nmethods effectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 06:14:59 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 14:52:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Park", "SeongUk", ""], ["Yoo", "KiYoon", ""], ["Kwak", "Nojun", ""]]}, {"id": "2009.04203", "submitter": "Haoyi Niu", "authors": "Haoyi Niu, Jianming Hu, Zheyu Cui, Yi Zhang", "title": "Tactical Decision Making for Emergency Vehicles Based on A Combinational\n  Learning Method", "comments": "12 pages,4 figures, prepared for a conference on intelligent\n  transportation system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the response time of emergency vehicles(EVs) could lead to an\nimmeasurable loss of property and life. On this account, tactical decision\nmaking for EVs' microscopic control remains an indispensable issue to be\nimproved. In this paper, a rule-based avoiding strategy(AS) is devised, that\nCVs in the prioritized zone ahead of EV should accelerate or change their lane\nto avoid it. Besides, a novel DQN method with speed-adaptive compact state\nspace (SC-DQN) is put forward to fit in EVs' high-speed feature and generalize\nin various road topologies. Afterward, the execution of AS feedback to the\ninput of SC-DQN so that they joint organically as a combinational method. The\nfollowing approach reveals that DRL could complement rule-based avoiding\nstrategy in generalization, and on the contrary, the rule-based avoiding\nstrategy could complement DRL in stability, and their combination could lead to\nless response time, lower collision rate and smoother trajectory.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:41:56 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 17:20:55 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 14:22:09 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Niu", "Haoyi", ""], ["Hu", "Jianming", ""], ["Cui", "Zheyu", ""], ["Zhang", "Yi", ""]]}, {"id": "2009.04215", "submitter": "Francisco Cruz", "authors": "Ruben Contreras, Angel Ayala, Francisco Cruz", "title": "Unmanned Aerial Vehicle Control Through Domain-based Automatic Speech\n  Recognition", "comments": "Submitted to Computers", "journal-ref": null, "doi": "10.3390/computers9030075", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, unmanned aerial vehicles, such as drones, are becoming a part of\nour lives and reaching out to many areas of society, including the\nindustrialized world. A common alternative to control the movements and actions\nof the drone is through unwired tactile interfaces, for which different remote\ncontrol devices can be found. However, control through such devices is not a\nnatural, human-like communication interface, which sometimes is difficult to\nmaster for some users. In this work, we present a domain-based speech\nrecognition architecture to effectively control an unmanned aerial vehicle such\nas a drone. The drone control is performed using a more natural, human-like way\nto communicate the instructions. Moreover, we implement an algorithm for\ncommand interpretation using both Spanish and English languages, as well as to\ncontrol the movements of the drone in a simulated domestic environment. The\nconducted experiments involve participants giving voice commands to the drone\nin both languages in order to compare the effectiveness of each of them,\nconsidering the mother tongue of the participants in the experiment.\nAdditionally, different levels of distortion have been applied to the voice\ncommands in order to test the proposed approach when facing noisy input\nsignals. The obtained results show that the unmanned aerial vehicle is capable\nof interpreting user voice instructions achieving an improvement in\nspeech-to-action recognition for both languages when using phoneme matching in\ncomparison to only using the cloud-based algorithm without domain-based\ninstructions. Using raw audio inputs, the cloud-based approach achieves 74.81%\nand 97.04% accuracy for English and Spanish instructions respectively, whereas\nusing our phoneme matching approach the results are improved achieving 93.33%\nand 100.00% accuracy for English and Spanish languages.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 11:17:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Contreras", "Ruben", ""], ["Ayala", "Angel", ""], ["Cruz", "Francisco", ""]]}, {"id": "2009.04298", "submitter": "Max Christl", "authors": "Max Christl", "title": "Vision-Based Autonomous Drone Control using Supervised Learning in\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limited power and computational resources, absence of high-end sensor\nequipment and GPS-denied environments are challenges faced by autonomous micro\nareal vehicles (MAVs). We address these challenges in the context of autonomous\nnavigation and landing of MAVs in indoor environments and propose a\nvision-based control approach using Supervised Learning. To achieve this, we\ncollected data samples in a simulation environment which were labelled\naccording to the optimal control command determined by a path planning\nalgorithm. Based on these data samples, we trained a Convolutional Neural\nNetwork (CNN) that maps low resolution image and sensor input to high-level\ncontrol commands. We have observed promising results in both obstructed and\nnon-obstructed simulation environments, showing that our model is capable of\nsuccessfully navigating a MAV towards a landing platform. Our approach requires\nshorter training times than similar Reinforcement Learning approaches and can\npotentially overcome the limitations of manual data collection faced by\ncomparable Supervised Learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:45:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Christl", "Max", ""]]}, {"id": "2009.04336", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Tuomas Sandholm", "title": "Polynomial-Time Computation of Optimal Correlated Equilibria in\n  Two-Player Extensive-Form Games with Public Chance Moves and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike normal-form games, where correlated equilibria have been studied for\nmore than 45 years, extensive-form correlation is still generally not well\nunderstood. Part of the reason for this gap is that the sequential nature of\nextensive-form games allows for a richness of behaviors and incentives that are\nnot possible in normal-form settings. This richness translates to a\nsignificantly different complexity landscape surrounding extensive-form\ncorrelated equilibria. As of today, it is known that finding an optimal\nextensive-form correlated equilibrium (EFCE), extensive-form coarse correlated\nequilibrium (EFCCE), or normal-form coarse correlated equilibrium (NFCCE) in a\ntwo-player extensive-form game is computationally tractable when the game does\nnot include chance moves, and intractable when the game involves chance moves.\nIn this paper we significantly refine this complexity threshold by showing\nthat, in two-player games, an optimal correlated equilibrium can be computed in\npolynomial time, provided that a certain condition is satisfied. We show that\nthe condition holds, for example, when all chance moves are public, that is,\nboth players observe all chance moves. This implies that an optimal EFCE, EFCCE\nand NFCCE can be computed in polynomial time in the game size in two-player\ngames with public chance moves, providing the biggest positive complexity\nresult surrounding extensive-form correlation in more than a decade.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:51:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Farina", "Gabriele", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2009.04346", "submitter": "Joberto Martins Prof. Dr.", "authors": "Eliseu M. Oliveira and Rafael F. Reale and Joberto S. B. Martins", "title": "A Methodological Approach to Model CBR-based Systems", "comments": "pp 1-16, 3 figures", "journal-ref": "Journal of Computer and Communications, September 2020, ISSN\n  Online: 2327-5227", "doi": "10.4236/jcc.2020.89001", "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has been used in various areas to support system\noptimization and find solutions where the complexity makes it challenging to\nuse algorithmic and heuristics. Case-based Reasoning (CBR) is an AI technique\nintensively exploited in domains like management, medicine, design,\nconstruction, retail and smart grid. CBR is a technique for problem-solving and\ncaptures new knowledge by using past experiences. One of the main CBR\ndeployment challenges is the target system modeling process. This paper\npresents a straightforward methodological approach to model CBR-based\napplications using the concepts of abstract and concrete models. Splitting the\nmodeling process with two models facilitates the allocation of expertise\nbetween the application domain and the CBR technology. The methodological\napproach intends to facilitate the CBR modeling process and to foster CBR use\nin various areas outside computer science.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:09:56 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Oliveira", "Eliseu M.", ""], ["Reale", "Rafael F.", ""], ["Martins", "Joberto S. B.", ""]]}, {"id": "2009.04374", "submitter": "Ulrich Paquet", "authors": "Nenad Toma\\v{s}ev, Ulrich Paquet, Demis Hassabis and Vladimir Kramnik", "title": "Assessing Game Balance with AlphaZero: Exploring Alternative Rule Sets\n  in Chess", "comments": "98 pages. Game AZ-8 on page 39 (Stalemate=win variant) replaced from\n  version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is non-trivial to design engaging and balanced sets of game rules. Modern\nchess has evolved over centuries, but without a similar recourse to history,\nthe consequences of rule changes to game dynamics are difficult to predict.\nAlphaZero provides an alternative in silico means of game balance assessment.\nIt is a system that can learn near-optimal strategies for any rule set from\nscratch, without any human supervision, by continually learning from its own\nexperience. In this study we use AlphaZero to creatively explore and design new\nchess variants. There is growing interest in chess variants like Fischer Random\nChess, because of classical chess's voluminous opening theory, the high\npercentage of draws in professional play, and the non-negligible number of\ngames that end while both players are still in their home preparation. We\ncompare nine other variants that involve atomic changes to the rules of chess.\nThe changes allow for novel strategic and tactical patterns to emerge, while\nkeeping the games close to the original. By learning near-optimal strategies\nfor each variant with AlphaZero, we determine what games between strong human\nplayers might look like if these variants were adopted. Qualitatively, several\nvariants are very dynamic. An analytic comparison show that pieces are valued\ndifferently between variants, and that some variants are more decisive than\nclassical chess. Our findings demonstrate the rich possibilities that lie\nbeyond the rules of modern chess.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:49:14 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 16:11:34 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Toma\u0161ev", "Nenad", ""], ["Paquet", "Ulrich", ""], ["Hassabis", "Demis", ""], ["Kramnik", "Vladimir", ""]]}, {"id": "2009.04383", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Mukund Telukunta and Venkata Sriram Siddhardh Nadendla", "title": "On the Identification of Fair Auditors to Evaluate Recommender Systems\n  based on a Novel Non-Comparative Fairness Notion", "comments": "10 pages, Accepted to FAccTRec-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-support systems are information systems that offer support to\npeople's decisions in various applications such as judiciary, real-estate and\nbanking sectors. Lately, these support systems have been found to be\ndiscriminatory in the context of many practical deployments. In an attempt to\nevaluate and mitigate these biases, algorithmic fairness literature has been\nnurtured using notions of comparative justice, which relies primarily on\ncomparing two/more individuals or groups within the society that is supported\nby such systems. However, such a fairness notion is not very useful in the\nidentification of fair auditors who are hired to evaluate latent biases within\ndecision-support systems. As a solution, we introduce a paradigm shift in\nalgorithmic fairness via proposing a new fairness notion based on the principle\nof non-comparative justice. Assuming that the auditor makes fairness\nevaluations based on some (potentially unknown) desired properties of the\ndecision-support system, the proposed fairness notion compares the system's\noutcome with that of the auditor's desired outcome. We show that the proposed\nfairness notion also provides guarantees in terms of comparative fairness\nnotions by proving that any system can be deemed fair from the perspective of\ncomparative fairness (e.g. individual fairness and statistical parity) if it is\nnon-comparatively fair with respect to an auditor who has been deemed fair with\nrespect to the same fairness notions. We also show that the converse holds true\nin the context of individual fairness. A brief discussion is also presented\nregarding how our fairness notion can be used to identify fair and reliable\nauditors, and how we can use them to quantify biases in decision-support\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:04:41 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2009.04404", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Bram Steenwinckel, Pieter Bonte, Michael Weyns,\n  Heiko Paulheim, Petar Ristoski, Filip De Turck, Femke Ongenae", "title": "Walk Extraction Strategies for Node Embeddings with RDF2Vec in Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As KGs are symbolic constructs, specialized techniques have to be applied in\norder to make them compatible with data mining techniques. RDF2Vec is an\nunsupervised technique that can create task-agnostic numerical representations\nof the nodes in a KG by extending successful language modelling techniques. The\noriginal work proposed the Weisfeiler-Lehman (WL) kernel to improve the quality\nof the representations. However, in this work, we show both formally and\nempirically that the WL kernel does little to improve walk embeddings in the\ncontext of a single KG. As an alternative to the WL kernel, we propose five\ndifferent strategies to extract information complementary to basic random\nwalks. We compare these walks on several benchmark datasets to show that the\n\\emph{n-gram} strategy performs best on average on node classification tasks\nand that tuning the walk strategy can result in improved predictive\nperformances.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 16:26:31 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Steenwinckel", "Bram", ""], ["Bonte", "Pieter", ""], ["Weyns", "Michael", ""], ["Paulheim", "Heiko", ""], ["Ristoski", "Petar", ""], ["De Turck", "Filip", ""], ["Ongenae", "Femke", ""]]}, {"id": "2009.04441", "submitter": "Diego Antognini", "authors": "Kirtan Padh, Diego Antognini, Emma Lejal Glaude, Boi Faltings, Claudiu\n  Musat", "title": "Addressing Fairness in Classification with a Model-Agnostic\n  Multi-Objective Algorithm", "comments": "Accepted at UAI 2021. 14 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of fairness in classification is to learn a classifier that does not\ndiscriminate against groups of individuals based on sensitive attributes, such\nas race and gender. One approach to designing fair algorithms is to use\nrelaxations of fairness notions as regularization terms or in a constrained\noptimization problem. We observe that the hyperbolic tangent function can\napproximate the indicator function. We leverage this property to define a\ndifferentiable relaxation that approximates fairness notions provably better\nthan existing relaxations. In addition, we propose a model-agnostic\nmulti-objective architecture that can simultaneously optimize for multiple\nfairness notions and multiple sensitive attributes and supports all statistical\nparity-based notions of fairness. We use our relaxation with the\nmulti-objective architecture to learn fair classifiers. Experiments on public\ndatasets show that our method suffers a significantly lower loss of accuracy\nthan current debiasing algorithms relative to the unconstrained model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:40:24 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 17:17:00 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 12:39:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Padh", "Kirtan", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04462", "submitter": "Jian Pei", "authors": "Jian Pei", "title": "A Survey on Data Pricing: from Economics to Data Science", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2021", "doi": "10.1109/TKDE.2020.3045927", "report-no": null, "categories": "econ.TH cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data are invaluable. How can we assess the value of data objectively,\nsystematically and quantitatively? Pricing data, or information goods in\ngeneral, has been studied and practiced in dispersed areas and principles, such\nas economics, marketing, electronic commerce, data management, data mining and\nmachine learning. In this article, we present a unified, interdisciplinary and\ncomprehensive overview of this important direction. We examine various\nmotivations behind data pricing, understand the economics of data pricing and\nreview the development and evolution of pricing models according to a series of\nfundamental principles. We discuss both digital products and data products. We\nalso consider a series of challenges and directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:31:38 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 23:10:46 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pei", "Jian", ""]]}, {"id": "2009.04508", "submitter": "Brian Felipe Keith Norambuena", "authors": "Brian Keith and Tanushree Mitra", "title": "Narrative Maps: An Algorithmic Approach to Represent and Extract\n  Information Narratives", "comments": "33 pages, 15 figures, CSCW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narratives are fundamental to our perception of the world and are pervasive\nin all activities that involve the representation of events in time. Yet,\nmodern online information systems do not incorporate narratives in their\nrepresentation of events occurring over time. This article aims to bridge this\ngap, combining the theory of narrative representations with the data from\nmodern online systems. We make three key contributions: a theory-driven\ncomputational representation of narratives, a novel extraction algorithm to\nobtain these representations from data, and an evaluation of our approach. In\nparticular, given the effectiveness of visual metaphors, we employ a route map\nmetaphor to design a narrative map representation. The narrative map\nrepresentation illustrates the events and stories in the narrative as a series\nof landmarks and routes on the map. Each element of our representation is\nbacked by a corresponding element from formal narrative theory, thus providing\na solid theoretical background to our method. Our approach extracts the\nunderlying graph structure of the narrative map using a novel optimization\ntechnique focused on maximizing coherence while respecting structural and\ncoverage constraints. We showcase the effectiveness of our approach by\nperforming a user evaluation to assess the quality of the representation,\nmetaphor, and visualization. Evaluation results indicate that the Narrative Map\nrepresentation is a powerful method to communicate complex narratives to\nindividuals. Our findings have implications for intelligence analysts,\ncomputational journalists, and misinformation researchers.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:30:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:38:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Keith", "Brian", ""], ["Mitra", "Tanushree", ""]]}, {"id": "2009.04518", "submitter": "Kristine Heiney", "authors": "Kristine Heiney, Gunnar Tufte, Stefano Nichele", "title": "On Artificial Life and Emergent Computation in Physical Substrates", "comments": "Accepted conference paper. HPCS2020, Session 3: BICAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In living systems, we often see the emergence of the ingredients necessary\nfor computation -- the capacity for information transmission, storage, and\nmodification -- begging the question of how we may exploit or imitate such\nbiological systems in unconventional computing applications. What can we gain\nfrom artificial life in the advancement of computing technology? Artificial\nlife provides us with powerful tools for understanding the dynamic behavior of\nbiological systems and capturing this behavior in manmade substrates. With this\napproach, we can move towards a new computing paradigm concerned with\nharnessing emergent computation in physical substrates not governed by the\nconstraints of Moore's law and ultimately realize massively parallel and\ndistributed computing technology. In this paper, we argue that the lens of\nartificial life offers valuable perspectives for the advancement of\nhigh-performance computing technology. We first present a brief foundational\nbackground on artificial life and some relevant tools that may be applicable to\nunconventional computing. Two specific substrates are then discussed in detail:\nbiological neurons and ensembles of nanomagnets. These substrates are the focus\nof the authors' ongoing work, and they are illustrative of the two sides of the\napproach outlined here -- the close study of living systems and the\nconstruction of artificial systems to produce life-like behaviors. We conclude\nwith a philosophical discussion on what we can learn from approaching\ncomputation with the curiosity inherent to the study of artificial life. The\nmain contribution of this paper is to present the great potential of using\nartificial life methodologies to uncover and harness the inherent computational\npower of physical substrates toward applications in unconventional\nhigh-performance computing.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:59:53 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Heiney", "Kristine", ""], ["Tufte", "Gunnar", ""], ["Nichele", "Stefano", ""]]}, {"id": "2009.04521", "submitter": "David Vigouroux", "authors": "Thomas Fel (ANITI), David Vigouroux, R\\'emi Cad\\`ene, Thomas Serre\n  (ANITI)", "title": "How good is your explanation? Algorithmic stability measures to assess\n  the qualityof explanations for deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of methods have been proposed to explain howdeep neural networks\nreach a decision but comparativelylittle effort has been made to ensure that\nthe explanationsproduced by these methods are objectively relevant.\nWhiledesirable properties for a good explanation are easy to come,objective\nmeasures have been harder to derive. Here, we pro-pose two new measures to\nevaluate explanations borrowedfrom the field of algorithmic stability: relative\nconsistencyReCo and mean generalizability MeGe. We conduct severalexperiments\non multiple image datasets and network archi-tectures to demonstrate the\nbenefits of the proposed measuresover representative methods. We show that\npopular fidelitymeasures are not sufficient to guarantee good\nexplanations.Finally, we show empirically that 1-Lipschitz networks pro-vide\ngeneral and consistent explanations, regardless of theexplanation method used,\nmaking them a relevant directionfor explainability.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:02:29 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 10:03:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Fel", "Thomas", "", "ANITI"], ["Vigouroux", "David", "", "ANITI"], ["Cad\u00e8ne", "R\u00e9mi", "", "ANITI"], ["Serre", "Thomas", "", "ANITI"]]}, {"id": "2009.04530", "submitter": "Thomas Winters", "authors": "Thomas Winters, Luc De Raedt", "title": "Discovering Textual Structures: Generative Grammar Induction using\n  Template Trees", "comments": "Published in the Proceedings of the 11th International Conference on\n  Computational Creativity, p177-180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation provides designers with methods for automatically\ngenerating text, e.g. for creating summaries, chatbots and game content. In\npractise, text generators are often either learned and hard to interpret, or\ncreated by hand using techniques such as grammars and templates. In this paper,\nwe introduce a novel grammar induction algorithm for learning interpretable\ngrammars for generative purposes, called Gitta. We also introduce the novel\nnotion of template trees to discover latent templates in corpora to derive\nthese generative grammars. By using existing human-created grammars, we found\nthat the algorithm can reasonably approximate these grammars using only a few\nexamples. These results indicate that Gitta could be used to automatically\nlearn interpretable and easily modifiable grammars, and thus provide a stepping\nstone for human-machine co-creation of generative models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:31:04 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Winters", "Thomas", ""], ["De Raedt", "Luc", ""]]}, {"id": "2009.04532", "submitter": "Mohammad Abuzar Shaikh", "authors": "Mohammad Abuzar Shaikh, Tiehang Duan, Mihir Chauhan, Sargur Srihari", "title": "Attention based Writer Independent Handwriting Verification", "comments": "7 pages, 6 figures, Published in 2020 17th International Conference\n  on Frontiers in Handwriting Recognition (ICFHR)", "journal-ref": null, "doi": "10.1109/ICFHR2020.2020.00074", "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of writer verification is to provide a likelihood score for whether\nthe queried and known handwritten image samples belong to the same writer or\nnot. Such a task calls for the neural network to make it's outcome\ninterpretable, i.e. provide a view into the network's decision making process.\nWe implement and integrate cross-attention and soft-attention mechanisms to\ncapture the highly correlated and salient points in feature space of 2D inputs.\nThe attention maps serve as an explanation premise for the network's output\nlikelihood score. The attention mechanism also allows the network to focus more\non relevant areas of the input, thus improving the classification performance.\nOur proposed approach achieves a precision of 86\\% for detecting intra-writer\ncases in CEDAR cursive \"AND\" dataset. Furthermore, we generate meaningful\nexplanations for the provided decision by extracting attention maps from\nmultiple levels of the network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 16:28:16 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 13:56:44 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 00:59:36 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Shaikh", "Mohammad Abuzar", ""], ["Duan", "Tiehang", ""], ["Chauhan", "Mihir", ""], ["Srihari", "Sargur", ""]]}, {"id": "2009.04535", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Sebastian Me\\v{z}nar, Nada Lavra\\v{c}, Bla\\v{z} \\v{S}krlj", "title": "SNoRe: Scalable Unsupervised Learning of Symbolic Node Representations", "comments": "Accepted to IEEEAccess", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3039541", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from complex real-life networks is a lively research area, with\nrecent advances in learning information-rich, low-dimensional network node\nrepresentations. However, state-of-the-art methods are not necessarily\ninterpretable and are therefore not fully applicable to sensitive settings in\nbiomedical or user profiling tasks, where explicit bias detection is highly\nrelevant. The proposed SNoRe (Symbolic Node Representations) algorithm is\ncapable of learning symbolic, human-understandable representations of\nindividual network nodes, based on the similarity of neighborhood hashes which\nserve as features. SNoRe's interpretable features are suitable for direct\nexplanation of individual predictions, which we demonstrate by coupling it with\nthe widely used instance explanation tool SHAP to obtain nomograms representing\nthe relevance of individual features for a given classification. To our\nknowledge, this is one of the first such attempts in a structural node\nembedding setting. In the experimental evaluation on eleven real-life datasets,\nSNoRe proved to be competitive to strong baselines, such as variational graph\nautoencoders, node2vec and LINE. The vectorized implementation of SNoRe scales\nto large networks, making it suitable for contemporary network learning and\nanalysis tasks.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 08:13:21 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 13:34:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Me\u017enar", "Sebastian", ""], ["Lavra\u010d", "Nada", ""], ["\u0160krlj", "Bla\u017e", ""]]}, {"id": "2009.04547", "submitter": "Pablo G. Morato", "authors": "P. G. Morato, K.G. Papakonstantinou, C.P. Andriotis, J.S. Nielsen and\n  P. Rigo", "title": "Optimal Inspection and Maintenance Planning for Deteriorating Structures\n  through Dynamic Bayesian Networks and Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Civil and maritime engineering systems, among others, from bridges to\noffshore platforms and wind turbines, must be efficiently managed as they are\nexposed to deterioration mechanisms throughout their operational life, such as\nfatigue or corrosion. Identifying optimal inspection and maintenance policies\ndemands the solution of a complex sequential decision-making problem under\nuncertainty, with the main objective of efficiently controlling the risk\nassociated with structural failures. Addressing this complexity, risk-based\ninspection planning methodologies, supported often by dynamic Bayesian\nnetworks, evaluate a set of pre-defined heuristic decision rules to reasonably\nsimplify the decision problem. However, the resulting policies may be\ncompromised by the limited space considered in the definition of the decision\nrules. Avoiding this limitation, Partially Observable Markov Decision Processes\n(POMDPs) provide a principled mathematical methodology for stochastic optimal\ncontrol under uncertain action outcomes and observations, in which the optimal\nactions are prescribed as a function of the entire, dynamically updated, state\nprobability distribution. In this paper, we combine dynamic Bayesian networks\nwith POMDPs in a joint framework for optimal inspection and maintenance\nplanning, and we provide the formulation for developing both infinite and\nfinite horizon POMDPs in a structural reliability context. The proposed\nmethodology is implemented and tested for the case of a structural component\nsubject to fatigue deterioration, demonstrating the capability of\nstate-of-the-art point-based POMDP solvers for solving the underlying planning\noptimization problem. Within the numerical experiments, POMDP and\nheuristic-based policies are thoroughly compared, and results showcase that\nPOMDPs achieve substantially lower costs as compared to their counterparts,\neven for traditional problem settings.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:03:42 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Morato", "P. G.", ""], ["Papakonstantinou", "K. G.", ""], ["Andriotis", "C. P.", ""], ["Nielsen", "J. S.", ""], ["Rigo", "P.", ""]]}, {"id": "2009.04549", "submitter": "Daniel Dunlavy", "authors": "Scott Heidbrink, Kathryn N. Rodhouse, Daniel M. Dunlavy", "title": "Multimodal Deep Learning for Flaw Detection in Software Programs", "comments": "13 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-9429R", "categories": "cs.LG cs.AI cs.CR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of multiple deep learning models for detecting flaws in\nsoftware programs. Current, standard approaches for flaw detection rely on a\nsingle representation of a software program (e.g., source code or a program\nbinary). We illustrate that, by using techniques from multimodal deep learning,\nwe can simultaneously leverage multiple representations of software programs to\nimprove flaw detection over single representation analyses. Specifically, we\nadapt three deep learning models from the multimodal learning literature for\nuse in flaw detection and demonstrate how these models outperform traditional\ndeep learning models. We present results on detecting software flaws using the\nJuliet Test Suite and Linux Kernel.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 20:15:11 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Heidbrink", "Scott", ""], ["Rodhouse", "Kathryn N.", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.04568", "submitter": "Bhavya Ghai", "authors": "Bhavya Ghai, Q. Vera Liao, Yunfeng Zhang, Klaus Mueller", "title": "Active Learning++: Incorporating Annotator's Rationale using Local Model\n  Explanation", "comments": "Accepted at Workshop on Data Science with Human in the Loop (DaSH) @\n  ACM SIGKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new active learning (AL) framework, Active Learning++, which can\nutilize an annotator's labels as well as its rationale. Annotators can provide\ntheir rationale for choosing a label by ranking input features based on their\nimportance for a given query. To incorporate this additional input, we modified\nthe disagreement measure for a bagging-based Query by Committee (QBC) sampling\nstrategy. Instead of weighing all committee models equally to select the next\ninstance, we assign higher weight to the committee model with higher agreement\nwith the annotator's ranking. Specifically, we generated a feature\nimportance-based local explanation for each committee model. The similarity\nscore between feature rankings provided by the annotator and the local model\nexplanation is used to assign a weight to each corresponding committee model.\nThis approach is applicable to any kind of ML model using model-agnostic\ntechniques to generate local explanation such as LIME. With a simulation study,\nwe show that our framework significantly outperforms a QBC based vanilla AL\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:07:33 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ghai", "Bhavya", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Mueller", "Klaus", ""]]}, {"id": "2009.04589", "submitter": "Andrey Rivkin", "authors": "Marco Montali, Andrey Rivkin, Daniel Ritter", "title": "Formalizing Integration Patterns with Multimedia Data (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The previous works on formalizing enterprise application integration (EAI)\nscenarios showed an emerging need for setting up formal foundations for\nintegration patterns, the EAI building blocks, in order to facilitate the\nmodel-driven development and ensure its correctness. So far, the formalization\nrequirements were focusing on more \"conventional\" integration scenarios, in\nwhich control-flow, transactional persistent data and time aspects were\nconsidered. However, none of these works took into consideration another\narising EAI trend that covers social and multimedia computing. In this work we\npropose a Petri net-based formalism that addresses requirements arising from\nthe multimedia domain. We also demonstrate realizations of one of the most\nfrequently used multimedia patterns and discuss which implications our formal\nproposal may bring into the area of the multimedia EAI development.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 22:00:41 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 17:23:36 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Montali", "Marco", ""], ["Rivkin", "Andrey", ""], ["Ritter", "Daniel", ""]]}, {"id": "2009.04617", "submitter": "Sarah Finch", "authors": "Sarah E. Finch, James D. Finch, Ali Ahmadvand, Ingyu (Jason) Choi,\n  Xiangjue Dong, Ruixiang Qi, Harshita Sahijwani, Sergey Volokhin, Zihan Wang,\n  Zihao Wang, Jinho D. Choi", "title": "Emora: An Inquisitive Social Chatbot Who Cares For You", "comments": "Published in 3rd Proceedings of Alexa Prize (Alexa Prize 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by studies on the overwhelming presence of experience-sharing in\nhuman-human conversations, Emora, the social chatbot developed by Emory\nUniversity, aims to bring such experience-focused interaction to the current\nfield of conversational AI. The traditional approach of information-sharing\ntopic handlers is balanced with a focus on opinion-oriented exchanges that\nEmora delivers, and new conversational abilities are developed that support\ndialogues that consist of a collaborative understanding and learning process of\nthe partner's life experiences. We present a curated dialogue system that\nleverages highly expressive natural language templates, powerful intent\nclassification, and ontology resources to provide an engaging and interesting\nconversational experience to every user.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 00:42:59 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Finch", "Sarah E.", "", "Jason"], ["Finch", "James D.", "", "Jason"], ["Ahmadvand", "Ali", "", "Jason"], ["Ingyu", "", "", "Jason"], ["Choi", "", ""], ["Dong", "Xiangjue", ""], ["Qi", "Ruixiang", ""], ["Sahijwani", "Harshita", ""], ["Volokhin", "Sergey", ""], ["Wang", "Zihan", ""], ["Wang", "Zihao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2009.04640", "submitter": "Arjun Prakash", "authors": "Lauren Boswell, Arjun Prakash", "title": "On the Fairness of 'Fake' Data in Legal AI", "comments": "Submitted to the Artificial Intelligence Ethics Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The economics of smaller budgets and larger case numbers necessitates the use\nof AI in legal proceedings. We examine the concept of disparate impact and how\nbiases in the training data lead to the search for fairer AI. This paper seeks\nto begin the discourse on what such an implementation would actually look like\nwith a criticism of pre-processing methods in a legal context . We outline how\npre-processing is used to correct biased data and then examine the legal\nimplications of effectively changing cases in order to achieve a fairer outcome\nincluding the black box problem and the slow encroachment on legal precedent.\nFinally we present recommendations on how to avoid the pitfalls of\npre-processed data with methods that either modify the classifier or correct\nthe output in the final step.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:23:19 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 08:35:55 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Boswell", "Lauren", ""], ["Prakash", "Arjun", ""]]}, {"id": "2009.04647", "submitter": "Mauricio Arango", "authors": "Mauricio Arango, Lyudmil Pelov", "title": "COVID-19 Pandemic Cyclic Lockdown Optimization Using Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the use of reinforcement learning (RL) to optimize cyclic\nlockdowns, which is one of the methods available for control of the COVID-19\npandemic. The problem is structured as an optimal control system for tracking a\nreference value, corresponding to the maximum usage level of a critical\nresource, such as ICU beds. However, instead of using conventional optimal\ncontrol methods, RL is used to find optimal control policies. A framework was\ndeveloped to calculate optimal cyclic lockdown timings using an RL-based on-off\ncontroller. The RL-based controller is implemented as an RL agent that\ninteracts with an epidemic simulator, implemented as an extended SEIR epidemic\nmodel. The RL agent learns a policy function that produces an optimal sequence\nof open/lockdown decisions such that goals specified in the RL reward function\nare optimized. Two concurrent goals were used: the first one is a public health\ngoal that minimizes overshoots of ICU bed usage above an ICU bed threshold, and\nthe second one is a socio-economic goal that minimizes the time spent under\nlockdowns. It is assumed that cyclic lockdowns are considered as a temporary\nalternative to extended lockdowns when a region faces imminent danger of\noverpassing resource capacity limits and when imposing an extended lockdown\nwould cause severe social and economic consequences due to lack of necessary\neconomic resources to support its affected population during an extended\nlockdown.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:51:02 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Arango", "Mauricio", ""], ["Pelov", "Lyudmil", ""]]}, {"id": "2009.04682", "submitter": "Nagender Aneja", "authors": "Rajarshi Roy Chowdhury, Sandhya Aneja, Nagender Aneja, Emeroylariffion\n  Abas", "title": "Network Traffic Analysis based IoT Device Identification", "comments": null, "journal-ref": "International Conference on Big Data and Internet of Things\n  (BDIOT2020), August 22-24, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device identification is the process of identifying a device on Internet\nwithout using its assigned network or other credentials. The sharp rise of\nusage in Internet of Things (IoT) devices has imposed new challenges in device\nidentification due to a wide variety of devices, protocols and control\ninterfaces. In a network, conventional IoT devices identify each other by\nutilizing IP or MAC addresses, which are prone to spoofing. Moreover, IoT\ndevices are low power devices with minimal embedded security solution. To\nmitigate the issue in IoT devices, fingerprint (DFP) for device identification\ncan be used. DFP identifies a device by using implicit identifiers, such as\nnetwork traffic (or packets), radio signal, which a device used for its\ncommunication over the network. These identifiers are closely related to the\ndevice hardware and software features. In this paper, we exploit TCP/IP packet\nheader features to create a device fingerprint utilizing device originated\nnetwork packets. We present a set of three metrics which separate some features\nfrom a packet which contribute actively for device identification. To evaluate\nour approach, we used publicly accessible two datasets. We observed the\naccuracy of device genre classification 99.37% and 83.35% of accuracy in the\nidentification of an individual device from IoT Sentinel dataset. However,\nusing UNSW dataset device type identification accuracy reached up to 97.78%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 06:28:11 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chowdhury", "Rajarshi Roy", ""], ["Aneja", "Sandhya", ""], ["Aneja", "Nagender", ""], ["Abas", "Emeroylariffion", ""]]}, {"id": "2009.04695", "submitter": "Diego Antognini", "authors": "Blagoj Mitrevski, Milena Filipovic, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Momentum-based Gradient Methods in Multi-objective Recommender Systems", "comments": "Under review. 8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective gradient methods are becoming the standard for solving\nmulti-objective problems. Among others, they show promising results in\ndeveloping multi-objective recommender systems with both correlated and\nuncorrelated objectives. Classic multi-gradient descent usually relies on the\ncombination of the gradients, not including the computation of first and second\nmoments of the gradients. This leads to a brittle behavior and misses important\nareas in the solution space.\n  In this work, we create a multi-objective Adamize method that leverage the\nbenefits of the Adam optimizer in single-objective problems. This corrects and\nstabilizes the gradients of every objective before calculating a common\ngradient descent vector that optimizes all the objectives simultaneously. We\nevaluate the benefits of Multi-objective Adamize on two multi-objective\nrecommender systems and for three different objective combinations, both\ncorrelated or uncorrelated. We report significant improvements, measured with\nthree different Pareto front metrics: hypervolume, coverage, and spacing.\nFinally, we show that the Adamized Pareto front strictly dominates the previous\none on multiple objective pairs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:12:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Mitrevski", "Blagoj", ""], ["Filipovic", "Milena", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.04703", "submitter": "Taesun Whang", "authors": "Taesun Whang, Dongyub Lee, Dongsuk Oh, Chanhee Lee, Kijong Han,\n  Dong-hun Lee, Saebyeok Lee", "title": "Do Response Selection Models Really Know What's Next? Utterance\n  Manipulation Strategies for Multi-turn Response Selection", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the task of selecting the optimal response given a\nuser and system utterance history in retrieval-based multi-turn dialog systems.\nRecently, pre-trained language models (e.g., BERT, RoBERTa, and ELECTRA) showed\nsignificant improvements in various natural language processing tasks. This and\nsimilar response selection tasks can also be solved using such language models\nby formulating the tasks as dialog--response binary classification tasks.\nAlthough existing works using this approach successfully obtained\nstate-of-the-art results, we observe that language models trained in this\nmanner tend to make predictions based on the relatedness of history and\ncandidates, ignoring the sequential nature of multi-turn dialog systems. This\nsuggests that the response selection task alone is insufficient for learning\ntemporal dependencies between utterances. To this end, we propose utterance\nmanipulation strategies (UMS) to address this problem. Specifically, UMS\nconsist of several strategies (i.e., insertion, deletion, and search), which\naid the response selection model towards maintaining dialog coherence. Further,\nUMS are self-supervised methods that do not require additional annotation and\nthus can be easily incorporated into existing approaches. Extensive evaluation\nacross multiple languages and models shows that UMS are highly effective in\nteaching dialog consistency, which leads to models pushing the state-of-the-art\nwith significant margins on multiple public benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:39:05 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 11:28:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Whang", "Taesun", ""], ["Lee", "Dongyub", ""], ["Oh", "Dongsuk", ""], ["Lee", "Chanhee", ""], ["Han", "Kijong", ""], ["Lee", "Dong-hun", ""], ["Lee", "Saebyeok", ""]]}, {"id": "2009.04743", "submitter": "Tom Bewley", "authors": "Tom Bewley, Jonathan Lawry", "title": "TripleTree: A Versatile Interpretable Representation of Black Box Agents\n  and their Environments", "comments": "12 pages (incl. references and appendices), 15 figures. Pre-print,\n  under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In explainable artificial intelligence, there is increasing interest in\nunderstanding the behaviour of autonomous agents to build trust and validate\nperformance. Modern agent architectures, such as those trained by deep\nreinforcement learning, are currently so lacking in interpretable structure as\nto effectively be black boxes, but insights may still be gained from an\nexternal, behaviourist perspective. Inspired by conceptual spaces theory, we\nsuggest that a versatile first step towards general understanding is to\ndiscretise the state space into convex regions, jointly capturing similarities\nover the agent's action, value function and temporal dynamics within a dataset\nof observations. We create such a representation using a novel variant of the\nCART decision tree algorithm, and demonstrate how it facilitates practical\nunderstanding of black box agents through prediction, visualisation and\nrule-based explanation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:22:27 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:06:19 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bewley", "Tom", ""], ["Lawry", "Jonathan", ""]]}, {"id": "2009.04780", "submitter": "Krenare Pireva Nuci", "authors": "Denis Selimi, Krenare Pireva Nuci", "title": "The use of Recommender Systems in web technology and an in-depth\n  analysis of Cold State problem", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the WWW (World Wide Web), dynamic development and spread of data has\nresulted a tremendous amount of information available on the Internet, yet user\nis unable to find relevant information in a short span of time. Consequently, a\nsystem called recommendation system developed to help users find their\ninfromation with ease through their browsing activities. In other words,\nrecommender systems are tools for interacting with large amount of information\nthat provide personalized view for prioritizing items likely to be of keen for\nusers. They have developed over the years in artificial intelligence techniques\nthat include machine learning and data mining amongst many to mention.\nFurthermore, the recommendation systems have personalized on an e-commerce,\non-line applications such as Amazon.com, Netflix, and Booking.com. As a result,\nthis has inspired many researchers to extend the reach of recommendation\nsystems into new sets of challenges and problem areas that are yet to be truly\nsolved, primarily a problem with the case of making a recommendation to a new\nuser that is called cold-state (i.e. cold-start) user problem where the new\nuser might likely not yield much of information searched. Therfore, the purpose\nof this paper is to tackle the said cold-start problem with a few effecient\nmethods and challenges, as well as identify and overview the current state of\nrecommendation system as a whole\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:32:59 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Selimi", "Denis", ""], ["Nuci", "Krenare Pireva", ""]]}, {"id": "2009.04861", "submitter": "Ole-Christoffer Granmo", "authors": "K. Darshana Abeyrathna, Bimal Bhattarai, Morten Goodwin, Saeed Gorji,\n  Ole-Christoffer Granmo, Lei Jiao, Rupsa Saha, Rohan K. Yadav", "title": "Massively Parallel and Asynchronous Tsetlin Machine Architecture\n  Supporting Almost Constant-Time Scaling", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using logical clauses to represent patterns, Tsetlin Machines (TMs) have\nrecently obtained competitive performance in terms of accuracy, memory\nfootprint, energy, and learning speed on several benchmarks. Each TM clause\nvotes for or against a particular class, with classification resolved using a\nmajority vote. While the evaluation of clauses is fast, being based on binary\noperators, the voting makes it necessary to synchronize the clause evaluation,\nimpeding parallelization. In this paper, we propose a novel scheme for\ndesynchronizing the evaluation of clauses, eliminating the voting bottleneck.\nIn brief, every clause runs in its own thread for massive native parallelism.\nFor each training example, we keep track of the class votes obtained from the\nclauses in local voting tallies. The local voting tallies allow us to detach\nthe processing of each clause from the rest of the clauses, supporting\ndecentralized learning. This means that the TM most of the time will operate on\noutdated voting tallies. We evaluated the proposed parallelization across\ndiverse learning tasks and it turns out that our decentralized TM learning\nalgorithm copes well with working on outdated data, resulting in no significant\nloss in learning accuracy. Furthermore, we show that the proposed approach\nprovides up to 50 times faster learning. Finally, learning time is almost\nconstant for reasonable clause amounts (employing from 20 to 7,000 clauses on a\nTesla V100 GPU). For sufficiently large clause numbers, computation time\nincreases approximately proportionally. Our parallel and asynchronous\narchitecture thus allows processing of massive datasets and operating with more\nclauses for higher accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:48:33 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 18:24:26 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 18:53:48 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 15:17:34 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Bhattarai", "Bimal", ""], ["Goodwin", "Morten", ""], ["Gorji", "Saeed", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""], ["Saha", "Rupsa", ""], ["Yadav", "Rohan K.", ""]]}, {"id": "2009.04869", "submitter": "Jean-Guy Mailly", "authors": "Jean-Guy Mailly", "title": "A Note on Rich Incomplete Argumentation Frameworks", "comments": "Technical report, 12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, qualitative uncertainty in abstract argumentation has received much\nattention. The first works on this topic introduced uncertainty about the\npresence of attacks, then about the presence of arguments, and finally combined\nboth kinds of uncertainty. This results in the Incomplete Argumentation\nFramework (IAFs). But another kind of uncertainty was introduced in the context\nof Control Argumentation Frameworks (CAFs): it consists in a conflict relation\nwith uncertain orientation, i.e. we are sure that there is an attack between\ntwo arguments, but the actual direction of the attack is unknown. Here, we\nformally define Rich IAFs, that combine the three different kinds of\nuncertainty that were previously introduced in IAFs and CAFs. We show that this\nnew model, although strictly more expressive than IAFs, does not suffer from a\nblow up of computational complexity. Also, the existing computational approach\nbased on SAT can be easily adapted to the new framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:11:02 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 04:35:56 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 14:33:35 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mailly", "Jean-Guy", ""]]}, {"id": "2009.04875", "submitter": "Alexandre Galashov", "authors": "Alexandre Galashov, Jakub Sygnowski, Guillaume Desjardins, Jan\n  Humplik, Leonard Hasenclever, Rae Jeong, Yee Whye Teh, Nicolas Heess", "title": "Importance Weighted Policy Learning and Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to exploit prior experience to solve novel problems rapidly is a\nhallmark of biological learning systems and of great practical importance for\nartificial ones. In the meta reinforcement learning literature much recent work\nhas focused on the problem of optimizing the learning process itself. In this\npaper we study a complementary approach which is conceptually simple, general,\nmodular and built on top of recent improvements in off-policy learning. The\nframework is inspired by ideas from the probabilistic inference literature and\ncombines robust off-policy learning with a behavior prior, or default behavior\nthat constrains the space of solutions and serves as a bias for exploration; as\nwell as a representation for the value function, both of which are easily\nlearned from a number of training tasks in a multi-task scenario. Our approach\nachieves competitive adaptation performance on hold-out tasks compared to meta\nreinforcement learning baselines and can scale to complex sparse-reward\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:16:58 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:21:40 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Galashov", "Alexandre", ""], ["Sygnowski", "Jakub", ""], ["Desjardins", "Guillaume", ""], ["Humplik", "Jan", ""], ["Hasenclever", "Leonard", ""], ["Jeong", "Rae", ""], ["Teh", "Yee Whye", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.04903", "submitter": "Jean-Guy Mailly", "authors": "Jean-Guy Mailly", "title": "Possible Controllability of Control Argumentation Frameworks -- Extended\n  Version", "comments": "Extended version of a paper accepted at the 8th International\n  Conference on Computational Models of Argument, 15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent Control Argumentation Framework (CAF) is a generalization of\nDung's Argumentation Framework which handles argumentation dynamics under\nuncertainty; especially it can be used to model the behavior of an agent which\ncan anticipate future changes in the environment. Here we provide new insights\non this model by defining the notion of possible controllability of a CAF. We\nstudy the complexity of this new form of reasoning for the four classical\nsemantics, and we provide a logical encoding for reasoning with this framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:50:53 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Mailly", "Jean-Guy", ""]]}, {"id": "2009.04912", "submitter": "Joop van de Heijning", "authors": "Joop van de Heijning, Stephan Leitner, Alexandra Rausch", "title": "On the Effectiveness of Minisum Approval Voting in an Open Strategy\n  Setting: An Agent-Based Approach", "comments": "5 pages, 3 figures; ; added literature review section, expanded and\n  strengthened introduction and conclusion, grammar and formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.GN econ.TH q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work researches the impact of including a wider range of participants in\nthe strategy-making process on the performance of organizations which operate\nin either moderately or highly complex environments. Agent-based simulation\ndemonstrates that the increased number of ideas generated from larger and\ndiverse crowds and subsequent preference aggregation lead to rapid discovery of\nhigher peaks in the organization's performance landscape. However, this is not\nthe case when the expansion in the number of participants is small. The results\nconfirm the most frequently mentioned benefit in the Open Strategy literature:\nthe discovery of better performing strategies.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:50:35 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 15:27:58 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["van de Heijning", "Joop", ""], ["Leitner", "Stephan", ""], ["Rausch", "Alexandra", ""]]}, {"id": "2009.04965", "submitter": "Meng-Jiun Chiou", "authors": "Meng-Jiun Chiou, Roger Zimmermann, Jiashi Feng", "title": "Visual Relationship Detection with Visual-Linguistic Knowledge from\n  Multimodal Representations", "comments": "Published in IEEE Access", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3069041", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relationship detection aims to reason over relationships among salient\nobjects in images, which has drawn increasing attention over the past few\nyears. Inspired by human reasoning mechanisms, it is believed that external\nvisual commonsense knowledge is beneficial for reasoning visual relationships\nof objects in images, which is however rarely considered in existing methods.\nIn this paper, we propose a novel approach named Relational Visual-Linguistic\nBidirectional Encoder Representations from Transformers (RVL-BERT), which\nperforms relational reasoning with both visual and language commonsense\nknowledge learned via self-supervised pre-training with multimodal\nrepresentations. RVL-BERT also uses an effective spatial module and a novel\nmask attention module to explicitly capture spatial information among the\nobjects. Moreover, our model decouples object detection from visual\nrelationship recognition by taking in object names directly, enabling it to be\nused on top of any object detection system. We show through quantitative and\nqualitative experiments that, with the transferred knowledge and novel modules,\nRVL-BERT achieves competitive results on two challenging visual relationship\ndetection datasets. The source code is available at\nhttps://github.com/coldmanck/RVL-BERT.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:15:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:01:49 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 07:48:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chiou", "Meng-Jiun", ""], ["Zimmermann", "Roger", ""], ["Feng", "Jiashi", ""]]}, {"id": "2009.04978", "submitter": "Iliana M. Petrova", "authors": "Piero A. Bonatti, Iliana M. Petrova, Luigi Sauro", "title": "Defeasible reasoning in Description Logics: an overview on DL^N", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DL^N is a recent approach that extends description logics with defeasible\nreasoning capabilities. In this paper we provide an overview on DL^N,\nillustrating the underlying knowledge engineering requirements as well as the\ncharacteristic features that preserve DL^N from some recurrent semantic and\ncomputational drawbacks. We also compare DL^N with some alternative\nnonmonotonic semantics, enlightening the relationships between the KLM\npostulates and DL^N.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:30:30 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 14:37:31 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Bonatti", "Piero A.", ""], ["Petrova", "Iliana M.", ""], ["Sauro", "Luigi", ""]]}, {"id": "2009.05104", "submitter": "Henry Charlesworth", "authors": "Henry Charlesworth and Giovanni Montana", "title": "Solving Challenging Dexterous Manipulation Tasks With Trajectory\n  Optimisation and Reinforcement Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training agents to autonomously learn how to use anthropomorphic robotic\nhands has the potential to lead to systems capable of performing a multitude of\ncomplex manipulation tasks in unstructured and uncertain environments. In this\nwork, we first introduce a suite of challenging simulated manipulation tasks\nthat current reinforcement learning and trajectory optimisation techniques find\ndifficult. These include environments where two simulated hands have to pass or\nthrow objects between each other, as well as an environment where the agent\nmust learn to spin a long pen between its fingers. We then introduce a simple\ntrajectory optimisation that performs significantly better than existing\nmethods on these environments. Finally, on the challenging PenSpin task we\ncombine sub-optimal demonstrations generated through trajectory optimisation\nwith off-policy reinforcement learning, obtaining performance that far exceeds\neither of these approaches individually, effectively solving the environment.\nVideos of all of our results are available at:\nhttps://dexterous-manipulation.github.io/\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 13:49:52 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 19:32:26 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Charlesworth", "Henry", ""], ["Montana", "Giovanni", ""]]}, {"id": "2009.05161", "submitter": "Pavel Surynek", "authors": "Pavel Surynek", "title": "Multi-Goal Multi-Agent Path Finding via Decoupled and Integrated Goal\n  Vertex Ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce multi-goal multi agent path finding (MAPF$^{MG}$) which\ngeneralizes the standard discrete multi-agent path finding (MAPF) problem.\nWhile the task in MAPF is to navigate agents in an undirected graph from their\nstarting vertices to one individual goal vertex per agent, MAPF$^{MG}$ assigns\neach agent multiple goal vertices and the task is to visit each of them at\nleast once. Solving MAPF$^{MG}$ not only requires finding collision free paths\nfor individual agents but also determining the order of visiting agent's goal\nvertices so that common objectives like the sum-of-costs are optimized. We\nsuggest two novel algorithms using different paradigms to address MAPF$^{MG}$:\na heuristic search-based search algorithm called Hamiltonian-CBS (HCBS) and a\ncompilation-based algorithm built using the SMT paradigm, called\nSMT-Hamiltonian-CBS (SMT-HCBS). Experimental comparison suggests limitations of\ncompilation-based approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:27:18 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Surynek", "Pavel", ""]]}, {"id": "2009.05186", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Juan Carlos Nieves, Ayslan Possebom, Josep\n  Puyol-Gruart, and Cesar Augusto Tacla", "title": "An Argumentation-based Approach for Identifying and Dealing with\n  Incompatibilities among Procedural Goals", "comments": "31 pages, 9 figures, Accepted in the International Journal of\n  Approximate Reasoning (2019)", "journal-ref": "International Journal of Approximate Reasoning, year 2019, vol.\n  105, pp. 1-26", "doi": "10.4114/intartif.vol22iss64pp47-62", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  During the first step of practical reasoning, i.e. deliberation, an\nintelligent agent generates a set of pursuable goals and then selects which of\nthem he commits to achieve. An intelligent agent may in general generate\nmultiple pursuable goals, which may be incompatible among them. In this paper,\nwe focus on the definition, identification and resolution of these\nincompatibilities. The suggested approach considers the three forms of\nincompatibility introduced by Castelfranchi and Paglieri, namely the terminal\nincompatibility, the instrumental or resources incompatibility and the\nsuperfluity. We characterise computationally these forms of incompatibility by\nmeans of arguments that represent the plans that allow an agent to achieve his\ngoals. Thus, the incompatibility among goals is defined based on the conflicts\namong their plans, which are represented by means of attacks in an\nargumentation framework. We also work on the problem of goals selection; we\npropose to use abstract argumentation theory to deal with this problem, i.e. by\napplying argumentation semantics. We use a modified version of the \"cleaner\nworld\" scenario in order to illustrate the performance of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 01:01:34 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Nieves", "Juan Carlos", ""], ["Possebom", "Ayslan", ""], ["Puyol-Gruart", "Josep", ""], ["Tacla", "Cesar Augusto", ""]]}, {"id": "2009.05199", "submitter": "Daniel Nemirovsky", "authors": "Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, Abhishek Gupta", "title": "CounteRGAN: Generating Realistic Counterfactuals with Residual\n  Generative Adversarial Nets", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of machine learning models in various industries has led to\ngrowing demands for model interpretability and for the ability to provide\nmeaningful recourse to users. For example, patients hoping to improve their\ndiagnoses or loan applicants seeking to increase their chances of approval.\nCounterfactuals can help in this regard by identifying input perturbations that\nwould result in more desirable prediction outcomes. Meaningful counterfactuals\nshould be able to achieve the desired outcome, but also be realistic,\nactionable, and efficient to compute. Current approaches achieve desired\noutcomes with moderate actionability but are severely limited in terms of\nrealism and latency. To tackle these limitations, we apply Generative\nAdversarial Nets (GANs) toward counterfactual search. We also introduce a novel\nResidual GAN (RGAN) that helps to improve counterfactual realism and\nactionability compared to regular GANs. The proposed CounteRGAN method utilizes\nan RGAN and a target classifier to produce counterfactuals capable of providing\nmeaningful recourse. Evaluations on two popular datasets highlight how the\nCounteRGAN is able to overcome the limitations of existing methods, including\nlatency improvements of >50x to >90,000x, making meaningful recourse available\nin real-time and applicable to a wide range of domains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 02:08:19 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 06:25:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Nemirovsky", "Daniel", ""], ["Thiebaut", "Nicolas", ""], ["Xu", "Ye", ""], ["Gupta", "Abhishek", ""]]}, {"id": "2009.05260", "submitter": "Markus Borg", "authors": "Markus Borg", "title": "The AIQ Meta-Testbed: Pragmatically Bridging Academic AI Testing and\n  Industrial Q Needs", "comments": "Accepted for publication in the Proc. of the Software Quality Days\n  2021, Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI solutions seem to appear in any and all application domains. As AI becomes\nmore pervasive, the importance of quality assurance increases. Unfortunately,\nthere is no consensus on what artificial intelligence means and interpretations\nrange from simple statistical analysis to sentient humanoid robots. On top of\nthat, quality is a notoriously hard concept to pinpoint. What does this mean\nfor AI quality? In this paper, we share our working definition and a pragmatic\napproach to address the corresponding quality assurance with a focus on\ntesting. Finally, we present our ongoing work on establishing the AIQ\nMeta-Testbed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 07:31:23 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Borg", "Markus", ""]]}, {"id": "2009.05282", "submitter": "Sahbi Sidhom", "authors": "Pedro Barrios, Davy Monticolo (ENSGSI), Sahbi Sidhom (KIWI)", "title": "Results of multi-agent system and ontology to manage ideas and represent\n  knowledge in a challenge of creativity", "comments": null, "journal-ref": "International Multi-Conference OCTA'2019 on Organization of\n  Knowledge and Advanced Technologies, University of Tunis (Tunisia) &\n  International scholarly society ISKO Maghreb, Feb 2020, Tunis (ALECSO),\n  Tunisia. pp.6-17", "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about an intelligent system to support ideas management as a\nresult of a multi-agent system used in a distributed system with heterogeneous\ninformation as ideas and knowledge, after the results about an ontology to\ndescribe the meaning of these ideas. The intelligent system assists\nparticipants of the creativity workshop to manage their ideas and consequently\nproposing an ontology dedicated to ideas. During the creative workshop many\ncreative activities and collaborative creative methods are used by roles\nimmersed in this creativity workshop event where they share knowledge. The\ncollaboration of these roles is physically distant, their interactions might be\nsynchrony or asynchrony, and the information of the ideas are heterogeneous, so\nwe can say that the process is distributed. Those ideas are writing in natural\nlanguage by participants which have a role and the ideas are heterogeneous\nsince some of them are described by schema, text or scenario of use. This paper\npresents first, our MAS and second our Ontology design.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:31:30 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Barrios", "Pedro", "", "ENSGSI"], ["Monticolo", "Davy", "", "ENSGSI"], ["Sidhom", "Sahbi", "", "KIWI"]]}, {"id": "2009.05283", "submitter": "David Berend", "authors": "Yushi Cao, David Berend, Palina Tolmach, Guy Amit, Moshe Levy, Yang\n  Liu, Asaf Shabtai, Yuval Elovici", "title": "Out-of-distribution detection and generalization to enhance fairness in\n  age prediction", "comments": "15 pages, 8 Figures, pre-print, adjusted title and content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based facial recognition systems have experienced increased\nmedia attention due to exhibiting unfair behavior. Large enterprises, such as\nIBM, shut down their facial recognition and age prediction systems as a\nconsequence. Age prediction is an especially difficult application with the\nissue of fairness remaining an open research problem (e.g. predicting age for\ndifferent ethnicity equally accurate). One of the main causes of unfair\nbehavior in age prediction methods lies in the distribution and diversity of\nthe training data. In this work, we present two novel approaches for dataset\ncuration and data augmentation in order to increase fairness through\ndistribution aware curation and increase diversity through distribution aware\naugmentation. To achieve this, we created an out-of-distribution technique\nwhich is used to select the data most relevant to the deep neural network's\n(DNN) task when balancing the data among age, ethnicity, and gender. Our\napproach shows promising results. Our best-trained DNN model outperformed all\nacademic and industrial baselines in terms of fairness by up to 4.92 times.\nWhen it comes to generalization, the increase in diversity also enhanced the\nDNN's performance, outperforming state-of-the-art approaches of prior research\non the Age Estimation Benchmark dataset AFAD by 30.40% and the Amazon AWS and\nMicrosoft Azure public cloud systems by 31.88% and 10.95%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:32:36 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 01:14:56 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 05:52:51 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 13:02:48 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Cao", "Yushi", ""], ["Berend", "David", ""], ["Tolmach", "Palina", ""], ["Amit", "Guy", ""], ["Levy", "Moshe", ""], ["Liu", "Yang", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2009.05322", "submitter": "Aditya Lahiri", "authors": "Aditya Lahiri, Narayanan Unny Edakunni", "title": "Accurate and Intuitive Contextual Explanations using Linear Model Trees", "comments": "KDD Workshop on ML in Finance 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing use of complex machine learning models in critical\napplications within the finance domain, explaining the decisions of the model\nhas become a necessity. With applications spanning from credit scoring to\ncredit marketing, the impact of these models is undeniable. Among the multiple\nways in which one can explain the decisions of these complicated models, local\npost hoc model agnostic explanations have gained massive adoption. These\nmethods allow one to explain each prediction independent of the modelling\ntechnique that was used while training. As explanations, they either give\nindividual feature attributions or provide sufficient rules that represent\nconditions for a prediction to be made. The current state of the art methods\nuse rudimentary methods to generate synthetic data around the point to be\nexplained. This is followed by fitting simple linear models as surrogates to\nobtain a local interpretation of the prediction. In this paper, we seek to\nsignificantly improve on both, the method used to generate the explanations and\nthe nature of explanations produced. We use a Generative Adversarial Network\nfor synthetic data generation and train a piecewise linear model in the form of\nLinear Model Trees to be used as the surrogate model.In addition to individual\nfeature attributions, we also provide an accompanying context to our\nexplanations by leveraging the structure and property of our surrogate model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:13:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Lahiri", "Aditya", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2009.05359", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil K Seth, Christopher L Buckley", "title": "Activation Relaxation: A Local Dynamical Approximation to\n  Backpropagation in the Brain", "comments": "initial upload; revised version (updated abstract, related work)\n  28-09-20; 05/10/20: revised for ICLR submission; 10/10/20: minor revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation of error algorithm (backprop) has been instrumental in\nthe recent success of deep learning. However, a key question remains as to\nwhether backprop can be formulated in a manner suitable for implementation in\nneural circuitry. The primary challenge is to ensure that any candidate\nformulation uses only local information, rather than relying on global signals\nas in standard backprop. Recently several algorithms for approximating backprop\nusing only local signals have been proposed. However, these algorithms\ntypically impose other requirements which challenge biological plausibility:\nfor example, requiring complex and precise connectivity schemes, or multiple\nsequential backwards phases with information being stored across phases. Here,\nwe propose a novel algorithm, Activation Relaxation (AR), which is motivated by\nconstructing the backpropagation gradient as the equilibrium point of a\ndynamical system. Our algorithm converges rapidly and robustly to the correct\nbackpropagation gradients, requires only a single type of computational unit,\nutilises only a single parallel backwards relaxation phase, and can operate on\narbitrary computation graphs. We illustrate these properties by training deep\nneural networks on visual classification tasks, and describe simplifications to\nthe algorithm which remove further obstacles to neurobiological implementation\n(for example, the weight-transport problem, and the use of nonlinear\nderivatives), while preserving performance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 11:56:34 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 10:37:05 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 21:19:22 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 18:21:01 GMT"}, {"version": "v5", "created": "Sat, 10 Oct 2020 14:16:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil K", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2009.05429", "submitter": "Steven Morad", "authors": "Steven D. Morad, Roberto Mecca, Rudra P.K. Poudel, Stephan Liwicki,\n  and Roberto Cipolla", "title": "Embodied Visual Navigation with Automatic Curriculum Learning in Real\n  Environments", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2020.3048662", "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NavACL, a method of automatic curriculum learning tailored to the\nnavigation task. NavACL is simple to train and efficiently selects relevant\ntasks using geometric features. In our experiments, deep reinforcement learning\nagents trained using NavACL significantly outperform state-of-the-art agents\ntrained with uniform sampling -- the current standard. Furthermore, our agents\ncan navigate through unknown cluttered indoor environments to\nsemantically-specified targets using only RGB images. Obstacle-avoiding\npolicies and frozen feature networks support transfer to unseen real-world\nenvironments, without any modification or retraining requirements. We evaluate\nour policies in simulation, and in the real world on a ground robot and a\nquadrotor drone. Videos of real-world results are available in the\nsupplementary material.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:28:26 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 18:29:42 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Morad", "Steven D.", ""], ["Mecca", "Roberto", ""], ["Poudel", "Rudra P. K.", ""], ["Liwicki", "Stephan", ""], ["Cipolla", "Roberto", ""]]}, {"id": "2009.05438", "submitter": "Ghada El-Khawaga", "authors": "Ghada Elkhawaga, Mervat Abuelkheir, Sherif I. Barakat, Alaa M. Riad\n  and Manfred Reichert", "title": "CONDA-PM -- A Systematic Review and Framework for Concept Drift Analysis\n  in Process Mining", "comments": "45 pages, 11 tables, 13 figures", "journal-ref": "Algorithms 2020, 13(7), 161", "doi": "10.3390/a13070161", "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes evolve over time to adapt to changing business\nenvironments. This requires continuous monitoring of business processes to gain\ninsights into whether they conform to the intended design or deviate from it.\nThe situation when a business process changes while being analysed is denoted\nas Concept Drift. Its analysis is concerned with studying how a business\nprocess changes, in terms of detecting and localising changes and studying the\neffects of the latter. Concept drift analysis is crucial to enable early\ndetection and management of changes, that is, whether to promote a change to\nbecome part of an improved process, or to reject the change and make decisions\nto mitigate its effects. Despite its importance, there exists no comprehensive\nframework for analysing concept drift types, affected process perspectives, and\ngranularity levels of a business process. This article proposes the CONcept\nDrift Analysis in Process Mining (CONDA-PM) framework describing phases and\nrequirements of a concept drift analysis approach. CONDA-PM was derived from a\nSystematic Literature Review (SLR) of current approaches analysing concept\ndrift. We apply the CONDA-PM framework on current approaches to concept drift\nanalysis and evaluate their maturity. Applying CONDA-PM framework highlights\nareas where research is needed to complement existing efforts.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:39:09 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Elkhawaga", "Ghada", ""], ["Abuelkheir", "Mervat", ""], ["Barakat", "Sherif I.", ""], ["Riad", "Alaa M.", ""], ["Reichert", "Manfred", ""]]}, {"id": "2009.05487", "submitter": "Timo Freiesleben", "authors": "Timo Freiesleben", "title": "Counterfactual Explanations & Adversarial Examples -- Common Grounds,\n  Essential Differences, and Potential Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The same optimization problem underlies counterfactual explanations (CEs) and\nadversarial examples (AEs). While this is well known, the relationship between\nthe two at the conceptual level remains unclear. The present paper provides\nexactly the missing conceptual link. We compare CEs and AEs with respect to\ntheir philosophical basis, aims, and modeling techniques. We argue that CEs are\na more general object-class than AEs. In particular, we introduce the\nconceptual distinction between feasible and contesting CEs and show that AEs\ncorrespond to the latter.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:09:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 10:05:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Freiesleben", "Timo", ""]]}, {"id": "2009.05524", "submitter": "Arthur Guez", "authors": "Mehdi Mirza, Andrew Jaegle, Jonathan J. Hunt, Arthur Guez, Saran\n  Tunyasuvunakool, Alistair Muldal, Th\\'eophane Weber, Peter Karkus,\n  S\\'ebastien Racani\\`ere, Lars Buesing, Timothy Lillicrap, Nicolas Heess", "title": "Physically Embedded Planning Problems: New Challenges for Reinforcement\n  Learning", "comments": "17 pages + appendix. Updated text and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in deep reinforcement learning (RL) has produced algorithms\ncapable of mastering challenging games such as Go, chess, or shogi. In these\nworks the RL agent directly observes the natural state of the game and controls\nthat state directly with its actions. However, when humans play such games,\nthey do not just reason about the moves but also interact with their physical\nenvironment. They understand the state of the game by looking at the physical\nboard in front of them and modify it by manipulating pieces using touch and\nfine-grained motor control. Mastering complicated physical systems with\nabstract goals is a central challenge for artificial intelligence, but it\nremains out of reach for existing RL algorithms. To encourage progress towards\nthis goal we introduce a set of physically embedded planning problems and make\nthem publicly available. We embed challenging symbolic tasks (Sokoban,\ntic-tac-toe, and Go) in a physics engine to produce a set of tasks that require\nperception, reasoning, and motor control over long time horizons. Although\nexisting RL algorithms can tackle the symbolic versions of these tasks, we find\nthat they struggle to master even the simplest of their physically embedded\ncounterparts. As a first step towards characterizing the space of solution to\nthese tasks, we introduce a strong baseline that uses a pre-trained expert game\nplayer to provide hints in the abstract space to an RL agent's policy while\ntraining it on the full sensorimotor control task. The resulting agent solves\nmany of the tasks, underlining the need for methods that bridge the gap between\nabstract planning and embodied control. See illustrating video at\nhttps://youtu.be/RwHiHlym_1k.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 16:56:33 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:28:38 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Mirza", "Mehdi", ""], ["Jaegle", "Andrew", ""], ["Hunt", "Jonathan J.", ""], ["Guez", "Arthur", ""], ["Tunyasuvunakool", "Saran", ""], ["Muldal", "Alistair", ""], ["Weber", "Th\u00e9ophane", ""], ["Karkus", "Peter", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Buesing", "Lars", ""], ["Lillicrap", "Timothy", ""], ["Heess", "Nicolas", ""]]}, {"id": "2009.05552", "submitter": "Qi Huang", "authors": "Tong Gao, Qi Huang, Raymond J. Mooney", "title": "Systematic Generalization on gSCAN with Language Conditioned Embedding", "comments": "Accepted by AACL-IJCNLP 2020. Huang and Gao share co-first\n  authorship, authors contribute equally and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic Generalization refers to a learning algorithm's ability to\nextrapolate learned behavior to unseen situations that are distinct but\nsemantically similar to its training data. As shown in recent work,\nstate-of-the-art deep learning models fail dramatically even on tasks for which\nthey are designed when the test set is systematically different from the\ntraining data. We hypothesize that explicitly modeling the relations between\nobjects in their contexts while learning their representations will help\nachieve systematic generalization. Therefore, we propose a novel method that\nlearns objects' contextualized embeddings with dynamic message passing\nconditioned on the input natural language and end-to-end trainable with other\ndownstream deep learning modules. To our knowledge, this model is the first one\nthat significantly outperforms the provided baseline and reaches\nstate-of-the-art performance on grounded-SCAN (gSCAN), a grounded natural\nlanguage navigation dataset designed to require systematic generalization in\nits test splits.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:35:05 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 20:59:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gao", "Tong", ""], ["Huang", "Qi", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2009.05602", "submitter": "Lan Zhang", "authors": "Lan Zhang, Peng Liu, Yoon-Ho Choi", "title": "Semantic-preserving Reinforcement Learning Attack Against Graph Neural\n  Networks for Malware Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an increasing number of deep-learning-based malware scanners have been\nproposed, the existing evasion techniques, including code obfuscation and\npolymorphic malware, are found to be less effective. In this work, we propose a\nreinforcement learning-based semantics-preserving\n(i.e.functionality-preserving) attack against black-box GNNs (GraphNeural\nNetworks) for malware detection. The key factor of adversarial malware\ngeneration via semantic Nops insertion is to select the appropriate\nsemanticNopsand their corresponding basic blocks. The proposed attack uses\nreinforcement learning to automatically make these \"how to select\" decisions.\nTo evaluate the attack, we have trained two kinds of GNNs with five types(i.e.,\nBackdoor, Trojan-Downloader, Trojan-Ransom, Adware, and Worm) of Windows\nmalware samples and various benign Windows programs. The evaluation results\nhave shown that the proposed attack can achieve a significantly higher evasion\nrate than three baseline attacks, namely the semantics-preserving random\ninstruction insertion attack, the semantics-preserving accumulative instruction\ninsertion attack, and the semantics-preserving gradient-based instruction\ninsertion attack.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:30:35 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 15:38:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Lan", ""], ["Liu", "Peng", ""], ["Choi", "Yoon-Ho", ""]]}, {"id": "2009.05603", "submitter": "Dumitru-Clementin Cercel", "authors": "Andrei-Marius Avram, Dumitru-Clementin Cercel, Costin-Gabriel Chiru", "title": "UPB at SemEval-2020 Task 6: Pretrained Language Models for Definition\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents our contribution in the context of the 6th task of\nSemEval-2020: Extracting Definitions from Free Text in Textbooks (DeftEval).\nThis competition consists of three subtasks with different levels of\ngranularity: (1) classification of sentences as definitional or\nnon-definitional,(2) labeling of definitional sentences, and (3) relation\nclassification. We use various pretrained language models (i.e., BERT, XLNet,\nRoBERTa, SciBERT, and ALBERT) to solve each of the three subtasks of the\ncompetition. Specifically, for each language model variant, we experiment by\nboth freezing its weights and fine-tuning them. We also explore a multi-task\narchitecture that was trained to jointly predict the outputs for the second and\nthe third subtasks. Our best performing model evaluated on the DeftEval dataset\nobtains the 32nd place for the first subtask and the 37th place for the second\nsubtask. The code is available for further research at:\nhttps://github.com/avramandrei/DeftEval.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:36:22 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:33:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Avram", "Andrei-Marius", ""], ["Cercel", "Dumitru-Clementin", ""], ["Chiru", "Costin-Gabriel", ""]]}, {"id": "2009.05609", "submitter": "Haomin Chen", "authors": "Haomin Chen, Shun Miao, Daguang Xu, Gregory D. Hager, Adam P. Harrison", "title": "Deep Hiearchical Multi-Label Classification Applied to Chest X-Ray\n  Abnormality Taxonomies", "comments": null, "journal-ref": "MEDIMA 101811, 5 September 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CXRs are a crucial and extraordinarily common diagnostic tool, leading to\nheavy research for CAD solutions. However, both high classification accuracy\nand meaningful model predictions that respect and incorporate clinical\ntaxonomies are crucial for CAD usability. To this end, we present a deep HMLC\napproach for CXR CAD. Different than other hierarchical systems, we show that\nfirst training the network to model conditional probability directly and then\nrefining it with unconditional probabilities is key in boosting performance. In\naddition, we also formulate a numerically stable cross-entropy loss function\nfor unconditional probabilities that provides concrete performance\nimprovements. Finally, we demonstrate that HMLC can be an effective means to\nmanage missing or incomplete labels. To the best of our knowledge, we are the\nfirst to apply HMLC to medical imaging CAD. We extensively evaluate our\napproach on detecting abnormality labels from the CXR arm of the PLCO dataset,\nwhich comprises over $198,000$ manually annotated CXRs. When using complete\nlabels, we report a mean AUC of 0.887, the highest yet reported for this\ndataset. These results are supported by ancillary experiments on the PadChest\ndataset, where we also report significant improvements, 1.2% and 4.1% in AUC\nand AP, respectively over strong \"flat\" classifiers. Finally, we demonstrate\nthat our HMLC approach can much better handle incompletely labelled data. These\nperformance improvements, combined with the inherent usefulness of taxonomic\npredictions, indicate that our approach represents a useful step forward for\nCXR CAD.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:50:23 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 15:47:54 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 18:47:52 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Chen", "Haomin", ""], ["Miao", "Shun", ""], ["Xu", "Daguang", ""], ["Hager", "Gregory D.", ""], ["Harrison", "Adam P.", ""]]}, {"id": "2009.05613", "submitter": "Rohan Chitnis", "authors": "Tom Silver, Rohan Chitnis, Aidan Curtis, Joshua Tenenbaum, Tomas\n  Lozano-Perez, Leslie Pack Kaelbling", "title": "Planning with Learned Object Importance in Large Problem Instances using\n  Graph Neural Networks", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world planning problems often involve hundreds or even thousands of\nobjects, straining the limits of modern planners. In this work, we address this\nchallenge by learning to predict a small set of objects that, taken together,\nwould be sufficient for finding a plan. We propose a graph neural network\narchitecture for predicting object importance in a single inference pass, thus\nincurring little overhead while greatly reducing the number of objects that\nmust be considered by the planner. Our approach treats the planner and\ntransition model as black boxes, and can be used with any off-the-shelf\nplanner. Empirically, across classical planning, probabilistic planning, and\nrobotic task and motion planning, we find that our method results in planning\nthat is significantly faster than several baselines, including other partial\ngrounding strategies and lifted planners. We conclude that learning to predict\na sufficient set of objects for a planning problem is a simple, powerful, and\ngeneral mechanism for planning in large instances. Video:\nhttps://youtu.be/FWsVJc2fvCE Code: https://git.io/JIsqX\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:55:08 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:58:17 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Silver", "Tom", ""], ["Chitnis", "Rohan", ""], ["Curtis", "Aidan", ""], ["Tenenbaum", "Joshua", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2009.05643", "submitter": "Diego Perez Liebana Dr.", "authors": "Diego Perez-Liebana, Alexander Dockhorn, Jorge Hurtado Grueso, Dominik\n  Jeurissen", "title": "The Design Of \"Stratega\": A General Strategy Games Framework", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratega, a general strategy games framework, has been designed to foster\nresearch on computational intelligence for strategy games. In contrast to other\nstrategy game frameworks, Stratega allows to create a wide variety of\nturn-based and real-time strategy games using a common API for agent\ndevelopment. While the current version supports the development of turn-based\nstrategy games and agents, we will add support for real-time strategy games in\nfuture updates. Flexibility is achieved by utilising YAML-files to configure\ntiles, units, actions, and levels. Therefore, the user can design and run a\nvariety of games to test developed agents without specifically adjusting it to\nthe game being generated. The framework has been built with a focus of\nstatistical forward planning (SFP) agents. For this purpose, agents can access\nand modify game-states and use the forward model to simulate the outcome of\ntheir actions. While SFP agents have shown great flexibility in general\ngame-playing, their performance is limited in case of complex state and\naction-spaces. Finally, we hope that the development of this framework and its\nrespective agents helps to better understand the complex decision-making\nprocess in strategy games. Stratega can be downloaded at:\nhttps://github.research.its.qmul.ac.uk/eecsgameai/Stratega\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:02:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Perez-Liebana", "Diego", ""], ["Dockhorn", "Alexander", ""], ["Grueso", "Jorge Hurtado", ""], ["Jeurissen", "Dominik", ""]]}, {"id": "2009.05647", "submitter": "Murad Tukan", "authors": "Murad Tukan and Alaa Maalouf and Matan Weksler and Dan Feldman", "title": "Compressed Deep Networks: Goodbye SVD, Hello Robust Low-Rank\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common technique for compressing a neural network is to compute the\n$k$-rank $\\ell_2$ approximation $A_{k,2}$ of the matrix\n$A\\in\\mathbb{R}^{n\\times d}$ that corresponds to a fully connected layer (or\nembedding layer). Here, $d$ is the number of the neurons in the layer, $n$ is\nthe number in the next one, and $A_{k,2}$ can be stored in $O((n+d)k)$ memory\ninstead of $O(nd)$.\n  This $\\ell_2$-approximation minimizes the sum over every entry to the power\nof $p=2$ in the matrix $A - A_{k,2}$, among every matrix\n$A_{k,2}\\in\\mathbb{R}^{n\\times d}$ whose rank is $k$. While it can be computed\nefficiently via SVD, the $\\ell_2$-approximation is known to be very sensitive\nto outliers (\"far-away\" rows). Hence, machine learning uses e.g. Lasso\nRegression, $\\ell_1$-regularization, and $\\ell_1$-SVM that use the\n$\\ell_1$-norm.\n  This paper suggests to replace the $k$-rank $\\ell_2$ approximation by\n$\\ell_p$, for $p\\in [1,2]$. We then provide practical and provable\napproximation algorithms to compute it for any $p\\geq1$, based on modern\ntechniques in computational geometry.\n  Extensive experimental results on the GLUE benchmark for compressing BERT,\nDistilBERT, XLNet, and RoBERTa confirm this theoretical advantage. For example,\nour approach achieves $28\\%$ compression of RoBERTa's embedding layer with only\n$0.63\\%$ additive drop in the accuracy (without fine-tuning) in average over\nall tasks in GLUE, compared to $11\\%$ drop using the existing\n$\\ell_2$-approximation. Open code is provided for reproducing and extending our\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:21:42 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 12:24:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tukan", "Murad", ""], ["Maalouf", "Alaa", ""], ["Weksler", "Matan", ""], ["Feldman", "Dan", ""]]}, {"id": "2009.05651", "submitter": "Shyam Thombre", "authors": "Shivani Shimpi, Shyam Thombre, Snehal Reddy, Ritik Sharma, Srijan\n  Singh", "title": "Multimodal Depression Severity Prediction from medical bio-markers using\n  Machine Learning Tools and Technologies", "comments": "The paper content has one major problem in a section that is needs\n  more attention and some work, and is agreed by all authors. The change is\n  necessary in terms of correctness and completeness of the paper. Hence,\n  requesting for the withdrawal to allow for the changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Depression has been a leading cause of mental-health illnesses across the\nworld. While the loss of lives due to unmanaged depression is a subject of\nattention, so is the lack of diagnostic tests and subjectivity involved. Using\nbehavioural cues to automate depression diagnosis and stage prediction in\nrecent years has relatively increased. However, the absence of labelled\nbehavioural datasets and a vast amount of possible variations prove to be a\nmajor challenge in accomplishing the task. This paper proposes a novel Custom\nCM Ensemble approach and focuses on a paradigm of a cross-platform smartphone\napplication that takes multimodal inputs from a user through a series of\npre-defined questions, sends it to the Cloud ML architecture and conveys back a\ndepression quotient, representative of its severity. Our app estimates the\nseverity of depression based on a multi-class classification model by utilizing\nthe language, audio, and visual modalities. The given approach attempts to\ndetect, emphasize, and classify the features of a depressed person based on the\nlow-level descriptors for verbal and visual features, and context of the\nlanguage features when prompted with a question. The model achieved a precision\nvalue of 0.88 and an accuracy of 91.56%. Further optimization reveals the\nintramodality and intermodality relevance through the selection of the most\ninfluential features within each modality for decision making.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:44:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 06:42:24 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Shimpi", "Shivani", ""], ["Thombre", "Shyam", ""], ["Reddy", "Snehal", ""], ["Sharma", "Ritik", ""], ["Singh", "Srijan", ""]]}, {"id": "2009.05653", "submitter": "Jessica Van Brummelen", "authors": "Jessica Van Brummelen, Tommy Heng, Viktoriya Tabunshchyk", "title": "Teaching Tech to Talk: K-12 Conversational Artificial Intelligence\n  Literacy Curriculum and Development Tools", "comments": "8 pages, 4 figures, for associated video:\n  https://youtu.be/VGskt7mI4K8, for appendix:\n  https://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With children talking to smart-speakers, smart-phones and even\nsmart-microwaves daily, it is increasingly important to educate students on how\nthese agents work-from underlying mechanisms to societal implications.\nResearchers are developing tools and curriculum to teach K-12 students broadly\nabout artificial intelligence (AI); however, few studies have evaluated these\ntools with respect to AI-specific learning outcomes, and even fewer have\naddressed student learning about AI-based conversational agents. We evaluate\nour Conversational Agent Interface for MIT App Inventor and workshop curriculum\nwith respect to eight AI competencies from the literature. Furthermore, we\nanalyze teacher (n=9) and student (n=47) feedback from workshops with the\ninterface and recommend that future work leverages design considerations from\nthe literature to optimize engagement, collaborates with teachers, and\naddresses a range of student abilities through pacing and opportunities for\nextension. We found students struggled most with the concepts of AI ethics and\nlearning, and recommend emphasizing these topics when teaching.\n  The appendix, including a demo video, can be found here:\nhttps://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:52:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Van Brummelen", "Jessica", ""], ["Heng", "Tommy", ""], ["Tabunshchyk", "Viktoriya", ""]]}, {"id": "2009.05664", "submitter": "Anurag Acharya", "authors": "Anurag Acharya, Kartik Talamadupula and Mark A Finlayson", "title": "Towards an Atlas of Cultural Commonsense for Machine Reasoning", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing commonsense reasoning datasets for AI and NLP tasks fail to address\nan important aspect of human life: cultural differences. We introduce an\napproach that extends prior work on crowdsourcing commonsense knowledge by\nincorporating differences in knowledge that are attributable to cultural or\nnational groups. We demonstrate the technique by collecting commonsense\nknowledge that surrounds six fairly universal rituals -- birth, coming-of-age,\nmarriage, funerals, new year, and birthdays -- across two national groups: the\nUnited States and India. Our study expands the different types of relationships\nidentified by existing work in the field of commonsense reasoning for\ncommonplace events, and uses these new types to gather information that\ndistinguish the identity of the groups providing the knowledge. It also moves\nus a step closer towards building a machine that doesn't assume a rigid\nframework of universal (and likely Western-biased) commonsense knowledge, but\nrather has the ability to reason in a contextually and culturally sensitive\nway. Our hope is that cultural knowledge of this sort will lead to more\nhuman-like performance in NLP tasks such as question answering (QA) and text\nunderstanding and generation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:24:33 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 06:31:44 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 23:26:25 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Acharya", "Anurag", ""], ["Talamadupula", "Kartik", ""], ["Finlayson", "Mark A", ""]]}, {"id": "2009.05668", "submitter": "Li Yang", "authors": "Li Yang, Zhezhi He, Junshan Zhang, Deliang Fan", "title": "KSM: Fast Multiple Task Adaption via Kernel-wise Soft Mask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) could forget the knowledge about earlier tasks\nwhen learning new tasks, and this is known as \\textit{catastrophic forgetting}.\nWhile recent continual learning methods are capable of alleviating the\ncatastrophic problem on toy-sized datasets, some issues still remain to be\ntackled when applying them in real-world problems. Recently, the fast\nmask-based learning method (e.g. piggyback \\cite{mallya2018piggyback}) is\nproposed to address these issues by learning only a binary element-wise mask in\na fast manner, while keeping the backbone model fixed. However, the binary mask\nhas limited modeling capacity for new tasks. A more recent work\n\\cite{hung2019compacting} proposes a compress-grow-based method (CPG) to\nachieve better accuracy for new tasks by partially training backbone model, but\nwith order-higher training cost, which makes it infeasible to be deployed into\npopular state-of-the-art edge-/mobile-learning. The primary goal of this work\nis to simultaneously achieve fast and high-accuracy multi task adaption in\ncontinual learning setting. Thus motivated, we propose a new training method\ncalled \\textit{kernel-wise Soft Mask} (KSM), which learns a kernel-wise hybrid\nbinary and real-value soft mask for each task, while using the same backbone\nmodel. Such a soft mask can be viewed as a superposition of a binary mask and a\nproperly scaled real-value tensor, which offers a richer representation\ncapability without low-level kernel support to meet the objective of low\nhardware overhead. We validate KSM on multiple benchmark datasets against\nrecent state-of-the-art methods (e.g. Piggyback, Packnet, CPG, etc.), which\nshows good improvement in both accuracy and training cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:48:39 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yang", "Li", ""], ["He", "Zhezhi", ""], ["Zhang", "Junshan", ""], ["Fan", "Deliang", ""]]}, {"id": "2009.05671", "submitter": "Nicky Bayat", "authors": "Nicky Bayat, Vahid Reza Khazaie, Yalda Mohsenzadeh", "title": "Inverse mapping of face GANs", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) synthesize realistic images from a\nrandom latent vector. While many studies have explored various training\nconfigurations and architectures for GANs, the problem of inverting a\ngenerative model to extract latent vectors of given input images has been\ninadequately investigated. Although there is exactly one generated image per\ngiven random vector, the mapping from an image to its recovered latent vector\ncan have more than one solution. We train a ResNet architecture to recover a\nlatent vector for a given face that can be used to generate a face nearly\nidentical to the target. We use a perceptual loss to embed face details in the\nrecovered latent vector while maintaining visual quality using a pixel loss.\nThe vast majority of studies on latent vector recovery perform well only on\ngenerated images, we argue that our method can be used to determine a mapping\nbetween real human faces and latent-space vectors that contain most of the\nimportant face style details. In addition, our proposed method projects\ngenerated faces to their latent-space with high fidelity and speed. At last, we\ndemonstrate the performance of our approach on both real and generated faces.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:06:56 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bayat", "Nicky", ""], ["Khazaie", "Vahid Reza", ""], ["Mohsenzadeh", "Yalda", ""]]}, {"id": "2009.05673", "submitter": "Jeff Heaton Ph.D.", "authors": "Jeff Heaton", "title": "Applications of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is a group of exciting new technologies for neural networks.\nThrough a combination of advanced training techniques and neural network\narchitectural components, it is now possible to create neural networks that can\nhandle tabular data, images, text, and audio as both input and output. Deep\nlearning allows a neural network to learn hierarchies of information in a way\nthat is like the function of the human brain. This course will introduce the\nstudent to classic neural network structures, Convolution Neural Networks\n(CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU),\nGeneral Adversarial Networks (GAN), and reinforcement learning. Application of\nthese architectures to computer vision, time series, security, natural language\nprocessing (NLP), and data generation will be covered. High-Performance\nComputing (HPC) aspects will demonstrate how deep learning can be leveraged\nboth on graphical processing units (GPUs), as well as grids. Focus is primarily\nupon the application of deep learning to problems, with some introduction to\nmathematical foundations. Readers will use the Python programming language to\nimplement deep learning using Google TensorFlow and Keras. It is not necessary\nto know Python prior to this book; however, familiarity with at least one\nprogramming language is assumed.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:09:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 23:11:56 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Heaton", "Jeff", ""]]}, {"id": "2009.05675", "submitter": "Ayu Purwarianti", "authors": "Turfa Auliarachman (1), Ayu Purwarianti (1) ((1) Institut Teknologi\n  Bandung)", "title": "Coreference Resolution System for Indonesian Text with Mention Pair\n  Method and Singleton Exclusion using Convolutional Neural Network", "comments": null, "journal-ref": "2019 International Conference of Advanced Informatics: Concepts,\n  Theory and Applications (ICAICTA)", "doi": "10.1109/ICAICTA.2019.8904261", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has shown promising performance on coreference resolution\nsystems that uses mention pair method. With deep neural network, it can learn\nhidden and deep relations between two mentions. However, there is no work on\ncoreference resolution for Indonesian text that uses this learning technique.\nThe state-of-the-art system for Indonesian text only states the use of lexical\nand syntactic features can improve the existing coreference resolution system.\nIn this paper, we propose a new coreference resolution system for Indonesian\ntext with mention pair method that uses deep neural network to learn the\nrelations of the two mentions. In addition to lexical and syntactic features,\nin order to learn the representation of the mentions words and context, we use\nword embeddings and feed them to Convolutional Neural Network (CNN).\nFurthermore, we do singleton exclusion using singleton classifier component to\nprevent singleton mentions entering any entity clusters at the end. Achieving\n67.37% without singleton exclusion, 63.27% with trained singleton classifier,\nand 75.95% with gold singleton classifier on CoNLL average F1 score, our\nproposed system outperforms the state-of-the-art system.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:21:19 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Auliarachman", "Turfa", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05678", "submitter": "Jingan Yang", "authors": "Jingan Yang, Yang Peng", "title": "To Root Artificial Intelligence Deeply in Basic Science for a New\n  Generation of AI", "comments": "13 pages; 7 figures; 23 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the ambitions of artificial intelligence is to root artificial\nintelligence deeply in basic science while developing brain-inspired artificial\nintelligence platforms that will promote new scientific discoveries. The\nchallenges are essential to push artificial intelligence theory and applied\ntechnologies research forward. This paper presents the grand challenges of\nartificial intelligence research for the next 20 years which include:~(i) to\nexplore the working mechanism of the human brain on the basis of understanding\nbrain science, neuroscience, cognitive science, psychology and data science;\n(ii) how is the electrical signal transmitted by the human brain? What is the\ncoordination mechanism between brain neural electrical signals and human\nactivities? (iii)~to root brain-computer interface~(BCI) and brain-muscle\ninterface~(BMI) technologies deeply in science on human behaviour; (iv)~making\nresearch on knowledge-driven visual commonsense reasoning~(VCR), develop a new\ninference engine for cognitive network recognition~(CNR); (v)~to develop\nhigh-precision, multi-modal intelligent perceptrons; (vi)~investigating\nintelligent reasoning and fast decision-making systems based on knowledge\ngraph~(KG). We believe that the frontier theory innovation of AI,\nknowledge-driven modeling methodologies for commonsense reasoning,\nrevolutionary innovation and breakthroughs of the novel algorithms and new\ntechnologies in AI, and developing responsible AI should be the main research\nstrategies of AI scientists in the future.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:38:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yang", "Jingan", ""], ["Peng", "Yang", ""]]}, {"id": "2009.05687", "submitter": "Ayu Purwarianti", "authors": "Devin Hoesen (1), Ayu Purwarianti (2) ((1) Prosa.ai, (2) Institut\n  Teknologi Bandung)", "title": "Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian\n  Named Entity Tagger", "comments": null, "journal-ref": "2018 International Conference on Asian Language Processing (IALP)", "doi": "10.1109/IALP.2018.8629158", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches on Indonesian named entity (NE) tagger have been conducted since\nyears ago. However, most did not use deep learning and instead employed\ntraditional machine learning algorithms such as association rule, support\nvector machine, random forest, na\\\"ive bayes, etc. In those researches, word\nlists as gazetteers or clue words were provided to enhance the accuracy. Here,\nwe attempt to employ deep learning in our Indonesian NE tagger. We use long\nshort-term memory (LSTM) as the topology since it is the state-of-the-art of NE\ntagger. By using LSTM, we do not need a word list in order to enhance the\naccuracy. Basically, there are two main things that we investigate. The first\nis the output layer of the network: Softmax vs conditional random field (CRF).\nThe second is the usage of part of speech (POS) tag embedding input layer.\nUsing 8400 sentences as the training data and 97 sentences as the evaluation\ndata, we find that using POS tag embedding as additional input improves the\nperformance of our Indonesian NE tagger. As for the comparison between Softmax\nand CRF, we find that both architectures have a weakness in classifying an NE\ntag.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:54:31 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hoesen", "Devin", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05697", "submitter": "Yuxuan Cai", "authors": "Yuxuan Cai, Hongjia Li, Geng Yuan, Wei Niu, Yanyu Li, Xulong Tang, Bin\n  Ren, Yanzhi Wang", "title": "YOLObile: Real-Time Object Detection on Mobile Devices via\n  Compression-Compilation Co-Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development and wide utilization of object detection techniques\nhave aroused attention on both accuracy and speed of object detectors. However,\nthe current state-of-the-art object detection works are either\naccuracy-oriented using a large model but leading to high latency or\nspeed-oriented using a lightweight model but sacrificing accuracy. In this\nwork, we propose YOLObile framework, a real-time object detection on mobile\ndevices via compression-compilation co-design. A novel block-punched pruning\nscheme is proposed for any kernel size. To improve computational efficiency on\nmobile devices, a GPU-CPU collaborative scheme is adopted along with advanced\ncompiler-assisted optimizations. Experimental results indicate that our pruning\nscheme achieves 14$\\times$ compression rate of YOLOv4 with 49.0 mAP. Under our\nYOLObile framework, we achieve 17 FPS inference speed using GPU on Samsung\nGalaxy S20. By incorporating our proposed GPU-CPU collaborative scheme, the\ninference speed is increased to 19.1 FPS, and outperforms the original YOLOv4\nby 5$\\times$ speedup. Source code is at:\n\\url{https://github.com/nightsnack/YOLObile}.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:41:08 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 15:55:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cai", "Yuxuan", ""], ["Li", "Hongjia", ""], ["Yuan", "Geng", ""], ["Niu", "Wei", ""], ["Li", "Yanyu", ""], ["Tang", "Xulong", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2009.05698", "submitter": "Ayu Purwarianti", "authors": "Ramos Janoah Hasudungan (1), Ayu Purwarianti (1) ((1) Institut\n  Teknologi Bandung)", "title": "Relation Detection for Indonesian Language using Deep Neural Network --\n  Support Vector Machine", "comments": "2018 International Conference on Asian Language Processing (IALP)", "journal-ref": null, "doi": "10.1109/IALP.2018.8629248", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Detection is a task to determine whether two entities are related or\nnot. In this paper, we employ neural network to do relation detection between\ntwo named entities for Indonesian Language. We used feature such as word\nembedding, position embedding, POS-Tag embedding, and character embedding. For\nthe model, we divide the model into two parts: Front-part classifier\n(Convolutional layer or LSTM layer) and Back-part classifier (Dense layer or\nSVM). We did grid search method of neural network hyper parameter and SVM. We\nused 6000 Indonesian sentences for training process and 1,125 for testing. The\nbest result is 0.8083 on F1-Score using Convolutional Layer as front-part and\nSVM as back-part.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:45:08 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hasudungan", "Ramos Janoah", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05700", "submitter": "Syrine Belakaria", "authors": "Syrine Belakaria, Aryan Deshwal, Janardhan Rao Doppa", "title": "Information-Theoretic Multi-Objective Bayesian Optimization with\n  Continuous Approximations", "comments": null, "journal-ref": "Workshop on machine learning for engineering modeling, simulation\n  and design @ NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications involve black-box optimization of multiple\nobjectives using continuous function approximations that trade-off accuracy and\nresource cost of evaluation. For example, in rocket launching research, we need\nto find designs that trade-off return-time and angular distance using\ncontinuous-fidelity simulators (e.g., varying tolerance parameter to trade-off\nsimulation time and accuracy) for design evaluations. The goal is to\napproximate the optimal Pareto set by minimizing the cost for evaluations. In\nthis paper, we propose a novel approach referred to as information-Theoretic\nMulti-Objective Bayesian Optimization with Continuous Approximations (iMOCA)}\nto solve this problem. The key idea is to select the sequence of input and\nfunction approximations for multiple objectives which maximize the information\ngain per unit cost for the optimal Pareto front. Our experiments on diverse\nsynthetic and real-world benchmarks show that iMOCA significantly improves over\nexisting single-fidelity methods.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:46:03 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 17:33:38 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 01:46:09 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Belakaria", "Syrine", ""], ["Deshwal", "Aryan", ""], ["Doppa", "Janardhan Rao", ""]]}, {"id": "2009.05702", "submitter": "Haruki Nishimura", "authors": "Haruki Nishimura and Boris Ivanovic and Adrien Gaidon and Marco Pavone\n  and Mac Schwager", "title": "Risk-Sensitive Sequential Action Control with Multi-Modal Human\n  Trajectory Forecasting for Safe Crowd-Robot Interaction", "comments": "To appear in 2020 IEEE/RSJ IROS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel online framework for safe crowd-robot interaction\nbased on risk-sensitive stochastic optimal control, wherein the risk is modeled\nby the entropic risk measure. The sampling-based model predictive control\nrelies on mode insertion gradient optimization for this risk measure as well as\nTrajectron++, a state-of-the-art generative model that produces multimodal\nprobabilistic trajectory forecasts for multiple interacting agents. Our modular\napproach decouples the crowd-robot interaction into learning-based prediction\nand model-based control, which is advantageous compared to end-to-end policy\nlearning methods in that it allows the robot's desired behavior to be specified\nat run time. In particular, we show that the robot exhibits diverse interaction\nbehavior by varying the risk sensitivity parameter. A simulation study and a\nreal-world experiment show that the proposed online framework can accomplish\nsafe and efficient navigation while avoiding collisions with more than 50\nhumans in the scene.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 02:02:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Nishimura", "Haruki", ""], ["Ivanovic", "Boris", ""], ["Gaidon", "Adrien", ""], ["Pavone", "Marco", ""], ["Schwager", "Mac", ""]]}, {"id": "2009.05713", "submitter": "Ayu Purwarianti", "authors": "Ilham Firdausi Putra (1), Ayu Purwarianti (1 and 2) ((1) Institut\n  Teknologi Bandung, (2) U-CoE AI-VLB)", "title": "Improving Indonesian Text Classification Using Multilingual Language\n  Model", "comments": null, "journal-ref": "2020 International Conference on Advanced Informatics: Concept,\n  Theory and Application (ICAICTA)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to English, the amount of labeled data for Indonesian text\nclassification tasks is very small. Recently developed multilingual language\nmodels have shown its ability to create multilingual representations\neffectively. This paper investigates the effect of combining English and\nIndonesian data on building Indonesian text classification (e.g., sentiment\nanalysis and hate speech) using multilingual language models. Using the\nfeature-based approach, we observe its performance on various data sizes and\ntotal added English data. The experiment showed that the addition of English\ndata, especially if the amount of Indonesian data is small, improves\nperformance. Using the fine-tuning approach, we further showed its\neffectiveness in utilizing the English language to build Indonesian text\nclassification models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:16:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Putra", "Ilham Firdausi", "", "1 and 2"], ["Purwarianti", "Ayu", "", "1 and 2"]]}, {"id": "2009.05720", "submitter": "Ayu Purwarianti", "authors": "Ayu Purwarianti (1), Ida Ayu Putu Ari Crisdayanti (1) ((1) Institut\n  Teknologi Bandung)", "title": "Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using\n  Paragraph Vector", "comments": null, "journal-ref": "2019 International Conference of Advanced Informatics: Concepts,\n  Theory and Applications (ICAICTA)", "doi": "10.1109/ICAICTA.2019.8904199", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Long Short-Term Memory Network (Bi-LSTM) has shown promising\nperformance in sentiment classification task. It processes inputs as sequence\nof information. Due to this behavior, sentiment predictions by Bi-LSTM were\ninfluenced by words sequence and the first or last phrases of the texts tend to\nhave stronger features than other phrases. Meanwhile, in the problem scope of\nIndonesian sentiment analysis, phrases that express the sentiment of a document\nmight not appear in the first or last part of the document that can lead to\nincorrect sentiment classification. To this end, we propose the using of an\nexisting document representation method called paragraph vector as additional\ninput features for Bi-LSTM. This vector provides information context of the\ndocument for each sequence processing. The paragraph vector is simply\nconcatenated to each word vector of the document. This representation also\nhelps to differentiate ambiguous Indonesian words. Bi-LSTM and paragraph vector\nwere previously used as separate methods. Combining the two methods has shown a\nsignificant performance improvement of Indonesian sentiment analysis model.\nSeveral case studies on testing data showed that the proposed method can handle\nthe sentiment phrases position problem encountered by Bi-LSTM.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:43:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Purwarianti", "Ayu", ""], ["Crisdayanti", "Ida Ayu Putu Ari", ""]]}, {"id": "2009.05739", "submitter": "Ze Cheng", "authors": "Ze Cheng, Juncheng Li, Chenxu Wang, Jixuan Gu, Hao Xu, Xinjian Li,\n  Florian Metze", "title": "Revisiting Factorizing Aggregated Posterior in Learning Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning disentangled representations, one of the promising\nmethods is to factorize aggregated posterior by penalizing the total\ncorrelation of sampled latent variables. However, this well-motivated strategy\nhas a blind spot: there is a disparity between the sampled latent\nrepresentation and its corresponding mean representation. In this paper, we\nprovide a theoretical explanation that low total correlation of sampled\nrepresentation cannot guarantee low total correlation of the mean\nrepresentation. Indeed, we prove that for the multivariate normal\ndistributions, the mean representation with arbitrarily high total correlation\ncan have a corresponding sampled representation with bounded total correlation.\nWe also propose a method to eliminate this disparity. Experiments show that our\nmodel can learn a mean representation with much lower total correlation, hence\na factorized mean representation. Moreover, we offer a detailed explanation of\nthe limitations of factorizing aggregated posterior: factor disintegration. Our\nwork indicates a potential direction for future research of disentangled\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 07:31:30 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 05:14:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cheng", "Ze", ""], ["Li", "Juncheng", ""], ["Wang", "Chenxu", ""], ["Gu", "Jixuan", ""], ["Xu", "Hao", ""], ["Li", "Xinjian", ""], ["Metze", "Florian", ""]]}, {"id": "2009.05743", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Hongwei Chen, Ruxin Wang, Yunpeng Cai, Hongyan Wu", "title": "Smoothness Sensor: Adaptive Smoothness-Transition Graph Convolutions for\n  Attributed Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering techniques attempt to group objects with similar properties into a\ncluster. Clustering the nodes of an attributed graph, in which each node is\nassociated with a set of feature attributes, has attracted significant\nattention. Graph convolutional networks (GCNs) represent an effective approach\nfor integrating the two complementary factors of node attributes and structural\ninformation for attributed graph clustering. However, oversmoothing of GCNs\nproduces indistinguishable representations of nodes, such that the nodes in a\ngraph tend to be grouped into fewer clusters, and poses a challenge due to the\nresulting performance drop. In this study, we propose a smoothness sensor for\nattributed graph clustering based on adaptive smoothness-transition graph\nconvolutions, which senses the smoothness of a graph and adaptively terminates\nthe current convolution once the smoothness is saturated to prevent\noversmoothing. Furthermore, as an alternative to graph-level smoothness, a\nnovel fine-gained node-wise level assessment of smoothness is proposed, in\nwhich smoothness is computed in accordance with the neighborhood conditions of\na given node at a certain order of graph convolution. In addition, a\nself-supervision criterion is designed considering both the tightness within\nclusters and the separation between clusters to guide the whole neural network\ntraining process. Experiments show that the proposed methods significantly\noutperform 12 other state-of-the-art baselines in terms of three different\nmetrics across four benchmark datasets. In addition, an extensive study reveals\nthe reasons for their effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 08:12:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ji", "Chaojie", ""], ["Chen", "Hongwei", ""], ["Wang", "Ruxin", ""], ["Cai", "Yunpeng", ""], ["Wu", "Hongyan", ""]]}, {"id": "2009.05748", "submitter": "Tianyi Ma", "authors": "Yaohua Bu, Weijun Li, Tianyi Ma, Shengqi Chen, Jia Jia, Kun Li, Xiaobo\n  Lu", "title": "Visual-speech Synthesis of Exaggerated Corrective Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide more discriminative feedback for the second language (L2) learners\nto better identify their mispronunciation, we propose a method for exaggerated\nvisual-speech feedback in computer-assisted pronunciation training (CAPT). The\nspeech exaggeration is realized by an emphatic speech generation neural network\nbased on Tacotron, while the visual exaggeration is accomplished by ADC Viseme\nBlending, namely increasing Amplitude of movement, extending the phone's\nDuration and enhancing the color Contrast. User studies show that exaggerated\nfeedback outperforms non-exaggerated version on helping learners with\npronunciation identification and pronunciation improvement.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 08:37:22 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 13:16:53 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bu", "Yaohua", ""], ["Li", "Weijun", ""], ["Ma", "Tianyi", ""], ["Chen", "Shengqi", ""], ["Jia", "Jia", ""], ["Li", "Kun", ""], ["Lu", "Xiaobo", ""]]}, {"id": "2009.05774", "submitter": "Christian Anti\\'c", "authors": "Christian Antic", "title": "Finite Horn Monoids via Propositional Horn Theory Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.DM math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing complex objects as the composition of elementary ones is a common\nstrategy in computer science and science in general. This paper contributes to\nthe foundations of knowledge representation and database theory by introducing\nand studying the sequential composition of propositional Horn theories.\nSpecifically, we show that the notion of composition gives rise to a family of\nmonoids and seminearrings, which we will call {\\em Horn monoids} and {\\em Horn\nseminearrings} in this paper. Particularly, we show that the combination of\ncomposition and union yields the structure of a finite idempotent seminearring.\nWe also show that the restricted class of proper propositional Krom-Horn\ntheories, which only contain rules with exactly one body atom, yields a finite\nidempotent semiring. On the semantic side, we show that the van Emden-Kowalski\nimmediate consequence operator of a theory can be represented via composition,\nwhich allows us to compute its least model semantics without any explicit\nreference to operators. This bridges the conceptual gap between the syntax and\nsemantics of a propositional Horn theory in a mathematically satisfactory way.\nMoreover, it gives rise to an algebraic meta-calculus for propositional Horn\ntheories. In a broader sense, this paper is a first step towards an algebra of\nrule-based logical theories and in the future we plan to adapt and generalize\nthe methods of this paper to wider classes of theories, most importantly to\nfirst-, and higher-order logic programs, and non-monotonic logic programs under\nthe stable model or answer set semantics and extensions thereof.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 11:57:30 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 14:47:23 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 17:18:49 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Antic", "Christian", ""]]}, {"id": "2009.05777", "submitter": "Can Li", "authors": "Can Li, Lei Bai, Wei Liu, Lina Yao, S Travis Waller", "title": "Knowledge Adaption for Demand Prediction based on Multi-task Memory\n  Neural Network", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate demand forecasting of different public transport modes(e.g., buses\nand light rails) is essential for public service operation.However, the\ndevelopment level of various modes often varies sig-nificantly, which makes it\nhard to predict the demand of the modeswith insufficient knowledge and sparse\nstation distribution (i.e.,station-sparse mode). Intuitively, different public\ntransit modes mayexhibit shared demand patterns temporally and spatially in a\ncity.As such, we propose to enhance the demand prediction of station-sparse\nmodes with the data from station-intensive mode and designaMemory-Augmented\nMulti-taskRecurrent Network (MATURE)to derive the transferable demand patterns\nfrom each mode andboost the prediction of station-sparse modes through\nadaptingthe relevant patterns from the station-intensive mode.\nSpecifically,MATUREcomprises three components: 1) a memory-augmentedrecurrent\nnetwork for strengthening the ability to capture the long-short term\ninformation and storing temporal knowledge of eachtransit mode; 2) a knowledge\nadaption module to adapt the rele-vant knowledge from a station-intensive\nsource to station-sparsesources; 3) a multi-task learning framework to\nincorporate all theinformation and forecast the demand of multiple modes\njointly.The experimental results on a real-world dataset covering four pub-lic\ntransport modes demonstrate that our model can promote thedemand forecasting\nperformance for the station-sparse modes.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 12:21:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Can", ""], ["Bai", "Lei", ""], ["Liu", "Wei", ""], ["Yao", "Lina", ""], ["Waller", "S Travis", ""]]}, {"id": "2009.05778", "submitter": "Thyagharajan K K", "authors": "S. D. Lalitha, K. K. Thyagharajan", "title": "Micro-Facial Expression Recognition Based on Deep-Rooted Learning\n  Algorithm", "comments": "20 pages, 7 figures, \"for the published version of the article, see\n  https://www.atlantis-press.com/journals/ijcis/125915627\"", "journal-ref": "12 (2) 903 - 913 2019/08 International Journal of Computational\n  Intelligence Systems", "doi": "10.2991/IJCIS.D.190801.001", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expressions are important cues to observe human emotions. Facial\nexpression recognition has attracted many researchers for years, but it is\nstill a challenging topic since expression features vary greatly with the head\nposes, environments, and variations in the different persons involved. In this\nwork, three major steps are involved to improve the performance of micro-facial\nexpression recognition. First, an Adaptive Homomorphic Filtering is used for\nface detection and rotation rectification processes. Secondly, Micro-facial\nfeatures were used to extract the appearance variations of a testing\nimage-spatial analysis. The features of motion information are used for\nexpression recognition in a sequence of facial images. An effective\nMicro-Facial Expression Based Deep-Rooted Learning (MFEDRL) classifier is\nproposed in this paper to better recognize spontaneous micro-expressions by\nlearning parameters on the optimal features. This proposed method includes two\nloss functions such as cross entropy loss function and centre loss function.\nThen the performance of the algorithm will be evaluated using recognition rate\nand false measures. Simulation results show that the predictive performance of\nthe proposed method outperforms that of the existing classifiers such as\nConvolutional Neural Network (CNN), Deep Neural Network (DNN), Artificial\nNeural Network (ANN), Support Vector Machine (SVM), and k-Nearest Neighbours\n(KNN) in terms of accuracy and Mean Absolute Error (MAE).\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 12:23:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lalitha", "S. D.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.05794", "submitter": "Jieming Zhu", "authors": "Jieming Zhu, Jinyang Liu, Shuai Yang, Qi Zhang, Xiuqiang He", "title": "FuxiCTR: An Open Benchmark for Click-Through Rate Prediction", "comments": "Feebacks and comments are welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, such as recommender systems, online advertising, and\nproduct search, click-through rate (CTR) prediction is a critical task, because\nits accuracy has a direct impact on both platform revenue and user experience.\nIn recent years, with the prevalence of deep learning, CTR prediction has been\nwidely studied in both academia and industry, resulting in an abundance of deep\nCTR models. Unfortunately, there is still a lack of a standardized benchmark\nand uniform evaluation protocols for CTR prediction. This leads to the\nnon-reproducible and even inconsistent experimental results among these\nstudies. In this paper, we present an open benchmark (namely FuxiCTR) for\nreproducible research and provide a rigorous comparison of different models for\nCTR prediction. Specifically, we ran over 4,600 experiments for a total of more\nthan 12,000 GPU hours in a uniform framework to re-evaluate 24 existing models\non two widely-used datasets, Criteo and Avazu. Surprisingly, our experiments\nshow that many models have smaller differences than expected and sometimes are\neven inconsistent with what reported in the literature. We believe that our\nbenchmark could not only allow researchers to gauge the effectiveness of new\nmodels conveniently, but also share some good practices to fairly compare with\nthe state of the arts. We will release all the code and benchmark settings.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 13:34:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhu", "Jieming", ""], ["Liu", "Jinyang", ""], ["Yang", "Shuai", ""], ["Zhang", "Qi", ""], ["He", "Xiuqiang", ""]]}, {"id": "2009.05800", "submitter": "Luc Libralesso", "authors": "Luc Libralesso, Pablo Andres Focke, Aur\\'elien Secardin, Vincent Jost", "title": "Iterative beam search algorithms for the permutation flowshop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an iterative beam search algorithm for the permutation flowshop\n(makespan and flowtime minimization). This algorithm combines branching\nstrategies inspired by recent branch-and-bounds and a guidance strategy\ninspired by the LR heuristic. It obtains competitive results, reports many\nnew-best-so-far solutions on the VFR benchmark (makespan minimization) and the\nTaillard benchmark (flowtime minimization) without using any NEH-based\nbranching or iterative-greedy strategy. The source code is available at:\nhttps://gitlab.com/librallu/cats-pfsp.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 14:23:41 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Libralesso", "Luc", ""], ["Focke", "Pablo Andres", ""], ["Secardin", "Aur\u00e9lien", ""], ["Jost", "Vincent", ""]]}, {"id": "2009.05812", "submitter": "Ashutosh Kumar Tiwari", "authors": "Ashutosh Tiwari and Sandeep Varma", "title": "Learning semantic Image attributes using Image recognition and knowledge\n  graph embeddings", "comments": "7 Pages, 6 figures, Accepted at Future Technologies Conference (FTC)\n  2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting structured knowledge from texts has traditionally been used for\nknowledge base generation. However, other sources of information, such as\nimages can be leveraged into this process to build more complete and richer\nknowledge bases. Structured semantic representation of the content of an image\nand knowledge graph embeddings can provide a unique representation of semantic\nrelationships between image entities. Linking known entities in knowledge\ngraphs and learning open-world images using language models has attracted lots\nof interest over the years. In this paper, we propose a shared learning\napproach to learn semantic attributes of images by combining a knowledge graph\nembedding model with the recognized attributes of images. The proposed model\npremises to help us understand the semantic relationship between the entities\nof an image and implicitly provide a link for the extracted entities through a\nknowledge graph embedding model. Under the limitation of using a custom\nuser-defined knowledge base with limited data, the proposed model presents\nsignificant accuracy and provides a new alternative to the earlier approaches.\nThe proposed approach is a step towards bridging the gap between frameworks\nwhich learn from large amounts of data and frameworks which use a limited set\nof predicates to infer new knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:18:48 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Tiwari", "Ashutosh", ""], ["Varma", "Sandeep", ""]]}, {"id": "2009.05815", "submitter": "Inga Ibs", "authors": "Inga Ibs and Nico Potyka", "title": "Explainable Automated Reasoning in Law using Probabilistic Epistemic\n  Argumentation", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying automated reasoning tools for decision support and analysis in law\nhas the potential to make court decisions more transparent and objective. Since\nthere is often uncertainty about the accuracy and relevance of evidence,\nnon-classical reasoning approaches are required. Here, we investigate\nprobabilistic epistemic argumentation as a tool for automated reasoning about\nlegal cases. We introduce a general scheme to model legal cases as\nprobabilistic epistemic argumentation problems, explain how evidence can be\nmodeled and sketch how explanations for legal decisions can be generated\nautomatically. Our framework is easily interpretable, can deal with cyclic\nstructures and imprecise probabilities and guarantees polynomial-time\nprobabilistic reasoning in the worst-case.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:40:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ibs", "Inga", ""], ["Potyka", "Nico", ""]]}, {"id": "2009.05818", "submitter": "Tiago Botari T.B.", "authors": "Tiago Botari, Frederik Hvilsh{\\o}j, Rafael Izbicki, Andre C. P. L. F.\n  de Carvalho", "title": "MeLIME: Meaningful Local Explanation for Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art machine learning algorithms induce black-box models,\npreventing their application in many sensitive domains. Hence, many\nmethodologies for explaining machine learning models have been proposed to\naddress this problem. In this work, we introduce strategies to improve local\nexplanations taking into account the distribution of the data used to train the\nblack-box models. We show that our approach, MeLIME, produces more meaningful\nexplanations compared to other techniques over different ML models, operating\non various types of data. MeLIME generalizes the LIME method, allowing more\nflexible perturbation sampling and the use of different local interpretable\nmodels. Additionally, we introduce modifications to standard training\nalgorithms of local interpretable models fostering more robust explanations,\neven allowing the production of counterfactual examples. To show the strengths\nof the proposed approach, we include experiments on tabular data, images, and\ntext; all showing improved explanations. In particular, MeLIME generated more\nmeaningful explanations on the MNIST dataset than methods such as\nGuidedBackprop, SmoothGrad, and Layer-wise Relevance Propagation. MeLIME is\navailable on https://github.com/tiagobotari/melime.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 16:06:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Botari", "Tiago", ""], ["Hvilsh\u00f8j", "Frederik", ""], ["Izbicki", "Rafael", ""], ["de Carvalho", "Andre C. P. L. F.", ""]]}, {"id": "2009.05835", "submitter": "Alexander Wong", "authors": "Alexander Wong, Xiao Yu Wang, and Andrew Hryniowski", "title": "How Much Can We Really Trust You? Towards Simple, Interpretable Trust\n  Quantification Metrics for Deep Neural Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical step to building trustworthy deep neural networks is trust\nquantification, where we ask the question: How much can we trust a deep neural\nnetwork? In this study, we take a step towards simple, interpretable metrics\nfor trust quantification by introducing a suite of metrics for assessing the\noverall trustworthiness of deep neural networks based on their behaviour when\nanswering a set of questions. We conduct a thought experiment and explore two\nkey questions about trust in relation to confidence: 1) How much trust do we\nhave in actors who give wrong answers with great confidence? and 2) How much\ntrust do we have in actors who give right answers hesitantly? Based on insights\ngained, we introduce the concept of question-answer trust to quantify\ntrustworthiness of an individual answer based on confident behaviour under\ncorrect and incorrect answer scenarios, and the concept of trust density to\ncharacterize the distribution of overall trust for an individual answer\nscenario. We further introduce the concept of trust spectrum for representing\noverall trust with respect to the spectrum of possible answer scenarios across\ncorrectly and incorrectly answered questions. Finally, we introduce\nNetTrustScore, a scalar metric summarizing overall trustworthiness. The suite\nof metrics aligns with past social psychology studies that study the\nrelationship between trust and confidence. Leveraging these metrics, we\nquantify the trustworthiness of several well-known deep neural network\narchitectures for image recognition to get a deeper understanding of where\ntrust breaks down. The proposed metrics are by no means perfect, but the hope\nis to push the conversation towards better metrics to help guide practitioners\nand regulators in producing, deploying, and certifying deep learning solutions\nthat can be trusted to operate in real-world, mission-critical scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:37:36 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 02:45:36 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 15:08:50 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wong", "Alexander", ""], ["Wang", "Xiao Yu", ""], ["Hryniowski", "Andrew", ""]]}, {"id": "2009.05836", "submitter": "Haihua Chen", "authors": "Haihua Chen and Huyen Nguyen", "title": "Fine-tuning Pre-trained Contextual Embeddings for Citation Content\n  Analysis in Scholarly Publication", "comments": "1 figure and three tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation function and citation sentiment are two essential aspects of\ncitation content analysis (CCA), which are useful for influence analysis, the\nrecommendation of scientific publications. However, existing studies are mostly\ntraditional machine learning methods, although deep learning techniques have\nalso been explored, the improvement of the performance seems not significant\ndue to insufficient training data, which brings difficulties to applications.\nIn this paper, we propose to fine-tune pre-trained contextual embeddings\nULMFiT, BERT, and XLNet for the task. Experiments on three public datasets show\nthat our strategy outperforms all the baselines in terms of the F1 score. For\ncitation function identification, the XLNet model achieves 87.2%, 86.90%, and\n81.6% on DFKI, UMICH, and TKDE2019 datasets respectively, while it achieves\n91.72% and 91.56% on DFKI and UMICH in term of citation sentiment\nidentification. Our method can be used to enhance the influence analysis of\nscholars and scholarly publications.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:46:24 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chen", "Haihua", ""], ["Nguyen", "Huyen", ""]]}, {"id": "2009.05859", "submitter": "Young-Ho Kim", "authors": "Young-Ho Kim, Jarrod Collins, Zhongyu Li, Ponraj Chinnadurai, Ankur\n  Kapoor, C. Huie Lin, Tommaso Mansi", "title": "Towards Automatic Manipulation of Intra-cardiac Echocardiography\n  Catheter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-cardiac Echocardiography (ICE) is a powerful imaging modality for\nguiding electrophysiology and structural heart interventions. ICE provides\nreal-time observation of anatomy, catheters, and emergent complications.\nHowever, this increased reliance on intraprocedural imaging creates a high\ncognitive demand on physicians who can often serve as interventionalist and\nimager. We present a robotic manipulator for ICE catheters to assist physicians\nwith imaging and serve as a platform for developing processes for procedural\nautomation. Herein, we introduce two application modules towards these goals:\n(1) a view recovery process that allows physicians to save views during\nintervention and automatically return with the push of a button and (2) a\ndata-driven approach to compensate kinematic model errors that result from\nnon-linear behaviors in catheter bending, providing more precise control of the\ncatheter tip. View recovery is validated by repeated catheter positioning in\ncardiac phantom and animal experiments with position- and image-based analysis.\nWe present a simplified calibration approach for error compensation and verify\nwith complex rotation of the catheter in benchtop and phantom experiments under\nvarying realistic curvature conditions. Results support that a robotic\nmanipulator for ICE can provide an efficient and reproducible tool, potentially\nreducing execution time and promoting greater utilization of ICE imaging.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 20:14:49 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 15:18:07 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 22:16:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kim", "Young-Ho", ""], ["Collins", "Jarrod", ""], ["Li", "Zhongyu", ""], ["Chinnadurai", "Ponraj", ""], ["Kapoor", "Ankur", ""], ["Lin", "C. Huie", ""], ["Mansi", "Tommaso", ""]]}, {"id": "2009.05863", "submitter": "Bryan Wilder", "authors": "Bryan Wilder, Michael J. Mina, Milind Tambe", "title": "Tracking disease outbreaks from sparse data with Bayesian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": "Accepted at AAAI 2021", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic provides new motivation for a classic problem in\nepidemiology: estimating the empirical rate of transmission during an outbreak\n(formally, the time-varying reproduction number) from case counts. While\nstandard methods exist, they work best at coarse-grained national or state\nscales with abundant data, and struggle to accommodate the partial\nobservability and sparse data common at finer scales (e.g., individual schools\nor towns). For example, case counts may be sparse when only a small fraction of\ninfections are caught by a testing program. Or, whether an infected individual\ntests positive may depend on the kind of test and the point in time when they\nare tested. We propose a Bayesian framework which accommodates partial\nobservability in a principled manner. Our model places a Gaussian process prior\nover the unknown reproduction number at each time step and models observations\nsampled from the distribution of a specific testing program. For example, our\nframework can accommodate a variety of kinds of tests (viral RNA, antibody,\nantigen, etc.) and sampling schemes (e.g., longitudinal or cross-sectional\nscreening). Inference in this framework is complicated by the presence of tens\nor hundreds of thousands of discrete latent variables. To address this\nchallenge, we propose an efficient stochastic variational inference method\nwhich relies on a novel gradient estimator for the variational objective.\nExperimental results for an example motivated by COVID-19 show that our method\nproduces an accurate and well-calibrated posterior, while standard methods for\nestimating the reproduction number can fail badly.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 20:37:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wilder", "Bryan", ""], ["Mina", "Michael J.", ""], ["Tambe", "Milind", ""]]}, {"id": "2009.05897", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Ayslan Possebom, and Cesar Augusto Tacla", "title": "Argumentation-based Agents that Explain their Decisions", "comments": "9 pages, accepted in the 7th Brazilian Conference on Intelligent\n  Systems, 2019", "journal-ref": null, "doi": "10.1109/BRACIS.2019.00088", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) systems, including intelligent\nagents, must be able to explain their internal decisions, behaviours and\nreasoning that produce their choices to the humans (or other systems) with\nwhich they interact. In this paper, we focus on how an extended model of BDI\n(Beliefs-Desires-Intentions) agents can be able to generate explanations about\ntheir reasoning, specifically, about the goals he decides to commit to. Our\nproposal is based on argumentation theory, we use arguments to represent the\nreasons that lead an agent to make a decision and use argumentation semantics\nto determine acceptable arguments (reasons). We propose two types of\nexplanations: the partial one and the complete one. We apply our proposal to a\nscenario of rescue robots.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:08:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Possebom", "Ayslan", ""], ["Tacla", "Cesar Augusto", ""]]}, {"id": "2009.05898", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Ayslan Possebom, and Cesar Augusto Tacla", "title": "Resolving Resource Incompatibilities in Intelligent Agents", "comments": "9 pages, 2 figures, accepted in the 6th Brazilian Conference on\n  Intelligent Systems, 2017", "journal-ref": null, "doi": "10.1109/BRACIS.2017.28", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An intelligent agent may in general pursue multiple procedural goals\nsimultaneously, which may lead to arise some conflicts (incompatibilities)\namong them. In this paper, we focus on the incompatibilities that emerge due to\nresources limitations. Thus, the contribution of this article is twofold. On\none hand, we give an algorithm for identifying resource incompatibilities from\na set of pursued goals and, on the other hand, we propose two ways for\nselecting those goals that will continue to be pursued: (i) the first is based\non abstract argumentation theory, and (ii) the second based on two algorithms\ndeveloped by us. We illustrate our proposal using examples throughout the\narticle.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:09:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Possebom", "Ayslan", ""], ["Tacla", "Cesar Augusto", ""]]}, {"id": "2009.05907", "submitter": "Yucheng Hang", "authors": "Yucheng Hang, Qingmin Liao, Wenming Yang, Yupeng Chen, Jie Zhou", "title": "Attention Cube Network for Image Restoration", "comments": "Accepted by the 28th ACM International Conference on Multimedia (ACM\n  MM 2020); Code is available at https://github.com/YCHang686/A-CubeNet", "journal-ref": null, "doi": "10.1145/3394171.3413564", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep convolutional neural network (CNN) have been widely used in\nimage restoration and obtained great success. However, most of existing methods\nare limited to local receptive field and equal treatment of different types of\ninformation. Besides, existing methods always use a multi-supervised method to\naggregate different feature maps, which can not effectively aggregate\nhierarchical feature information. To address these issues, we propose an\nattention cube network (A-CubeNet) for image restoration for more powerful\nfeature expression and feature correlation learning. Specifically, we design a\nnovel attention mechanism from three dimensions, namely spatial dimension,\nchannel-wise dimension and hierarchical dimension. The adaptive spatial\nattention branch (ASAB) and the adaptive channel attention branch (ACAB)\nconstitute the adaptive dual attention module (ADAM), which can capture the\nlong-range spatial and channel-wise contextual information to expand the\nreceptive field and distinguish different types of information for more\neffective feature representations. Furthermore, the adaptive hierarchical\nattention module (AHAM) can capture the long-range hierarchical contextual\ninformation to flexibly aggregate different feature maps by weights depending\non the global context. The ADAM and AHAM cooperate to form an \"attention in\nattention\" structure, which means AHAM's inputs are enhanced by ASAB and ACAB.\nExperiments demonstrate the superiority of our method over state-of-the-art\nimage restoration methods in both quantitative comparison and visual analysis.\nCode is available at https://github.com/YCHang686/A-CubeNet.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 03:42:14 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 03:35:45 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 11:32:04 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hang", "Yucheng", ""], ["Liao", "Qingmin", ""], ["Yang", "Wenming", ""], ["Chen", "Yupeng", ""], ["Zhou", "Jie", ""]]}, {"id": "2009.05912", "submitter": "Yushan Zhu", "authors": "Yushan Zhu (1), Wen Zhang (1), Hui Chen (2), Xu Cheng (3), Wei Zhang\n  (2), Huajun Chen (1) ((1) Zhejiang University, (2) Alibaba Group, (3) CETC\n  Big Data Research Institute)", "title": "DistilE: Distiling Knowledge Graph Embeddings for Faster and Cheaper\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Embedding (KGE) is a popular method for KG reasoning and\nusually a higher dimensional one ensures better reasoning capability. However,\nhigh-dimensional KGEs pose huge challenges to storage and computing resources\nand are not suitable for resource-limited or time-constrained applications, for\nwhich faster and cheaper reasoning is necessary. To address this problem, we\npropose DistilE, a knowledge distillation method to build low-dimensional\nstudent KGE from pre-trained high-dimensional teacher KGE. We take the original\nKGE loss as hard label loss and design specific soft label loss for different\nKGEs in DistilE. We also propose a two-stage distillation approach to make the\nstudent and teacher adapt to each other and further improve the reasoning\ncapability of the student. Our DistilE is general enough to be applied to\nvarious KGEs. Experimental results of link prediction show that our method\nsuccessfully distills a good student which performs better than a same\ndimensional one directly trained, and sometimes even better than the teacher,\nand it can achieve 2 times - 8 times embedding compression rate and more than\n10 times faster inference speed than the teacher with a small performance loss.\nWe also experimentally prove the effectiveness of our two-stage training\nproposal via ablation study.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 04:03:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhu", "Yushan", ""], ["Zhang", "Wen", ""], ["Chen", "Hui", ""], ["Cheng", "Xu", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.05931", "submitter": "Weiwei Wang", "authors": "Weiwei Wang, Wiebke Eberhardt, Stefano Bromuri", "title": "That looks interesting! Personalizing Communication and Segmentation\n  with Random Forest Node Embeddings", "comments": "32 pages, 8 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicating effectively with customers is a challenge for many marketers,\nbut especially in a context that is both pivotal to individual long-term\nfinancial well-being and difficult to understand: pensions. Around the world,\nparticipants are reluctant to consider their pension in advance, it leads to a\nlack of preparation of their pension retirement [1], [2]. In order to engage\nparticipants to obtain information on their expected pension benefits,\npersonalizing the pension providers' email communication is a first and crucial\nstep. We describe a machine learning approach to model email newsletters to fit\nparticipants' interests. The data for the modeling and analysis is collected\nfrom newsletters sent by a large Dutch pension provider of the Netherlands and\nis divided into two parts. The first part comprises 2,228,000 customers whereas\nthe second part comprises the data of a pilot study, which took place in July\n2018 with 465,711 participants. In both cases, our algorithm extracts features\nfrom continuous and categorical data using random forests, and then calculates\nnode embeddings of the decision boundaries of the random forest. We illustrate\nthe algorithm's effectiveness for the classification task, and how it can be\nused to perform data mining tasks. In order to confirm that the result is valid\nfor more than one data set, we also illustrate the properties of our algorithm\nin benchmark data sets concerning churning. In the data sets considered, the\nproposed modeling demonstrates competitive performance with respect to other\nstate of the art approaches based on random forests, achieving the best Area\nUnder the Curve (AUC) in the pension data set (0.948). For the descriptive\npart, the algorithm can identify customer segmentations that can be used by\nmarketing departments to better target their communication towards their\ncustomers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 06:14:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wang", "Weiwei", ""], ["Eberhardt", "Wiebke", ""], ["Bromuri", "Stefano", ""]]}, {"id": "2009.05934", "submitter": "Xuequan Lu", "authors": "Disheng Feng, Xuequan Lu, Xufeng Lin", "title": "Deep Detection for Face Manipulation", "comments": "accepted to the 27th International Conference on Neural Information\n  Processing Xuequan Lu is the corresponding author (see www.xuequanlu.com for\n  more information)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become increasingly challenging to distinguish real faces from their\nvisually realistic fake counterparts, due to the great advances of deep\nlearning based face manipulation techniques in recent years. In this paper, we\nintroduce a deep learning method to detect face manipulation. It consists of\ntwo stages: feature extraction and binary classification. To better distinguish\nfake faces from real faces, we resort to the triplet loss function in the first\nstage. We then design a simple linear classification network to bridge the\nlearned contrastive features with the real/fake faces. Experimental results on\npublic benchmark datasets demonstrate the effectiveness of this method, and\nshow that it generates better performance than state-of-the-art techniques in\nmost cases.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 06:48:34 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Feng", "Disheng", ""], ["Lu", "Xuequan", ""], ["Lin", "Xufeng", ""]]}, {"id": "2009.05951", "submitter": "Nguyen Quoc Khanh Le Dr.", "authors": "Hieu X. Le, Phuong D. Nguyen, Thang H. Nguyen, Khanh N.Q. Le, Thanh T.\n  Nguyen", "title": "Interpretation of smartphone-captured radiographs utilizing a deep\n  learning-based approach", "comments": "10 pages, 5 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, computer-aided diagnostic systems (CADs) that could automatically\ninterpret medical images effectively have been the emerging subject of recent\nacademic attention. For radiographs, several deep learning-based systems or\nmodels have been developed to study the multi-label diseases recognition tasks.\nHowever, none of them have been trained to work on smartphone-captured chest\nradiographs. In this study, we proposed a system that comprises a sequence of\ndeep learning-based neural networks trained on the newly released CheXphoto\ndataset to tackle this issue. The proposed approach achieved promising results\nof 0.684 in AUC and 0.699 in average F1 score. To the best of our knowledge,\nthis is the first published study that showed to be capable of processing\nsmartphone-captured radiographs.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 08:26:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Le", "Hieu X.", ""], ["Nguyen", "Phuong D.", ""], ["Nguyen", "Thang H.", ""], ["Le", "Khanh N. Q.", ""], ["Nguyen", "Thanh T.", ""]]}, {"id": "2009.05959", "submitter": "Tongwen Huang", "authors": "Tongwen Huang, Qingyun She, Junlin Zhang", "title": "BoostingBERT:Integrating Multi-Class Boosting into BERT for NLP Tasks", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a pre-trained Transformer model, BERT (Bidirectional Encoder\nRepresentations from Transformers) has achieved ground-breaking performance on\nmultiple NLP tasks. On the other hand, Boosting is a popular ensemble learning\ntechnique which combines many base classifiers and has been demonstrated to\nyield better generalization performance in many machine learning tasks. Some\nworks have indicated that ensemble of BERT can further improve the application\nperformance. However, current ensemble approaches focus on bagging or stacking\nand there has not been much effort on exploring the boosting. In this work, we\nproposed a novel Boosting BERT model to integrate multi-class boosting into the\nBERT. Our proposed model uses the pre-trained Transformer as the base\nclassifier to choose harder training sets to fine-tune and gains the benefits\nof both the pre-training language knowledge and boosting ensemble in NLP tasks.\nWe evaluate the proposed model on the GLUE dataset and 3 popular Chinese NLU\nbenchmarks. Experimental results demonstrate that our proposed model\nsignificantly outperforms BERT on all datasets and proves its effectiveness in\nmany NLP tasks. Replacing the BERT base with RoBERTa as base classifier,\nBoostingBERT achieves new state-of-the-art results in several NLP Tasks. We\nalso use knowledge distillation within the \"teacher-student\" framework to\nreduce the computational overhead and model storage of BoostingBERT while\nkeeping its performance for practical application.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:07:14 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Huang", "Tongwen", ""], ["She", "Qingyun", ""], ["Zhang", "Junlin", ""]]}, {"id": "2009.05977", "submitter": "Duyen Le Nguyen Thanh", "authors": "Duyen N.T. Le, Hieu X. Le, Lua T. Ngo, Hoan T. Ngo", "title": "Transfer learning with class-weighted and focal loss function for\n  automatic skin cancer classification", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Skin cancer is by far in top-3 of the world's most common cancer. Among\ndifferent skin cancer types, melanoma is particularly dangerous because of its\nability to metastasize. Early detection is the key to success in skin cancer\ntreatment. However, skin cancer diagnosis is still a challenge, even for\nexperienced dermatologists, due to strong resemblances between benign and\nmalignant lesions. To aid dermatologists in skin cancer diagnosis, we developed\na deep learning system that can effectively and automatically classify skin\nlesions into one of the seven classes: (1) Actinic Keratoses, (2) Basal Cell\nCarcinoma, (3) Benign Keratosis, (4) Dermatofibroma, (5) Melanocytic nevi, (6)\nMelanoma, (7) Vascular Skin Lesion. The HAM10000 dataset was used to train the\nsystem. An end-to-end deep learning process, transfer learning technique,\nutilizing multiple pre-trained models, combining with class-weighted and focal\nloss were applied for the classification process. The result was that our\nensemble of modified ResNet50 models can classify skin lesions into one of the\nseven classes with top-1, top-2 and top-3 accuracy 93%, 97% and 99%,\nrespectively. This deep learning system can potentially be integrated into\ncomputer-aided diagnosis systems that support dermatologists in skin cancer\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 10:59:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Le", "Duyen N. T.", ""], ["Le", "Hieu X.", ""], ["Ngo", "Lua T.", ""], ["Ngo", "Hoan T.", ""]]}, {"id": "2009.05990", "submitter": "Nived Rajaraman", "authors": "Nived Rajaraman, Lin F. Yang, Jiantao Jiao, Kannan Ramachandran", "title": "Toward the Fundamental Limits of Imitation Learning", "comments": "45 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning (IL) aims to mimic the behavior of an expert policy in a\nsequential decision-making problem given only demonstrations. In this paper, we\nfocus on understanding the minimax statistical limits of IL in episodic Markov\nDecision Processes (MDPs). We first consider the setting where the learner is\nprovided a dataset of $N$ expert trajectories ahead of time, and cannot\ninteract with the MDP. Here, we show that the policy which mimics the expert\nwhenever possible is in expectation $\\lesssim \\frac{|\\mathcal{S}| H^2 \\log\n(N)}{N}$ suboptimal compared to the value of the expert, even when the expert\nfollows an arbitrary stochastic policy. Here $\\mathcal{S}$ is the state space,\nand $H$ is the length of the episode. Furthermore, we establish a suboptimality\nlower bound of $\\gtrsim |\\mathcal{S}| H^2 / N$ which applies even if the expert\nis constrained to be deterministic, or if the learner is allowed to actively\nquery the expert at visited states while interacting with the MDP for $N$\nepisodes. To our knowledge, this is the first algorithm with suboptimality\nhaving no dependence on the number of actions, under no additional assumptions.\nWe then propose a novel algorithm based on minimum-distance functionals in the\nsetting where the transition model is given and the expert is deterministic.\nThe algorithm is suboptimal by $\\lesssim \\min \\{ H \\sqrt{|\\mathcal{S}| / N} ,\\\n|\\mathcal{S}| H^{3/2} / N \\}$, showing that knowledge of transition improves\nthe minimax rate by at least a $\\sqrt{H}$ factor.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:45:52 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rajaraman", "Nived", ""], ["Yang", "Lin F.", ""], ["Jiao", "Jiantao", ""], ["Ramachandran", "Kannan", ""]]}, {"id": "2009.05991", "submitter": "Yang Yang", "authors": "Yang Yang, Jian Shen, Yanru Qu, Yunfei Liu, Kerong Wang, Yaoming Zhu,\n  Weinan Zhang and Yong Yu", "title": "GIKT: A Graph-based Interaction Model for Knowledge Tracing", "comments": "16 pages,2 figures, ECMLPKDD2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development in online education, knowledge tracing (KT) has\nbecome a fundamental problem which traces students' knowledge status and\npredicts their performance on new questions. Questions are often numerous in\nonline education systems, and are always associated with much fewer skills.\nHowever, the previous literature fails to involve question information together\nwith high-order question-skill correlations, which is mostly limited by data\nsparsity and multi-skill problems. From the model perspective, previous models\ncan hardly capture the long-term dependency of student exercise history, and\ncannot model the interactions between student-questions, and student-skills in\na consistent way. In this paper, we propose a Graph-based Interaction model for\nKnowledge Tracing (GIKT) to tackle the above probems. More specifically, GIKT\nutilizes graph convolutional network (GCN) to substantially incorporate\nquestion-skill correlations via embedding propagation. Besides, considering\nthat relevant questions are usually scattered throughout the exercise history,\nand that question and skill are just different instantiations of knowledge,\nGIKT generalizes the degree of students' master of the question to the\ninteractions between the student's current state, the student's history related\nexercises, the target question, and related skills. Experiments on three\ndatasets demonstrate that GIKT achieves the new state-of-the-art performance,\nwith at least 1% absolute AUC improvement.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 12:50:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yang", "Yang", ""], ["Shen", "Jian", ""], ["Qu", "Yanru", ""], ["Liu", "Yunfei", ""], ["Wang", "Kerong", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "2009.06001", "submitter": "Thyagharajan K K", "authors": "K. K. Thyagharajan, I. Kiruba Raji", "title": "A Review of Visual Descriptors and Classification Techniques Used in\n  Leaf Species Identification", "comments": "44 pages, 7 figures, \"for final published version, see\n  https://link.springer.com/article/10.1007/s11831-018-9266-3\"", "journal-ref": "Sept. 2019", "doi": "10.1007/s11831-018-9266-3", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plants are fundamentally important to life. Key research areas in plant\nscience include plant species identification, weed classification using hyper\nspectral images, monitoring plant health and tracing leaf growth, and the\nsemantic interpretation of leaf information. Botanists easily identify plant\nspecies by discriminating between the shape of the leaf, tip, base, leaf margin\nand leaf vein, as well as the texture of the leaf and the arrangement of\nleaflets of compound leaves. Because of the increasing demand for experts and\ncalls for biodiversity, there is a need for intelligent systems that recognize\nand characterize leaves so as to scrutinize a particular species, the diseases\nthat affect them, the pattern of leaf growth, and so on. We review several\nimage processing methods in the feature extraction of leaves, given that\nfeature extraction is a crucial technique in computer vision. As computers\ncannot comprehend images, they are required to be converted into features by\nindividually analysing image shapes, colours, textures and moments. Images that\nlook the same may deviate in terms of geometric and photometric variations. In\nour study, we also discuss certain machine learning classifiers for an analysis\nof different species of leaves.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:11:00 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Thyagharajan", "K. K.", ""], ["Raji", "I. Kiruba", ""]]}, {"id": "2009.06011", "submitter": "Berry Weinstein", "authors": "Berry Weinstein, Shai Fine, Yacov Hel-Or", "title": "Margin-Based Regularization and Selective Sampling in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a new margin-based regularization formulation, termed multi-margin\nregularization (MMR), for deep neural networks (DNNs). The MMR is inspired by\nprinciples that were applied in margin analysis of shallow linear classifiers,\ne.g., support vector machine (SVM). Unlike SVM, MMR is continuously scaled by\nthe radius of the bounding sphere (i.e., the maximal norm of the feature vector\nin the data), which is constantly changing during training. We empirically\ndemonstrate that by a simple supplement to the loss function, our method\nachieves better results on various classification tasks across domains. Using\nthe same concept, we also derive a selective sampling scheme and demonstrate\naccelerated training of DNNs by selecting samples according to a minimal margin\nscore (MMS). This score measures the minimal amount of displacement an input\nshould undergo until its predicted classification is switched. We evaluate our\nproposed methods on three image classification tasks and six language text\nclassification tasks. Specifically, we show improved empirical results on\nCIFAR10, CIFAR100 and ImageNet using state-of-the-art convolutional neural\nnetworks (CNNs) and BERT-BASE architecture for the MNLI, QQP, QNLI, MRPC, SST-2\nand RTE benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 15:06:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Weinstein", "Berry", ""], ["Fine", "Shai", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2009.06034", "submitter": "Zishen Wan", "authors": "Zishen Wan, Bo Yu, Thomas Yuang Li, Jie Tang, Yuhao Zhu, Yu Wang,\n  Arijit Raychowdhury, Shaoshan Liu", "title": "A Survey of FPGA-Based Robotic Computing", "comments": "To appear in IEEE Circuits and Systems Magazine (CAS-M), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches on robotics have shown significant improvement, spanning\nfrom algorithms, mechanics to hardware architectures. Robotics, including\nmanipulators, legged robots, drones, and autonomous vehicles, are now widely\napplied in diverse scenarios. However, the high computation and data complexity\nof robotic algorithms pose great challenges to its applications. On the one\nhand, CPU platform is flexible to handle multiple robotic tasks. GPU platform\nhas higher computational capacities and easy-touse development frameworks, so\nthey have been widely adopted in several applications. On the other hand,\nFPGA-based robotic accelerators are becoming increasingly competitive\nalternatives, especially in latency-critical and power-limited scenarios. With\nspecialized designed hardware logic and algorithm kernels, FPGA-based\naccelerators can surpass CPU and GPU in performance and energy efficiency. In\nthis paper, we give an overview of previous work on FPGA-based robotic\naccelerators covering different stages of the robotic system pipeline. An\nanalysis of software and hardware optimization techniques and main technical\nissues is presented, along with some commercial and space applications, to\nserve as a guide for future work.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 16:22:08 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 03:10:31 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 04:56:55 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wan", "Zishen", ""], ["Yu", "Bo", ""], ["Li", "Thomas Yuang", ""], ["Tang", "Jie", ""], ["Zhu", "Yuhao", ""], ["Wang", "Yu", ""], ["Raychowdhury", "Arijit", ""], ["Liu", "Shaoshan", ""]]}, {"id": "2009.06051", "submitter": "Meghna Lowalekar", "authors": "Meghna Lowalekar, Pradeep Varakantham and Patrick Jaillet", "title": "Zone pAth Construction (ZAC) based Approaches for Effective Real-Time\n  Ridesharing", "comments": "48 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time ridesharing systems such as UberPool, Lyft Line, GrabShare have\nbecome hugely popular as they reduce the costs for customers, improve per trip\nrevenue for drivers and reduce traffic on the roads by grouping customers with\nsimilar itineraries. The key challenge in these systems is to group the \"right\"\nrequests to travel together in the \"right\" available vehicles in real-time, so\nthat the objective (e.g., requests served, revenue or delay) is optimized. This\nchallenge has been addressed in existing work by: (i) generating as many\nrelevant feasible (with respect to the available delay for customers)\ncombinations of requests as possible in real-time; and then (ii) optimizing\nassignment of the feasible request combinations to vehicles. Since the number\nof request combinations increases exponentially with the increase in vehicle\ncapacity and number of requests, unfortunately, such approaches have to employ\nad hoc heuristics to identify a subset of request combinations for assignment.\nOur key contribution is in developing approaches that employ zone (abstraction\nof individual locations) paths instead of request combinations. Zone paths\nallow for generation of significantly more \"relevant\" combinations (in\ncomparison to ad hoc heuristics) in real-time than competing approaches due to\ntwo reasons: (i) Each zone path can typically represent multiple request\ncombinations; (ii) Zone paths are generated using a combination of offline and\nonline methods. Specifically, we contribute both myopic (ridesharing assignment\nfocussed on current requests only) and non-myopic (ridesharing assignment\nconsiders impact on expected future requests) approaches that employ zone\npaths. In our experimental results, we demonstrate that our myopic approach\noutperforms (with respect to both objective and runtime) the current best\nmyopic approach for ridesharing on both real-world and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 17:57:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lowalekar", "Meghna", ""], ["Varakantham", "Pradeep", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2009.06082", "submitter": "Karina Kanjaria", "authors": "Karina Kanjaria, Anup Pillai, Chaitanya Shivade, Marina Bendersky,\n  Ashutosh Jadhav, Vandana Mukherjee, Tanveer Syeda-Mahmood", "title": "Receptivity of an AI Cognitive Assistant by the Radiology Community: A\n  Report on Data Collected at RSNA", "comments": null, "journal-ref": "Proceedings of the 13th International Joint Conference on\n  Biomedical Engineering Systems and Technologies - Volume 5: HEALTHINF, ISBN\n  978-989-758-398-8, pages 178-186. 2020", "doi": "10.5220/0008984901780186", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to advances in machine learning and artificial intelligence (AI), a new\nrole is emerging for machines as intelligent assistants to radiologists in\ntheir clinical workflows. But what systematic clinical thought processes are\nthese machines using? Are they similar enough to those of radiologists to be\ntrusted as assistants? A live demonstration of such a technology was conducted\nat the 2016 Scientific Assembly and Annual Meeting of the Radiological Society\nof North America (RSNA). The demonstration was presented in the form of a\nquestion-answering system that took a radiology multiple choice question and a\nmedical image as inputs. The AI system then demonstrated a cognitive workflow,\ninvolving text analysis, image analysis, and reasoning, to process the question\nand generate the most probable answer. A post demonstration survey was made\navailable to the participants who experienced the demo and tested the question\nanswering system. Of the reported 54,037 meeting registrants, 2,927 visited the\ndemonstration booth, 1,991 experienced the demo, and 1,025 completed a\npost-demonstration survey. In this paper, the methodology of the survey is\nshown and a summary of its results are presented. The results of the survey\nshow a very high level of receptiveness to cognitive computing technology and\nartificial intelligence among radiologists.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 20:40:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kanjaria", "Karina", ""], ["Pillai", "Anup", ""], ["Shivade", "Chaitanya", ""], ["Bendersky", "Marina", ""], ["Jadhav", "Ashutosh", ""], ["Mukherjee", "Vandana", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "2009.06086", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Yuan Zhou, Jian Peng", "title": "Efficient Competitive Self-Play Policy Optimization", "comments": "18 pages (10 for main text, 2 for reference, 8 for appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning from self-play has recently reported many successes.\nSelf-play, where the agents compete with themselves, is often used to generate\ntraining data for iterative policy improvement. In previous work, heuristic\nrules are designed to choose an opponent for the current learner. Typical rules\ninclude choosing the latest agent, the best agent, or a random historical\nagent. However, these rules may be inefficient in practice and sometimes do not\nguarantee convergence even in the simplest matrix games. In this paper, we\npropose a new algorithmic framework for competitive self-play reinforcement\nlearning in two-player zero-sum games. We recognize the fact that the Nash\nequilibrium coincides with the saddle point of the stochastic payoff function,\nwhich motivates us to borrow ideas from classical saddle point optimization\nliterature. Our method trains several agents simultaneously, and intelligently\ntakes each other as opponent based on simple adversarial rules derived from a\nprincipled perturbation-based saddle optimization method. We prove\ntheoretically that our algorithm converges to an approximate equilibrium with\nhigh probability in convex-concave games under standard assumptions. Beyond the\ntheory, we further show the empirical superiority of our method over baseline\nmethods relying on the aforementioned opponent-selection heuristics in matrix\ngames, grid-world soccer, Gomoku, and simulated robot sumo, with neural net\npolicy function approximators.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:01:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Zhou", "Yuan", ""], ["Peng", "Jian", ""]]}, {"id": "2009.06087", "submitter": "Alessandro Daniele", "authors": "Alessandro Daniele, Luciano Serafini", "title": "Neural Networks Enhancement through Prior Logical Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent past, there has been a growing interest in Neural-Symbolic\nIntegration frameworks, i.e., hybrid systems that integrate connectionist and\nsymbolic approaches: on the one hand, neural networks show remarkable abilities\nto learn from a large amount of data in presence of noise, on the other, pure\nsymbolic methods can perform reasoning as well as learning from few samples. By\ncombining the two paradigms, it should be possible to obtain a system that can\nboth learn from data and apply inference over some background knowledge. Here\nwe propose KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic\narchitecture that injects prior knowledge, codified in a set of universally\nquantified FOL clauses, into a neural network model. In KENN, clauses are used\nto generate a new final layer of the neural network which modifies the initial\npredictions based on the knowledge. Among the advantages of this strategy,\nthere is the possibility to include additional learnable parameters, the clause\nweights, each of which represents the strength of a specific clause. We\nevaluated KENN on two standard datasets for multi-label classification, showing\nthat the injection of clauses, automatically extracted from the training data,\nsensibly improves the performances. In a further experiment with manually\ncurated knowledge, KENN outperformed state-of-the-art methods on the VRD\nDataset, where the task is to classify relationships between detected objects\nin images. Finally, to evaluate how KENN deals with relational data, we tested\nit with different learning configurations on Citeseer, a standard dataset for\nCollective Classification. The obtained results show that KENN is capable of\nincreasing the performances of the underlying neural network even in the\npresence of relational data obtaining results in line with other methods that\ncombine learning with logic.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 21:12:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Daniele", "Alessandro", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.06103", "submitter": "Jay Yu Ph.D.", "authors": "Jay Yu, Kevin McCluskey, Saikat Mukherjee", "title": "Tax Knowledge Graph for a Smarter and More Personalized TurboTax", "comments": "KDD2020 International Workshop on Knowledge Graph: Mining Knowledge\n  Graph for Deep Insights. See:\n  https://suitclub.ischool.utexas.edu/IWKG_KDD2020/index.html. 6 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most knowledge graph use cases are data-centric, focusing on representing\ndata entities and their semantic relationships. There are no published success\nstories to represent large-scale complicated business logic with knowledge\ngraph technologies. In this paper, we will share our innovative and practical\napproach to representing complicated U.S. and Canadian income tax compliance\nlogic (calculations and rules) via a large-scale knowledge graph. We will cover\nhow the Tax Knowledge Graph is constructed and automated, how it is used to\ncalculate tax refunds, reasoned to find missing info, and navigated to explain\nthe calculated results. The Tax Knowledge Graph has helped transform Intuit's\nflagship TurboTax product into a smart and personalized experience,\naccelerating and automating the tax preparation process while instilling\nconfidence for millions of customers.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:41:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yu", "Jay", ""], ["McCluskey", "Kevin", ""], ["Mukherjee", "Saikat", ""]]}, {"id": "2009.06108", "submitter": "Tongxin Zhou", "authors": "Tongxin Zhou, Yingfei Wang, Lu (Lucy) Yan, Yong Tan", "title": "Spoiled for Choice? Personalized Recommendation for Healthcare\n  Decisions: A Multi-Armed Bandit Approach", "comments": "39 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online healthcare communities provide users with various healthcare\ninterventions to promote healthy behavior and improve adherence. When faced\nwith too many intervention choices, however, individuals may find it difficult\nto decide which option to take, especially when they lack the experience or\nknowledge to evaluate different options. The choice overload issue may\nnegatively affect users' engagement in health management. In this study, we\ntake a design-science perspective to propose a recommendation framework that\nhelps users to select healthcare interventions. Taking into account that users'\nhealth behaviors can be highly dynamic and diverse, we propose a multi-armed\nbandit (MAB)-driven recommendation framework, which enables us to adaptively\nlearn users' preference variations while promoting recommendation diversity in\nthe meantime. To better adapt an MAB to the healthcare context, we synthesize\ntwo innovative model components based on prominent health theories. The first\ncomponent is a deep-learning-based feature engineering procedure, which is\ndesigned to learn crucial recommendation contexts in regard to users'\nsequential health histories, health-management experiences, preferences, and\nintrinsic attributes of healthcare interventions. The second component is a\ndiversity constraint, which structurally diversifies recommendations in\ndifferent dimensions to provide users with well-rounded support. We apply our\napproach to an online weight management context and evaluate it rigorously\nthrough a series of experiments. Our results demonstrate that each of the\ndesign components is effective and that our recommendation design outperforms a\nwide range of state-of-the-art recommendation systems. Our study contributes to\nthe research on the application of business intelligence and has implications\nfor multiple stakeholders, including online healthcare platforms, policymakers,\nand users.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:55:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhou", "Tongxin", "", "Lucy"], ["Wang", "Yingfei", "", "Lucy"], ["Lu", "", "", "Lucy"], ["Yan", "", ""], ["Tan", "Yong", ""]]}, {"id": "2009.06110", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Identity-Based Patterns in Deep Convolutional Networks: Generative\n  Adversarial Phonology and Reduplication", "comments": "Paper accepted at TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models unsupervised learning of an identity-based pattern (or\ncopying) in speech called reduplication from raw continuous data with deep\nconvolutional neural networks. We use the ciwGAN architecture Begu\\v{s} (2021a;\narXiv:2006.02951) in which learning of meaningful representations in speech\nemerges from a requirement that the CNNs generate informative data. We propose\na technique to wug-test CNNs trained on speech and, based on four generative\ntests, argue that the network learns to represent an identity-based pattern in\nits latent space. By manipulating only two categorical variables in the latent\nspace, we can actively turn an unreduplicated form into a reduplicated form\nwith no other substantial changes to the output in the majority of cases. We\nalso argue that the network extends the identity-based pattern to unobserved\ndata. Exploration of how meaningful representations of identity-based patterns\nemerge in CNNs and how the latent space variables outside of the training range\ncorrelate with identity-based patterns in the output has general implications\nfor neural network interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:12:49 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 12:03:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2009.06112", "submitter": "Xinran Wang", "authors": "Xinran Wang, Yu Xiang, Jun Gao, Jie Ding", "title": "Information Laundering for Model Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose information laundering, a novel framework for\nenhancing model privacy. Unlike data privacy that concerns the protection of\nraw data information, model privacy aims to protect an already-learned model\nthat is to be deployed for public use. The private model can be obtained from\ngeneral learning methods, and its deployment means that it will return a\ndeterministic or random response for a given input query. An\ninformation-laundered model consists of probabilistic components that\ndeliberately maneuver the intended input and output for queries to the model,\nso the model's adversarial acquisition is less likely. Under the proposed\nframework, we develop an information-theoretic principle to quantify the\nfundamental tradeoffs between model utility and privacy leakage and derive the\noptimal design.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:24:08 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Wang", "Xinran", ""], ["Xiang", "Yu", ""], ["Gao", "Jun", ""], ["Ding", "Jie", ""]]}, {"id": "2009.06114", "submitter": "Peipei Xu", "authors": "Peipei Xu and Wenjie Ruan and Xiaowei Huang", "title": "Towards the Quantification of Safety Risks in Deep Neural Networks", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety concerns on the deep neural networks (DNNs) have been raised when they\nare applied to critical sectors. In this paper, we define safety risks by\nrequesting the alignment of the network's decision with human perception. To\nenable a general methodology for quantifying safety risks, we define a generic\nsafety property and instantiate it to express various safety risks. For the\nquantification of risks, we take the maximum radius of safe norm balls, in\nwhich no safety risk exists. The computation of the maximum safe radius is\nreduced to the computation of their respective Lipschitz metrics - the\nquantities to be computed. In addition to the known adversarial example,\nreachability example, and invariant example, in this paper we identify a new\nclass of risk - uncertainty example - on which humans can tell easily but the\nnetwork is unsure. We develop an algorithm, inspired by derivative-free\noptimization techniques and accelerated by tensor-based parallelization on\nGPUs, to support efficient computation of the metrics. We perform evaluations\non several benchmark neural networks, including ACSC-Xu, MNIST, CIFAR-10, and\nImageNet networks. The experiments show that, our method can achieve\ncompetitive performance on safety quantification in terms of the tightness and\nthe efficiency of computation. Importantly, as a generic approach, our method\ncan work with a broad class of safety risks and without restrictions on the\nstructure of neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:30:09 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xu", "Peipei", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""]]}, {"id": "2009.06131", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Cesar Augusto Tacla, and Henrique Jasinski", "title": "An Argumentation-based Approach for Explaining Goal Selection in\n  Intelligent Agents", "comments": "11 pages, 3 figures, accepted in the 9th Brazilian Conference on\n  Intelligent Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  During the first step of practical reasoning, i.e. deliberation or goals\nselection, an intelligent agent generates a set of pursuable goals and then\nselects which of them he commits to achieve. Explainable Artificial\nIntelligence (XAI) systems, including intelligent agents, must be able to\nexplain their internal decisions. In the context of goals selection, agents\nshould be able to explain the reasoning path that leads them to select (or not)\na certain goal. In this article, we use an argumentation-based approach for\ngenerating explanations about that reasoning path. Besides, we aim to enrich\nthe explanations with information about emerging conflicts during the selection\nprocess and how such conflicts were resolved. We propose two types of\nexplanations: the partial one and the complete one and a set of explanatory\nschemes to generate pseudo-natural explanations. Finally, we apply our proposal\nto the cleaner world scenario.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:10:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Tacla", "Cesar Augusto", ""], ["Jasinski", "Henrique", ""]]}, {"id": "2009.06141", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yiqing Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Composing Answer from Multi-spans for Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method to generate answers for non-extraction\nmachine reading comprehension (MRC) tasks whose answers cannot be simply\nextracted as one span from the given passages. Using a pointer network-style\nextractive decoder for such type of MRC may result in unsatisfactory\nperformance when the ground-truth answers are given by human annotators or\nhighly re-paraphrased from parts of the passages. On the other hand, using\ngenerative decoder cannot well guarantee the resulted answers with well-formed\nsyntax and semantics when encountering long sentences. Therefore, to alleviate\nthe obvious drawbacks of both sides, we propose an answer making-up method from\nextracted multi-spans that are learned by our model as highly confident\n$n$-gram candidates in the given passage. That is, the returned answers are\ncomposed of discontinuous multi-spans but not just one consecutive span in the\ngiven passages anymore. The proposed method is simple but effective: empirical\nexperiments on MS MARCO show that the proposed method has a better performance\non accurately generating long answers, and substantially outperforms two\ncompetitive typical one-span and Seq2Seq baseline decoders.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:44:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhang", "Yiqing", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.06202", "submitter": "Johannes Lederer", "authors": "Johannes Lederer", "title": "Risk Bounds for Robust Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been observed that certain loss functions can render deep-learning\npipelines robust against flaws in the data. In this paper, we support these\nempirical findings with statistical theory. We especially show that\nempirical-risk minimization with unbounded, Lipschitz-continuous loss\nfunctions, such as the least-absolute deviation loss, Huber loss, Cauchy loss,\nand Tukey's biweight loss, can provide efficient prediction under minimal\nassumptions on the data. More generally speaking, our paper provides\ntheoretical evidence for the benefits of robust loss functions in deep\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:06:59 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lederer", "Johannes", ""]]}, {"id": "2009.06215", "submitter": "Feng Zhu", "authors": "Feng Zhu, Yan Wang, Chaochao Chen, Guanfeng Liu, Mehmet Orgun, Jia Wu", "title": "A Deep Framework for Cross-Domain and Cross-System Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Domain Recommendation (CDR) and Cross-System Recommendations (CSR) are\ntwo of the promising solutions to address the long-standing data sparsity\nproblem in recommender systems. They leverage the relatively richer\ninformation, e.g., ratings, from the source domain or system to improve the\nrecommendation accuracy in the target domain or system. Therefore, finding an\naccurate mapping of the latent factors across domains or systems is crucial to\nenhancing recommendation accuracy. However, this is a very challenging task\nbecause of the complex relationships between the latent factors of the source\nand target domains or systems. To this end, in this paper, we propose a Deep\nframework for both Cross-Domain and Cross-System Recommendations, called\nDCDCSR, based on Matrix Factorization (MF) models and a fully connected Deep\nNeural Network (DNN). Specifically, DCDCSR first employs the MF models to\ngenerate user and item latent factors and then employs the DNN to map the\nlatent factors across domains or systems. More importantly, we take into\naccount the rating sparsity degrees of individual users and items in different\ndomains or systems and use them to guide the DNN training process for utilizing\nthe rating data more effectively. Extensive experiments conducted on three\nreal-world datasets demonstrate that DCDCSR framework outperforms the\nstate-of-the-art CDR and CSR approaches in terms of recommendation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:11:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhu", "Feng", ""], ["Wang", "Yan", ""], ["Chen", "Chaochao", ""], ["Liu", "Guanfeng", ""], ["Orgun", "Mehmet", ""], ["Wu", "Jia", ""]]}, {"id": "2009.06237", "submitter": "Jinho Lee", "authors": "Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim,\n  Jinho Lee", "title": "DANCE: Differentiable Accelerator/Network Co-Exploration", "comments": "Accepted to DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the ever-increasing computational demand of the DNN execution,\nrecent neural architecture search (NAS) algorithms consider hardware cost\nmetrics into account, such as GPU latency. To further pursue a fast, efficient\nexecution, DNN-specialized hardware accelerators are being designed for\nmultiple purposes, which far-exceeds the efficiency of the GPUs. However, those\nhardware-related metrics have been proven to exhibit non-linear relationships\nwith the network architectures. Therefore it became a chicken-and-egg problem\nto optimize the network against the accelerator, or to optimize the accelerator\nagainst the network. In such circumstances, this work presents DANCE, a\ndifferentiable approach towards the co-exploration of the hardware accelerator\nand network architecture design. At the heart of DANCE is a differentiable\nevaluator network. By modeling the hardware evaluation software with a neural\nnetwork, the relation between the accelerator architecture and the hardware\nmetrics becomes differentiable, allowing the search to be performed with\nbackpropagation. Compared to the naive existing approaches, our method performs\nco-exploration in a significantly shorter time, while achieving superior\naccuracy and hardware cost metrics.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:43:27 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 12:14:17 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 04:41:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Choi", "Kanghyun", ""], ["Hong", "Deokki", ""], ["Yoon", "Hojae", ""], ["Yu", "Joonsang", ""], ["Kim", "Youngsok", ""], ["Lee", "Jinho", ""]]}, {"id": "2009.06245", "submitter": "Chao Qian Mr", "authors": "Chao Qian, Wenjing Ye", "title": "Accelerating gradient-based topology optimization design with dual-model\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology optimization (TO) is a common technique used in free-form designs.\nHowever, conventional TO-based design approaches suffer from high computational\ncost due to the need for repetitive forward calculations and/or sensitivity\nanalysis, which are typically done using high-dimensional simulations such as\nFinite Element Analysis (FEA). In this work, neural networks are used as\nefficient surrogate models for forward and sensitivity calculations in order to\ngreatly accelerate the design process of topology optimization. To improve the\naccuracy of sensitivity analyses, dual-model neural networks that are trained\nwith both forward and sensitivity data are constructed and are integrated into\nthe Solid Isotropic Material with Penalization (SIMP) method to replace FEA.\nThe performance of the accelerated SIMP method is demonstrated on two benchmark\ndesign problems namely minimum compliance design and metamaterial design. The\nefficiency gained in the problem with size of 64x64 is 137 times in forward\ncalculation and 74 times in sensitivity analysis. In addition, effective data\ngeneration methods suitable for TO designs are investigated and developed,\nwhich lead to a great saving in training time. In both benchmark design\nproblems, a design accuracy of 95% can be achieved with only around 2000\ntraining data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 07:52:55 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Qian", "Chao", ""], ["Ye", "Wenjing", ""]]}, {"id": "2009.06251", "submitter": "Boris Ruf", "authors": "Boris Ruf and Marcin Detyniecki", "title": "Active Fairness Instead of Unawareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possible risk that AI systems could promote discrimination by reproducing\nand enforcing unwanted bias in data has been broadly discussed in research and\nsociety. Many current legal standards demand to remove sensitive attributes\nfrom data in order to achieve \"fairness through unawareness\". We argue that\nthis approach is obsolete in the era of big data where large datasets with\nhighly correlated attributes are common. In the contrary, we propose the active\nuse of sensitive attributes with the purpose of observing and controlling any\nkind of discrimination, and thus leading to fair results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:14:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ruf", "Boris", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2009.06288", "submitter": "Javier Juan-Albarrac\\'in", "authors": "Javier Juan-Albarrac\\'in", "title": "Unsupervised learning for vascular heterogeneity assessment of\n  glioblastoma based on magnetic resonance imaging: The Hemodynamic Tissue\n  Signature", "comments": "PhD thesis. Supervisors: Juan M. Garc\\'ia-G\\'omez and Elies\n  Fuster-Garcia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis focuses on the research and development of the Hemodynamic Tissue\nSignature (HTS) method: an unsupervised machine learning approach to describe\nthe vascular heterogeneity of glioblastomas by means of perfusion MRI analysis.\nThe HTS builds on the concept of habitats. An habitat is defined as a\nsub-region of the lesion with a particular MRI profile describing a specific\nphysiological behavior. The HTS method delineates four habitats within the\nglioblastoma: the High Angiogenic Tumor (HAT) habitat, as the most perfused\nregion of the enhancing tumor; the Low Angiogenic Tumor (LAT) habitat, as the\nregion of the enhancing tumor with a lower angiogenic profile; the potentially\nInfiltrated Peripheral Edema (IPE) habitat, as the non-enhancing region\nadjacent to the tumor with elevated perfusion indexes; and the Vasogenic\nPeripheral Edema (VPE) habitat, as the remaining edema of the lesion with the\nlowest perfusion profile.\n  The results of this thesis have been published in ten scientific\ncontributions, including top-ranked journals and conferences in the areas of\nMedical Informatics, Statistics and Probability, Radiology & Nuclear Medicine,\nMachine Learning and Data Mining and Biomedical Engineering. An industrial\npatent registered in Spain (ES201431289A), Europe (EP3190542A1) and EEUU\n(US20170287133A1) was also issued, summarizing the efforts of the thesis to\ngenerate tangible assets besides the academic revenue obtained from research\npublications. Finally, the methods, technologies and original ideas conceived\nin this thesis led to the foundation of ONCOANALYTICS CDX, a company framed\ninto the business model of companion diagnostics for pharmaceutical compounds,\nthought as a vehicle to facilitate the industrialization of the ONCOhabitats\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:35:01 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Juan-Albarrac\u00edn", "Javier", ""]]}, {"id": "2009.06295", "submitter": "Hassan Ahmed Sial", "authors": "Hassan Sial, Ramon Baldrich, Maria Vanrell", "title": "Deep intrinsic decomposition trained on surreal scenes yet with\n  realistic light effects", "comments": null, "journal-ref": "JOSA A 2020", "doi": "10.1364/JOSAA.37.000001", "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of intrinsic images still remains a challenging task due to\nweaknesses of ground-truth datasets, which either are too small or present\nnon-realistic issues. On the other hand, end-to-end deep learning architectures\nstart to achieve interesting results that we believe could be improved if\nimportant physical hints were not ignored. In this work, we present a twofold\nframework: (a) a flexible generation of images overcoming some classical\ndataset problems such as larger size jointly with coherent lighting appearance;\nand (b) a flexible architecture tying physical properties through intrinsic\nlosses. Our proposal is versatile, presents low computation time, and achieves\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 09:45:49 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sial", "Hassan", ""], ["Baldrich", "Ramon", ""], ["Vanrell", "Maria", ""]]}, {"id": "2009.06345", "submitter": "Yassine Himeur", "authors": "Yassine Himeur, Abdullah Alsalemi, Ayman Al-Kababji, Faycal Bensaali,\n  Abbes Amira", "title": "Data fusion strategies for energy efficiency in buildings: Overview,\n  challenges and novel orientations", "comments": null, "journal-ref": "Information Fusion, 2020, 64, 99-120", "doi": "10.1016/j.inffus.2020.07.003", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, tremendous interest has been devoted to develop data fusion\nstrategies for energy efficiency in buildings, where various kinds of\ninformation can be processed. However, applying the appropriate data fusion\nstrategy to design an efficient energy efficiency system is not\nstraightforward; it requires a priori knowledge of existing fusion strategies,\ntheir applications and their properties. To this regard, seeking to provide the\nenergy research community with a better understanding of data fusion strategies\nin building energy saving systems, their principles, advantages, and potential\napplications, this paper proposes an extensive survey of existing data fusion\nmechanisms deployed to reduce excessive consumption and promote sustainability.\nWe investigate their conceptualizations, advantages, challenges and drawbacks,\nas well as performing a taxonomy of existing data fusion strategies and other\ncontributing factors. Following, a comprehensive comparison of the\nstate-of-the-art data fusion based energy efficiency frameworks is conducted\nusing various parameters, including data fusion level, data fusion techniques,\nbehavioral change influencer, behavioral change incentive, recorded data,\nplatform architecture, IoT technology and application scenario. Moreover, a\nnovel method for electrical appliance identification is proposed based on the\nfusion of 2D local texture descriptors, where 1D power signals are transformed\ninto 2D space and treated as images. The empirical evaluation, conducted on\nthree real datasets, shows promising performance, in which up to 99.68%\naccuracy and 99.52% F1 score have been attained. In addition, various open\nresearch challenges and future orientations to improve data fusion based energy\nefficiency ecosystems are explored.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:04:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Al-Kababji", "Ayman", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2009.06354", "submitter": "Michael Collins", "authors": "Matthew Lamm, Jennimaria Palomaki, Chris Alberti, Daniel Andor, Eunsol\n  Choi, Livio Baldini Soares, Michael Collins", "title": "QED: A Framework and Dataset for Explanations in Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A question answering system that in addition to providing an answer provides\nan explanation of the reasoning that leads to that answer has potential\nadvantages in terms of debuggability, extensibility and trust. To this end, we\npropose QED, a linguistically informed, extensible framework for explanations\nin question answering. A QED explanation specifies the relationship between a\nquestion and answer according to formal semantic notions such as referential\nequality, sentencehood, and entailment. We describe and publicly release an\nexpert-annotated dataset of QED explanations built upon a subset of the Google\nNatural Questions dataset, and report baseline models on two tasks -- post-hoc\nexplanation generation given an answer, and joint question answering and\nexplanation generation. In the joint setting, a promising result suggests that\ntraining on a relatively small amount of QED data can improve question\nanswering. In addition to describing the formal, language-theoretic motivations\nfor the QED approach, we describe a large user study showing that the presence\nof QED explanations significantly improves the ability of untrained raters to\nspot errors made by a strong neural QA baseline.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 23:34:18 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lamm", "Matthew", ""], ["Palomaki", "Jennimaria", ""], ["Alberti", "Chris", ""], ["Andor", "Daniel", ""], ["Choi", "Eunsol", ""], ["Soares", "Livio Baldini", ""], ["Collins", "Michael", ""]]}, {"id": "2009.06355", "submitter": "Jamie Carr", "authors": "Jamie Carr", "title": "Using Graph Convolutional Networks and TD($\\lambda$) to play the game of\n  Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk is 6 player game with significant randomness and a large game-tree\ncomplexity which poses a challenge to creating an agent to play the game\neffectively. Previous AIs focus on creating high-level handcrafted features\ndetermine agent decision making. In this project, I create D.A.D, A Risk agent\nusing temporal difference reinforcement learning to train a Deep Neural Network\nincluding a Graph Convolutional Network to evaluate player positions. This is\nused in a game-tree to select optimal moves. This allows minimal handcrafting\nof knowledge into the AI, assuring input features are as low-level as possible\nto allow the network to extract useful and sophisticated features itself, even\nwith the network starting from a random initialisation. I also tackle the issue\nof non-determinism in Risk by introducing a new method of interpreting attack\nmoves necessary for the search. The result is an AI which wins 35% of the time\nversus 5 of best inbuilt AIs in Lux Delux, a Risk variant.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:47:08 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Carr", "Jamie", ""]]}, {"id": "2009.06356", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Adam Summerville, Sam Snodgrass, Gerard Bentley, Joseph\n  Osborn", "title": "Exploring Level Blending across Platformers via Paths and Affordances", "comments": "6 pages, 5 figures, 16th AAAI Conference on Artificial Intelligence\n  and Interactive Digital Entertainment (AIIDE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for procedural content generation via machine learning (PCGML)\nhave been shown to be useful for generating novel game content. While used\nprimarily for producing new content in the style of the game domain used for\ntraining, recent works have increasingly started to explore methods for\ndiscovering and generating content in novel domains via techniques such as\nlevel blending and domain transfer. In this paper, we build on these works and\nintroduce a new PCGML approach for producing novel game content spanning\nmultiple domains. We use a new affordance and path vocabulary to encode data\nfrom six different platformer games and train variational autoencoders on this\ndata, enabling us to capture the latent level space spanning all the domains\nand generate new content with varying proportions of the different domains.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:43:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sarkar", "Anurag", ""], ["Summerville", "Adam", ""], ["Snodgrass", "Sam", ""], ["Bentley", "Gerard", ""], ["Osborn", "Joseph", ""]]}, {"id": "2009.06368", "submitter": "Yanjun  Qi Dr.", "authors": "Jin Yong Yoo, John X. Morris, Eli Lifland, Yanjun Qi", "title": "Searching for a Search Method: Benchmarking Search Algorithms for\n  Generating NLP Adversarial Examples", "comments": "14 pages, 5 figures, 4 tables; Accepted by EMNLP BlackBox NLP\n  Workshop 2020 @ https://blackboxnlp.github.io/cfp.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of several black-box search algorithms used for\ngenerating adversarial examples for natural language processing (NLP) tasks. We\nperform a fine-grained analysis of three elements relevant to search: search\nalgorithm, search space, and search budget. When new search algorithms are\nproposed in past work, the attack search space is often modified alongside the\nsearch algorithm. Without ablation studies benchmarking the search algorithm\nchange with the search space held constant, one cannot tell if an increase in\nattack success rate is a result of an improved search algorithm or a less\nrestrictive search space. Additionally, many previous studies fail to properly\nconsider the search algorithms' run-time cost, which is essential for\ndownstream tasks like adversarial training. Our experiments provide a\nreproducible benchmark of search algorithms across a variety of search spaces\nand query budgets to guide future research in adversarial NLP. Based on our\nexperiments, we recommend greedy attacks with word importance ranking when\nunder a time constraint or attacking long inputs, and either beam search or\nparticle swarm optimization otherwise. Code implementation shared via\nhttps://github.com/QData/TextAttack-Search-Benchmark\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:04:42 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:46:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yoo", "Jin Yong", ""], ["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Qi", "Yanjun", ""]]}, {"id": "2009.06370", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Transparency and granularity in the SP Theory of Intelligence and its\n  realisation in the SP Computer Model", "comments": "Published in the book {\\em Interpretable Artificial Intelligence: A\n  Perspective of Granular Computing}, Witold Pedrycz and Shyi-Ming Chen\n  (editors), Springer: Heidelberg, 2021, ISBN 978-3-030-64948-7, DOI:\n  10.1007/978-3-030-64949-4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter describes how the SP System, meaning the SP Theory of\nIntelligence, and its realisation as the SP Computer Model, may promote\ntransparency and granularity in AI, and some other areas of application. The\nchapter describes how transparency in the workings and output of the SP\nComputer Model may be achieved via three routes: 1) the program provides a very\nfull audit trail for such processes as recognition, reasoning, analysis of\nlanguage, and so on. There is also an explicit audit trail for the unsupervised\nlearning of new knowledge; 2) knowledge from the system is likely to be\ngranular and easy for people to understand; and 3) there are seven principles\nfor the organisation of knowledge which are central in the workings of the SP\nSystem and also very familiar to people (eg chunking-with-codes, part-whole\nhierarchies, and class-inclusion hierarchies), and that kind of familiarity in\nthe way knowledge is structured by the system, is likely to be important in the\ninterpretability, explainability, and transparency of that knowledge. Examples\nfrom the SP Computer Model are shown throughout the chapter.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:31:12 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 13:32:31 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "2009.06371", "submitter": "Noslen Hernandez", "authors": "Noslen Hern\\'andez and Aline Duarte", "title": "SeqROCTM: A Matlab toolbox for the analysis of Sequence of Random\n  Objects driven by Context Tree Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several research problems we deal with probabilistic sequences of inputs\n(e.g., sequence of stimuli) from which an agent generates a corresponding\nsequence of responses and it is of interest to model the relation between them.\nA new class of stochastic processes, namely \\textit{sequences of random objects\ndriven by context tree models}, has been introduced to model such relation in\nthe context of auditory statistical learning. This paper introduces a freely\navailable Matlab toolbox (SeqROCTM) that implements this new class of\nstochastic processes and three model selection procedures to make inference on\nit. Besides, due to the close relation of the new mathematical framework with\ncontext tree models, the toolbox also implements several existing model\nselection algorithms for context tree models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 15:28:32 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 00:33:42 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 16:38:05 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Hern\u00e1ndez", "Noslen", ""], ["Duarte", "Aline", ""]]}, {"id": "2009.06389", "submitter": "Sahib Singh", "authors": "Tom Farrand, Fatemehsadat Mireshghallah, Sahib Singh, Andrew Trask", "title": "Neither Private Nor Fair: Impact of Data Imbalance on Utility and\n  Fairness in Differential Privacy", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep learning in different fields and industries is growing day\nby day due to its performance, which relies on the availability of data and\ncompute. Data is often crowd-sourced and contains sensitive information about\nits contributors, which leaks into models that are trained on it. To achieve\nrigorous privacy guarantees, differentially private training mechanisms are\nused. However, it has recently been shown that differential privacy can\nexacerbate existing biases in the data and have disparate impacts on the\naccuracy of different subgroups of data. In this paper, we aim to study these\neffects within differentially private deep learning. Specifically, we aim to\nstudy how different levels of imbalance in the data affect the accuracy and the\nfairness of the decisions made by the model, given different levels of privacy.\nWe demonstrate that even small imbalances and loose privacy guarantees can\ncause disparate impacts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:35:49 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 16:00:29 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 11:55:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Farrand", "Tom", ""], ["Mireshghallah", "Fatemehsadat", ""], ["Singh", "Sahib", ""], ["Trask", "Andrew", ""]]}, {"id": "2009.06398", "submitter": "Reda Marzouk", "authors": "Reda Marzouk", "title": "On Computability, Learnability and Extractability of Finite State\n  Machines from Recurrent Neural Networks", "comments": "Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at shedding some light on connections between finite state\nmachines (FSMs), and recurrent neural networks (RNNs). Examined connections in\nthis master's thesis is threefold: the extractability of finite state machines\nfrom recurrent neural networks, learnability aspects and computationnal links.\nWith respect to the former, the long-standing clustering hypothesis of RNN\nhidden state space when trained to recognize regular languages was explored,\nand new insights into this hypothesis through the lens of recent advances of\nthe generalization theory of Deep Learning are provided. As for learnability,\nan extension of the active learning framework better suited to the problem of\napproximating RNNs with FSMs is proposed, with the aim of better formalizing\nthe problem of RNN approximation by FSMs. Theoretical analysis of two possible\nscenarions in this framework were performed. With regard to computability, new\ncomputational results on the distance and the equivalence problem between RNNs\ntrained as language models and different types of weighted finite state\nmachines were given.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:55:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Marzouk", "Reda", ""]]}, {"id": "2009.06399", "submitter": "Mark Keane", "authors": "Eoin M. Kenny and Mark T. Keane", "title": "On Generating Plausible Counterfactual and Semi-Factual Explanations for\n  Deep Learning", "comments": "4 figures, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing concern that the recent progress made in AI, especially\nregarding the predictive competence of deep learning models, will be undermined\nby a failure to properly explain their operation and outputs. In response to\nthis disquiet counterfactual explanations have become massively popular in\neXplainable AI (XAI) due to their proposed computational psychological, and\nlegal benefits. In contrast however, semifactuals, which are a similar way\nhumans commonly explain their reasoning, have surprisingly received no\nattention. Most counterfactual methods address tabular rather than image data,\npartly due to the nondiscrete nature of the latter making good counterfactuals\ndifficult to define. Additionally generating plausible looking explanations\nwhich lie on the data manifold is another issue which hampers progress. This\npaper advances a novel method for generating plausible counterfactuals (and\nsemifactuals) for black box CNN classifiers doing computer vision. The present\nmethod, called PlausIble Exceptionality-based Contrastive Explanations (PIECE),\nmodifies all exceptional features in a test image to be normal from the\nperspective of the counterfactual class (hence concretely defining a\ncounterfactual). Two controlled experiments compare this method to others in\nthe literature, showing that PIECE not only generates the most plausible\ncounterfactuals on several measures, but also the best semifactuals.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:48:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kenny", "Eoin M.", ""], ["Keane", "Mark T.", ""]]}, {"id": "2009.06401", "submitter": "Pepa Atanasova", "authors": "Wojciech Ostrowski, Arnav Arora, Pepa Atanasova, Isabelle Augenstein", "title": "Multi-Hop Fact Checking of Political Claims", "comments": "10 pages, to be published at Proceedings of IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed multi-hop models and datasets for studying complex\nnatural language reasoning. One notable task requiring multi-hop reasoning is\nfact checking, where a set of connected evidence pieces leads to the final\nverdict of a claim. However, existing datasets either do not provide\nannotations for gold evidence pages, or the only dataset which does (FEVER)\nmostly consists of claims which can be fact-checked with simple reasoning and\nis constructed artificially. Here, we study more complex claim verification of\nnaturally occurring claims with multiple hops over interconnected evidence\nchunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence\nsentences for claim verification; 2) compare it to existing multi-hop datasets;\nand 3) study how to transfer knowledge from more extensive in- and\nout-of-domain resources to PolitiHop. We find that the task is complex and\nachieve the best performance with an architecture that specifically models\nreasoning over evidence pieces in combination with in-domain transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:54:15 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:00:26 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 14:06:14 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ostrowski", "Wojciech", ""], ["Arora", "Arnav", ""], ["Atanasova", "Pepa", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.06410", "submitter": "Celine Hocquette", "authors": "Lun Ai and Stephen H. Muggleton and C\\'eline Hocquette and Mark\n  Gromowski and Ute Schmid", "title": "Beneficial and Harmful Explanatory Machine Learning", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent successes of Deep Learning in AI there has been increased\ninterest in the role and need for explanations in machine learned theories. A\ndistinct notion in this context is that of Michie's definition of Ultra-Strong\nMachine Learning (USML). USML is demonstrated by a measurable increase in human\nperformance of a task following provision to the human of a symbolic machine\nlearned theory for task performance. A recent paper demonstrates the beneficial\neffect of a machine learned logic theory for a classification task, yet no\nexisting work to our knowledge has examined the potential harmfulness of\nmachine's involvement for human comprehension during learning. This paper\ninvestigates the explanatory effects of a machine learned theory in the context\nof simple two person games and proposes a framework for identifying the\nharmfulness of machine explanations based on the Cognitive Science literature.\nThe approach involves a cognitive window consisting of two quantifiable bounds\nand it is supported by empirical evidence collected from human trials. Our\nquantitative and qualitative results indicate that human learning aided by a\nsymbolic machine learned theory which satisfies a cognitive window has achieved\nsignificantly higher performance than human self learning. Results also\ndemonstrate that human learning aided by a symbolic machine learned theory that\nfails to satisfy this window leads to significantly worse performance than\nunaided human learning.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:14:38 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:19:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ai", "Lun", ""], ["Muggleton", "Stephen H.", ""], ["Hocquette", "C\u00e9line", ""], ["Gromowski", "Mark", ""], ["Schmid", "Ute", ""]]}, {"id": "2009.06415", "submitter": "Alexandre Lacoste", "authors": "Alexandre Lacoste, Pau Rodr\\'iguez, Fr\\'ed\\'eric Branchaud-Charron,\n  Parmida Atighehchian, Massimo Caccia, Issam Laradji, Alexandre Drouin, Matt\n  Craddock, Laurent Charlin, David V\\'azquez", "title": "Synbols: Probing Learning Algorithms with Synthetic Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in the field of machine learning has been fueled by the introduction\nof benchmark datasets pushing the limits of existing algorithms. Enabling the\ndesign of datasets to test specific properties and failure modes of learning\nalgorithms is thus a problem of high interest, as it has a direct impact on\ninnovation in the field. In this sense, we introduce Synbols -- Synthetic\nSymbols -- a tool for rapidly generating new datasets with a rich composition\nof latent features rendered in low resolution images. Synbols leverages the\nlarge amount of symbols available in the Unicode standard and the wide range of\nartistic font provided by the open font community. Our tool's high-level\ninterface provides a language for rapidly generating new distributions on the\nlatent features, including various types of textures and occlusions. To\nshowcase the versatility of Synbols, we use it to dissect the limitations and\nflaws in standard learning algorithms in various learning setups including\nsupervised learning, active learning, out of distribution generalization,\nunsupervised representation learning, and object counting.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:03:27 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 21:57:37 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Lacoste", "Alexandre", ""], ["Rodr\u00edguez", "Pau", ""], ["Branchaud-Charron", "Fr\u00e9d\u00e9ric", ""], ["Atighehchian", "Parmida", ""], ["Caccia", "Massimo", ""], ["Laradji", "Issam", ""], ["Drouin", "Alexandre", ""], ["Craddock", "Matt", ""], ["Charlin", "Laurent", ""], ["V\u00e1zquez", "David", ""]]}, {"id": "2009.06425", "submitter": "Ghalib Tahir", "authors": "Nauman Khalid, Ghalib Ahmed Tahir, Peter Bloodsworth", "title": "Persistent And Scalable JADE: A Cloud based InMemory Multi-agent\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-agent systems are often limited in terms of persistenceand scalability.\nThis issue is more prevalent for applications inwhich agent states changes\nfrequently. This makes the existingmethods less usable as they increase the\nagent's complexityand are less scalable. This research study has presented\nanovel in-memory agent persistence framework. Two prototypeshave been\nimplemented, one using the proposed solution andthe other using an established\nagent persistency environment.Experimental results confirm that the proposed\nframework ismore scalable than existing approaches whilst providing asimilar\nlevel of persistency. These findings will help futurereal-time multiagent\nsystems to become scalable and persistentin a dynamic cloud environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:22:37 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 23:50:02 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Khalid", "Nauman", ""], ["Tahir", "Ghalib Ahmed", ""], ["Bloodsworth", "Peter", ""]]}, {"id": "2009.06429", "submitter": "Anna Lukina", "authors": "Anna Lukina, Christian Schilling, Thomas A. Henzinger", "title": "Into the Unknown: Active Monitoring of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-network classifiers achieve high accuracy when predicting the class of\nan input that they were trained to identify. Maintaining this accuracy in\ndynamic environments, where inputs frequently fall outside the fixed set of\ninitially known classes, remains a challenge. The typical approach is to detect\ninputs from novel classes and retrain the classifier on an augmented dataset.\nHowever, not only the classifier but also the detection mechanism needs to\nadapt in order to distinguish between newly learned and yet unknown input\nclasses. To address this challenge, we introduce an algorithmic framework for\nactive monitoring of a neural network. A monitor wrapped in our framework\noperates in parallel with the neural network and interacts with a human user\nvia a series of interpretable labeling queries for incremental adaptation. In\naddition, we propose an adaptive quantitative monitor to improve precision. An\nexperimental evaluation on a diverse set of benchmarks with varying numbers of\nclasses confirms the benefits of our active monitoring framework in dynamic\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:29:47 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 13:00:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lukina", "Anna", ""], ["Schilling", "Christian", ""], ["Henzinger", "Thomas A.", ""]]}, {"id": "2009.06432", "submitter": "Ujwal Krothapalli", "authors": "Ujwal Krothapalli and A. Lynn Abbott", "title": "Adaptive Label Smoothing", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the use of objectness measures to improve the calibration\nperformance of Convolutional Neural Networks (CNNs). CNNs have proven to be\nvery good classifiers and generally localize objects well; however, the loss\nfunctions typically used to train classification CNNs do not penalize inability\nto localize an object, nor do they take into account an object's relative size\nin the given image. During training on ImageNet-1K almost all approaches use\nrandom crops on the images and this transformation sometimes provides the CNN\nwith background only samples. This causes the classifiers to depend on context.\nContext dependence is harmful for safety-critical applications. We present a\nnovel approach to classification that combines the ideas of objectness and\nlabel smoothing during training. Unlike previous methods, we compute a\nsmoothing factor that is \\emph{adaptive} based on relative object size within\nan image. This causes our approach to produce confidences that are grounded in\nthe size of the object being classified instead of relying on context to make\nthe correct predictions. We present extensive results using ImageNet to\ndemonstrate that CNNs trained using adaptive label smoothing are much less\nlikely to be overconfident in their predictions. We show qualitative results\nusing class activation maps and quantitative results using classification and\ntransfer learning tasks. Our approach is able to produce an order of magnitude\nreduction in confidence when predicting on context only images when compared to\nbaselines. Using transfer learning, we gain 2.1mAP on MS COCO compared to the\nhard label approach.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:37:30 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 23:19:08 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Krothapalli", "Ujwal", ""], ["Abbott", "A. Lynn", ""]]}, {"id": "2009.06433", "submitter": "Fabian Sperrle", "authors": "Fabian Sperrle, Mennatallah El-Assady, Grace Guo, Duen Horng Chau,\n  Alex Endert, Daniel Keim", "title": "Should We Trust (X)AI? Design Dimensions for Structured Experimental\n  Evaluations", "comments": "18pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper systematically derives design dimensions for the structured\nevaluation of explainable artificial intelligence (XAI) approaches. These\ndimensions enable a descriptive characterization, facilitating comparisons\nbetween different study designs. They further structure the design space of\nXAI, converging towards a precise terminology required for a rigorous study of\nXAI. Our literature review differentiates between comparative studies and\napplication papers, revealing methodological differences between the fields of\nmachine learning, human-computer interaction, and visual analytics. Generally,\neach of these disciplines targets specific parts of the XAI process. Bridging\nthe resulting gaps enables a holistic evaluation of XAI in real-world\nscenarios, as proposed by our conceptual model characterizing bias sources and\ntrust-building. Furthermore, we identify and discuss the potential for future\nwork based on observed research gaps that should lead to better coverage of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:40:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sperrle", "Fabian", ""], ["El-Assady", "Mennatallah", ""], ["Guo", "Grace", ""], ["Chau", "Duen Horng", ""], ["Endert", "Alex", ""], ["Keim", "Daniel", ""]]}, {"id": "2009.06444", "submitter": "Debo Cheng", "authors": "Debo Cheng, Jiuyong Li, Lin Liu, Jixue Liu", "title": "Sufficient Dimension Reduction for Average Causal Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a large number of covariates can have a negative impact on the quality\nof causal effect estimation since confounding adjustment becomes unreliable\nwhen the number of covariates is large relative to the samples available.\nPropensity score is a common way to deal with a large covariate set, but the\naccuracy of propensity score estimation (normally done by logistic regression)\nis also challenged by large number of covariates. In this paper, we prove that\na large covariate set can be reduced to a lower dimensional representation\nwhich captures the complete information for adjustment in causal effect\nestimation. The theoretical result enables effective data-driven algorithms for\ncausal effect estimation. We develop an algorithm which employs a supervised\nkernel dimension reduction method to search for a lower dimensional\nrepresentation for the original covariates, and then utilizes nearest neighbor\nmatching in the reduced covariate space to impute the counterfactual outcomes\nto avoid large-sized covariate set problem. The proposed algorithm is evaluated\non two semi-synthetic and three real-world datasets and the results have\ndemonstrated the effectiveness of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 13:58:57 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Liu", "Jixue", ""]]}, {"id": "2009.06487", "submitter": "Chengyu Wang", "authors": "Chengyu Wang, Mengli Cheng, Xu Hu, Jun Huang", "title": "EasyASR: A Distributed Machine Learning Platform for End-to-end\n  Automatic Speech Recognition", "comments": "aaai 2021 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EasyASR, a distributed machine learning platform for training and\nserving large-scale Automatic Speech Recognition (ASR) models, as well as\ncollecting and processing audio data at scale. Our platform is built upon the\nMachine Learning Platform for AI of Alibaba Cloud. Its main functionality is to\nsupport efficient learning and inference for end-to-end ASR models on\ndistributed GPU clusters. It allows users to learn ASR models with either\npre-defined or user-customized network architectures via simple user interface.\nOn EasyASR, we have produced state-of-the-art results over several public\ndatasets for Mandarin speech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:47:02 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 09:44:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Chengyu", ""], ["Cheng", "Mengli", ""], ["Hu", "Xu", ""], ["Huang", "Jun", ""]]}, {"id": "2009.06489", "submitter": "Sara Hooker", "authors": "Sara Hooker", "title": "The Hardware Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware, systems and algorithms research communities have historically had\ndifferent incentive structures and fluctuating motivation to engage with each\nother explicitly. This historical treatment is odd given that hardware and\nsoftware have frequently determined which research ideas succeed (and fail).\nThis essay introduces the term hardware lottery to describe when a research\nidea wins because it is suited to the available software and hardware and not\nbecause the idea is superior to alternative research directions. Examples from\nearly computer science history illustrate how hardware lotteries can delay\nresearch progress by casting successful ideas as failures. These lessons are\nparticularly salient given the advent of domain specialized hardware which make\nit increasingly costly to stray off of the beaten path of research ideas. This\nessay posits that the gains from progress in computing are likely to become\neven more uneven, with certain research directions moving into the fast-lane\nwhile progress on others is further obstructed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:49:10 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 22:58:12 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Hooker", "Sara", ""]]}, {"id": "2009.06496", "submitter": "Fauzi Adi Rafrastara", "authors": "Etika Kartikadarma, Sari Wijayanti, Sari Ayu Wulandari, Fauzi Adi\n  Rafrastara", "title": "Principle Component Analysis for Classification of the Quality of\n  Aromatic Rice", "comments": "5 pages, 11 figures, International Journal of Computer Science and\n  Information Security (IJCSIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research introduces an instrument for performing quality control on\naromatic rice by utilizing feature extraction of Principle Component Analysis\n(PCA) method. Our proposed system (DNose v0.2) uses the principle of electronic\nnose or enose. Enose is a detector instrument that work based on classification\nof the smell, like function of human nose. It has to be trained first for\nrecognizing the smell before work in classification process. The aim of this\nresearch is to build an enose system for quality control instrument, especially\non aromatic rice. The advantage of this system is easy to operate and not\ndamaging the object of research. In this experiment, ATMega 328 and 6 gas\nsensors are involved in the electronic module and PCA method is used for\nclassification process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:58:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kartikadarma", "Etika", ""], ["Wijayanti", "Sari", ""], ["Wulandari", "Sari Ayu", ""], ["Rafrastara", "Fauzi Adi", ""]]}, {"id": "2009.06504", "submitter": "Longxiang Liu", "authors": "Longxiang Liu, Zhuosheng Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for\n  Multi-turn Dialogue", "comments": "accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-turn dialogue is composed of multiple utterances from two or more\ndifferent speaker roles. Thus utterance- and speaker-aware clues are supposed\nto be well captured in models. However, in the existing retrieval-based\nmulti-turn dialogue modeling, the pre-trained language models (PrLMs) as\nencoder represent the dialogues coarsely by taking the pairwise dialogue\nhistory and candidate response as a whole, the hierarchical information on\neither utterance interrelation or speaker roles coupled in such representations\nis not well addressed. In this work, we propose a novel model to fill such a\ngap by modeling the effective utterance-aware and speaker-aware representations\nentailed in a dialogue history. In detail, we decouple the contextualized word\nrepresentations by masking mechanisms in Transformer-based PrLM, making each\nword only focus on the words in current utterance, other utterances, two\nspeaker roles (i.e., utterances of sender and utterances of receiver),\nrespectively. Experimental results show that our method boosts the strong\nELECTRA baseline substantially in four public benchmark datasets, and achieves\nvarious new state-of-the-art performance over previous methods. A series of\nablation studies are conducted to demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:07:19 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 19:01:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Longxiang", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.06516", "submitter": "Debabrota Basu", "authors": "Bishwamittra Ghosh, Debabrota Basu, Kuldeep S. Meel", "title": "Justicia: A Stochastic SAT Approach to Formally Verify Fairness", "comments": "24 pages, 7 figures, 5 theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a technology ML is oblivious to societal good or bad, and thus, the field\nof fair machine learning has stepped up to propose multiple mathematical\ndefinitions, algorithms, and systems to ensure different notions of fairness in\nML applications. Given the multitude of propositions, it has become imperative\nto formally verify the fairness metrics satisfied by different algorithms on\ndifferent datasets. In this paper, we propose a \\textit{stochastic\nsatisfiability} (SSAT) framework, Justicia, that formally verifies different\nfairness measures of supervised learning algorithms with respect to the\nunderlying data distribution. We instantiate Justicia on multiple\nclassification and bias mitigation algorithms, and datasets to verify different\nfairness metrics, such as disparate impact, statistical parity, and equalized\nodds. Justicia is scalable, accurate, and operates on non-Boolean and compound\nsensitive attributes unlike existing distribution-based verifiers, such as\nFairSquare and VeriFair. Being distribution-based by design, Justicia is more\nrobust than the verifiers, such as AIF360, that operate on specific test\nsamples. We also theoretically bound the finite-sample error of the verified\nfairness measure.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:23:51 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Basu", "Debabrota", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2009.06520", "submitter": "Kevin Moran P", "authors": "Cody Watson, Nathan Cooper, David Nader Palacio, Kevin Moran and Denys\n  Poshyvanyk", "title": "A Systematic Literature Review on the Use of Deep Learning in Software\n  Engineering Research", "comments": "48 pages, Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly popular set of techniques adopted by software engineering\n(SE) researchers to automate development tasks are those rooted in the concept\nof Deep Learning (DL). The popularity of such techniques largely stems from\ntheir automated feature engineering capabilities, which aid in modeling\nsoftware artifacts. However, due to the rapid pace at which DL techniques have\nbeen adopted, it is difficult to distill the current successes, failures, and\nopportunities of the current research landscape. In an effort to bring clarity\nto this cross-cutting area of work, from its modern inception to the present,\nthis paper presents a systematic literature review of research at the\nintersection of SE & DL. The review canvases work appearing in the most\nprominent SE and DL conferences and journals and spans 84 papers across 22\nunique SE tasks. We center our analysis around the components of learning, a\nset of principles that govern the application of machine learning techniques\n(ML) to a given problem domain, discussing several aspects of the surveyed work\nat a granular level. The end result of our analysis is a research roadmap that\nboth delineates the foundations of DL techniques applied to SE research, and\nlikely areas of fertile exploration for the future.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:28:28 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Watson", "Cody", ""], ["Cooper", "Nathan", ""], ["Palacio", "David Nader", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2009.06544", "submitter": "Torsten Schaub", "authors": "Felicidad Aguado, Pedro Cabalar, Martin Dieguez, Gilberto Perez,\n  Torsten Schaub, Anna Schuhmann, Concepcion Vidal", "title": "Temporal Answer Set Programming", "comments": "47 pages, 5 figures, 4 tables, lots of theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview on Temporal Logic Programming under the perspective of\nits application for Knowledge Representation and declarative problem solving.\nSuch programs are the result of combining usual rules with temporal modal\noperators, as in Linear-time Temporal Logic (LTL). We focus on recent results\nof the non-monotonic formalism called Temporal Equilibrium Logic (TEL) that is\ndefined for the full syntax of LTL, but performs a model selection criterion\nbased on Equilibrium Logic, a well known logical characterization of Answer Set\nProgramming (ASP). We obtain a proper extension of the stable models semantics\nfor the general case of arbitrary temporal formulas. We recall the basic\ndefinitions for TEL and its monotonic basis, the temporal logic of\nHere-and-There (THT), and study the differences between infinite and finite\ntraces. We also provide other useful results, such as the translation into\nother formalisms like Quantified Equilibrium Logic or Second-order LTL, and\nsome techniques for computing temporal stable models based on automata. In a\nsecond part, we focus on practical aspects, defining a syntactic fragment\ncalled temporal logic programs closer to ASP, and explain how this has been\nexploited in the construction of the solver TELINGO.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 16:13:36 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 15:57:56 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Aguado", "Felicidad", ""], ["Cabalar", "Pedro", ""], ["Dieguez", "Martin", ""], ["Perez", "Gilberto", ""], ["Schaub", "Torsten", ""], ["Schuhmann", "Anna", ""], ["Vidal", "Concepcion", ""]]}, {"id": "2009.06573", "submitter": "Runze Su", "authors": "Runze Su, Fei Tao, Xudong Liu, Haoran Wei, Xiaorong Mei, Zhiyao Duan,\n  Lei Yuan, Ji Liu, Yuying Xie", "title": "Themes Informed Audio-visual Correspondence Learning", "comments": "Submitting to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applications of short-term user-generated video (UGV), such as Snapchat,\nand Youtube short-term videos, booms recently, raising lots of multimodal\nmachine learning tasks. Among them, learning the correspondence between audio\nand visual information from videos is a challenging one. Most previous work of\nthe audio-visual correspondence(AVC) learning only investigated constrained\nvideos or simple settings, which may not fit the application of UGV. In this\npaper, we proposed new principles for AVC and introduced a new framework to set\nsight of videos' themes to facilitate AVC learning. We also released the\nKWAI-AD-AudVis corpus which contained 85432 short advertisement videos (around\n913 hours) made by users. We evaluated our proposed approach on this corpus,\nand it was able to outperform the baseline by 23.15% absolute difference.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:03:04 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 06:40:40 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Su", "Runze", ""], ["Tao", "Fei", ""], ["Liu", "Xudong", ""], ["Wei", "Haoran", ""], ["Mei", "Xiaorong", ""], ["Duan", "Zhiyao", ""], ["Yuan", "Lei", ""], ["Liu", "Ji", ""], ["Xie", "Yuying", ""]]}, {"id": "2009.06586", "submitter": "Yunhao Ge", "authors": "Yunhao Ge, Sami Abu-El-Haija, Gan Xin and Laurent Itti", "title": "Zero-shot Synthesis with Group-Supervised Learning", "comments": "Published at ICLR 2021 (16 pages including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual cognition of primates is superior to that of artificial neural\nnetworks in its ability to 'envision' a visual object, even a newly-introduced\none, in different attributes including pose, position, color, texture, etc. To\naid neural networks to envision objects with different attributes, we propose a\nfamily of objective functions, expressed on groups of examples, as a novel\nlearning framework that we term Group-Supervised Learning (GSL). GSL allows us\nto decompose inputs into a disentangled representation with swappable\ncomponents, that can be recombined to synthesize new samples. For instance,\nimages of red boats & blue cars can be decomposed and recombined to synthesize\nnovel images of red cars. We propose an implementation based on auto-encoder,\ntermed group-supervised zero-shot synthesis network (GZS-Net) trained with our\nlearning framework, that can produce a high-quality red car even if no such\nexample is witnessed during training. We test our model and learning framework\non existing benchmarks, in addition to anew dataset that we open-source. We\nqualitatively and quantitatively demonstrate that GZS-Net trained with GSL\noutperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:17:49 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 19:43:03 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 21:19:12 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ge", "Yunhao", ""], ["Abu-El-Haija", "Sami", ""], ["Xin", "Gan", ""], ["Itti", "Laurent", ""]]}, {"id": "2009.06592", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Analogy-Making as a Core Primitive in the Software Engineering Toolbox", "comments": "Conference paper at SPLASH 'Onward!' 2020. Code is available at\n  https://github.com/95616ARG/sifter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analogy is an identification of structural similarities and\ncorrespondences between two objects. Computational models of analogy making\nhave been studied extensively in the field of cognitive science to better\nunderstand high-level human cognition. For instance, Melanie Mitchell and\nDouglas Hofstadter sought to better understand high-level perception by\ndeveloping the Copycat algorithm for completing analogies between letter\nsequences. In this paper, we argue that analogy making should be seen as a core\nprimitive in software engineering. We motivate this argument by showing how\ncomplex software engineering problems such as program understanding and\nsource-code transformation learning can be reduced to an instance of the\nanalogy-making problem. We demonstrate this idea using Sifter, a new\nanalogy-making algorithm suitable for software engineering applications that\nadapts and extends ideas from Copycat. In particular, Sifter reduces\nanalogy-making to searching for a sequence of update rule applications. Sifter\nuses a novel representation for mathematical structures capable of effectively\nrepresenting the wide variety of information embedded in software. We conclude\nby listing major areas of future work for Sifter and analogy-making in software\nengineering.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:24:15 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "2009.06602", "submitter": "Tavpritesh Sethi", "authors": "Raghav Awasthi, Keerat Kaur Guliani, Saif Ahmad Khan, Aniket\n  Vashishtha, Mehrab Singh Gill, Arshita Bhatt, Aditya Nagori, Aniket Gupta,\n  Ponnurangam Kumaraguru, Tavpritesh Sethi", "title": "VacSIM: Learning Effective Strategies for COVID-19 Vaccine Distribution\n  using Reinforcement Learning", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A COVID-19 vaccine is our best bet for mitigating the ongoing onslaught of\nthe pandemic. However, vaccine is also expected to be a limited resource. An\noptimal allocation strategy, especially in countries with access inequities and\ntemporal separation of hot-spots, might be an effective way of halting the\ndisease spread. We approach this problem by proposing a novel pipeline VacSIM\nthat dovetails Sequential Decision based RL models into a Contextual Bandits\napproach for optimizing the distribution of COVID-19 vaccine. Whereas the\nReinforcement Learning models suggest better actions and rewards, Contextual\nBandits allow online modifications that may need to be implemented on a\nday-to-day basis in the real world scenario. We evaluate this framework against\na naive allocation approach of distributing vaccine proportional to the\nincidence of COVID-19 cases in five different States across India and\ndemonstrate up to 9039 additional lives potentially saved and a significant\nincrease in the efficacy of limiting the spread over a period of 45 days\nthrough the VacSIM approach. We also propose novel evaluation strategies\nincluding standard compartmental model-based projections and a causality\npreserving evaluation of our model. Finally, we contribute a new Open-AI\nenvironment meant for the vaccine distribution scenario and open-source VacSIM\nfor wide testing and applications across the\nglobe(http://vacsim.tavlab.iiitd.edu.in:8000/).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:37:13 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:21:29 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Awasthi", "Raghav", ""], ["Guliani", "Keerat Kaur", ""], ["Khan", "Saif Ahmad", ""], ["Vashishtha", "Aniket", ""], ["Gill", "Mehrab Singh", ""], ["Bhatt", "Arshita", ""], ["Nagori", "Aditya", ""], ["Gupta", "Aniket", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2009.06625", "submitter": "Meng Wang", "authors": "Xinyue Zhang, Meng Wang, Muhammad Saleem, Axel-Cyrille Ngonga Ngomo,\n  Guilin Qi, and Haofen Wang", "title": "Revealing Secrets in SPARQL Session Level", "comments": "18 pages. Accepted by ISWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on Semantic Web technologies, knowledge graphs help users to discover\ninformation of interest by using live SPARQL services. Answer-seekers often\nexamine intermediate results iteratively and modify SPARQL queries repeatedly\nin a search session. In this context, understanding user behaviors is critical\nfor effective intention prediction and query optimization. However, these\nbehaviors have not yet been researched systematically at the SPARQL session\nlevel. This paper reveals secrets of session-level user search behaviors by\nconducting a comprehensive investigation over massive real-world SPARQL query\nlogs. In particular, we thoroughly assess query changes made by users w.r.t.\nstructural and data-driven features of SPARQL queries. To illustrate the\npotentiality of our findings, we employ an application example of how to use\nour findings, which might be valuable to devise efficient SPARQL caching,\nauto-completion, query suggestion, approximation, and relaxation techniques in\nthe future.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 16:00:21 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 03:39:41 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Xinyue", ""], ["Wang", "Meng", ""], ["Saleem", "Muhammad", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Qi", "Guilin", ""], ["Wang", "Haofen", ""]]}, {"id": "2009.06629", "submitter": "Maria Athanasiou", "authors": "Maria Athanasiou, Konstantina Sfrintzeri, Konstantia Zarkogianni,\n  Anastasia C. Thanopoulou, and Konstantina S. Nikita", "title": "An explainable XGBoost-based approach towards assessing the risk of\n  cardiovascular disease in patients with Type 2 Diabetes Mellitus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular Disease (CVD) is an important cause of disability and death\namong individuals with Diabetes Mellitus (DM). International clinical\nguidelines for the management of Type 2 DM (T2DM) are founded on primary and\nsecondary prevention and favor the evaluation of CVD related risk factors\ntowards appropriate treatment initiation. CVD risk prediction models can\nprovide valuable tools for optimizing the frequency of medical visits and\nperforming timely preventive and therapeutic interventions against CVD events.\nThe integration of explainability modalities in these models can enhance human\nunderstanding on the reasoning process, maximize transparency and embellish\ntrust towards the models' adoption in clinical practice. The aim of the present\nstudy is to develop and evaluate an explainable personalized risk prediction\nmodel for the fatal or non-fatal CVD incidence in T2DM individuals. An\nexplainable approach based on the eXtreme Gradient Boosting (XGBoost) and the\nTree SHAP (SHapley Additive exPlanations) method is deployed for the\ncalculation of the 5-year CVD risk and the generation of individual\nexplanations on the model's decisions. Data from the 5-year follow up of 560\npatients with T2DM are used for development and evaluation purposes. The\nobtained results (AUC = 71.13%) indicate the potential of the proposed approach\nto handle the unbalanced nature of the used dataset, while providing clinically\nmeaningful insights about the ensemble model's decision process.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 12:19:10 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 18:03:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Athanasiou", "Maria", ""], ["Sfrintzeri", "Konstantina", ""], ["Zarkogianni", "Konstantia", ""], ["Thanopoulou", "Anastasia C.", ""], ["Nikita", "Konstantina S.", ""]]}, {"id": "2009.06675", "submitter": "David Broniatowski", "authors": "Lydia P. Gleaves, Reva Schwartz, David A. Broniatowski", "title": "The Role of Individual User Differences in Interpretable and Explainable\n  Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increased interest in assisting non-expert audiences to effectively\ninteract with machine learning (ML) tools and understand the complex output\nsuch systems produce. Here, we describe user experiments designed to study how\nindividual skills and personality traits predict interpretability,\nexplainability, and knowledge discovery from ML generated model output. Our\nwork relies on Fuzzy Trace Theory, a leading theory of how humans process\nnumerical stimuli, to examine how different end users will interpret the output\nthey receive while interacting with the ML system. While our sample was small,\nwe found that interpretability -- being able to make sense of system output --\nand explainability -- understanding how that output was generated -- were\ndistinct aspects of user experience. Additionally, subjects were more able to\ninterpret model output if they possessed individual traits that promote\nmetacognitive monitoring and editing, associated with more detailed, verbatim,\nprocessing of ML output. Finally, subjects who are more familiar with ML\nsystems felt better supported by them and more able to discover new patterns in\ndata; however, this did not necessarily translate to meaningful insights. Our\nwork motivates the design of systems that explicitly take users' mental\nrepresentations into account during the design process to more effectively\nsupport end user requirements.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 18:15:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gleaves", "Lydia P.", ""], ["Schwartz", "Reva", ""], ["Broniatowski", "David A.", ""]]}, {"id": "2009.06709", "submitter": "Jaydip Sen", "authors": "Jaydip Sen and Sidra Mehtab", "title": "Machine Learning Applications in Misuse and Anomaly Detection", "comments": "21 Pages; 4 Figures; 3 Tables", "journal-ref": "Book Chapter Published in the Volume: \"Security and Privacy From a\n  Legal, Ethical, and Technical Perspective\", Editors: Christos Kalloniatis and\n  Carlos Travieso-Gonzalez, InTechOpen Publishers, London, UK, June 2020", "doi": "10.5772/intechopen.92653", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and data mining algorithms play important roles in designing\nintrusion detection systems. Based on their approaches toward the detection of\nattacks in a network, intrusion detection systems can be broadly categorized\ninto two types. In the misuse detection systems, an attack in a system is\ndetected whenever the sequence of activities in the network matches with a\nknown attack signature. In the anomaly detection approach, on the other hand,\nanomalous states in a system are identified based on a significant difference\nin the state transitions of the system from its normal states. This chapter\npresents a comprehensive discussion on some of the existing schemes of\nintrusion detection based on misuse detection, anomaly detection and hybrid\ndetection approaches. Some future directions of research in the design of\nalgorithms for intrusion detection are also identified.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:52:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Sen", "Jaydip", ""], ["Mehtab", "Sidra", ""]]}, {"id": "2009.06732", "submitter": "Yi Tay", "authors": "Yi Tay, Mostafa Dehghani, Dara Bahri, Donald Metzler", "title": "Efficient Transformers: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer model architectures have garnered immense interest lately due to\ntheir effectiveness across a range of domains like language, vision and\nreinforcement learning. In the field of natural language processing for\nexample, Transformers have become an indispensable staple in the modern deep\nlearning stack. Recently, a dizzying number of \"X-former\" models have been\nproposed - Reformer, Linformer, Performer, Longformer, to name a few - which\nimprove upon the original Transformer architecture, many of which make\nimprovements around computational and memory efficiency. With the aim of\nhelping the avid researcher navigate this flurry, this paper characterizes a\nlarge and thoughtful selection of recent efficiency-flavored \"X-former\" models,\nproviding an organized and comprehensive overview of existing work and models\nacross multiple domains.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:38:14 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:23:37 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Tay", "Yi", ""], ["Dehghani", "Mostafa", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""]]}, {"id": "2009.06750", "submitter": "Niander Assis", "authors": "Niander Assis, Renato Assun\\c{c}\\~ao and Pedro O. S. Vaz-De-Melo", "title": "Stop the Clock: Are Timeout Effects Real?", "comments": "Accepted at ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timeout is a short interruption during games used to communicate a change in\nstrategy, to give the players a rest or to stop a negative flow in the game.\nWhatever the reason, coaches expect an improvement in their team's performance\nafter a timeout. But how effective are these timeouts in doing so? The simple\naverage of the differences between the scores before and after the timeouts has\nbeen used as evidence that there is an effect and that it is substantial. We\nclaim that these statistical averages are not proper evidence and a more sound\napproach is needed. We applied a formal causal framework using a large dataset\nof official NBA play-by-play tables and drew our assumptions about the data\ngeneration process in a causal graph. Using different matching techniques to\nestimate the causal effect of timeouts, we concluded that timeouts have no\neffect on teams' performances. Actually, since most timeouts are called when\nthe opposing team is scoring more frequently, the moments that follow resemble\nan improvement in the team's performance but are just the natural game tendency\nto return to its average state. This is another example of what statisticians\ncall the regression to the mean phenomenon.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:21:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Assis", "Niander", ""], ["Assun\u00e7\u00e3o", "Renato", ""], ["Vaz-De-Melo", "Pedro O. S.", ""]]}, {"id": "2009.06756", "submitter": "Justin Harris", "authors": "Justin D. Harris", "title": "Analysis of Models for Decentralized and Collaborative AI on Blockchain", "comments": "Accepted to ICBC 2020", "journal-ref": null, "doi": "10.1007/978-3-030-59638-5_10", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently enabled large advances in artificial\nintelligence, but these results can be highly centralized. The large datasets\nrequired are generally proprietary; predictions are often sold on a per-query\nbasis; and published models can quickly become out of date without effort to\nacquire more data and maintain them. Published proposals to provide models and\ndata for free for certain tasks include Microsoft Research's Decentralized and\nCollaborative AI on Blockchain. The framework allows participants to\ncollaboratively build a dataset and use smart contracts to share a continuously\nupdated model on a public blockchain. The initial proposal gave an overview of\nthe framework omitting many details of the models used and the incentive\nmechanisms in real world scenarios. In this work, we evaluate the use of\nseveral models and configurations in order to propose best practices when using\nthe Self-Assessment incentive mechanism so that models can remain accurate and\nwell-intended participants that submit correct data have the chance to profit.\nWe have analyzed simulations for each of three models: Perceptron, Na\\\"ive\nBayes, and a Nearest Centroid Classifier, with three different datasets:\npredicting a sport with user activity from Endomondo, sentiment analysis on\nmovie reviews from IMDB, and determining if a news article is fake. We compare\nseveral factors for each dataset when models are hosted in smart contracts on a\npublic blockchain: their accuracy over time, balances of a good and bad user,\nand transaction costs (or gas) for deploying, updating, collecting refunds, and\ncollecting rewards. A free and open source implementation for the Ethereum\nblockchain and simulations written in Python is provided at\nhttps://github.com/microsoft/0xDeCA10B. This version has updated gas costs\nusing newer optimizations written after the original publication.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 21:38:55 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 03:14:47 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Harris", "Justin D.", ""]]}, {"id": "2009.06781", "submitter": "Kushal Chawla", "authors": "Kushal Chawla, Gale Lucas", "title": "Pilot: Winner of the Human-Agent Negotiation Challenge at IJCAI 2020", "comments": "Winner at ANAC, IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes our agent Pilot, winner of the Human-Agent\nNegotiation Challenge at ANAC, IJCAI 2020. Pilot is a virtual human that\nparticipates in a sequence of three negotiations with a human partner. Our\nsystem is based on the Interactive Arbitration Guide Online (IAGO) negotiation\nframework. We leverage prior Affective Computing and Psychology research in\nnegotiations to guide various key principles that define the behavior and\npersonality of our agent.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:56:47 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 21:42:23 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chawla", "Kushal", ""], ["Lucas", "Gale", ""]]}, {"id": "2009.06797", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Eva Zhang, Yongchan Kwon, James Zou", "title": "Competing AI: How does competition feedback affect machine learning?", "comments": "Accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This papers studies how competition affects machine learning (ML) predictors.\nAs ML becomes more ubiquitous, it is often deployed by companies to compete\nover customers. For example, digital platforms like Yelp use ML to predict user\npreference and make recommendations. A service that is more often queried by\nusers, perhaps because it more accurately anticipates user preferences, is also\nmore likely to obtain additional user data (e.g. in the form of a Yelp review).\nThus, competing predictors cause feedback loops whereby a predictor's\nperformance impacts what training data it receives and biases its predictions\nover time. We introduce a flexible model of competing ML predictors that\nenables both rapid experimentation and theoretical tractability. We show with\nempirical and mathematical analysis that competition causes predictors to\nspecialize for specific sub-populations at the cost of worse performance over\nthe general population. We further analyze the impact of predictor\nspecialization on the overall prediction quality experienced by users. We show\nthat having too few or too many competing predictors in a market can hurt the\noverall prediction quality. Our theory is complemented by experiments on\nseveral real datasets using popular learning algorithms, such as neural\nnetworks and nearest neighbor methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:13:32 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:12:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 05:01:12 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 04:04:22 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Ginart", "Antonio", ""], ["Zhang", "Eva", ""], ["Kwon", "Yongchan", ""], ["Zou", "James", ""]]}, {"id": "2009.06799", "submitter": "Jacob Buckman", "authors": "Jacob Buckman, Carles Gelada, Marc G. Bellemare", "title": "The Importance of Pessimism in Fixed-Dataset Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study worst-case guarantees on the expected return of fixed-dataset policy\noptimization algorithms. Our core contribution is a unified conceptual and\nmathematical framework for the study of algorithms in this regime. This\nanalysis reveals that for naive approaches, the possibility of erroneous value\noverestimation leads to a difficult-to-satisfy requirement: in order to\nguarantee that we select a policy which is near-optimal, we may need the\ndataset to be informative of the value of every policy. To avoid this,\nalgorithms can follow the pessimism principle, which states that we should\nchoose the policy which acts optimally in the worst possible world. We show why\npessimistic algorithms can achieve good performance even when the dataset is\nnot informative of every policy, and derive families of algorithms which follow\nthis principle. These theoretical findings are validated by experiments on a\ntabular gridworld, and deep learning experiments on four MinAtar environments.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:18:34 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:51:31 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 05:58:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Buckman", "Jacob", ""], ["Gelada", "Carles", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "2009.06807", "submitter": "Alex Newhouse", "authors": "Kris McGuffie, Alex Newhouse", "title": "The Radicalization Risks of GPT-3 and Advanced Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 00:55:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["McGuffie", "Kris", ""], ["Newhouse", "Alex", ""]]}, {"id": "2009.06837", "submitter": "EPTCS", "authors": "Bruno Gavranovi\\'c", "title": "Learning Functors using Gradient Descent", "comments": "In Proceedings ACT 2019, arXiv:2009.06334. This paper is a condensed\n  version of the master thesis of the author (arXiv:1907.08292)", "journal-ref": "EPTCS 323, 2020, pp. 230-245", "doi": "10.4204/EPTCS.323.15", "report-no": null, "categories": "cs.LG cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are a general framework for differentiable optimization which\nincludes many other machine learning approaches as special cases. In this paper\nwe build a category-theoretic formalism around a neural network system called\nCycleGAN. CycleGAN is a general approach to unpaired image-to-image translation\nthat has been getting attention in the recent years. Inspired by categorical\ndatabase systems, we show that CycleGAN is a \"schema\", i.e. a specific category\npresented by generators and relations, whose specific parameter instantiations\nare just set-valued functors on this schema. We show that enforcing\ncycle-consistencies amounts to enforcing composition invariants in this\ncategory. We generalize the learning procedure to arbitrary such categories and\nshow a special class of functors, rather than functions, can be learned using\ngradient descent. Using this framework we design a novel neural network system\ncapable of learning to insert and delete objects from images without paired\ndata. We qualitatively evaluate the system on the CelebA dataset and obtain\npromising results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:17:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gavranovi\u0107", "Bruno", ""]]}, {"id": "2009.06847", "submitter": "Guansong Pang", "authors": "Guansong Pang, Anton van den Hengel, Chunhua Shen, Longbing Cao", "title": "Toward Deep Supervised Anomaly Detection: Reinforcement Learning from\n  Partially Labeled Anomaly Data", "comments": "Accepted to KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467417", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of anomaly detection with a small set of partially\nlabeled anomaly examples and a large-scale unlabeled dataset. This is a common\nscenario in many important applications. Existing related methods either\nexclusively fit the limited anomaly examples that typically do not span the\nentire set of anomalies, or proceed with unsupervised learning from the\nunlabeled data. We propose here instead a deep reinforcement learning-based\napproach that enables an end-to-end optimization of the detection of both\nlabeled and unlabeled anomalies. This approach learns the known abnormality by\nautomatically interacting with an anomaly-biased simulation environment, while\ncontinuously extending the learned abnormality to novel classes of anomaly\n(i.e., unknown anomalies) by actively exploring possible anomalies in the\nunlabeled data. This is achieved by jointly optimizing the exploitation of the\nsmall labeled anomaly data and the exploration of the rare unlabeled anomalies.\nExtensive experiments on 48 real-world datasets show that our model\nsignificantly outperforms five state-of-the-art competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:05:39 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:40:11 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Pang", "Guansong", ""], ["Hengel", "Anton van den", ""], ["Shen", "Chunhua", ""], ["Cao", "Longbing", ""]]}, {"id": "2009.06876", "submitter": "Ross Maciejewski", "authors": "Yuxin Ma, Arlen Fan, Jingrui He, Arun Reddy Nelakurthi, Ross\n  Maciejewski", "title": "A Visual Analytics Framework for Explaining and Diagnosing Transfer\n  Learning Processes", "comments": "Accepted to IEEE Transactions on Visualization and Computer Graphics\n  (Proc. IEEE VAST 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical learning models hold an assumption that the training data\nand the future unlabeled data are drawn from the same distribution. However,\nthis assumption is difficult to fulfill in real-world scenarios and creates\nbarriers in reusing existing labels from similar application domains. Transfer\nLearning is intended to relax this assumption by modeling relationships between\ndomains, and is often applied in deep learning applications to reduce the\ndemand for labeled data and training time. Despite recent advances in exploring\ndeep learning models with visual analytics tools, little work has explored the\nissue of explaining and diagnosing the knowledge transfer process between deep\nlearning models. In this paper, we present a visual analytics framework for the\nmulti-level exploration of the transfer learning processes when training deep\nneural networks. Our framework establishes a multi-aspect design to explain how\nthe learned knowledge from the existing model is transferred into the new\nlearning task when training deep neural networks. Based on a comprehensive\nrequirement and task analysis, we employ descriptive visualization with\nperformance measures and detailed inspections of model behaviors from the\nstatistical, instance, feature, and model structure levels. We demonstrate our\nframework through two case studies on image classification by fine-tuning\nAlexNets to illustrate how analysts can utilize our framework.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 05:59:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Ma", "Yuxin", ""], ["Fan", "Arlen", ""], ["He", "Jingrui", ""], ["Nelakurthi", "Arun Reddy", ""], ["Maciejewski", "Ross", ""]]}, {"id": "2009.06921", "submitter": "Emir Demirovi\\'c", "authors": "Emir Demirovi\\'c, Peter J. Stuckey", "title": "Optimal Decision Trees for Nonlinear Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear metrics, such as the F1-score, Matthews correlation coefficient,\nand Fowlkes-Mallows index, are often used to evaluate the performance of\nmachine learning models, in particular, when facing imbalanced datasets that\ncontain more samples of one class than the other. Recent optimal decision tree\nalgorithms have shown remarkable progress in producing trees that are optimal\nwith respect to linear criteria, such as accuracy, but unfortunately nonlinear\nmetrics remain a challenge. To address this gap, we propose a novel algorithm\nbased on bi-objective optimisation, which treats misclassifications of each\nbinary class as a separate objective. We show that, for a large class of\nmetrics, the optimal tree lies on the Pareto frontier. Consequently, we obtain\nthe optimal tree by using our method to generate the set of all nondominated\ntrees. To the best of our knowledge, this is the first method to compute\nprovably optimal decision trees for nonlinear metrics. Our approach leads to a\ntrade-off when compared to optimising linear metrics: the resulting trees may\nbe more desirable according to the given nonlinear metric at the expense of\nhigher runtimes. Nevertheless, the experiments illustrate that runtimes are\nreasonable for majority of the tested datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:30:56 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Demirovi\u0107", "Emir", ""], ["Stuckey", "Peter J.", ""]]}, {"id": "2009.06962", "submitter": "Jang-Hyun Kim", "authors": "Jang-Hyun Kim, Wonho Choo, Hyun Oh Song", "title": "Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup", "comments": "Published at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks achieve great performance on fitting the training\ndistribution, the learned networks are prone to overfitting and are susceptible\nto adversarial attacks. In this regard, a number of mixup based augmentation\nmethods have been recently proposed. However, these approaches mainly focus on\ncreating previously unseen virtual examples and can sometimes provide\nmisleading supervisory signal to the network. To this end, we propose Puzzle\nMix, a mixup method for explicitly utilizing the saliency information and the\nunderlying statistics of the natural examples. This leads to an interesting\noptimization problem alternating between the multi-label objective for optimal\nmixing mask and saliency discounted optimal transport objective. Our\nexperiments show Puzzle Mix achieves the state of the art generalization and\nthe adversarial robustness results compared to other mixup methods on\nCIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available\nat https://github.com/snu-mllab/PuzzleMix.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:10:23 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 10:45:39 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kim", "Jang-Hyun", ""], ["Choo", "Wonho", ""], ["Song", "Hyun Oh", ""]]}, {"id": "2009.06963", "submitter": "Dario Zanca", "authors": "Dario Zanca, Marco Gori, Stefano Melacci, Alessandra Rufa", "title": "Gravitational Models Explain Shifts on Human Visual Attention", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-73494-2", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual attention refers to the human brain's ability to select relevant\nsensory information for preferential processing, improving performance in\nvisual and cognitive tasks. It proceeds in two phases. One in which visual\nfeature maps are acquired and processed in parallel. Another where the\ninformation from these maps is merged in order to select a single location to\nbe attended for further and more complex computations and reasoning. Its\ncomputational description is challenging, especially if the temporal dynamics\nof the process are taken into account. Numerous methods to estimate saliency\nhave been proposed in the last three decades. They achieve almost perfect\nperformance in estimating saliency at the pixel level, but the way they\ngenerate shifts in visual attention fully depends on winner-take-all (WTA)\ncircuitry. WTA is implemented} by the biological hardware in order to select a\nlocation with maximum saliency, towards which to direct overt attention. In\nthis paper we propose a gravitational model (GRAV) to describe the attentional\nshifts. Every single feature acts as an attractor and {the shifts are the\nresult of the joint effects of the attractors. In the current framework, the\nassumption of a single, centralized saliency map is no longer necessary, though\nstill plausible. Quantitative results on two large image datasets show that\nthis model predicts shifts more accurately than winner-take-all.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:12:41 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Zanca", "Dario", ""], ["Gori", "Marco", ""], ["Melacci", "Stefano", ""], ["Rufa", "Alessandra", ""]]}, {"id": "2009.06981", "submitter": "Martin Plajner", "authors": "Martin Plajner and Ji\\v{r}\\'i Vomlel", "title": "Monotonicity in practice of adaptive testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous work we have shown how Bayesian networks can be used for\nadaptive testing of student skills. Later, we have taken the advantage of\nmonotonicity restrictions in order to learn models fitting data better. This\narticle provides a synergy between these two phases as it evaluates Bayesian\nnetwork models used for computerized adaptive testing and learned with a\nrecently proposed monotonicity gradient algorithm. This learning method is\ncompared with another monotone method, the isotonic regression EM algorithm.\nThe quality of methods is empirically evaluated on a large data set of the\nCzech National Mathematics Exam. Besides advantages of adaptive testing\napproach we observed also advantageous behavior of monotonic methods,\nespecially for small learning data set sizes. Another novelty of this work is\nthe use of the reliability interval of the score distribution, which is used to\npredict student's final score and grade. In the experiments we have clearly\nshown we can shorten the test while keeping its reliability. We have also shown\nthat the monotonicity increases the prediction quality with limited training\ndata sets. The monotone model learned by the gradient method has a lower\nquestion prediction quality than unrestricted models but it is better in the\nmain target of this application, which is the student score prediction. It is\nan important observation that a mere optimization of the model likelihood or\nthe prediction accuracy do not necessarily lead to a model that describes best\nthe student.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:55:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Plajner", "Martin", ""], ["Vomlel", "Ji\u0159\u00ed", ""]]}, {"id": "2009.06996", "submitter": "Yufei Wang", "authors": "Haoliang Li (1), Yufei Wang (1), Xiaofei Xie (1), Yang Liu (1), Shiqi\n  Wang (2), Renjie Wan (1), Lap-Pui Chau (1), and Alex C. Kot (1) ((1) Nanyang\n  Technological University, Singapore, (2) City University of Hong Kong)", "title": "Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition\n  Systems", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have shown great success in many computer vision\napplications. However, they are also known to be susceptible to backdoor\nattacks. When conducting backdoor attacks, most of the existing approaches\nassume that the targeted DNN is always available, and an attacker can always\ninject a specific pattern to the training data to further fine-tune the DNN\nmodel. However, in practice, such attack may not be feasible as the DNN model\nis encrypted and only available to the secure enclave.\n  In this paper, we propose a novel black-box backdoor attack technique on face\nrecognition systems, which can be conducted without the knowledge of the\ntargeted DNN model. To be specific, we propose a backdoor attack with a novel\ncolor stripe pattern trigger, which can be generated by modulating LED in a\nspecialized waveform. We also use an evolutionary computing strategy to\noptimize the waveform for backdoor attack. Our backdoor attack can be conducted\nin a very mild condition: 1) the adversary cannot manipulate the input in an\nunnatural way (e.g., injecting adversarial noise); 2) the adversary cannot\naccess the training database; 3) the adversary has no knowledge of the training\nmodel as well as the training set used by the victim party.\n  We show that the backdoor trigger can be quite effective, where the attack\nsuccess rate can be up to $88\\%$ based on our simulation study and up to $40\\%$\nbased on our physical-domain study by considering the task of face recognition\nand verification based on at most three-time attempts during authentication.\nFinally, we evaluate several state-of-the-art potential defenses towards\nbackdoor attacks, and find that our attack can still be effective. We highlight\nthat our study revealed a new physical backdoor attack, which calls for the\nattention of the security issue of the existing face recognition/verification\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 11:50:29 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Li", "Haoliang", ""], ["Wang", "Yufei", ""], ["Xie", "Xiaofei", ""], ["Liu", "Yang", ""], ["Wang", "Shiqi", ""], ["Wan", "Renjie", ""], ["Chau", "Lap-Pui", ""], ["Kot", "Alex C.", ""]]}, {"id": "2009.07058", "submitter": "Louis Clouatre", "authors": "Louis Clouatre, Philippe Trempe, Amal Zouaq, Sarath Chandar", "title": "MLMLM: Link Prediction with Mean Likelihood Masked Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Bases (KBs) are easy to query, verifiable, and interpretable. They\nhowever scale with man-hours and high-quality data. Masked Language Models\n(MLMs), such as BERT, scale with computing power as well as unstructured raw\ntext data. The knowledge contained within those models is however not directly\ninterpretable. We propose to perform link prediction with MLMs to address both\nthe KBs scalability issues and the MLMs interpretability issues. To do that we\nintroduce MLMLM, Mean Likelihood Masked Language Model, an approach comparing\nthe mean likelihood of generating the different entities to perform link\nprediction in a tractable manner. We obtain State of the Art (SotA) results on\nthe WN18RR dataset and the best non-entity-embedding based results on the\nFB15k-237 dataset. We also obtain convincing results on link prediction on\npreviously unseen entities, making MLMLM a suitable approach to introducing new\nentities to a KB.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:11:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Clouatre", "Louis", ""], ["Trempe", "Philippe", ""], ["Zouaq", "Amal", ""], ["Chandar", "Sarath", ""]]}, {"id": "2009.07118", "submitter": "Timo Schick", "authors": "Timo Schick, Hinrich Sch\\\"utze", "title": "It's Not Just Size That Matters: Small Language Models Are Also Few-Shot\n  Learners", "comments": "Accepted at NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When scaled to hundreds of billions of parameters, pretrained language models\nsuch as GPT-3 (Brown et al., 2020) achieve remarkable few-shot performance.\nHowever, enormous amounts of compute are required for training and applying\nsuch big models, resulting in a large carbon footprint and making it difficult\nfor researchers and practitioners to use them. We show that performance similar\nto GPT-3 can be obtained with language models that are much \"greener\" in that\ntheir parameter count is several orders of magnitude smaller. This is achieved\nby converting textual inputs into cloze questions that contain a task\ndescription, combined with gradient-based optimization; exploiting unlabeled\ndata gives further improvements. We identify key factors required for\nsuccessful natural language understanding with small language models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:18:53 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:16:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2009.07132", "submitter": "Nicola Milano", "authors": "Nicola Milano, Stefano Nolfi", "title": "Autonomous Learning of Features for Control: Experiments with Embodied\n  and Situated Agents", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0250040", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As discussed in previous studies, the efficacy of evolutionary or\nreinforcement learning algorithms for continuous control optimization can be\nenhanced by including a neural module dedicated to feature extraction trained\nthrough self-supervised methods. In this paper we report additional experiments\nsupporting this hypothesis and we demonstrate how the advantage provided by\nfeature extraction is not limited to problems that benefit from dimensionality\nreduction or that involve agents operating on the basis of allocentric\nperception. We introduce a method that permits to continue the training of the\nfeature-extraction module during the training of the policy network and that\nincreases the efficacy of feature extraction. Finally, we compare alternative\nfeature-extracting methods and we show that sequence-to-sequence learning\nyields better results than the methods considered in previous studies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:34:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Milano", "Nicola", ""], ["Nolfi", "Stefano", ""]]}, {"id": "2009.07185", "submitter": "Gregor Betz", "authors": "Gregor Betz and Christian Voigt and Kyle Richardson", "title": "Critical Thinking for Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes a first step towards a critical thinking curriculum for\nneural auto-regressive language models. We introduce a synthetic corpus of\ndeductively valid arguments, and generate artificial argumentative texts to\ntrain and evaluate GPT-2. Significant transfer learning effects can be\nobserved: Training a model on three simple core schemes allows it to accurately\ncomplete conclusions of different, and more complex types of arguments, too.\nThe language models generalize the core argument schemes in a correct way.\nMoreover, we obtain consistent and promising results for NLU benchmarks. In\nparticular, pre-training on the argument schemes raises zero-shot accuracy on\nthe GLUE diagnostics by up to 15 percentage points. The findings suggest that\nintermediary pre-training on texts that exemplify basic reasoning abilities\n(such as typically covered in critical thinking textbooks) might help language\nmodels to acquire a broad range of reasoning skills. The synthetic\nargumentative texts presented in this paper are a promising starting point for\nbuilding such a \"critical thinking curriculum for language models.\"\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:49:19 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:42:42 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Betz", "Gregor", ""], ["Voigt", "Christian", ""], ["Richardson", "Kyle", ""]]}, {"id": "2009.07238", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov and Lior Rokach", "title": "Lessons Learned from Applying off-the-shelf BERT: There is no Silver\n  Bullet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in the NLP field is training large classification\nmodels, a task that is both difficult and tedious. It is even harder when GPU\nhardware is unavailable. The increased availability of pre-trained and\noff-the-shelf word embeddings, models, and modules aim at easing the process of\ntraining large models and achieving a competitive performance. We explore the\nuse of off-the-shelf BERT models and share the results of our experiments and\ncompare their results to those of LSTM networks and more simple baselines. We\nshow that the complexity and computational cost of BERT is not a guarantee for\nenhanced predictive performance in the classification tasks at hand.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:24:52 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 12:58:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Makarenkov", "Victor", ""], ["Rokach", "Lior", ""]]}, {"id": "2009.07243", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Tianxing He, Kyunghyun Cho, James Glass", "title": "A Systematic Characterization of Sampling Algorithms for Open-ended\n  Language Generation", "comments": "To appear at AACL 2020; 9 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the widely adopted ancestral sampling algorithms for\nauto-regressive language models, which is not widely studied in the literature.\nWe use the quality-diversity (Q-D) trade-off to investigate three popular\nsampling algorithms (top-k, nucleus and tempered sampling). We focus on the\ntask of open-ended language generation. We first show that the existing\nsampling algorithms have similar performance. After carefully inspecting the\ntransformations defined by different sampling algorithms, we identify three key\nproperties that are shared among them: entropy reduction, order preservation,\nand slope preservation. To validate the importance of the identified\nproperties, we design two sets of new sampling algorithms: one set in which\neach algorithm satisfies all three properties, and one set in which each\nalgorithm violates at least one of the properties. We compare their performance\nwith existing sampling algorithms, and find that violating the identified\nproperties could lead to drastic performance degradation, as measured by the\nQ-D trade-off. On the other hand, we find that the set of sampling algorithms\nthat satisfies these properties performs on par with the existing sampling\nalgorithms. Our data and code are available at\nhttps://github.com/moinnadeem/characterizing-sampling-algorithms\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:28:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nadeem", "Moin", ""], ["He", "Tianxing", ""], ["Cho", "Kyunghyun", ""], ["Glass", "James", ""]]}, {"id": "2009.07262", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), Victoria Heath\n  (1) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3) Algora Lab)", "title": "Report prepared by the Montreal AI Ethics Institute (MAIEI) on\n  Publication Norms for Responsible AI", "comments": "Report submitted to Partnership on AI for inclusion in their work on\n  Publishing Norms for Responsible AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The history of science and technology shows that seemingly innocuous\ndevelopments in scientific theories and research have enabled real-world\napplications with significant negative consequences for humanity. In order to\nensure that the science and technology of AI is developed in a humane manner,\nwe must develop research publication norms that are informed by our growing\nunderstanding of AI's potential threats and use cases. Unfortunately, it's\ndifficult to create a set of publication norms for responsible AI because the\nfield of AI is currently fragmented in terms of how this technology is\nresearched, developed, funded, etc. To examine this challenge and find\nsolutions, the Montreal AI Ethics Institute (MAIEI) co-hosted two public\nconsultations with the Partnership on AI in May 2020. These meetups examined\npotential publication norms for responsible AI, with the goal of creating a\nclear set of recommendations and ways forward for publishers.\n  In its submission, MAIEI provides six initial recommendations, these include:\n1) create tools to navigate publication decisions, 2) offer a page number\nextension, 3) develop a network of peers, 4) require broad impact statements,\n5) require the publication of expected results, and 6) revamp the peer-review\nprocess. After considering potential concerns regarding these recommendations,\nincluding constraining innovation and creating a \"black market\" for AI\nresearch, MAIEI outlines three ways forward for publishers, these include: 1)\nstate clearly and consistently the need for established norms, 2) coordinate\nand build trust as a community, and 3) change the approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:51:40 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 07:50:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Heath", "Victoria", "", "Montreal AI Ethics Institute"]]}, {"id": "2009.07360", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie, Bert Huang", "title": "Constrained Labeling for Weakly Supervised Learning", "comments": "Accepted at UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Curation of large fully supervised datasets has become one of the major\nroadblocks for machine learning. Weak supervision provides an alternative to\nsupervised learning by training with cheap, noisy, and possibly correlated\nlabeling functions from varying sources. The key challenge in weakly supervised\nlearning is combining the different weak supervision signals while navigating\nmisleading correlations in their errors. In this paper, we propose a simple\ndata-free approach for combining weak supervision signals by defining a\nconstrained space for the possible labels of the weak signals and training with\na random labeling within this constrained space. Our method is efficient and\nstable, converging after a few iterations of gradient descent. We prove\ntheoretical conditions under which the worst-case error of the randomized label\ndecreases with the rank of the linear constraints. We show experimentally that\nour method outperforms other weak supervision methods on various text- and\nimage-classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:30:53 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:32:49 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 02:48:45 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 17:35:46 GMT"}, {"version": "v5", "created": "Sat, 29 May 2021 19:51:20 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "2009.07362", "submitter": "Mayssa Kahla", "authors": "Mayssa Ben Kahla and Dalel Kanzari and Ahmed Maalel", "title": "General DeepLCP model for disease prediction : Case of Lung Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to GHO (Global Health Observatory (GHO), the high prevalence of a\nlarge variety of diseases such as Ischaemic heart disease, stroke, lung cancer\ndisease and lower respiratory infections have remained the top killers during\nthe past decade.\n  The growth in the number of mortalities caused by these disease is due to the\nvery delayed symptoms'detection. Since in the early stages, the symptoms are\ninsignificant and similar to those of benign diseases (e.g. the flu ), and we\ncan only detect the disease at an advanced stage.\n  In addition, The high frequency of improper practices that are harmful to\nhealth, the hereditary factors, and the stressful living conditions can\nincrease the death rates.\n  Many researches dealt with these fatal disease, and most of them applied\nadvantage machine learning models to deal with image diagnosis. However the\ndrawback is that imagery permit only to detect disease at a very delayed stage\nand then patient can hardly be saved.\n  In this Paper we present our new approach \"DeepLCP\" to predict fatal diseases\nthat threaten people's lives. It's mainly based on raw and heterogeneous data\nof the concerned (or under-tested) person. \"DeepLCP\" results of a combination\ncombination of the Natural Language Processing (NLP) and the deep learning\nparadigm.The experimental results of the proposed model in the case of Lung\ncancer prediction have approved high accuracy and a low loss data rate during\nthe validation of the disease prediction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:43:48 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Kahla", "Mayssa Ben", ""], ["Kanzari", "Dalel", ""], ["Maalel", "Ahmed", ""]]}, {"id": "2009.07363", "submitter": "Rashied Amini", "authors": "Rashied Amini, Abigail Azari, Shyam Bhaskaran, Patricia Beauchamp,\n  Julie Castillo-Rogez, Rebecca Castano, Seung Chung, John Day, Richard Doyle,\n  Martin Feather, Lorraine Fesq, Jeremy Frank, P. Michael Furlong, Michel\n  Ingham, Brian Kennedy, Ksenia Kolcio, Issa Nesnas, Robert Rasmussen, Glenn\n  Reeves, Cristina Sorice, Bethany Theiling, Jay Wyatt", "title": "Advancing the Scientific Frontier with Increasingly Autonomous Systems", "comments": "10 pages (compared to 8 submitted to PSADS), 2 figures, submitted to\n  National Academy of Sciences Planetary Science and Astrobiology Decadal\n  Survey 2023-2032", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A close partnership between people and partially autonomous machines has\nenabled decades of space exploration. But to further expand our horizons, our\nsystems must become more capable. Increasing the nature and degree of autonomy\n- allowing our systems to make and act on their own decisions as directed by\nmission teams - enables new science capabilities and enhances science return.\nThe 2011 Planetary Science Decadal Survey (PSDS) and on-going pre-Decadal\nmission studies have identified increased autonomy as a core technology\nrequired for future missions. However, even as scientific discovery has\nnecessitated the development of autonomous systems and past flight\ndemonstrations have been successful, institutional barriers have limited its\nmaturation and infusion on existing planetary missions. Consequently, the\nauthors and endorsers of this paper recommend that new programmatic pathways be\ndeveloped to infuse autonomy, infrastructure for support autonomous systems be\ninvested in, new practices be adopted, and the cost-saving value of autonomy\nfor operations be studied.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:49:03 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Amini", "Rashied", ""], ["Azari", "Abigail", ""], ["Bhaskaran", "Shyam", ""], ["Beauchamp", "Patricia", ""], ["Castillo-Rogez", "Julie", ""], ["Castano", "Rebecca", ""], ["Chung", "Seung", ""], ["Day", "John", ""], ["Doyle", "Richard", ""], ["Feather", "Martin", ""], ["Fesq", "Lorraine", ""], ["Frank", "Jeremy", ""], ["Furlong", "P. Michael", ""], ["Ingham", "Michel", ""], ["Kennedy", "Brian", ""], ["Kolcio", "Ksenia", ""], ["Nesnas", "Issa", ""], ["Rasmussen", "Robert", ""], ["Reeves", "Glenn", ""], ["Sorice", "Cristina", ""], ["Theiling", "Bethany", ""], ["Wyatt", "Jay", ""]]}, {"id": "2009.07368", "submitter": "William Whitney", "authors": "William F. Whitney, Min Jae Song, David Brandfonbrener, Jaan Altosaar,\n  Kyunghyun Cho", "title": "Evaluating representations by the complexity of learning low-loss\n  predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of evaluating representations of data for use in\nsolving a downstream task. We propose to measure the quality of a\nrepresentation by the complexity of learning a predictor on top of the\nrepresentation that achieves low loss on a task of interest, and introduce two\nmethods, surplus description length (SDL) and $\\varepsilon$ sample complexity\n($\\varepsilon$SC). In contrast to prior methods, which measure the amount of\ninformation about the optimal predictor that is present in a specific amount of\ndata, our methods measure the amount of information needed from the data to\nrecover an approximation of the optimal predictor up to a specified tolerance.\nWe present a framework to compare these methods based on plotting the\nvalidation loss versus evaluation dataset size (the \"loss-data\" curve).\nExisting measures, such as mutual information and minimum description length\nprobes, correspond to slices and integrals along the data axis of the loss-data\ncurve, while ours correspond to slices and integrals along the loss axis. We\nprovide experiments on real data to compare the behavior of each of these\nmethods over datasets of varying size along with a high performance open source\nlibrary for representation evaluation at\nhttps://github.com/willwhitney/reprieve.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:06:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:50:13 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Whitney", "William F.", ""], ["Song", "Min Jae", ""], ["Brandfonbrener", "David", ""], ["Altosaar", "Jaan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.07373", "submitter": "Rujun Han", "authors": "Rujun Han, Yichao Zhou, Nanyun Peng", "title": "Domain Knowledge Empowered Structured Neural Net for End-to-End Event\n  Temporal Relation Extraction", "comments": "Appear in EMNLP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting event temporal relations is a critical task for information\nextraction and plays an important role in natural language understanding. Prior\nsystems leverage deep learning and pre-trained language models to improve the\nperformance of the task. However, these systems often suffer from two\nshort-comings: 1) when performing maximum a posteriori (MAP) inference based on\nneural models, previous systems only used structured knowledge that are assumed\nto be absolutely correct, i.e., hard constraints; 2) biased predictions on\ndominant temporal relations when training with a limited amount of data. To\naddress these issues, we propose a framework that enhances deep neural network\nwith distributional constraints constructed by probabilistic domain knowledge.\nWe solve the constrained inference problem via Lagrangian Relaxation and apply\nit on end-to-end event temporal relation extraction tasks. Experimental results\nshow our framework is able to improve the baseline neural network models with\nstrong statistical significance on two widely used datasets in news and\nclinical domains.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:20:27 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:58:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Han", "Rujun", ""], ["Zhou", "Yichao", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.07387", "submitter": "Christophe Combastel", "authors": "Christophe Combastel", "title": "Functional sets with typed symbols: Framework and mixed Polynotopes for\n  hybrid nonlinear reachability and filtering", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification and synthesis of Cyber-Physical Systems (CPS) are challenging\nand still raise numerous issues so far. In this paper, an original framework\nwith mixed sets defined as function images of symbol type domains is first\nproposed. Syntax and semantics are explicitly distinguished. Then, both\ncontinuous (interval) and discrete (signed, boolean) symbol types are used to\nmodel dependencies through linear and polynomial functions, so leading to mixed\nzonotopic and polynotopic sets. Polynotopes extend sparse polynomial zonotopes\nwith typed symbols. Polynotopes can both propagate a mixed encoding of\nintervals and describe the behavior of logic gates. A functional completeness\nresult is given, as well as an inclusion method for elementary nonlinear and\nswitching functions. A Polynotopic Kalman Filter (PKF) is then proposed as a\nhybrid nonlinear extension of Zonotopic Kalman Filters (ZKF). Bridges with a\nstochastic uncertainty paradigm are outlined. Finally, several discrete,\ncontinuous and hybrid numerical examples including comparisons illustrate the\neffectiveness of the theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 23:18:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Combastel", "Christophe", ""]]}, {"id": "2009.07396", "submitter": "Victor Zhong", "authors": "Victor Zhong, Mike Lewis, Sida I. Wang, Luke Zettlemoyer", "title": "Grounded Adaptation for Zero-shot Executable Semantic Parsing", "comments": "EMNLP 2020 long paper. 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing\n(GAZP) to adapt an existing semantic parser to new environments (e.g. new\ndatabase schemas). GAZP combines a forward semantic parser with a backward\nutterance generator to synthesize data (e.g. utterances and SQL queries) in the\nnew environment, then selects cycle-consistent examples to adapt the parser.\nUnlike data-augmentation, which typically synthesizes unverified examples in\nthe training environment, GAZP synthesizes examples in the new environment\nwhose input-output consistency are verified. On the Spider, Sparc, and CoSQL\nzero-shot semantic parsing tasks, GAZP improves logical form and execution\naccuracy of the baseline parser. Our analyses show that GAZP outperforms\ndata-augmentation in the training environment, performance increases with the\namount of GAZP-synthesized data, and cycle-consistency is central to successful\nadaptation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:16:59 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 00:37:15 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 20:44:05 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Lewis", "Mike", ""], ["Wang", "Sida I.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2009.07405", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Juan Carlos Nieves, and Cesar Augusto Tacla", "title": "An Imprecise Probability Approach for Abstract Argumentation based on\n  Credal Sets", "comments": "8 pages, 2 figures, Accepted in The 15th European Conference on\n  Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU\n  2019)", "journal-ref": null, "doi": "10.1007/978-3-030-29765-7_4", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Some abstract argumentation approaches consider that arguments have a degree\nof uncertainty, which impacts on the degree of uncertainty of the extensions\nobtained from a abstract argumentation framework (AAF) under a semantics. In\nthese approaches, both the uncertainty of the arguments and of the extensions\nare modeled by means of precise probability values. However, in many real life\nsituations the exact probabilities values are unknown and sometimes there is a\nneed for aggregating the probability values of different sources. In this\npaper, we tackle the problem of calculating the degree of uncertainty of the\nextensions considering that the probability values of the arguments are\nimprecise. We use credal sets to model the uncertainty values of arguments and\nfrom these credal sets, we calculate the lower and upper bounds of the\nextensions. We study some properties of the suggested approach and illustrate\nit with an scenario of decision making.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:52:18 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Nieves", "Juan Carlos", ""], ["Tacla", "Cesar Augusto", ""]]}, {"id": "2009.07406", "submitter": "Martin Kuo", "authors": "Martin Kuo, Yaobo Liang, Lei Ji, Nan Duan, Linjun Shou, Ming Gong,\n  Peng Chen", "title": "Tag and Correct: Question aware Open Information Extraction with\n  Two-stage Decoding", "comments": "11 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Aware Open Information Extraction (Question aware Open IE) takes\nquestion and passage as inputs, outputting an answer tuple which contains a\nsubject, a predicate, and one or more arguments. Each field of answer is a\nnatural language word sequence and is extracted from the passage. The\nsemi-structured answer has two advantages which are more readable and\nfalsifiable compared to span answer. There are two approaches to solve this\nproblem. One is an extractive method which extracts candidate answers from the\npassage with the Open IE model, and ranks them by matching with questions. It\nfully uses the passage information at the extraction step, but the extraction\nis independent to the question. The other one is the generative method which\nuses a sequence to sequence model to generate answers directly. It combines the\nquestion and passage as input at the same time, but it generates the answer\nfrom scratch, which does not use the facts that most of the answer words come\nfrom in the passage. To guide the generation by passage, we present a two-stage\ndecoding model which contains a tagging decoder and a correction decoder. At\nthe first stage, the tagging decoder will tag keywords from the passage. At the\nsecond stage, the correction decoder will generate answers based on tagged\nkeywords. Our model could be trained end-to-end although it has two stages.\nCompared to previous generative models, we generate better answers by\ngenerating coarse to fine. We evaluate our model on WebAssertions (Yan et al.,\n2018) which is a Question aware Open IE dataset. Our model achieves a BLEU\nscore of 59.32, which is better than previous generative methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:58:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Kuo", "Martin", ""], ["Liang", "Yaobo", ""], ["Ji", "Lei", ""], ["Duan", "Nan", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Chen", "Peng", ""]]}, {"id": "2009.07429", "submitter": "Denghui Zhang", "authors": "Denghui Zhang, Junming Liu, Hengshu Zhu, Yanchi Liu, Lichen Wang,\n  Pengyang Wang, Hui Xiong", "title": "Job2Vec: Job Title Benchmarking with Collective Multi-View\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job Title Benchmarking (JTB) aims at matching job titles with similar\nexpertise levels across various companies. JTB could provide precise guidance\nand considerable convenience for both talent recruitment and job seekers for\nposition and salary calibration/prediction. Traditional JTB approaches mainly\nrely on manual market surveys, which is expensive and labor-intensive.\nRecently, the rapid development of Online Professional Graph has accumulated a\nlarge number of talent career records, which provides a promising trend for\ndata-driven solutions. However, it is still a challenging task since (1) the\njob title and job transition (job-hopping) data is messy which contains a lot\nof subjective and non-standard naming conventions for the same position (e.g.,\nProgrammer, Software Development Engineer, SDE, Implementation Engineer), (2)\nthere is a large amount of missing title/transition information, and (3) one\ntalent only seeks limited numbers of jobs which brings the incompleteness and\nrandomness modeling job transition patterns. To overcome these challenges, we\naggregate all the records to construct a large-scale Job Title Benchmarking\nGraph (Job-Graph), where nodes denote job titles affiliated with specific\ncompanies and links denote the correlations between jobs. We reformulate the\nJTB as the task of link prediction over the Job-Graph that matched job titles\nshould have links. Along this line, we propose a collective multi-view\nrepresentation learning method (Job2Vec) by examining the Job-Graph jointly in\n(1) graph topology view, (2)semantic view, (3) job transition balance view, and\n(4) job transition duration view. We fuse the multi-view representations in the\nencode-decode paradigm to obtain a unified optimal representation for the task\nof link prediction. Finally, we conduct extensive experiments to validate the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 02:33:32 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Denghui", ""], ["Liu", "Junming", ""], ["Zhu", "Hengshu", ""], ["Liu", "Yanchi", ""], ["Wang", "Lichen", ""], ["Wang", "Pengyang", ""], ["Xiong", "Hui", ""]]}, {"id": "2009.07445", "submitter": "Dung Nguyen", "authors": "Dung Nguyen, Svetha Venkatesh, Phuoc Nguyen, Truyen Tran", "title": "Theory of Mind with Guilt Aversion Facilitates Cooperative Reinforcement\n  Learning", "comments": "Accepted for publication at ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guilt aversion induces experience of a utility loss in people if they believe\nthey have disappointed others, and this promotes cooperative behaviour in\nhuman. In psychological game theory, guilt aversion necessitates modelling of\nagents that have theory about what other agents think, also known as Theory of\nMind (ToM). We aim to build a new kind of affective reinforcement learning\nagents, called Theory of Mind Agents with Guilt Aversion (ToMAGA), which are\nequipped with an ability to think about the wellbeing of others instead of just\nself-interest. To validate the agent design, we use a general-sum game known as\nStag Hunt as a test bed. As standard reinforcement learning agents could learn\nsuboptimal policies in social dilemmas like Stag Hunt, we propose to use\nbelief-based guilt aversion as a reward shaping mechanism. We show that our\nbelief-based guilt averse agents can efficiently learn cooperative behaviours\nin Stag Hunt Games.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:15:46 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Nguyen", "Dung", ""], ["Venkatesh", "Svetha", ""], ["Nguyen", "Phuoc", ""], ["Tran", "Truyen", ""]]}, {"id": "2009.07448", "submitter": "Xingyi Cheng", "authors": "Kunlong Chen, Weidi Xu, Xingyi Cheng, Zou Xiaochuan, Yuyu Zhang, Le\n  Song, Taifeng Wang, Yuan Qi, Wei Chu", "title": "Question Directed Graph Attention Network for Numerical Reasoning over\n  Text", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical reasoning over texts, such as addition, subtraction, sorting and\ncounting, is a challenging machine reading comprehension task, since it\nrequires both natural language understanding and arithmetic computation. To\naddress this challenge, we propose a heterogeneous graph representation for the\ncontext of the passage and question needed for such reasoning, and design a\nquestion directed graph attention network to drive multi-step numerical\nreasoning over this context graph.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:37:54 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chen", "Kunlong", ""], ["Xu", "Weidi", ""], ["Cheng", "Xingyi", ""], ["Xiaochuan", "Zou", ""], ["Zhang", "Yuyu", ""], ["Song", "Le", ""], ["Wang", "Taifeng", ""], ["Qi", "Yuan", ""], ["Chu", "Wei", ""]]}, {"id": "2009.07470", "submitter": "Sathyanarayanan Aakur", "authors": "Sathyanarayanan N. Aakur, Sanjoy Kundu, Nikhil Gunti", "title": "Knowledge Guided Learning: Towards Open Domain Egocentric Action\n  Recognition with Zero Supervision", "comments": "8 pages, 2 figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning have enabled the development of models that have\nexhibited a remarkable tendency to recognize and even localize actions in\nvideos. However, they tend to experience errors when faced with scenes or\nexamples beyond their initial training environment. Hence, they fail to adapt\nto new domains without significant retraining with large amounts of annotated\ndata. Current algorithms are trained in an inductive learning environment where\nthey use data-driven models to learn associations between input observations\nwith a fixed set of known classes. In this paper, we propose to overcome these\nlimitations by moving to an open world setting by decoupling the ideas of\nrecognition and reasoning. Building upon the compositional representation\noffered by Grenander's Pattern Theory formalism, we show that attention and\ncommonsense knowledge can be used to enable the self-supervised discovery of\nnovel actions in egocentric videos in an open-world setting, a considerably\nmore difficult task than zero-shot learning and (un)supervised domain\nadaptation tasks where target domain data (both labeled and unlabeled) are\navailable during training. We show that our approach can be used to infer and\nlearn novel classes for open vocabulary classification in egocentric videos and\nnovel object detection with zero supervision. Extensive experiments show that\nit performs competitively with fully supervised baselines on publicly available\ndatasets under open-world conditions. This is one of the first works to address\nthe problem of open-world action recognition in egocentric videos with zero\nhuman supervision to the best of our knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 04:44:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Aakur", "Sathyanarayanan N.", ""], ["Kundu", "Sanjoy", ""], ["Gunti", "Nikhil", ""]]}, {"id": "2009.07473", "submitter": "Mayank Raj", "authors": "Mayank Raj, Ajay Jaiswal, Rohit R.R, Ankita Gupta, Sudeep Kumar Sahoo,\n  Vertika Srivastava, Yeon Hyang Kim", "title": "Solomon at SemEval-2020 Task 11: Ensemble Architecture for Fine-Tuned\n  Propaganda Detection in News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system (Solomon) details and results of\nparticipation in the SemEval 2020 Task 11 \"Detection of Propaganda Techniques\nin News Articles\"\\cite{DaSanMartinoSemeval20task11}. We participated in Task\n\"Technique Classification\" (TC) which is a multi-class classification task. To\naddress the TC task, we used RoBERTa based transformer architecture for\nfine-tuning on the propaganda dataset. The predictions of RoBERTa were further\nfine-tuned by class-dependent-minority-class classifiers. A special classifier,\nwhich employs dynamically adapted Least Common Sub-sequence algorithm, is used\nto adapt to the intricacies of repetition class. Compared to the other\nparticipating systems, our submission is ranked 4th on the leaderboard.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:00:40 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Raj", "Mayank", ""], ["Jaiswal", "Ajay", ""], ["R", "Rohit R.", ""], ["Gupta", "Ankita", ""], ["Sahoo", "Sudeep Kumar", ""], ["Srivastava", "Vertika", ""], ["Kim", "Yeon Hyang", ""]]}, {"id": "2009.07476", "submitter": "Ryo Yonetani", "authors": "Ryo Yonetani and Tatsunori Taniai and Mohammadamin Barekatain and Mai\n  Nishimura and Asako Kanezaki", "title": "Path Planning using Neural A* Search", "comments": "To appear in the International Conference on Machine Learning (ICML\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural A*, a novel data-driven search method for path planning\nproblems. Despite the recent increasing attention to data-driven path planning,\nmachine learning approaches to search-based planning are still challenging due\nto the discrete nature of search algorithms. In this work, we reformulate a\ncanonical A* search algorithm to be differentiable and couple it with a\nconvolutional encoder to form an end-to-end trainable neural network planner.\nNeural A* solves a path planning problem by encoding a problem instance to a\nguidance map and then performing the differentiable A* search with the guidance\nmap. By learning to match the search results with ground-truth paths provided\nby experts, Neural A* can produce a path consistent with the ground truth\naccurately and efficiently. Our extensive experiments confirmed that Neural A*\noutperformed state-of-the-art data-driven planners in terms of the search\noptimality and efficiency trade-off. Furthermore, Neural A* successfully\npredicted realistic human trajectories by directly performing search-based\nplanning on natural image inputs. Project page:\nhttps://omron-sinicx.github.io/neural-astar/\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:22:44 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 03:38:06 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 13:27:47 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yonetani", "Ryo", ""], ["Taniai", "Tatsunori", ""], ["Barekatain", "Mohammadamin", ""], ["Nishimura", "Mai", ""], ["Kanezaki", "Asako", ""]]}, {"id": "2009.07497", "submitter": "Paolo Liberatore", "authors": "Paolo Liberatore", "title": "One head is better than two: a polynomial restriction for propositional\n  definite Horn forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical forgetting is NP-complete even in the simple case of propositional\nHorn formulae, and may exponentially increase their size. A way to forget is to\nreplace each variable to forget with the body of each clause whose head is the\nvariable. It takes polynomial time in the single-head case: each variable is at\nmost the head of a clause. Some formulae are not single-head but can be made so\nto simplify forgetting. They are single-head equivalent. The first contribution\nof this article is the study of a semantical characterization of single-head\nequivalence. Two necessary conditions are given. They are sufficient when the\nformula is inequivalent: it makes two sets of variables equivalent only if they\nare also equivalent to their intersection. All acyclic formulae are\ninequivalent. The second contribution of this article is an incomplete\nalgorithm for turning a formula single-head. In case of success, forgetting\nbecomes possible in polynomial time and produces a polynomial-size formula,\nnone of which is otherwise guaranteed. The algorithm is complete on\ninequivalent formulae.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:49:08 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 08:59:42 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Liberatore", "Paolo", ""]]}, {"id": "2009.07503", "submitter": "Ranran Haoran Zhang", "authors": "Ranran Haoran Zhang, Qianying Liu, Aysa Xuemo Fan, Heng Ji, Daojian\n  Zeng, Fei Cheng, Daisuke Kawahara and Sadao Kurohashi", "title": "Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation\n  Extraction", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint entity and relation extraction aims to extract relation triplets from\nplain text directly. Prior work leverages Sequence-to-Sequence (Seq2Seq) models\nfor triplet sequence generation. However, Seq2Seq enforces an unnecessary order\non the unordered triplets and involves a large decoding length associated with\nerror accumulation. These introduce exposure bias, which may cause the models\noverfit to the frequent label combination, thus deteriorating the\ngeneralization. We propose a novel Sequence-to-Unordered-Multi-Tree\n(Seq2UMTree) model to minimize the effects of exposure bias by limiting the\ndecoding length to three within a triplet and removing the order among\ntriplets. We evaluate our model on two datasets, DuIE and NYT, and\nsystematically study how exposure bias alters the performance of Seq2Seq\nmodels. Experiments show that the state-of-the-art Seq2Seq model overfits to\nboth datasets while Seq2UMTree shows significantly better generalization. Our\ncode is available at https://github.com/WindChimeRan/OpenJERE .\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:53:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 08:56:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhang", "Ranran Haoran", ""], ["Liu", "Qianying", ""], ["Fan", "Aysa Xuemo", ""], ["Ji", "Heng", ""], ["Zeng", "Daojian", ""], ["Cheng", "Fei", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "2009.07518", "submitter": "Alexandre Letard", "authors": "Alexandre Letard, Tassadit Amghar, Olivier Camp, Nicolas Gutowski", "title": "Partial Bandit and Semi-Bandit: Making the Most Out of Scarce Users'\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on Multi-Armed Bandits (MAB) and Combinatorial Multi-Armed\nBandits (COM-MAB) show good results on a global accuracy metric. This can be\nachieved, in the case of recommender systems, with personalization. However,\nwith a combinatorial online learning approach, personalization implies a large\namount of user feedbacks. Such feedbacks can be hard to acquire when users need\nto be directly and frequently solicited. For a number of fields of activities\nundergoing the digitization of their business, online learning is unavoidable.\nThus, a number of approaches allowing implicit user feedback retrieval have\nbeen implemented. Nevertheless, this implicit feedback can be misleading or\ninefficient for the agent's learning. Herein, we propose a novel approach\nreducing the number of explicit feedbacks required by Combinatorial Multi Armed\nbandit (COM-MAB) algorithms while providing similar levels of global accuracy\nand learning efficiency to classical competitive methods. In this paper we\npresent a novel approach for considering user feedback and evaluate it using\nthree distinct strategies. Despite a limited number of feedbacks returned by\nusers (as low as 20% of the total), our approach obtains similar results to\nthose of state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:32:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Letard", "Alexandre", ""], ["Amghar", "Tassadit", ""], ["Camp", "Olivier", ""], ["Gutowski", "Nicolas", ""]]}, {"id": "2009.07543", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao,\n  Weipeng Yan, Xiaofang Zhao", "title": "Group-wise Contrastive Learning for Neural Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialogue response generation has gained much popularity in recent\nyears. Maximum Likelihood Estimation (MLE) objective is widely adopted in\nexisting dialogue model learning. However, models trained with MLE objective\nfunction are plagued by the low-diversity issue when it comes to the\nopen-domain conversational setting. Inspired by the observation that humans not\nonly learn from the positive signals but also benefit from correcting behaviors\nof undesirable actions, in this work, we introduce contrastive learning into\ndialogue generation, where the model explicitly perceives the difference\nbetween the well-chosen positive and negative utterances. Specifically, we\nemploy a pretrained baseline model as a reference. During contrastive learning,\nthe target dialogue model is trained to give higher conditional probabilities\nfor the positive samples, and lower conditional probabilities for those\nnegative samples, compared to the reference model. To manage the multi-mapping\nrelations prevailed in human conversation, we augment contrastive dialogue\nlearning with group-wise dual sampling. Extensive experimental results show\nthat the proposed group-wise contrastive learning framework is suited for\ntraining a wide range of neural dialogue generation models with very favorable\nperformance over the baseline training approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:28:30 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 04:12:07 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Song", "Yonghao", ""], ["Ding", "Zhuoye", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""], ["Zhao", "Xiaofang", ""]]}, {"id": "2009.07563", "submitter": "Mina Ghaffari", "authors": "Mina Ghaffari, Arcot Sowmya, and Ruth Oliver", "title": "Brain tumour segmentation using cascaded 3D densely-connected U-net", "comments": "10 pages paper submitted to BraTS20 workshop (MICCAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate brain tumour segmentation is a crucial step towards improving\ndisease diagnosis and proper treatment planning. In this paper, we propose a\ndeep-learning based method to segment a brain tumour into its subregions: whole\ntumour, tumour core and enhancing tumour. The proposed architecture is a 3D\nconvolutional neural network based on a variant of the U-Net architecture of\nRonneberger et al. [17] with three main modifications: (i) a heavy encoder,\nlight decoder structure using residual blocks (ii) employment of dense blocks\ninstead of skip connections, and (iii) utilization of self-ensembling in the\ndecoder part of the network. The network was trained and tested using two\ndifferent approaches: a multitask framework to segment all tumour subregions at\nthe same time and a three-stage cascaded framework to segment one sub-region at\na time. An ensemble of the results from both frameworks was also computed. To\naddress the class imbalance issue, appropriate patch extraction was employed in\na pre-processing step. The connected component analysis was utilized in the\npost-processing step to reduce false positive predictions. Experimental results\non the BraTS20 validation dataset demonstrates that the proposed model achieved\naverage Dice Scores of 0.90, 0.82, and 0.78 for whole tumour, tumour core and\nenhancing tumour respectively.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 09:14:59 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ghaffari", "Mina", ""], ["Sowmya", "Arcot", ""], ["Oliver", "Ruth", ""]]}, {"id": "2009.07583", "submitter": "Fan Zhang Dr", "authors": "Fan Zhang, Di Ma, Chen Feng and David R. Bull", "title": "Video Compression with CNN-based Post Processing", "comments": null, "journal-ref": null, "doi": "10.1109/MMUL.2021.3052437", "report-no": null, "categories": "eess.IV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, video compression techniques have been significantly\nchallenged by the rapidly increased demands associated with high quality and\nimmersive video content. Among various compression tools, post-processing can\nbe applied on reconstructed video content to mitigate visible compression\nartefacts and to enhance overall perceptual quality. Inspired by advances in\ndeep learning, we propose a new CNN-based post-processing approach, which has\nbeen integrated with two state-of-the-art coding standards, VVC and AV1. The\nresults show consistent coding gains on all tested sequences at various spatial\nresolutions, with average bit rate savings of 4.0% and 5.8% against original\nVVC and AV1 respectively (based on the assessment of PSNR). This network has\nalso been trained with perceptually inspired loss functions, which have further\nimproved reconstruction quality based on perceptual quality assessment (VMAF),\nwith average coding gains of 13.9% over VVC and 10.5% against AV1.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 10:07:32 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 20:23:24 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Zhang", "Fan", ""], ["Ma", "Di", ""], ["Feng", "Chen", ""], ["Bull", "David R.", ""]]}, {"id": "2009.07604", "submitter": "Bianjiang Yang", "authors": "Bianjiang Yang, Zi Hui, Haoji Hu, Xinyi Hu, Lu Yu", "title": "Compressing Facial Makeup Transfer Networks by Collaborative\n  Distillation and Kernel Decomposition", "comments": "This paper will be published on 2020 IEEE International Conference on\n  Visual Communications and Image Processing (VCIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the facial makeup transfer network has achieved high-quality\nperformance in generating perceptually pleasing makeup images, its capability\nis still restricted by the massive computation and storage of the network\narchitecture. We address this issue by compressing facial makeup transfer\nnetworks with collaborative distillation and kernel decomposition. The main\nidea of collaborative distillation is underpinned by a finding that the\nencoder-decoder pairs construct an exclusive collaborative relationship, which\nis regarded as a new kind of knowledge for low-level vision tasks. For kernel\ndecomposition, we apply the depth-wise separation of convolutional kernels to\nbuild a light-weighted Convolutional Neural Network (CNN) from the original\nnetwork. Extensive experiments show the effectiveness of the compression method\nwhen applied to the state-of-the-art facial makeup transfer network --\nBeautyGAN.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:07:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Yang", "Bianjiang", ""], ["Hui", "Zi", ""], ["Hu", "Haoji", ""], ["Hu", "Xinyi", ""], ["Yu", "Lu", ""]]}, {"id": "2009.07659", "submitter": "Heiko Paulheim", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings", "comments": "Accepted at International Semantic Web Conference (ISWC) 2020,\n  Posters and Demonstrations Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph embedding approaches represent nodes and edges of graphs as\nmathematical vectors. Current approaches focus on embedding complete knowledge\ngraphs, i.e. all nodes and edges. This leads to very high computational\nrequirements on large graphs such as DBpedia or Wikidata. However, for most\ndownstream application scenarios, only a small subset of concepts is of actual\ninterest. In this paper, we present RDF2Vec Light, a lightweight embedding\napproach based on RDF2Vec which generates vectors for only a subset of\nentities. To that end, RDF2Vec Light only traverses and processes a subgraph of\nthe knowledge graph. Our method allows the application of embeddings of very\nlarge knowledge graphs in scenarios where such embeddings were not possible\nbefore due to a significantly lower runtime and significantly reduced hardware\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:58:31 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:53:12 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2009.07664", "submitter": "Abdelhak Lemkhenter", "authors": "Abdelhak Lemkhenter and Paolo Favaro", "title": "Boosting Generalization in Bio-Signal Classification by Learning the\n  Phase-Amplitude Coupling", "comments": "Accepted at GCPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various hand-crafted features representations of bio-signals rely primarily\non the amplitude or power of the signal in specific frequency bands. The phase\ncomponent is often discarded as it is more sample specific, and thus more\nsensitive to noise, than the amplitude. However, in general, the phase\ncomponent also carries information relevant to the underlying biological\nprocesses. In fact, in this paper we show the benefits of learning the coupling\nof both phase and amplitude components of a bio-signal. We do so by introducing\na novel self-supervised learning task, which we call Phase-Swap, that detects\nif bio-signals have been obtained by merging the amplitude and phase from\ndifferent sources. We show in our evaluation that neural networks trained on\nthis task generalize better across subjects and recording sessions than their\nfully supervised counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:07:00 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:07:05 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Lemkhenter", "Abdelhak", ""], ["Favaro", "Paolo", ""]]}, {"id": "2009.07698", "submitter": "Reuben Tan", "authors": "Reuben Tan, Bryan A. Plummer, Kate Saenko", "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:13:15 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:17:19 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 21:37:02 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 21:10:15 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 15:16:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tan", "Reuben", ""], ["Plummer", "Bryan A.", ""], ["Saenko", "Kate", ""]]}, {"id": "2009.07707", "submitter": "Zhi Wang", "authors": "Zhi Wang, Chaoge Liu, Xiang Cui, Di Wu, Jie Yin, Jiaxi Liu, Jialong\n  Zhang", "title": "DeepC2: AI-powered Covert Botnet Command and Control on OSNs", "comments": "13 pages, 15 figures, 7 tables. Discussion on possible\n  countermeasures updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are one of the major threats to computer security. In previous botnet\ncommand and control (C&C) scenarios using online social networks (OSNs),\nmethods for addressing (e.g., IDs, links, or DGAs) are hardcoded into bots.\nOnce a bot is reverse engineered, the botmaster and C&C infrastructure will be\nexposed. Additionally, abnormal content from explicit commands may expose\nbotmasters and raise anomalies on OSNs. To overcome these deficiencies, we\nproposed DeepC2, an AI-powered covert C&C method on OSNs. By leveraging neural\nnetworks, bots can find botmasters by avatars, which are converted into feature\nvectors and embedded into bots. Adversaries cannot infer botmasters' accounts\nfrom the vectors. Commands are embedded into normal contents (e.g., tweets and\ncomments) using text data augmentation and hash collision. Experiments on\nTwitter show that command-embedded contents can be generated efficiently, and\nbots can find botmasters and obtain commands accurately. Security analysis on\ndifferent scenarios show that DeepC2 is robust and hard to be shut down. By\ndemonstrating how AI may help promote covert communication on OSNs, this work\nprovides a new perspective on botnet detection and confrontation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:31:49 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 09:11:18 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 12:07:41 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 08:20:16 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Zhi", ""], ["Liu", "Chaoge", ""], ["Cui", "Xiang", ""], ["Wu", "Di", ""], ["Yin", "Jie", ""], ["Liu", "Jiaxi", ""], ["Zhang", "Jialong", ""]]}, {"id": "2009.07726", "submitter": "Nandana Mihindukulasooriya", "authors": "Nandana Mihindukulasooriya, Gaetano Rossiello, Pavan Kapanipathi,\n  Ibrahim Abdelaziz, Srinivas Ravishankar, Mo Yu, Alfio Gliozzo, Salim Roukos\n  and Alexander Gray", "title": "Leveraging Semantic Parsing for Relation Linking over Knowledge Bases", "comments": "Accepted at the 19th International Semantic Web Conference (ISWC\n  2020)", "journal-ref": null, "doi": "10.1007/978-3-030-62419-4_23", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledgebase question answering systems are heavily dependent on relation\nextraction and linking modules. However, the task of extracting and linking\nrelations from text to knowledgebases faces two primary challenges; the\nambiguity of natural language and lack of training data. To overcome these\nchallenges, we present SLING, a relation linking framework which leverages\nsemantic parsing using Abstract Meaning Representation (AMR) and distant\nsupervision. SLING integrates multiple relation linking approaches that capture\ncomplementary signals such as linguistic cues, rich semantic representation,\nand information from the knowledgebase. The experiments on relation linking\nusing three KBQA datasets; QALD-7, QALD-9, and LC-QuAD 1.0 demonstrate that the\nproposed approach achieves state-of-the-art performance on all benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:56:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mihindukulasooriya", "Nandana", ""], ["Rossiello", "Gaetano", ""], ["Kapanipathi", "Pavan", ""], ["Abdelaziz", "Ibrahim", ""], ["Ravishankar", "Srinivas", ""], ["Yu", "Mo", ""], ["Gliozzo", "Alfio", ""], ["Roukos", "Salim", ""], ["Gray", "Alexander", ""]]}, {"id": "2009.07734", "submitter": "Ruisi Zhang", "authors": "Ruisi Zhang and Luntian Mou and Pengtao Xie", "title": "TreeGAN: Incorporating Class Hierarchy into Image Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional image generation (CIG) is a widely studied problem in computer\nvision and machine learning. Given a class, CIG takes the name of this class as\ninput and generates a set of images that belong to this class. In existing CIG\nworks, for different classes, their corresponding images are generated\nindependently, without considering the relationship among classes. In\nreal-world applications, the classes are organized into a hierarchy and their\nhierarchical relationships are informative for generating high-fidelity images.\nIn this paper, we aim to leverage the class hierarchy for conditional image\ngeneration. We propose two ways of incorporating class hierarchy: prior control\nand post constraint. In prior control, we first encode the class hierarchy,\nthen feed it as a prior into the conditional generator to generate images. In\npost constraint, after the images are generated, we measure their consistency\nwith the class hierarchy and use the consistency score to guide the training of\nthe generator. Based on these two ideas, we propose a TreeGAN model which\nconsists of three modules: (1) a class hierarchy encoder (CHE) which takes the\nhierarchical structure of classes and their textual names as inputs and learns\nan embedding for each class; the embedding captures the hierarchical\nrelationship among classes; (2) a conditional image generator (CIG) which takes\nthe CHE-generated embedding of a class as input and generates a set of images\nbelonging to this class; (3) a consistency checker which performs hierarchical\nclassification on the generated images and checks whether the generated images\nare compatible with the class hierarchy; the consistency score is used to guide\nthe CIG to generate hierarchy-compatible images. Experiments on various\ndatasets demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:06:52 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Ruisi", ""], ["Mou", "Luntian", ""], ["Xie", "Pengtao", ""]]}, {"id": "2009.07756", "submitter": "Stephen Makonin", "authors": "Richard Jones, Christoph Klemenjak, Stephen Makonin, Ivan V. Bajic", "title": "Exploring Bayesian Surprise to Prevent Overfitting and to Predict Model\n  Performance in Non-Intrusive Load Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Intrusive Load Monitoring (NILM) is a field of research focused on\nsegregating constituent electrical loads in a system based only on their\naggregated signal. Significant computational resources and research time are\nspent training models, often using as much data as possible, perhaps driven by\nthe preconception that more data equates to more accurate models and better\nperforming algorithms. When has enough prior training been done? When has a\nNILM algorithm encountered new, unseen data? This work applies the notion of\nBayesian surprise to answer these questions which are important for both\nsupervised and unsupervised algorithms. We quantify the degree of surprise\nbetween the predictive distribution (termed postdictive surprise), as well as\nthe transitional probabilities (termed transitional surprise), before and after\na window of observations. We compare the performance of several benchmark NILM\nalgorithms supported by NILMTK, in order to establish a useful threshold on the\ntwo combined measures of surprise. We validate the use of transitional surprise\nby exploring the performance of a popular Hidden Markov Model as a function of\nsurprise threshold. Finally, we explore the use of a surprise threshold as a\nregularization technique to avoid overfitting in cross-dataset performance.\nAlthough the generality of the specific surprise threshold discussed herein may\nbe suspect without further testing, this work provides clear evidence that a\npoint of diminishing returns of model performance with respect to dataset size\nexists. This has implications for future model development, dataset\nacquisition, as well as aiding in model flexibility during deployment.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:39:08 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Jones", "Richard", ""], ["Klemenjak", "Christoph", ""], ["Makonin", "Stephen", ""], ["Bajic", "Ivan V.", ""]]}, {"id": "2009.07758", "submitter": "Aditya Kalyanpur", "authors": "Nasrin Mostafazadeh, Aditya Kalyanpur, Lori Moon, David Buchanan,\n  Lauren Berkowitz, Or Biran, Jennifer Chu-Carroll", "title": "GLUCOSE: GeneraLized and COntextualized Story Explanations", "comments": "EMNLP 2020 Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans read or listen, they make implicit commonsense inferences that\nframe their understanding of what happened and why. As a step toward AI systems\nthat can build similar mental models, we introduce GLUCOSE, a large-scale\ndataset of implicit commonsense causal knowledge, encoded as causal\nmini-theories about the world, each grounded in a narrative context. To\nconstruct GLUCOSE, we drew on cognitive psychology to identify ten dimensions\nof causal explanation, focusing on events, states, motivations, and emotions.\nEach GLUCOSE entry includes a story-specific causal statement paired with an\ninference rule generalized from the statement. This paper details two concrete\ncontributions. First, we present our platform for effectively crowdsourcing\nGLUCOSE data at scale, which uses semi-structured templates to elicit causal\nexplanations. Using this platform, we collected a total of ~670K specific\nstatements and general rules that capture implicit commonsense knowledge about\neveryday situations. Second, we show that existing knowledge resources and\npretrained language models do not include or readily predict GLUCOSE's rich\ninferential content. However, when state-of-the-art neural models are trained\non this knowledge, they can start to make commonsense inferences on unseen\nstories that match humans' mental models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:41:21 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:10:39 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Mostafazadeh", "Nasrin", ""], ["Kalyanpur", "Aditya", ""], ["Moon", "Lori", ""], ["Buchanan", "David", ""], ["Berkowitz", "Lauren", ""], ["Biran", "Or", ""], ["Chu-Carroll", "Jennifer", ""]]}, {"id": "2009.07778", "submitter": "Maxime Langevin", "authors": "Maxime Langevin, Herve Minoux, Maximilien Levesque, Marc Bianciotto", "title": "Scaffold-constrained molecular generation", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.0c01015", "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major applications of generative models for drug Discovery targets\nthe lead-optimization phase. During the optimization of a lead series, it is\ncommon to have scaffold constraints imposed on the structure of the molecules\ndesigned. Without enforcing such constraints, the probability of generating\nmolecules with the required scaffold is extremely low and hinders the\npracticality of generative models for de-novo drug design. To tackle this\nissue, we introduce a new algorithm to perform scaffold-constrained in-silico\nmolecular design. We build on the well-known SMILES-based Recurrent Neural\nNetwork (RNN) generative model, with a modified sampling procedure to achieve\nscaffold-constrained generation. We directly benefit from the associated\nreinforcement Learning methods, allowing to design molecules optimized for\ndifferent properties while exploring only the relevant chemical space. We\nshowcase the method's ability to perform scaffold-constrained generation on\nvarious tasks: designing novel molecules around scaffolds extracted from\nSureChEMBL chemical series, generating novel active molecules on the Dopamine\nReceptor D2 (DRD2) target, and, finally, designing predicted actives on the\nMMP-12 series, an industrial lead-optimization project.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:41:18 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:30:28 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 10:50:26 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Langevin", "Maxime", ""], ["Minoux", "Herve", ""], ["Levesque", "Maximilien", ""], ["Bianciotto", "Marc", ""]]}, {"id": "2009.07810", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoDEx, a set of knowledge graph completion datasets extracted from\nWikidata and Wikipedia that improve upon existing knowledge graph completion\nbenchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises\nthree knowledge graphs varying in size and structure, multilingual descriptions\nof entities and relations, and tens of thousands of hard negative triples that\nare plausible but verified to be false. To characterize CoDEx, we contribute\nthorough empirical analyses and benchmarking experiments. First, we analyze\neach CoDEx dataset in terms of logical relation patterns. Next, we report\nbaseline link prediction and triple classification results on CoDEx for five\nextensively tuned embedding models. Finally, we differentiate CoDEx from the\npopular FB15K-237 knowledge graph completion dataset by showing that CoDEx\ncovers more diverse and interpretable content, and is a more difficult link\nprediction benchmark. Data, code, and pretrained models are available at\nhttps://bit.ly/2EPbrJs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:08:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:10:10 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.07816", "submitter": "Li Su", "authors": "Yuen-Jen Lin, Hsuan-Kai Kao, Yih-Chih Tseng, Ming Tsai, Li Su", "title": "A Human-Computer Duet System for Music Performance", "comments": null, "journal-ref": null, "doi": "10.1145/3394171.3413921", "report-no": null, "categories": "cs.MM cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Virtual musicians have become a remarkable phenomenon in the contemporary\nmultimedia arts. However, most of the virtual musicians nowadays have not been\nendowed with abilities to create their own behaviors, or to perform music with\nhuman musicians. In this paper, we firstly create a virtual violinist, who can\ncollaborate with a human pianist to perform chamber music automatically without\nany intervention. The system incorporates the techniques from various fields,\nincluding real-time music tracking, pose estimation, and body movement\ngeneration. In our system, the virtual musician's behavior is generated based\non the given music audio alone, and such a system results in a low-cost,\nefficient and scalable way to produce human and virtual musicians'\nco-performance. The proposed system has been validated in public concerts.\nObjective quality assessment approaches and possible ways to systematically\nimprove the system are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:19:23 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lin", "Yuen-Jen", ""], ["Kao", "Hsuan-Kai", ""], ["Tseng", "Yih-Chih", ""], ["Tsai", "Ming", ""], ["Su", "Li", ""]]}, {"id": "2009.07888", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, and Jiayu Zhou", "title": "Transfer Learning in Deep Reinforcement Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is a key technique to address sequential\ndecision-making problems and is crucial to realize advanced artificial\nintelligence. Recent years have witnessed remarkable progress in RL by virtue\nof the fast development of deep neural networks. Along with the promising\nprospects of RL in numerous domains, such as robotics and game-playing,\ntransfer learning has arisen as an important technique to tackle various\nchallenges faced by RL, by transferring knowledge from external expertise to\naccelerate the learning process. In this survey, we systematically investigate\nthe recent progress of transfer learning approaches in the context of deep\nreinforcement learning. Specifically, we provide a framework for categorizing\nthe state-of-the-art transfer learning approaches, under which we analyze their\ngoals, methodologies, compatible RL backbones, and practical applications. We\nalso draw connections between transfer learning and other relevant topics from\nthe RL perspective and explore their potential challenges as well as open\nquestions that await future research progress.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:38:54 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 02:22:54 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 23:28:31 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 16:46:02 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2009.07889", "submitter": "Barak Sober", "authors": "Wei Pu, Barak Sober, Nathan Daly, Zahra Sabetsarvestani, Catherine\n  Higgitt, Ingrid Daubechies, and Miguel R.D. Rodrigues", "title": "Image Separation with Side Information: A Connected Auto-Encoders Based\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  X-radiography (X-ray imaging) is a widely used imaging technique in art\ninvestigation. It can provide information about the condition of a painting as\nwell as insights into an artist's techniques and working methods, often\nrevealing hidden information invisible to the naked eye. In this paper, we deal\nwith the problem of separating mixed X-ray images originating from the\nradiography of double-sided paintings. Using the visible color images (RGB\nimages) from each side of the painting, we propose a new Neural Network\narchitecture, based upon 'connected' auto-encoders, designed to separate the\nmixed X-ray image into two simulated X-ray images corresponding to each side.\nIn this proposed architecture, the convolutional auto encoders extract features\nfrom the RGB images. These features are then used to (1) reproduce both of the\noriginal RGB images, (2) reconstruct the hypothetical separated X-ray images,\nand (3) regenerate the mixed X-ray image. The algorithm operates in a totally\nself-supervised fashion without requiring a sample set that contains both the\nmixed X-ray images and the separated ones. The methodology was tested on images\nfrom the double-sided wing panels of the \\textsl{Ghent Altarpiece}, painted in\n1432 by the brothers Hubert and Jan van Eyck. These tests show that the\nproposed approach outperforms other state-of-the-art X-ray image separation\nmethods for art investigation applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:39:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Pu", "Wei", ""], ["Sober", "Barak", ""], ["Daly", "Nathan", ""], ["Sabetsarvestani", "Zahra", ""], ["Higgitt", "Catherine", ""], ["Daubechies", "Ingrid", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "2009.07896", "submitter": "Narine Kokhlikyan", "authors": "Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal\n  Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos\n  Araya, Siqi Yan, Orion Reblitz-Richardson", "title": "Captum: A unified and generic model interpretability library for PyTorch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel, unified, open-source model\ninterpretability library for PyTorch [12]. The library contains generic\nimplementations of a number of gradient and perturbation-based attribution\nalgorithms, also known as feature, neuron and layer importance algorithms, as\nwell as a set of evaluation metrics for these algorithms. It can be used for\nboth classification and non-classification models including graph-structured\nmodels built on Neural Networks (NN). In this paper we give a high-level\noverview of supported attribution algorithms and show how to perform\nmemory-efficient and scalable computations. We emphasize that the three main\ncharacteristics of the library are multimodality, extensibility and ease of\nuse. Multimodality supports different modality of inputs such as image, text,\naudio or video. Extensibility allows adding new algorithms and features. The\nlibrary is also designed for easy understanding and use. Besides, we also\nintroduce an interactive visualization tool called Captum Insights that is\nbuilt on top of Captum library and allows sample-based model debugging and\nvisualization using feature importance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:57:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kokhlikyan", "Narine", ""], ["Miglani", "Vivek", ""], ["Martin", "Miguel", ""], ["Wang", "Edward", ""], ["Alsallakh", "Bilal", ""], ["Reynolds", "Jonathan", ""], ["Melnikov", "Alexander", ""], ["Kliushkina", "Natalia", ""], ["Araya", "Carlos", ""], ["Yan", "Siqi", ""], ["Reblitz-Richardson", "Orion", ""]]}, {"id": "2009.07916", "submitter": "Noud De Kroon", "authors": "Arnoud A.W.M. de Kroon, Danielle Belgrave, Joris M. Mooij", "title": "Causal Discovery for Causal Bandits utilizing Separating Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Causal Bandit is a variant of the classic Bandit problem where an agent\nmust identify the best action in a sequential decision-making process, where\nthe reward distribution of the actions displays a non-trivial dependence\nstructure that is governed by a causal model. All methods proposed thus far in\nthe literature rely on exact prior knowledge of the causal model to obtain\nimproved estimators for the reward. We formulate a new causal bandit algorithm\nthat is the first to no longer rely on explicit prior causal knowledge and\ninstead uses the output of causal discovery algorithms. This algorithm relies\non a new estimator based on separating sets, a causal structure already known\nin causal discovery literature. We show that given a separating set, this\nestimator is unbiased, and has lower variance compared to the sample mean. We\nderive a concentration bound and construct a UCB-type algorithm based on this\nbound, as well as a Thompson sampling variant. We compare our algorithms with\ntraditional bandit algorithms on simulation data. On these problems, our\nalgorithms show a significant boost in performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 20:08:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["de Kroon", "Arnoud A. W. M.", ""], ["Belgrave", "Danielle", ""], ["Mooij", "Joris M.", ""]]}, {"id": "2009.07925", "submitter": "Meghna Lowalekar", "authors": "Meghna Lowalekar, Pradeep Varakantham, Patrick Jaillet", "title": "Competitive Ratios for Online Multi-capacity Ridesharing", "comments": "28 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-capacity ridesharing, multiple requests (e.g., customers, food\nitems, parcels) with different origin and destination pairs travel in one\nresource. In recent years, online multi-capacity ridesharing services (i.e.,\nwhere assignments are made online) like Uber-pool, foodpanda, and on-demand\nshuttles have become hugely popular in transportation, food delivery, logistics\nand other domains. This is because multi-capacity ridesharing services benefit\nall parties involved { the customers (due to lower costs), the drivers (due to\nhigher revenues) and the matching platforms (due to higher revenues per\nvehicle/resource). Most importantly these services can also help reduce carbon\nemissions (due to fewer vehicles on roads).\n  Online multi-capacity ridesharing is extremely challenging as the underlying\nmatching graph is no longer bipartite (as in the unit-capacity case) but a\ntripartite graph with resources (e.g., taxis, cars), requests and request\ngroups (combinations of requests that can travel together). The desired\nmatching between resources and request groups is constrained by the edges\nbetween requests and request groups in this tripartite graph (i.e., a request\ncan be part of at most one request group in the final assignment). While there\nhave been myopic heuristic approaches employed for solving the online\nmulti-capacity ridesharing problem, they do not provide any guarantees on the\nsolution quality. To that end, this paper presents the first approach with\nbounds on the competitive ratio for online multi-capacity ridesharing (when\nresources rejoin the system at their initial location/depot after serving a\ngroup of requests).\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 20:29:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lowalekar", "Meghna", ""], ["Varakantham", "Pradeep", ""], ["Jaillet", "Patrick", ""]]}, {"id": "2009.07938", "submitter": "Zijun Cui", "authors": "Zijun Cui, Pavan Kapanipathi, Kartik Talamadupula, Tian Gao, Qiang Ji", "title": "Type-augmented Relation Prediction in Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:14:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:59:56 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:57:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Cui", "Zijun", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""], ["Gao", "Tian", ""], ["Ji", "Qiang", ""]]}, {"id": "2009.07963", "submitter": "Akash Gupta", "authors": "Akash Gupta, Michael T. Lash, Senthil K. Nachimuthu", "title": "Optimal Sepsis Patient Treatment using Human-in-the-loop Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sepsis is one of the leading causes of death in Intensive Care Units (ICU).\nThe strategy for treating sepsis involves the infusion of intravenous (IV)\nfluids and administration of antibiotics. Determining the optimal quantity of\nIV fluids is a challenging problem due to the complexity of a patient's\nphysiology. In this study, we develop a data-driven optimization solution that\nderives the optimal quantity of IV fluids for individual patients. The proposed\nmethod minimizes the probability of severe outcomes by controlling the\nprescribed quantity of IV fluids and utilizes human-in-the-loop artificial\nintelligence. We demonstrate the performance of our model on 1122 ICU patients\nwith sepsis diagnosis extracted from the MIMIC-III dataset. The results show\nthat, on average, our model can reduce mortality by 22%. This study has the\npotential to help physicians synthesize optimal, patient-specific treatment\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 22:34:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Gupta", "Akash", ""], ["Lash", "Michael T.", ""], ["Nachimuthu", "Senthil K.", ""]]}, {"id": "2009.07974", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "Analysis of Generalizability of Deep Neural Networks Based on the\n  Complexity of Decision Boundary", "comments": "7 pages, 11 figures. Accepted by ICMLA 2020", "journal-ref": "19th IEEE International Conference on Machine Learning and\n  Applications (ICMLA), 2020, pp. 101-106", "doi": "10.1109/ICMLA51294.2020.00025", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For supervised learning models, the analysis of generalization ability\n(generalizability) is vital because the generalizability expresses how well a\nmodel will perform on unseen data. Traditional generalization methods, such as\nthe VC dimension, do not apply to deep neural network (DNN) models. Thus, new\ntheories to explain the generalizability of DNNs are required. In this study,\nwe hypothesize that the DNN with a simpler decision boundary has better\ngeneralizability by the law of parsimony (Occam's Razor). We create the\ndecision boundary complexity (DBC) score to define and measure the complexity\nof decision boundary of DNNs. The idea of the DBC score is to generate data\npoints (called adversarial examples) on or near the decision boundary. Our new\napproach then measures the complexity of the boundary using the entropy of\neigenvalues of these data. The method works equally well for high-dimensional\ndata. We use training data and the trained model to compute the DBC score. And,\nthe ground truth for model's generalizability is its test accuracy. Experiments\nbased on the DBC score have verified our hypothesis. The DBC is shown to\nprovide an effective method to measure the complexity of a decision boundary\nand gives a quantitative measure of the generalizability of DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 23:25:52 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2009.07982", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Strategy Proof Mechanisms for Facility Location at Limited Locations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facility location problems often permit facilities to be located at any\nposition. But what if this is not the case in practice? What if facilities can\nonly be located at particular locations like a highway exit or close to a bus\nstop? We consider here the impact of such constraints on the location of\nfacilities on the performance of strategy proof mechanisms for locating\nfacilities.We study four different performance objectives: the total distance\nagents must travel to their closest facility, the maximum distance any agent\nmust travel to their closest facility, and the utilitarian and egalitarian\nwelfare.We show that constraining facilities to a limited set of locations\nmakes all four objectives harder to approximate in general.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:22:34 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 01:42:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2009.07983", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Strategy Proof Mechanisms for Facility Location in Euclidean and\n  Manhattan Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact on mechanisms for facility location of moving from one\ndimension to two (or more) dimensions and Euclidean or Manhattan distances. We\nconsider three fundamental axiomatic properties: anonymity which is a basic\nfairness property, Pareto optimality which is one of the most important\nefficiency properties, and strategy proofness which ensures agents do not have\nan incentive to mis-report. We also consider how well such mechanisms can\napproximate the optimal welfare. Our results are somewhat negative. Moving from\none dimension to two (or more) dimensions often makes these axiomatic\nproperties more difficult to achieve. For example, with two facilities in\nEuclidean space or with just a single facility in Manhattan space, no mechanism\nis anonymous, Pareto optimal and strategy proof. By contrast, mechanisms on the\nline exist with all three properties.We also show that approximation ratios may\nincrease when moving to two (or more) dimensions. All our impossibility results\nare minimal. If we drop one of the three axioms (anonymity, Pareto optimality\nor strategy proofness) multiple mechanisms satisfy the other two axioms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:25:55 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2009.07986", "submitter": "Toby Walsh", "authors": "Toby Walsh", "title": "Strategy Proof Mechanisms for Facility Location with Capacity Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important feature of many real world facility location problems are\ncapacity limits on the facilities. We show here how capacity constraints make\nit harder to design strategy proof mechanisms for facility location, but\ncounter-intuitively can improve the guarantees on how well we can approximate\nthe optimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:29:15 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Walsh", "Toby", ""]]}, {"id": "2009.07999", "submitter": "George Pu", "authors": "Yanlin Zhou, George Pu, Xiyao Ma, Xiaolin Li, Dapeng Wu", "title": "Distilled One-Shot Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current federated learning algorithms take tens of communication rounds\ntransmitting unwieldy model weights under ideal circumstances and hundreds when\ndata is poorly distributed. Inspired by recent work on dataset distillation and\ndistributed one-shot learning, we propose Distilled One-Shot Federated Learning\n(DOSFL) to significantly reduce the communication cost while achieving\ncomparable performance. In just one round, each client distills their private\ndataset, sends the synthetic data (e.g. images or sentences) to the server, and\ncollectively trains a global model. The distilled data look like noise and are\nonly useful to the specific model weights, i.e., become useless after the model\nupdates. With this weight-less and gradient-less design, the total\ncommunication cost of DOSFL is up to three orders of magnitude less than FedAvg\nwhile preserving between 93% to 99% performance of a centralized counterpart.\nAfterwards, clients could switch to traditional methods such as FedAvg to\nfinetune the last few percent to fit personalized local models with local\ndatasets. Through comprehensive experiments, we show the accuracy and\ncommunication performance of DOSFL on both vision and language tasks with\ndifferent models including CNN, LSTM, Transformer, etc. We demonstrate that an\neavesdropping attacker cannot properly train a good model using the leaked\ndistilled data, without knowing the initial model weights. DOSFL serves as an\ninexpensive method to quickly converge on a performant pre-trained model with\nless than 0.1% communication cost of traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:14:47 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 21:10:36 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 06:55:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhou", "Yanlin", ""], ["Pu", "George", ""], ["Ma", "Xiyao", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2009.08002", "submitter": "Pushpendra Rana", "authors": "Pushpendra Rana and Lav R Varshney", "title": "Planting trees at the right places: Recommending suitable sites for\n  growing trees using algorithm fusion", "comments": "26 pages, 4 figures, 2 tables, 2 supplemental tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale planting of trees has been proposed as a low-cost natural\nsolution for carbon mitigation, but is hampered by poor selection of plantation\nsites, especially in developing countries. To aid in site selection, we develop\nthe ePSA (e-Plantation Site Assistant) recommendation system based on algorithm\nfusion that combines physics-based/traditional forestry science knowledge with\nmachine learning. ePSA assists forest range officers by identifying blank\npatches inside forest areas and ranking each such patch based on their tree\ngrowth potential. Experiments, user studies, and deployment results\ncharacterize the utility of the recommender system in shaping the long-term\nsuccess of tree plantations as a nature climate solution for carbon mitigation\nin northern India and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 01:17:13 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 08:08:46 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Rana", "Pushpendra", ""], ["Varshney", "Lav R", ""]]}, {"id": "2009.08015", "submitter": "Li Su", "authors": "Hsuan-Kai Kao and Li Su", "title": "Temporally Guided Music-to-Body-Movement Generation", "comments": null, "journal-ref": null, "doi": "10.1145/3394171.3413848", "report-no": null, "categories": "cs.MM cs.AI cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a neural network model to generate virtual violinist's\n3-D skeleton movements from music audio. Improved from the conventional\nrecurrent neural network models for generating 2-D skeleton data in previous\nworks, the proposed model incorporates an encoder-decoder architecture, as well\nas the self-attention mechanism to model the complicated dynamics in body\nmovement sequences. To facilitate the optimization of self-attention model,\nbeat tracking is applied to determine effective sizes and boundaries of the\ntraining examples. The decoder is accompanied with a refining network and a\nbowing attack inference mechanism to emphasize the right-hand behavior and\nbowing attack timing. Both objective and subjective evaluations reveal that the\nproposed model outperforms the state-of-the-art methods. To the best of our\nknowledge, this work represents the first attempt to generate 3-D violinists'\nbody movements considering key features in musical body movement.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:10:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Kao", "Hsuan-Kai", ""], ["Su", "Li", ""]]}, {"id": "2009.08044", "submitter": "Mark Hamilton", "authors": "Mark Hamilton, Nick Gonsalves, Christina Lee, Anand Raman, Brendan\n  Walsh, Siddhartha Prasad, Dalitso Banda, Lucy Zhang, Lei Zhang, William T.\n  Freeman", "title": "Large-Scale Intelligent Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deploying Machine Learning (ML) algorithms within databases is a challenge\ndue to the varied computational footprints of modern ML algorithms and the\nmyriad of database technologies each with its own restrictive syntax. We\nintroduce an Apache Spark-based micro-service orchestration framework that\nextends database operations to include web service primitives. Our system can\norchestrate web services across hundreds of machines and takes full advantage\nof cluster, thread, and asynchronous parallelism. Using this framework, we\nprovide large scale clients for intelligent services such as speech, vision,\nsearch, anomaly detection, and text analysis. This allows users to integrate\nready-to-use intelligence into any datastore with an Apache Spark connector. To\neliminate the majority of overhead from network communication, we also\nintroduce a low-latency containerized version of our architecture. Finally, we\ndemonstrate that the services we investigate are competitive on a variety of\nbenchmarks, and present two applications of this framework to create\nintelligent search engines, and real-time auto race analytics systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:38:28 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 20:51:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Hamilton", "Mark", ""], ["Gonsalves", "Nick", ""], ["Lee", "Christina", ""], ["Raman", "Anand", ""], ["Walsh", "Brendan", ""], ["Prasad", "Siddhartha", ""], ["Banda", "Dalitso", ""], ["Zhang", "Lucy", ""], ["Zhang", "Lei", ""], ["Freeman", "William T.", ""]]}, {"id": "2009.08052", "submitter": "Chang Liu", "authors": "Chang Liu, Huichu Zhang, Weinan Zhang, Guanjie Zheng, Yong Yu", "title": "GeneraLight: Improving Environment Generalization of Traffic Signal\n  Control via Meta Reinforcement Learning", "comments": "Proceedings of the 29th ACM International on Conference on\n  Information and Knowledge Management (CIKM). ACM, 2020", "journal-ref": null, "doi": "10.1145/3340531.3411859", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy traffic congestion problem has always been a concern for modern\ncities. To alleviate traffic congestion, researchers use reinforcement learning\n(RL) to develop better traffic signal control (TSC) algorithms in recent years.\nHowever, most RL models are trained and tested in the same traffic flow\nenvironment, which results in a serious overfitting problem. Since the traffic\nflow environment in the real world keeps varying, these models can hardly be\napplied due to the lack of generalization ability. Besides, the limited number\nof accessible traffic flow data brings extra difficulty in testing the\ngeneralization ability of the models. In this paper, we design a novel traffic\nflow generator based on Wasserstein generative adversarial network to generate\nsufficient diverse and quality traffic flows and use them to build proper\ntraining and testing environments. Then we propose a meta-RL TSC framework\nGeneraLight to improve the generalization ability of TSC models. GeneraLight\nboosts the generalization performance by combining the idea of flow clustering\nand model-agnostic meta-learning. We conduct extensive experiments on multiple\nreal-world datasets to show the superior performance of GeneraLight on\ngeneralizing to different traffic flows.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:14:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Liu", "Chang", ""], ["Zhang", "Huichu", ""], ["Zhang", "Weinan", ""], ["Zheng", "Guanjie", ""], ["Yu", "Yong", ""]]}, {"id": "2009.08065", "submitter": "Zhenglun Kong", "authors": "Bingbing Li, Zhenglun Kong, Tianyun Zhang, Ji Li, Zhengang Li, Hang\n  Liu, Caiwen Ding", "title": "Efficient Transformer-based Large Scale Language Representations using\n  Hardware-friendly Block Structured Pruning", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained large-scale language models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. However, the limited\nweight storage and computational speed on hardware platforms have impeded the\npopularity of pre-trained models, especially in the era of edge computing. In\nthis work, we propose an efficient transformer-based large-scale language\nrepresentation using hardware-friendly block structure pruning. We incorporate\nthe reweighted group Lasso into block-structured pruning for optimization.\nBesides the significantly reduced weight storage and computation, the proposed\napproach achieves high compression rates. Experimental results on different\nmodels (BERT, RoBERTa, and DistilBERT) on the General Language Understanding\nEvaluation (GLUE) benchmark tasks show that we achieve up to 5.0x with zero or\nminor accuracy degradation on certain task(s). Our proposed method is also\northogonal to existing compact pre-trained language models such as DistilBERT\nusing knowledge distillation, since a further 1.79x average compression rate\ncan be achieved on top of DistilBERT with zero or minor accuracy degradation.\nIt is suitable to deploy the final compressed model on resource-constrained\nedge devices.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:45:47 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 20:09:04 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 19:14:32 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 22:13:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Li", "Bingbing", ""], ["Kong", "Zhenglun", ""], ["Zhang", "Tianyun", ""], ["Li", "Ji", ""], ["Li", "Zhengang", ""], ["Liu", "Hang", ""], ["Ding", "Caiwen", ""]]}, {"id": "2009.08087", "submitter": "Ya Zhang", "authors": "Ya Zhang, Mingming Lu, Haifeng Li", "title": "Urban Traffic Flow Forecast Based on FastGCRNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is an important prerequisite for the application of\nintelligent transportation systems in urban traffic networks. The existing\nworks adopted RNN and CNN/GCN, among which GCRN is the state of art work, to\ncharacterize the temporal and spatial correlation of traffic flows. However, it\nis hard to apply GCRN to the large scale road networks due to high\ncomputational complexity. To address this problem, we propose to abstract the\nroad network into a geometric graph and build a Fast Graph Convolution\nRecurrent Neural Network (FastGCRNN) to model the spatial-temporal dependencies\nof traffic flow. Specifically, We use FastGCN unit to efficiently capture the\ntopological relationship between the roads and the surrounding roads in the\ngraph with reducing the computational complexity through importance sampling,\ncombine GRU unit to capture the temporal dependency of traffic flow, and embed\nthe spatiotemporal features into Seq2Seq based on the Encoder-Decoder\nframework. Experiments on large-scale traffic data sets illustrate that the\nproposed method can greatly reduce computational complexity and memory\nconsumption while maintaining relatively high accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:05:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Zhang", "Ya", ""], ["Lu", "Mingming", ""], ["Li", "Haifeng", ""]]}, {"id": "2009.08097", "submitter": "Sumit Kumar Jha", "authors": "Sumit Kumar Jha, Susmit Jha, Rickard Ewetz, Sunny Raj, Alvaro\n  Velasquez, Laura L. Pullum, Ananthram Swami", "title": "An Extension of Fano's Inequality for Characterizing Model\n  Susceptibility to Membership Inference Attacks", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to be vulnerable to membership inference\nattacks wherein the attacker aims to detect whether specific input data were\nused to train the model. These attacks can potentially leak private or\nproprietary data. We present a new extension of Fano's inequality and employ it\nto theoretically establish that the probability of success for a membership\ninference attack on a deep neural network can be bounded using the mutual\ninformation between its inputs and its activations. This enables the use of\nmutual information to measure the susceptibility of a DNN model to membership\ninference attacks. In our empirical evaluation, we show that the correlation\nbetween the mutual information and the susceptibility of the DNN model to\nmembership inference attacks is 0.966, 0.996, and 0.955 for CIFAR-10, SVHN and\nGTSRB models, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:37:15 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Jha", "Sumit Kumar", ""], ["Jha", "Susmit", ""], ["Ewetz", "Rickard", ""], ["Raj", "Sunny", ""], ["Velasquez", "Alvaro", ""], ["Pullum", "Laura L.", ""], ["Swami", "Ananthram", ""]]}, {"id": "2009.08111", "submitter": "Lancelot Da Costa", "authors": "Lancelot Da Costa, Noor Sajid, Thomas Parr, Karl Friston, Ryan Smith", "title": "The relationship between dynamic programming and active inference: the\n  discrete, finite-horizon case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference is a normative framework for generating behaviour based upon\nthe free energy principle, a theory of self-organisation. This framework has\nbeen successfully used to solve reinforcement learning and stochastic control\nproblems, yet, the formal relation between active inference and reward\nmaximisation has not been fully explicated. In this paper, we consider the\nrelation between active inference and dynamic programming under the Bellman\nequation, which underlies many approaches to reinforcement learning and\ncontrol. We show that, on partially observable Markov decision processes,\ndynamic programming is a limiting case of active inference. In active\ninference, agents select actions to minimise expected free energy. In the\nabsence of ambiguity about states, this reduces to matching expected states\nwith a target distribution encoding the agent's preferences. When target states\ncorrespond to rewarding states, this maximises expected reward, as in\nreinforcement learning. When states are ambiguous, active inference agents will\nchoose actions that simultaneously minimise ambiguity. This allows active\ninference agents to supplement their reward maximising (or exploitative)\nbehaviour with novelty-seeking (or exploratory) behaviour. This clarifies the\nconnection between active inference and reinforcement learning, and how both\nframeworks may benefit from each other.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:13:59 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 17:28:07 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 17:19:26 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Da Costa", "Lancelot", ""], ["Sajid", "Noor", ""], ["Parr", "Thomas", ""], ["Friston", "Karl", ""], ["Smith", "Ryan", ""]]}, {"id": "2009.08115", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou, Huixin Wang, Junlan Feng", "title": "A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief\n  States towards Semi-Supervised Learning", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured belief states are crucial for user goal tracking and database\nquery in task-oriented dialog systems. However, training belief trackers often\nrequires expensive turn-level annotations of every user utterance. In this\npaper we aim at alleviating the reliance on belief state labels in building\nend-to-end dialog systems, by leveraging unlabeled dialog data towards\nsemi-supervised learning. We propose a probabilistic dialog model, called the\nLAtent BElief State (LABES) model, where belief states are represented as\ndiscrete latent variables and jointly modeled with system responses given user\ninputs. Such latent variable modeling enables us to develop semi-supervised\nlearning under the principled variational learning framework. Furthermore, we\nintroduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of\nLABES. In supervised experiments, LABES-S2S obtains strong results on three\nbenchmark datasets of different scales. In utilizing unlabeled dialog data,\nsemi-supervised LABES-S2S significantly outperforms both supervised-only and\nsemi-supervised baselines. Remarkably, we can reduce the annotation demands to\n50% without performance loss on MultiWOZ.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:26:37 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 06:43:09 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 14:18:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""], ["Wang", "Huixin", ""], ["Feng", "Junlan", ""]]}, {"id": "2009.08123", "submitter": "Akshay Smit", "authors": "Damir Vrabac, Akshay Smit, Rebecca Rojansky, Yasodha Natkunam, Ranjana\n  H. Advani, Andrew Y. Ng, Sebastian Fernandez-Pol, Pranav Rajpurkar", "title": "DLBCL-Morph: Morphological features computed using deep learning for an\n  annotated digital DLBCL image set", "comments": "Corrections to folder structure figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffuse Large B-Cell Lymphoma (DLBCL) is the most common non-Hodgkin\nlymphoma. Though histologically DLBCL shows varying morphologies, no\nmorphologic features have been consistently demonstrated to correlate with\nprognosis. We present a morphologic analysis of histology sections from 209\nDLBCL cases with associated clinical and cytogenetic data. Duplicate tissue\ncore sections were arranged in tissue microarrays (TMAs), and replicate\nsections were stained with H&E and immunohistochemical stains for CD10, BCL6,\nMUM1, BCL2, and MYC. The TMAs are accompanied by pathologist-annotated\nregions-of-interest (ROIs) that identify areas of tissue representative of\nDLBCL. We used a deep learning model to segment all tumor nuclei in the ROIs,\nand computed several geometric features for each segmented nucleus. We fit a\nCox proportional hazards model to demonstrate the utility of these geometric\nfeatures in predicting survival outcome, and found that it achieved a C-index\n(95% CI) of 0.635 (0.574,0.691). Our finding suggests that geometric features\ncomputed from tumor nuclei are of prognostic importance, and should be\nvalidated in prospective studies.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:43:42 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 07:09:07 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 11:02:28 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Vrabac", "Damir", ""], ["Smit", "Akshay", ""], ["Rojansky", "Rebecca", ""], ["Natkunam", "Yasodha", ""], ["Advani", "Ranjana H.", ""], ["Ng", "Andrew Y.", ""], ["Fernandez-Pol", "Sebastian", ""], ["Rajpurkar", "Pranav", ""]]}, {"id": "2009.08138", "submitter": "Yutai Hou", "authors": "Yutai Hou, Jiafeng Mao, Yongkui Lai, Cheng Chen, Wanxiang Che, Zhigang\n  Chen, Ting Liu", "title": "FewJoint: A Few-shot Learning Benchmark for Joint Language Understanding", "comments": "Code and dataset is available at:\n  https://github.com/AtmaHou/MetaDialog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot learning (FSL) is one of the key future steps in machine learning\nand has raised a lot of attention. However, in contrast to the rapid\ndevelopment in other domains, such as Computer Vision, the progress of FSL in\nNature Language Processing (NLP) is much slower. One of the key reasons for\nthis is the lacking of public benchmarks. NLP FSL researches always report new\nresults on their own constructed few-shot datasets, which is pretty inefficient\nin results comparison and thus impedes cumulative progress. In this paper, we\npresent FewJoint, a novel Few-Shot Learning benchmark for NLP. Different from\nmost NLP FSL research that only focus on simple N-classification problems, our\nbenchmark introduces few-shot joint dialogue language understanding, which\nadditionally covers the structure prediction and multi-task reliance problems.\nThis allows our benchmark to reflect the real-word NLP complexity beyond simple\nN-classification. Our benchmark is used in the few-shot learning contest of\nSMP2020-ECDT task-1. We also provide a compatible FSL platform to ease\nexperiment set-up.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:17:12 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:19:05 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 06:24:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hou", "Yutai", ""], ["Mao", "Jiafeng", ""], ["Lai", "Yongkui", ""], ["Chen", "Cheng", ""], ["Che", "Wanxiang", ""], ["Chen", "Zhigang", ""], ["Liu", "Ting", ""]]}, {"id": "2009.08229", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "AIN: Fast and Accurate Sequence Labeling with Approximate Inference\n  Network", "comments": "Accept to Main Conference of EMNLP 2020 (Short). Camera-ready, 8\n  Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The linear-chain Conditional Random Field (CRF) model is one of the most\nwidely-used neural sequence labeling approaches. Exact probabilistic inference\nalgorithms such as the forward-backward and Viterbi algorithms are typically\napplied in training and prediction stages of the CRF model. However, these\nalgorithms require sequential computation that makes parallelization\nimpossible. In this paper, we propose to employ a parallelizable approximate\nvariational inference algorithm for the CRF model. Based on this algorithm, we\ndesign an approximate inference network that can be connected with the encoder\nof the neural CRF model to form an end-to-end network, which is amenable to\nparallelization for faster training and prediction. The empirical results show\nthat our proposed approaches achieve a 12.7-fold improvement in decoding speed\nwith long sentences and a competitive accuracy compared with the traditional\nCRF approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:18:43 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 11:59:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2009.08274", "submitter": "Liangming Chen", "authors": "Liangming Chen, Long Jin, Xiujuan Du, Shuai Li, Mei Liu", "title": "Deforming the Loss Surface to Affect the Behaviour of the Optimizer", "comments": "arXiv admin note: substantial text overlap with arXiv:2007.12515", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning, it is usually assumed that the optimization process is\nconducted on a shape-fixed loss surface. Differently, we first propose a novel\nconcept of deformation mapping in this paper to affect the behaviour of the\noptimizer. Vertical deformation mapping (VDM), as a type of deformation\nmapping, can make the optimizer enter a flat region, which often implies better\ngeneralization performance. Moreover, we design various VDMs, and further\nprovide their contributions to the loss surface. After defining the local M\nregion, theoretical analyses show that deforming the loss surface can enhance\nthe gradient descent optimizer's ability to filter out sharp minima. With\nvisualizations of loss landscapes, we evaluate the flatnesses of minima\nobtained by both the original optimizer and optimizers enhanced by VDMs on\nCIFAR-100. The experimental results show that VDMs do find flatter regions.\nMoreover, we compare popular convolutional neural networks enhanced by VDMs\nwith the corresponding original ones on ImageNet, CIFAR-10, and CIFAR-100. The\nresults are surprising: there are significant improvements on all of the\ninvolved models equipped with VDMs. For example, the top-1 test accuracy of\nResNet-20 on CIFAR-100 increases by 1.46%, with insignificant additional\ncomputational overhead.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:43:16 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Chen", "Liangming", ""], ["Jin", "Long", ""], ["Du", "Xiujuan", ""], ["Li", "Shuai", ""], ["Liu", "Mei", ""]]}, {"id": "2009.08281", "submitter": "Michael Lyons", "authors": "Michael Lyons and Kazunori Morikawa", "title": "A Linked Aggregate Code for Processing Faces (Revised Version)", "comments": "18 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.5281/zenodo.4034544", "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of face representation, inspired by the biology of the visual system,\nis compared to experimental data on the perception of facial similarity. The\nface representation model uses aggregate primary visual cortex (V1) cell\nresponses topographically linked to a grid covering the face, allowing\ncomparison of shape and texture at corresponding points in two facial images.\nWhen a set of relatively similar faces was used as stimuli, this Linked\nAggregate Code (LAC) predicted human performance in similarity judgment\nexperiments. When faces of perceivable categories were used, dimensions such as\napparent sex and race emerged from the LAC model without training. The\ndimensional structure of the LAC similarity measure for the mixed category task\ndisplayed some psychologically plausible features but also highlighted\ndifferences between the model and the human similarity judgements. The human\njudgements exhibited a racial perceptual bias that was not shared by the LAC\nmodel. The results suggest that the LAC based similarity measure may offer a\nfertile starting point for further modelling studies of face representation in\nhigher visual areas, including studies of the development of biases in face\nperception.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:29:25 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lyons", "Michael", ""], ["Morikawa", "Kazunori", ""]]}, {"id": "2009.08295", "submitter": "James Morrill Mr", "authors": "James Morrill and Cristopher Salvi and Patrick Kidger and James Foster\n  and Terry Lyons", "title": "Neural Rough Differential Equations for Long Time Series", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural controlled differential equations (CDEs) are the continuous-time\nanalogue of recurrent neural networks, as Neural ODEs are to residual networks,\nand offer a memory-efficient continuous-time way to model functions of\npotentially irregular time series. Existing methods for computing the forward\npass of a Neural CDE involve embedding the incoming time series into path\nspace, often via interpolation, and using evaluations of this path to drive the\nhidden state. Here, we use rough path theory to extend this formulation.\nInstead of directly embedding into path space, we instead represent the input\nsignal over small time intervals through its \\textit{log-signature}, which are\nstatistics describing how the signal drives a CDE. This is the approach for\nsolving \\textit{rough differential equations} (RDEs), and correspondingly we\ndescribe our main contribution as the introduction of Neural RDEs. This\nextension has a purpose: by generalising the Neural CDE approach to a broader\nclass of driving signals, we demonstrate particular advantages for tackling\nlong time series. In this regime, we demonstrate efficacy on problems of length\nup to 17k observations and observe significant training speed-ups, improvements\nin model performance, and reduced memory requirements compared to existing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:43:47 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:08:20 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 11:28:41 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 12:04:06 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Morrill", "James", ""], ["Salvi", "Cristopher", ""], ["Kidger", "Patrick", ""], ["Foster", "James", ""], ["Lyons", "Terry", ""]]}, {"id": "2009.08302", "submitter": "Pallavi Bagga", "authors": "Pallavi Bagga, Nicola Paoletti and Kostas Stathis", "title": "Learnable Strategies for Bilateral Agent Negotiation over Multiple\n  Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel bilateral negotiation model that allows a self-interested\nagent to learn how to negotiate over multiple issues in the presence of user\npreference uncertainty. The model relies upon interpretable strategy templates\nrepresenting the tactics the agent should employ during the negotiation and\nlearns template parameters to maximize the average utility received over\nmultiple negotiations, thus resulting in optimal bid acceptance and generation.\nOur model also uses deep reinforcement learning to evaluate threshold utility\nvalues, for those tactics that require them, thereby deriving optimal utilities\nfor every environment state. To handle user preference uncertainty, the model\nrelies on a stochastic search to find user model that best agrees with a given\npartial preference profile. Multi-objective optimization and multi-criteria\ndecision-making methods are applied at negotiation time to generate\nPareto-optimal outcomes thereby increasing the number of successful (win-win)\nnegotiations. Rigorous experimental evaluations show that the agent employing\nour model outperforms the winning agents of the 10th Automated Negotiating\nAgents Competition (ANAC'19) in terms of individual as well as social-welfare\nutilities.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:52:18 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Bagga", "Pallavi", ""], ["Paoletti", "Nicola", ""], ["Stathis", "Kostas", ""]]}, {"id": "2009.08319", "submitter": "Michael Laskin", "authors": "Adam Stooke, Kimin Lee, Pieter Abbeel, and Michael Laskin", "title": "Decoupling Representation Learning from Reinforcement Learning", "comments": "Improved related works and fixed code hyperlink", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an effort to overcome limitations of reward-driven feature learning in\ndeep reinforcement learning (RL) from images, we propose decoupling\nrepresentation learning from policy learning. To this end, we introduce a new\nunsupervised learning (UL) task, called Augmented Temporal Contrast (ATC),\nwhich trains a convolutional encoder to associate pairs of observations\nseparated by a short time difference, under image augmentations and using a\ncontrastive loss. In online RL experiments, we show that training the encoder\nexclusively using ATC matches or outperforms end-to-end RL in most\nenvironments. Additionally, we benchmark several leading UL algorithms by\npre-training encoders on expert demonstrations and using them, with weights\nfrozen, in RL agents; we find that agents using ATC-trained encoders outperform\nall others. We also train multi-task encoders on data from multiple\nenvironments and show generalization to different downstream RL tasks. Finally,\nwe ablate components of ATC, and introduce a new data augmentation to enable\nreplay of (compressed) latent images from pre-trained encoders when RL requires\naugmentation. Our experiments span visually diverse RL benchmarks in DeepMind\nControl, DeepMind Lab, and Atari, and our complete code is available at\nhttps://github.com/astooke/rlpyt/tree/master/rlpyt/ul.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:11:13 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 16:35:40 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 20:44:18 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Stooke", "Adam", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2009.08373", "submitter": "Melanie Sclar", "authors": "M. Sclar, G. Bujia, S. Vita, G. Solovey, J. E. Kamienkowski", "title": "Modeling human visual search: A combined Bayesian searcher and saliency\n  map approach for eye movement guidance in natural scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding objects is essential for almost any daily-life visual task. Saliency\nmodels have been useful to predict fixation locations in natural images, but\nare static, i.e., they provide no information about the time-sequence of\nfixations. Nowadays, one of the biggest challenges in the field is to go beyond\nsaliency maps to predict a sequence of fixations related to a visual task, such\nas searching for a given target. Bayesian observer models have been proposed\nfor this task, as they represent visual search as an active sampling process.\nNevertheless, they were mostly evaluated on artificial images, and how they\nadapt to natural images remains largely unexplored.\n  Here, we propose a unified Bayesian model for visual search guided by\nsaliency maps as prior information. We validated our model with a visual search\nexperiment in natural scenes recording eye movements. We show that, although\nstate-of-the-art saliency models perform well in predicting the first two\nfixations in a visual search task, their performance degrades to chance\nafterward. This suggests that saliency maps alone are good to model bottom-up\nfirst impressions, but are not enough to explain the scanpaths when top-down\ntask information is critical. Thus, we propose to use them as priors of\nBayesian searchers. This approach leads to a behavior very similar to humans\nfor the whole scanpath, both in the percentage of target found as a function of\nthe fixation rank and the scanpath similarity, reproducing the entire sequence\nof eye movements.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:38:23 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 04:02:44 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Sclar", "M.", ""], ["Bujia", "G.", ""], ["Vita", "S.", ""], ["Solovey", "G.", ""], ["Kamienkowski", "J. E.", ""]]}, {"id": "2009.08395", "submitter": "Tariq Habib Afridi Mr.", "authors": "Tariq Habib Afridi, Aftab Alam, Muhammad Numan Khan, Jawad Khan,\n  Young-Koo Lee", "title": "A Multimodal Memes Classification: A Survey and Open Research Issues", "comments": "This is a survey paper on recent state of the art VL models that can\n  be used for memes classification. it has 15 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:13:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Afridi", "Tariq Habib", ""], ["Alam", "Aftab", ""], ["Khan", "Muhammad Numan", ""], ["Khan", "Jawad", ""], ["Lee", "Young-Koo", ""]]}, {"id": "2009.08424", "submitter": "Mariya Toneva", "authors": "Mariya Toneva, Otilia Stretcu, Barnabas Poczos, Leila Wehbe, Tom M.\n  Mitchell", "title": "Modeling Task Effects on Meaning Representation in the Brain via\n  Zero-Shot MEG Prediction", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How meaning is represented in the brain is still one of the big open\nquestions in neuroscience. Does a word (e.g., bird) always have the same\nrepresentation, or does the task under which the word is processed alter its\nrepresentation (answering \"can you eat it?\" versus \"can it fly?\")? The brain\nactivity of subjects who read the same word while performing different semantic\ntasks has been shown to differ across tasks. However, it is still not\nunderstood how the task itself contributes to this difference. In the current\nwork, we study Magnetoencephalography (MEG) brain recordings of participants\ntasked with answering questions about concrete nouns. We investigate the effect\nof the task (i.e. the question being asked) on the processing of the concrete\nnoun by predicting the millisecond-resolution MEG recordings as a function of\nboth the semantics of the noun and the task. Using this approach, we test\nseveral hypotheses about the task-stimulus interactions by comparing the\nzero-shot predictions made by these hypotheses for novel tasks and nouns not\nseen during training. We find that incorporating the task semantics\nsignificantly improves the prediction of MEG recordings, across participants.\nThe improvement occurs 475-550ms after the participants first see the word,\nwhich corresponds to what is considered to be the ending time of semantic\nprocessing for a word. These results suggest that only the end of semantic\nprocessing of a word is task-dependent, and pose a challenge for future\nresearch to formulate new hypotheses for earlier task effects as a function of\nthe task and stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:20:18 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 22:31:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Toneva", "Mariya", ""], ["Stretcu", "Otilia", ""], ["Poczos", "Barnabas", ""], ["Wehbe", "Leila", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2009.08438", "submitter": "Szymon Brych", "authors": "Szymon Brych and Antoine Cully", "title": "Competitiveness of MAP-Elites against Proximal Policy Optimization on\n  locomotion tasks in deterministic simulations", "comments": "Quality-Diversity optimization, Reinforcement Learning, Proximal\n  Policy Optimization, MAP-Elites", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing importance of robots and automation creates a demand for\nlearnable controllers which can be obtained through various approaches such as\nEvolutionary Algorithms (EAs) or Reinforcement Learning (RL). Unfortunately,\nthese two families of algorithms have mainly developed independently and there\nare only a few works comparing modern EAs with deep RL algorithms. We show that\nMultidimensional Archive of Phenotypic Elites (MAP-Elites), which is a modern\nEA, can deliver better-performing solutions than one of the state-of-the-art RL\nmethods, Proximal Policy Optimization (PPO) in the generation of locomotion\ncontrollers for a simulated hexapod robot. Additionally, extensive\nhyper-parameter tuning shows that MAP-Elites displays greater robustness across\nseeds and hyper-parameter sets. Generally, this paper demonstrates that EAs\ncombined with modern computational resources display promising characteristics\nand have the potential to contribute to the state-of-the-art in controller\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:41:46 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 08:33:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Brych", "Szymon", ""], ["Cully", "Antoine", ""]]}, {"id": "2009.08451", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Pan Li, Ritesh Kumar, Bryan Hooi", "title": "MSTREAM: Fast Anomaly Detection in Multi-Aspect Streams", "comments": "The Web Conference (WWW), 2021", "journal-ref": null, "doi": "10.1145/3442381.3450023", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a stream of entries in a multi-aspect data setting i.e., entries having\nmultiple dimensions, how can we detect anomalous activities in an unsupervised\nmanner? For example, in the intrusion detection setting, existing work seeks to\ndetect anomalous events or edges in dynamic graph streams, but this does not\nallow us to take into account additional attributes of each entry. Our work\naims to define a streaming multi-aspect data anomaly detection framework,\ntermed MSTREAM which can detect unusual group anomalies as they occur, in a\ndynamic manner. MSTREAM has the following properties: (a) it detects anomalies\nin multi-aspect data including both categorical and numeric attributes; (b) it\nis online, thus processing each record in constant time and constant memory;\n(c) it can capture the correlation between multiple aspects of the data.\nMSTREAM is evaluated over the KDDCUP99, CICIDS-DoS, UNSW-NB 15 and CICIDS-DDoS\ndatasets, and outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:16 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:11:06 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 23:42:21 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 14:49:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Li", "Pan", ""], ["Kumar", "Ritesh", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08453", "submitter": "Zhiqiang Shen", "authors": "Zhiqiang Shen and Marios Savvides", "title": "MEAL V2: Boosting Vanilla ResNet-50 to 80%+ Top-1 Accuracy on ImageNet\n  without Tricks", "comments": "12 pages. Code and trained models are available at:\n  https://github.com/szq0214/MEAL-V2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple yet effective distillation framework that is able to\nboost the vanilla ResNet-50 to 80%+ Top-1 accuracy on ImageNet without tricks.\nWe construct such a framework through analyzing the problems in the existing\nclassification system and simplify the base method ensemble knowledge\ndistillation via discriminators by: (1) adopting the similarity loss and\ndiscriminator only on the final outputs and (2) using the average of softmax\nprobabilities from all teacher ensembles as the stronger supervision.\nIntriguingly, three novel perspectives are presented for distillation: (1)\nweight decay can be weakened or even completely removed since the soft label\nalso has a regularization effect; (2) using a good initialization for students\nis critical; and (3) one-hot/hard label is not necessary in the distillation\nprocess if the weights are well initialized. We show that such a\nstraight-forward framework can achieve state-of-the-art results without\ninvolving any commonly-used techniques, such as architecture modification;\noutside training data beyond ImageNet; autoaug/randaug; cosine learning rate;\nmixup/cutmix training; label smoothing; etc. Our method obtains 80.67% top-1\naccuracy on ImageNet using a single crop-size of 224x224 with vanilla\nResNet-50, outperforming the previous state-of-the-arts by a significant margin\nunder the same network structure. Our result can be regarded as a strong\nbaseline using knowledge distillation, and to our best knowledge, this is also\nthe first method that is able to boost vanilla ResNet-50 to surpass 80% on\nImageNet without architecture modification or additional training data. On\nsmaller ResNet-18, our distillation framework consistently improves from 69.76%\nto 73.19%, which shows tremendous practical values in real-world applications.\nOur code and models are available at: https://github.com/szq0214/MEAL-V2.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 17:40:19 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Shen", "Zhiqiang", ""], ["Savvides", "Marios", ""]]}, {"id": "2009.08454", "submitter": "Siddharth Bhatia", "authors": "Siddharth Bhatia, Arjit Jain, Bryan Hooi", "title": "ExGAN: Adversarial Generation of Extreme Samples", "comments": "AAAI Conference on Artificial Intelligence (AAAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating the risk arising from extreme events is a fundamental goal with\nmany applications, such as the modelling of natural disasters, financial\ncrashes, epidemics, and many others. To manage this risk, a vital step is to be\nable to understand or generate a wide range of extreme scenarios. Existing\napproaches based on Generative Adversarial Networks (GANs) excel at generating\nrealistic samples, but seek to generate typical samples, rather than extreme\nsamples. Hence, in this work, we propose ExGAN, a GAN-based approach to\ngenerate realistic and extreme samples. To model the extremes of the training\ndistribution in a principled way, our work draws from Extreme Value Theory\n(EVT), a probabilistic approach for modelling the extreme tails of\ndistributions. For practical utility, our framework allows the user to specify\nboth the desired extremeness measure, as well as the desired extremeness\nprobability they wish to sample at. Experiments on real US Precipitation data\nshow that our method generates realistic samples, based on visual inspection\nand quantitative measures, in an efficient manner. Moreover, generating\nincreasingly extreme examples using ExGAN can be done in constant time (with\nrespect to the extremeness probability $\\tau$), as opposed to the\n$\\mathcal{O}(\\frac{1}{\\tau})$ time required by the baseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:59:36 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:17:31 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 15:49:39 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bhatia", "Siddharth", ""], ["Jain", "Arjit", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.08457", "submitter": "Baihan Lin", "authors": "Baihan Lin", "title": "Online Semi-Supervised Learning in Contextual Bandits with Episodic\n  Reward", "comments": "Proceeding of AJCAI 2020. This article supersedes our work\n  arXiv:1802.00981 on contextual bandits in nonstationary setting, introduces a\n  new problem setting with episodically revealed reward, and provides a novel\n  solution by propagating pseudo-feedbacks to un-rewarded cases from\n  self-supervision. Also check out our speaker diarization application of this\n  algorithm at arXiv:2006.04376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We considered a novel practical problem of online learning with episodically\nrevealed rewards, motivated by several real-world applications, where the\ncontexts are nonstationary over different episodes and the reward feedbacks are\nnot always available to the decision making agents. For this online\nsemi-supervised learning setting, we introduced Background Episodic Reward\nLinUCB (BerlinUCB), a solution that easily incorporates clustering as a\nself-supervision module to provide useful side information when rewards are not\nobserved. Our experiments on a variety of datasets, both in stationary and\nnonstationary environments of six different scenarios, demonstrated clear\nadvantages of the proposed approach over the standard contextual bandit.\nLastly, we introduced a relevant real-life example where this problem setting\nis especially useful.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:41:02 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 03:29:56 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Baihan", ""]]}, {"id": "2009.08497", "submitter": "Tarek Richard Besold", "authors": "Lorijn Zaadnoordijk, Tarek R. Besold, Rhodri Cusack", "title": "The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons\n  from Infant Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a surge in popularity of supervised Deep Learning, the desire to reduce\nthe dependence on curated, labelled data sets and to leverage the vast\nquantities of unlabelled data available recently triggered renewed interest in\nunsupervised learning algorithms. Despite a significantly improved performance\ndue to approaches such as the identification of disentangled latent\nrepresentations, contrastive learning, and clustering optimisations, the\nperformance of unsupervised machine learning still falls short of its\nhypothesised potential. Machine learning has previously taken inspiration from\nneuroscience and cognitive science with great success. However, this has mostly\nbeen based on adult learners with access to labels and a vast amount of prior\nknowledge. In order to push unsupervised machine learning forward, we argue\nthat developmental science of infant cognition might hold the key to unlocking\nthe next generation of unsupervised learning approaches. Conceptually, human\ninfant learning is the closest biological parallel to artificial unsupervised\nlearning, as infants too must learn useful representations from unlabelled\ndata. In contrast to machine learning, these new representations are learned\nrapidly and from relatively few examples. Moreover, infants learn robust\nrepresentations that can be used flexibly and efficiently in a number of\ndifferent tasks and contexts. We identify five crucial factors enabling\ninfants' quality and speed of learning, assess the extent to which these have\nalready been exploited in machine learning, and propose how further adoption of\nthese factors can give rise to previously unseen performance levels in\nunsupervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:47:06 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Zaadnoordijk", "Lorijn", ""], ["Besold", "Tarek R.", ""], ["Cusack", "Rhodri", ""]]}, {"id": "2009.08507", "submitter": "Zifan Wang", "authors": "Xuan Chen, Zifan Wang, Yucai Fan, Bonan Jin, Piotr Mardziel, Carlee\n  Joe-Wong, Anupam Datta", "title": "Reconstructing Actions To Explain Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution has been a foundational building block for explaining the\ninput feature importance in supervised learning with Deep Neural Network\n(DNNs), but face new challenges when applied to deep Reinforcement Learning\n(RL).We propose a new approach to explaining deep RL actions by defining a\nclass of \\emph{action reconstruction} functions that mimic the behavior of a\nnetwork in deep RL. This approach allows us to answer more complex\nexplainability questions than direct application of DNN attribution methods,\nwhich we adapt to \\emph{behavior-level attributions} in building our action\nreconstructions. It also allows us to define \\emph{agreement}, a metric for\nquantitatively evaluating the explainability of our methods. Our experiments on\na variety of Atari games suggest that perturbation-based attribution methods\nare significantly more suitable in reconstructing actions to explain the deep\nRL agent than alternative attribution methods, and show greater\n\\emph{agreement} than existing explainability work utilizing attention. We\nfurther show that action reconstruction allows us to demonstrate how a deep\nagent learns to play Pac-Man game.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 19:25:56 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 06:09:26 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 01:42:38 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Chen", "Xuan", ""], ["Wang", "Zifan", ""], ["Fan", "Yucai", ""], ["Jin", "Bonan", ""], ["Mardziel", "Piotr", ""], ["Joe-Wong", "Carlee", ""], ["Datta", "Anupam", ""]]}, {"id": "2009.08525", "submitter": "Kevin Moran P", "authors": "Prem Devanbu, Matthew Dwyer, Sebastian Elbaum, Michael Lowry, Kevin\n  Moran, Denys Poshyvanyk, Baishakhi Ray, Rishabh Singh, and Xiangyu Zhang", "title": "Deep Learning & Software Engineering: State of Research and Future\n  Directions", "comments": "Community Report from the 2019 NSF Workshop on Deep Learning &\n  Software Engineering, 37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the current transformative potential of research that sits at the\nintersection of Deep Learning (DL) and Software Engineering (SE), an\nNSF-sponsored community workshop was conducted in co-location with the 34th\nIEEE/ACM International Conference on Automated Software Engineering (ASE'19) in\nSan Diego, California. The goal of this workshop was to outline high priority\nareas for cross-cutting research. While a multitude of exciting directions for\nfuture work were identified, this report provides a general summary of the\nresearch areas representing the areas of highest priority which were discussed\nat the workshop. The intent of this report is to serve as a potential roadmap\nto guide future work that sits at the intersection of SE & DL.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 20:46:08 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Devanbu", "Prem", ""], ["Dwyer", "Matthew", ""], ["Elbaum", "Sebastian", ""], ["Lowry", "Michael", ""], ["Moran", "Kevin", ""], ["Poshyvanyk", "Denys", ""], ["Ray", "Baishakhi", ""], ["Singh", "Rishabh", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2009.08552", "submitter": "Liang Qiu", "authors": "Liang Qiu, Yizhou Zhao, Weiyan Shi, Yuan Liang, Feng Shi, Tao Yuan,\n  Zhou Yu, Song-Chun Zhu", "title": "Structured Attention for Unsupervised Dialogue Structure Induction", "comments": "Long paper accepted by EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.148", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing a meaningful structural representation from one or a set of\ndialogues is a crucial but challenging task in computational linguistics.\nAdvancement made in this area is critical for dialogue system design and\ndiscourse analysis. It can also be extended to solve grammatical inference. In\nthis work, we propose to incorporate structured attention layers into a\nVariational Recurrent Neural Network (VRNN) model with discrete latent states\nto learn dialogue structure in an unsupervised fashion. Compared to a vanilla\nVRNN, structured attention enables a model to focus on different parts of the\nsource sentence embeddings while enforcing a structural inductive bias.\nExperiments show that on two-party dialogue datasets, VRNN with structured\nattention learns semantic structures that are similar to templates used to\ngenerate this dialogue corpus. While on multi-party dialogue datasets, our\nmodel learns an interactive structure demonstrating its capability of\ndistinguishing speakers or addresses, automatically disentangling dialogues\nwithout explicit human annotation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:07:03 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:33:18 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Qiu", "Liang", ""], ["Zhao", "Yizhou", ""], ["Shi", "Weiyan", ""], ["Liang", "Yuan", ""], ["Shi", "Feng", ""], ["Yuan", "Tao", ""], ["Yu", "Zhou", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2009.08586", "submitter": "Ting-Han Fan", "authors": "Ting-Han Fan, Peter J. Ramadge", "title": "A Contraction Approach to Model-based Reinforcement Learning", "comments": "The 24th International Conference on Artificial Intelligence and\n  Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its experimental success, Model-based Reinforcement Learning still\nlacks a complete theoretical understanding. To this end, we analyze the error\nin the cumulative reward using a contraction approach. We consider both\nstochastic and deterministic state transitions for continuous (non-discrete)\nstate and action spaces. This approach doesn't require strong assumptions and\ncan recover the typical quadratic error to the horizon. We prove that branched\nrollouts can reduce this error and are essential for deterministic transitions\nto have a Bellman contraction. Our analysis of policy mismatch error also\napplies to Imitation Learning. In this case, we show that GAN-type learning has\nan advantage over Behavioral Cloning when its discriminator is well-trained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:03:14 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 11:35:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fan", "Ting-Han", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2009.08616", "submitter": "Yi Yu", "authors": "Yi Yu, Abhishek Srivastava, Rajiv Ratn Shah", "title": "Conditional Hybrid GAN for Sequence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional sequence generation aims to instruct the generation procedure by\nconditioning the model with additional context information, which is a\nself-supervised learning issue (a form of unsupervised learning with\nsupervision information from data itself). Unfortunately, the current\nstate-of-the-art generative models have limitations in sequence generation with\nmultiple attributes. In this paper, we propose a novel conditional hybrid GAN\n(C-Hybrid-GAN) to solve this issue. Discrete sequence with triplet attributes\nare separately generated when conditioned on the same context. Most\nimportantly, relational reasoning technique is exploited to model not only the\ndependency inside each sequence of the attribute during the training of the\ngenerator but also the consistency among the sequences of attributes during the\ntraining of the discriminator. To avoid the non-differentiability problem in\nGANs encountered during discrete data generation, we exploit the Gumbel-Softmax\ntechnique to approximate the distribution of discrete-valued sequences.Through\nevaluating the task of generating melody (associated with note, duration, and\nrest) from lyrics, we demonstrate that the proposed C-Hybrid-GAN outperforms\nthe existing methods in context-conditioned discrete-valued sequence\ngeneration.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:52:55 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Yu", "Yi", ""], ["Srivastava", "Abhishek", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2009.08634", "submitter": "Guy Van den Broeck", "authors": "Guy Van den Broeck, Anton Lykov, Maximilian Schleich, Dan Suciu", "title": "On the Tractability of SHAP Explanations", "comments": "Proceedings of the 35th AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SHAP explanations are a popular feature-attribution mechanism for explainable\nAI. They use game-theoretic notions to measure the influence of individual\nfeatures on the prediction of a machine learning model. Despite a lot of recent\ninterest from both academia and industry, it is not known whether SHAP\nexplanations of common machine learning models can be computed efficiently. In\nthis paper, we establish the complexity of computing the SHAP explanation in\nthree important settings. First, we consider fully-factorized data\ndistributions, and show that the complexity of computing the SHAP explanation\nis the same as the complexity of computing the expected value of the model.\nThis fully-factorized setting is often used to simplify the SHAP computation,\nyet our results show that the computation can be intractable for commonly used\nmodels such as logistic regression. Going beyond fully-factorized\ndistributions, we show that computing SHAP explanations is already intractable\nfor a very simple setting: computing SHAP explanations of trivial classifiers\nover naive Bayes distributions. Finally, we show that even computing SHAP over\nthe empirical distribution is #P-hard.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:48:15 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:41:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Broeck", "Guy Van den", ""], ["Lykov", "Anton", ""], ["Schleich", "Maximilian", ""], ["Suciu", "Dan", ""]]}, {"id": "2009.08644", "submitter": "Zihan Ding", "authors": "Zihan Ding, Tianyang Yu, Yanhua Huang, Hongming Zhang, Luo Mai and Hao\n  Dong", "title": "RLzoo: A Comprehensive and Adaptive Reinforcement Learning Library", "comments": "Paper under submission at Journal of Machine Learning Research-Open\n  Source Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have seen a rapidly growing adoption of Deep Reinforcement\nLearning (DRL) technologies. Fully achieving the promise of these technologies\nin practice is, however, extremely difficult. Users have to invest tremendous\nefforts in building DRL agents, incorporating the agents into various external\ntraining environments, and tuning agent implementation/hyper-parameters so that\nthey can reproduce state-of-the-art (SOTA) performance. In this paper, we\npropose RLzoo, a new DRL library that aims to make it easy to develop and\nreproduce DRL algorithms. RLzoo has both high-level APIs and low-level APIs,\nuseful for constructing and customising DRL agents, respectively. It has an\nadaptive agent construction algorithm that can automatically integrate custom\nRLzoo agents into various external training environments. To help reproduce the\nresults of SOTA algorithms, RLzoo provides rich reference DRL algorithm\nimplementations and effective hyper-parameter settings. Extensive evaluation\nresults show that RLzoo not only outperforms existing DRL libraries in its\nsimplicity of API design; but also provides the largest number of reference DRL\nalgorithm implementations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 06:18:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ding", "Zihan", ""], ["Yu", "Tianyang", ""], ["Huang", "Yanhua", ""], ["Zhang", "Hongming", ""], ["Mai", "Luo", ""], ["Dong", "Hao", ""]]}, {"id": "2009.08656", "submitter": "Zhaochong An", "authors": "Zhaochong An, Bozhou Chen, Houde Quan, Qihui Lin, Hongzhi Wang", "title": "EM-RBR: a reinforced framework for knowledge graph completion from\n  reasoning perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph completion aims to predict the new links in given entities\namong the knowledge graph (KG). Most mainstream embedding methods focus on fact\ntriplets contained in the given KG, however, ignoring the rich background\ninformation provided by logic rules driven from knowledge base implicitly. To\nsolve this problem, in this paper, we propose a general framework, named\nEM-RBR(embedding and rule-based reasoning), capable of combining the advantages\nof reasoning based on rules and the state-of-the-art models of embedding.\nEM-RBR aims to utilize relational background knowledge contained in rules to\nconduct multi-relation reasoning link prediction rather than superficial vector\ntriangle linkage in embedding models. By this way, we can explore relation\nbetween two entities in deeper context to achieve higher accuracy. In\nexperiments, we demonstrate that EM-RBR achieves better performance compared\nwith previous models on FB15k, WN18 and our new dataset FB15k-R, especially the\nnew dataset where our model perform futher better than those state-of-the-arts.\nWe make the implementation of EM-RBR available at\nhttps://github.com/1173710224/link-prediction-with-rule-based-reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:02:41 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 17:36:25 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["An", "Zhaochong", ""], ["Chen", "Bozhou", ""], ["Quan", "Houde", ""], ["Lin", "Qihui", ""], ["Wang", "Hongzhi", ""]]}, {"id": "2009.08666", "submitter": "Anirudh Joshi", "authors": "Anirudh Joshi, Namit Katariya, Xavier Amatriain, Anitha Kannan", "title": "Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting\n  Local Structures", "comments": "Accepted for publication in Findings of EMNLP at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a medical conversation between a patient and a physician poses\na unique natural language understanding challenge since it combines elements of\nstandard open ended conversation with very domain specific elements that\nrequire expertise and medical knowledge. Summarization of medical conversations\nis a particularly important aspect of medical conversation understanding since\nit addresses a very real need in medical practice: capturing the most important\naspects of a medical encounter so that they can be used for medical decision\nmaking and subsequent follow ups.\n  In this paper we present a novel approach to medical conversation\nsummarization that leverages the unique and independent local structures\ncreated when gathering a patient's medical history. Our approach is a variation\nof the pointer generator network where we introduce a penalty on the generator\ndistribution, and we explicitly model negations. The model also captures\nimportant properties of medical conversations such as medical knowledge coming\nfrom standardized medical ontologies better than when those concepts are\nintroduced explicitly. Through evaluation by doctors, we show that our approach\nis preferred on twice the number of summaries to the baseline pointer generator\nmodel and captures most or all of the information in 80% of the conversations\nmaking it a realistic alternative to costly manual summarization by medical\nexperts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:35:44 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Joshi", "Anirudh", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""], ["Kannan", "Anitha", ""]]}, {"id": "2009.08694", "submitter": "Kuldeep Singh", "authors": "Anson Bastos, Abhishek Nadgeri, Kuldeep Singh, Isaiah Onando Mulang',\n  Saeedeh Shekarpour, Johannes Hoffart, Manohar Kaul", "title": "RECON: Relation Extraction using Knowledge Graph Context in a Graph\n  Neural Network", "comments": "The Web Conference 2021 (WWW'21) full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel method named RECON, that automatically\nidentifies relations in a sentence (sentential relation extraction) and aligns\nto a knowledge graph (KG). RECON uses a graph neural network to learn\nrepresentations of both the sentence as well as facts stored in a KG, improving\nthe overall extraction quality. These facts, including entity attributes\n(label, alias, description, instance-of) and factual triples, have not been\ncollectively used in the state of the art methods. We evaluate the effect of\nvarious forms of representing the KG context on the performance of RECON. The\nempirical evaluation on two standard relation extraction datasets shows that\nRECON significantly outperforms all state of the art methods on NYT Freebase\nand Wikidata datasets. RECON reports 87.23 F1 score (Vs 82.29 baseline) on\nWikidata dataset whereas on NYT Freebase, reported values are 87.5(P@10) and\n74.1(P@30) compared to the previous baseline scores of 81.3(P@10) and\n63.1(P@30).\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:02:31 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 18:08:45 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bastos", "Anson", ""], ["Nadgeri", "Abhishek", ""], ["Singh", "Kuldeep", ""], ["Mulang'", "Isaiah Onando", ""], ["Shekarpour", "Saeedeh", ""], ["Hoffart", "Johannes", ""], ["Kaul", "Manohar", ""]]}, {"id": "2009.08696", "submitter": "Raul Montoliu", "authors": "Alejandro Estaben, C\\'esar D\\'iaz, Raul Montoliu, Diego\n  P\\'erez-Liebana", "title": "TotalBotWar: A New Pseudo Real-time Multi-action Game Challenge and\n  Competition for AI", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents TotalBotWar, a new pseudo real-time multi-action\nchallenge for game AI, as well as some initial experiments that benchmark the\nframework with different agents. The game is based on the real-time battles of\nthe popular TotalWar games series where players manage an army to defeat the\nopponent's one. In the proposed game, a turn consists of a set of orders to\ncontrol the units. The number and specific orders that can be performed in a\nturn vary during the progression of the game. One interesting feature of the\ngame is that if a particular unit does not receive an order in a turn, it will\ncontinue performing the action specified in a previous turn. The turn-wise\nbranching factor becomes overwhelming for traditional algorithms and the\npartial observability of the game state makes the proposed game an interesting\nplatform to test modern AI algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:13:56 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Estaben", "Alejandro", ""], ["D\u00edaz", "C\u00e9sar", ""], ["Montoliu", "Raul", ""], ["P\u00e9rez-Liebana", "Diego", ""]]}, {"id": "2009.08700", "submitter": "Sarah McDaid PhD", "authors": "Edward McDaid, Sarah McDaid", "title": "A Visual Language for Composable Inductive Programming", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Zoea Visual which is a visual programming language based on the\nZoea composable inductive programming language. Zoea Visual allows users to\ncreate software directly from a specification that resembles a set of\nfunctional test cases. Programming with Zoea Visual involves the definition of\na data flow model of test case inputs, optional intermediate values, and\noutputs. Data elements are represented visually and can be combined to create\nstructures of any complexity. Data flows between elements provide additional\ninformation that allows the Zoea compiler to generate larger programs in less\ntime. This paper includes an overview of the language. The benefits of the\napproach and some possible future enhancements are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:21:31 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["McDaid", "Edward", ""], ["McDaid", "Sarah", ""]]}, {"id": "2009.08720", "submitter": "Diego Marcos", "authors": "Diego Marcos, Ruth Fong, Sylvain Lobry, Remi Flamary, Nicolas Courty\n  and Devis Tuia", "title": "Contextual Semantic Interpretability", "comments": null, "journal-ref": "ACCV 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional neural networks (CNN) are known to learn an image\nrepresentation that captures concepts relevant to the task, but do so in an\nimplicit way that hampers model interpretability. However, one could argue that\nsuch a representation is hidden in the neurons and can be made explicit by\nteaching the model to recognize semantically interpretable attributes that are\npresent in the scene. We call such an intermediate layer a \\emph{semantic\nbottleneck}. Once the attributes are learned, they can be re-combined to reach\nthe final decision and provide both an accurate prediction and an explicit\nreasoning behind the CNN decision. In this paper, we look into semantic\nbottlenecks that capture context: we want attributes to be in groups of a few\nmeaningful elements and participate jointly to the final decision. We use a\ntwo-layer semantic bottleneck that gathers attributes into interpretable,\nsparse groups, allowing them contribute differently to the final output\ndepending on the context. We test our contextual semantic interpretable\nbottleneck (CSIB) on the task of landscape scenicness estimation and train the\nsemantic interpretable bottleneck using an auxiliary database (SUN Attributes).\nOur model yields in predictions as accurate as a non-interpretable baseline\nwhen applied to a real-world test set of Flickr images, all while providing\nclear and interpretable explanations for each prediction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:47:05 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Marcos", "Diego", ""], ["Fong", "Ruth", ""], ["Lobry", "Sylvain", ""], ["Flamary", "Remi", ""], ["Courty", "Nicolas", ""], ["Tuia", "Devis", ""]]}, {"id": "2009.08770", "submitter": "Bishwamittra Ghosh", "authors": "Daniel Neider and Bishwamittra Ghosh", "title": "Probably Approximately Correct Explanations of Machine Learning Models\n  via Syntax-Guided Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to understanding the decision making of complex\nmachine learning models (e.g., deep neural networks) using a combination of\nprobably approximately correct learning (PAC) and a logic inference methodology\ncalled syntax-guided synthesis (SyGuS). We prove that our framework produces\nexplanations that with a high probability make only few errors and show\nempirically that it is effective in generating small, human-interpretable\nexplanations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:10:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Neider", "Daniel", ""], ["Ghosh", "Bishwamittra", ""]]}, {"id": "2009.08776", "submitter": "Mariela Morveli-Espinoza", "authors": "Mariela Morveli-Espinoza, Juan Carlos Nieves, Ayslan Trevizan\n  Possebom, and Cesar Augusto Tacla", "title": "Dealing with Incompatibilities among Procedural Goals under Uncertainty", "comments": "14 pages, 4 figures, accepted in the Iberoamerican Journal of\n  Artificial Intelligence. arXiv admin note: substantial text overlap with\n  arXiv:2009.05186", "journal-ref": null, "doi": "10.4114/intartif.vol22iss64pp47-62", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  By considering rational agents, we focus on the problem of selecting goals\nout of a set of incompatible ones. We consider three forms of incompatibility\nintroduced by Castelfranchi and Paglieri, namely the terminal, the instrumental\n(or based on resources), and the superfluity. We represent the agent's plans by\nmeans of structured arguments whose premises are pervaded with uncertainty. We\nmeasure the strength of these arguments in order to determine the set of\ncompatible goals. We propose two novel ways for calculating the strength of\nthese arguments, depending on the kind of incompatibility that exists between\nthem. The first one is the logical strength value, it is denoted by a\nthree-dimensional vector, which is calculated from a probabilistic interval\nassociated with each argument. The vector represents the precision of the\ninterval, the location of it, and the combination of precision and location.\nThis type of representation and treatment of the strength of a structured\nargument has not been defined before by the state of the art. The second way\nfor calculating the strength of the argument is based on the cost of the plans\n(regarding the necessary resources) and the preference of the goals associated\nwith the plans. Considering our novel approach for measuring the strength of\nstructured arguments, we propose a semantics for the selection of plans and\ngoals that is based on Dung's abstract argumentation theory. Finally, we make a\ntheoretical evaluation of our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 00:56:45 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Morveli-Espinoza", "Mariela", ""], ["Nieves", "Juan Carlos", ""], ["Possebom", "Ayslan Trevizan", ""], ["Tacla", "Cesar Augusto", ""]]}, {"id": "2009.08791", "submitter": "Julie Bu Daher", "authors": "Julie Bu Daher, Armelle Brun and Anne Boyer", "title": "Multi-source Data Mining for e-Learning", "comments": null, "journal-ref": "7th International Symposium \"From Data to Models and Back\n  (DataMod)\" 2018 Jun 25", "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining is the task of discovering interesting, unexpected or valuable\nstructures in large datasets and transforming them into an understandable\nstructure for further use . Different approaches in the domain of data mining\nhave been proposed, among which pattern mining is the most important one.\nPattern mining mining involves extracting interesting frequent patterns from\ndata. Pattern mining has grown to be a topic of high interest where it is used\nfor different purposes, for example, recommendations. Some of the most common\nchallenges in this domain include reducing the complexity of the process and\navoiding the redundancy within the patterns. So far, pattern mining has mainly\nfocused on the mining of a single data source. However, with the increase in\nthe amount of data, in terms of volume, diversity of sources and nature of\ndata, mining multi-source and heterogeneous data has become an emerging\nchallenge in this domain. This challenge is the main focus of our work where we\npropose to mine multi-source data in order to extract interesting frequent\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:39:45 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Daher", "Julie Bu", ""], ["Brun", "Armelle", ""], ["Boyer", "Anne", ""]]}, {"id": "2009.08792", "submitter": "Thierry Deruyttere", "authors": "Thierry Deruyttere, Simon Vandenhende, Dusan Grujicic, Yu Liu, Luc Van\n  Gool, Matthew Blaschko, Tinne Tuytelaars, Marie-Francine Moens", "title": "Commands 4 Autonomous Vehicles (C4AV) Workshop Summary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of visual grounding requires locating the most relevant region or\nobject in an image, given a natural language query. So far, progress on this\ntask was mostly measured on curated datasets, which are not always\nrepresentative of human spoken language. In this work, we deviate from recent,\npopular task settings and consider the problem under an autonomous vehicle\nscenario. In particular, we consider a situation where passengers can give\nfree-form natural language commands to a vehicle which can be associated with\nan object in the street scene. To stimulate research on this topic, we have\norganized the \\emph{Commands for Autonomous Vehicles} (C4AV) challenge based on\nthe recent \\emph{Talk2Car} dataset (URL:\nhttps://www.aicrowd.com/challenges/eccv-2020-commands-4-autonomous-vehicles).\nThis paper presents the results of the challenge. First, we compare the used\nbenchmark against existing datasets for visual grounding. Second, we identify\nthe aspects that render top-performing models successful, and relate them to\nexisting state-of-the-art models for visual grounding, in addition to detecting\npotential failure cases by evaluating on carefully selected subsets. Finally,\nwe discuss several possibilities for future work.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 12:33:21 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Deruyttere", "Thierry", ""], ["Vandenhende", "Simon", ""], ["Grujicic", "Dusan", ""], ["Liu", "Yu", ""], ["Van Gool", "Luc", ""], ["Blaschko", "Matthew", ""], ["Tuytelaars", "Tinne", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2009.08801", "submitter": "Marco Anteghini", "authors": "Marco Anteghini, Jennifer D'Souza, Vitor A. P. Martins dos Santos,\n  S\\\"oren Auer", "title": "SciBERT-based Semantification of Bioassays in the Open Research\n  Knowledge Graph", "comments": "In proceedings of the '22nd International Conference on Knowledge\n  Engineering and Knowledge Management' 'Demo and Poster section'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a novel contribution to the problem of semantifying biological assays, in\nthis paper, we propose a neural-network-based approach to automatically\nsemantify, thereby structure, unstructured bioassay text descriptions.\nExperimental evaluations, to this end, show promise as the neural-based\nsemantification significantly outperforms a naive frequency-based baseline\napproach. Specifically, the neural method attains 72% F1 versus 47% F1 from the\nfrequency-based method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:36:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anteghini", "Marco", ""], ["D'Souza", "Jennifer", ""], ["Santos", "Vitor A. P. Martins dos", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2009.08807", "submitter": "Amit Surana", "authors": "Kunal Srivastava, Amit Surana", "title": "Monte Carlo Tree Search Based Tactical Maneuvering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the application of simultaneous move Monte Carlo\nTree Search (MCTS) based online framework for tactical maneuvering between two\nunmanned aircrafts. Compared to other techniques, MCTS enables efficient search\nover long horizons and uses self-play to select best maneuver in the current\nstate while accounting for the opponent aircraft tactics. We explore different\nalgorithmic choices in MCTS and demonstrate the framework numerically in a\nsimulated 2D tactical maneuvering application.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 02:03:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Srivastava", "Kunal", ""], ["Surana", "Amit", ""]]}, {"id": "2009.08856", "submitter": "Sim\\'on C. Smith Dr", "authors": "Sim\\'on C. Smith and Subramanian Ramamoorthy", "title": "Counterfactual Explanation and Causal Inference in Service of Robustness\n  in Robot Control", "comments": "8 pages, 11 figures. To be published in the 10th IEEE International\n  Conference on Development and Learning (ICDL), Valparaiso, Chile", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an architecture for training generative models of counterfactual\nconditionals of the form, 'can we modify event A to cause B instead of C?',\nmotivated by applications in robot control. Using an 'adversarial training'\nparadigm, an image-based deep neural network model is trained to produce small\nand realistic modifications to an original image in order to cause user-defined\neffects. These modifications can be used in the design process of image-based\nrobust control - to determine the ability of the controller to return to a\nworking regime by modifications in the input space, rather than by adaptation.\nIn contrast to conventional control design approaches, where robustness is\nquantified in terms of the ability to reject noise, we explore the space of\ncounterfactuals that might cause a certain requirement to be violated, thus\nproposing an alternative model that might be more expressive in certain\nrobotics applications. So, we propose the generation of counterfactuals as an\napproach to explanation of black-box models and the envisioning of potential\nmovement paths in autonomous robotic control. Firstly, we demonstrate this\napproach in a set of classification tasks, using the well known MNIST and\nCelebFaces Attributes datasets. Then, addressing multi-dimensional regression,\nwe demonstrate our approach in a reaching task with a physical robot, and in a\nnavigation task with a robot in a digital twin simulation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:22:47 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 09:50:00 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Smith", "Sim\u00f3n C.", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2009.08869", "submitter": "Wajid Arshad Abbasi", "authors": "Wajid Arshad Abbasi, Syed Ali Abbas, Saiqa Andleeb", "title": "PANDA: Predicting the change in proteins binding affinity upon mutations\n  using sequence information", "comments": null, "journal-ref": "Journal of Bioinformatics and Computational Biology, 2021", "doi": "10.1142/S0219720021500153", "report-no": null, "categories": "q-bio.BM cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately determining a change in protein binding affinity upon mutations is\nimportant for the discovery and design of novel therapeutics and to assist\nmutagenesis studies. Determination of change in binding affinity upon mutations\nrequires sophisticated, expensive, and time-consuming wet-lab experiments that\ncan be aided with computational methods. Most of the computational prediction\ntechniques require protein structures that limit their applicability to protein\ncomplexes with known structures. In this work, we explore the sequence-based\nprediction of change in protein binding affinity upon mutation. We have used\nprotein sequence information instead of protein structures along with machine\nlearning techniques to accurately predict the change in protein binding\naffinity upon mutation. Our proposed sequence-based novel change in protein\nbinding affinity predictor called PANDA gives better accuracy than existing\nmethods over the same validation set as well as on an external independent test\ndataset. On an external test dataset, our proposed method gives a maximum\nPearson correlation coefficient of 0.52 in comparison to the state-of-the-art\nexisting protein structure-based method called MutaBind which gives a maximum\nPearson correlation coefficient of 0.59. Our proposed protein sequence-based\nmethod, to predict a change in binding affinity upon mutations, has wide\napplicability and comparable performance in comparison to existing protein\nstructure-based methods. A cloud-based webserver implementation of PANDA and\nits python code is available at\nhttps://sites.google.com/view/wajidarshad/software and\nhttps://github.com/wajidarshad/panda.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:12:25 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Abbasi", "Wajid Arshad", ""], ["Abbas", "Syed Ali", ""], ["Andleeb", "Saiqa", ""]]}, {"id": "2009.08880", "submitter": "Jakob Struye", "authors": "Jakob Struye, Kevin Mets, Steven Latr\\'e", "title": "HTMRL: Biologically Plausible Reinforcement Learning with Hierarchical\n  Temporal Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building Reinforcement Learning (RL) algorithms which are able to adapt to\ncontinuously evolving tasks is an open research challenge. One technology that\nis known to inherently handle such non-stationary input patterns well is\nHierarchical Temporal Memory (HTM), a general and biologically plausible\ncomputational model for the human neocortex. As the RL paradigm is inspired by\nhuman learning, HTM is a natural framework for an RL algorithm supporting\nnon-stationary environments. In this paper, we present HTMRL, the first\nstrictly HTM-based RL algorithm. We empirically and statistically show that\nHTMRL scales to many states and actions, and demonstrate that HTM's ability for\nadapting to changing patterns extends to RL. Specifically, HTMRL performs well\non a 10-armed bandit after 750 steps, but only needs a third of that to adapt\nto the bandit suddenly shuffling its arms. HTMRL is the first iteration of a\nnovel RL approach, with the potential of extending to a capable algorithm for\nMeta-RL.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:05:17 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Struye", "Jakob", ""], ["Mets", "Kevin", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "2009.08922", "submitter": "James Goodman", "authors": "James Goodman, Sebastian Risi, Simon Lucas", "title": "AI and Wargaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in Game AI has demonstrated that given enough data from human\ngameplay, or experience gained via simulations, machines can rival or surpass\nthe most skilled human players in classic games such as Go, or commercial\ncomputer games such as Starcraft. We review the current state-of-the-art\nthrough the lens of wargaming, and ask firstly what features of wargames\ndistinguish them from the usual AI testbeds, and secondly which recent AI\nadvances are best suited to address these wargame-specific features.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 16:39:54 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 08:40:57 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Goodman", "James", ""], ["Risi", "Sebastian", ""], ["Lucas", "Simon", ""]]}, {"id": "2009.08931", "submitter": "Parth Mahendra", "authors": "Parth Mahendra", "title": "Spatio-Temporal Activation Function To Map Complex Dynamical Systems", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the real world is governed by complex and chaotic dynamical systems.\nAll of these dynamical systems pose a challenge in modelling them using neural\nnetworks. Currently, reservoir computing, which is a subset of recurrent neural\nnetworks, is actively used to simulate complex dynamical systems. In this work,\na two dimensional activation function is proposed which includes an additional\ntemporal term to impart dynamic behaviour on its output. The inclusion of a\ntemporal term alters the fundamental nature of an activation function, it\nprovides capability to capture the complex dynamics of time series data without\nrelying on recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 23:08:25 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Mahendra", "Parth", ""]]}, {"id": "2009.08949", "submitter": "Yafei Xu", "authors": "Yafei Xu and Tian Xie and Yu Zhang", "title": "Boosting Retailer Revenue by Generated Optimized Combined Multiple\n  Digital Marketing Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Campaign is a frequently employed instrument in lifting up the GMV (Gross\nMerchandise Volume) of retailer in traditional marketing. As its counterpart in\nonline context, digital-marketing-campaign (DMC) has being trending in recent\nyears with the rapid development of the e-commerce. However, how to empower\nmassive sellers on the online retailing platform the capacity of applying\ncombined multiple digital marketing campaigns to boost their shops' revenue, is\nstill a novel topic. In this work, a comprehensive solution of generating\noptimized combined multiple DMCs is presented. Firstly, a potential\npersonalized DMC pool is generated for every retailer by a newly proposed\nneural network model, i.e. the DMCNet (Digital-Marketing-Campaign Net).\nSecondly, based on the sub-modular optimization theory and the DMC pool by\nDMCNet, the generated combined multiple DMCs are ranked with respect to their\nrevenue generation strength then the top three ranked campaigns are returned to\nthe sellers' back-end management system, so that retailers can set combined\nmultiple DMCs for their online shops just in one-shot. Real online A/B-test\nshows that with the integrated solution, sellers of the online retailing\nplatform increase their shops' GMVs with approximately 6$\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 14:42:15 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Xu", "Yafei", ""], ["Xie", "Tian", ""], ["Zhang", "Yu", ""]]}, {"id": "2009.08973", "submitter": "Lin Shao", "authors": "Lin Shao, Yifan You, Mengyuan Yan, Qingyun Sun, Jeannette Bohg", "title": "GRAC: Self-Guided and Self-Regularized Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) algorithms have successfully been\ndemonstrated on a range of challenging decision making and control tasks. One\ndominant component of recent deep reinforcement learning algorithms is the\ntarget network which mitigates the divergence when learning the Q function.\nHowever, target networks can slow down the learning process due to delayed\nfunction updates. Our main contribution in this work is a self-regularized\nTD-learning method to address divergence without requiring a target network.\nAdditionally, we propose a self-guided policy improvement method by combining\npolicy-gradient with zero-order optimization to search for actions associated\nwith higher Q-values in a broad neighborhood. This makes learning more robust\nto local noise in the Q function approximation and guides the updates of our\nactor network. Taken together, these components define GRAC, a novel\nself-guided and self-regularized actor critic algorithm. We evaluate GRAC on\nthe suite of OpenAI gym tasks, achieving or outperforming state of the art in\nevery environment tested.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:58:29 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 02:26:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shao", "Lin", ""], ["You", "Yifan", ""], ["Yan", "Mengyuan", ""], ["Sun", "Qingyun", ""], ["Bohg", "Jeannette", ""]]}, {"id": "2009.08978", "submitter": "Diego Antognini", "authors": "Milena Filipovic, Blagoj Mitrevski, Diego Antognini, Emma Lejal\n  Glaude, Boi Faltings, Claudiu Musat", "title": "Modeling Online Behavior in Recommender Systems: The Importance of\n  Temporal Context", "comments": "Under review. 8 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating online recommender system performance is notoriously difficult and\nthe discrepancy between the online and offline behaviors is typically not\naccounted for in offline evaluations. Recommender systems research tends to\nevaluate model performance on randomly sampled targets, yet the same systems\nare later used to predict user behavior sequentially from a fixed point in\ntime. This disparity permits weaknesses to go unnoticed until the model is\ndeployed in a production setting. We first demonstrate how omitting temporal\ncontext when evaluating recommender system performance leads to false\nconfidence. To overcome this, we propose an offline evaluation protocol\nmodeling the real-life use-case that simultaneously accounts for temporal\ncontext.\n  Next, we propose a training procedure to further embed the temporal context\nin existing models: we introduce it in a multi-objective approach to\ntraditionally time-unaware recommender systems. We confirm the advantage of\nadding a temporal objective via the proposed evaluation protocol. Finally, we\nvalidate that the Pareto Fronts obtained with the added objective dominate\nthose produced by state-of-the-art models that are only optimized for accuracy\non three real-world publicly available datasets. The results show that\nincluding our temporal objective can improve recall@20 by up to 20%.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:36:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Filipovic", "Milena", ""], ["Mitrevski", "Blagoj", ""], ["Antognini", "Diego", ""], ["Glaude", "Emma Lejal", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2009.09009", "submitter": "Vidya A. Chhabria", "authors": "Vidya A. Chhabria, Vipul Ahuja, Ashwath Prabhu, Nikhil Patil, Palkesh\n  Jain, and Sachin S. Sapatnekar", "title": "Thermal and IR Drop Analysis Using Convolutional Encoder-Decoder\n  Networks", "comments": "Accepted in ASP-DAC 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computationally expensive temperature and power grid analyses are required\nduring the design cycle to guide IC design. This paper employs encoder-decoder\nbased generative (EDGe) networks to map these analyses to fast and accurate\nimage-to-image and sequence-to-sequence translation tasks. The network takes a\npower map as input and outputs the corresponding temperature or IR drop map. We\npropose two networks: (i) ThermEDGe: a static and dynamic full-chip temperature\nestimator and (ii) IREDGe: a full-chip static IR drop predictor based on input\npower, power grid distribution, and power pad distribution patterns. The models\nare design-independent and must be trained just once for a particular\ntechnology and packaging solution. ThermEDGe and IREDGe are demonstrated to\nrapidly predict the on-chip temperature and IR drop contours in milliseconds\n(in contrast with commercial tools that require several hours or more) and\nprovide an average error of 0.6% and 0.008% respectively.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:29:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chhabria", "Vidya A.", ""], ["Ahuja", "Vipul", ""], ["Prabhu", "Ashwath", ""], ["Patil", "Nikhil", ""], ["Jain", "Palkesh", ""], ["Sapatnekar", "Sachin S.", ""]]}, {"id": "2009.09028", "submitter": "Kapil Ahuja", "authors": "Aditya A. Shastri, Kapil Ahuja, Milind B. Ratnaparkhe, and Yann Busnel", "title": "Probabilistically Sampled and Spectrally Clustered Plant Genotypes using\n  Phenotypic Characteristics", "comments": "16 Pages, 3 Figures, and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering genotypes based upon their phenotypic characteristics is used to\nobtain diverse sets of parents that are useful in their breeding programs. The\nHierarchical Clustering (HC) algorithm is the current standard in clustering of\nphenotypic data. This algorithm suffers from low accuracy and high\ncomputational complexity issues. To address the accuracy challenge, we propose\nthe use of Spectral Clustering (SC) algorithm. To make the algorithm\ncomputationally cheap, we propose using sampling, specifically, Pivotal\nSampling that is probability based. Since application of samplings to\nphenotypic data has not been explored much, for effective comparison, another\nsampling technique called Vector Quantization (VQ) is adapted for this data as\nwell. VQ has recently given promising results for genome data.\n  The novelty of our SC with Pivotal Sampling algorithm is in constructing the\ncrucial similarity matrix for the clustering algorithm and defining\nprobabilities for the sampling technique. Although our algorithm can be applied\nto any plant genotypes, we test it on the phenotypic data obtained from about\n2400 Soybean genotypes. SC with Pivotal Sampling achieves substantially more\naccuracy (in terms of Silhouette Values) than all the other proposed\ncompetitive clustering with sampling algorithms (i.e. SC with VQ, HC with\nPivotal Sampling, and HC with VQ). The complexities of our SC with Pivotal\nSampling algorithm and these three variants are almost same because of the\ninvolved sampling. In addition to this, SC with Pivotal Sampling outperforms\nthe standard HC algorithm in both accuracy and computational complexity. We\nexperimentally show that we are up to 45% more accurate than HC in terms of\nclustering accuracy. The computational complexity of our algorithm is more than\na magnitude lesser than HC.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:59:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Shastri", "Aditya A.", ""], ["Ahuja", "Kapil", ""], ["Ratnaparkhe", "Milind B.", ""], ["Busnel", "Yann", ""]]}, {"id": "2009.09031", "submitter": "YooJung Choi", "authors": "YooJung Choi, Meihua Dang, Guy Van den Broeck", "title": "Group Fairness by Probabilistic Modeling with Latent Fair Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are increasingly being used to make impactful\ndecisions such as loan applications and criminal justice risk assessments, and\nas such, ensuring fairness of these systems is critical. This is often\nchallenging as the labels in the data are biased. This paper studies learning\nfair probability distributions from biased data by explicitly modeling a latent\nvariable that represents a hidden, unbiased label. In particular, we aim to\nachieve demographic parity by enforcing certain independencies in the learned\nmodel. We also show that group fairness guarantees are meaningful only if the\ndistribution used to provide those guarantees indeed captures the real-world\ndata. In order to closely model the data distribution, we employ probabilistic\ncircuits, an expressive and tractable probabilistic model, and propose an\nalgorithm to learn them from incomplete data. We evaluate our approach on a\nsynthetic dataset in which observed labels indeed come from fair labels but\nwith added bias, and demonstrate that the fair labels are successfully\nretrieved. Moreover, we show on real-world datasets that our approach not only\nis a better model than existing methods of how the data was generated but also\nachieves competitive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:13:23 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 00:28:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Choi", "YooJung", ""], ["Dang", "Meihua", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2009.09051", "submitter": "Ian Fox", "authors": "Ian Fox, Joyce Lee, Rodica Pop-Busui, Jenna Wiens", "title": "Deep Reinforcement Learning for Closed-Loop Blood Glucose Control", "comments": "Accepted to MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People with type 1 diabetes (T1D) lack the ability to produce the insulin\ntheir bodies need. As a result, they must continually make decisions about how\nmuch insulin to self-administer to adequately control their blood glucose\nlevels. Longitudinal data streams captured from wearables, like continuous\nglucose monitors, can help these individuals manage their health, but currently\nthe majority of the decision burden remains on the user. To relieve this\nburden, researchers are working on closed-loop solutions that combine a\ncontinuous glucose monitor and an insulin pump with a control algorithm in an\n`artificial pancreas.' Such systems aim to estimate and deliver the appropriate\namount of insulin. Here, we develop reinforcement learning (RL) techniques for\nautomated blood glucose control. Through a series of experiments, we compare\nthe performance of different deep RL approaches to non-RL approaches. We\nhighlight the flexibility of RL approaches, demonstrating how they can adapt to\nnew individuals with little additional data. On over 2.1 million hours of data\nfrom 30 simulated patients, our RL approach outperforms baseline control\nalgorithms: leading to a decrease in median glycemic risk of nearly 50% from\n8.34 to 4.24 and a decrease in total time hypoglycemic of 99.8%, from 4,610\ndays to 6. Moreover, these approaches are able to adapt to predictable meal\ntimes (decreasing average risk by an additional 24% as meals increase in\npredictability). This work demonstrates the potential of deep RL to help people\nwith T1D manage their blood glucose levels without requiring expert knowledge.\nAll of our code is publicly available, allowing for replication and extension.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 20:15:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Fox", "Ian", ""], ["Lee", "Joyce", ""], ["Pop-Busui", "Rodica", ""], ["Wiens", "Jenna", ""]]}, {"id": "2009.09068", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "Norbert B\\'atfai", "title": "Hacking with God: a Common Programming Language of Robopsychology and\n  Robophilosophy", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a sketch of how the concept of robopsychology and robophilosophy\ncould be reinterpreted and repositioned in the spirit of the original vocation\nof psychology and philosophy. The notion of the robopsychology as a fictional\nscience and a fictional occupation was introduced by Asimov in the middle of\nthe last century. The robophilosophy, on the other hand, is only a few years\nold today. But at this moment, none of these new emerging disciplines focus on\nthe fundamental and overall issues of the development of artificial general\nintelligence. Instead, they focus only on issues that, although are extremely\nimportant, play a complementary role, such as moral or ethical ones, rather\nthan the big questions of life. We try to outline a conception in which the\nrobophilosophy and robopsychology will be able to play a similar leading rule\nin the progress of artificial intelligence than the philosophy and psychology\nhave done in the progress of human intelligence. To facilitate this, we outline\nthe idea of a visual artificial language and interactive theorem prover-based\ncomputer application called Prime Convo Assistant. The question to be decided\nin the future is whether we can develop such an application. And if so, can we\nbuild a computer game on it, or even an esport game? It may be an interesting\nquestion in order for this game will be able to transform human thinking on the\nwidest possible social scale and will be able to develop a standard\nmathematical logic-based communication channel between human and machine\nintelligence.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:59:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["B\u00e1tfai", "Norbert", ""]]}, {"id": "2009.09070", "submitter": "Tim Friede", "authors": "Sarah Friedrich, Gerd Antes, Sigrid Behr, Harald Binder, Werner\n  Brannath, Florian Dumpert, Katja Ickstadt, Hans Kestler, Johannes Lederer,\n  Heinz Leitg\\\"ob, Markus Pauly, Ansgar Steland, Adalbert Wilhelm, Tim Friede", "title": "Is there a role for statistics in artificial intelligence?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on and application of artificial intelligence (AI) has triggered\na comprehensive scientific, economic, social and political discussion. Here we\nargue that statistics, as an interdisciplinary scientific field, plays a\nsubstantial role both for the theoretical and practical understanding of AI and\nfor its future development. Statistics might even be considered a core element\nof AI. With its specialist knowledge of data evaluation, starting with the\nprecise formulation of the research question and passing through a study design\nstage on to analysis and interpretation of the results, statistics is a natural\npartner for other disciplines in teaching, research and practice. This paper\naims at contributing to the current discussion by highlighting the relevance of\nstatistical methodology in the context of AI development. In particular, we\ndiscuss contributions of statistics to the field of artificial intelligence\nconcerning methodological development, planning and design of studies,\nassessment of data quality and data collection, differentiation of causality\nand associations and assessment of uncertainty in results. Moreover, the paper\nalso deals with the equally necessary and meaningful extension of curricula in\nschools and universities.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 14:39:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Friedrich", "Sarah", ""], ["Antes", "Gerd", ""], ["Behr", "Sigrid", ""], ["Binder", "Harald", ""], ["Brannath", "Werner", ""], ["Dumpert", "Florian", ""], ["Ickstadt", "Katja", ""], ["Kestler", "Hans", ""], ["Lederer", "Johannes", ""], ["Leitg\u00f6b", "Heinz", ""], ["Pauly", "Markus", ""], ["Steland", "Ansgar", ""], ["Wilhelm", "Adalbert", ""], ["Friede", "Tim", ""]]}, {"id": "2009.09072", "submitter": "Matthew Ross", "authors": "Blake VanBerlo, Matthew A. S. Ross, Jonathan Rivard and Ryan Booker", "title": "Interpretable Machine Learning Approaches to Prediction of Chronic\n  Homelessness", "comments": "14 pages, 7 figures, submitted to Engineering Applications of\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a machine learning approach to predict chronic homelessness from\nde-identified client shelter records drawn from a commonly used Canadian\nhomelessness management information system. Using a 30-day time step, a dataset\nfor 6521 individuals was generated. Our model, HIFIS-RNN-MLP, incorporates both\nstatic and dynamic features of a client's history to forecast chronic\nhomelessness 6 months into the client's future. The training method was\nfine-tuned to achieve a high F1-score, giving a desired balance between high\nrecall and precision. Mean recall and precision across 10-fold cross validation\nwere 0.921 and 0.651 respectively. An interpretability method was applied to\nexplain individual predictions and gain insight into the overall factors\ncontributing to chronic homelessness among the population studied. The model\nachieves state-of-the-art performance and improved stakeholder trust of what is\nusually a \"black box\" neural network model through interpretable AI.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:02:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["VanBerlo", "Blake", ""], ["Ross", "Matthew A. S.", ""], ["Rivard", "Jonathan", ""], ["Booker", "Ryan", ""]]}, {"id": "2009.09079", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Problems in AI research and how the SP System may help to solve them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes problems in AI research and how the SP System (described\nin an appendix) may help to solve them. Most of the problems are described by\nleading researchers in AI in interviews with science writer Martin Ford, and\nreported by him in his book {\\em Architects of Intelligence}. These problems\nare: the need to bridge the divide between symbolic and non-symbolic kinds of\nknowledge and processing; the tendency of deep neural networks (DNNs) to make\nlarge and unexpected errors in recognition; the need to strengthen the\nrepresentation and processing of natural languages; the challenges of\nunsupervised learning; the need for a coherent account of generalisation; how\nto learn usable knowledge from a single exposure; how to achieve transfer\nlearning; how to increase the efficiency of AI processing; the need for\ntransparency in AI structures and processes; how to achieve varieties of\nprobabilistic reasoning; the need for more emphasis on top-down strategies; how\nto minimise the risk of accidents with self-driving vehicles; the need for\nstrong compositionality in AI knowledge; the challenges of commonsense\nreasoning and commonsense knowledge; establishing the importance of information\ncompression in AI research; establishing the importance of a biological\nperspective in AI research; establishing whether knowledge in the brain is\nrepresented in `distributed' or `localist' form; how to bypassing the limited\nscope for adaptation in deep neural networks; the need to develop `broad AI';\nand how to eliminate the problem of catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:33:07 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:38:50 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 16:30:22 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "2009.09083", "submitter": "Martin Molina", "authors": "Martin Molina", "title": "What is an intelligent system?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of intelligent system has emerged in information technology as a\ntype of system derived from successful applications of artificial intelligence.\nThe goal of this paper is to give a general description of an intelligent\nsystem, which integrates previous approaches and takes into account recent\nadvances in artificial intelligence. The paper describes an intelligent system\nin a generic way, identifying its main properties and functional components,\nand presents some common categories. The presented description follows a\npractical approach to be used by system engineers. Its generality and its use\nis illustrated with real-world system examples and related with artificial\nintelligence methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:23:49 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Molina", "Martin", ""]]}, {"id": "2009.09086", "submitter": "Maulik Kamdar", "authors": "Maulik R. Kamdar, Michael Carroll, Will Dowling, Linda Wogulis, Cailey\n  Fitzgerald, Matt Corkum, Danielle Walsh, David Conrad, Craig E. Stanley, Jr.,\n  Steve Ross, Dru Henke, Mevan Samarasinghe", "title": "Focused Clinical Query Understanding and Retrieval of Medical Snippets\n  powered through a Healthcare Knowledge Graph", "comments": "Under Review as a Podium Talk at the AMIA Informatics Summit 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clinicians face several significant barriers to search and synthesize\naccurate, succinct, updated, and trustworthy medical information from several\nliterature sources during the practice of medicine and patient care. In this\ntalk, we will be presenting our research behind the development of a Focused\nClinical Search Service, powered by a Healthcare Knowledge Graph, to interpret\nthe query intent behind clinical search queries and retrieve relevant medical\nsnippets from a diverse corpus of medical literature.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:18:38 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamdar", "Maulik R.", ""], ["Carroll", "Michael", ""], ["Dowling", "Will", ""], ["Wogulis", "Linda", ""], ["Fitzgerald", "Cailey", ""], ["Corkum", "Matt", ""], ["Walsh", "Danielle", ""], ["Conrad", "David", ""], ["Stanley,", "Craig E.", "Jr."], ["Ross", "Steve", ""], ["Henke", "Dru", ""], ["Samarasinghe", "Mevan", ""]]}, {"id": "2009.09088", "submitter": "Rudresh Mishra", "authors": "Rudresh Mishra, Ricardo Rodriguez, Valentin Portillo", "title": "An AI based talent acquisition and benchmarking for job", "comments": "26 pages , 23 figures, This paper is yet to publish in conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a recruitment industry, selecting a best CV from a particular job post\nwithin a pile of thousand CV's is quite challenging. Finding a perfect\ncandidate for an organization who can be fit to work within organizational\nculture is a difficult task. In order to help the recruiters to fill these gaps\nwe leverage the help of AI. We propose a methodology to solve these problems by\nmatching the skill graph generated from CV and Job Post. In this report our\napproach is to perform the business understanding in order to justify why such\nproblems arise and how we intend to solve these problems using natural language\nprocessing and machine learning techniques. We limit our project only to solve\nthe problem in the domain of the computer science industry.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:57:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Rudresh", ""], ["Rodriguez", "Ricardo", ""], ["Portillo", "Valentin", ""]]}, {"id": "2009.09093", "submitter": "Runsheng Xu", "authors": "Runsheng Xu, Faezeh Tafazzoli, Li Zhang, Timo Rehfeld, Gunther Krehl,\n  Arunava Seal", "title": "Holistic Grid Fusion Based Stop Line Estimation", "comments": "Submitted to ICPR2020", "journal-ref": "2020 25th International Conference on Pattern Recognition (ICPR),\n  Milan, Italy, 2021 pp. 8400-8407", "doi": "10.1109/ICPR48806.2021.9413070", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intersection scenarios provide the most complex traffic situations in\nAutonomous Driving and Driving Assistance Systems. Knowing where to stop in\nadvance in an intersection is an essential parameter in controlling the\nlongitudinal velocity of the vehicle. Most of the existing methods in\nliterature solely use cameras to detect stop lines, which is typically not\nsufficient in terms of detection range. To address this issue, we propose a\nmethod that takes advantage of fused multi-sensory data including stereo camera\nand lidar as input and utilizes a carefully designed convolutional neural\nnetwork architecture to detect stop lines. Our experiments show that the\nproposed approach can improve detection range compared to camera data alone,\nworks under heavy occlusion without observing the ground markings explicitly,\nis able to predict stop lines for all lanes and allows detection at a distance\nup to 50 meters.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:29:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Xu", "Runsheng", ""], ["Tafazzoli", "Faezeh", ""], ["Zhang", "Li", ""], ["Rehfeld", "Timo", ""], ["Krehl", "Gunther", ""], ["Seal", "Arunava", ""]]}, {"id": "2009.09099", "submitter": "Anshuman Mishra", "authors": "Anshuman Mishra, Dhruvesh Patel, Aparna Vijayakumar, Xiang Li, Pavan\n  Kapanipathi, Kartik Talamadupula", "title": "Looking Beyond Sentence-Level Natural Language Inference for Downstream\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the Natural Language Inference (NLI) task has garnered\nsignificant attention, with new datasets and models achieving near human-level\nperformance on it. However, the full promise of NLI -- particularly that it\nlearns knowledge that should be generalizable to other downstream NLP tasks --\nhas not been realized. In this paper, we study this unfulfilled promise from\nthe lens of two downstream tasks: question answering (QA), and text\nsummarization. We conjecture that a key difference between the NLI datasets and\nthese downstream tasks concerns the length of the premise; and that creating\nnew long premise NLI datasets out of existing QA datasets is a promising avenue\nfor training a truly generalizable NLI model. We validate our conjecture by\nshowing competitive results on the task of QA and obtaining the best reported\nresults on the task of Checking Factual Correctness of Summaries.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:44:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Anshuman", ""], ["Patel", "Dhruvesh", ""], ["Vijayakumar", "Aparna", ""], ["Li", "Xiang", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2009.09123", "submitter": "Yuval Pinter", "authors": "Yuval Pinter, Cassandra L. Jacobs, Jacob Eisenstein", "title": "Will it Unblend?", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing systems often struggle with out-of-vocabulary\n(OOV) terms, which do not appear in training data. Blends, such as\n\"innoventor\", are one particularly challenging class of OOV, as they are formed\nby fusing together two or more bases that relate to the intended meaning in\nunpredictable manners and degrees. In this work, we run experiments on a novel\ndataset of English OOV blends to quantify the difficulty of interpreting the\nmeanings of blends by large-scale contextual language models such as BERT. We\nfirst show that BERT's processing of these blends does not fully access the\ncomponent meanings, leaving their contextual representations semantically\nimpoverished. We find this is mostly due to the loss of characters resulting\nfrom blend formation. Then, we assess how easily different models can recognize\nthe structure and recover the origin of blends, and find that context-aware\nembedding systems outperform character-level and context-free embeddings,\nalthough their results are still far from satisfactory.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 23:59:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pinter", "Yuval", ""], ["Jacobs", "Cassandra L.", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2009.09126", "submitter": "Kai Fan Dr", "authors": "Jiayi Wang, Ke Wang, Niyu Ge, Yangbing Shi, Yu Zhao, Kai Fan", "title": "Computer Assisted Translation with Neural Quality Estimation and\n  Automatic Post-Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of neural machine translation, there has been a marked shift\ntowards leveraging and consuming the machine translation results. However, the\ngap between machine translation systems and human translators needs to be\nmanually closed by post-editing. In this paper, we propose an end-to-end deep\nlearning framework of the quality estimation and automatic post-editing of the\nmachine translation output. Our goal is to provide error correction suggestions\nand to further relieve the burden of human translators through an interpretable\nmodel. To imitate the behavior of human translators, we design three efficient\ndelegation modules -- quality estimation, generative post-editing, and atomic\noperation post-editing and construct a hierarchical model based on them. We\nexamine this approach with the English--German dataset from WMT 2017 APE shared\ntask and our experimental results can achieve the state-of-the-art performance.\nWe also verify that the certified translators can significantly expedite their\npost-editing processing with our model in human evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 00:29:00 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 00:23:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Jiayi", ""], ["Wang", "Ke", ""], ["Ge", "Niyu", ""], ["Shi", "Yangbing", ""], ["Zhao", "Yu", ""], ["Fan", "Kai", ""]]}, {"id": "2009.09127", "submitter": "Kai Fan Dr", "authors": "Pei Zhang, Boxing Chen, Niyu Ge, Kai Fan", "title": "Long-Short Term Masking Transformer: A Simple but Effective Baseline for\n  Document-level Neural Machine Translation", "comments": "accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many document-level neural machine translation (NMT) systems have explored\nthe utility of context-aware architecture, usually requiring an increasing\nnumber of parameters and computational complexity. However, few attention is\npaid to the baseline model. In this paper, we research extensively the pros and\ncons of the standard transformer in document-level translation, and find that\nthe auto-regressive property can simultaneously bring both the advantage of the\nconsistency and the disadvantage of error accumulation. Therefore, we propose a\nsurprisingly simple long-short term masking self-attention on top of the\nstandard transformer to both effectively capture the long-range dependence and\nreduce the propagation of errors. We examine our approach on the two publicly\navailable document-level datasets. We can achieve a strong result in BLEU and\ncapture discourse phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 00:29:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhang", "Pei", ""], ["Chen", "Boxing", ""], ["Ge", "Niyu", ""], ["Fan", "Kai", ""]]}, {"id": "2009.09143", "submitter": "Sayyed Zahiri", "authors": "Yun Zhu, Sayyed M. Zahiri, Jiaqi Wang, Han-Yu Chen, Faizan Javed", "title": "Active Learning for Product Type Ontology Enhancement in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity-based semantic search has been widely adopted in modern search engines\nto improve search accuracy by understanding users' intent. In e-commerce, an\naccurate and complete product type (PT) ontology is essential for recognizing\nproduct entities in queries and retrieving relevant products from catalog.\nHowever, finding product types (PTs) to construct such an ontology is usually\nexpensive due to the considerable amount of human efforts it may involve. In\nthis work, we propose an active learning framework that efficiently utilizes\ndomain experts' knowledge for PT discovery. We also show the quality and\ncoverage of the resulting PTs in the experiment results.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:21:12 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 22:41:09 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Zhu", "Yun", ""], ["Zahiri", "Sayyed M.", ""], ["Wang", "Jiaqi", ""], ["Chen", "Han-Yu", ""], ["Javed", "Faizan", ""]]}, {"id": "2009.09153", "submitter": "David Krueger", "authors": "David Krueger, Tegan Maharaj, Jan Leike", "title": "Hidden Incentives for Auto-Induced Distributional Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decisions made by machine learning systems have increasing influence on the\nworld, yet it is common for machine learning algorithms to assume that no such\ninfluence exists. An example is the use of the i.i.d. assumption in content\nrecommendation. In fact, the (choice of) content displayed can change users'\nperceptions and preferences, or even drive them away, causing a shift in the\ndistribution of users. We introduce the term auto-induced distributional shift\n(ADS) to describe the phenomenon of an algorithm causing a change in the\ndistribution of its own inputs. Our goal is to ensure that machine learning\nsystems do not leverage ADS to increase performance when doing so could be\nundesirable. We demonstrate that changes to the learning algorithm, such as the\nintroduction of meta-learning, can cause hidden incentives for auto-induced\ndistributional shift (HI-ADS) to be revealed. To address this issue, we\nintroduce `unit tests' and a mitigation strategy for HI-ADS, as well as a toy\nenvironment for modelling real-world issues with HI-ADS in content\nrecommendation, where we demonstrate that strong meta-learners achieve gains in\nperformance via ADS. We show meta-learning and Q-learning both sometimes fail\nunit tests, but pass when using our mitigation strategy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:31:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Krueger", "David", ""], ["Maharaj", "Tegan", ""], ["Leike", "Jan", ""]]}, {"id": "2009.09158", "submitter": "EPTCS", "authors": "Francesco Ricca (University of Calabria), Alessandra Russo (Imperial\n  College London), Sergio Greco (University of Calabria), Nicola Leone\n  (University of Calabria), Alexander Artikis (University of Piraeus), Gerhard\n  Friedrich (Universit\\\"at Klagenfurt), Paul Fodor (Stony Brook University),\n  Angelika Kimmig (Cardiff University), Francesca Lisi (University of Bari Aldo\n  Moro), Marco Maratea (University of Genova), Alessandra Mileo (INSIGHT Centre\n  for Data Analytics), Fabrizio Riguzzi (Universit\\`a di Ferrara)", "title": "Proceedings 36th International Conference on Logic Programming\n  (Technical Communications)", "comments": null, "journal-ref": "EPTCS 325, 2020", "doi": "10.4204/EPTCS.325", "report-no": null, "categories": "cs.LO cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first conference held in Marseille in 1982, ICLP has been the\npremier international event for presenting research in logic programming.\nContributions are solicited in all areas of logic programming and related\nareas, including but not restricted to:\n  - Foundations: Semantics, Formalisms, Answer-Set Programming, Non-monotonic\nReasoning, Knowledge Representation.\n  - Declarative Programming: Inference engines, Analysis, Type and mode\ninference, Partial evaluation, Abstract interpretation, Transformation,\nValidation, Verification, Debugging, Profiling, Testing, Logic-based\ndomain-specific languages, constraint handling rules.\n  - Related Paradigms and Synergies: Inductive and Co-inductive Logic\nProgramming, Constraint Logic Programming, Interaction with SAT, SMT and CSP\nsolvers, Logic programming techniques for type inference and theorem proving,\nArgumentation, Probabilistic Logic Programming, Relations to object-oriented\nand Functional programming, Description logics, Neural-Symbolic Machine\nLearning, Hybrid Deep Learning and Symbolic Reasoning.\n  - Implementation: Concurrency and distribution, Objects, Coordination,\nMobility, Virtual machines, Compilation, Higher Order, Type systems, Modules,\nConstraint handling rules, Meta-programming, Foreign interfaces, User\ninterfaces.\n  - Applications: Databases, Big Data, Data Integration and Federation,\nSoftware Engineering, Natural Language Processing, Web and Semantic Web,\nAgents, Artificial Intelligence, Bioinformatics, Education, Computational life\nsciences, Education, Cybersecurity, and Robotics.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:18:41 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ricca", "Francesco", "", "University of Calabria"], ["Russo", "Alessandra", "", "Imperial\n  College London"], ["Greco", "Sergio", "", "University of Calabria"], ["Leone", "Nicola", "", "University of Calabria"], ["Artikis", "Alexander", "", "University of Piraeus"], ["Friedrich", "Gerhard", "", "Universit\u00e4t Klagenfurt"], ["Fodor", "Paul", "", "Stony Brook University"], ["Kimmig", "Angelika", "", "Cardiff University"], ["Lisi", "Francesca", "", "University of Bari Aldo\n  Moro"], ["Maratea", "Marco", "", "University of Genova"], ["Mileo", "Alessandra", "", "INSIGHT Centre\n  for Data Analytics"], ["Riguzzi", "Fabrizio", "", "Universit\u00e0 di Ferrara"]]}, {"id": "2009.09161", "submitter": "Chenguang Zhang", "authors": "Chenguang Zhang and Yuexian Hou and Dawei Song and Liangzhu Ge and\n  Yaoshuai Yao", "title": "Label-Based Diversity Measure Among Hidden Units of Deep Neural\n  Networks: A Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the deep structure guarantees the powerful expressivity of deep\nnetworks (DNNs), it also triggers serious overfitting problem. To improve the\ngeneralization capacity of DNNs, many strategies were developed to improve the\ndiversity among hidden units. However, most of these strategies are empirical\nand heuristic in absence of either a theoretical derivation of the diversity\nmeasure or a clear connection from the diversity to the generalization\ncapacity. In this paper, from an information theoretic perspective, we\nintroduce a new definition of redundancy to describe the diversity of hidden\nunits under supervised learning settings by formalizing the effect of hidden\nlayers on the generalization capacity as the mutual information. We prove an\nopposite relationship existing between the defined redundancy and the\ngeneralization capacity, i.e., the decrease of redundancy generally improving\nthe generalization capacity. The experiments show that the DNNs using the\nredundancy as the regularizer can effectively reduce the overfitting and\ndecrease the generalization error, which well supports above points.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:27:44 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 12:32:54 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Chenguang", ""], ["Hou", "Yuexian", ""], ["Song", "Dawei", ""], ["Ge", "Liangzhu", ""], ["Yao", "Yaoshuai", ""]]}, {"id": "2009.09191", "submitter": "Fanchao Qi", "authors": "Guoyang Zeng, Fanchao Qi, Qianrui Zhou, Tingji Zhang, Bairu Hou, Yuan\n  Zang, Zhiyuan Liu, Maosong Sun", "title": "OpenAttack: An Open-source Textual Adversarial Attack Toolkit", "comments": "Work in progress, 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Textual adversarial attacking has received wide and increasing attention in\nrecent years. Various attack models have been proposed, which are enormously\ndistinct and implemented with different programming frameworks and settings.\nThese facts hinder quick utilization and apt comparison of attack models. In\nthis paper, we present an open-source textual adversarial attack toolkit named\nOpenAttack. It currently builds in 12 typical attack models that cover all the\nattack types. Its highly inclusive modular design not only supports quick\nutilization of existing attack models, but also enables great flexibility and\nextensibility. OpenAttack has broad uses including comparing and evaluating\nattack models, measuring robustness of a victim model, assisting in developing\nnew attack models, and adversarial training. Source code, built-in models and\ndocumentation can be obtained at https://github.com/thunlp/OpenAttack.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:02:56 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zeng", "Guoyang", ""], ["Qi", "Fanchao", ""], ["Zhou", "Qianrui", ""], ["Zhang", "Tingji", ""], ["Hou", "Bairu", ""], ["Zang", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.09192", "submitter": "Fanchao Qi", "authors": "Yuan Zang, Bairu Hou, Fanchao Qi, Zhiyuan Liu, Xiaojun Meng, Maosong\n  Sun", "title": "Learning to Attack: Towards Textual Adversarial Attacking in Real-world\n  Situations", "comments": "work in progress, 10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacking aims to fool deep neural networks with adversarial\nexamples. In the field of natural language processing, various textual\nadversarial attack models have been proposed, varying in the accessibility to\nthe victim model. Among them, the attack models that only require the output of\nthe victim model are more fit for real-world situations of adversarial\nattacking. However, to achieve high attack performance, these models usually\nneed to query the victim model too many times, which is neither efficient nor\nviable in practice. To tackle this problem, we propose a reinforcement learning\nbased attack model, which can learn from attack history and launch attacks more\nefficiently. In experiments, we evaluate our model by attacking several\nstate-of-the-art models on the benchmark datasets of multiple tasks including\nsentiment analysis, text classification and natural language inference.\nExperimental results demonstrate that our model consistently achieves both\nbetter attack performance and higher efficiency than recently proposed baseline\nmethods. We also find our attack model can bring more robustness improvement to\nthe victim model by adversarial training. All the code and data of this paper\nwill be made public.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:12:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zang", "Yuan", ""], ["Hou", "Bairu", ""], ["Qi", "Fanchao", ""], ["Liu", "Zhiyuan", ""], ["Meng", "Xiaojun", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.09206", "submitter": "Ayush Mangal", "authors": "Ayush Mangal, Jitesh Jain, Keerat Kaur Guliani, Omkar Bhalerao", "title": "DEAP Cache: Deep Eviction Admission and Prefetching for Cache", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for learning policies to improve caching, target just one\nout of the prefetching, admission and eviction processes. In contrast, we\npropose an end to end pipeline to learn all three policies using machine\nlearning. We also take inspiration from the success of pretraining on large\ncorpora to learn specialized embeddings for the task. We model prefetching as a\nsequence prediction task based on past misses. Following previous works\nsuggesting that frequency and recency are the two orthogonal fundamental\nattributes for caching, we use an online reinforcement learning technique to\nlearn the optimal policy distribution between two orthogonal eviction\nstrategies based on them. While previous approaches used the past as an\nindicator of the future, we instead explicitly model the future frequency and\nrecency in a multi-task fashion with prefetching, leveraging the abilities of\ndeep networks to capture futuristic trends and use them for learning eviction\nand admission. We also model the distribution of the data in an online fashion\nusing Kernel Density Estimation in our approach, to deal with the problem of\ncaching non-stationary data. We present our approach as a \"proof of concept\" of\nlearning all three components of cache strategies using machine learning and\nleave improving practical deployment for future work.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 10:23:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mangal", "Ayush", ""], ["Jain", "Jitesh", ""], ["Guliani", "Keerat Kaur", ""], ["Bhalerao", "Omkar", ""]]}, {"id": "2009.09209", "submitter": "Kengo Machida", "authors": "Kengo Machida, Kuniaki Uto, Koichi Shinoda and Taiji Suzuki", "title": "MSR-DARTS: Minimum Stable Rank of Differentiable Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural architecture search (NAS), differentiable architecture search\n(DARTS) has recently attracted much attention due to its high efficiency. It\ndefines an over-parameterized network with mixed edges, each of which\nrepresents all operator candidates, and jointly optimizes the weights of the\nnetwork and its architecture in an alternating manner. However, this method\nfinds a model with the weights converging faster than the others, and such a\nmodel with fastest convergence often leads to overfitting. Accordingly, the\nresulting model cannot always be well-generalized. To overcome this problem, we\npropose a method called minimum stable rank DARTS (MSR-DARTS), for finding a\nmodel with the best generalization error by replacing architecture optimization\nwith the selection process using the minimum stable rank criterion.\nSpecifically, a convolution operator is represented by a matrix, and MSR-DARTS\nselects the one with the smallest stable rank. We evaluated MSR-DARTS on\nCIFAR-10 and ImageNet datasets. It achieves an error rate of 2.54% with 4.0M\nparameters within 0.3 GPU-days on CIFAR-10, and a top-1 error rate of 23.9% on\nImageNet. The official code is available at\nhttps://github.com/mtaecchhi/msrdarts.git.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 11:03:39 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 08:58:01 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Machida", "Kengo", ""], ["Uto", "Kuniaki", ""], ["Shinoda", "Koichi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "2009.09215", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Faster Smarter Induction in Isabelle/HOL", "comments": "This is the preprint of our paper of the same title, which is\n  accepted to IJCAI2021. For the formal proceeding, please refer to the\n  IJCAI2021 website", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proof by induction plays a critical role in formal verification and\nmathematics at large. However, its automation remains as one of the\nlong-standing challenges in Computer Science. To address this problem, we\ndeveloped sem_ind. Given inductive problem, sem_ind recommends what arguments\nto pass to the induct method. To improve the accuracy of sem_ind, we introduced\ndefinitional quantifiers, a new kind of quantifiers that allow us to\ninvestigate not only the syntactic structures of inductive problems but also\nthe definitions of relevant constants in a domain-agnostic style. Our\nevaluation shows that compared to its predecessor sem_ind improves the accuracy\nof recommendation from 20.1% to 38.2% for the most promising candidates within\n5.0 seconds of timeout while decreasing the median value of execution time from\n2.79 seconds to 1.06 seconds.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 11:51:54 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 09:05:41 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 09:41:12 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 07:58:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2009.09217", "submitter": "Luca Martino", "authors": "Luca Martino, Jesse Read", "title": "A Joint introduction to Gaussian Processes and Relevance Vector Machines\n  with Connections to Kalman filtering and other Kernel Smoothers", "comments": null, "journal-ref": "Information Fusion, Volume 74, Pages 17-38, 2021", "doi": "10.1016/j.inffus.2021.03.002", "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of Bayesian kernel-based methods has led them to become\nan important tool across many different facets of artificial intelligence, and\nuseful to a plethora of modern application domains, providing both power and\ninterpretability via uncertainty analysis. This article introduces and\ndiscusses two methods which straddle the areas of probabilistic Bayesian\nschemes and kernel methods for regression: Gaussian Processes and Relevance\nVector Machines. Our focus is on developing a common framework with which to\nview these methods, via intermediate methods a probabilistic version of the\nwell-known kernel ridge regression, and drawing connections among them, via\ndual formulations, and discussion of their application in the context of major\ntasks: regression, smoothing, interpolation, and filtering. Overall, we provide\nunderstanding of the mathematical concepts behind these models, and we\nsummarize and discuss in depth different interpretations and highlight the\nrelationship to other methods, such as linear kernel smoothers, Kalman\nfiltering and Fourier approximations. Throughout, we provide numerous figures\nto promote understanding, and we make numerous recommendations to\npractitioners. Benefits and drawbacks of the different techniques are\nhighlighted. To our knowledge, this is the most in-depth study of its kind to\ndate focused on these two methods, and will be relevant to theoretical\nunderstanding and practitioners throughout the domains of data-science, signal\nprocessing, machine learning, and artificial intelligence in general.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:22:41 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 20:03:15 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 17:02:30 GMT"}, {"version": "v4", "created": "Sun, 11 Jul 2021 19:28:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Martino", "Luca", ""], ["Read", "Jesse", ""]]}, {"id": "2009.09234", "submitter": "Richard Savery", "authors": "Richard Savery, Lisa Zahray, Gil Weinberg", "title": "Shimon the Rapper: A Real-Time System for Human-Robot Interactive Rap\n  Battles", "comments": "International Conference for Computational Creativity 2020, ICCC 20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for real-time lyrical improvisation between a human and a\nrobot in the style of hip hop. Our system takes vocal input from a human\nrapper, analyzes the semantic meaning, and generates a response that is rapped\nback by a robot over a musical groove. Previous work with real-time interactive\nmusic systems has largely focused on instrumental output, and vocal\ninteractions with robots have been explored, but not in a musical context. Our\ngenerative system includes custom methods for censorship, voice, rhythm,\nrhyming and a novel deep learning pipeline based on phoneme embeddings. The rap\nperformances are accompanied by synchronized robotic gestures and mouth\nmovements. Key technical challenges that were overcome in the system are\ndeveloping rhymes, performing with low-latency and dataset censorship. We\nevaluated several aspects of the system through a survey of videos and sample\ntext output. Analysis of comments showed that the overall perception of the\nsystem was positive. The model trained on our hip hop dataset was rated\nsignificantly higher than our metal dataset in coherence, rhyme quality, and\nenjoyment. Participants preferred outputs generated by a given input phrase\nover outputs generated from unknown keywords, indicating that the system\nsuccessfully relates its output to its input.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 14:04:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Savery", "Richard", ""], ["Zahray", "Lisa", ""], ["Weinberg", "Gil", ""]]}, {"id": "2009.09263", "submitter": "Bin Wang", "authors": "Bin Wang, Guangtao Wang, Jing Huang, Jiaxuan You, Jure Leskovec, C.-C.\n  Jay Kuo", "title": "Inductive Learning on Commonsense Knowledge Graph Completion", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge graph (CKG) is a special type of knowledge graph (KG),\nwhere entities are composed of free-form text. However, most existing CKG\ncompletion methods focus on the setting where all the entities are presented at\ntraining time. Although this setting is standard for conventional KG\ncompletion, it has limitations for CKG completion. At test time, entities in\nCKGs can be unseen because they may have unseen text/names and entities may be\ndisconnected from the training graph, since CKGs are generally very sparse.\nHere, we propose to study the inductive learning setting for CKG completion\nwhere unseen entities may present at test time. We develop a novel learning\nframework named InductivE. Different from previous approaches, InductiveE\nensures the inductive learning capability by directly computing entity\nembeddings from raw entity attributes/text. InductiveE consists of a free-text\nencoder, a graph encoder, and a KG completion decoder. Specifically, the\nfree-text encoder first extracts the textual representation of each entity\nbased on the pre-trained language model and word embedding. The graph encoder\nis a gated relational graph convolutional neural network that learns from a\ndensified graph for more informative entity representation learning. We develop\na method that densifies CKGs by adding edges among semantic-related entities\nand provide more supportive information for unseen entities, leading to better\ngeneralization ability of entity embedding for unseen entities. Finally,\ninductiveE employs Conv-TransE as the CKG completion decoder. Experimental\nresults show that InductiveE significantly outperforms state-of-the-art\nbaselines in both standard and inductive settings on ATOMIC and ConceptNet\nbenchmarks. InductivE performs especially well on inductive scenarios where it\nachieves above 48% improvement over present methods.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 16:10:26 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 19:48:13 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wang", "Bin", ""], ["Wang", "Guangtao", ""], ["Huang", "Jing", ""], ["You", "Jiaxuan", ""], ["Leskovec", "Jure", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2009.09266", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Humans learn too: Better Human-AI Interaction using Optimized Human\n  Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans rely more and more on systems with AI components. The AI community\ntypically treats human inputs as a given and optimizes AI models only. This\nthinking is one-sided and it neglects the fact that humans can learn, too. In\nthis work, human inputs are optimized for better interaction with an AI model\nwhile keeping the model fixed. The optimized inputs are accompanied by\ninstructions on how to create them. They allow humans to save time and cut on\nerrors, while keeping required changes to original inputs limited. We propose\ncontinuous and discrete optimization methods modifying samples in an iterative\nfashion. Our quantitative and qualitative evaluation including a human study on\ndifferent hand-generated inputs shows that the generated proposals lead to\nlower error rates, require less effort to create and differ only modestly from\nthe original samples.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 16:30:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "2009.09283", "submitter": "Kang Liu", "authors": "Kang Liu, Benjamin Tan, Siddharth Garg", "title": "Subverting Privacy-Preserving GANs: Hiding Secrets in Sanitized Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unprecedented data collection and sharing have exacerbated privacy concerns\nand led to increasing interest in privacy-preserving tools that remove\nsensitive attributes from images while maintaining useful information for other\ntasks. Currently, state-of-the-art approaches use privacy-preserving generative\nadversarial networks (PP-GANs) for this purpose, for instance, to enable\nreliable facial expression recognition without leaking users' identity.\nHowever, PP-GANs do not offer formal proofs of privacy and instead rely on\nexperimentally measuring information leakage using classification accuracy on\nthe sensitive attributes of deep learning (DL)-based discriminators. In this\nwork, we question the rigor of such checks by subverting existing\nprivacy-preserving GANs for facial expression recognition. We show that it is\npossible to hide the sensitive identification data in the sanitized output\nimages of such PP-GANs for later extraction, which can even allow for\nreconstruction of the entire input images, while satisfying privacy checks. We\ndemonstrate our approach via a PP-GAN-based architecture and provide\nqualitative and quantitative evaluations using two public datasets. Our\nexperimental results raise fundamental questions about the need for more\nrigorous privacy checks of PP-GANs, and we provide insights into the social\nimpact of these.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:02:17 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Garg", "Siddharth", ""]]}, {"id": "2009.09288", "submitter": "Mark Levin Sh.", "authors": "Mark Sh. Levin", "title": "On combinatorial optimization for dominating sets (literature survey,\n  new models)", "comments": "17 pages, figures 6, table 5", "journal-ref": null, "doi": "10.13140/RG.2.2.34919.68006", "report-no": null, "categories": "cs.DS cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper focuses on some versions of connected dominating set problems:\nbasic problems and multicriteria problems. A literature survey on basic problem\nformulations and solving approaches is presented. The basic connected\ndominating set problems are illustrated by simplifyed numerical examples. New\ninteger programming formulations of dominating set problems (with multiset\nestimates) are suggested.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:52:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Levin", "Mark Sh.", ""]]}, {"id": "2009.09300", "submitter": "Thyagharajan K K", "authors": "S. Kavitha, K.K. Thyagharajan", "title": "Features based Mammogram Image Classification using Weighted Feature\n  Support Vector Machine", "comments": "9 pages, 3 figures, \"submitted to International Conference on\n  Computing and Communication Systems\"", "journal-ref": "Vol. 270, 2012, 320-329", "doi": "10.1007/978-3-642-29216-3_35", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the existing research of mammogram image classification, either clinical\ndata or image features of a specific type is considered along with the\nsupervised classifiers such as Neural Network (NN) and Support Vector Machine\n(SVM). This paper considers automated classification of breast tissue type as\nbenign or malignant using Weighted Feature Support Vector Machine (WFSVM)\nthrough constructing the precomputed kernel function by assigning more weight\nto relevant features using the principle of maximizing deviations. Initially,\nMIAS dataset of mammogram images is divided into training and test set, then\nthe preprocessing techniques such as noise removal and background removal are\napplied to the input images and the Region of Interest (ROI) is identified. The\nstatistical features and texture features are extracted from the ROI and the\nclinical features are obtained directly from the dataset. The extracted\nfeatures of the training dataset are used to construct the weighted features\nand precomputed linear kernel for training the WFSVM, from which the training\nmodel file is created. Using this model file the kernel matrix of test samples\nis classified as benign or malignant. This analysis shows that the texture\nfeatures have resulted in better accuracy than the other features with WFSVM\nand SVM. However, the number of support vectors created in WFSVM is less than\nthe SVM classifier.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 21:28:31 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kavitha", "S.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.09308", "submitter": "Filipe Mutz", "authors": "Filipe Mutz, Thiago Oliveira-Santos, Avelino Forechi, Karin S. Komati,\n  Claudine Badue, Felipe M. G. Fran\\c{c}a, Alberto F. De Souza", "title": "What is the Best Grid-Map for Self-Driving Cars Localization? An\n  Evaluation under Diverse Types of Illumination, Traffic, and Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The localization of self-driving cars is needed for several tasks such as\nkeeping maps updated, tracking objects, and planning. Localization algorithms\noften take advantage of maps for estimating the car pose. Since maintaining and\nusing several maps is computationally expensive, it is important to analyze\nwhich type of map is more adequate for each application. In this work, we\nprovide data for such analysis by comparing the accuracy of a particle filter\nlocalization when using occupancy, reflectivity, color, or semantic grid maps.\nTo the best of our knowledge, such evaluation is missing in the literature. For\nbuilding semantic and colour grid maps, point clouds from a Light Detection and\nRanging (LiDAR) sensor are fused with images captured by a front-facing camera.\nSemantic information is extracted from images with a deep neural network.\nExperiments are performed in varied environments, under diverse conditions of\nillumination and traffic. Results show that occupancy grid maps lead to more\naccurate localization, followed by reflectivity grid maps. In most scenarios,\nthe localization with semantic grid maps kept the position tracking without\ncatastrophic losses, but with errors from 2 to 3 times bigger than the\nprevious. Colour grid maps led to inaccurate and unstable localization even\nusing a robust metric, the entropy correlation coefficient, for comparing\nonline data and the map.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 22:02:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mutz", "Filipe", ""], ["Oliveira-Santos", "Thiago", ""], ["Forechi", "Avelino", ""], ["Komati", "Karin S.", ""], ["Badue", "Claudine", ""], ["Fran\u00e7a", "Felipe M. G.", ""], ["De Souza", "Alberto F.", ""]]}, {"id": "2009.09318", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Maximilian Baader, Mislav Balunovi\\'c, Martin Vechev", "title": "Efficient Certification of Spatial Robustness", "comments": "Conference Paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has exposed the vulnerability of computer vision models to vector\nfield attacks. Due to the widespread usage of such models in safety-critical\napplications, it is crucial to quantify their robustness against such spatial\ntransformations. However, existing work only provides empirical robustness\nquantification against vector field deformations via adversarial attacks, which\nlack provable guarantees. In this work, we propose novel convex relaxations,\nenabling us, for the first time, to provide a certificate of robustness against\nvector field transformations. Our relaxations are model-agnostic and can be\nleveraged by a wide range of neural network verifiers. Experiments on various\nnetwork architectures and different datasets demonstrate the effectiveness and\nscalability of our method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:09:11 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:24:32 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ruoss", "Anian", ""], ["Baader", "Maximilian", ""], ["Balunovi\u0107", "Mislav", ""], ["Vechev", "Martin", ""]]}, {"id": "2009.09321", "submitter": "Vincent Lostanlen", "authors": "Christopher Ick and Vincent Lostanlen", "title": "Learning a Lie Algebra from Unlabeled Data Pairs", "comments": "2 pages, 1 figure. Presented at the first DeepMath conference, New\n  York City, NY, USA, November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional networks (convnets) show a remarkable ability to learn\ndisentangled representations. In recent years, the generalization of deep\nlearning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to\nbuild convnets over datasets with non-trivial symmetries, such as patterns over\nthe surface of a sphere. However, one limitation of this approach is the need\nto explicitly define the Lie group underlying the desired invariance property\nbefore training the convnet. Whereas rotations on the sphere have a well-known\nsymmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world\nfactors of variability. For example, the disentanglement of pitch, intensity\ndynamics, and playing technique remains a challenging task in music information\nretrieval.\n  This article proposes a machine learning method to discover a nonlinear\ntransformation of the space $\\mathbb{R}^n$ which maps a collection of\n$n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target\nvectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target\n$\\boldsymbol{y}_i$ by a matrix--vector product of the form\n$\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where\nthe matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of\n$\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in\n\\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i,\n\\boldsymbol{y}_i)$ and does not need to be known in advance.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 23:23:52 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 02:08:00 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 09:29:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ick", "Christopher", ""], ["Lostanlen", "Vincent", ""]]}, {"id": "2009.09333", "submitter": "Liming Zhang", "authors": "Liming Zhang, Liang Zhao, Dieter Pfoser", "title": "Factorized Deep Generative Models for Trajectory Generation with\n  Spatiotemporal-Validity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory data generation is an important domain that characterizes the\ngenerative process of mobility data. Traditional methods heavily rely on\npredefined heuristics and distributions and are weak in learning unknown\nmechanisms. Inspired by the success of deep generative neural networks for\nimages and texts, a fast-developing research topic is deep generative models\nfor trajectory data which can learn expressively explanatory models for\nsophisticated latent patterns. This is a nascent yet promising domain for many\napplications. We first propose novel deep generative models factorizing\ntime-variant and time-invariant latent variables that characterize global and\nlocal semantics, respectively. We then develop new inference strategies based\non variational inference and constrained optimization to encapsulate the\nspatiotemporal validity. New deep neural network architectures have been\ndeveloped to implement the inference and generation models with\nnewly-generalized latent variable priors. The proposed methods achieved\nsignificant improvements in quantitative and qualitative evaluations in\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:06:36 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhang", "Liming", ""], ["Zhao", "Liang", ""], ["Pfoser", "Dieter", ""]]}, {"id": "2009.09334", "submitter": "Hengameh Fakhravar", "authors": "Hengameh Fakhravar", "title": "Quantifying Uncertainty in Risk Assessment using Fuzzy Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk specialists are trying to understand risk better and use complex models\nfor risk assessment, while many risks are not yet well understood. The lack of\nempirical data and complex causal and outcome relationships make it difficult\nto estimate the degree to which certain risk types are exposed. Traditional\nrisk models are based on classical set theory. In comparison, fuzzy logic\nmodels are built on fuzzy set theory and are useful for analyzing risks with\ninsufficient knowledge or inaccurate data. Fuzzy logic systems help to make\nlarge-scale risk management frameworks more simple. For risks that do not have\nan appropriate probability model, a fuzzy logic system can help model the cause\nand effect relationships, assess the level of risk exposure, rank key risks in\na consistent way, and consider available data and experts'opinions. Besides, in\nfuzzy logic systems, some rules explicitly explain the connection, dependence,\nand relationships between model factors. This can help identify risk mitigation\nsolutions. Resources can be used to mitigate risks with very high levels of\nexposure and relatively low hedging costs. Fuzzy set and fuzzy logic models can\nbe used with Bayesian and other types of method recognition and decision\nmodels, including artificial neural networks and decision tree models. These\ndeveloped models have the potential to solve difficult risk assessment\nproblems. This research paper explores areas in which fuzzy logic models can be\nused to improve risk assessment and risk decision making. We will discuss the\nmethodology, framework, and process of using fuzzy logic systems in risk\nassessment.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:12:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Fakhravar", "Hengameh", ""]]}, {"id": "2009.09335", "submitter": "Kung-Hsiang Huang", "authors": "Kung-Hsiang Huang, Mu Yang, Nanyun Peng", "title": "Biomedical Event Extraction with Hierarchical Knowledge Graphs", "comments": "8 pages, 3 figures, Findings of EMNLP 2020 (short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical event extraction is critical in understanding biomolecular\ninteractions described in scientific corpus. One of the main challenges is to\nidentify nested structured events that are associated with non-indicative\ntrigger words. We propose to incorporate domain knowledge from Unified Medical\nLanguage System (UMLS) to a pre-trained language model via Graph\nEdge-conditioned Attention Networks (GEANet) and hierarchical graph\nrepresentation. To better recognize the trigger words, each sentence is first\ngrounded to a sentence graph based on a jointly modeled hierarchical knowledge\ngraph from UMLS. The grounded graphs are then propagated by GEANet, a novel\ngraph neural networks for enhanced capabilities in inferring complex events. On\nBioNLP 2011 GENIA Event Extraction task, our approach achieved 1.41% F1 and\n3.19% F1 improvements on all events and complex events, respectively. Ablation\nstudies confirm the importance of GEANet and hierarchical KG.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:25:05 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 18:09:50 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 16:38:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Huang", "Kung-Hsiang", ""], ["Yang", "Mu", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.09341", "submitter": "Justin Terry", "authors": "Justin K. Terry, Benjamin Black, Luis Santos", "title": "Multiplayer Support for the Arcade Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arcade Learning Environment (\"ALE\") is a widely used library in the\nreinforcement learning community that allows easy programmatic interfacing with\nAtari 2600 games, via the Stella emulator. We introduce a publicly available\nextension to the ALE that extends its support to multiplayer games and game\nmodes. This interface is additionally integrated with PettingZoo to allow for a\nsimple Gym-like interface in Python to interact with these games. We\nadditionally introduce experimental baselines for all environments included.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:19:12 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 22:21:57 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Terry", "Justin K.", ""], ["Black", "Benjamin", ""], ["Santos", "Luis", ""]]}, {"id": "2009.09347", "submitter": "Zhecheng Wang", "authors": "Mingxiang Chen, Qichang Chen, Lei Gao, Yilin Chen, Zhecheng Wang", "title": "Predicting Geographic Information with Neural Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework using neural cellular automata (NCA) to\nregenerate and predict geographic information. The model extends the idea of\nusing NCA to generate/regenerate a specific image by training the model with\nvarious geographic data, and thus, taking the traffic condition map as an\nexample, the model is able to predict traffic conditions by giving certain\ninduction information. Our research verified the analogy between NCA and gene\nin biology, while the innovation of the model significantly widens the boundary\nof possible applications based on NCAs. From our experimental results, the\nmodel shows great potentials in its usability and versatility which are not\navailable in previous studies. The code for model implementation is available\nat https://redacted.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 03:53:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Mingxiang", ""], ["Chen", "Qichang", ""], ["Gao", "Lei", ""], ["Chen", "Yilin", ""], ["Wang", "Zhecheng", ""]]}, {"id": "2009.09354", "submitter": "Ruturaj Raval", "authors": "Ruturaj Raval", "title": "An Improved Approach of Intention Discovery with Machine Learning for\n  POMDP-based Dialogue Management", "comments": "In addition to my thesis: https://scholar.uwindsor.ca/etd/7731/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An Embodied Conversational Agent (ECA) is an intelligent agent that works as\nthe front end of software applications to interact with users through\nverbal/nonverbal expressions and to provide online assistance without the\nlimits of time, location, and language. To help to improve the experience of\nhuman-computer interaction, there is an increasing need to empower ECA with not\nonly the realistic look of its human counterparts but also a higher level of\nintelligence. This thesis first highlights the main topics related to the\nconstruction of ECA, including different approaches of dialogue management, and\nthen discusses existing techniques of trend analysis for its application in\nuser classification. As a further refinement and enhancement to prior work on\nECA, this thesis research proposes a cohesive framework to integrate\nemotion-based facial animation with improved intention discovery. In addition,\na machine learning technique is introduced to support sentiment analysis for\nthe adjustment of policy design in POMDP-based dialogue management. The\nproposed research work is going to improve the accuracy of intention discovery\nwhile reducing the length of dialogues.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 05:28:36 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Raval", "Ruturaj", ""]]}, {"id": "2009.09355", "submitter": "Shyni Thomas", "authors": "Shyni Thomas and Dipti Deodhare and M.N. Murty", "title": "Multi Agent Path Finding with Awareness for Spatially Extended Agents", "comments": "Submitted to Expert Systems with Application 26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path finding problems involve identification of a plan for conflict free\nmovement of agents over a common road network. Most approaches to this problem\nhandle the agents as point objects, wherein the size of the agent is\nsignificantly smaller than the road on which it travels. In this paper, we\nconsider spatially extended agents which have a size comparable to the length\nof the road on which they travel. An optimal multi agent path finding approach\nfor spatially-extended agents was proposed in the eXtended Conflict Based\nSearch (XCBS) algorithm. As XCBS resolves only a pair of conflicts at a time,\nit results in deeper search trees in case of cascading or multiple (more than\ntwo agent) conflicts at a given location. This issue is addressed in eXtended\nConflict Based Search with Awareness (XCBS-A) in which an agent uses awareness\nof other agents' plans to make its own plan. In this paper, we explore XCBS-A\nin greater detail, we theoretically prove its completeness and empirically\ndemonstrate its performance with other algorithms in terms of variances in road\ncharacteristics, agent characteristics and plan characteristics. We demonstrate\nthe distributive nature of the algorithm by evaluating its performance when\ndistributed over multiple machines. XCBS-A generates a huge search space\nimpacting its efficiency in terms of memory; to address this we propose an\napproach for memory-efficiency and empirically demonstrate the performance of\nthe algorithm. The nature of XCBS-A is such that it may lead to suboptimal\nsolutions, hence the final contribution of this paper is an enhanced approach,\nXCBS-Local Awareness (XCBS-LA) which we prove will be optimal and complete.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 05:40:04 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Thomas", "Shyni", ""], ["Deodhare", "Dipti", ""], ["Murty", "M. N.", ""]]}, {"id": "2009.09372", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre and Atsushi Fujita", "title": "Softmax Tempering for Training Neural Machine Translation Models", "comments": "The paper is about prediction smoothing for improving sequence to\n  sequence performance. Related to but not the same as label smoothing. Work in\n  progress. Updates with deeper analyses and comparisons to related methods to\n  follow. Rejected from EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models are typically trained using a softmax\ncross-entropy loss where the softmax distribution is compared against smoothed\ngold labels. In low-resource scenarios, NMT models tend to over-fit because the\nsoftmax distribution quickly approaches the gold label distribution. To address\nthis issue, we propose to divide the logits by a temperature coefficient, prior\nto applying softmax, during training. In our experiments on 11 language pairs\nin the Asian Language Treebank dataset and the WMT 2019 English-to-German\ntranslation task, we observed significant improvements in translation quality\nby up to 3.9 BLEU points. Furthermore, softmax tempering makes the greedy\nsearch to be as good as beam search decoding in terms of translation quality,\nenabling 1.5 to 3.5 times speed-up. We also study the impact of softmax\ntempering on multilingual NMT and recurrently stacked NMT, both of which aim to\nreduce the NMT model size by parameter sharing thereby verifying the utility of\ntemperature in developing compact NMT models. Finally, an analysis of softmax\nentropies and gradients reveal the impact of our method on the internal\nbehavior of NMT models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:06:22 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""]]}, {"id": "2009.09378", "submitter": "Chujie Zheng", "authors": "Chujie Zheng, Yunbo Cao, Daxin Jiang, Minlie Huang", "title": "Difference-aware Knowledge Selection for Knowledge-grounded Conversation\n  Generation", "comments": "Accepted to Findings of EMNLP 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-turn knowledge-grounded dialog, the difference between the\nknowledge selected at different turns usually provides potential clues to\nknowledge selection, which has been largely neglected in previous research. In\nthis paper, we propose a difference-aware knowledge selection method. It first\ncomputes the difference between the candidate knowledge sentences provided at\nthe current turn and those chosen in the previous turns. Then, the differential\ninformation is fused with or disentangled from the contextual information to\nfacilitate final knowledge selection. Automatic, human observational, and\ninteractive evaluation shows that our method is able to select knowledge more\naccurately and generate more informative responses, significantly outperforming\nthe state-of-the-art baselines. The codes are available at\nhttps://github.com/chujiezheng/DiffKS.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:47:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zheng", "Chujie", ""], ["Cao", "Yunbo", ""], ["Jiang", "Daxin", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.09379", "submitter": "Leye Wang", "authors": "Leye Wang, Di Chai, Xuanzhe Liu, Liyue Chen, Kai Chen", "title": "Exploring the Generalizability of Spatio-Temporal Crowd Flow Prediction:\n  Meta-Modeling and an Analytic Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Spatio-Temporal Crowd Flow Prediction (STCFP) problem is a classical\nproblem with plenty of prior research efforts that benefit from traditional\nstatistical learning and recent deep learning approaches. While STCFP can refer\nto many real-world problems, most existing studies focus on quite specific\napplications, such as the prediction of taxi demand, ridesharing order, and so\non. This hinders the STCFP research as the approaches designed for different\napplications are hardly comparable, and thus how an applicationdriven approach\ncan be generalized to other scenarios is unclear. To fill in this gap, this\npaper makes two efforts: (i) we propose an analytic framework, called\nSTAnalytic, to qualitatively investigate STCFP approaches regarding their\ndesign considerations on various spatial and temporal factors, aiming to make\ndifferent application-driven approaches comparable; (ii) we construct an\nextensively large-scale STCFP benchmark datasets with four different scenarios\n(including ridesharing, bikesharing, metro, and electrical vehicle charging)\nwith up to hundreds of millions of flow records, to quantitatively measure the\ngeneralizability of STCFP approaches. Furthermore, to elaborate the\neffectiveness of STAnalytic in helping design generalizable STCFP approaches,\nwe propose a spatio-temporal meta-model, called STMeta, by integrating\ngeneralizable temporal and spatial knowledge identified by STAnalytic. We\nimplement three variants of STMeta with different deep learning techniques.\nWith the datasets, we demonstrate that STMeta variants can outperform\nstate-of-the-art STCFP approaches by 5%.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:50:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Leye", ""], ["Chai", "Di", ""], ["Liu", "Xuanzhe", ""], ["Chen", "Liyue", ""], ["Chen", "Kai", ""]]}, {"id": "2009.09405", "submitter": "Yaniv Benny", "authors": "Yaniv Benny, Niv Pekar, and Lior Wolf", "title": "Scale-Localized Abstract Reasoning", "comments": "Presented at Computer Vision and Pattern Recognition (CVPR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the abstract relational reasoning task, which is commonly used as\nan intelligence test. Since some patterns have spatial rationales, while others\nare only semantic, we propose a multi-scale architecture that processes each\nquery in multiple resolutions. We show that indeed different rules are solved\nby different resolutions and a combined multi-scale approach outperforms the\nexisting state of the art in this task on all benchmarks by 5-54%. The success\nof our method is shown to arise from multiple novelties. First, it searches for\nrelational patterns in multiple resolutions, which allows it to readily detect\nvisual relations, such as location, in higher resolution, while allowing the\nlower resolution module to focus on semantic relations, such as shape type.\nSecond, we optimize the reasoning network of each resolution proportionally to\nits performance, hereby we motivate each resolution to specialize on the rules\nfor which it performs better than the others and ignore cases that are already\nsolved by the other resolutions. Third, we propose a new way to pool\ninformation along the rows and the columns of the illustration-grid of the\nquery. Our work also analyses the existing benchmarks, demonstrating that the\nRAVEN dataset selects the negative examples in a way that is easily exploited.\nWe, therefore, propose a modified version of the RAVEN dataset, named\nRAVEN-FAIR. Our code and pretrained models are available at\nhttps://github.com/yanivbenny/MRNet.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 10:37:29 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 20:11:10 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Benny", "Yaniv", ""], ["Pekar", "Niv", ""], ["Wolf", "Lior", ""]]}, {"id": "2009.09422", "submitter": "Alfredo Braunstein", "authors": "Antoine Baker, Indaco Biazzo, Alfredo Braunstein, Giovanni Catania,\n  Luca Dall'Asta, Alessandro Ingrosso, Florent Krzakala, Fabio Mazza, Marc\n  M\\'ezard, Anna Paola Muntoni, Maria Refinetti, Stefano Sarao Mannelli, Lenka\n  Zdeborov\\'a", "title": "Epidemic mitigation by statistical inference from contact tracing data", "comments": "21 pages, 7 figures", "journal-ref": "PNAS 2021 Vol. 118 No. 32 e2106548118", "doi": "10.1073/pnas.2106548118", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-tracing is an essential tool in order to mitigate the impact of\npandemic such as the COVID-19. In order to achieve efficient and scalable\ncontact-tracing in real time, digital devices can play an important role. While\na lot of attention has been paid to analyzing the privacy and ethical risks of\nthe associated mobile applications, so far much less research has been devoted\nto optimizing their performance and assessing their impact on the mitigation of\nthe epidemic. We develop Bayesian inference methods to estimate the risk that\nan individual is infected. This inference is based on the list of his recent\ncontacts and their own risk levels, as well as personal information such as\nresults of tests or presence of syndromes. We propose to use probabilistic risk\nestimation in order to optimize testing and quarantining strategies for the\ncontrol of an epidemic. Our results show that in some range of epidemic\nspreading (typically when the manual tracing of all contacts of infected people\nbecomes practically impossible, but before the fraction of infected people\nreaches the scale where a lock-down becomes unavoidable), this inference of\nindividuals at risk could be an efficient way to mitigate the epidemic. Our\napproaches translate into fully distributed algorithms that only require\ncommunication between individuals who have recently been in contact. Such\ncommunication may be encrypted and anonymized and thus compatible with privacy\npreserving standards. We conclude that probabilistic risk estimation is capable\nto enhance performance of digital contact tracing and should be considered in\nthe currently developed mobile applications.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 12:24:45 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Baker", "Antoine", ""], ["Biazzo", "Indaco", ""], ["Braunstein", "Alfredo", ""], ["Catania", "Giovanni", ""], ["Dall'Asta", "Luca", ""], ["Ingrosso", "Alessandro", ""], ["Krzakala", "Florent", ""], ["Mazza", "Fabio", ""], ["M\u00e9zard", "Marc", ""], ["Muntoni", "Anna Paola", ""], ["Refinetti", "Maria", ""], ["Mannelli", "Stefano Sarao", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2009.09439", "submitter": "Hlynur Dav{\\i}{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Merlin Sch\\\"uler, Robin Schiewer, Tobias\n  Glasmachers, Laurenz Wiskott", "title": "Latent Representation Prediction Networks", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deeply-learned planning methods are often based on learning representations\nthat are optimized for unrelated tasks. For example, they might be trained on\nreconstructing the environment. These representations are then combined with\npredictor functions for simulating rollouts to navigate the environment. We\nfind this principle of learning representations unsatisfying and propose to\nlearn them such that they are directly optimized for the task at hand: to be\nmaximally predictable for the predictor function. This results in\nrepresentations that are by design optimal for the downstream task of planning,\nwhere the learned predictor function is used as a forward model.\n  To this end, we propose a new way of jointly learning this representation\nalong with the prediction function, a system we dub Latent Representation\nPrediction Network (LARP). The prediction function is used as a forward model\nfor search on a graph in a viewpoint-matching task and the representation\nlearned to maximize predictability is found to outperform a pre-trained\nrepresentation. Our approach is shown to be more sample-efficient than standard\nreinforcement learning methods and our learned representation transfers\nsuccessfully to dissimilar objects.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:26:03 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 13:42:06 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Sch\u00fcler", "Merlin", ""], ["Schiewer", "Robin", ""], ["Glasmachers", "Tobias", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2009.09443", "submitter": "Duc Nguyen", "authors": "Duc Nguyen, Phuoc Nguyen, Kien Do, Santu Rana, Sunil Gupta, Truyen\n  Tran", "title": "Unsupervised Anomaly Detection on Temporal Multiway Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal anomaly detection looks for irregularities over space-time.\nUnsupervised temporal models employed thus far typically work on sequences of\nfeature vectors, and much less on temporal multiway data. We focus our\ninvestigation on two-way data, in which a data matrix is observed at each time\nstep. Leveraging recent advances in matrix-native recurrent neural networks, we\ninvestigated strategies for data arrangement and unsupervised training for\ntemporal multiway anomaly detection. These include compressing-decompressing,\nencoding-predicting, and temporal data differencing. We conducted a\ncomprehensive suite of experiments to evaluate model behaviors under various\nsettings on synthetic data, moving digits, and ECG recordings. We found\ninteresting phenomena not previously reported. These include the capacity of\nthe compact matrix LSTM to compress noisy data near perfectly, making the\nstrategy of compressing-decompressing data ill-suited for anomaly detection\nunder the noise. Also, long sequence of vectors can be addressed directly by\nmatrix models that allow very long context and multiple step prediction.\nOverall, the encoding-predicting strategy works very well for the matrix LSTMs\nin the conducted experiments, thanks to its compactness and better fit to the\ndata dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:49:34 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nguyen", "Duc", ""], ["Nguyen", "Phuoc", ""], ["Do", "Kien", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Tran", "Truyen", ""]]}, {"id": "2009.09508", "submitter": "Pranav Garimidi", "authors": "Artem Baklanov, Pranav Garimidi, Vasilis Gkatzelis, Daniel Schoepflin", "title": "Achieving Proportionality up to the Maximin Item with Indivisible Goods", "comments": "Changes to wording throughout and changes to framing of section 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fairly allocating indivisible goods and focus on the\nclassic fairness notion of proportionality. The indivisibility of the goods is\nlong known to pose highly non-trivial obstacles to achieving fairness, and a\nvery vibrant line of research has aimed to circumvent them using appropriate\nnotions of approximate fairness. Recent work has established that even\napproximate versions of proportionality (PROPx) may be impossible to achieve\neven for small instances, while the best known achievable approximations\n(PROP1) are much weaker. We introduce the notion of proportionality up to the\nmaximin item (PROPm) and show how to reach an allocation satisfying this notion\nfor any instance involving up to five agents with additive valuations. PROPm\nprovides a well-motivated middle-ground between PROP1 and PROPx, while also\ncapturing some elements of the well-studied maximin share (MMS) benchmark:\nanother relaxation of proportionality that has attracted a lot of attention.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 19:21:19 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 16:32:34 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 17:31:04 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Baklanov", "Artem", ""], ["Garimidi", "Pranav", ""], ["Gkatzelis", "Vasilis", ""], ["Schoepflin", "Daniel", ""]]}, {"id": "2009.09538", "submitter": "Mengfan Xu", "authors": "Mengfan Xu and Diego Klabjan", "title": "Regret Bounds and Reinforcement Learning Exploration of EXP-based\n  Algorithms", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXP-based algorithms are often used for exploration in multi-armed bandit. We\nrevisit the EXP3.P algorithm and establish both the lower and upper bounds of\nregret in the Gaussian multi-armed bandit setting, as well as a more general\ndistribution option. The analyses do not require bounded rewards compared to\nclassical regret assumptions. We also extend EXP4 from multi-armed bandit to\nreinforcement learning to incentivize exploration by multiple agents. The\nresulting algorithm has been tested on hard-to-explore games and it shows an\nimprovement on exploration compared to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 22:31:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xu", "Mengfan", ""], ["Klabjan", "Diego", ""]]}, {"id": "2009.09571", "submitter": "Zhuangzhuang Zhang", "authors": "Zhuangzhuang Zhang, Tianyu Zhao, Hiram Gay, Baozhou Sun, and Weixiong\n  Zhang", "title": "Semi-supervised Semantic Segmentation of Prostate and Organs-at-Risk on\n  3D Pelvic CT Images", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated segmentation can assist radiotherapy treatment planning by saving\nmanual contouring efforts and reducing intra-observer and inter-observer\nvariations. The recent development of deep learning approaches has revoluted\nmedical data processing, including semantic segmentation, by dramatically\nimproving performance. However, training effective deep learning models usually\nrequire a large amount of high-quality labeled data, which are often costly to\ncollect. We developed a novel semi-supervised adversarial deep learning\napproach for 3D pelvic CT image semantic segmentation. Unlike supervised deep\nlearning methods, the new approach can utilize both annotated and un-annotated\ndata for training. It generates un-annotated synthetic data by a data\naugmentation scheme using generative adversarial networks (GANs). We applied\nthe new approach to segmenting multiple organs in male pelvic CT images, where\nCT images without annotations and GAN-synthesized un-annotated images were used\nin semi-supervised learning. Experimental results, evaluated by three metrics\n(Dice similarity coefficient, average Hausdorff distance, and average surface\nHausdorff distance), showed that the new method achieved either comparable\nperformance with substantially fewer annotated images or better performance\nwith the same amount of annotated data, outperforming the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 01:57:23 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 00:33:46 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 18:10:25 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Zhuangzhuang", ""], ["Zhao", "Tianyu", ""], ["Gay", "Hiram", ""], ["Sun", "Baozhou", ""], ["Zhang", "Weixiong", ""]]}, {"id": "2009.09575", "submitter": "Francisco Cruz", "authors": "Adam Bignold, Francisco Cruz, Richard Dazeley, Peter Vamplew, Cameron\n  Foale", "title": "Human Engagement Providing Evaluative and Informative Advice for\n  Interactive Reinforcement Learning", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is an approach used by intelligent agents to\nautonomously learn new skills. Although reinforcement learning has been\ndemonstrated to be an effective learning approach in several different\ncontexts, a common drawback exhibited is the time needed in order to\nsatisfactorily learn a task, especially in large state-action spaces. To\naddress this issue, interactive reinforcement learning proposes the use of\nexternally-sourced information in order to speed up the learning process. Up to\nnow, different information sources have been used to give advice to the learner\nagent, among them human-sourced advice. When interacting with a learner agent,\nhumans may provide either evaluative or informative advice. From the agent's\nperspective these styles of interaction are commonly referred to as\nreward-shaping and policy-shaping respectively. Evaluation requires the human\nto provide feedback on the prior action performed, while informative advice\nthey provide advice on the best action to select for a given situation. Prior\nresearch has focused on the effect of human-sourced advice on the interactive\nreinforcement learning process, specifically aiming to improve the learning\nspeed of the agent, while reducing the engagement with the human. This work\npresents an experimental setup for a human-trial designed to compare the\nmethods people use to deliver advice in term of human engagement. Obtained\nresults show that users giving informative advice to the learner agents provide\nmore accurate advice, are willing to assist the learner agent for a longer\ntime, and provide more advice per episode. Additionally, self-evaluation from\nparticipants using the informative approach has indicated that the agent's\nability to follow the advice is higher, and therefore, they feel their own\nadvice to be of higher accuracy when compared to people providing evaluative\nadvice.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:14:02 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bignold", "Adam", ""], ["Cruz", "Francisco", ""], ["Dazeley", "Richard", ""], ["Vamplew", "Peter", ""], ["Foale", "Cameron", ""]]}, {"id": "2009.09579", "submitter": "JaeSung Yoo", "authors": "Jaesung Yoo, Jeman Park, An Wang, David Mohaisen, and Joongheon Kim", "title": "On the Performance of Generative Adversarial Network (GAN) Variants: A\n  Clinical Data Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a useful type of Neural Networks in\nvarious types of applications including generative models and feature\nextraction. Various types of GANs are being researched with different insights,\nresulting in a diverse family of GANs with a better performance in each\ngeneration. This review focuses on various GANs categorized by their common\ntraits.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:18:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yoo", "Jaesung", ""], ["Park", "Jeman", ""], ["Wang", "An", ""], ["Mohaisen", "David", ""], ["Kim", "Joongheon", ""]]}, {"id": "2009.09590", "submitter": "Lirong Wu", "authors": "Lirong Wu, Zicheng Liu, Zelin Zang, Jun Xia, Siyuan Li, Stan. Z Li", "title": "Deep Clustering and Representation Learning with Geometric Structure\n  Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for Deep Clustering and\nmulti-manifold Representation Learning (DCRL) that preserves the geometric\nstructure of data. In the proposed framework, manifold clustering is done in\nthe latent space guided by a clustering loss. To overcome the problem that\nclustering-oriented losses may deteriorate the geometric structure of\nembeddings in the latent space, an isometric loss is proposed for preserving\nintra-manifold structure locally and a ranking loss for inter-manifold\nstructure globally. Experimental results on various datasets show that DCRL\nleads to performances comparable to current state-of-the-art deep clustering\nalgorithms, yet exhibits superior performance for manifold representation. Our\nresults also demonstrate the importance and effectiveness of the proposed\nlosses in preserving geometric structure in terms of visualization and\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:04:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 00:56:18 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 14:59:56 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Wu", "Lirong", ""], ["Liu", "Zicheng", ""], ["Zang", "Zelin", ""], ["Xia", "Jun", ""], ["Li", "Siyuan", ""], ["Li", "Stan. Z", ""]]}, {"id": "2009.09593", "submitter": "Junjie Wang", "authors": "Junjie Wang, Qichao Zhang, Dongbin Zhao, Mengchen Zhao, Jianye Hao", "title": "Dynamic Horizon Value Estimation for Model-based Reinforcement Learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing model-based value expansion methods typically leverage a world model\nfor value estimation with a fixed rollout horizon to assist policy learning.\nHowever, the fixed rollout with an inaccurate model has a potential to harm the\nlearning process. In this paper, we investigate the idea of using the model\nknowledge for value expansion adaptively. We propose a novel method called\nDynamic-horizon Model-based Value Expansion (DMVE) to adjust the world model\nusage with different rollout horizons. Inspired by reconstruction-based\ntechniques that can be applied for visual data novelty detection, we utilize a\nworld model with a reconstruction module for image feature extraction, in order\nto acquire more precise value estimation. The raw and the reconstructed images\nare both used to determine the appropriate horizon for adaptive value\nexpansion. On several benchmark visual control tasks, experimental results show\nthat DMVE outperforms all baselines in sample efficiency and final performance,\nindicating that DMVE can achieve more effective and accurate value estimation\nthan state-of-the-art model-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:09:33 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Junjie", ""], ["Zhang", "Qichao", ""], ["Zhao", "Dongbin", ""], ["Zhao", "Mengchen", ""], ["Hao", "Jianye", ""]]}, {"id": "2009.09595", "submitter": "Tamir Blum", "authors": "Tamir Blum, Gabin Paillet, Mickael Laine, Kazuya Yoshida", "title": "RL STaR Platform: Reinforcement Learning for Simulation based Training\n  of Robots", "comments": "3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising field to enhance robotic autonomy\nand decision making capabilities for space robotics, something which is\nchallenging with traditional techniques due to stochasticity and uncertainty\nwithin the environment. RL can be used to enable lunar cave exploration with\ninfrequent human feedback, faster and safer lunar surface locomotion or the\ncoordination and collaboration of multi-robot systems. However, there are many\nhurdles making research challenging for space robotic applications using RL and\nmachine learning, particularly due to insufficient resources for traditional\nrobotics simulators like CoppeliaSim. Our solution to this is an open source\nmodular platform called Reinforcement Learning for Simulation based Training of\nRobots, or RL STaR, that helps to simplify and accelerate the application of RL\nto the space robotics research field. This paper introduces the RL STaR\nplatform, and how researchers can use it through a demonstration.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:09:53 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Blum", "Tamir", ""], ["Paillet", "Gabin", ""], ["Laine", "Mickael", ""], ["Yoshida", "Kazuya", ""]]}, {"id": "2009.09609", "submitter": "Shamik Roy", "authors": "Shamik Roy, Dan Goldwasser", "title": "Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization\n  in News Media", "comments": "19 pages, 6 figures, Will appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest a minimally-supervised approach for identifying\nnuanced frames in news article coverage of politically divisive topics. We\nsuggest to break the broad policy frames suggested by Boydstun et al., 2014\ninto fine-grained subframes which can capture differences in political ideology\nin a better way. We evaluate the suggested subframes and their embedding,\nlearned using minimal supervision, over three topics, namely, immigration,\ngun-control and abortion. We demonstrate the ability of the subframes to\ncapture ideological differences and analyze political discourse in news media.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:29:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Roy", "Shamik", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2009.09654", "submitter": "Quanyu Long", "authors": "Quanyu Long, Mingxuan Wang, Lei Li", "title": "Generative Imagination Elevates Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are common semantics shared across text and images. Given a sentence in\na source language, whether depicting the visual scene helps translation into a\ntarget language? Existing multimodal neural machine translation methods (MNMT)\nrequire triplets of bilingual sentence - image for training and tuples of\nsource sentence - image for inference. In this paper, we propose ImagiT, a\nnovel machine translation method via visual imagination. ImagiT first learns to\ngenerate visual representation from the source sentence, and then utilizes both\nsource sentence and the \"imagined representation\" to produce a target\ntranslation. Unlike previous methods, it only needs the source sentence at the\ninference time. Experiments demonstrate that ImagiT benefits from visual\nimagination and significantly outperforms the text-only neural machine\ntranslation baselines. Further analysis reveals that the imagination process in\nImagiT helps fill in missing information when performing the degradation\nstrategy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:44:04 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 03:02:15 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Long", "Quanyu", ""], ["Wang", "Mingxuan", ""], ["Li", "Lei", ""]]}, {"id": "2009.09663", "submitter": "Yu Li", "authors": "Yu Li, Min Li, Bo Luo, Ye Tian, and Qiang Xu", "title": "DeepDyve: Dynamic Verification for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3372297.3423338", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become one of the enabling technologies in\nmany safety-critical applications, e.g., autonomous driving and medical image\nanalysis. DNN systems, however, suffer from various kinds of threats, such as\nadversarial example attacks and fault injection attacks. While there are many\ndefense methods proposed against maliciously crafted inputs, solutions against\nfaults presented in the DNN system itself (e.g., parameters and calculations)\nare far less explored. In this paper, we develop a novel lightweight\nfault-tolerant solution for DNN-based systems, namely DeepDyve, which employs\npre-trained neural networks that are far simpler and smaller than the original\nDNN for dynamic verification. The key to enabling such lightweight checking is\nthat the smaller neural network only needs to produce approximate results for\nthe initial task without sacrificing fault coverage much. We develop efficient\nand effective architecture and task exploration techniques to achieve optimized\nrisk/overhead trade-off in DeepDyve. Experimental results show that DeepDyve\ncan reduce 90% of the risks at around 10% overhead.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:58:18 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:00:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Yu", ""], ["Li", "Min", ""], ["Luo", "Bo", ""], ["Tian", "Ye", ""], ["Xu", "Qiang", ""]]}, {"id": "2009.09689", "submitter": "Neziha Akalin", "authors": "Neziha Akalin and Amy Loutfi", "title": "Reinforcement Learning Approaches in Social Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article surveys reinforcement learning approaches in social robotics.\nReinforcement learning is a framework for decision-making problems in which an\nagent interacts through trial-and-error with its environment to discover an\noptimal behavior. Since interaction is a key component in both reinforcement\nlearning and social robotics, it can be a well-suited approach for real-world\ninteractions with physically embodied social robots. The scope of the paper is\nfocused particularly on studies that include social physical robots and\nreal-world human-robot interactions with users. We present a thorough analysis\nof reinforcement learning approaches in social robotics. In addition to a\nsurvey, we categorize existent reinforcement learning approaches based on the\nused method and the design of the reward mechanisms. Moreover, since\ncommunication capability is a prominent feature of social robots, we discuss\nand group the papers based on the communication medium used for reward\nformulation. Considering the importance of designing the reward function, we\nalso provide a categorization of the papers based on the nature of the reward.\nThis categorization includes three major themes: interactive reinforcement\nlearning, intrinsically motivated methods, and task performance-driven methods.\nThe benefits and challenges of reinforcement learning in social robotics,\nevaluation methods of the papers regarding whether or not they use subjective\nand algorithmic measures, a discussion in the view of real-world reinforcement\nlearning challenges and proposed solutions, the points that remain to be\nexplored, including the approaches that have thus far received less attention\nis also given in the paper. Thus, this paper aims to become a starting point\nfor researchers interested in using and applying reinforcement learning methods\nin this particular research field.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:56:18 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:21:42 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 18:41:13 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 16:44:08 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Akalin", "Neziha", ""], ["Loutfi", "Amy", ""]]}, {"id": "2009.09696", "submitter": "Yash Satsangi", "authors": "Yash Satsangi, Shimon Whiteson, Frans A. Oliehoek, Matthijs T. J.\n  Spaan", "title": "Exploiting Submodular Value Functions For Scaling Up Active Perception", "comments": null, "journal-ref": "Autonomous Robot 42 2018. Original article available via Springer\n  journal open access:\n  https://link.springer.com/article/10.1007/s10514-017-9666-5", "doi": "10.1007/s10514-017-9666-5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In active perception tasks, an agent aims to select sensory actions that\nreduce its uncertainty about one or more hidden variables. While partially\nobservable Markov decision processes (POMDPs) provide a natural model for such\nproblems, reward functions that directly penalize uncertainty in the agent's\nbelief can remove the piecewise-linear and convex property of the value\nfunction required by most POMDP planners. Furthermore, as the number of sensors\navailable to the agent grows, the computational cost of POMDP planning grows\nexponentially with it, making POMDP planning infeasible with traditional\nmethods. In this article, we address a twofold challenge of modeling and\nplanning for active perception tasks. We show the mathematical equivalence of\n$\\rho$POMDP and POMDP-IR, two frameworks for modeling active perception tasks,\nthat restore the PWLC property of the value function. To efficiently plan for\nactive perception tasks, we identify and exploit the independence properties of\nPOMDP-IR to reduce the computational cost of solving POMDP-IR (and\n$\\rho$POMDP). We propose greedy point-based value iteration (PBVI), a new POMDP\nplanning method that uses greedy maximization to greatly improve scalability in\nthe action space of an active perception POMDP. Furthermore, we show that,\nunder certain conditions, including submodularity, the value function computed\nusing greedy PBVI is guaranteed to have bounded error with respect to the\noptimal value function. We establish the conditions under which the value\nfunction of an active perception POMDP is guaranteed to be submodular. Finally,\nwe present a detailed empirical analysis on a dataset collected from a\nmulti-camera tracking system employed in a shopping mall. Our method achieves\nsimilar performance to existing methods but at a fraction of the computational\ncost leading to better scalability for solving active perception tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:11:36 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Satsangi", "Yash", ""], ["Whiteson", "Shimon", ""], ["Oliehoek", "Frans A.", ""], ["Spaan", "Matthijs T. J.", ""]]}, {"id": "2009.09706", "submitter": "Johannes Dornheim", "authors": "Johannes Dornheim, Lukas Morand, Samuel Zeitvogel, Tarek Iraki,\n  Norbert Link, Dirk Helm", "title": "Deep Reinforcement Learning Methods for Structure-Guided Processing Path\n  Optimization", "comments": null, "journal-ref": "Journal of Intelligent Manufacturing (2021)", "doi": "10.1007/s10845-021-01805-z", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major goal of materials design is to find material structures with desired\nproperties and in a second step to find a processing path to reach one of these\nstructures. In this paper, we propose and investigate a deep reinforcement\nlearning approach for the optimization of processing paths. The goal is to find\noptimal processing paths in the material structure space that lead to\ntarget-structures, which have been identified beforehand to result in desired\nmaterial properties. There exists a target set containing one or multiple\ndifferent structures. Our proposed methods can find an optimal path from a\nstart structure to a single target structure, or optimize the processing paths\nto one of the equivalent target-structures in the set. In the latter case, the\nalgorithm learns during processing to simultaneously identify the best\nreachable target structure and the optimal path to it. The proposed methods\nbelong to the family of model-free deep reinforcement learning algorithms. They\nare guided by structure representations as features of the process state and by\na reward signal, which is formulated based on a distance function in the\nstructure space. Model-free reinforcement learning algorithms learn through\ntrial and error while interacting with the process. Thereby, they are not\nrestricted to information from a priori sampled processing data and are able to\nadapt to the specific process. The optimization itself is model-free and does\nnot require any prior knowledge about the process itself. We instantiate and\nevaluate the proposed methods by optimizing paths of a generic metal forming\nprocess. We show the ability of both methods to find processing paths leading\nclose to target structures and the ability of the extended method to identify\ntarget-structures that can be reached effectively and efficiently and to focus\non these targets for sample efficient processing path optimization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:20:24 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 10:47:15 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 12:55:49 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 23:00:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Dornheim", "Johannes", ""], ["Morand", "Lukas", ""], ["Zeitvogel", "Samuel", ""], ["Iraki", "Tarek", ""], ["Link", "Norbert", ""], ["Helm", "Dirk", ""]]}, {"id": "2009.09723", "submitter": "Stefano Teso", "authors": "Teodora Popordanoska, Mohit Kumar, Stefano Teso", "title": "Machine Guides, Human Supervises: Interactive Learning with Global\n  Explanations", "comments": "Preliminary version. Submitted to AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce explanatory guided learning (XGL), a novel interactive learning\nstrategy in which a machine guides a human supervisor toward selecting\ninformative examples for a classifier. The guidance is provided by means of\nglobal explanations, which summarize the classifier's behavior on different\nregions of the instance space and expose its flaws. Compared to other\nexplanatory interactive learning strategies, which are machine-initiated and\nrely on local explanations, XGL is designed to be robust against cases in which\nthe explanations supplied by the machine oversell the classifier's quality.\nMoreover, XGL leverages global explanations to open up the black-box of\nhuman-initiated interaction, enabling supervisors to select informative\nexamples that challenge the learned model. By drawing a link to interactive\nmachine teaching, we show theoretically that global explanations are a viable\napproach for guiding supervisors. Our simulations show that explanatory guided\nlearning avoids overselling the model's quality and performs comparably or\nbetter than machine- and human-initiated interactive learning strategies in\nterms of model quality.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:55:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Popordanoska", "Teodora", ""], ["Kumar", "Mohit", ""], ["Teso", "Stefano", ""]]}, {"id": "2009.09748", "submitter": "Resul Tugay", "authors": "Muhammet cakir, sule gunduz oguducu, resul tugay", "title": "A Deep Hybrid Model for Recommendation Systems", "comments": "International Conference of the Italian Association for Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation has been a long-standing problem in many areas ranging from\ne-commerce to social websites. Most current studies focus only on traditional\napproaches such as content-based or collaborative filtering while there are\nrelatively fewer studies in hybrid recommender systems. Due to the latest\nadvances of deep learning achieved in different fields including computer\nvision and natural language processing, deep learning has also gained much\nattention in Recommendation Systems. There are several studies that utilize ID\nembeddings of users and items to implement collaborative filtering with deep\nneural networks. However, such studies do not take advantage of other\ncategorical or continuous features of inputs. In this paper, we propose a new\ndeep neural network architecture which consists of not only ID embeddings but\nalso auxiliary information such as features of job postings and candidates for\njob recommendation system which is a reciprocal recommendation system.\nExperimental results on the dataset from a job-site show that the proposed\nmethod improves recommendation results over deep learning models utilizing ID\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:41:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["cakir", "Muhammet", ""], ["oguducu", "sule gunduz", ""], ["tugay", "resul", ""]]}, {"id": "2009.09756", "submitter": "Resul Tugay", "authors": "Resul Tugay, Sule Gunduz Oguducu", "title": "Demand Prediction Using Machine Learning Methods and Stacked\n  Generalization", "comments": "Proceedings of the 6th International Conference on Data Science,\n  Technology and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply and demand are two fundamental concepts of sellers and customers.\nPredicting demand accurately is critical for organizations in order to be able\nto make plans. In this paper, we propose a new approach for demand prediction\non an e-commerce web site. The proposed model differs from earlier models in\nseveral ways. The business model used in the e-commerce web site, for which the\nmodel is implemented, includes many sellers that sell the same product at the\nsame time at different prices where the company operates a market place model.\nThe demand prediction for such a model should consider the price of the same\nproduct sold by competing sellers along the features of these sellers. In this\nstudy we first applied different regression algorithms for specific set of\nproducts of one department of a company that is one of the most popular online\ne-commerce companies in Turkey. Then we used stacked generalization or also\nknown as stacking ensemble learning to predict demand. Finally, all the\napproaches are evaluated on a real world data set obtained from the e-commerce\ncompany. The experimental results show that some of the machine learning\nmethods do produce almost as good results as the stacked generalization method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:58:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tugay", "Resul", ""], ["Oguducu", "Sule Gunduz", ""]]}, {"id": "2009.09768", "submitter": "Santtu Tikka", "authors": "Santtu Tikka, Antti Hyttinen, Juha Karvanen", "title": "Identifying Causal Effects via Context-specific Independence Relations", "comments": "Appeared at 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect identification considers whether an interventional probability\ndistribution can be uniquely determined from a passively observed distribution\nin a given causal structure. If the generating system induces context-specific\nindependence (CSI) relations, the existing identification procedures and\ncriteria based on do-calculus are inherently incomplete. We show that deciding\ncausal effect non-identifiability is NP-hard in the presence of CSIs. Motivated\nby this, we design a calculus and an automated search procedure for identifying\ncausal effects in the presence of CSIs. The approach is provably sound and it\nincludes standard do-calculus as a special case. With the approach we can\nobtain identifying formulas that were unobtainable previously, and demonstrate\nthat a small number of CSI-relations may be sufficient to turn a previously\nnon-identifiable instance to identifiable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:38:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tikka", "Santtu", ""], ["Hyttinen", "Antti", ""], ["Karvanen", "Juha", ""]]}, {"id": "2009.09774", "submitter": "Tao Bai", "authors": "Jinqi Luo, Tao Bai, Jun Zhao", "title": "Generating Adversarial yet Inconspicuous Patches with a Single Image", "comments": "Accepted by AAAI2021 Student Abstract and Poster Program. Full paper\n  available as arXiv:2009.09774.v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown vulnerable toadversarial patches, where\nexotic patterns can resultin models wrong prediction. Nevertheless, existing\nap-proaches to adversarial patch generation hardly con-sider the contextual\nconsistency between patches andthe image background, causing such patches to be\neas-ily detected and adversarial attacks to fail. On the otherhand, these\nmethods require a large amount of data fortraining, which is computationally\nexpensive. To over-come these challenges, we propose an approach to gen-erate\nadversarial yet inconspicuous patches with onesingle image. In our approach,\nadversarial patches areproduced in a coarse-to-fine way with multiple scalesof\ngenerators and discriminators. Contextual informa-tion is encoded during the\nMin-Max training to makepatches consistent with surroundings. The selection\nofpatch location is based on the perceptual sensitivity ofvictim models.\nThrough extensive experiments, our ap-proach shows strong attacking ability in\nboth the white-box and black-box setting. Experiments on saliency de-tection\nand user evaluation indicate that our adversar-ial patches can evade human\nobservations, demonstratethe inconspicuousness of our approach. Lastly, we\nshowthat our approach preserves the attack ability in thephysical world.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:56:01 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 12:05:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Luo", "Jinqi", ""], ["Bai", "Tao", ""], ["Zhao", "Jun", ""]]}, {"id": "2009.09777", "submitter": "Nghi D. Q. Bui", "authors": "Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang", "title": "TreeCaps: Tree-Based Capsule Networks for Source Code Processing", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently program learning techniques have been proposed to process source\ncode based on syntactical structures (e.g., Abstract Syntax Trees) and/or\nsemantic information (e.g., Dependency Graphs). Although graphs may be better\nat capturing various viewpoints of code semantics than trees, constructing\ngraph inputs from code needs static code semantic analysis that may not be\naccurate and introduces noise during learning. Although syntax trees are\nprecisely defined according to the language grammar and easier to construct and\nprocess than graphs, previous tree-based learning techniques have not been able\nto learn semantic information from trees to achieve better accuracy than\ngraph-based techniques. We propose a new learning technique, named TreeCaps, by\nfusing together capsule networks with tree-based convolutional neural networks,\nto achieve learning accuracy higher than existing graph-based techniques while\nit is based only on trees. TreeCaps introduces novel variable-to-static routing\nalgorithms into the capsule networks to compensate for the loss of previous\nrouting algorithms. Aside from accuracy, we also find that TreeCaps is the most\nrobust to withstand those semantic-preserving program transformations that\nchange code syntax without modifying the semantics. Evaluated on a large number\nof Java and C/C++ programs, TreeCaps models outperform prior deep learning\nmodels of program source code, in terms of both accuracy and robustness for\nprogram comprehension tasks such as code functionality classification and\nfunction name prediction\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 16:37:19 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 20:43:17 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 10:05:39 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 15:12:16 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bui", "Nghi D. Q.", ""], ["Yu", "Yijun", ""], ["Jiang", "Lingxiao", ""]]}, {"id": "2009.09801", "submitter": "Michael Thomazo", "authors": "Meghyn Bienvenu (UB, CNRS, Bordeaux INP, LaBRI), Quentin Mani\\`ere\n  (UB, CNRS, Bordeaux INP, LaBRI), Micha\\\"el Thomazo (VALDA )", "title": "Answering Counting Queries over DL-Lite Ontologies", "comments": null, "journal-ref": "Twenty-Ninth International Joint Conference on Artificial\n  Intelligence (IJCAI 2020), 2020, Yokohama, Japan", "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology-mediated query answering (OMQA) is a promising approach to data\naccess and integration that has been actively studied in the knowledge\nrepresentation and database communities for more than a decade. The vast\nmajority of work on OMQA focuses on conjunctive queries, whereas more\nexpressive queries that feature counting or other forms of aggregation remain\nlargely unex-plored. In this paper, we introduce a general form of counting\nquery, relate it to previous proposals, and study the complexity of answering\nsuch queries in the presence of DL-Lite ontologies. As it follows from existing\nwork that query answering is intractable and often of high complexity, we\nconsider some practically relevant restrictions, for which we establish\nimproved complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 11:10:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bienvenu", "Meghyn", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Mani\u00e8re", "Quentin", "", "UB, CNRS, Bordeaux INP, LaBRI"], ["Thomazo", "Micha\u00ebl", "", "VALDA"]]}, {"id": "2009.09803", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Defending against substitute model black box adversarial attacks with\n  the 01 loss", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.07800;\n  text overlap with arXiv:2008.09148", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Substitute model black box attacks can create adversarial examples for a\ntarget model just by accessing its output labels. This poses a major challenge\nto machine learning models in practice, particularly in security sensitive\napplications. The 01 loss model is known to be more robust to outliers and\nnoise than convex models that are typically used in practice. Motivated by\nthese properties we present 01 loss linear and 01 loss dual layer neural\nnetwork models as a defense against transfer based substitute model black box\nattacks. We compare the accuracy of adversarial examples from substitute model\nblack box attacks targeting our 01 loss models and their convex counterparts\nfor binary classification on popular image benchmarks. Our 01 loss dual layer\nneural network has an adversarial accuracy of 66.2%, 58%, 60.5%, and 57% on\nMNIST, CIFAR10, STL10, and ImageNet respectively whereas the sigmoid activated\nlogistic loss counterpart has accuracies of 63.5%, 19.3%, 14.9%, and 27.6%.\nExcept for MNIST the convex counterparts have substantially lower adversarial\naccuracies. We show practical applications of our models to deter traffic sign\nand facial recognition adversarial attacks. On GTSRB street sign and CelebA\nfacial detection our 01 loss network has 34.6% and 37.1% adversarial accuracy\nrespectively whereas the convex logistic counterpart has accuracy 24% and 1.9%.\nFinally we show that our 01 loss network can attain robustness on par with\nsimple convolutional neural networks and much higher than its convex\ncounterpart even when attacked with a convolutional network substitute model.\nOur work shows that 01 loss models offer a powerful defense against substitute\nmodel black box attacks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 22:32:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2009.09806", "submitter": "Paolo Pareti Dr.", "authors": "Paolo Pareti and George Konstantinidis and Fabio Mogavero and Timothy\n  J. Norman", "title": "SHACL Satisfiability and Containment (Extended Paper)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Shapes Constraint Language (SHACL) is a recent W3C recommendation\nlanguage for validating RDF data. Specifically, SHACL documents are collections\nof constraints that enforce particular shapes on an RDF graph. Previous work on\nthe topic has provided theoretical and practical results for the validation\nproblem, but did not consider the standard decision problems of satisfiability\nand containment, which are crucial for verifying the feasibility of the\nconstraints and important for design and optimization purposes. In this paper,\nwe undertake a thorough study of different features of non-recursive SHACL by\nproviding a translation to a new first-order language, called SCL, that\nprecisely captures the semantics of SHACL w.r.t. satisfiability and\ncontainment. We study the interaction of SHACL features in this logic and\nprovide the detailed map of decidability and complexity results of the\naforementioned decision problems for different SHACL sublanguages. Notably, we\nprove that both problems are undecidable for the full language, but we present\ndecidable combinations of interesting features.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 14:52:03 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 10:55:19 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pareti", "Paolo", ""], ["Konstantinidis", "George", ""], ["Mogavero", "Fabio", ""], ["Norman", "Timothy J.", ""]]}, {"id": "2009.09815", "submitter": "Mahdi Azari", "authors": "M. Mahdi Azari, Atefeh Hajijamali Arani, Fernando Rosas", "title": "Mobile Cellular-Connected UAVs: Reinforcement Learning for Sky Limits", "comments": "Accepted to present at IEEE Globecom2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cellular-connected unmanned aerial vehicle (UAV)faces several key\nchallenges concerning connectivity and energy efficiency. Through a\nlearning-based strategy, we propose a general novel multi-armed bandit (MAB)\nalgorithm to reduce disconnectivity time, handover rate, and energy consumption\nof UAV by taking into account its time of task completion. By formulating the\nproblem as a function of UAV's velocity, we show how each of these performance\nindicators (PIs) is improved by adopting a proper range of corresponding\nlearning parameter, e.g. 50% reduction in HO rate as compared to a blind\nstrategy. However, results reveal that the optimal combination of the learning\nparameters depends critically on any specific application and the weights of\nPIs on the final objective function.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:35:23 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Azari", "M. Mahdi", ""], ["Arani", "Atefeh Hajijamali", ""], ["Rosas", "Fernando", ""]]}, {"id": "2009.09826", "submitter": "Hengjun Zhao", "authors": "Hengjun Zhao, Xia Zeng, Taolue Chen, Zhiming Liu and Jim Woodcock", "title": "Learning Safe Neural Network Controllers with Barrier Certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel approach to synthesize controllers for nonlinear\ncontinuous dynamical systems with control against safety properties. The\ncontrollers are based on neural networks (NNs). To certify the safety property\nwe utilize barrier functions, which are represented by NNs as well. We train\nthe controller-NN and barrier-NN simultaneously, achieving a\nverification-in-the-loop synthesis. We provide a prototype tool nncontroller\nwith a number of case studies. The experiment results confirm the feasibility\nand efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:55:55 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Hengjun", ""], ["Zeng", "Xia", ""], ["Chen", "Taolue", ""], ["Liu", "Zhiming", ""], ["Woodcock", "Jim", ""]]}, {"id": "2009.09828", "submitter": "Eric Bonjour", "authors": "Felipe Sanchez (ERPI), Davy Monticolo (ERPI), Eric Bonjour (ERPI),\n  Jean-Pierre Mica\\\"elli", "title": "Use of Bayesian Network characteristics to link project management\n  maturity and risk of project overcost", "comments": null, "journal-ref": "2018 14th International Conference on Signal-Image Technology &\n  Internet-Based Systems (SITIS), Nov 2018, Las Palmas de Gran Canaria, Spain.\n  pp.420-426", "doi": "10.1109/SITIS.2018.00071", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project management field has the imperative to increase the project\nprobability of success. Experts have developed several project management\nmaturity models to assets and improve the project outcome. However, the current\nliterature lacks of models allowing correlating the measured maturity and the\nexpected probability of success. This paper uses the characteristics of\nBayesian networks to formalize experts' knowledge and to extract knowledge from\na project overcost database. It develops a method to estimate the impact of\nproject management maturity on the risk of project overcost. A general\nframework is presented. An industrial case is used to illustrate the\napplication of the method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 08:00:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sanchez", "Felipe", "", "ERPI"], ["Monticolo", "Davy", "", "ERPI"], ["Bonjour", "Eric", "", "ERPI"], ["Mica\u00eblli", "Jean-Pierre", ""]]}, {"id": "2009.09841", "submitter": "Zifeng Wang", "authors": "Zifeng Wang, Rui Wen, Xi Chen, Shao-Lun Huang, Ningyu Zhang, Yefeng\n  Zheng", "title": "Finding Influential Instances for Distantly Supervised Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has been demonstrated to be highly beneficial to enhance\nrelation extraction models, but it often suffers from high label noise. In this\nwork, we propose a novel model-agnostic instance subsampling method for\ndistantly supervised relation extraction, namely REIF, which bridges the gap of\nrealizing influence subsampling in deep learning. It encompasses two key steps:\nfirst calculating instance-level influences that measure how much each training\ninstance contributes to the validation loss change of our model, then deriving\nsampling probabilities via the proposed sigmoid sampling function to perform\nbatch-in-bag sampling. We design a fast influence subsampling scheme that\nreduces the computational complexity from O(mn) to O(1), and analyze its\nrobustness when the sigmoid sampling function is employed. Empirical\nexperiments demonstrate our method's superiority over the baselines, and its\nability to support interpretable instance selection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:02:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Zifeng", ""], ["Wen", "Rui", ""], ["Chen", "Xi", ""], ["Huang", "Shao-Lun", ""], ["Zhang", "Ningyu", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.09847", "submitter": "Yongchao Huang Dr.", "authors": "Yongchao Huang, Hugh Miles, Pengfei Zhang", "title": "A Sequential Modelling Approach for Indoor Temperature Prediction and\n  Heating Control in Smart Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rising availability of large volume data, along with increasing computing\npower, has enabled a wide application of statistical Machine Learning (ML)\nalgorithms in the domains of Cyber-Physical Systems (CPS), Internet of Things\n(IoT) and Smart Building Networks (SBN). This paper proposes a learning-based\nframework for sequentially applying the data-driven statistical methods to\npredict indoor temperature and yields an algorithm for controlling building\nheating system accordingly. This framework consists of a two-stage modelling\neffort: in the first stage, an univariate time series model (AR) was employed\nto predict ambient conditions; together with other control variables, they\nserved as the input features for a second stage modelling where an multivariate\nML model (XGBoost) was deployed. The models were trained with real world data\nfrom building sensor network measurements, and used to predict future\ntemperature trajectories. Experimental results demonstrate the effectiveness of\nthe modelling approach and control algorithm, and reveal the promising\npotential of the mixed data-driven approach in smart building applications. By\nmaking wise use of IoT sensory data and ML algorithms, this work contributes to\nefficient energy management and sustainability in smart buildings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:20:27 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:43:39 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Huang", "Yongchao", ""], ["Miles", "Hugh", ""], ["Zhang", "Pengfei", ""]]}, {"id": "2009.09870", "submitter": "Seraphina Goldfarb-Tarrant", "authors": "Seraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph Weischedel,\n  Nanyun Peng", "title": "Content Planning for Neural Story Generation with Aristotelian Rescoring", "comments": "EMNLP 2020, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Long-form narrative text generated from large language models manages a\nfluent impersonation of human writing, but only at the local sentence level,\nand lacks structure or global cohesion. We posit that many of the problems of\nstory generation can be addressed via high-quality content planning, and\npresent a system that focuses on how to learn good plot structures to guide\nstory generation. We utilize a plot-generation language model along with an\nensemble of rescoring models that each implement an aspect of good\nstory-writing as detailed in Aristotle's Poetics. We find that stories written\nwith our more principled plot-structure are both more relevant to a given\nprompt and higher quality than baselines that do not content plan, or that plan\nin an unprincipled way.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:41:32 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:28:23 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Goldfarb-Tarrant", "Seraphina", ""], ["Chakrabarty", "Tuhin", ""], ["Weischedel", "Ralph", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.09879", "submitter": "Amina Gaber Abdelnabi", "authors": "Ahmed Sultan (WideBot), Mahmoud Salim (WideBot), Amina Gaber\n  (WideBot), Islam El Hosary (WideBot)", "title": "WESSA at SemEval-2020 Task 9: Code-Mixed Sentiment Analysis using\n  Transformers", "comments": "Proceedings of SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our system submitted for SemEval 2020 Task 9,\nSentiment Analysis for Code-Mixed Social Media Text alongside other\nexperiments. Our best performing system is a Transfer Learning-based model that\nfine-tunes \"XLM-RoBERTa\", a transformer-based multilingual masked language\nmodel, on monolingual English and Spanish data and Spanish-English code-mixed\ndata. Our system outperforms the official task baseline by achieving a 70.1%\naverage F1-Score on the official leaderboard using the test set. For later\nsubmissions, our system manages to achieve a 75.9% average F1-Score on the test\nset using CodaLab username \"ahmed0sultan\".\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:59:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sultan", "Ahmed", "", "WideBot"], ["Salim", "Mahmoud", "", "WideBot"], ["Gaber", "Amina", "", "WideBot"], ["Hosary", "Islam El", "", "WideBot"]]}, {"id": "2009.09926", "submitter": "Po Li", "authors": "Po Li, Lei Li, Yan Fu, Jun Rong, Yu Zhang", "title": "Cross-Modal Alignment with Mixture Experts Neural Network for\n  Intral-City Retail Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Cross-modal Alignment with mixture experts Neural\nNetwork (CameNN) recommendation model for intral-city retail industry, which\naims to provide fresh foods and groceries retailing within 5 hours delivery\nservice arising for the outbreak of Coronavirus disease (COVID-19) pandemic\naround the world. We propose CameNN, which is a multi-task model with three\ntasks including Image to Text Alignment (ITA) task, Text to Image Alignment\n(TIA) task and CVR prediction task. We use pre-trained BERT to generate the\ntext embedding and pre-trained InceptionV4 to generate image patch embedding\n(each image is split into small patches with the same pixels and treat each\npatch as an image token). Softmax gating networks follow to learn the weight of\neach transformer expert output and choose only a subset of experts conditioned\non the input. Then transformer encoder is applied as the share-bottom layer to\nlearn all input features' shared interaction. Next, mixture of transformer\nexperts (MoE) layer is implemented to model different aspects of tasks. At top\nof the MoE layer, we deploy a transformer layer for each task as task tower to\nlearn task-specific information. On the real word intra-city dataset,\nexperiments demonstrate CameNN outperform baselines and achieve significant\nimprovements on the image and text representation. In practice, we applied\nCameNN on CVR prediction in our intra-city recommender system which is one of\nthe leading intra-city platforms operated in China.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:36:52 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Po", ""], ["Li", "Lei", ""], ["Fu", "Yan", ""], ["Rong", "Jun", ""], ["Zhang", "Yu", ""]]}, {"id": "2009.09929", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Lorenzo Pellegrini, Pau Rodriguez, Massimo Caccia,\n  Qi She, Yu Chen, Quentin Jodelet, Ruiping Wang, Zheda Mai, David Vazquez,\n  German I. Parisi, Nikhil Churamani, Marc Pickett, Issam Laradji, Davide\n  Maltoni", "title": "CVPR 2020 Continual Learning in Computer Vision Competition: Approaches,\n  Results, Current Challenges and Future Directions", "comments": "Pre-print v1: 12 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, we have witnessed a renewed and fast-growing interest\nin continual learning with deep neural networks with the shared objective of\nmaking current AI systems more adaptive, efficient and autonomous. However,\ndespite the significant and undoubted progress of the field in addressing the\nissue of catastrophic forgetting, benchmarking different continual learning\napproaches is a difficult task by itself. In fact, given the proliferation of\ndifferent settings, training and evaluation protocols, metrics and\nnomenclature, it is often tricky to properly characterize a continual learning\nalgorithm, relate it to other solutions and gauge its real-world applicability.\nThe first Continual Learning in Computer Vision challenge held at CVPR in 2020\nhas been one of the first opportunities to evaluate different continual\nlearning algorithms on a common hardware with a large set of shared evaluation\nmetrics and 3 different settings based on the realistic CORe50 video benchmark.\nIn this paper, we report the main results of the competition, which counted\nmore than 79 teams registered, 11 finalists and 2300$ in prizes. We also\nsummarize the winning approaches, current challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:53:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Pellegrini", "Lorenzo", ""], ["Rodriguez", "Pau", ""], ["Caccia", "Massimo", ""], ["She", "Qi", ""], ["Chen", "Yu", ""], ["Jodelet", "Quentin", ""], ["Wang", "Ruiping", ""], ["Mai", "Zheda", ""], ["Vazquez", "David", ""], ["Parisi", "German I.", ""], ["Churamani", "Nikhil", ""], ["Pickett", "Marc", ""], ["Laradji", "Issam", ""], ["Maltoni", "Davide", ""]]}, {"id": "2009.09935", "submitter": "Christine Bauer", "authors": "Markus Schedl, Christine Bauer, Wolfgang Reisinger, Dominik Kowald,\n  Elisabeth Lex", "title": "Listener Modeling and Context-aware Music Recommendation Based on\n  Country Archetypes", "comments": "30 pages, 3 tables, 12 figures", "journal-ref": null, "doi": "10.3389/frai.2020.508725", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music preferences are strongly shaped by the cultural and socio-economic\nbackground of the listener, which is reflected, to a considerable extent, in\ncountry-specific music listening profiles. Previous work has already identified\nseveral country-specific differences in the popularity distribution of music\nartists listened to. In particular, what constitutes the \"music mainstream\"\nstrongly varies between countries. To complement and extend these results, the\narticle at hand delivers the following major contributions: First, using\nstate-of-the-art unsupervised learning techniques, we identify and thoroughly\ninvestigate (1) country profiles of music preferences on the fine-grained level\nof music tracks (in contrast to earlier work that relied on music preferences\non the artist level) and (2) country archetypes that subsume countries sharing\nsimilar patterns of listening preferences. Second, we formulate four user\nmodels that leverage the user's country information on music preferences. Among\nothers, we propose a user modeling approach to describe a music listener as a\nvector of similarities over the identified country clusters or archetypes.\nThird, we propose a context-aware music recommendation system that leverages\nimplicit user feedback, where context is defined via the four user models. More\nprecisely, it is a multi-layer generative model based on a variational\nautoencoder, in which contextual features can influence recommendations through\na gating mechanism. Fourth, we thoroughly evaluate the proposed recommendation\nsystem and user models on a real-world corpus of more than one billion\nlistening records of users around the world (out of which we use 369 million in\nour experiments) and show its merits vis-a-vis state-of-the-art algorithms that\ndo not exploit this type of context information.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:59:04 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Schedl", "Markus", ""], ["Bauer", "Christine", ""], ["Reisinger", "Wolfgang", ""], ["Kowald", "Dominik", ""], ["Lex", "Elisabeth", ""]]}, {"id": "2009.09942", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, J. Andrew Bagnell, Maxim Likhachev", "title": "CMAX++ : Leveraging Experience in Planning and Execution using\n  Inaccurate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given access to accurate dynamical models, modern planning approaches are\neffective in computing feasible and optimal plans for repetitive robotic tasks.\nHowever, it is difficult to model the true dynamics of the real world before\nexecution, especially for tasks requiring interactions with objects whose\nparameters are unknown. A recent planning approach, CMAX, tackles this problem\nby adapting the planner online during execution to bias the resulting plans\naway from inaccurately modeled regions. CMAX, while being provably guaranteed\nto reach the goal, requires strong assumptions on the accuracy of the model\nused for planning and fails to improve the quality of the solution over\nrepetitions of the same task. In this paper we propose CMAX++, an approach that\nleverages real-world experience to improve the quality of resulting plans over\nsuccessive repetitions of a robotic task. CMAX++ achieves this by integrating\nmodel-free learning using acquired experience with model-based planning using\nthe potentially inaccurate model. We provide provable guarantees on the\ncompleteness and asymptotic convergence of CMAX++ to the optimal path cost as\nthe number of repetitions increases. CMAX++ is also shown to outperform\nbaselines in simulated robotic tasks including 3D mobile robot navigation where\nthe track friction is incorrectly modeled, and a 7D pick-and-place task where\nthe mass of the object is unknown leading to discrepancy between true and\nmodeled dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 14:59:31 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 01:23:29 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 18:44:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Vemula", "Anirudh", ""], ["Bagnell", "J. Andrew", ""], ["Likhachev", "Maxim", ""]]}, {"id": "2009.09984", "submitter": "Asad Anwar Butt", "authors": "George Awad, Asad A. Butt, Keith Curtis, Yooyoung Lee, Jonathan\n  Fiscus, Afzal Godil, Andrew Delgado, Jesse Zhang, Eliot Godard, Lukas Diduch,\n  Alan F. Smeaton, Yvette Graham, Wessel Kraaij, Georges Quenot", "title": "TRECVID 2019: An Evaluation Campaign to Benchmark Video Activity\n  Detection, Video Captioning and Matching, and Video Search & Retrieval", "comments": "TRECVID Workshop overview paper. 39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TREC Video Retrieval Evaluation (TRECVID) 2019 was a TREC-style video\nanalysis and retrieval evaluation, the goal of which remains to promote\nprogress in research and development of content-based exploitation and\nretrieval of information from digital video via open, metrics-based evaluation.\nOver the last nineteen years this effort has yielded a better understanding of\nhow systems can effectively accomplish such processing and how one can reliably\nbenchmark their performance. TRECVID has been funded by NIST (National\nInstitute of Standards and Technology) and other US government agencies. In\naddition, many organizations and individuals worldwide contribute significant\ntime and effort. TRECVID 2019 represented a continuation of four tasks from\nTRECVID 2018. In total, 27 teams from various research organizations worldwide\ncompleted one or more of the following four tasks: 1. Ad-hoc Video Search (AVS)\n2. Instance Search (INS) 3. Activities in Extended Video (ActEV) 4. Video to\nText Description (VTT) This paper is an introduction to the evaluation\nframework, tasks, data, and measures used in the workshop.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:08:47 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Awad", "George", ""], ["Butt", "Asad A.", ""], ["Curtis", "Keith", ""], ["Lee", "Yooyoung", ""], ["Fiscus", "Jonathan", ""], ["Godil", "Afzal", ""], ["Delgado", "Andrew", ""], ["Zhang", "Jesse", ""], ["Godard", "Eliot", ""], ["Diduch", "Lukas", ""], ["Smeaton", "Alan F.", ""], ["Graham", "Yvette", ""], ["Kraaij", "Wessel", ""], ["Quenot", "Georges", ""]]}, {"id": "2009.10002", "submitter": "Yujia Zheng", "authors": "Yujia Zheng, Siyi Liu, Zekun Li, Shu Wu", "title": "DGTN: Dual-channel Graph Transition Network for Session-based\n  Recommendation", "comments": "Accepted at ICDMW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of session-based recommendation is to predict user actions based on\nanonymous sessions. Recent research mainly models the target session as a\nsequence or a graph to capture item transitions within it, ignoring complex\ntransitions between items in different sessions that have been generated by\nother users. These item transitions include potential collaborative information\nand reflect similar behavior patterns, which we assume may help with the\nrecommendation for the target session. In this paper, we propose a novel\nmethod, namely Dual-channel Graph Transition Network (DGTN), to model item\ntransitions within not only the target session but also the neighbor sessions.\nSpecifically, we integrate the target session and its neighbor (similar)\nsessions into a single graph. Then the transition signals are explicitly\ninjected into the embedding by channel-aware propagation. Experiments on\nreal-world datasets demonstrate that DGTN outperforms other state-of-the-art\nmethods. Further analysis verifies the rationality of dual-channel item\ntransition modeling, suggesting a potential future direction for session-based\nrecommendation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:29:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zheng", "Yujia", ""], ["Liu", "Siyi", ""], ["Li", "Zekun", ""], ["Wu", "Shu", ""]]}, {"id": "2009.10014", "submitter": "Madhav Marathe", "authors": "Aniruddha Adiga, Devdatt Dubhashi, Bryan Lewis, Madhav Marathe,\n  Srinivasan Venkatramanan, Anil Vullikanti", "title": "Models for COVID-19 Pandemic: A Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 pandemic represents an unprecedented global health crisis in the\nlast 100 years. Its economic, social and health impact continues to grow and is\nlikely to end up as one of the worst global disasters since the 1918 pandemic\nand the World Wars. Mathematical models have played an important role in the\nongoing crisis; they have been used to inform public policies and have been\ninstrumental in many of the social distancing measures that were instituted\nworldwide.\n  In this article we review some of the important mathematical models used to\nsupport the ongoing planning and response efforts. These models differ in their\nuse, their mathematical form and their scope.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:42:00 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Adiga", "Aniruddha", ""], ["Dubhashi", "Devdatt", ""], ["Lewis", "Bryan", ""], ["Marathe", "Madhav", ""], ["Venkatramanan", "Srinivasan", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2009.10017", "submitter": "Ryan Rossi", "authors": "Di Jin, Sungchul Kim, Ryan A. Rossi, Danai Koutra", "title": "From Static to Dynamic Node Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for leveraging graph stream data for\ntemporal prediction-based applications. Our proposed framework includes novel\nmethods for learning an appropriate graph time-series representation, modeling\nand weighting the temporal dependencies, and generalizing existing embedding\nmethods for such data. While previous work on dynamic modeling and embedding\nhas focused on representing a stream of timestamped edges using a time-series\nof graphs based on a specific time-scale (e.g., 1 month), we propose the notion\nof an $\\epsilon$-graph time-series that uses a fixed number of edges for each\ngraph, and show its superiority over the time-scale representation used in\nprevious work. In addition, we propose a number of new temporal models based on\nthe notion of temporal reachability graphs and weighted temporal summary\ngraphs. These temporal models are then used to generalize existing base\n(static) embedding methods by enabling them to incorporate and appropriately\nmodel temporal dependencies in the data. From the 6 temporal network models\ninvestigated (for each of the 7 base embedding methods), we find that the top-3\ntemporal models are always those that leverage the new $\\epsilon$-graph\ntime-series representation. Furthermore, the dynamic embedding methods from the\nframework almost always achieve better predictive performance than existing\nstate-of-the-art dynamic node embedding methods that are developed specifically\nfor such temporal prediction tasks. Finally, the findings of this work are\nuseful for designing better dynamic embedding methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 16:48:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jin", "Di", ""], ["Kim", "Sungchul", ""], ["Rossi", "Ryan A.", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.10033", "submitter": "Atrisha Sarkar", "authors": "Atrisha Sarkar, Krzysztof Czarnecki", "title": "Solution Concepts in Hierarchical Games under Bounded Rationality with\n  Applications to Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With autonomous vehicles (AV) set to integrate further into regular human\ntraffic, there is an increasing consensus of treating AV motion planning as a\nmulti-agent problem. However, the traditional game theoretic assumption of\ncomplete rationality is too strong for the purpose of human driving, and there\nis a need for understanding human driving as a \\emph{bounded rational} activity\nthrough a behavioral game theoretic lens. To that end, we adapt three\nmetamodels of bounded rational behavior; two based on Quantal level-k and one\nbased on Nash equilibrium with quantal errors. We formalize the different\nsolution concepts that can be applied in the context of hierarchical games, a\nframework used in multi-agent motion planning, for the purpose of creating game\ntheoretic models of driving behavior. Furthermore, based on a contributed\ndataset of human driving at a busy urban intersection with a total of ~4k\nagents and ~44k decision points, we evaluate the behavior models on the basis\nof model fit to naturalistic data, as well as their predictive capacity. Our\nresults suggest that among the behavior models evaluated, modeling driving\nbehavior as pure strategy NE with quantal errors at the level of maneuvers with\nbounds sampling of actions at the level of trajectories provides the best fit\nto naturalistic driving behavior, and there is a significant impact of\nsituational factors on the performance of behavior models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:13:50 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:00:54 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 17:10:49 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 17:49:20 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Sarkar", "Atrisha", ""], ["Czarnecki", "Krzysztof", ""]]}, {"id": "2009.10058", "submitter": "Asim Iqbal", "authors": "Hassan Mahmood, Asim Iqbal, Syed Mohammed Shamsul Islam", "title": "Exploring Intensity Invariance in Deep Neural Networks for Brain Image\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration is a widely-used technique in analysing large scale\ndatasets that are captured through various imaging modalities and techniques in\nbiomedical imaging such as MRI, X-Rays, etc. These datasets are typically\ncollected from various sites and under different imaging protocols using a\nvariety of scanners. Such heterogeneity in the data collection process causes\ninhomogeneity or variation in intensity (brightness) and noise distribution.\nThese variations play a detrimental role in the performance of image\nregistration, segmentation and detection algorithms. Classical image\nregistration methods are computationally expensive but are able to handle these\nartifacts relatively better. However, deep learning-based techniques are shown\nto be computationally efficient for automated brain registration but are\nsensitive to the intensity variations. In this study, we investigate the effect\nof variation in intensity distribution among input image pairs for deep\nlearning-based image registration methods. We find a performance degradation of\nthese models when brain image pairs with different intensity distribution are\npresented even with similar structures. To overcome this limitation, we\nincorporate a structural similarity-based loss function in a deep neural\nnetwork and test its performance on the validation split separated before\ntraining as well as on a completely unseen new dataset. We report that the deep\nlearning models trained with structure similarity-based loss seems to perform\nbetter for both datasets. This investigation highlights a possible performance\nlimiting factor in deep learning-based registration models and suggests a\npotential solution to incorporate the intensity distribution variation in the\ninput image pairs. Our code and models are available at\nhttps://github.com/hassaanmahmood/DeepIntense.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:49:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mahmood", "Hassan", ""], ["Iqbal", "Asim", ""], ["Islam", "Syed Mohammed Shamsul", ""]]}, {"id": "2009.10061", "submitter": "Gabriele Farina", "authors": "Gabriele Farina and Andrea Celli and Nicola Gatti and Tuomas Sandholm", "title": "Faster Algorithms for Optimal Ex-Ante Coordinated Collusive Strategies\n  in Extensive-Form Zero-Sum Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of finding an optimal strategy for a team of two\nplayers that faces an opponent in an imperfect-information zero-sum\nextensive-form game. Team members are not allowed to communicate during play\nbut can coordinate before the game. In that setting, it is known that the best\nthe team can do is sample a profile of potentially randomized strategies (one\nper player) from a joint (a.k.a. correlated) probability distribution at the\nbeginning of the game. In this paper, we first provide new modeling results\nabout computing such an optimal distribution by drawing a connection to a\ndifferent literature on extensive-form correlation. Second, we provide an\nalgorithm that computes such an optimal distribution by only using profiles\nwhere only one of the team members gets to randomize in each profile. We can\nalso cap the number of such profiles we allow in the solution. This begets an\nanytime algorithm by increasing the cap. We find that often a handful of\nwell-chosen such profiles suffices to reach optimal utility for the team. This\nenables team members to reach coordination through a relatively simple and\nunderstandable plan. Finally, inspired by this observation and leveraging\ntheoretical concepts that we introduce, we develop an efficient\ncolumn-generation algorithm for finding an optimal distribution for the team.\nWe evaluate it on a suite of common benchmark games. It is three orders of\nmagnitude faster than the prior state of the art on games that the latter can\nsolve and it can also solve several games that were previously unsolvable.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:51:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Farina", "Gabriele", ""], ["Celli", "Andrea", ""], ["Gatti", "Nicola", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2009.10073", "submitter": "Dattaraj Rao", "authors": "Dattaraj Rao", "title": "Contextual Bandits for adapting to changing User preferences over time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits provide an effective way to model the dynamic data problem\nin ML by leveraging online (incremental) learning to continuously adjust the\npredictions based on changing environment. We explore details on contextual\nbandits, an extension to the traditional reinforcement learning (RL) problem\nand build a novel algorithm to solve this problem using an array of\naction-based learners. We apply this approach to model an article\nrecommendation system using an array of stochastic gradient descent (SGD)\nlearners to make predictions on rewards based on actions taken. We then extend\nthe approach to a publicly available MovieLens dataset and explore the\nfindings. First, we make available a simplified simulated dataset showing\nvarying user preferences over time and how this can be evaluated with static\nand dynamic learning algorithms. This dataset made available as part of this\nresearch is intentionally simulated with limited number of features and can be\nused to evaluate different problem-solving strategies. We will build a\nclassifier using static dataset and evaluate its performance on this dataset.\nWe show limitations of static learner due to fixed context at a point of time\nand how changing that context brings down the accuracy. Next we develop a novel\nalgorithm for solving the contextual bandit problem. Similar to the linear\nbandits, this algorithm maps the reward as a function of context vector but\nuses an array of learners to capture variation between actions/arms. We develop\na bandit algorithm using an array of stochastic gradient descent (SGD)\nlearners, with separate learner per arm. Finally, we will apply this contextual\nbandit algorithm to predicting movie ratings over time by different users from\nthe standard Movie Lens dataset and demonstrate the results.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:17:42 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 06:01:59 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Rao", "Dattaraj", ""]]}, {"id": "2009.10132", "submitter": "Sarah Jabbour", "authors": "Sarah Jabbour, David Fouhey, Ella Kazerooni, Michael W. Sjoding, Jenna\n  Wiens", "title": "Deep Learning Applied to Chest X-Rays: Exploiting and Preventing\n  Shortcuts", "comments": "32 pages, 9 figures, 12 tables, MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown promise in improving the automated diagnosis of\ndisease based on chest X-rays, deep networks may exhibit undesirable behavior\nrelated to shortcuts. This paper studies the case of spurious class skew in\nwhich patients with a particular attribute are spuriously more likely to have\nthe outcome of interest. For instance, clinical protocols might lead to a\ndataset in which patients with pacemakers are disproportionately likely to have\ncongestive heart failure. This skew can lead to models that take shortcuts by\nheavily relying on the biased attribute. We explore this problem across a\nnumber of attributes in the context of diagnosing the cause of acute hypoxemic\nrespiratory failure. Applied to chest X-rays, we show that i) deep nets can\naccurately identify many patient attributes including sex (AUROC = 0.96) and\nage (AUROC >= 0.90), ii) they tend to exploit correlations between such\nattributes and the outcome label when learning to predict a diagnosis, leading\nto poor performance when such correlations do not hold in the test population\n(e.g., everyone in the test set is male), and iii) a simple transfer learning\napproach is surprisingly effective at preventing the shortcut and promoting\ngood generalization performance. On the task of diagnosing congestive heart\nfailure based on a set of chest X-rays skewed towards older patients (age >=\n63), the proposed approach improves generalization over standard training from\n0.66 (95% CI: 0.54-0.77) to 0.84 (95% CI: 0.73-0.92) AUROC. While simple, the\nproposed approach has the potential to improve the performance of models across\npopulations by encouraging reliance on clinically relevant manifestations of\ndisease, i.e., those that a clinician would use to make a diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:52:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jabbour", "Sarah", ""], ["Fouhey", "David", ""], ["Kazerooni", "Ella", ""], ["Sjoding", "Michael W.", ""], ["Wiens", "Jenna", ""]]}, {"id": "2009.10149", "submitter": "Khaza Anuarul Hoque", "authors": "Gautam Raj Mode, Khaza Anuarul Hoque", "title": "Crafting Adversarial Examples for Deep Learning Based Prognostics\n  (Extended Version)", "comments": "This is the extended version of the paper \"Crafting Adversarial\n  Examples for Deep Learning Based Prognostics\" accepted for publication in the\n  IEEE International Conference on Machine Learning and Applications (ICMLA\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In manufacturing, unexpected failures are considered a primary operational\nrisk, as they can hinder productivity and can incur huge losses.\nState-of-the-art Prognostics and Health Management (PHM) systems incorporate\nDeep Learning (DL) algorithms and Internet of Things (IoT) devices to ascertain\nthe health status of equipment, and thus reduce the downtime, maintenance cost\nand increase the productivity. Unfortunately, IoT sensors and DL algorithms,\nboth are vulnerable to cyber attacks, and hence pose a significant threat to\nPHM systems. In this paper, we adopt the adversarial example crafting\ntechniques from the computer vision domain and apply them to the PHM domain.\nSpecifically, we craft adversarial examples using the Fast Gradient Sign Method\n(FGSM) and Basic Iterative Method (BIM) and apply them on the Long Short-Term\nMemory (LSTM), Gated Recurrent Unit (GRU), and Convolutional Neural Network\n(CNN) based PHM models. We evaluate the impact of adversarial attacks using\nNASA's turbofan engine dataset. The obtained results show that all the\nevaluated PHM models are vulnerable to adversarial attacks and can cause a\nserious defect in the remaining useful life estimation. The obtained results\nalso show that the crafted adversarial examples are highly transferable and may\ncause significant damages to PHM systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:43:38 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 15:26:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Mode", "Gautam Raj", ""], ["Hoque", "Khaza Anuarul", ""]]}, {"id": "2009.10152", "submitter": "\\\"Ozg\\\"ur Akg\\\"un", "authors": "Patrick Spracklen, Nguyen Dang, \\\"Ozg\\\"ur Akg\\\"un, Ian Miguel", "title": "Towards Portfolios of Streamlined Constraint Models: A Case Study with\n  the Balanced Academic Curriculum Problem", "comments": null, "journal-ref": "ModRef 2020 - The 19th workshop on Constraint Modelling and\n  Reformulation", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Augmenting a base constraint model with additional constraints can strengthen\nthe inferences made by a solver and therefore reduce search effort. We focus on\nthe automatic addition of streamliner constraints, derived from the types\npresent in an abstract Essence specification of a problem class of interest,\nwhich trade completeness for potentially very significant reduction in search.\nThe refinement of streamlined Essence specifications into constraint models\nsuitable for input to constraint solvers gives rise to a large number of\nmodelling choices in addition to those required for the base Essence\nspecification. Previous automated streamlining approaches have been limited in\nevaluating only a single default model for each streamlined specification. In\nthis paper we explore the effect of model selection in the context of\nstreamlined specifications. We propose a new best-first search method that\ngenerates a portfolio of Pareto Optimal streamliner-model combinations by\nevaluating for each streamliner a portfolio of models to search and explore the\nvariability in performance and find the optimal model. Various forms of racing\nare utilised to constrain the computational cost of training.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:48:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Spracklen", "Patrick", ""], ["Dang", "Nguyen", ""], ["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Miguel", "Ian", ""]]}, {"id": "2009.10156", "submitter": "\\\"Ozg\\\"ur Akg\\\"un", "authors": "\\\"Ozg\\\"ur Akg\\\"un, Nguyen Dang, Joan Espasa, Ian Miguel, Andr\\'as Z.\n  Salamon, Christopher Stone", "title": "Exploring Instance Generation for Automated Planning", "comments": null, "journal-ref": "ModRef 2020 - The 19th workshop on Constraint Modelling and\n  Reformulation", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many of the core disciplines of artificial intelligence have sets of standard\nbenchmark problems well known and widely used by the community when developing\nnew algorithms. Constraint programming and automated planning are examples of\nthese areas, where the behaviour of a new algorithm is measured by how it\nperforms on these instances. Typically the efficiency of each solving method\nvaries not only between problems, but also between instances of the same\nproblem. Therefore, having a diverse set of instances is crucial to be able to\neffectively evaluate a new solving method. Current methods for automatic\ngeneration of instances for Constraint Programming problems start with a\ndeclarative model and search for instances with some desired attributes, such\nas hardness or size. We first explore the difficulties of adapting this\napproach to generate instances starting from problem specifications written in\nPDDL, the de-facto standard language of the automated planning community. We\nthen propose a new approach where the whole planning problem description is\nmodelled using Essence, an abstract modelling language that allows expressing\nhigh-level structures without committing to a particular low level\nrepresentation in PDDL.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:58:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Dang", "Nguyen", ""], ["Espasa", "Joan", ""], ["Miguel", "Ian", ""], ["Salamon", "Andr\u00e1s Z.", ""], ["Stone", "Christopher", ""]]}, {"id": "2009.10224", "submitter": "Luis A. Pineda", "authors": "Luis A. Pineda", "title": "Entropy, Computing and Rationality", "comments": "43 pages, 4 figures, 44 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making decisions freely presupposes that there is some indeterminacy in the\nenvironment and in the decision making engine. The former is reflected on the\nbehavioral changes due to communicating: few changes indicate rigid\nenvironments; productive changes manifest a moderate indeterminacy, but a large\ncommunicating effort with few productive changes characterize a chaotic\nenvironment. Hence, communicating, effective decision making and productive\nbehavioral changes are related. The entropy measures the indeterminacy of the\nenvironment, and there is an entropy range in which communicating supports\neffective decision making. This conjecture is referred to here as the The\nPotential Productivity of Decisions.\n  The computing engine that is causal to decision making should also have some\nindeterminacy. However, computations performed by standard Turing Machines are\npredetermined. To overcome this limitation an entropic mode of computing that\nis called here Relational-Indeterminate is presented. Its implementation in a\ntable format has been used to model an associative memory. The present theory\nand experiment suggest the Entropy Trade-off: There is an entropy range in\nwhich computing is effective but if the entropy is too low computations are too\nrigid and if it is too high computations are unfeasible. The entropy trade-off\nof computing engines corresponds to the potential productivity of decisions of\nthe environment.\n  The theory is referred to an Interaction-Oriented Cognitive Architecture.\nMemory, perception, action and thought involve a level of indeterminacy and\ndecision making may be free in such degree. The overall theory supports an\necological view of rationality. The entropy of the brain has been measured in\nneuroscience studies and the present theory supports that the brain is an\nentropic machine. The paper is concluded with a number of predictions that may\nbe tested empirically.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 23:56:03 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Pineda", "Luis A.", ""]]}, {"id": "2009.10228", "submitter": "Jessica Van Brummelen", "authors": "Xiaofei Zhou and Jessica Van Brummelen and Phoebe Lin", "title": "Designing AI Learning Experiences for K-12: Emerging Works, Future\n  Opportunities and a Design Framework", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) literacy is a rapidly growing research area and\na critical addition to K-12 education. However, support for designing tools and\ncurriculum to teach K-12 AI literacy is still limited. There is a need for\nadditional interdisciplinary human-computer interaction and education research\ninvestigating (1) how general AI literacy is currently implemented in learning\nexperiences and (2) what additional guidelines are required to teach AI\nliteracy in specifically K-12 learning contexts. In this paper, we analyze a\ncollection of K-12 AI and education literature to show how core competencies of\nAI literacy are applied successfully and organize them into an\neducator-friendly chart to enable educators to efficiently find appropriate\nresources for their classrooms. We also identify future opportunities and K-12\nspecific design guidelines, which we synthesized into a conceptual framework to\nsupport researchers, designers, and educators in creating K-12 AI learning\nexperiences.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:08:04 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhou", "Xiaofei", ""], ["Van Brummelen", "Jessica", ""], ["Lin", "Phoebe", ""]]}, {"id": "2009.10233", "submitter": "Boyuan Feng", "authors": "Boyuan Feng, Yuke Wang, Xu Li, and Yufei Ding", "title": "Scalable Adversarial Attack on Graph Neural Networks with Alternating\n  Direction Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved high performance in analyzing\ngraph-structured data and have been widely deployed in safety-critical areas,\nsuch as finance and autonomous driving. However, only a few works have explored\nGNNs' robustness to adversarial attacks, and their designs are usually limited\nby the scale of input datasets (i.e., focusing on small graphs with only\nthousands of nodes). In this work, we propose, SAG, the first scalable\nadversarial attack method with Alternating Direction Method of Multipliers\n(ADMM). We first decouple the large-scale graph into several smaller graph\npartitions and cast the original problem into several subproblems. Then, we\npropose to solve these subproblems using projected gradient descent on both the\ngraph topology and the node features that lead to considerably lower memory\nconsumption compared to the conventional attack methods. Rigorous experiments\nfurther demonstrate that SAG can significantly reduce the computation and\nmemory overhead compared with the state-of-the-art approach, making SAG\napplicable towards graphs with large size of nodes and edges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:33:36 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Feng", "Boyuan", ""], ["Wang", "Yuke", ""], ["Li", "Xu", ""], ["Ding", "Yufei", ""]]}, {"id": "2009.10236", "submitter": "EPTCS", "authors": "Alex Brik (Google Inc.)", "title": "Splitting a Hybrid ASP Program", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 21-34", "doi": "10.4204/EPTCS.325.8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid Answer Set Programming (Hybrid ASP) is an extension of Answer Set\nProgramming (ASP) that allows ASP-like rules to interact with outside sources.\nThe Splitting Set Theorem is an important and extensively used result for ASP.\nThe paper introduces the Splitting Set Theorem for Hybrid ASP, which is for\nHybrid ASP the equivalent of the Splitting Set Theorem, and shows how it can be\napplied to simplify computing answer sets for Hybrid ASP programs most relevant\nfor practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Brik", "Alex", "", "Google Inc."]]}, {"id": "2009.10237", "submitter": "EPTCS", "authors": "Esra Erdem (Sabanci University), Andreas Herzig (Institut de Recherche\n  en Informatique de Toulouse)", "title": "Solving Gossip Problems using Answer Set Programming: An Epistemic\n  Planning Approach", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 52-58", "doi": "10.4204/EPTCS.325.11", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Answer Set Programming to solve variations of\ngossip problems, by modeling them as epistemic planning problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:55 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Erdem", "Esra", "", "Sabanci University"], ["Herzig", "Andreas", "", "Institut de Recherche\n  en Informatique de Toulouse"]]}, {"id": "2009.10239", "submitter": "EPTCS", "authors": "Kinjal Basu, Sarat Chandra Varanasi, Farhad Shakerin, Gopal Gupta", "title": "SQuARE: Semantics-based Question Answering and Reasoning Engine", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 73-86", "doi": "10.4204/EPTCS.325.13", "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) and from its early days, it has received\nsignificant attention through question answering (QA) tasks. We introduce a\ngeneral semantics-based framework for natural language QA and also describe the\nSQuARE system, an application of this framework. The framework is based on the\ndenotational semantics approach widely used in programming language research.\nIn our framework, valuation function maps syntax tree of the text to its\ncommonsense meaning represented using basic knowledge primitives (the semantic\nalgebra) coded using answer set programming (ASP). We illustrate an application\nof this framework by using VerbNet primitives as our semantic algebra and a\nnovel algorithm based on partial tree matching that generates an answer set\nprogram that represents the knowledge in the text. A question posed against\nthat text is converted into an ASP query using the same framework and executed\nusing the s(CASP) goal-directed ASP system. Our approach is based purely on\n(commonsense) reasoning. SQuARE achieves 100% accuracy on all the five datasets\nof bAbI QA tasks that we have tested. The significance of our work is that,\nunlike other machine learning based approaches, ours is based on\n\"understanding\" the text and does not require any training. SQuARE can also\ngenerate an explanation for an answer while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Basu", "Kinjal", ""], ["Varanasi", "Sarat Chandra", ""], ["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "2009.10240", "submitter": "EPTCS", "authors": "Michael Dingess (University of Kentucky), Miroslaw Truszczynski\n  (University of Kentucky)", "title": "Automated Aggregator -- Rewriting with the Counting Aggregate", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 96-109", "doi": "10.4204/EPTCS.325.17", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming is a leading declarative constraint programming\nparadigm with wide use for complex knowledge-intensive applications. Modern\nanswer set programming languages support many equivalent ways to model\nconstraints and specifications in a program. However, so far answer set\nprogramming has failed to develop systematic methodologies for building\nrepresentations that would uniformly lend well to automated processing. This\nsuggests that encoding selection, in the same way as algorithm selection and\nportfolio solving, may be a viable direction for improving performance of\nanswer-set solving. The necessary precondition is automating the process of\ngenerating possible alternative encodings. Here we present an automated\nrewriting system, the Automated Aggregator or AAgg, that given a non-ground\nlogic program, produces a family of equivalent programs with complementary\nperformance when run under modern answer set programming solvers. We\ndemonstrate this behavior through experimental analysis and propose the\nsystem's use in automated answer set programming solver selection tools.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dingess", "Michael", "", "University of Kentucky"], ["Truszczynski", "Miroslaw", "", "University of Kentucky"]]}, {"id": "2009.10241", "submitter": "EPTCS", "authors": "Paul Tarau (University of North Texas), Valeria de Paiva (Topos\n  Institute)", "title": "Deriving Theorems in Implicational Linear Logic, Declaratively", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 110-123", "doi": "10.4204/EPTCS.325.18", "report-no": null, "categories": "cs.LO cs.AI cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem we want to solve is how to generate all theorems of a given size\nin the implicational fragment of propositional intuitionistic linear logic. We\nstart by filtering for linearity the proof terms associated by our Prolog-based\ntheorem prover for Implicational Intuitionistic Logic. This works, but using\nfor each formula a PSPACE-complete algorithm limits it to very small formulas.\nWe take a few walks back and forth over the bridge between proof terms and\ntheorems, provided by the Curry-Howard isomorphism, and derive step-by-step an\nefficient algorithm requiring a low polynomial effort per generated theorem.\nThe resulting Prolog program runs in O(N) space for terms of size N and\ngenerates in a few hours 7,566,084,686 theorems in the implicational fragment\nof Linear Intuitionistic Logic together with their proof terms in normal form.\nAs applications, we generate datasets for correctness and scalability testing\nof linear logic theorem provers and training data for neural networks working\non theorem proving challenges. The results in the paper, organized as a\nliterate Prolog program, are fully replicable.\n  Keywords: combinatorial generation of provable formulas of a given size,\nintuitionistic and linear logic theorem provers, theorems of the implicational\nfragment of propositional linear intuitionistic logic, Curry-Howard\nisomorphism, efficient generation of linear lambda terms in normal form, Prolog\nprograms for lambda term generation and theorem proving.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Tarau", "Paul", "", "University of North Texas"], ["de Paiva", "Valeria", "", "Topos\n  Institute"]]}, {"id": "2009.10242", "submitter": "EPTCS", "authors": "Pedro Cabalar (University of Coru\\~na, Spain), Jorge Fandinno\n  (University of Potsdam, Germany), Brais Mu\\~niz (CITIC, University of\n  Coru\\~na, Spain)", "title": "A System for Explainable Answer Set Programming", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 124-136", "doi": "10.4204/EPTCS.325.19", "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present xclingo, a tool for generating explanations from ASP programs\nannotated with text and labels. These annotations allow tracing the application\nof rules or the atoms derived by them. The input of xclingo is a markup\nlanguage written as ASP comment lines, so the programs annotated in this way\ncan still be accepted by a standard ASP solver. xclingo translates the\nannotations into additional predicates and rules and uses the ASP solver clingo\nto obtain the extension of those auxiliary predicates. This information is used\nafterwards to construct derivation trees containing textual explanations. The\nlanguage allows selecting which atoms to explain and, in its turn, which atoms\nor rules to include in those explanations. We illustrate the basic features\nthrough a diagnosis problem from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:59 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cabalar", "Pedro", "", "University of Coru\u00f1a, Spain"], ["Fandinno", "Jorge", "", "University of Potsdam, Germany"], ["Mu\u00f1iz", "Brais", "", "CITIC, University of\n  Coru\u00f1a, Spain"]]}, {"id": "2009.10243", "submitter": "EPTCS", "authors": "Ridhwan Dewoprabowo, Ari Saptawijaya", "title": "Tabling Optimization for Contextual Abduction", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 137-150", "doi": "10.4204/EPTCS.325.20", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabling for contextual abduction in logic programming has been introduced as\na means to store previously obtained abductive solutions in one context to be\nreused in another context. This paper identifies a number of issues in the\nexisting implementations of tabling in contextual abduction and aims to\nmitigate the issues. We propose a new program transformation for integrity\nconstraints to deal with their proper application for filtering solutions while\nalso reducing the table memory usage. We further optimize the table memory\nusage by selectively picking predicates to table and by pragmatically\nsimplifying the representation of the problem. The evaluation of our proposed\napproach, on both artificial and real world problems, shows that they improve\nthe scalability of tabled abduction compared to previous implementations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:49:10 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dewoprabowo", "Ridhwan", ""], ["Saptawijaya", "Ari", ""]]}, {"id": "2009.10246", "submitter": "EPTCS", "authors": "Tobias Geibinger, Hans Tompits", "title": "Sequent-Type Calculi for Systems of Nonmonotonic Paraconsistent Logics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 178-191", "doi": "10.4204/EPTCS.325.23", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraconsistent logics constitute an important class of formalisms dealing\nwith non-trivial reasoning from inconsistent premisses. In this paper, we\nintroduce uniform axiomatisations for a family of nonmonotonic paraconsistent\nlogics based on minimal inconsistency in terms of sequent-type proof systems.\nThe latter are prominent and widely-used forms of calculi well-suited for\nanalysing proof search. In particular, we provide sequent-type calculi for\nPriest's three-valued minimally inconsistent logic of paradox, and for\nfour-valued paraconsistent inference relations due to Arieli and Avron. Our\ncalculi follow the sequent method first introduced in the context of\nnonmonotonic reasoning by Bonatti and Olivetti, whose distinguishing feature is\nthe use of a so-called rejection calculus for axiomatising invalid formulas. In\nfact, we present a general method to obtain sequent systems for any many-valued\nlogic based on minimal inconsistency, yielding the calculi for the logics of\nPriest and of Arieli and Avron as special instances.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:49:52 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Geibinger", "Tobias", ""], ["Tompits", "Hans", ""]]}, {"id": "2009.10248", "submitter": "EPTCS", "authors": "Wolf De Wulf (Vrije Universiteit Brussel), Bart Bogaerts (Vrije\n  Universiteit Brussel)", "title": "LP2PB: Translating Answer Set Programs into Pseudo-Boolean Theories", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 206-219", "doi": "10.4204/EPTCS.325.25", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer set programming (ASP) is a well-established knowledge representation\nformalism. Most ASP solvers are based on (extensions of) technology from\nBoolean satisfiability solving. While these solvers have shown to be very\nsuccessful in many practical applications, their strength is limited by their\nunderlying proof system, resolution. In this paper, we present a new tool LP2PB\nthat translates ASP programs into pseudo-Boolean theories, for which solvers\nbased on the (stronger) cutting plane proof system exist. We evaluate our tool,\nand the potential of cutting-plane-based solving for ASP on traditional ASP\nbenchmarks as well as benchmarks from pseudo-Boolean solving. Our results are\nmixed: overall, traditional ASP solvers still outperform our translational\napproach, but several benchmark families are identified where the balance\nshifts the other way, thereby suggesting that further investigation into a\nstronger proof system for ASP is valuable.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:17 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["De Wulf", "Wolf", "", "Vrije Universiteit Brussel"], ["Bogaerts", "Bart", "", "Vrije\n  Universiteit Brussel"]]}, {"id": "2009.10249", "submitter": "EPTCS", "authors": "Basem Atiq (Sabanci University), Volkan Patoglu (Sabanci University),\n  Esra Erdem (Sabanci University)", "title": "Dynamic Multi-Agent Path Finding based on Conflict Resolution using\n  Answer Set Programming", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 223-229", "doi": "10.4204/EPTCS.325.27", "report-no": null, "categories": "cs.AI cs.LO cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a dynamic version of multi-agent path finding problem (called\nD-MAPF) where existing agents may leave and new agents may join the team at\ndifferent times. We introduce a new method to solve D-MAPF based on\nconflict-resolution. The idea is, when a set of new agents joins the team and\nthere are conflicts, instead of replanning for the whole team, to replan only\nfor a minimal subset of agents whose plans conflict with each other. We utilize\nanswer set programming as part of our method for planning, replanning and\nidentifying minimal set of conflicts.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:35 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Atiq", "Basem", "", "Sabanci University"], ["Patoglu", "Volkan", "", "Sabanci University"], ["Erdem", "Esra", "", "Sabanci University"]]}, {"id": "2009.10250", "submitter": "EPTCS", "authors": "Stefania Costantini (University of L'Aquila, Italy), Lorenzo De\n  Lauretis (University of L'Aquila, Italy)", "title": "An application of Answer Set Programming in Distributed Architectures:\n  ASP Microservices", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 230-243", "doi": "10.4204/EPTCS.325.28", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to the definition of microservices with an Answer Set\nProgramming (ASP) `core', where microservices are a successful abstraction for\ndesigning distributed applications as suites of independently deployable\ninteracting components. Such ASP-based components might be employed in\ndistributed architectures related to Cloud Computing or to the Internet of\nThings (IoT).\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:50:46 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["De Lauretis", "Lorenzo", "", "University of L'Aquila, Italy"]]}, {"id": "2009.10252", "submitter": "EPTCS", "authors": "Elena Mastria (Department of Mathematics and Computer Science,\n  University of Calabria, Italy), Jessica Zangari (Department of Mathematics\n  and Computer Science, University of Calabria, Italy), Simona Perri\n  (Department of Mathematics and Computer Science, University of Calabria,\n  Italy), Francesco Calimeri (Department of Mathematics and Computer Science,\n  University of Calabria, Italy)", "title": "A Machine Learning guided Rewriting Approach for ASP Logic Programs", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 261-267", "doi": "10.4204/EPTCS.325.31", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a declarative logic formalism that allows to\nencode computational problems via logic programs. Despite the declarative\nnature of the formalism, some advanced expertise is required, in general, for\ndesigning an ASP encoding that can be efficiently evaluated by an actual ASP\nsystem. A common way for trying to reduce the burden of manually tweaking an\nASP program consists in automatically rewriting the input encoding according to\nsuitable techniques, for producing alternative, yet semantically equivalent,\nASP programs. However, rewriting does not always grant benefits in terms of\nperformance; hence, proper means are needed for predicting their effects with\nthis respect. In this paper we describe an approach based on Machine Learning\n(ML) to automatically decide whether to rewrite. In particular, given an ASP\nprogram and a set of input facts, our approach chooses whether and how to\nrewrite input rules based on a set of features measuring their structural\nproperties and domain information. To this end, a Multilayer Perceptrons model\nhas then been trained to guide the ASP grounder I-DLV on rewriting input rules.\nWe report and discuss the results of an experimental evaluation over a\nprototypical implementation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:13 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mastria", "Elena", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"], ["Zangari", "Jessica", "", "Department of Mathematics\n  and Computer Science, University of Calabria, Italy"], ["Perri", "Simona", "", "Department of Mathematics and Computer Science, University of Calabria,\n  Italy"], ["Calimeri", "Francesco", "", "Department of Mathematics and Computer Science,\n  University of Calabria, Italy"]]}, {"id": "2009.10253", "submitter": "EPTCS", "authors": "Alessandro Bertagnon (University of Ferrara)", "title": "Constraint Programming Algorithms for Route Planning Exploiting\n  Geometrical Information", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 286-295", "doi": "10.4204/EPTCS.325.38", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems affecting the transport of people or goods are plentiful in industry\nand commerce and they also appear to be at the origin of much more complex\nproblems. In recent years, the logistics and transport sector keeps growing\nsupported by technological progress, i.e. companies to be competitive are\nresorting to innovative technologies aimed at efficiency and effectiveness.\nThis is why companies are increasingly using technologies such as Artificial\nIntelligence (AI), Blockchain and Internet of Things (IoT). Artificial\nintelligence, in particular, is often used to solve optimization problems in\norder to provide users with the most efficient ways to exploit available\nresources. In this work we present an overview of our current research\nactivities concerning the development of new algorithms, based on CLP\ntechniques, for route planning problems exploiting the geometric information\nintrinsically present in many of them or in some of their variants. The\nresearch so far has focused in particular on the Euclidean Traveling\nSalesperson Problem (Euclidean TSP) with the aim to exploit the results\nobtained also to other problems of the same category, such as the Euclidean\nVehicle Routing Problem (Euclidean VRP), in the future.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:51:45 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Bertagnon", "Alessandro", "", "University of Ferrara"]]}, {"id": "2009.10256", "submitter": "EPTCS", "authors": "Zhun Yang", "title": "Extending Answer Set Programs with Neural Networks", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 313-322", "doi": "10.4204/EPTCS.325.41", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of low-level perception with high-level reasoning is one of\nthe oldest problems in Artificial Intelligence. Recently, several proposals\nwere made to implement the reasoning process in complex neural network\narchitectures. While these works aim at extending neural networks with the\ncapability of reasoning, a natural question that we consider is: can we extend\nanswer set programs with neural networks to allow complex and high-level\nreasoning on neural network outputs? As a preliminary result, we propose\nNeurASP -- a simple extension of answer set programs by embracing neural\nnetworks where neural network outputs are treated as probability distributions\nover atomic facts in answer set programs. We show that NeurASP can not only\nimprove the perception accuracy of a pre-trained neural network, but also help\nto train a neural network better by giving restrictions through logic rules.\nHowever, training with NeurASP would take much more time than pure neural\nnetwork training due to the internal use of a symbolic reasoning engine. For\nfuture work, we plan to investigate the potential ways to solve the scalability\nissue of NeurASP. One potential way is to embed logic programs directly in\nneural networks. On this route, we plan to first design a SAT solver using\nneural networks, then extend such a solver to allow logic programs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:52:30 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Yang", "Zhun", ""]]}, {"id": "2009.10282", "submitter": "Juan Manuel Carrillo Garcia", "authors": "Juan Carrillo, Mark Crowley, Guangyuan Pan, Liping Fu", "title": "Design of Efficient Deep Learning models for Determining Road Surface\n  Condition from Roadside Camera Images and Weather Data", "comments": "Source code for experiments is available at\n  https://github.com/jmcarrillog/deep-learning-for-road-surface-condition", "journal-ref": "Published also in proceedings of the TAC-ITS 2019 Conference", "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Road maintenance during the Winter season is a safety critical and resource\ndemanding operation. One of its key activities is determining road surface\ncondition (RSC) in order to prioritize roads and allocate cleaning efforts such\nas plowing or salting. Two conventional approaches for determining RSC are:\nvisual examination of roadside camera images by trained personnel and\npatrolling the roads to perform on-site inspections. However, with more than\n500 cameras collecting images across Ontario, visual examination becomes a\nresource-intensive activity, difficult to scale especially during periods of\nsnowstorms. This paper presents the results of a study focused on improving the\nefficiency of road maintenance operations. We use multiple Deep Learning models\nto automatically determine RSC from roadside camera images and weather\nvariables, extending previous research where similar methods have been used to\ndeal with the problem. The dataset we use was collected during the 2017-2018\nWinter season from 40 stations connected to the Ontario Road Weather\nInformation System (RWIS), it includes 14.000 labeled images and 70.000 weather\nmeasurements. We train and evaluate the performance of seven state-of-the-art\nmodels from the Computer Vision literature, including the recent DenseNet,\nNASNet, and MobileNet. Moreover, by following systematic ablation experiments\nwe adapt previously published Deep Learning models and reduce their number of\nparameters to about ~1.3% compared to their original parameter count, and by\nintegrating observations from weather variables the models are able to better\nascertain RSC under poor visibility conditions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:30:32 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Carrillo", "Juan", ""], ["Crowley", "Mark", ""], ["Pan", "Guangyuan", ""], ["Fu", "Liping", ""]]}, {"id": "2009.10311", "submitter": "Cristian Canton Ferrer", "authors": "Alon Halevy, Cristian Canton Ferrer, Hao Ma, Umut Ozertem, Patrick\n  Pantel, Marzieh Saeidi, Fabrizio Silvestri, Ves Stoyanov", "title": "Preserving Integrity in Online Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks provide a platform for sharing information and free\nexpression. However, these networks are also used for malicious purposes, such\nas distributing misinformation and hate speech, selling illegal drugs, and\ncoordinating sex trafficking or child exploitation. This paper surveys the\nstate of the art in keeping online platforms and their users safe from such\nharm, also known as the problem of preserving integrity. This survey comes from\nthe perspective of having to combat a broad spectrum of integrity violations at\nFacebook. We highlight the techniques that have been proven useful in practice\nand that deserve additional attention from the academic community. Instead of\ndiscussing the many individual violation types, we identify key aspects of the\nsocial-media eco-system, each of which is common to a wide variety violation\ntypes. Furthermore, each of these components represents an area for research\nand development, and the innovations that are found can be applied widely.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:32:24 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 05:03:29 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 17:55:20 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Halevy", "Alon", ""], ["Ferrer", "Cristian Canton", ""], ["Ma", "Hao", ""], ["Ozertem", "Umut", ""], ["Pantel", "Patrick", ""], ["Saeidi", "Marzieh", ""], ["Silvestri", "Fabrizio", ""], ["Stoyanov", "Ves", ""]]}, {"id": "2009.10325", "submitter": "Xiaosong Wang", "authors": "Xiaosong Wang, Ziyue Xu, Dong Yang, Leo Tam, Holger Roth, Daguang Xu", "title": "Learning Image Labels On-the-fly for Training Robust Classification\n  Models", "comments": "v2: Minor Corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning paradigms largely benefit from the tremendous amount of\nannotated data. However, the quality of the annotations often varies among\nlabelers. Multi-observer studies have been conducted to study these annotation\nvariances (by labeling the same data for multiple times) and its effects on\ncritical applications like medical image analysis. This process indeed adds an\nextra burden to the already tedious annotation work that usually requires\nprofessional training and expertise in the specific domains. On the other hand,\nautomated annotation methods based on NLP algorithms have recently shown\npromise as a reasonable alternative, relying on the existing diagnostic reports\nof those images that are widely available in the clinical system. Compared to\nhuman labelers, different algorithms provide labels with varying qualities that\nare even noisier. In this paper, we show how noisy annotations (e.g., from\ndifferent algorithm-based labelers) can be utilized together and mutually\nbenefit the learning of classification tasks. Specifically, the concept of\nattention-on-label is introduced to sample better label sets on-the-fly as the\ntraining data. A meta-training based label-sampling module is designed to\nattend the labels that benefit the model learning the most through additional\nback-propagation processes. We apply the attention-on-label scheme on the\nclassification task of a synthetic noisy CIFAR-10 dataset to prove the concept,\nand then demonstrate superior results (3-5% increase on average in multiple\ndisease classification AUCs) on the chest x-ray images from a hospital-scale\ndataset (MIMIC-CXR) and hand-labeled dataset (OpenI) in comparison to regular\ntraining paradigms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:38:44 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 04:35:55 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Wang", "Xiaosong", ""], ["Xu", "Ziyue", ""], ["Yang", "Dong", ""], ["Tam", "Leo", ""], ["Roth", "Holger", ""], ["Xu", "Daguang", ""]]}, {"id": "2009.10348", "submitter": "Cristian Galleguillos", "authors": "Cristian Galleguillos, Zeynep Kiziltan, Ricardo Soto", "title": "A Constraint Programming-based Job Dispatcher for Modern HPC Systems and\n  Applications", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Constraint Programming (CP) is a well-established area in AI as a programming\nparadigm for modelling and solving discrete optimization problems, and it has\nbeen been successfully applied to tackle the on-line job dispatching problem in\nHPC systems including those running modern applications. The limitations of the\navailable CP-based job dispatchers may hinder their practical use in today's\nsystems that are becoming larger in size and more demanding in resource\nallocation. In an attempt to bring basic AI research closer to a deployed\napplication, we present a new CP-based on-line job dispatcher for modern HPC\nsystems and applications. Unlike its predecessors, our new dispatcher tackles\nthe entire problem in CP and its model size is independent of the system size.\nExperimental results based on a simulation study show that with our approach\ndispatching performance increases significantly in a large system and in a\nsystem where allocation is nontrivial.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:02:26 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 20:28:03 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Galleguillos", "Cristian", ""], ["Kiziltan", "Zeynep", ""], ["Soto", "Ricardo", ""]]}, {"id": "2009.10359", "submitter": "Wei Hu", "authors": "Difeng Wang and Wei Hu and Ermei Cao and Weijian Sun", "title": "Global-to-Local Neural Networks for Document-Level Relation Extraction", "comments": "Accepted in the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) aims to identify the semantic relations between\nnamed entities in text. Recent years have witnessed it raised to the document\nlevel, which requires complex reasoning with entities and mentions throughout\nan entire document. In this paper, we propose a novel model to document-level\nRE, by encoding the document information in terms of entity global and local\nrepresentations as well as context relation representations. Entity global\nrepresentations model the semantic information of all entities in the document,\nentity local representations aggregate the contextual information of multiple\nmentions of specific entities, and context relation representations encode the\ntopic information of other relations. Experimental results demonstrate that our\nmodel achieves superior performance on two public datasets for document-level\nRE. It is particularly effective in extracting relations between entities of\nlong distance and having multiple mentions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:30:19 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Wang", "Difeng", ""], ["Hu", "Wei", ""], ["Cao", "Ermei", ""], ["Sun", "Weijian", ""]]}, {"id": "2009.10370", "submitter": "Bassem Seddik", "authors": "Bassem Seddik and Najoua Essoukri Ben Amara", "title": "Visual Methods for Sign Language Recognition: A Modality-Based Review", "comments": "This survey paper is accepted as Springer book chapter, currently\n  under edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign language visual recognition from continuous multi-modal streams is still\none of the most challenging fields.\n  Recent advances in human actions recognition are exploiting the ascension of\nGPU-based learning from massive data, and are getting closer to human-like\nperformances.\n  They are then prone to creating interactive services for the deaf and\nhearing-impaired communities.\n  A population that is expected to grow considerably in the years to come.\n  This paper aims at reviewing the human actions recognition literature with\nthe sign-language visual understanding as a scope.\n  The methods analyzed will be mainly organized according to the different\ntypes of unimodal inputs exploited, their relative multi-modal combinations and\npipeline steps.\n  In each section, we will detail and compare the related datasets, approaches\nthen distinguish the still open contribution paths suitable for the creation of\nsign language related services.\n  Special attention will be paid to the approaches and commercial solutions\nhandling facial expressions and continuous signing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:56:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Seddik", "Bassem", ""], ["Amara", "Najoua Essoukri Ben", ""]]}, {"id": "2009.10396", "submitter": "Fabrice Harel-Canada", "authors": "Kushagra Rastogi and Jonathan Lee and Fabrice Harel-Canada and Aditya\n  Joglekar", "title": "Is Q-Learning Provably Efficient? An Extended Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends the analysis of the theoretical results presented within\nthe paper Is Q-Learning Provably Efficient? by Jin et al. We include a survey\nof related research to contextualize the need for strengthening the theoretical\nguarantees related to perhaps the most important threads of model-free\nreinforcement learning. We also expound upon the reasoning used in the proofs\nto highlight the critical steps leading to the main result showing that\nQ-learning with UCB exploration achieves a sample efficiency that matches the\noptimal regret that can be achieved by any model-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 09:00:25 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Rastogi", "Kushagra", ""], ["Lee", "Jonathan", ""], ["Harel-Canada", "Fabrice", ""], ["Joglekar", "Aditya", ""]]}, {"id": "2009.10468", "submitter": "Xiong Dan", "authors": "Xiong Dan", "title": "Spatial-Temporal Block and LSTM Network for Pedestrian Trajectories\n  Prediction", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian trajectory prediction is a critical to avoid autonomous driving\ncollision. But this prediction is a challenging problem due to social forces\nand cluttered scenes. Such human-human and human-space interactions lead to\nmany socially plausible trajectories. In this paper, we propose a novel\nLSTM-based algorithm. We tackle the problem by considering the static scene and\npedestrian which combine the Graph Convolutional Networks and Temporal\nConvolutional Networks to extract features from pedestrians. Each pedestrian in\nthe scene is regarded as a node, and we can obtain the relationship between\neach node and its neighborhoods by graph embedding. It is LSTM that encode the\nrelationship so that our model predicts nodes trajectories in crowd scenarios\nsimultaneously. To effectively predict multiple possible future trajectories,\nwe further introduce Spatio-Temporal Convolutional Block to make the network\nflexible. Experimental results on two public datasets, i.e. ETH and UCY,\ndemonstrate the effectiveness of our proposed ST-Block and we achieve\nstate-of-the-art approaches in human trajectory prediction.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:43:40 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 07:51:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dan", "Xiong", ""]]}, {"id": "2009.10513", "submitter": "Nijat Mehdiyev", "authors": "Nijat Mehdiyev and Peter Fettke", "title": "Local Post-Hoc Explanations for Predictive Process Monitoring in\n  Manufacturing", "comments": "Accepted for publication in ECIS-2021 Proceedings (initial submission\n  November 18, 2020). This version is an extension of the previous arXiv\n  version", "journal-ref": "ECIS 2021 Research Papers. 35 (2021)\n  https://aisel.aisnet.org/ecis2021_rp/35", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an innovative explainable predictive quality analytics\nsolution to facilitate data-driven decision-making for process planning in\nmanufacturing by combining process mining, machine learning, and explainable\nartificial intelligence (XAI) methods. For this purpose, after integrating the\ntop-floor and shop-floor data obtained from various enterprise information\nsystems, a deep learning model was applied to predict the process outcomes.\nSince this study aims to operationalize the delivered predictive insights by\nembedding them into decision-making processes, it is essential to generate\nrelevant explanations for domain experts. To this end, two complementary local\npost-hoc explanation approaches, Shapley values and Individual Conditional\nExpectation (ICE) plots are adopted, which are expected to enhance the\ndecision-making capabilities by enabling experts to examine explanations from\ndifferent perspectives. After assessing the predictive strength of the applied\ndeep neural network with relevant binary classification evaluation measures, a\ndiscussion of the generated explanations is provided.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:07:17 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 08:58:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mehdiyev", "Nijat", ""], ["Fettke", "Peter", ""]]}, {"id": "2009.10537", "submitter": "Yaguan Qian", "authors": "Yaguan Qian, Qiqi Shao, Jiamin Wang, Xiang Lin, Yankai Guo, Zhaoquan\n  Gu, Bin Wang, Chunming Wu", "title": "EI-MTD:Moving Target Defense for Edge Intelligence against Adversarial\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the boom of edge intelligence, its vulnerability to adversarial attacks\nbecomes an urgent problem. The so-called adversarial example can fool a deep\nlearning model on the edge node to misclassify. Due to the property of\ntransferability, the adversary can easily make a black-box attack using a local\nsubstitute model. Nevertheless, the limitation of resource of edge nodes cannot\nafford a complicated defense mechanism as doing on the cloud data center. To\novercome the challenge, we propose a dynamic defense mechanism, namely EI-MTD.\nIt first obtains robust member models with small size through differential\nknowledge distillation from a complicated teacher model on the cloud data\ncenter. Then, a dynamic scheduling policy based on a Bayesian Stackelberg game\nis applied to the choice of a target model for service. This dynamic defense\ncan prohibit the adversary from selecting an optimal substitute model for\nblack-box attacks. Our experimental result shows that this dynamic scheduling\ncan effectively protect edge intelligence against adversarial attacks under the\nblack-box setting.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:04:18 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 02:44:15 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 01:13:39 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Qian", "Yaguan", ""], ["Shao", "Qiqi", ""], ["Wang", "Jiamin", ""], ["Lin", "Xiang", ""], ["Guo", "Yankai", ""], ["Gu", "Zhaoquan", ""], ["Wang", "Bin", ""], ["Wu", "Chunming", ""]]}, {"id": "2009.10564", "submitter": "Yiwei Wang", "authors": "Yiwei Wang, Wei Wang, Yuxuan Liang, Yujun Cai, Bryan Hooi", "title": "GraphCrop: Subgraph Cropping for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method to regularize graph neural networks (GNNs) for better\ngeneralization in graph classification. Observing that the omission of\nsub-structures does not necessarily change the class label of the whole graph,\nwe develop the \\textbf{GraphCrop} (Subgraph Cropping) data augmentation method\nto simulate the real-world noise of sub-structure omission. In principle,\nGraphCrop utilizes a node-centric strategy to crop a contiguous subgraph from\nthe original graph while maintaining its connectivity. By preserving the valid\nstructure contexts for graph classification, we encourage GNNs to understand\nthe content of graph structures in a global sense, rather than rely on a few\nkey nodes or edges, which may not always be present. GraphCrop is parameter\nlearning free and easy to implement within existing GNN-based graph\nclassifiers. Qualitatively, GraphCrop expands the existing training set by\ngenerating novel and informative augmented graphs, which retain the original\ngraph labels in most cases. Quantitatively, GraphCrop yields significant and\nconsistent gains on multiple standard datasets, and thus enhances the popular\nGNNs to outperform the baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:05:41 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Wang", "Yiwei", ""], ["Wang", "Wei", ""], ["Liang", "Yuxuan", ""], ["Cai", "Yujun", ""], ["Hooi", "Bryan", ""]]}, {"id": "2009.10574", "submitter": "Steffen van Bergerem", "authors": "Steffen van Bergerem, Nicole Schweikardt", "title": "Learning Concepts Described by Weight Aggregation Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider weighted structures, which extend ordinary relational structures\nby assigning weights, i.e. elements from a particular group or ring, to tuples\npresent in the structure. We introduce an extension of first-order logic that\nallows to aggregate weights of tuples, compare such aggregates, and use them to\nbuild more complex formulas. We provide locality properties of fragments of\nthis logic including Feferman-Vaught decompositions and a Gaifman normal form\nfor a fragment called FOW1, as well as a localisation theorem for a larger\nfragment called FOWA1. This fragment can express concepts from various machine\nlearning scenarios. Using the locality properties, we show that concepts\ndefinable in FOWA1 over a weighted background structure of at most\npolylogarithmic degree are agnostically PAC-learnable in polylogarithmic time\nafter pseudo-linear time preprocessing.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:32:42 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["van Bergerem", "Steffen", ""], ["Schweikardt", "Nicole", ""]]}, {"id": "2009.10576", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emma Pierson, Sherri Rose, Shalmali Joshi, Kadija\n  Ferryman, and Marzyeh Ghassemi", "title": "Ethical Machine Learning in Health Care", "comments": "Annual Reviews in Biomedical Data Science 2021", "journal-ref": null, "doi": "10.1146/annurev-biodatasci-092820-114757", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of machine learning (ML) in health care raises numerous ethical\nconcerns, especially as models can amplify existing health inequities. Here, we\noutline ethical considerations for equitable ML in the advancement of health\ncare. Specifically, we frame ethics of ML in health care through the lens of\nsocial justice. We describe ongoing efforts and outline challenges in a\nproposed pipeline of ethical ML in health, ranging from problem selection to\npost-deployment considerations. We close by summarizing recommendations to\naddress these challenges.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:34:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 12:16:57 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 03:26:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Irene Y.", ""], ["Pierson", "Emma", ""], ["Rose", "Sherri", ""], ["Joshi", "Shalmali", ""], ["Ferryman", "Kadija", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10580", "submitter": "Nannan Li", "authors": "Nannan Li, Yu Pan, Yaran Chen, Zixiang Ding, Dongbin Zhao, Zenglin Xu", "title": "Heuristic Rank Selection with Progressively Searching Tensor Ring\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Tensor Ring Networks (TRNs) have been applied in deep networks,\nachieving remarkable successes in compression ratio and accuracy. Although\nhighly related to the performance of TRNs, rank selection is seldom studied in\nprevious works and usually set to equal in experiments. Meanwhile, there is not\nany heuristic method to choose the rank, and an enumerating way to find\nappropriate rank is extremely time-consuming. Interestingly, we discover that\npart of the rank elements is sensitive and usually aggregate in a narrow\nregion, namely an interest region. Therefore, based on the above phenomenon, we\npropose a novel progressive genetic algorithm named Progressively Searching\nTensor Ring Network Search (PSTRN), which has the ability to find optimal rank\nprecisely and efficiently. Through the evolutionary phase and progressive\nphase, PSTRN can converge to the interest region quickly and harvest good\nperformance. Experimental results show that PSTRN can significantly reduce the\ncomplexity of seeking rank, compared with the enumerating method. Furthermore,\nour method is validated on public benchmarks like MNIST, CIFAR10/100, UCF11 and\nHMDB51, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:44:27 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 08:44:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Li", "Nannan", ""], ["Pan", "Yu", ""], ["Chen", "Yaran", ""], ["Ding", "Zixiang", ""], ["Zhao", "Dongbin", ""], ["Xu", "Zenglin", ""]]}, {"id": "2009.10589", "submitter": "Catherine Ordun", "authors": "Catherine Ordun, Edward Raff, Sanjay Purushotham", "title": "The Use of AI for Thermal Emotion Recognition: A Review of Problems and\n  Limitations in Standard Design and Data", "comments": "Presented at AAAI FSS-20: Artificial Intelligence in Government and\n  Public Sector, Washington, DC, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased attention on thermal imagery for Covid-19 screening, the\npublic sector may believe there are new opportunities to exploit thermal as a\nmodality for computer vision and AI. Thermal physiology research has been\nongoing since the late nineties. This research lies at the intersections of\nmedicine, psychology, machine learning, optics, and affective computing. We\nwill review the known factors of thermal vs. RGB imaging for facial emotion\nrecognition. But we also propose that thermal imagery may provide a\nsemi-anonymous modality for computer vision, over RGB, which has been plagued\nby misuse in facial recognition. However, the transition to adopting thermal\nimagery as a source for any human-centered AI task is not easy and relies on\nthe availability of high fidelity data sources across multiple demographics and\nthorough validation. This paper takes the reader on a short review of machine\nlearning in thermal FER and the limitations of collecting and developing\nthermal FER data for AI training. Our motivation is to provide an introductory\noverview into recent advances for thermal FER and stimulate conversation about\nthe limitations in current datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 14:58:59 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ordun", "Catherine", ""], ["Raff", "Edward", ""], ["Purushotham", "Sanjay", ""]]}, {"id": "2009.10601", "submitter": "Xu Chen", "authors": "Shuai Yu and Xu Chen and Zhi Zhou and Xiaowen Gong and Di Wu", "title": "When Deep Reinforcement Learning Meets Federated Learning: Intelligent\n  Multi-Timescale Resource Management for Multi-access Edge Computing in 5G\n  Ultra Dense Network", "comments": "Accepted by IEEE IoTJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-dense edge computing (UDEC) has great potential, especially in the 5G\nera, but it still faces challenges in its current solutions, such as the lack\nof: i) efficient utilization of multiple 5G resources (e.g., computation,\ncommunication, storage and service resources); ii) low overhead offloading\ndecision making and resource allocation strategies; and iii) privacy and\nsecurity protection schemes. Thus, we first propose an intelligent ultra-dense\nedge computing (I-UDEC) framework, which integrates blockchain and Artificial\nIntelligence (AI) into 5G ultra-dense edge computing networks. First, we show\nthe architecture of the framework. Then, in order to achieve real-time and low\noverhead computation offloading decisions and resource allocation strategies,\nwe design a novel two-timescale deep reinforcement learning (\\textit{2Ts-DRL})\napproach, consisting of a fast-timescale and a slow-timescale learning process,\nrespectively. The primary objective is to minimize the total offloading delay\nand network resource usage by jointly optimizing computation offloading,\nresource allocation and service caching placement. We also leverage federated\nlearning (FL) to train the \\textit{2Ts-DRL} model in a distributed manner,\naiming to protect the edge devices' data privacy. Simulation results\ncorroborate the effectiveness of both the \\textit{2Ts-DRL} and FL in the I-UDEC\nframework and prove that our proposed algorithm can reduce task execution time\nup to 31.87%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:08:00 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Yu", "Shuai", ""], ["Chen", "Xu", ""], ["Zhou", "Zhi", ""], ["Gong", "Xiaowen", ""], ["Wu", "Di", ""]]}, {"id": "2009.10610", "submitter": "Daniel Neider", "authors": "Igor Khmelnitsky, Daniel Neider, Rajarshi Roy, Beno\\^it Barbot,\n  Benedikt Bollig, Alain Finkel, Serge Haddad, Martin Leucker, Lina Ye", "title": "Property-Directed Verification of Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a property-directed approach to verifying recurrent\nneural networks (RNNs). To this end, we learn a deterministic finite automaton\nas a surrogate model from a given RNN using active automata learning. This\nmodel may then be analyzed using model checking as verification technique. The\nterm property-directed reflects the idea that our procedure is guided and\ncontrolled by the given property rather than performing the two steps\nseparately. We show that this not only allows us to discover small\ncounterexamples fast, but also to generalize them by pumping towards faulty\nflows hinting at the underlying error in the RNN.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:15:20 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Khmelnitsky", "Igor", ""], ["Neider", "Daniel", ""], ["Roy", "Rajarshi", ""], ["Barbot", "Beno\u00eet", ""], ["Bollig", "Benedikt", ""], ["Finkel", "Alain", ""], ["Haddad", "Serge", ""], ["Leucker", "Martin", ""], ["Ye", "Lina", ""]]}, {"id": "2009.10613", "submitter": "Larry Muhlstein", "authors": "Larry Muhlstein", "title": "The Relativity of Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately there has been a lot of discussion about why deep learning algorithms\nperform better than we would theoretically suspect. To get insight into this\nquestion, it helps to improve our understanding of how learning works. We\nexplore the core problem of generalization and show that long-accepted Occam's\nrazor and parsimony principles are insufficient to ground learning. Instead, we\nderive and demonstrate a set of relativistic principles that yield clearer\ninsight into the nature and dynamics of learning. We show that concepts of\nsimplicity are fundamentally contingent, that all learning operates relative to\nan initial guess, and that generalization cannot be measured or strongly\ninferred, but that it can be expected given enough observation. Using these\nprinciples, we reconstruct our understanding in terms of distributed learning\nsystems whose components inherit beliefs and update them. We then apply this\nperspective to elucidate the nature of some real world inductive processes\nincluding deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:17:26 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Muhlstein", "Larry", ""]]}, {"id": "2009.10616", "submitter": "Anas Blasi", "authors": "Mohammad Awis Al Lababede, Anas H. Blasi, Mohammed A. Alsuwaiket", "title": "Mosques Smart Domes System using Machine Learning Algorithms", "comments": null, "journal-ref": null, "doi": "10.14569/IJACSA.2020.0110347", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of mosques around the world are suffering some problems such as\nventilation and difficulty getting rid of bacteria, especially in rush hours\nwhere congestion in mosques leads to air pollution and spread of bacteria, in\naddition to unpleasant odors and to a state of discomfort during the pray\ntimes, where in most mosques there are no enough windows to ventilate the\nmosque well. This paper aims to solve these problems by building a model of\nsmart mosques domes using weather features and outside temperatures. Machine\nlearning algorithms such as k Nearest Neighbors and Decision Tree were applied\nto predict the state of the domes open or close. The experiments of this paper\nwere applied on Prophet mosque in Saudi Arabia, which basically contains twenty\nseven manually moving domes. Both machine learning algorithms were tested and\nevaluated using different evaluation methods. After comparing the results for\nboth algorithms, DT algorithm was achieved higher accuracy 98% comparing with\n95% accuracy for kNN algorithm. Finally, the results of this study were\npromising and will be helpful for all mosques to use our proposed model for\ncontrolling domes automatically.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 19:51:30 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lababede", "Mohammad Awis Al", ""], ["Blasi", "Anas H.", ""], ["Alsuwaiket", "Mohammed A.", ""]]}, {"id": "2009.10622", "submitter": "TrungTin Nguyen", "authors": "TrungTin Nguyen, Hien D Nguyen, Faicel Chamroukhi and Geoffrey J\n  McLachlan", "title": "An $l_1$-oracle inequality for the Lasso in mixture-of-experts\n  regression models", "comments": "Corrected typos. Added new Section 4. Discussion and comparisons", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixture-of-experts (MoE) models are a popular framework for modeling\nheterogeneity in data, for both regression and classification problems in\nstatistics and machine learning, due to their flexibility and the abundance of\nstatistical estimation and model choice tools. Such flexibility comes from\nallowing the mixture weights (or gating functions) in the MoE model to depend\non the explanatory variables, along with the experts (or component densities).\nThis permits the modeling of data arising from more complex data generating\nprocesses, compared to the classical finite mixtures and finite mixtures of\nregression models, whose mixing parameters are independent of the covariates.\nThe use of MoE models in a high-dimensional setting, when the number of\nexplanatory variables can be much larger than the sample size (i.e., $p\\gg n$),\nis challenging from a computational point of view, and in particular from a\ntheoretical point of view, where the literature is still lacking results in\ndealing with the curse of dimensionality, in both the statistical estimation\nand feature selection. We consider the finite mixture-of-experts model with\nsoft-max gating functions and Gaussian experts for high-dimensional regression\non heterogeneous data, and its $l_1$-regularized estimation via the Lasso. We\nfocus on the Lasso estimation properties rather than its feature selection\nproperties. We provide a lower bound on the regularization parameter of the\nLasso function that ensures an $l_1$-oracle inequality satisfied by the Lasso\nestimator according to the Kullback-Leibler loss.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:23:35 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 17:28:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Nguyen", "TrungTin", ""], ["Nguyen", "Hien D", ""], ["Chamroukhi", "Faicel", ""], ["McLachlan", "Geoffrey J", ""]]}, {"id": "2009.10625", "submitter": "Petru Soviany", "authors": "Petru Soviany", "title": "Curriculum Learning with Diversity for Supervised Computer Vision Tasks", "comments": "Accepted at MRC 2020 @ ECAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Curriculum learning techniques are a viable solution for improving the\naccuracy of automatic models, by replacing the traditional random training with\nan easy-to-hard strategy. However, the standard curriculum methodology does not\nautomatically provide improved results, but it is constrained by multiple\nelements like the data distribution or the proposed model. In this paper, we\nintroduce a novel curriculum sampling strategy which takes into consideration\nthe diversity of the training data together with the difficulty of the inputs.\nWe determine the difficulty using a state-of-the-art estimator based on the\nhuman time required for solving a visual search task. We consider this kind of\ndifficulty metric to be better suited for solving general problems, as it is\nnot based on certain task-dependent elements, but more on the context of each\nimage. We ensure the diversity during training, giving higher priority to\nelements from less visited classes. We conduct object detection and instance\nsegmentation experiments on Pascal VOC 2007 and Cityscapes data sets,\nsurpassing both the randomly-trained baseline and the standard curriculum\napproach. We prove that our strategy is very efficient for unbalanced data\nsets, leading to faster convergence and more accurate results, when other\ncurriculum-based strategies fail.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:32:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Soviany", "Petru", ""]]}, {"id": "2009.10634", "submitter": "Hans Dolfing", "authors": "Hans J.G.A. Dolfing", "title": "Whole page recognition of historical handwriting", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historical handwritten documents guard an important part of human knowledge\nonly within reach of a few scholars and experts. Recent developments in machine\nlearning and handwriting research have the potential of rendering this\ninformation accessible and searchable to a larger audience. To this end, we\ninvestigate an end-to-end inference approach without text localization which\ntakes a handwritten page and transcribes its full text. No explicit character,\nword or line segmentation is involved in inference which is why we call this\napproach \"segmentation free\". We explore its robustness and accuracy compared\nto a line-by-line segmented approach based on the IAM, RODRIGO and ScribbleLens\ncorpora, in three languages with handwriting styles spanning 400 years. We\nconcentrate on model types and sizes which can be deployed on a hand-held or\nembedded device. We conclude that a whole page inference approach without text\nlocalization and segmentation is competitive.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:46:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dolfing", "Hans J. G. A.", ""]]}, {"id": "2009.10639", "submitter": "Yi-Shan Lin", "authors": "Yi-Shan Lin, Wen-Chuan Lee, Z. Berkay Celik", "title": "What Do You See? Evaluation of Explainable Artificial Intelligence (XAI)\n  Interpretability through Neural Backdoors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXplainable AI (XAI) methods have been proposed to interpret how a deep\nneural network predicts inputs through model saliency explanations that\nhighlight the parts of the inputs deemed important to arrive a decision at a\nspecific target. However, it remains challenging to quantify correctness of\ntheir interpretability as current evaluation approaches either require\nsubjective input from humans or incur high computation cost with automated\nevaluation. In this paper, we propose backdoor trigger patterns--hidden\nmalicious functionalities that cause misclassification--to automate the\nevaluation of saliency explanations. Our key observation is that triggers\nprovide ground truth for inputs to evaluate whether the regions identified by\nan XAI method are truly relevant to its output. Since backdoor triggers are the\nmost important features that cause deliberate misclassification, a robust XAI\nmethod should reveal their presence at inference time. We introduce three\ncomplementary metrics for systematic evaluation of explanations that an XAI\nmethod generates and evaluate seven state-of-the-art model-free and\nmodel-specific posthoc methods through 36 models trojaned with specifically\ncrafted triggers using color, shape, texture, location, and size. We discovered\nsix methods that use local explanation and feature relevance fail to completely\nhighlight trigger regions, and only a model-free approach can uncover the\nentire trigger region.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:53:19 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lin", "Yi-Shan", ""], ["Lee", "Wen-Chuan", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2009.10644", "submitter": "Daniel Dunlavy", "authors": "Alexis Cooper and Xin Zhou and Scott Heidbrink and Daniel M. Dunlavy", "title": "Using Neural Architecture Search for Improving Software Flaw Detection\n  in Multimodal Deep Learning Models", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": "SAND2020-10141R", "categories": "stat.ML cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software flaw detection using multimodal deep learning models has been\ndemonstrated as a very competitive approach on benchmark problems. In this\nwork, we demonstrate that even better performance can be achieved using neural\narchitecture search (NAS) combined with multimodal learning models. We adapt a\nNAS framework aimed at investigating image classification to the problem of\nsoftware flaw detection and demonstrate improved results on the Juliet Test\nSuite, a popular benchmarking data set for measuring performance of machine\nlearning models in this problem domain.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 15:59:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Cooper", "Alexis", ""], ["Zhou", "Xin", ""], ["Heidbrink", "Scott", ""], ["Dunlavy", "Daniel M.", ""]]}, {"id": "2009.10679", "submitter": "Manish Bhattarai", "authors": "Manish Bhattarai, Aura Rose Jensen-Curtis, Manel Mart\\'iNez-Ram\\'on", "title": "An embedded deep learning system for augmented reality in firefighting\n  applications", "comments": "Accepted to ICMLA Special Session on Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firefighting is a dynamic activity, in which numerous operations occur\nsimultaneously. Maintaining situational awareness (i.e., knowledge of current\nconditions and activities at the scene) is critical to the accurate\ndecision-making necessary for the safe and successful navigation of a fire\nenvironment by firefighters. Conversely, the disorientation caused by hazards\nsuch as smoke and extreme heat can lead to injury or even fatality. This\nresearch implements recent advancements in technology such as deep learning,\npoint cloud and thermal imaging, and augmented reality platforms to improve a\nfirefighter's situational awareness and scene navigation through improved\ninterpretation of that scene. We have designed and built a prototype embedded\nsystem that can leverage data streamed from cameras built into a firefighter's\npersonal protective equipment (PPE) to capture thermal, RGB color, and depth\nimagery and then deploy already developed deep learning models to analyze the\ninput data in real time. The embedded system analyzes and returns the processed\nimages via wireless streaming, where they can be viewed remotely and relayed\nback to the firefighter using an augmented reality platform that visualizes the\nresults of the analyzed inputs and draws the firefighter's attention to objects\nof interest, such as doors and windows otherwise invisible through smoke and\nflames.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:55:44 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bhattarai", "Manish", ""], ["Jensen-Curtis", "Aura Rose", ""], ["Mart\u00edNez-Ram\u00f3n", "Manel", ""]]}, {"id": "2009.10684", "submitter": "Bruno Taill\\'e", "authors": "Bruno Taill\\'e, Vincent Guigue, Geoffrey Scoutheeten and Patrick\n  Gallinari", "title": "Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite efforts to distinguish three different evaluation setups (Bekoulis et\nal., 2018), numerous end-to-end Relation Extraction (RE) articles present\nunreliable performance comparison to previous work. In this paper, we first\nidentify several patterns of invalid comparisons in published papers and\ndescribe them to avoid their propagation. We then propose a small empirical\nstudy to quantify the impact of the most common mistake and evaluate it leads\nto overestimating the final RE performance by around 5% on ACE05. We also seize\nthis opportunity to study the unexplored ablations of two recent developments:\nthe use of language model pretraining (specifically BERT) and span-level NER.\nThis meta-analysis emphasizes the need for rigor in the report of both the\nevaluation setting and the datasets statistics and we call for unifying the\nevaluation setting in end-to-end RE.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:59:15 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:43:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Taill\u00e9", "Bruno", ""], ["Guigue", "Vincent", ""], ["Scoutheeten", "Geoffrey", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2009.10750", "submitter": "Sahisnu Mazumder", "authors": "Bing Liu, Sahisnu Mazumder", "title": "Lifelong Learning Dialogue Systems: Chatbots that Self-Learn On the Job", "comments": "A revised version of this work has been published in AAAI-2021 with\n  title: \"Lifelong and Continual Learning Dialogue Systems: Learning during\n  Conversation\". Please use this revised AAAI-21 version for citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems, also called chatbots, are now used in a wide range of\napplications. However, they still have some major weaknesses. One key weakness\nis that they are typically trained from manually-labeled data and/or written\nwith handcrafted rules, and their knowledge bases (KBs) are also compiled by\nhuman experts. Due to the huge amount of manual effort involved, they are\ndifficult to scale and also tend to produce many errors ought to their limited\nability to understand natural language and the limited knowledge in their KBs.\nThus, the level of user satisfactory is often low. In this paper, we propose to\ndramatically improve this situation by endowing the system the ability to\ncontinually learn (1) new world knowledge, (2) new language expressions to\nground them to actions, and (3) new conversational skills, during conversation\nor \"on the job\" by themselves so that as the systems chat more and more with\nusers, they become more and more knowledgeable and are better and better able\nto understand diverse natural language expressions and improve their\nconversational skills. A key approach to achieving these is to exploit the\nmulti-user environment of such systems to self-learn through interactions with\nusers via verb and non-verb means. The paper discusses not only key challenges\nand promising directions to learn from users during conversation but also how\nto ensure the correctness of the learned knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 18:10:08 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 00:10:21 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Liu", "Bing", ""], ["Mazumder", "Sahisnu", ""]]}, {"id": "2009.10777", "submitter": "Thyagharajan K K", "authors": "S. Kavitha, K. K. Thyagharajan", "title": "Efficient DWT-based fusion techniques using genetic algorithm for\n  optimal parameter estimation", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": "10.1007/s00500-015-2009-6", "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image fusion plays a vital role in medical imaging. Image fusion aims to\nintegrate complementary as well as redundant information from multiple\nmodalities into a single fused image without distortion or loss of information.\nIn this research work, discrete wavelet transform (DWT)and undecimated discrete\nwavelet transform (UDWT)-based fusion techniques using genetic algorithm\n(GA)foroptimalparameter(weight)estimationinthefusionprocessareimplemented and\nanalyzed with multi-modality brain images. The lack of shift variance while\nperforming image fusion using DWT is addressed using UDWT. The proposed fusion\nmodel uses an efficient, modified GA in DWT and UDWT for optimal parameter\nestimation, to improve the image quality and contrast. The complexity of the\nbasic GA (pixel level) has been reduced in the modified GA (feature level), by\nlimiting the search space. It is observed from our experiments that fusion\nusing DWT and UDWT techniques with GA for optimal parameter estimation resulted\nin a better fused image in the aspects of retaining the information and\ncontrast without error, both in human perception as well as evaluation using\nobjective metrics. The contributions of this research work are (1) reduced time\nand space complexity in estimating the weight values using GA for fusion (2)\nsystem is scalable for input image of any size with similar time complexity,\nowing to feature level GA implementation and (3) identification of source image\nthat contributes more to the fused image, from the weight values estimated.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:28:57 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kavitha", "S.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.10778", "submitter": "Danqing Zhang", "authors": "Danqing Zhang, Tao Li, Haiyang Zhang, Bing Yin", "title": "On Data Augmentation for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on data augmentation for the extreme multi-label\nclassification (XMC) problem. One of the most challenging issues of XMC is the\nlong tail label distribution where even strong models suffer from insufficient\nsupervision. To mitigate such label bias, we propose a simple and effective\naugmentation framework and a new state-of-the-art classifier. Our augmentation\nframework takes advantage of the pre-trained GPT-2 model to generate\nlabel-invariant perturbations of the input texts to augment the existing\ntraining data. As a result, it present substantial improvements over baseline\nmodels. Our contributions are two-factored: (1) we introduce a new\nstate-of-the-art classifier that uses label attention with RoBERTa and combine\nit with our augmentation framework for further improvement; (2) we present a\nbroad study on how effective are different augmentation methods in the XMC\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:31:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhang", "Danqing", ""], ["Li", "Tao", ""], ["Zhang", "Haiyang", ""], ["Yin", "Bing", ""]]}, {"id": "2009.10790", "submitter": "Seamus Brady", "authors": "Seamus Brady", "title": "Using Unsupervised Learning to Help Discover the Causal Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The software outlined in this paper, AitiaExplorer, is an exploratory causal\nanalysis tool which uses unsupervised learning for feature selection in order\nto expedite causal discovery. In this paper the problem space of causality is\nbriefly described and an overview of related research is provided. A problem\nstatement and requirements for the software are outlined. The key requirements\nin the implementation, the key design decisions and the actual implementation\nof AitiaExplorer are discussed. Finally, this implementation is evaluated in\nterms of the problem statement and requirements outlined earlier. It is found\nthat AitiaExplorer meets these requirements and is a useful exploratory causal\nanalysis tool that automatically selects subsets of important features from a\ndataset and creates causal graph candidates for review based on these features.\nThe software is available at https://github.com/corvideon/aitiaexplorer\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:07:19 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Brady", "Seamus", ""]]}, {"id": "2009.10800", "submitter": "Susheel Suresh", "authors": "Susheel Suresh and Jennifer Neville", "title": "A Hybrid Model for Learning Embeddings and Logical Rules Simultaneously\n  from Knowledge Graphs", "comments": "10 page extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of knowledge graph (KG) reasoning has been widely explored by\ntraditional rule-based systems and more recently by knowledge graph embedding\nmethods. While logical rules can capture deterministic behavior in a KG they\nare brittle and mining ones that infer facts beyond the known KG is\nchallenging. Probabilistic embedding methods are effective in capturing global\nsoft statistical tendencies and reasoning with them is computationally\nefficient. While embedding representations learned from rich training data are\nexpressive, incompleteness and sparsity in real-world KGs can impact their\neffectiveness. We aim to leverage the complementary properties of both methods\nto develop a hybrid model that learns both high-quality rules and embeddings\nsimultaneously. Our method uses a cross feedback paradigm wherein, an embedding\nmodel is used to guide the search of a rule mining system to mine rules and\ninfer new facts. These new facts are sampled and further used to refine the\nembedding model. Experiments on multiple benchmark datasets show the\neffectiveness of our method over other competitive standalone and hybrid\nbaselines. We also show its efficacy in a sparse KG setting and finally explore\nthe connection with negative sampling.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:29:27 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Suresh", "Susheel", ""], ["Neville", "Jennifer", ""]]}, {"id": "2009.10835", "submitter": "Morteza Haghir Chehreghani", "authors": "John Daniel Boss\\'er, Erik S\\\"orstadius, Morteza Haghir Chehreghani", "title": "Model-Centric and Data-Centric Aspects of Active Learning for Neural\n  Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study different data-centric and model-centric aspects of active learning\nwith neural network models. i) We investigate incremental and cumulative\ntraining modes that specify how the currently labeled data are used for\ntraining. ii) Neural networks are models with a large capacity. Thus, we study\nhow active learning depends on the number of epochs and neurons as well as the\nchoice of batch size. iii) We analyze in detail the behavior of query\nstrategies and their corresponding informativeness measures and accordingly\npropose more efficient querying and active learning paradigms. iv) We perform\nstatistical analyses, e.g., on actively learned classes and test error\nestimation, that reveal several insights about active learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:58:03 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:09:41 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Boss\u00e9r", "John Daniel", ""], ["S\u00f6rstadius", "Erik", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2009.10847", "submitter": "Mikhail Galkin", "authors": "Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck,\n  Jens Lehmann", "title": "Message Passing for Hyper-Relational Knowledge Graphs", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating\nadditional key-value pairs along with the main triple to disambiguate, or\nrestrict the validity of a fact. In this work, we propose a message passing\nbased graph encoder - StarE capable of modeling such hyper-relational KGs.\nUnlike existing approaches, StarE can encode an arbitrary number of additional\ninformation (qualifiers) along with the main triple while keeping the semantic\nroles of qualifiers and triples intact. We also demonstrate that existing\nbenchmarks for evaluating link prediction (LP) performance on hyper-relational\nKGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset\n- WD50K. Our experiments demonstrate that StarE based LP model outperforms\nexisting approaches across multiple benchmarks. We also confirm that leveraging\nqualifiers is vital for link prediction with gains up to 25 MRR points compared\nto triple-based representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 22:38:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Galkin", "Mikhail", ""], ["Trivedi", "Priyansh", ""], ["Maheshwari", "Gaurav", ""], ["Usbeck", "Ricardo", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.10864", "submitter": "John Rieffel", "authors": "Kyle Doney, Aikaterini Petridou, Jacob Karaul, Ali Khan, Geoffrey Liu\n  and John Rieffel", "title": "Behavioral Repertoires for Soft Tensegrity Robots", "comments": "7 pages, 6 figures, accepted, IEEE SSCI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile soft robots offer compelling applications in fields ranging from urban\nsearch and rescue to planetary exploration. A critical challenge of soft\nrobotic control is that the nonlinear dynamics imposed by soft materials often\nresult in complex behaviors that are counterintuitive and hard to model or\npredict. As a consequence, most behaviors for mobile soft robots are discovered\nthrough empirical trial and error and hand-tuning. A second challenge is that\nsoft materials are difficult to simulate with high fidelity -- leading to a\nsignificant reality gap when trying to discover or optimize new behaviors. In\nthis work we employ a Quality Diversity Algorithm running model-free on a\nphysical soft tensegrity robot that autonomously generates a behavioral\nrepertoire with no a priori knowledge of the robot dynamics, and minimal human\nintervention. The resulting behavior repertoire displays a diversity of unique\nlocomotive gaits useful for a variety of tasks. These results help provide a\nroad map for increasing the behavioral capabilities of mobile soft robots\nthrough real-world automation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 00:09:35 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 18:51:23 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Doney", "Kyle", ""], ["Petridou", "Aikaterini", ""], ["Karaul", "Jacob", ""], ["Khan", "Ali", ""], ["Liu", "Geoffrey", ""], ["Rieffel", "John", ""]]}, {"id": "2009.10867", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Yiming Ying, Steven Skiena", "title": "Online AUC Optimization for Sparse High-Dimensional Datasets", "comments": "20th IEEE International Conference on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Area Under the ROC Curve (AUC) is a widely used performance measure for\nimbalanced classification arising from many application domains where\nhigh-dimensional sparse data is abundant. In such cases, each $d$ dimensional\nsample has only $k$ non-zero features with $k \\ll d$, and data arrives\nsequentially in a streaming form. Current online AUC optimization algorithms\nhave high per-iteration cost $\\mathcal{O}(d)$ and usually produce non-sparse\nsolutions in general, and hence are not suitable for handling the data\nchallenge mentioned above.\n  In this paper, we aim to directly optimize the AUC score for high-dimensional\nsparse datasets under online learning setting and propose a new algorithm,\n\\textsc{FTRL-AUC}. Our proposed algorithm can process data in an online fashion\nwith a much cheaper per-iteration cost $\\mathcal{O}(k)$, making it amenable for\nhigh-dimensional sparse streaming data analysis. Our new algorithmic design\ncritically depends on a novel reformulation of the U-statistics AUC objective\nfunction as the empirical saddle point reformulation, and the innovative\nintroduction of the \"lazy update\" rule so that the per-iteration complexity is\ndramatically reduced from $\\mathcal{O}(d)$ to $\\mathcal{O}(k)$. Furthermore,\n\\textsc{FTRL-AUC} can inherently capture sparsity more effectively by applying\na generalized Follow-The-Regularized-Leader (FTRL) framework.\n  Experiments on real-world datasets demonstrate that \\textsc{FTRL-AUC}\nsignificantly improves both run time and model sparsity while achieving\ncompetitive AUC scores compared with the state-of-the-art methods. Comparison\nwith the online learning method for logistic loss demonstrates that\n\\textsc{FTRL-AUC} achieves higher AUC scores especially when datasets are\nimbalanced.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 00:50:01 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhou", "Baojian", ""], ["Ying", "Yiming", ""], ["Skiena", "Steven", ""]]}, {"id": "2009.10874", "submitter": "Xianbiao Qi", "authors": "Bingcong Li, Xin Tang, Xianbiao Qi, Yihao Chen, Rong Xiao", "title": "Hamming OCR: A Locality Sensitive Hashing Neural Network for Scene Text\n  Recognition", "comments": "9 Pages, 4 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, inspired by Transformer, self-attention-based scene text\nrecognition approaches have achieved outstanding performance. However, we find\nthat the size of model expands rapidly with the lexicon increasing.\nSpecifically, the number of parameters for softmax classification layer and\noutput embedding layer are proportional to the vocabulary size. It hinders the\ndevelopment of a lightweight text recognition model especially applied for\nChinese and multiple languages. Thus, we propose a lightweight scene text\nrecognition model named Hamming OCR. In this model, a novel Hamming classifier,\nwhich adopts locality sensitive hashing (LSH) algorithm to encode each\ncharacter, is proposed to replace the softmax regression and the generated LSH\ncode is directly employed to replace the output embedding. We also present a\nsimplified transformer decoder to reduce the number of parameters by removing\nthe feed-forward network and using cross-layer parameter sharing technique.\nCompared with traditional methods, the number of parameters in both\nclassification and embedding layers is independent on the size of vocabulary,\nwhich significantly reduces the storage requirement without loss of accuracy.\nExperimental results on several datasets, including four public benchmaks and a\nChinese text dataset synthesized by SynthText with more than 20,000 characters,\nshows that Hamming OCR achieves competitive results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:20:19 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Bingcong", ""], ["Tang", "Xin", ""], ["Qi", "Xianbiao", ""], ["Chen", "Yihao", ""], ["Xiao", "Rong", ""]]}, {"id": "2009.10883", "submitter": "EPTCS", "authors": "Andrew M. Wells (Rice University), Morteza Lahijanian (University of\n  Colorado at Boulder), Lydia E. Kavraki (Rice University), Moshe Y. Vardi\n  (Rice University)", "title": "LTLf Synthesis on Probabilistic Systems", "comments": "In Proceedings GandALF 2020, arXiv:2009.09360", "journal-ref": "EPTCS 326, 2020, pp. 166-181", "doi": "10.4204/EPTCS.326.11", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems are naturally modeled as Markov Decision Processes (MDPs),\ncombining probabilities and strategic actions. Given a model of a system as an\nMDP and some logical specification of system behavior, the goal of synthesis is\nto find a policy that maximizes the probability of achieving this behavior. A\npopular choice for defining behaviors is Linear Temporal Logic (LTL). Policy\nsynthesis on MDPs for properties specified in LTL has been well studied. LTL,\nhowever, is defined over infinite traces, while many properties of interest are\ninherently finite. Linear Temporal Logic over finite traces (LTLf) has been\nused to express such properties, but no tools exist to solve policy synthesis\nfor MDP behaviors given finite-trace properties. We present two algorithms for\nsolving this synthesis problem: the first via reduction of LTLf to LTL and the\nsecond using native tools for LTLf. We compare the scalability of these two\napproaches for synthesis and show that the native approach offers better\nscalability compared to existing automaton generation tools for LTL.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:26:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wells", "Andrew M.", "", "Rice University"], ["Lahijanian", "Morteza", "", "University of\n  Colorado at Boulder"], ["Kavraki", "Lydia E.", "", "Rice University"], ["Vardi", "Moshe Y.", "", "Rice University"]]}, {"id": "2009.10887", "submitter": "Ryuta Mizutani", "authors": "Ryuta Mizutani, Senta Noguchi, Rino Saiga, Mitsuhiro Miyashita, Makoto\n  Arai, and Masanari Itokawa", "title": "Schizophrenia-mimicking layers outperform conventional neural network\n  layers", "comments": "15 pages, 4 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have reported nanometer-scale three-dimensional studies of brain networks\nof schizophrenia cases and found that their neurites are thin and tortuous\ncompared to healthy controls. This suggests that connections between distal\nneurons are impaired in microcircuits of the schizophrenia cases. In this\nstudy, we applied this biological findings to designing schizophrenia-mimicking\nartificial neural network to simulate the connection impairment in the\ndisorder. Neural networks having the schizophrenia connection layer in place of\nfully connected layer were subjected to image classification tasks using MNIST\nand CIFAR-10 datasets. The obtained results revealed that the schizophrenia\nconnection layer is tolerant to overfitting and outperforms fully connected\nlayer. Schizophrenia-mimicking convolution layer was also tested with the VGG\nconfiguration, showing that 60% of kernel weights of the last convolution layer\ncan be eliminated while keeping competitive performance.\nSchizophrenia-mimicking layers can be used instead of fully-connected or\nconvolution layers without any change in the network configuration and training\nprocedures, hence the outperformance of the schizophrenia-mimicking layer is\neasily incorporated in neural networks. The results of this study indicate that\nthe connection impairment in schizophrenia is not a burden to the brain, but\nhas some functional roles to attain a better brain performance. We suggest that\nthe seemingly neuropathological alterations observed in schizophrenia have been\nrationally implemented in our brain during the process of biological evolution.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:35:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mizutani", "Ryuta", ""], ["Noguchi", "Senta", ""], ["Saiga", "Rino", ""], ["Miyashita", "Mitsuhiro", ""], ["Arai", "Makoto", ""], ["Itokawa", "Masanari", ""]]}, {"id": "2009.10893", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Pruning Convolutional Filters using Batch Bridgeout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art computer vision models are rapidly increasing in capacity,\nwhere the number of parameters far exceeds the number required to fit the\ntraining set. This results in better optimization and generalization\nperformance. However, the huge size of contemporary models results in large\ninference costs and limits their use on resource-limited devices. In order to\nreduce inference costs, convolutional filters in trained neural networks could\nbe pruned to reduce the run-time memory and computational requirements during\ninference. However, severe post-training pruning results in degraded\nperformance if the training algorithm results in dense weight vectors. We\npropose the use of Batch Bridgeout, a sparsity inducing stochastic\nregularization scheme, to train neural networks so that they could be pruned\nefficiently with minimal degradation in performance. We evaluate the proposed\nmethod on common computer vision models VGGNet, ResNet, and Wide-ResNet on the\nCIFAR image classification task. For all the networks, experimental results\nshow that Batch Bridgeout trained networks achieve higher accuracy across a\nwide range of pruning intensities compared to Dropout and weight decay\nregularization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:51:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "2009.10938", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang and Jiahao Xu and Charlie Soh and Lihui Chen", "title": "LA-HCN: Label-based Attention for Hierarchical Multi-label\n  TextClassification Neural Network", "comments": "code is available at https://github.com/XinyiZ001/LA-HCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical multi-label text classification (HMTC) has been gaining\npopularity in recent years thanks to its applicability to a plethora of\nreal-world applications. The existing HMTC algorithms largely focus on the\ndesign of classifiers, such as the local, global, or a combination of them.\nHowever, very few studies have focused on hierarchical feature extraction and\nexplore the association between the hierarchical labels and the text. In this\npaper, we propose a Label-based Attention for Hierarchical Mutlti-label Text\nClassification Neural Network (LA-HCN), where the novel label-based attention\nmodule is designed to hierarchically extract important information from the\ntext based on the labels from different hierarchy levels. Besides, hierarchical\ninformation is shared across levels while preserving the hierarchical\nlabel-based information. Separate local and global document embeddings are\nobtained and used to facilitate the respective local and global\nclassifications. In our experiments, LA-HCN outperforms other state-of-the-art\nneural network-based HMTC algorithms on four public HMTC datasets. The ablation\nstudy also demonstrates the effectiveness of the proposed label-based attention\nmodule as well as the novel local and global embeddings and classifications. By\nvisualizing the learned attention (words), we find that LA-HCN is able to\nextract meaningful information corresponding to the different labels which\nprovides explainability that may be helpful for the human analyst.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 06:18:25 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:43:11 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 12:20:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Xinyi", ""], ["Xu", "Jiahao", ""], ["Soh", "Charlie", ""], ["Chen", "Lihui", ""]]}, {"id": "2009.10968", "submitter": "Sao Mai Nguyen", "authors": "Alexandre Manoury (IMT Atlantique - INFO), Sao Mai Nguyen, C\\'edric\n  Buche", "title": "Hierarchical Affordance Discovery using Intrinsic Motivation", "comments": "7th International Conference on Human-Agent Interaction (HAI '19),\n  Oct 2019, Kyoto, Japan", "journal-ref": null, "doi": "10.1145/3349537.3351898", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be capable of lifelong learning in a real-life environment, robots have to\ntackle multiple challenges. Being able to relate physical properties they may\nobserve in their environment to possible interactions they may have is one of\nthem. This skill, named affordance learning, is strongly related to embodiment\nand is mastered through each person's development: each individual learns\naffordances differently through their own interactions with their surroundings.\nCurrent methods for affordance learning usually use either fixed actions to\nlearn these affordances or focus on static setups involving a robotic arm to be\noperated. In this article, we propose an algorithm using intrinsic motivation\nto guide the learning of affordances for a mobile robot. This algorithm is\ncapable to autonomously discover, learn and adapt interrelated affordances\nwithout pre-programmed actions. Once learned, these affordances may be used by\nthe algorithm to plan sequences of actions in order to perform tasks of various\ndifficulties. We then present one experiment and analyse our system before\ncomparing it with other approaches from reinforcement learning and affordance\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 07:18:21 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Manoury", "Alexandre", "", "IMT Atlantique - INFO"], ["Nguyen", "Sao Mai", ""], ["Buche", "C\u00e9dric", ""]]}, {"id": "2009.10989", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Dhruv Gelda, Zhongfang Zhuang, Yan Zheng, Liang\n  Gou, Wei Zhang", "title": "Towards a Flexible Embedding Learning Framework", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a fundamental building block for analyzing\nentities in a database. While the existing embedding learning methods are\neffective in various data mining problems, their applicability is often limited\nbecause these methods have pre-determined assumptions on the type of semantics\ncaptured by the learned embeddings, and the assumptions may not well align with\nspecific downstream tasks. In this work, we propose an embedding learning\nframework that 1) uses an input format that is agnostic to input data type, 2)\nis flexible in terms of the relationships that can be embedded into the learned\nrepresentations, and 3) provides an intuitive pathway to incorporate domain\nknowledge into the embedding learning process. Our proposed framework utilizes\na set of entity-relation-matrices as the input, which quantifies the affinities\namong different entities in the database. Moreover, a sampling mechanism is\ncarefully designed to establish a direct connection between the input and the\ninformation captured by the output embeddings. To complete the representation\nlearning toolbox, we also outline a simple yet effective post-processing\ntechnique to properly visualize the learned embeddings. Our empirical results\ndemonstrate that the proposed framework, in conjunction with a set of relevant\nentity-relation-matrices, outperforms the existing state-of-the-art approaches\nin various data mining tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:00:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Gelda", "Dhruv", ""], ["Zhuang", "Zhongfang", ""], ["Zheng", "Yan", ""], ["Gou", "Liang", ""], ["Zhang", "Wei", ""]]}, {"id": "2009.11044", "submitter": "Dime Kostadinov", "authors": "Dimche Kostadinov and Davide Scaramuzza", "title": "Unsupervised Feature Learning for Event Data: Direct vs Inverse Problem\n  Formulation", "comments": null, "journal-ref": "IAPR IEEE/Computer Society International Conference on Pattern\n  Recognition (ICPR), Milan, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based cameras record an asynchronous stream of per-pixel brightness\nchanges. As such, they have numerous advantages over the standard frame-based\ncameras, including high temporal resolution, high dynamic range, and no motion\nblur. Due to the asynchronous nature, efficient learning of compact\nrepresentation for event data is challenging. While it remains not explored the\nextent to which the spatial and temporal event \"information\" is useful for\npattern recognition tasks. In this paper, we focus on single-layer\narchitectures. We analyze the performance of two general problem formulations:\nthe direct and the inverse, for unsupervised feature learning from local event\ndata (local volumes of events described in space-time). We identify and show\nthe main advantages of each approach. Theoretically, we analyze guarantees for\nan optimal solution, possibility for asynchronous, parallel parameter update,\nand the computational complexity. We present numerical experiments for object\nrecognition. We evaluate the solution under the direct and the inverse problem\nand give a comparison with the state-of-the-art methods. Our empirical results\nhighlight the advantages of both approaches for representation learning from\nevent data. We show improvements of up to 9 % in the recognition accuracy\ncompared to the state-of-the-art methods from the same class of methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:40:03 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 13:09:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "2009.11102", "submitter": "Jan Philipp Portisch", "authors": "Sven Hertling, Jan Portisch, Heiko Paulheim", "title": "Supervised Ontology and Instance Matching with MELT", "comments": "accepted at the the Fifteenth International Workshop on Ontology\n  Matching collocated with the 19th International Semantic Web Conference\n  ISWC-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MELT-ML, a machine learning extension to the\nMatching and EvaLuation Toolkit (MELT) which facilitates the application of\nsupervised learning for ontology and instance matching. Our contributions are\ntwofold: We present an open source machine learning extension to the matching\ntoolkit as well as two supervised learning use cases demonstrating the\ncapabilities of the new extension.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:42:33 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hertling", "Sven", ""], ["Portisch", "Jan", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2009.11111", "submitter": "\\\"Ozg\\\"ur Akg\\\"un", "authors": "G\\\"okberk Ko\\c{c}ak, \\\"Ozg\\\"ur Akg\\\"un, Nguyen Dang, Ian Miguel", "title": "Efficient Incremental Modelling and Solving", "comments": null, "journal-ref": "ModRef 2020 - The 19th workshop on Constraint Modelling and\n  Reformulation", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In various scenarios, a single phase of modelling and solving is either not\nsufficient or not feasible to solve the problem at hand. A standard approach to\nsolving AI planning problems, for example, is to incrementally extend the\nplanning horizon and solve the problem of trying to find a plan of a particular\nlength. Indeed, any optimization problem can be solved as a sequence of\ndecision problems in which the objective value is incrementally updated.\nAnother example is constraint dominance programming (CDP), in which search is\norganized into a sequence of levels. The contribution of this work is to enable\na native interaction between SAT solvers and the automated modelling system\nSavile Row to support efficient incremental modelling and solving. This allows\nadding new decision variables, posting new constraints and removing existing\nconstraints (via assumptions) between incremental steps. Two additional\nbenefits of the native coupling of modelling and solving are the ability to\nretain learned information between SAT solver calls and to enable SAT\nassumptions, further improving flexibility and efficiency. Experiments on one\noptimisation problem and five pattern mining tasks demonstrate that the native\ninteraction between the modelling system and SAT solver consistently improves\nperformance significantly.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:40:23 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ko\u00e7ak", "G\u00f6kberk", ""], ["Akg\u00fcn", "\u00d6zg\u00fcr", ""], ["Dang", "Nguyen", ""], ["Miguel", "Ian", ""]]}, {"id": "2009.11116", "submitter": "Vahid Shahrivari", "authors": "Vahid Shahrivari, Mohammad Mahdi Darabi, Mohammad Izadi", "title": "Phishing Detection Using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet has become an indispensable part of our life, However, It also\nhas provided opportunities to anonymously perform malicious activities like\nPhishing. Phishers try to deceive their victims by social engineering or\ncreating mock-up websites to steal information such as account ID, username,\npassword from individuals and organizations. Although many methods have been\nproposed to detect phishing websites, Phishers have evolved their methods to\nescape from these detection methods. One of the most successful methods for\ndetecting these malicious activities is Machine Learning. This is because most\nPhishing attacks have some common characteristics which can be identified by\nmachine learning methods. In this paper, we compared the results of multiple\nmachine learning methods for predicting phishing websites.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 11:52:52 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Shahrivari", "Vahid", ""], ["Darabi", "Mohammad Mahdi", ""], ["Izadi", "Mohammad", ""]]}, {"id": "2009.11142", "submitter": "Patrick Rodler", "authors": "Patrick Rodler and Erich Teppan", "title": "The Scheduling Job-Set Optimization Problem: A Model-Based Diagnosis\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common issue for companies is that the volume of product orders may at\ntimes exceed the production capacity. We formally introduce two novel problems\ndealing with the question which orders to discard or postpone in order to meet\ncertain (timeliness) goals, and try to approach them by means of model-based\ndiagnosis. In thorough analyses, we identify many similarities of the\nintroduced problems to diagnosis problems, but also reveal crucial\nidiosyncracies and outline ways to handle or leverage them. Finally, a\nproof-of-concept evaluation on industrial-scale problem instances from a\nwell-known scheduling benchmark suite demonstrates that one of the two\nformalized problems can be well attacked by out-of-the-box model-based\ndiagnosis tools.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:38:36 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Rodler", "Patrick", ""], ["Teppan", "Erich", ""]]}, {"id": "2009.11152", "submitter": "Pierre Colombo", "authors": "Emile Chapuis and Pierre Colombo, Matteo Manica, Matthieu Labeau,\n  Chloe Clavel", "title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labelling tasks like Dialog Act and Emotion/Sentiment identification\nare a key component of spoken dialog systems. In this work, we propose a new\napproach to learn generic representations adapted to spoken dialog, which we\nevaluate on a new benchmark we call Sequence labellIng evaLuatIon benChmark fOr\nspoken laNguagE benchmark (\\texttt{SILICONE}). \\texttt{SILICONE} is\nmodel-agnostic and contains 10 different datasets of various sizes. We obtain\nour representations with a hierarchical encoder based on transformer\narchitectures, for which we extend two well-known pre-training objectives.\nPre-training is performed on OpenSubtitles: a large corpus of spoken dialog\ncontaining over $2.3$ billion of tokens. We demonstrate how hierarchical\nencoders achieve competitive results with consistently fewer parameters\ncompared to state-of-the-art models and we show their importance for both\npre-training and fine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:54:57 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 15:58:48 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 13:49:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chapuis", "Emile", ""], ["Colombo", "Pierre", ""], ["Manica", "Matteo", ""], ["Labeau", "Matthieu", ""], ["Clavel", "Chloe", ""]]}, {"id": "2009.11154", "submitter": "Albert Mosella-Montoro", "authors": "Albert Mosella-Montoro, Javier Ruiz-Hidalgo", "title": "2D-3D Geometric Fusion Network using Multi-Neighbourhood Graph\n  Convolution for RGB-D Indoor Scene Classification", "comments": "Information Fusion 2021", "journal-ref": null, "doi": "10.1016/j.inffus.2021.05.002", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multi-modal fusion has been proved to help enhance the performance of scene\nclassification tasks. This paper presents a 2D-3D Fusion stage that combines 3D\nGeometric Features with 2D Texture Features obtained by 2D Convolutional Neural\nNetworks. To get a robust 3D Geometric embedding, a network that uses two novel\nlayers is proposed. The first layer, Multi-Neighbourhood Graph Convolution,\naims to learn a more robust geometric descriptor of the scene combining two\ndifferent neighbourhoods: one in the Euclidean space and the other in the\nFeature space. The second proposed layer, Nearest Voxel Pooling, improves the\nperformance of the well-known Voxel Pooling. Experimental results, using\nNYU-Depth-V2 and SUN RGB-D datasets, show that the proposed method outperforms\nthe current state-of-the-art in RGB-D indoor scene classification task.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:58:12 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 16:27:55 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 10:06:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Mosella-Montoro", "Albert", ""], ["Ruiz-Hidalgo", "Javier", ""]]}, {"id": "2009.11180", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "AI and Legal Argumentation: Aligning the Autonomous Levels of AI Legal\n  Reasoning", "comments": "26 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:2009.02243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal argumentation is a vital cornerstone of justice, underpinning an\nadversarial form of law, and extensive research has attempted to augment or\nundertake legal argumentation via the use of computer-based automation\nincluding Artificial Intelligence (AI). AI advances in Natural Language\nProcessing (NLP) and Machine Learning (ML) have especially furthered the\ncapabilities of leveraging AI for aiding legal professionals, doing so in ways\nthat are modeled here as CARE, namely Crafting, Assessing, Refining, and\nEngaging in legal argumentation. In addition to AI-enabled legal argumentation\nserving to augment human-based lawyering, an aspirational goal of this\nmulti-disciplinary field consists of ultimately achieving autonomously effected\nhuman-equivalent legal argumentation. As such, an innovative meta-approach is\nproposed to apply the Levels of Autonomy (LoA) of AI Legal Reasoning (AILR) to\nthe maturation of AI and Legal Argumentation (AILA), proffering a new means of\ngauging progress in this ever-evolving and rigorously sought domain.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:05:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.11186", "submitter": "EPTCS", "authors": "Abeer Dyoub (University of L'Aquila, Italy), Stefania Costantini\n  (University of L'Aquila, Italy), Francesca A. Lisi (University of Bari \"A.\n  Moro\", Italy)", "title": "Logic Programming and Machine Ethics", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158. Invited paper for the\n  ICLP2020 Panel on \"Machine Ethics\". arXiv admin note: text overlap with\n  arXiv:1909.08255", "journal-ref": "EPTCS 325, 2020, pp. 6-17", "doi": "10.4204/EPTCS.325.6", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency is a key requirement for ethical machines. Verified ethical\nbehavior is not enough to establish justified trust in autonomous intelligent\nagents: it needs to be supported by the ability to explain decisions. Logic\nProgramming (LP) has a great potential for developing such perspective ethical\nsystems, as in fact logic rules are easily comprehensible by humans.\nFurthermore, LP is able to model causality, which is crucial for ethical\ndecision making.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:47:18 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dyoub", "Abeer", "", "University of L'Aquila, Italy"], ["Costantini", "Stefania", "", "University of L'Aquila, Italy"], ["Lisi", "Francesca A.", "", "University of Bari \"A.\n  Moro\", Italy"]]}, {"id": "2009.11190", "submitter": "Ulrich Kerzel", "authors": "U. Kerzel", "title": "Enterprise AI Canvas -- Integrating Artificial Intelligence into\n  Business", "comments": "Accepted at \"Applied Artificial Intelligence UAAI\"", "journal-ref": null, "doi": "10.1080/08839514.2020.1826146", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) and Machine Learning have enormous potential to\ntransform businesses and disrupt entire industry sectors. However, companies\nwishing to integrate algorithmic decisions into their face multiple challenges:\nThey have to identify use-cases in which artificial intelligence can create\nvalue, as well as decisions that can be supported or executed automatically.\nFurthermore, the organization will need to be transformed to be able to\nintegrate AI based systems into their human work-force. Furthermore, the more\ntechnical aspects of the underlying machine learning model have to be discussed\nin terms of how they impact the various units of a business: Where do the\nrelevant data come from, which constraints have to be considered, how is the\nquality of the data and the prediction evaluated?\n  The Enterprise AI canvas is designed to bring Data Scientist and business\nexpert together to discuss and define all relevant aspects which need to be\nclarified in order to integrate AI based systems into a digital enterprise. It\nconsists of two parts where part one focuses on the business view and\norganizational aspects, whereas part two focuses on the underlying machine\nlearning model and the data it uses.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:30:56 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kerzel", "U.", ""]]}, {"id": "2009.11195", "submitter": "Amr Gomaa", "authors": "Amr Gomaa, Guillermo Reyes, Alexandra Alles, Lydia Rupp and Michael\n  Feld", "title": "Studying Person-Specific Pointing and Gaze Behavior for Multimodal\n  Referencing of Outside Objects from a Moving Vehicle", "comments": null, "journal-ref": "In Proceedings of the 2020 International Conference on Multimodal\n  Interaction, pp. 501-509. 2020", "doi": "10.1145/3382507.3418817", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand pointing and eye gaze have been extensively investigated in automotive\napplications for object selection and referencing. Despite significant\nadvances, existing outside-the-vehicle referencing methods consider these\nmodalities separately. Moreover, existing multimodal referencing methods focus\non a static situation, whereas the situation in a moving vehicle is highly\ndynamic and subject to safety-critical constraints. In this paper, we\ninvestigate the specific characteristics of each modality and the interaction\nbetween them when used in the task of referencing outside objects (e.g.\nbuildings) from the vehicle. We furthermore explore person-specific differences\nin this interaction by analyzing individuals' performance for pointing and gaze\npatterns, along with their effect on the driving task. Our statistical analysis\nshows significant differences in individual behaviour based on object's\nlocation (i.e. driver's right side vs. left side), object's surroundings,\ndriving mode (i.e. autonomous vs. normal driving) as well as pointing and gaze\nduration, laying the foundation for a user-adaptive approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 14:56:19 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Gomaa", "Amr", ""], ["Reyes", "Guillermo", ""], ["Alles", "Alexandra", ""], ["Rupp", "Lydia", ""], ["Feld", "Michael", ""]]}, {"id": "2009.11219", "submitter": "Huajian Huang", "authors": "Huajian Huang, Wen-Yan Lin, Siying Liu, Dong Zhang and Sai-Kit Yeung", "title": "Dual-SLAM: A framework for robust single camera navigation", "comments": "Accepted by International Conference on Intelligent Robots and\n  Systems (IROS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SLAM (Simultaneous Localization And Mapping) seeks to provide a moving agent\nwith real-time self-localization. To achieve real-time speed, SLAM\nincrementally propagates position estimates. This makes SLAM fast but also\nmakes it vulnerable to local pose estimation failures. As local pose estimation\nis ill-conditioned, local pose estimation failures happen regularly, making the\noverall SLAM system brittle. This paper attempts to correct this problem. We\nnote that while local pose estimation is ill-conditioned, pose estimation over\nlonger sequences is well-conditioned. Thus, local pose estimation errors\neventually manifest themselves as mapping inconsistencies. When this occurs, we\nsave the current map and activate two new SLAM threads. One processes incoming\nframes to create a new map and the other, recovery thread, backtracks to link\nnew and old maps together. This creates a Dual-SLAM framework that maintains\nreal-time performance while being robust to local pose estimation failures.\nEvaluation on benchmark datasets shows Dual-SLAM can reduce failures by a\ndramatic $88\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:31:46 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Huang", "Huajian", ""], ["Lin", "Wen-Yan", ""], ["Liu", "Siying", ""], ["Zhang", "Dong", ""], ["Yeung", "Sai-Kit", ""]]}, {"id": "2009.11222", "submitter": "Zitao Liu", "authors": "Wentao Wang, Guowei Xu, Wenbiao Ding, Gale Yan Huang, Guoliang Li,\n  Jiliang Tang and Zitao Liu", "title": "Representation Learning from Limited Educational Data with Crowdsourced\n  Labels", "comments": "IEEE Transactions on Knowledge and Data Engineering (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has been proven to play an important role in the\nunprecedented success of machine learning models in numerous tasks, such as\nmachine translation, face recognition and recommendation. The majority of\nexisting representation learning approaches often require a large number of\nconsistent and noise-free labels. However, due to various reasons such as\nbudget constraints and privacy concerns, labels are very limited in many\nreal-world scenarios. Directly applying standard representation learning\napproaches on small labeled data sets will easily run into over-fitting\nproblems and lead to sub-optimal solutions. Even worse, in some domains such as\neducation, the limited labels are usually annotated by multiple workers with\ndiverse expertise, which yields noises and inconsistency in such crowdsourcing\nsettings. In this paper, we propose a novel framework which aims to learn\neffective representations from limited data with crowdsourced labels.\nSpecifically, we design a grouping based deep neural network to learn\nembeddings from a limited number of training samples and present a Bayesian\nconfidence estimator to capture the inconsistency among crowdsourced labels.\nFurthermore, to expedite the training process, we develop a hard example\nselection procedure to adaptively pick up training examples that are\nmisclassified by the model. Extensive experiments conducted on three real-world\ndata sets demonstrate the superiority of our framework on learning\nrepresentations from limited data with crowdsourced labels, comparing with\nvarious state-of-the-art baselines. In addition, we provide a comprehensive\nanalysis on each of the main components of our proposed framework and also\nintroduce the promising results it achieved in our real production to fully\nunderstand the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:34:40 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Wentao", ""], ["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Huang", "Gale Yan", ""], ["Li", "Guoliang", ""], ["Tang", "Jiliang", ""], ["Liu", "Zitao", ""]]}, {"id": "2009.11224", "submitter": "Jacek Czaja", "authors": "Jacek Czaja, Michal Gallus, Joanna Wozna, Adam Grygielski, Luo Tao", "title": "Applying the Roofline model for Deep Learning performance optimizations", "comments": "oneDNN library analysis with roofline model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper We present a methodology for creating Roofline models\nautomatically for Non-Unified Memory Access (NUMA) using Intel Xeon as an\nexample. Finally, we present an evaluation of highly efficient deep learning\nprimitives as implemented in the Intel oneDNN Library.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:39:12 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Czaja", "Jacek", ""], ["Gallus", "Michal", ""], ["Wozna", "Joanna", ""], ["Grygielski", "Adam", ""], ["Tao", "Luo", ""]]}, {"id": "2009.11225", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "Randomized fast no-loss expert system to play tic tac toe like a human", "comments": "Author's version of the paper published in IET Cognitive Computation\n  and Systems. For the journal-typeset version, please see\n  https://doi.org/10.1049/ccs.2020.0018", "journal-ref": "Cognitive Computation and Systems, Volume 2, Issue 4, December\n  2020, pp. 231 - 241", "doi": "10.1049/ccs.2020.0018", "report-no": null, "categories": "cs.AI cs.GT cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a blazingly fast, no-loss expert system for Tic Tac Toe\nusing Decision Trees called T3DT, that tries to emulate human gameplay as\nclosely as possible. It does not make use of any brute force, minimax or\nevolutionary techniques, but is still always unbeatable. In order to make the\ngameplay more human-like, randomization is prioritized and T3DT randomly\nchooses one of the multiple optimal moves at each step. Since it does not need\nto analyse the complete game tree at any point, T3DT is exceptionally faster\nthan any brute force or minimax algorithm, this has been shown theoretically as\nwell as empirically from clock-time analyses in this paper. T3DT also doesn't\nneed the data sets or the time to train an evolutionary model, making it a\npractical no-loss approach to play Tic Tac Toe.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:41:10 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:37:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2009.11245", "submitter": "Karla Burelo", "authors": "Mohammadali Sharifshazileh (1 and 2), Karla Burelo (1 and 2), Johannes\n  Sarnthein (2) and Giacomo Indiveri (1) ((1) Institute of Neuroinformatics,\n  University of Zurich and ETH Zurich, (2) Klinik f\\\"ur Neurochirurgie,\n  Universit\\\"atsSpital und Universit\\\"at Z\\\"urich)", "title": "An electronic neuromorphic system for real-time detection of High\n  Frequency Oscillations (HFOs) in intracranial EEG", "comments": "16 pages. A short video describing the rationale underlying the study\n  can be viewed on https://youtu.be/NuAA91fdmaM", "journal-ref": null, "doi": "10.1038/s41467-021-23342-2", "report-no": null, "categories": "eess.SP cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a neuromorphic system that combines for the first\ntime a neural recording headstage with a signal-to-spike conversion circuit and\na multi-core spiking neural network (SNN) architecture on the same die for\nrecording, processing, and detecting High Frequency Oscillations (HFO), which\nare biomarkers for the epileptogenic zone. The device was fabricated using a\nstandard 0.18$\\mu$m CMOS technology node and has a total area of 99mm$^{2}$. We\ndemonstrate its application to HFO detection in the iEEG recorded from 9\npatients with temporal lobe epilepsy who subsequently underwent epilepsy\nsurgery. The total average power consumption of the chip during the detection\ntask was 614.3$\\mu$W. We show how the neuromorphic system can reliably detect\nHFOs: the system predicts postsurgical seizure outcome with state-of-the-art\naccuracy, specificity and sensitivity (78%, 100%, and 33% respectively). This\nis the first feasibility study towards identifying relevant features in\nintracranial human data in real-time, on-chip, using event-based processors and\nspiking neural networks. By providing \"neuromorphic intelligence\" to neural\nrecording circuits the approach proposed will pave the way for the development\nof systems that can detect HFO areas directly in the operation room and improve\nthe seizure outcome of epilepsy surgery.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 16:40:44 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:22:30 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sharifshazileh", "Mohammadali", "", "1 and 2"], ["Burelo", "Karla", "", "1 and 2"], ["Sarnthein", "Johannes", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2009.11253", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Zachary New, Nico Courts, Jung H. Lee, Lauren A.\n  Phillips, Courtney D. Corley, Aaron Tuor, Andrew Avila, Nathan O. Hodas", "title": "Fuzzy Simplicial Networks: A Topology-Inspired Model to Improve Task\n  Generalization in Few-shot Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV math.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown great success in settings with massive amounts of\ndata but has struggled when data is limited. Few-shot learning algorithms,\nwhich seek to address this limitation, are designed to generalize well to new\ntasks with limited data. Typically, models are evaluated on unseen classes and\ndatasets that are defined by the same fundamental task as they are trained for\n(e.g. category membership). One can also ask how well a model can generalize to\nfundamentally different tasks within a fixed dataset (for example: moving from\ncategory membership to tasks that involve detecting object orientation or\nquantity). To formalize this kind of shift we define a notion of \"independence\nof tasks\" and identify three new sets of labels for established computer vision\ndatasets that test a model's ability to generalize to tasks which draw on\northogonal attributes in the data. We use these datasets to investigate the\nfailure modes of metric-based few-shot models. Based on our findings, we\nintroduce a new few-shot model called Fuzzy Simplicial Networks (FSN) which\nleverages a construction from topology to more flexibly represent each class\nfrom limited data. In particular, FSN models can not only form multiple\nrepresentations for a given class but can also begin to capture the\nlow-dimensional structure which characterizes class manifolds in the encoded\nspace of deep networks. We show that FSN outperforms state-of-the-art models on\nthe challenging tasks we introduce in this paper while remaining competitive on\nstandard few-shot benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:01:09 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kvinge", "Henry", ""], ["New", "Zachary", ""], ["Courts", "Nico", ""], ["Lee", "Jung H.", ""], ["Phillips", "Lauren A.", ""], ["Corley", "Courtney D.", ""], ["Tuor", "Aaron", ""], ["Avila", "Andrew", ""], ["Hodas", "Nathan O.", ""]]}, {"id": "2009.11278", "submitter": "Jaemin Cho", "authors": "Jaemin Cho, Jiasen Lu, Dustin Schwenk, Hannaneh Hajishirzi, Aniruddha\n  Kembhavi", "title": "X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal\n  Transformers", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirroring the success of masked language models, vision-and-language\ncounterparts like ViLBERT, LXMERT and UNITER have achieved state of the art\nperformance on a variety of multimodal discriminative tasks like visual\nquestion answering and visual grounding. Recent work has also successfully\nadapted such models towards the generative task of image captioning. This begs\nthe question: Can these models go the other way and generate images from pieces\nof text? Our analysis of a popular representative from this model family -\nLXMERT - finds that it is unable to generate rich and semantically meaningful\nimagery with its current training setup. We introduce X-LXMERT, an extension to\nLXMERT with training refinements including: discretizing visual\nrepresentations, using uniform masking with a large range of masking ratios and\naligning the right pre-training datasets to the right objectives which enables\nit to paint. X-LXMERT's image generation capabilities rival state of the art\ngenerative models while its question answering and captioning abilities remains\ncomparable to LXMERT. Finally, we demonstrate the generality of these training\nrefinements by adding image generation capabilities into UNITER to produce\nX-UNITER.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:45:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Cho", "Jaemin", ""], ["Lu", "Jiasen", ""], ["Schwenk", "Dustin", ""], ["Hajishirzi", "Hannaneh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2009.11342", "submitter": "Amir Shalev", "authors": "Amir Shalev (1,2), Omer Achrack (2), Brian Fulkerson, and Ben-Zion\n  Bobrovsky (1) ((1) Tel-Aviv-University, (2) Intel)", "title": "Insights on Evaluation of Camera Re-localization Using Relative Pose\n  Regression", "comments": "Accepted at ECCV 2020 joint workshop of UAVision and VisDrone", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of relative pose regression in visual relocalization.\nRecently, several promising approaches have emerged in this area. We claim that\neven though they demonstrate on the same datasets using the same split to train\nand test, a faithful comparison between them was not available since on\ncurrently used evaluation metric, some approaches might perform favorably,\nwhile in reality performing worse. We reveal a tradeoff between accuracy and\nthe 3D volume of the regressed subspace. We believe that unlike other\nrelocalization approaches, in the case of relative pose regression, the\nregressed subspace 3D volume is less dependent on the scene and more affect by\nthe method used to score the overlap, which determined how closely sampled\nviewpoints are. We propose three new metrics to remedy the issue mentioned\nabove. The proposed metrics incorporate statistics about the regression\nsubspace volume. We also propose a new pose regression network that serves as a\nnew baseline for this task. We compare the performance of our trained model on\nMicrosoft 7-Scenes and Cambridge Landmarks datasets both with the standard\nmetrics and the newly proposed metrics and adjust the overlap score to reveal\nthe tradeoff between the subspace and performance. The results show that the\nproposed metrics are more robust to different overlap threshold than the\nconventional approaches. Finally, we show that our network generalizes well,\nspecifically, training on a single scene leads to little loss of performance on\nthe other scenes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:16:26 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Shalev", "Amir", "", "Tel-Aviv-University", "Intel"], ["Achrack", "Omer", "", "Intel"], ["Fulkerson", "Brian", "", "Tel-Aviv-University"], ["Bobrovsky", "Ben-Zion", "", "Tel-Aviv-University"]]}, {"id": "2009.11348", "submitter": "Krishna Chaitanya Kalagarla", "authors": "Krishna C. Kalagarla, Rahul Jain, Pierluigi Nuzzo", "title": "A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Processes (CMDPs) formalize sequential\ndecision-making problems whose objective is to minimize a cost function while\nsatisfying constraints on various cost functions. In this paper, we consider\nthe setting of episodic fixed-horizon CMDPs. We propose an online algorithm\nwhich leverages the linear programming formulation of finite-horizon CMDP for\nrepeated optimistic planning to provide a probably approximately correct (PAC)\nguarantee on the number of episodes needed to ensure an $\\epsilon$-optimal\npolicy, i.e., with resulting objective value within $\\epsilon$ of the optimal\nvalue and satisfying the constraints within $\\epsilon$-tolerance, with\nprobability at least $1-\\delta$. The number of episodes needed is shown to be\nof the order\n$\\tilde{\\mathcal{O}}\\big(\\frac{|S||A|C^{2}H^{2}}{\\epsilon^{2}}\\log\\frac{1}{\\delta}\\big)$,\nwhere $C$ is the upper bound on the number of possible successor states for a\nstate-action pair. Therefore, if $C \\ll |S|$, the number of episodes needed\nhave a linear dependence on the state and action space sizes $|S|$ and $|A|$,\nrespectively, and quadratic dependence on the time horizon $H$.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:30:46 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kalagarla", "Krishna C.", ""], ["Jain", "Rahul", ""], ["Nuzzo", "Pierluigi", ""]]}, {"id": "2009.11403", "submitter": "Nathan Fulton", "authors": "Koundinya Vajjha, Avraham Shinnar, Vasily Pestun, Barry Trager, Nathan\n  Fulton", "title": "CertRL: Formalizing Convergence Proofs for Value and Policy Iteration in\n  Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms solve sequential decision-making problems\nin probabilistic environments by optimizing for long-term reward. The desire to\nuse reinforcement learning in safety-critical settings inspires a recent line\nof work on formally constrained reinforcement learning; however, these methods\nplace the implementation of the learning algorithm in their Trusted Computing\nBase. The crucial correctness property of these implementations is a guarantee\nthat the learning algorithm converges to an optimal policy. This paper begins\nthe work of closing this gap by developing a Coq formalization of two canonical\nreinforcement learning algorithms: value and policy iteration for finite state\nMarkov decision processes. The central results are a formalization of Bellman's\noptimality principle and its proof, which uses a contraction property of\nBellman optimality operator to establish that a sequence converges in the\ninfinite horizon limit. The CertRL development exemplifies how the Giry monad\nand mechanized metric coinduction streamline optimality proofs for\nreinforcement learning algorithms. The CertRL library provides a general\nframework for proving properties about Markov decision processes and\nreinforcement learning algorithms, paving the way for further work on\nformalization of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:28:17 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 19:39:30 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Vajjha", "Koundinya", ""], ["Shinnar", "Avraham", ""], ["Pestun", "Vasily", ""], ["Trager", "Barry", ""], ["Fulton", "Nathan", ""]]}, {"id": "2009.11440", "submitter": "Riadul Islam", "authors": "Riadul Islam, Rafi Ud Daula Refat, Sai Manikanta Yerram, Hafiz Malik", "title": "Graph-Based Intrusion Detection System for Controller Area Networks", "comments": "This paper is accepted to IEEE Transactions on Intelligent\n  Transportation Systems for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The controller area network (CAN) is the most widely used intra-vehicular\ncommunication network in the automotive industry. Because of its simplicity in\ndesign, it lacks most of the requirements needed for a security-proven\ncommunication protocol. However, a safe and secured environment is imperative\nfor autonomous as well as connected vehicles. Therefore CAN security is\nconsidered one of the important topics in the automotive research community. In\nthis paper, we propose a four-stage intrusion detection system that uses the\nchi-squared method and can detect any kind of strong and weak cyber attacks in\na CAN. This work is the first-ever graph-based defense system proposed for the\nCAN. Our experimental results show that we have a very low 5.26%\nmisclassification for denial of service (DoS) attack, 10% misclassification for\nfuzzy attack, 4.76% misclassification for replay attack, and no\nmisclassification for spoofing attack. In addition, the proposed methodology\nexhibits up to 13.73% better accuracy compared to existing ID sequence-based\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:33:58 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:59:25 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Islam", "Riadul", ""], ["Refat", "Rafi Ud Daula", ""], ["Yerram", "Sai Manikanta", ""], ["Malik", "Hafiz", ""]]}, {"id": "2009.11459", "submitter": "Nils Jansen", "authors": "Murat Cubuktepe, Nils Jansen, Sebastian Junges, Ahmadreza Marandi,\n  Marnix Suilen, Ufuk Topcu", "title": "Robust Finite-State Controllers for Uncertain POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertain partially observable Markov decision processes (uPOMDPs) allow the\nprobabilistic transition and observation functions of standard POMDPs to belong\nto a so-called uncertainty set. Such uncertainty, referred to as epistemic\nuncertainty, captures uncountable sets of probability distributions caused by,\nfor instance, a lack of data available. We develop an algorithm to compute\nfinite-memory policies for uPOMDPs that robustly satisfy specifications against\nany admissible distribution. In general, computing such policies is\ntheoretically and practically intractable. We provide an efficient solution to\nthis problem in four steps. (1) We state the underlying problem as a nonconvex\noptimization problem with infinitely many constraints. (2) A dedicated\ndualization scheme yields a dual problem that is still nonconvex but has\nfinitely many constraints. (3) We linearize this dual problem and (4) solve the\nresulting finite linear program to obtain locally optimal solutions to the\noriginal problem. The resulting problem formulation is exponentially smaller\nthan those resulting from existing methods. We demonstrate the applicability of\nour algorithm using large instances of an aircraft collision-avoidance scenario\nand a novel spacecraft motion planning case study.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 02:58:50 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 21:00:38 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Jansen", "Nils", ""], ["Junges", "Sebastian", ""], ["Marandi", "Ahmadreza", ""], ["Suilen", "Marnix", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2009.11469", "submitter": "Hongwei Zhang", "authors": "Hongwei Zhang, Tijin Yan, Zenjun Xie, Yuanqing Xia, Yuan Zhang", "title": "Revisiting Graph Convolutional Network on Semi-Supervised Node\n  Classification from an Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have achieved promising performance on\nvarious graph-based tasks. However they suffer from over-smoothing when\nstacking more layers. In this paper, we present a quantitative study on this\nobservation and develop novel insights towards the deeper GCN. First, we\ninterpret the current graph convolutional operations from an optimization\nperspective and argue that over-smoothing is mainly caused by the naive\nfirst-order approximation of the solution to the optimization problem.\nSubsequently, we introduce two metrics to measure the over-smoothing on\nnode-level tasks. Specifically, we calculate the fraction of the pairwise\ndistance between connected and disconnected nodes to the overall distance\nrespectively. Based on our theoretical and empirical analysis, we establish a\nuniversal theoretical framework of GCN from an optimization perspective and\nderive a novel convolutional kernel named GCN+ which has lower parameter amount\nwhile relieving the over-smoothing inherently. Extensive experiments on\nreal-world datasets demonstrate the superior performance of GCN+ over\nstate-of-the-art baseline methods on the node classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:36:43 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 02:00:16 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhang", "Hongwei", ""], ["Yan", "Tijin", ""], ["Xie", "Zenjun", ""], ["Xia", "Yuanqing", ""], ["Zhang", "Yuan", ""]]}, {"id": "2009.11484", "submitter": "Ryan K. L. Ko", "authors": "Hetong Jiang, Taejun Choi, Ryan K. L. Ko", "title": "Pandora: A Cyber Range Environment for the Safe Testing and Deployment\n  of Autonomous Cyber Attack Tools", "comments": "20 pages, 10 figures, to be published in SSCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity tools are increasingly automated with artificial intelligent\n(AI) capabilities to match the exponential scale of attacks, compensate for the\nrelatively slower rate of training new cybersecurity talents, and improve of\nthe accuracy and performance of both tools and users. However, the safe and\nappropriate usage of autonomous cyber attack tools - especially at the\ndevelopment stages for these tools - is still largely an unaddressed gap. Our\nsurvey of current literature and tools showed that most of the existing cyber\nrange designs are mostly using manual tools and have not considered augmenting\nautomated tools or the potential security issues caused by the tools. In other\nwords, there is still room for a novel cyber range design which allow security\nresearchers to safely deploy autonomous tools and perform automated tool\ntesting if needed. In this paper, we introduce Pandora, a safe testing\nenvironment which allows security researchers and cyber range users to perform\nexperiments on automated cyber attack tools that may have strong potential of\nusage and at the same time, a strong potential for risks. Unlike existing\ntestbeds and cyber ranges which have direct compatibility with enterprise\ncomputer systems and the potential for risk propagation across the enterprise\nnetwork, our test system is intentionally designed to be incompatible with\nenterprise real-world computing systems to reduce the risk of attack\npropagation into actual infrastructure. Our design also provides a tool to\nconvert in-development automated cyber attack tools into to executable test\nbinaries for validation and usage realistic enterprise system environments if\nrequired. Our experiments tested automated attack tools on our proposed system\nto validate the usability of our proposed environment. Our experiments also\nproved the safety of our environment by compatibility testing using simple\nmalicious code.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:38:47 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Jiang", "Hetong", ""], ["Choi", "Taejun", ""], ["Ko", "Ryan K. L.", ""]]}, {"id": "2009.11485", "submitter": "Zehong Cao Dr.", "authors": "Xinping Liu, Zehong Cao, Son Tran", "title": "CogniFNN: A Fuzzy Neural Network Framework for Cognitive Word Embedding\n  Evaluation", "comments": "The method and results need to be further investigated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings can reflect the semantic representations, and the embedding\nqualities can be comprehensively evaluated with human natural reading-related\ncognitive data sources. In this paper, we proposed the CogniFNN framework,\nwhich is the first attempt at using fuzzy neural networks to extract non-linear\nand non-stationary characteristics for evaluations of English word embeddings\nagainst the corresponding cognitive datasets. In our experiment, we used 15\nhuman cognitive datasets across three modalities: EEG, fMRI, and eye-tracking,\nand selected the mean square error and multiple hypotheses testing as metrics\nto evaluate our proposed CogniFNN framework. Compared to the recent pioneer\nframework, our proposed CogniFNN showed smaller prediction errors of both\ncontext-independent (GloVe) and context-sensitive (BERT) word embeddings, and\nachieved higher significant ratios with randomly generated word embeddings. Our\nfindings suggested that the CogniFNN framework could provide a more accurate\nand comprehensive evaluation of cognitive word embeddings. It will potentially\nbe beneficial to the further word embeddings evaluation on extrinsic natural\nlanguage processing tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:39:38 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:34:32 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Liu", "Xinping", ""], ["Cao", "Zehong", ""], ["Tran", "Son", ""]]}, {"id": "2009.11491", "submitter": "Anoop Krishnan Upendran Nair", "authors": "Anoop Krishnan, Ali Almadan, Ajita Rattani", "title": "Understanding Fairness of Gender Classification Algorithms Across\n  Gender-Race Groups", "comments": "19th IEEE International Conference On Machine Learning And\n  Applications 2020 | Miami, Florida", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated gender classification has important applications in many domains,\nsuch as demographic research, law enforcement, online advertising, as well as\nhuman-computer interaction. Recent research has questioned the fairness of this\ntechnology across gender and race. Specifically, the majority of the studies\nraised the concern of higher error rates of the face-based gender\nclassification system for darker-skinned people like African-American and for\nwomen. However, to date, the majority of existing studies were limited to\nAfrican-American and Caucasian only. The aim of this paper is to investigate\nthe differential performance of the gender classification algorithms across\ngender-race groups. To this aim, we investigate the impact of (a) architectural\ndifferences in the deep learning algorithms and (b) training set imbalance, as\na potential source of bias causing differential performance across gender and\nrace. Experimental investigations are conducted on two latest large-scale\npublicly available facial attribute datasets, namely, UTKFace and FairFace. The\nexperimental results suggested that the algorithms with architectural\ndifferences varied in performance with consistency towards specific gender-race\ngroups. For instance, for all the algorithms used, Black females (Black race in\ngeneral) always obtained the least accuracy rates. Middle Eastern males and\nLatino females obtained higher accuracy rates most of the time. Training set\nimbalance further widens the gap in the unequal accuracy rates across all\ngender-race groups. Further investigations using facial landmarks suggested\nthat facial morphological differences due to the bone structure influenced by\ngenetic and environmental factors could be the cause of the least performance\nof Black females and Black race, in general.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:56:10 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Krishnan", "Anoop", ""], ["Almadan", "Ali", ""], ["Rattani", "Ajita", ""]]}, {"id": "2009.11564", "submitter": "Simon Razniewski", "authors": "Gerhard Weikum, Luna Dong, Simon Razniewski, Fabian Suchanek", "title": "Machine Knowledge: Creation and Curation of Comprehensive Knowledge\n  Bases", "comments": "Submitted to Foundations and Trends in Databases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equipping machines with comprehensive knowledge of the world's entities and\ntheir relationships has been a long-standing goal of AI. Over the last decade,\nlarge-scale knowledge bases, also known as knowledge graphs, have been\nautomatically constructed from web contents and text sources, and have become a\nkey asset for search engines. This machine knowledge can be harnessed to\nsemantically interpret textual phrases in news, social media and web tables,\nand contributes to question answering, natural language processing and data\nanalytics. This article surveys fundamental concepts and practical methods for\ncreating and curating large knowledge bases. It covers models and methods for\ndiscovering and canonicalizing entities and their semantic types and organizing\nthem into clean taxonomies. On top of this, the article discusses the automatic\nextraction of entity-centric properties. To support the long-term life-cycle\nand the quality assurance of machine knowledge, the article presents methods\nfor constructing open schemas and for knowledge curation. Case studies on\nacademic projects and industrial knowledge graphs complement the survey of\nconcepts and methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 09:28:13 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 23:18:35 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Weikum", "Gerhard", ""], ["Dong", "Luna", ""], ["Razniewski", "Simon", ""], ["Suchanek", "Fabian", ""]]}, {"id": "2009.11577", "submitter": "Lea Berthomier", "authors": "L\\'ea Berthomier, Bruno Pradel and Lior Perez", "title": "Cloud Cover Nowcasting with Deep Learning", "comments": "6 pages, 11 figures", "journal-ref": "Proceedings of the 2020 Tenth International Conference on Image\n  Processing Theory, Tools and Applications (IPTA), IEEE, Paris, France, 9-12\n  November 2020", "doi": "10.1109/IPTA50016.2020.9286606", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowcasting is a field of meteorology which aims at forecasting weather on a\nshort term of up to a few hours. In the meteorology landscape, this field is\nrather specific as it requires particular techniques, such as data\nextrapolation, where conventional meteorology is generally based on physical\nmodeling. In this paper, we focus on cloud cover nowcasting, which has various\napplication areas such as satellite shots optimisation and photovoltaic energy\nproduction forecast.\n  Following recent deep learning successes on multiple imagery tasks, we\napplied deep convolutionnal neural networks on Meteosat satellite images for\ncloud cover nowcasting. We present the results of several architectures\nspecialized in image segmentation and time series prediction. We selected the\nbest models according to machine learning metrics as well as meteorological\nmetrics. All selected architectures showed significant improvements over\npersistence and the well-known U-Net surpasses AROME physical model.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 09:57:29 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:23:35 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 11:57:43 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Berthomier", "L\u00e9a", ""], ["Pradel", "Bruno", ""], ["Perez", "Lior", ""]]}, {"id": "2009.11640", "submitter": "Ra\\\"ida Ktari", "authors": "Ra\\\"ida Ktari and Mohamed Ayman Boujelben", "title": "On the use of evidence theory in belief base revision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with belief base revision that is a form of belief change\nconsisting of the incorporation of new facts into an agent's beliefs\nrepresented by a finite set of propositional formulas. In the aim to guarantee\nmore reliability and rationality for real applications while performing\nrevision, we propose the idea of credible belief base revision yielding to\ndefine two new formula-based revision operators using the suitable tools\noffered by evidence theory. These operators, uniformly presented in the same\nspirit of others in [9], stem from consistent subbases maximal with respect to\ncredibility instead of set inclusion and cardinality. Moreover, in between\nthese two extremes operators, evidence theory let us shed some light on a\ncompromise operator avoiding losing initial beliefs to the maximum extent\npossible. Its idea captures maximal consistent sets stemming from all possible\nintersections of maximal consistent subbases. An illustration of all these\noperators and a comparison with others are inverstigated by examples.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 12:45:32 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Ktari", "Ra\u00efda", ""], ["Boujelben", "Mohamed Ayman", ""]]}, {"id": "2009.11647", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "The Next Era of American Law Amid the Advent of Autonomous AI Legal\n  Reasoning", "comments": "20 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1802.08722, arXiv:2009.02243, arXiv:2009.11180, arXiv:2008.12615,\n  arXiv:2008.10575, arXiv:2008.09507, arXiv:2008.07743", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal scholars have postulated that there have been three eras of American\nlaw to-date, consisting in chronological order of the initial Age of Discovery,\nthe Age of Faith, and then the Age of Anxiety. An open question that has\nreceived erudite attention in legal studies is what the next era, the fourth\nera, might consist of, and for which various proposals exist including examples\nsuch as the Age of Consent, the Age of Information, etc. There is no consensus\nin the literature as yet on what the fourth era is, and nor whether the fourth\nera has already begun or will instead emerge in the future. This paper examines\nthe potential era-elucidating impacts amid the advent of autonomous Artificial\nIntelligence Legal Reasoning (AILR), entailing whether such AILR will be an\nelement of a fourth era or a driver of a fourth, fifth, or perhaps the sixth\nera of American law. Also, a set of meta-characteristics about the means of\nidentifying a legal era changeover are introduced, along with an innovative\ndiscussion of the role entailing legal formalism versus legal realism in the\nemergence of the American law eras.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 18:22:57 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.11676", "submitter": "Benedikt Hosp", "authors": "Benedikt Hosp, Florian Schultz, Oliver H\\\"oner, Enkelejda Kasneci", "title": "Eye Movement Feature Classification for Soccer Goalkeeper Expertise\n  Identification in Virtual Reality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest research in expertise assessment of soccer players has affirmed\nthe importance of perceptual skills (especially for decision making) by\nfocusing either on high experimental control or on a realistic presentation. To\nassess the perceptual skills of athletes in an optimized manner, we captured\nomnidirectional in-field scenes and showed these to 12 expert, 10 intermediate\nand 13 novice soccer goalkeepers on virtual reality glasses. All scenes were\nshown from the same natural goalkeeper perspective and ended after the return\npass to the goalkeeper. Based on their gaze behavior we classified their\nexpertise with common machine learning techniques. This pilot study shows\npromising results for objective classification of goalkeepers expertise based\non their gaze behaviour and provided valuable insight to inform the design of\ntraining systems to enhance perceptual skills of athletes.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:18:41 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 17:22:41 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hosp", "Benedikt", ""], ["Schultz", "Florian", ""], ["H\u00f6ner", "Oliver", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2009.11684", "submitter": "Fenglin Li", "authors": "Feng-Lin Li, Hehong Chen, Guohai Xu, Tian Qiu, Feng Ji, Ji Zhang,\n  Haiqing Chen", "title": "AliMe KG: Domain Knowledge Graph Construction and Application in\n  E-commerce", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412685", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-sales customer service is of importance to E-commerce platforms as it\ncontributes to optimizing customers' buying process. To better serve users, we\npropose AliMe KG, a domain knowledge graph in E-commerce that captures user\nproblems, points of interests (POI), item information and relations thereof. It\nhelps to understand user needs, answer pre-sales questions and generate\nexplanation texts. We applied AliMe KG to several online business scenarios\nsuch as shopping guide, question answering over properties and recommendation\nreason generation, and gained positive results. In the paper, we systematically\nintroduce how we construct domain knowledge graph from free text, and\ndemonstrate its business value with several applications. Our experience shows\nthat mining structured knowledge from free text in vertical domain is\npracticable, and can be of substantial value in industrial settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:40:18 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Li", "Feng-Lin", ""], ["Chen", "Hehong", ""], ["Xu", "Guohai", ""], ["Qiu", "Tian", ""], ["Ji", "Feng", ""], ["Zhang", "Ji", ""], ["Chen", "Haiqing", ""]]}, {"id": "2009.11697", "submitter": "Nathan Zhao", "authors": "Nathan Zhao, Beicheng Lou", "title": "Compressed imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analogy to compressed sensing, which allows sample-efficient signal\nreconstruction given prior knowledge of its sparsity in frequency domain, we\npropose to utilize policy simplicity (Occam's Razor) as a prior to enable\nsample-efficient imitation learning. We first demonstrated the feasibility of\nthis scheme on linear case where state-value function can be sampled directly.\nWe also extended the scheme to scenarios where only actions are visible and\nscenarios where the policy is obtained from nonlinear network. The method is\nbenchmarked against behavior cloning and results in significantly higher scores\nwith limited expert demonstrations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 19:50:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zhao", "Nathan", ""], ["Lou", "Beicheng", ""]]}, {"id": "2009.11698", "submitter": "Vaishak Belle", "authors": "Vaishak Belle and Ioannis Papantonis", "title": "Principles and Practice of Explainable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) provides many opportunities to improve private\nand public life. Discovering patterns and structures in large troves of data in\nan automated manner is a core component of data science, and currently drives\napplications in diverse areas such as computational biology, law and finance.\nHowever, such a highly positive impact is coupled with significant challenges:\nhow do we understand the decisions suggested by these systems in order that we\ncan trust them? In this report, we focus specifically on data-driven methods --\nmachine learning (ML) and pattern recognition models in particular -- so as to\nsurvey and distill the results and observations from the literature. The\npurpose of this report can be especially appreciated by noting that ML models\nare increasingly deployed in a wide range of businesses. However, with the\nincreasing prevalence and complexity of methods, business stakeholders in the\nvery least have a growing number of concerns about the drawbacks of models,\ndata-specific biases, and so on. Analogously, data science practitioners are\noften not aware about approaches emerging from the academic literature, or may\nstruggle to appreciate the differences between different methods, so end up\nusing industry standards such as SHAP. Here, we have undertaken a survey to\nhelp industry practitioners (but also data scientists more broadly) understand\nthe field of explainable machine learning better and apply the right tools. Our\nlatter sections build a narrative around a putative data scientist, and discuss\nhow she might go about explaining her models by asking the right questions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:50:27 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Belle", "Vaishak", ""], ["Papantonis", "Ioannis", ""]]}, {"id": "2009.11722", "submitter": "Bogdan Trasnea", "authors": "Sorin Grigorescu, Tiberiu Cocias, Bogdan Trasnea, Andrea Margheri,\n  Federico Lombardi, Leonardo Aniello", "title": "Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI\n  Inference Engines in Autonomous Vehicles", "comments": "21 pages Published in Sensors:\n  https://www.mdpi.com/1424-8220/20/19/5450", "journal-ref": null, "doi": "10.3390/s20195450", "report-no": null, "categories": "cs.SE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving cars and autonomous vehicles are revolutionizing the automotive\nsector, shaping the future of mobility altogether. Although the integration of\nnovel technologies such as Artificial Intelligence (AI) and Cloud/Edge\ncomputing provides golden opportunities to improve autonomous driving\napplications, there is the need to modernize accordingly the whole prototyping\nand deployment cycle of AI components. This paper proposes a novel framework\nfor developing so-called AI Inference Engines for autonomous driving\napplications based on deep learning modules, where training tasks are deployed\nelastically over both Cloud and Edge resources, with the purpose of reducing\nthe required network bandwidth, as well as mitigating privacy issues. Based on\nour proposed data driven V-Model, we introduce a simple yet elegant solution\nfor the AI components development cycle, where prototyping takes place in the\ncloud according to the Software-in-the-Loop (SiL) paradigm, while deployment\nand evaluation on the target ECUs (Electronic Control Units) is performed as\nHardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework\nis demonstrated using two real-world use-cases of AI inference engines for\nautonomous vehicles, that is environment perception and most probable path\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:23:29 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Grigorescu", "Sorin", ""], ["Cocias", "Tiberiu", ""], ["Trasnea", "Bogdan", ""], ["Margheri", "Andrea", ""], ["Lombardi", "Federico", ""], ["Aniello", "Leonardo", ""]]}, {"id": "2009.11727", "submitter": "The Anh Han", "authors": "Ogbo Ndidi Bianca, Aiman Elgarig, The Anh Han", "title": "Evolution of Coordination in Pairwise and Multi-player Interactions via\n  Prior Commitments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT math-ph math.MP nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Upon starting a collective endeavour, it is important to understand your\npartners' preferences and how strongly they commit to a common goal.\nEstablishing a prior commitment or agreement in terms of posterior benefits and\nconsequences from those engaging in it provides an important mechanism for\nsecuring cooperation. Resorting to methods from Evolutionary Game Theory (EGT),\nhere we analyse how prior commitments can also be adopted as a tool for\nenhancing coordination when its outcomes exhibit an asymmetric payoff\nstructure, in both pairwise and multiparty interactions. Arguably, coordination\nis more complex to achieve than cooperation since there might be several\ndesirable collective outcomes in a coordination problem (compared to mutual\ncooperation, the only desirable collective outcome in cooperation dilemmas).\nOur analysis, both analytically and via numerical simulations, shows that\nwhether prior commitment would be a viable evolutionary mechanism for enhancing\ncoordination and the overall population social welfare strongly depends on the\ncollective benefit and severity of competition, and more importantly, how\nasymmetric benefits are resolved in a commitment deal. Moreover, in multiparty\ninteractions, prior commitments prove to be crucial when a high level of group\ndiversity is required for optimal coordination. The results are robust for\ndifferent selection intensities. Overall, our analysis provides new insights\ninto the complexity and beauty of behavioral evolution driven by humans'\ncapacity for commitment, as well as for the design of self-organised and\ndistributed multi-agent systems for ensuring coordination among autonomous\nagents.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:36:49 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:21:52 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bianca", "Ogbo Ndidi", ""], ["Elgarig", "Aiman", ""], ["Han", "The Anh", ""]]}, {"id": "2009.11729", "submitter": "Quanshi Zhang", "authors": "Hao Zhang, Sen Li, Yinchao Ma, Mingjie Li, Yichen Xie, Quanshi Zhang", "title": "Interpreting and Boosting Dropout from a Game-Theoretic View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to understand and improve the utility of the dropout\noperation from the perspective of game-theoretic interactions. We prove that\ndropout can suppress the strength of interactions between input variables of\ndeep neural networks (DNNs). The theoretic proof is also verified by various\nexperiments. Furthermore, we find that such interactions were strongly related\nto the over-fitting problem in deep learning. Thus, the utility of dropout can\nbe regarded as decreasing interactions to alleviate the significance of\nover-fitting. Based on this understanding, we propose an interaction loss to\nfurther improve the utility of dropout. Experimental results have shown that\nthe interaction loss can effectively improve the utility of dropout and boost\nthe performance of DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:39:42 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 16:45:35 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 10:30:51 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 10:42:04 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhang", "Hao", ""], ["Li", "Sen", ""], ["Ma", "Yinchao", ""], ["Li", "Mingjie", ""], ["Xie", "Yichen", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2009.11732", "submitter": "Lukas Ruff", "authors": "Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, Gr\\'egoire\n  Montavon, Wojciech Samek, Marius Kloft, Thomas G. Dietterich, Klaus-Robert\n  M\\\"uller", "title": "A Unifying Review of Deep and Shallow Anomaly Detection", "comments": "40 pages; accepted for publication in the Proceedings of the IEEE;", "journal-ref": "Proceedings of the IEEE (2021) 1-40", "doi": "10.1109/JPROC.2021.3052449", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to anomaly detection have recently improved the\nstate of the art in detection performance on complex datasets such as large\ncollections of images or text. These results have sparked a renewed interest in\nthe anomaly detection problem and led to the introduction of a great variety of\nnew methods. With the emergence of numerous such methods, including approaches\nbased on generative models, one-class classification, and reconstruction, there\nis a growing need to bring methods of this field into a systematic and unified\nperspective. In this review we aim to identify the common underlying principles\nas well as the assumptions that are often made implicitly by various methods.\nIn particular, we draw connections between classic 'shallow' and novel deep\napproaches and show how this relation might cross-fertilize or extend both\ndirections. We further provide an empirical assessment of major existing\nmethods that is enriched by the use of recent explainability techniques, and\npresent specific worked-through examples together with practical advice.\nFinally, we outline critical open challenges and identify specific paths for\nfuture research in anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:47:54 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 07:46:38 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 12:43:59 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ruff", "Lukas", ""], ["Kauffmann", "Jacob R.", ""], ["Vandermeulen", "Robert A.", ""], ["Montavon", "Gr\u00e9goire", ""], ["Samek", "Wojciech", ""], ["Kloft", "Marius", ""], ["Dietterich", "Thomas G.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2009.11848", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Mozhi Zhang, Jingling Li, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how neural networks trained by gradient descent extrapolate, i.e.,\nwhat they learn outside the support of the training distribution. Previous\nworks report mixed empirical results when extrapolating with neural networks:\nwhile feedforward neural networks, a.k.a. multilayer perceptrons (MLPs), do not\nextrapolate well in certain simple tasks, Graph Neural Networks (GNNs) --\nstructured networks with MLP modules -- have shown some success in more complex\ntasks. Working towards a theoretical explanation, we identify conditions under\nwhich MLPs and GNNs extrapolate well. First, we quantify the observation that\nReLU MLPs quickly converge to linear functions along any direction from the\norigin, which implies that ReLU MLPs do not extrapolate most nonlinear\nfunctions. But, they can provably learn a linear target function when the\ntraining distribution is sufficiently \"diverse\". Second, in connection to\nanalyzing the successes and limitations of GNNs, these results suggest a\nhypothesis for which we provide theoretical and empirical evidence: the success\nof GNNs in extrapolating algorithmic tasks to new data (e.g., larger graphs or\nedge weights) relies on encoding task-specific non-linearities in the\narchitecture or features. Our theoretical analysis builds on a connection of\nover-parameterized networks to the neural tangent kernel. Empirically, our\ntheory holds across different training settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:48:59 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 03:54:28 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 23:54:16 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2021 19:42:02 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 23:05:49 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Xu", "Keyulu", ""], ["Zhang", "Mozhi", ""], ["Li", "Jingling", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2009.11867", "submitter": "Samuel Dooley", "authors": "Samuel Dooley, John P. Dickerson", "title": "The Affiliate Matching Problem: On Labor Markets where Firms are Also\n  Interested in the Placement of Previous Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI cs.CY cs.DS cs.GT q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many labor markets, workers and firms are connected via affiliative\nrelationships. A management consulting firm wishes to both accept the best new\nworkers but also place its current affiliated workers at strong firms.\nSimilarly, a research university wishes to hire strong job market candidates\nwhile also placing its own candidates at strong peer universities. We model\nthis affiliate matching problem in a generalization of the classic stable\nmarriage setting by permitting firms to state preferences over not just which\nworkers to whom they are matched, but also to which firms their affiliated\nworkers are matched. Based on results from a human survey, we find that\nparticipants (acting as firms) give preference to their own affiliate workers\nin surprising ways that violate some assumptions of the classical stable\nmarriage problem. This motivates a nuanced discussion of how stability could be\ndefined in affiliate matching problems; we give an example of a marketplace\nwhich admits a stable match under one natural definition of stability, and does\nnot for that same marketplace under a different, but still natural, definition.\nWe conclude by setting a research agenda toward the creation of a centralized\nclearing mechanism in this general setting.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:27:47 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dooley", "Samuel", ""], ["Dickerson", "John P.", ""]]}, {"id": "2009.11905", "submitter": "Muharrem Ugur Yavas", "authors": "M. Ugur Yavas, N. Kemal Ure, Tufan Kumbasar", "title": "A New Approach for Tactical Decision Making in Lane Changing: Sample\n  Efficient Deep Q Learning with a Safety Feedback Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated lane change is one of the most challenging task to be solved of\nhighly automated vehicles due to its safety-critical, uncertain and multi-agent\nnature. This paper presents the novel deployment of the state of art Q learning\nmethod, namely Rainbow DQN, that uses a new safety driven rewarding scheme to\ntackle the issues in an dynamic and uncertain simulation environment. We\npresent various comparative results to show that our novel approach of having\nreward feedback from the safety layer dramatically increases both the agent's\nperformance and sample efficiency. Furthermore, through the novel deployment of\nRainbow DQN, it is shown that more intuition about the agent's actions is\nextracted by examining the distributions of generated Q values of the agents.\nThe proposed algorithm shows superior performance to the baseline algorithm in\nthe challenging scenarios with only 200000 training steps (i.e. equivalent to\n55 hours driving).\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:59:02 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Yavas", "M. Ugur", ""], ["Ure", "N. Kemal", ""], ["Kumbasar", "Tufan", ""]]}, {"id": "2009.11917", "submitter": "Benson Tsz Kin Leung", "authors": "Benson Tsz Kin Leung", "title": "Learning in a Small/Big World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Savage (1972) lays down the foundation of Bayesian decision theory, but\nasserts that it is not applicable in big worlds where the environment is\ncomplex. Using the theory of finite automaton to model belief formation, this\npaper studies the characteristics of optimal learning behavior in small and big\nworlds, where the complexity of the environment is low and high, respectively,\nrelative to the cognitive ability of the decision maker. Confirming Savage's\nclaim, optimal learning behavior is closed to Bayesian in small worlds but\nsignificantly different in big worlds. In addition, I show that in big worlds,\nthe optimal learning behavior could exhibit a wide range of well-documented\nnon-Bayesian learning behavior, including the use of heuristic, correlation\nneglect, persistent over-confidence, inattentive learning, and other behaviors\nof model simplification or misspecification. These results establish a clear\nand testable relationship between the prominence of non-Bayesian learning\nbehavior, complexity and cognitive ability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 19:25:02 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 09:53:05 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 19:42:13 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 14:25:01 GMT"}, {"version": "v5", "created": "Sat, 17 Oct 2020 20:51:54 GMT"}, {"version": "v6", "created": "Sun, 1 Nov 2020 16:31:05 GMT"}, {"version": "v7", "created": "Fri, 13 Nov 2020 17:45:08 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Leung", "Benson Tsz Kin", ""]]}, {"id": "2009.11963", "submitter": "Jonathan Enderle", "authors": "Jonathan Scott Enderle", "title": "Toward a Thermodynamics of Meaning", "comments": "To be published in the proceedings of CHR 2020: Workshop on\n  Computational Humanities Research, November 18-20, 2020, Amsterdam, The\n  Netherlands", "journal-ref": "Proceedings of the Workshop on Computational Humanities Research\n  CEUR Vol-2723 (2020) 191-201", "doi": "10.5281/zenodo.4302259", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As language models such as GPT-3 become increasingly successful at generating\nrealistic text, questions about what purely text-based modeling can learn about\nthe world have become more urgent. Is text purely syntactic, as skeptics argue?\nOr does it in fact contain some semantic information that a sufficiently\nsophisticated language model could use to learn about the world without any\nadditional inputs? This paper describes a new model that suggests some\nqualified answers to those questions. By theorizing the relationship between\ntext and the world it describes as an equilibrium relationship between a\nthermodynamic system and a much larger reservoir, this paper argues that even\nvery simple language models do learn structural facts about the world, while\nalso proposing relatively precise limits on the nature and extent of those\nfacts. This perspective promises not only to answer questions about what\nlanguage models actually learn, but also to explain the consistent and\nsurprising success of cooccurrence prediction as a meaning-making strategy in\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 21:56:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Enderle", "Jonathan Scott", ""]]}, {"id": "2009.11979", "submitter": "Mohammad Arani", "authors": "Md. Mohsin Ahmed and S. M. Salauddin Iqbal and Tazrin Jahan Priyanka\n  and Mohammad Arani and Mohsen Momenitabar and Md Mashum Billal", "title": "An Environmentally Sustainable Closed-Loop Supply Chain Network Design\n  under Uncertainty: Application of Optimization", "comments": "The paper has been accepted by \"the 4th International Conference on\n  Intelligent Decision Science (IDS)\" and it will be published in \"the Advances\n  in Intelligent Systems and Computing\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newly, the rates of energy and material consumption to augment industrial\npro-duction are substantially high, thus the environmentally sustainable\nindustrial de-velopment has emerged as the main issue of either developed or\ndeveloping coun-tries. A novel approach to supply chain management is proposed\nto maintain economic growth along with environmentally friendly concerns for\nthe design of the supply chain network. In this paper, a new green supply chain\ndesign approach has been suggested to maintain the financial virtue\naccompanying the environ-mental factors that required to be mitigated the\nnegative effect of rapid industrial development on the environment. This\napproach has been suggested a multi-objective mathematical model minimizing the\ntotal costs and CO2 emissions for establishing an environmentally sustainable\nclosed-loop supply chain. Two opti-mization methods are used namely Epsilon\nConstraint Method, and Genetic Al-gorithm Optimization Method. The results of\nthe two mentioned methods have been compared and illustrated their\neffectiveness. The outcome of the analysis is approved to verify the accuracy\nof the proposed model to deal with financial and environmental issues\nconcurrently.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 23:25:35 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Ahmed", "Md. Mohsin", ""], ["Iqbal", "S. M. Salauddin", ""], ["Priyanka", "Tazrin Jahan", ""], ["Arani", "Mohammad", ""], ["Momenitabar", "Mohsen", ""], ["Billal", "Md Mashum", ""]]}, {"id": "2009.11997", "submitter": "Yizhou Huang", "authors": "Yizhou Huang, Kevin Xie, Homanga Bharadhwaj and Florian Shkurti", "title": "Continual Model-Based Reinforcement Learning with Hypernetworks", "comments": "7 pages (+2 pages in appendix), 8 figures. To appear in the proc. of\n  the 2021 IEEE International Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective planning in model-based reinforcement learning (MBRL) and\nmodel-predictive control (MPC) relies on the accuracy of the learned dynamics\nmodel. In many instances of MBRL and MPC, this model is assumed to be\nstationary and is periodically re-trained from scratch on state transition\nexperience collected from the beginning of environment interactions. This\nimplies that the time required to train the dynamics model - and the pause\nrequired between plan executions - grows linearly with the size of the\ncollected experience. We argue that this is too slow for lifelong robot\nlearning and propose HyperCRL, a method that continually learns the encountered\ndynamics in a sequence of tasks using task-conditional hypernetworks. Our\nmethod has three main attributes: first, it includes dynamics learning sessions\nthat do not revisit training data from previous tasks, so it only needs to\nstore the most recent fixed-size portion of the state transition experience;\nsecond, it uses fixed-capacity hypernetworks to represent non-stationary and\ntask-aware dynamics; third, it outperforms existing continual learning\nalternatives that rely on fixed-capacity networks, and does competitively with\nbaselines that remember an ever increasing coreset of past experience. We show\nthat HyperCRL is effective in continual model-based reinforcement learning in\nrobot locomotion and manipulation scenarios, such as tasks involving pushing\nand door opening. Our project website with videos is at this link\nhttps://rvl.cs.toronto.edu/blog/2020/hypercrl\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 01:46:26 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 02:46:27 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Huang", "Yizhou", ""], ["Xie", "Kevin", ""], ["Bharadhwaj", "Homanga", ""], ["Shkurti", "Florian", ""]]}, {"id": "2009.12005", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Pascale Fung", "title": "MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems", "comments": "EMNLP 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify\nthe system design process of task-oriented dialogue systems and alleviate the\nover-dependency on annotated data. MinTL is a simple yet effective transfer\nlearning framework, which allows us to plug-and-play pre-trained seq2seq\nmodels, and jointly learn dialogue state tracking and dialogue response\ngeneration. Unlike previous approaches, which use a copy mechanism to\n\"carryover\" the old dialogue states to the new one, we introduce Levenshtein\nbelief spans (Lev), that allows efficient dialogue state tracking with a\nminimal generation length. We instantiate our learning framework with two\npre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive\nexperiments demonstrate that: 1) our systems establish new state-of-the-art\nresults on end-to-end response generation, 2) MinTL-based systems are more\nrobust than baseline methods in the low resource setting, and they achieve\ncompetitive results with only 20\\% training data, and 3) Lev greatly improves\nthe inference efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 02:19:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 06:43:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.12030", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Bo Li, Yongfei Zhang, Shiliang Pu, Jingyang Li", "title": "AutoETER: Automated Entity Type Representation for Knowledge Graph\n  Embedding", "comments": "10 pages, 3 figures, the full version of a paper accepted to EMNLP\n  2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Knowledge Graph Embedding (KGE) allow for representing\nentities and relations in continuous vector spaces. Some traditional KGE models\nleveraging additional type information can improve the representation of\nentities which however totally rely on the explicit types or neglect the\ndiverse type representations specific to various relations. Besides, none of\nthe existing methods is capable of inferring all the relation patterns of\nsymmetry, inversion and composition as well as the complex properties of 1-N,\nN-1 and N-N relations, simultaneously. To explore the type information for any\nKG, we develop a novel KGE framework with Automated Entity TypE Representation\n(AutoETER), which learns the latent type embedding of each entity by regarding\neach relation as a translation operation between the types of two entities with\na relation-aware projection mechanism. Particularly, our designed automated\ntype representation learning mechanism is a pluggable module which can be\neasily incorporated with any KGE model. Besides, our approach could model and\ninfer all the relation patterns and complex relations. Experiments on four\ndatasets demonstrate the superior performance of our model compared to\nstate-of-the-art baselines on link prediction tasks, and the visualization of\ntype clustering provides clearly the explanation of type embeddings and\nverifies the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:27:35 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 13:52:59 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Niu", "Guanglin", ""], ["Li", "Bo", ""], ["Zhang", "Yongfei", ""], ["Pu", "Shiliang", ""], ["Li", "Jingyang", ""]]}, {"id": "2009.12064", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada and Hitoshi Iyatomi", "title": "Attention Meets Perturbations: Robust and Interpretable Attention with\n  Adversarial Training", "comments": "12 pages, 4 figures. Accepted by IEEE Access on Jun. 21, 2021", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3093456", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although attention mechanisms have been applied to a variety of deep learning\nmodels and have been shown to improve the prediction performance, it has been\nreported to be vulnerable to perturbations to the mechanism. To overcome the\nvulnerability to perturbations in the mechanism, we are inspired by adversarial\ntraining (AT), which is a powerful regularization technique for enhancing the\nrobustness of the models. In this paper, we propose a general training\ntechnique for natural language processing tasks, including AT for attention\n(Attention AT) and more interpretable AT for attention (Attention iAT). The\nproposed techniques improved the prediction performance and the model\ninterpretability by exploiting the mechanisms with AT. In particular, Attention\niAT boosts those advantages by introducing adversarial perturbation, which\nenhances the difference in the attention of the sentences. Evaluation\nexperiments with ten open datasets revealed that AT for attention mechanisms,\nespecially Attention iAT, demonstrated (1) the best performance in nine out of\nten tasks and (2) more interpretable attention (i.e., the resulting attention\ncorrelated more strongly with gradient-based word importance) for all tasks.\nAdditionally, the proposed techniques are (3) much less dependent on\nperturbation size in AT. Our code is available at\nhttps://github.com/shunk031/attention-meets-perturbation\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:26:45 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 02:31:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2009.12065", "submitter": "Diego Perez Liebana Dr.", "authors": "Raluca D. Gaina, Martin Balla, Alexander Dockhorn, Raul Montoliu,\n  Diego Perez-Liebana", "title": "Design and Implementation of TAG: A Tabletop Games Framework", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document describes the design and implementation of the Tabletop Games\nframework (TAG), a Java-based benchmark for developing modern board games for\nAI research. TAG provides a common skeleton for implementing tabletop games\nbased on a common API for AI agents, a set of components and classes to easily\nadd new games and an import module for defining data in JSON format. At\npresent, this platform includes the implementation of seven different tabletop\ngames that can also be used as an example for further developments.\nAdditionally, TAG also incorporates logging functionality that allows the user\nto perform a detailed analysis of the game, in terms of action space, branching\nfactor, hidden information, and other measures of interest for Game AI\nresearch. The objective of this document is to serve as a central point where\nthe framework can be described at length. TAG can be downloaded at:\nhttps://github.com/GAIGResearch/TabletopGames\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:27:30 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Balla", "Martin", ""], ["Dockhorn", "Alexander", ""], ["Montoliu", "Raul", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2009.12068", "submitter": "Jin Yang", "authors": "Gang Peng, Jin Yang, Xinde Lia, Mohammad Omar Khyam", "title": "Deep Reinforcement Learning with a Stage Incentive Mechanism of Dense\n  Reward for Robotic Trajectory Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (This work has been submitted to the IEEE for possible publication. Copyright\nmay be transferred without notice, after which this version may no longer be\naccessible.)\n  To improve the efficiency of deep reinforcement learning (DRL)-based methods\nfor robot manipulator trajectory planning in random working environments, we\npresent three dense reward functions. These rewards differ from the traditional\nsparse reward. First, a posture reward function is proposed to speed up the\nlearning process with a more reasonable trajectory by modeling the distance and\ndirection constraints, which can reduce the blindness of exploration. Second, a\nstride reward function is proposed to improve the stability of the learning\nprocess by modeling the distance and movement distance of joint constraints.\nFinally, in order to further improve learning efficiency, we are inspired by\nthe cognitive process of human behavior and propose a stage incentive\nmechanism, including a hard stage incentive reward function and a soft stage\nincentive reward function. Extensive experiments show that the soft stage\nincentive reward function is able to improve the convergence rate by up to\n46.9% with the state-of-the-art DRL methods. The percentage increase in the\nconvergence mean reward was 4.4-15.5% and the percentage decreases with respect\nto standard deviation were 21.9-63.2%. In the evaluation experiments, the\nsuccess rate of trajectory planning for a robot manipulator reached 99.6%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:36:32 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 04:55:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Peng", "Gang", ""], ["Yang", "Jin", ""], ["Lia", "Xinde", ""], ["Khyam", "Mohammad Omar", ""]]}, {"id": "2009.12106", "submitter": "Hai Zhu", "authors": "\\'Alvaro Serra-G\\'omez, Bruno Brito, Hai Zhu, Jen Jen Chung, Javier\n  Alonso-Mora", "title": "With Whom to Communicate: Learning Efficient Communication for\n  Multi-Robot Collision Avoidance", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized multi-robot systems typically perform coordinated motion\nplanning by constantly broadcasting their intentions as a means to cope with\nthe lack of a central system coordinating the efforts of all robots. Especially\nin complex dynamic environments, the coordination boost allowed by\ncommunication is critical to avoid collisions between cooperating robots.\nHowever, the risk of collision between a pair of robots fluctuates through\ntheir motion and communication is not always needed. Additionally, constant\ncommunication makes much of the still valuable information shared in previous\ntime steps redundant. This paper presents an efficient communication method\nthat solves the problem of \"when\" and with \"whom\" to communicate in multi-robot\ncollision avoidance scenarios. In this approach, every robot learns to reason\nabout other robots' states and considers the risk of future collisions before\nasking for the trajectory plans of other robots. We evaluate and verify the\nproposed communication strategy in simulation with four quadrotors and compare\nit with three baseline strategies: non-communicating, broadcasting and a\ndistance-based method broadcasting information with quadrotors within a\npredefined distance.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:49:22 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Serra-G\u00f3mez", "\u00c1lvaro", ""], ["Brito", "Bruno", ""], ["Zhu", "Hai", ""], ["Chung", "Jen Jen", ""], ["Alonso-Mora", "Javier", ""]]}, {"id": "2009.12178", "submitter": "Patrick Rodler", "authors": "Patrick Rodler and Fatima Elichanova", "title": "Do We Really Sample Right In Model-Based Diagnosis?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical samples, in order to be representative, have to be drawn from a\npopulation in a random and unbiased way. Nevertheless, it is common practice in\nthe field of model-based diagnosis to make estimations from (biased) best-first\nsamples. One example is the computation of a few most probable possible fault\nexplanations for a defective system and the use of these to assess which aspect\nof the system, if measured, would bring the highest information gain.\n  In this work, we scrutinize whether these statistically not well-founded\nconventions, that both diagnosis researchers and practitioners have adhered to\nfor decades, are indeed reasonable. To this end, we empirically analyze various\nsampling methods that generate fault explanations. We study the\nrepresentativeness of the produced samples in terms of their estimations about\nfault explanations and how well they guide diagnostic decisions, and we\ninvestigate the impact of sample size, the optimal trade-off between sampling\nefficiency and effectivity, and how approximate sampling techniques compare to\nexact ones.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:30:14 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Rodler", "Patrick", ""], ["Elichanova", "Fatima", ""]]}, {"id": "2009.12190", "submitter": "Patrick Rodler", "authors": "Patrick Rodler", "title": "Sound, Complete, Linear-Space, Best-First Diagnosis Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various model-based diagnosis scenarios require the computation of the most\npreferred fault explanations. Existing algorithms that are sound (i.e., output\nonly actual fault explanations) and complete (i.e., can return all\nexplanations), however, require exponential space to achieve this task. As a\nremedy, to enable successful diagnosis on memory-restricted devices and for\nmemory-intensive problem cases, we propose RBF-HS, a diagnostic search method\nbased on Korf's well-known RBFS algorithm. RBF-HS can enumerate an arbitrary\nfixed number of fault explanations in best-first order within linear space\nbounds, without sacrificing the desirable soundness or completeness properties.\nEvaluations using real-world diagnosis cases show that RBF-HS, when used to\ncompute minimum-cardinality fault explanations, in most cases saves substantial\nspace (up to 98 %) while requiring only reasonably more or even less time than\nReiter's HS-Tree, a commonly used and as generally applicable sound, complete\nand best-first diagnosis search.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:49:49 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Rodler", "Patrick", ""]]}, {"id": "2009.12199", "submitter": "Vijil Chenthamarakshan", "authors": "Kar Wai Lim, Bhanushee Sharma, Payel Das, Vijil Chenthamarakshan,\n  Jonathan S. Dordick", "title": "Explaining Chemical Toxicity using Missing Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical toxicity prediction using machine learning is important in drug\ndevelopment to reduce repeated animal and human testing, thus saving cost and\ntime. It is highly recommended that the predictions of computational toxicology\nmodels are mechanistically explainable. Current state of the art machine\nlearning classifiers are based on deep neural networks, which tend to be\ncomplex and harder to interpret. In this paper, we apply a recently developed\nmethod named contrastive explanations method (CEM) to explain why a chemical or\nmolecule is predicted to be toxic or not. In contrast to popular methods that\nprovide explanations based on what features are present in the molecule, the\nCEM provides additional explanation on what features are missing from the\nmolecule that is crucial for the prediction, known as the pertinent negative.\nThe CEM does this by optimizing for the minimum perturbation to the model using\na projected fast iterative shrinkage-thresholding algorithm (FISTA). We\nverified that the explanation from CEM matches known toxicophores and findings\nfrom other work.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 23:34:34 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Lim", "Kar Wai", ""], ["Sharma", "Bhanushee", ""], ["Das", "Payel", ""], ["Chenthamarakshan", "Vijil", ""], ["Dordick", "Jonathan S.", ""]]}, {"id": "2009.12213", "submitter": "Qi Dai", "authors": "Qi Dai, Xunnong Xu, Wen Guo, Suzhou Huang, Dimitar Filev", "title": "Towards a Systematic Computational Framework for Modeling Multi-Agent\n  Decision-Making at Micro Level for Smart Vehicles in a Smart World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-agent based computational framework for modeling\ndecision-making and strategic interaction at micro level for smart vehicles in\na smart world. The concepts of Markov game and best response dynamics are\nheavily leveraged. Our aim is to make the framework conceptually sound and\ncomputationally practical for a range of realistic applications, including\nmicro path planning for autonomous vehicles. To this end, we first convert the\nwould-be stochastic game problem into a closely related deterministic one by\nintroducing risk premium in the utility function for each individual agent. We\nshow how the sub-game perfect Nash equilibrium of the simplified deterministic\ngame can be solved by an algorithm based on best response dynamics. In order to\nbetter model human driving behaviors with bounded rationality, we seek to\nfurther simplify the solution concept by replacing the Nash equilibrium\ncondition with a heuristic and adaptive optimization with finite look-ahead\nanticipation. In addition, the algorithm corresponding to the new solution\nconcept drastically improves the computational efficiency. To demonstrate how\nour approach can be applied to realistic traffic settings, we conduct a\nsimulation experiment: to derive merging and yielding behaviors on a\ndouble-lane highway with an unexpected barrier. Despite assumption differences\ninvolved in the two solution concepts, the derived numerical solutions show\nthat the endogenized driving behaviors are very similar. We also briefly\ncomment on how the proposed framework can be further extended in a number of\ndirections in our forthcoming work, such as behavioral calibration using real\ntraffic video data, computational mechanism design for traffic policy\noptimization, and so on.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:05:28 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Dai", "Qi", ""], ["Xu", "Xunnong", ""], ["Guo", "Wen", ""], ["Huang", "Suzhou", ""], ["Filev", "Dimitar", ""]]}, {"id": "2009.12237", "submitter": "Sagar Malhotra", "authors": "Sagar Malhotra and Luciano Serafini", "title": "Weighted Model Counting in the two variable fragment with Cardinality\n  Constraints: A Closed Form Formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Weighted First-Order Model Counting (WFOMC) computes the weighted sum of the\nmodels of a first-order theory on a given finite domain. WFOMC has emerged as a\nfundamental tool for probabilistic inference. Algorithms for WFOMC that run in\npolynomial time w.r.t. the domain size are called lifted inference algorithms.\nSuch algorithms have been developed for multiple extensions of FO2(the fragment\nof first-order logic with two variables) for the special case of symmetric\nweight functions. We introduce the concept of lifted interpretations as a tool\nfor formulating polynomials for WFOMC. Using lifted interpretations, we\nreconstruct the closed-form formula for polynomial-time FOMC in the universal\nfragment of FO2, earlier proposed by Beame et al. We then expand this\nclosed-form to incorporate existential quantifiers and cardinality constraints\nwithout losing domain-liftability. Finally, we show that the obtained\nclosed-form motivates a natural definition of a family of weight functions\nstrictly larger than symmetric weight functions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:50:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 08:45:49 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 13:29:45 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 11:45:58 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 17:03:19 GMT"}, {"version": "v6", "created": "Fri, 26 Mar 2021 16:51:58 GMT"}, {"version": "v7", "created": "Thu, 13 May 2021 17:29:59 GMT"}, {"version": "v8", "created": "Fri, 28 May 2021 13:26:02 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Malhotra", "Sagar", ""], ["Serafini", "Luciano", ""]]}, {"id": "2009.12240", "submitter": "Mark Riedl", "authors": "Mark Riedl", "title": "Weird AI Yankovic: Generating Parody Lyrics", "comments": "9 pages, serious paper about a silly task, written accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyrics parody swaps one set of words that accompany a melody with a new set\nof words, preserving the number of syllables per line and the rhyme scheme.\nLyrics parody generation is a challenge for controllable text generation. We\nshow how a specialized sampling procedure, combined with backward text\ngeneration with XLNet can produce parody lyrics that reliably meet the syllable\nand rhyme scheme constraints.We introduce the Weird AI Yankovic system and\nprovide a case study evaluation. We conclude with societal implications of\nneural lyric parody generation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:56:20 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Riedl", "Mark", ""]]}, {"id": "2009.12285", "submitter": "Cogan Shimizu", "authors": "Cogan Shimizu, Ryan McGranaghan, Aaron Eberhart, Adam C. Kellerman", "title": "Towards a Modular Ontology for Space Weather Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The interactions between the Sun, interplanetary space, near Earth space\nenvironment, the Earth's surface, and the power grid are, perhaps\nunsurprisingly, very complicated. The study of such requires the collaboration\nbetween many different organizations spanning the public and private sectors.\nThus, an important component of studying space weather is the integration and\nanalysis of heterogeneous information. As such, we have developed a modular\nontology to drive the core of the data integration and serve the needs of a\nhighly interdisciplinary community. This paper presents our preliminary modular\nontology, for space weather research, as well as demonstrate a method for\nadaptation to a particular use-case, through the use of existential rules and\nexplicit typing.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:17:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:24:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shimizu", "Cogan", ""], ["McGranaghan", "Ryan", ""], ["Eberhart", "Aaron", ""], ["Kellerman", "Adam C.", ""]]}, {"id": "2009.12293", "submitter": "Yuke Zhu", "authors": "Yuke Zhu and Josiah Wong and Ajay Mandlekar and Roberto\n  Mart\\'in-Mart\\'in", "title": "robosuite: A Modular Simulation Framework and Benchmark for Robot\n  Learning", "comments": "For more information, please visit https://robosuite.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  robosuite is a simulation framework for robot learning powered by the MuJoCo\nphysics engine. It offers a modular design for creating robotic tasks as well\nas a suite of benchmark environments for reproducible research. This paper\ndiscusses the key system modules and the benchmark environments of our new\nrelease robosuite v1.0.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:32:31 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Zhu", "Yuke", ""], ["Wong", "Josiah", ""], ["Mandlekar", "Ajay", ""], ["Mart\u00edn-Mart\u00edn", "Roberto", ""]]}, {"id": "2009.12303", "submitter": "Prasetya Ajie Utama", "authors": "Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych", "title": "Towards Debiasing NLU Models from Unknown Biases", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLU models often exploit biases to achieve high dataset-specific performance\nwithout properly learning the intended task. Recently proposed debiasing\nmethods are shown to be effective in mitigating this tendency. However, these\nmethods rely on a major assumption that the types of bias should be known\na-priori, which limits their application to many NLU tasks and datasets. In\nthis work, we present the first step to bridge this gap by introducing a\nself-debiasing framework that prevents models from mainly utilizing biases\nwithout knowing them in advance. The proposed framework is general and\ncomplementary to the existing debiasing methods. We show that it allows these\nexisting methods to retain the improvement on the challenge datasets (i.e.,\nsets of examples designed to expose models' reliance on biases) without\nspecifically targeting certain biases. Furthermore, the evaluation suggests\nthat applying the framework results in improved overall robustness.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:49:39 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 11:00:39 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 11:52:22 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 12:37:27 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Utama", "Prasetya Ajie", ""], ["Moosavi", "Nafise Sadat", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2009.12414", "submitter": "Haruna Isah", "authors": "Chantal Montgomery, Haruna Isah, Farhana Zulkernine", "title": "Towards a Natural Language Query Processing System", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling the information retrieval gap between non-technical database\nend-users and those with the knowledge of formal query languages has been an\ninteresting area of data management and analytics research. The use of natural\nlanguage interfaces to query information from databases offers the opportunity\nto bridge the communication challenges between end-users and systems that use\nformal query languages. Previous research efforts mainly focused on developing\nstructured query interfaces to relational databases. However, the evolution of\nunstructured big data such as text, images, and video has exposed the\nlimitations of traditional structured query interfaces. While the existing web\nsearch tools prove the popularity and usability of natural language query, they\nreturn complete documents and web pages instead of focused query responses and\nare not applicable to database systems. This paper reports our study on the\ndesign and development of a natural language query interface to a backend\nrelational database. The novelty in the study lies in defining a graph database\nas a middle layer to store necessary metadata needed to transform a natural\nlanguage query into structured query language that can be executed on backend\ndatabases. We implemented and evaluated our approach using a restaurant\ndataset. The translation results for some sample queries yielded a 90% accuracy\nrate.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:52:20 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Montgomery", "Chantal", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""]]}, {"id": "2009.12415", "submitter": "Haruna Isah", "authors": "Ruoran Liu, Haruna Isah, Farhana Zulkernine", "title": "A Big Data Lake for Multilevel Streaming Analytics", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large organizations are seeking to create new architectures and scalable\nplatforms to effectively handle data management challenges due to the explosive\nnature of data rarely seen in the past. These data management challenges are\nlargely posed by the availability of streaming data at high velocity from\nvarious sources in multiple formats. The changes in data paradigm have led to\nthe emergence of new data analytics and management architecture. This paper\nfocuses on storing high volume, velocity and variety data in the raw formats in\na data storage architecture called a data lake. First, we present our study on\nthe limitations of traditional data warehouses in handling recent changes in\ndata paradigms. We discuss and compare different open source and commercial\nplatforms that can be used to develop a data lake. We then describe our\nend-to-end data lake design and implementation approach using the Hadoop\nDistributed File System (HDFS) on the Hadoop Data Platform (HDP). Finally, we\npresent a real-world data lake development use case for data stream ingestion,\nstaging, and multilevel streaming analytics which combines structured and\nunstructured data. This study can serve as a guide for individuals or\norganizations planning to implement a data lake solution for their use cases.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:57:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Ruoran", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""]]}, {"id": "2009.12416", "submitter": "Diego Carvalho", "authors": "Rafael Garcia Barbastefano and Maria Clara Lippi and Diego Carvalho", "title": "Process mining classification with a weightless neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a weightless neural network architecture WiSARD we propose a\nstraightforward graph to retina codification to represent business process\ngraph flows avoiding kernels, and we present how WiSARD outperforms the\nclassification performance with small training sets in the process mining\ncontext.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:59:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Barbastefano", "Rafael Garcia", ""], ["Lippi", "Maria Clara", ""], ["Carvalho", "Diego", ""]]}, {"id": "2009.12430", "submitter": "Saeed Ranjbar Alvar", "authors": "Saeed Ranjbar Alvar and Ivan V. Baji\\'c", "title": "Pareto-Optimal Bit Allocation for Collaborative Intelligence", "comments": null, "journal-ref": "IEEE Trans. Image Processing, vol. 30, pp. 3348-3361, Feb. 2021", "doi": "10.1109/TIP.2021.3060875", "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, collaborative intelligence (CI) has emerged as a promising\nframework for deployment of Artificial Intelligence (AI)-based services on\nmobile/edge devices. In CI, the AI model (a deep neural network) is split\nbetween the edge and the cloud, and intermediate features are sent from the\nedge sub-model to the cloud sub-model. In this paper, we study bit allocation\nfor feature coding in multi-stream CI systems. We model task distortion as a\nfunction of rate using convex surfaces similar to those found in\ndistortion-rate theory. Using such models, we are able to provide closed-form\nbit allocation solutions for single-task systems and scalarized multi-task\nsystems. Moreover, we provide analytical characterization of the full Pareto\nset for 2-stream k-task systems, and bounds on the Pareto set for 3-stream\n2-task systems. Analytical results are examined on a variety of DNN models from\nthe literature to demonstrate wide applicability of the results\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:48:33 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 23:41:16 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Alvar", "Saeed Ranjbar", ""], ["Baji\u0107", "Ivan V.", ""]]}, {"id": "2009.12462", "submitter": "Jarom\\'ir Janisch", "authors": "Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y and Viliam Lis\\'y", "title": "Symbolic Relational Deep Reinforcement Learning based on Graph Neural\n  Networks", "comments": "RL4RealLife @ ICML2021; code available at\n  https://github.com/jaromiru/sr-drl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on reinforcement learning (RL) in relational problems that are\nnaturally defined in terms of objects, their relations, and manipulations.\nThese problems are characterized by variable state and action spaces, and\nfinding a fixed-length representation, required by most existing RL methods, is\ndifficult, if not impossible. We present a deep RL framework based on graph\nneural networks and auto-regressive policy decomposition that naturally works\nwith these problems and is completely domain-independent. We demonstrate the\nframework in three very distinct domains and we report the method's competitive\nperformance and impressive zero-shot generalization over different problem\nsizes. In goal-oriented BlockWorld, we demonstrate multi-parameter actions with\npre-conditions. In SysAdmin, we show how to select multiple objects\nsimultaneously. In the classical planning domain of Sokoban, the method trained\nexclusively on 10x10 problems with three boxes solves 89% of 15x15 problems\nwith five boxes.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:41:04 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 20:02:52 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 14:05:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Janisch", "Jarom\u00edr", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["Lis\u00fd", "Viliam", ""]]}, {"id": "2009.12517", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Thanh Vu and Tu Dinh Nguyen and Dinh Phung", "title": "QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and effective embedding model, named QuatRE, to learn\nquaternion embeddings for entities and relations in knowledge graphs. QuatRE\naims to enhance correlations between head and tail entities given a relation\nwithin the Quaternion space with Hamilton product. QuatRE achieves this by\nassociating each relation with two quaternion vectors which are used to rotate\nthe quaternion embeddings of the head and tail entities, respectively. To\nobtain the triple score, QuatRE rotates the rotated embedding of the head\nentity using the normalized quaternion embedding of the relation, followed by a\nquaternion-inner product with the rotated embedding of the tail entity.\nExperimental results show that our QuatRE outperforms up-to-date embedding\nmodels on well-known benchmark datasets for knowledge graph completion.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 04:44:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2009.12521", "submitter": "EPTCS", "authors": "Grant Passmore (Imandra, Inc. and Clare Hall, Cambridge), Ruben Gamboa\n  (University of Wyoming)", "title": "Proceedings of the Sixteenth International Workshop on the ACL2 Theorem\n  Prover and its Applications", "comments": null, "journal-ref": "EPTCS 327, 2020", "doi": "10.4204/EPTCS.327", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains a selection of papers presented at the 16th\nInternational Workshop on the ACL2 Theorem Prover and its Applications\n(ACL2-2020). The workshops are the premier technical forum for presenting\nresearch and experiences related to ACL2.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 05:19:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Passmore", "Grant", "", "Imandra, Inc. and Clare Hall, Cambridge"], ["Gamboa", "Ruben", "", "University of Wyoming"]]}, {"id": "2009.12562", "submitter": "Ferdinando Fioretto", "authors": "Cuong Tran, Ferdinando Fioretto, Pascal Van Hentenryck", "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical concern in data-driven decision making is to build models whose\noutcomes do not discriminate against some demographic groups, including gender,\nethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of\nthe sensitive attributes is essential, while, in practice, these attributes may\nnot be available due to legal and ethical requirements. To address this\nchallenge, this paper studies a model that protects the privacy of the\nindividuals sensitive information while also allowing it to learn\nnon-discriminatory predictors. The method relies on the notion of differential\nprivacy and the use of Lagrangian duality to design neural networks that can\naccommodate fairness constraints while guaranteeing the privacy of sensitive\nattributes. The paper analyses the tension between accuracy, privacy, and\nfairness and the experimental evaluation illustrates the benefits of the\nproposed model on several prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 10:50:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Tran", "Cuong", ""], ["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2009.12576", "submitter": "Minhae Kwon", "authors": "Minhae Kwon, Saurabh Daptardar, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control with Partially Observable Continuous Nonlinear\n  Dynamics", "comments": "NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in neuroscience is how the brain creates an internal\nmodel of the world to guide actions using sequences of ambiguous sensory\ninformation. This is naturally formulated as a reinforcement learning problem\nunder partial observations, where an agent must estimate relevant latent\nvariables in the world from its evidence, anticipate possible future states,\nand choose actions that optimize total expected reward. This problem can be\nsolved by control theory, which allows us to find the optimal actions for a\ngiven system dynamics and objective function. However, animals often appear to\nbehave suboptimally. Why? We hypothesize that animals have their own flawed\ninternal model of the world, and choose actions with the highest expected\nsubjective reward according to that flawed model. We describe this behavior as\nrational but not optimal. The problem of Inverse Rational Control (IRC) aims to\nidentify which internal model would best explain an agent's actions. Our\ncontribution here generalizes past work on Inverse Rational Control which\nsolved this problem for discrete control in partially observable Markov\ndecision processes. Here we accommodate continuous nonlinear dynamics and\ncontinuous actions, and impute sensory observations corrupted by unknown noise\nthat is private to the animal. We first build an optimal Bayesian agent that\nlearns an optimal policy generalized over the entire model space of dynamics\nand subjective rewards using deep reinforcement learning. Crucially, this\nallows us to compute a likelihood over models for experimentally observable\naction trajectories acquired from a suboptimal agent. We then find the model\nparameters that maximize the likelihood using gradient ascent.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:47:48 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:09:41 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Kwon", "Minhae", ""], ["Daptardar", "Saurabh", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "2009.12600", "submitter": "Gavin Rens", "authors": "Gavin Rens, Jean-Fran\\c{c}ois Raskin, Rapha\\\"el Reynouad, Giuseppe\n  Marra", "title": "Online Learning of Non-Markovian Reward Models", "comments": "24 pages, single column, 7 figures. arXiv admin note: substantial\n  text overlap with arXiv:2001.09293", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are situations in which an agent should receive rewards only after\nhaving accomplished a series of previous tasks, that is, rewards are\nnon-Markovian. One natural and quite general way to represent history-dependent\nrewards is via a Mealy machine, a finite state automaton that produces output\nsequences from input sequences. In our formal setting, we consider a Markov\ndecision process (MDP) that models the dynamics of the environment in which the\nagent evolves and a Mealy machine synchronized with this MDP to formalize the\nnon-Markovian reward function. While the MDP is known by the agent, the reward\nfunction is unknown to the agent and must be learned.\n  Our approach to overcome this challenge is to use Angluin's $L^*$ active\nlearning algorithm to learn a Mealy machine representing the underlying\nnon-Markovian reward machine (MRM). Formal methods are used to determine the\noptimal strategy for answering so-called membership queries posed by $L^*$.\n  Moreover, we prove that the expected reward achieved will eventually be at\nleast as much as a given, reasonable value provided by a domain expert. We\nevaluate our framework on three problems. The results show that using $L^*$ to\nlearn an MRM in a non-Markovian reward decision process is effective.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 13:54:34 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 08:56:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Rens", "Gavin", ""], ["Raskin", "Jean-Fran\u00e7ois", ""], ["Reynouad", "Rapha\u00ebl", ""], ["Marra", "Giuseppe", ""]]}, {"id": "2009.12604", "submitter": "Andreea-Ioana Deac", "authors": "Andreea Deac, Pierre-Luc Bacon, Jian Tang", "title": "Graph neural induction of value iteration", "comments": "ICML GRL+ 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning tasks can benefit from explicit planning based on\nan internal model of the environment. Previously, such planning components have\nbeen incorporated through a neural network that partially aligns with the\ncomputational graph of value iteration. Such network have so far been focused\non restrictive environments (e.g. grid-worlds), and modelled the planning\nprocedure only indirectly. We relax these constraints, proposing a graph neural\nnetwork (GNN) that executes the value iteration (VI) algorithm, across\narbitrary environment models, with direct supervision on the intermediate steps\nof VI. The results indicate that GNNs are able to model value iteration\naccurately, recovering favourable metrics and policies across a variety of\nout-of-distribution tests. This suggests that GNN executors with strong\nsupervision are a viable component within deep reinforcement learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:09:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Deac", "Andreea", ""], ["Bacon", "Pierre-Luc", ""], ["Tang", "Jian", ""]]}, {"id": "2009.12678", "submitter": "Benjamin Busam", "authors": "Benjamin Busam and Hyun Jun Jung and Nassir Navab", "title": "I Like to Move It: 6D Pose Estimation as an Action Decision Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object pose estimation is an integral part of robot vision and AR. Previous\n6D pose retrieval pipelines treat the problem either as a regression task or\ndiscretize the pose space to classify. We change this paradigm and reformulate\nthe problem as an action decision process where an initial pose is updated in\nincremental discrete steps that sequentially move a virtual 3D rendering\ntowards the correct solution. A neural network estimates likely moves from a\nsingle RGB image iteratively and determines so an acceptable final pose. In\ncomparison to other approaches that train object-specific pose models, we learn\na decision process. This allows for a lightweight architecture while it\nnaturally generalizes to unseen objects. A coherent stop action for process\ntermination enables dynamic reduction of the computation cost if there are\ninsignificant changes in a video sequence. Instead of a static inference time,\nwe thereby automatically increase the runtime depending on the object motion.\nRobustness and accuracy of our action decision network are evaluated on Laval\nand YCB video scenes where we significantly improve the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:05:42 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 19:03:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Busam", "Benjamin", ""], ["Jung", "Hyun Jun", ""], ["Navab", "Nassir", ""]]}, {"id": "2009.12691", "submitter": "Juan Camilo Fonseca-Galindo", "authors": "Juan Camilo Fonseca-Galindo, Gabriela de Castro Surita, Jos\\'e Maia\n  Neto, Cristiano Leite de Castro and Andr\\'e Paim Lemos", "title": "A Multi-Agent System for Solving the Dynamic Capacitated Vehicle Routing\n  Problem with Stochastic Customers using Trajectory Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worldwide growth of e-commerce has created new challenges for logistics\ncompanies, one of which is being able to deliver products quickly and at low\ncost, which reflects directly in the way of sorting packages, needing to\neliminate steps such as storage and batch creation. Our work presents a\nmulti-agent system that uses trajectory data mining techniques to extract\nterritorial patterns and use them in the dynamic creation of last-mile routes.\nThe problem can be modeled as a Dynamic Capacitated Vehicle Routing Problem\n(VRP) with Stochastic Customer, being therefore NP-HARD, what makes its\nimplementation unfeasible for many packages. The work's main contribution is to\nsolve this problem only depending on the Warehouse system configurations and\nnot on the number of packages processed, which is appropriate for Big Data\nscenarios commonly present in the delivery of e-commerce products.\nComputational experiments were conducted for single and multi depot instances.\nDue to its probabilistic nature, the proposed approach presented slightly lower\nperformances when compared to the static VRP algorithm. However, the\noperational gains that our solution provides making it very attractive for\nsituations in which the routes must be set dynamically.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 21:36:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fonseca-Galindo", "Juan Camilo", ""], ["Surita", "Gabriela de Castro", ""], ["Neto", "Jos\u00e9 Maia", ""], ["de Castro", "Cristiano Leite", ""], ["Lemos", "Andr\u00e9 Paim", ""]]}, {"id": "2009.12795", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "NN-EVCLUS: Neural Network-based Evidential Clustering", "comments": null, "journal-ref": "Information Sciences, Volume 572, Pages 297-330, 2021", "doi": "10.1016/j.ins.2021.05.011", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential clustering is an approach to clustering based on the use of\nDempster-Shafer mass functions to represent cluster-membership uncertainty. In\nthis paper, we introduce a neural-network based evidential clustering\nalgorithm, called NN-EVCLUS, which learns a mapping from attribute vectors to\nmass functions, in such a way that more similar inputs are mapped to output\nmass functions with a lower degree of conflict. The neural network can be\npaired with a one-class support vector machine to make it robust to outliers\nand allow for novelty detection. The network is trained to minimize the\ndiscrepancy between dissimilarities and degrees of conflict for all or some\nobject pairs. Additional terms can be added to the loss function to account for\npairwise constraints or labeled data, which can also be used to adapt the\nmetric. Comparative experiments show the superiority of N-EVCLUS over\nstate-of-the-art evidential clustering algorithms for a range of unsupervised\nand constrained clustering tasks involving both attribute and dissimilarity\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 09:05:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 01:56:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "2009.12864", "submitter": "Lei M. Zhang", "authors": "Lei M. Zhang, Matthias Plappert, Wojciech Zaremba", "title": "Predicting Sim-to-Real Transfer with Probabilistic Dynamics Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to predict the sim-to-real transfer performance of RL\npolicies. Our transfer metric simplifies the selection of training setups (such\nas algorithm, hyperparameters, randomizations) and policies in simulation,\nwithout the need for extensive and time-consuming real-world rollouts. A\nprobabilistic dynamics model is trained alongside the policy and evaluated on a\nfixed set of real-world trajectories to obtain the transfer metric. Experiments\nshow that the transfer metric is highly correlated with policy performance in\nboth simulated and real-world robotic environments for complex manipulation\ntasks. We further show that the transfer metric can predict the effect of\ntraining setups on policy transfer performance.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:06:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Lei M.", ""], ["Plappert", "Matthias", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2009.12924", "submitter": "Dustin Arendt", "authors": "Brittany Davis, Maria Glenski, William Sealy, Dustin Arendt", "title": "Measure Utility, Gain Trust: Practical Advice for XAI Researcher", "comments": "To appear in TREX 2020: Workshop on TRust and EXperience in Visual\n  Analytics. https://trexvis.github.io/Workshop2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research into the explanation of machine learning models, i.e., explainable\nAI (XAI), has seen a commensurate exponential growth alongside deep artificial\nneural networks throughout the past decade. For historical reasons, explanation\nand trust have been intertwined. However, the focus on trust is too narrow, and\nhas led the research community astray from tried and true empirical methods\nthat produced more defensible scientific knowledge about people and\nexplanations. To address this, we contribute a practical path forward for\nresearchers in the XAI field. We recommend researchers focus on the utility of\nmachine learning explanations instead of trust. We outline five broad use cases\nwhere explanations are useful and, for each, we describe pseudo-experiments\nthat rely on objective empirical measurements and falsifiable hypotheses. We\nbelieve that this experimental rigor is necessary to contribute to scientific\nknowledge in the field of XAI.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 18:55:33 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Davis", "Brittany", ""], ["Glenski", "Maria", ""], ["Sealy", "William", ""], ["Arendt", "Dustin", ""]]}, {"id": "2009.12974", "submitter": "Fred Valdez Ameneyro", "authors": "Fred Valdez Ameneyro, Edgar Galvan, Anger Fernando Kuri Morales", "title": "Playing Carcassonne with Monte Carlo Tree Search", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo Tree Search (MCTS) is a relatively new sampling method with\nmultiple variants in the literature. They can be applied to a wide variety of\nchallenging domains including board games, video games, and energy-based\nproblems to mention a few. In this work, we explore the use of the vanilla MCTS\nand the MCTS with Rapid Action Value Estimation (MCTS-RAVE) in the game of\nCarcassonne, a stochastic game with a deceptive scoring system where limited\nresearch has been conducted. We compare the strengths of the MCTS-based methods\nwith the Star2.5 algorithm, previously reported to yield competitive results in\nthe game of Carcassonne when a domain-specific heuristic is used to evaluate\nthe game states. We analyse the particularities of the strategies adopted by\nthe algorithms when they share a common reward system. The MCTS-based methods\nconsistently outperformed the Star2.5 algorithm given their ability to find and\nfollow long-term strategies, with the vanilla MCTS exhibiting a more robust\ngame-play than the MCTS-RAVE.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 22:35:53 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 17:49:29 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ameneyro", "Fred Valdez", ""], ["Galvan", "Edgar", ""], ["Morales", "Anger Fernando Kuri", ""]]}, {"id": "2009.12990", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Uncertain Linear Logic via Fibring of Probabilistic and Fuzzy Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning with a simple semantics for propositions, based on counting\nobservations, it is shown that probabilistic and fuzzy logic correspond to two\ndifferent heuristic assumptions regarding the combination of propositions whose\nevidence bases are not currently available. These two different heuristic\nassumptions lead to two different sets of formulas for propagating quantitative\ntruth values through lattice operations. It is shown that these two sets of\nformulas provide a natural grounding for the multiplicative and additive\noperator-sets in linear logic. The standard rules of linear logic then emerge\nas consequences of the underlying semantics. The concept of linear logic as a\n``logic of resources\" is manifested here via the principle of ``conservation of\nevidence\" -- the restrictions to weakening and contraction in linear logic\nserve to avoid double-counting of evidence (beyond any double-counting incurred\nvia use of heuristic truth value functions).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 00:19:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "2009.13028", "submitter": "Haochen Liu", "authors": "Haochen Liu, Wentao Wang, Yiqi Wang, Hui Liu, Zitao Liu and Jiliang\n  Tang", "title": "Mitigating Gender Bias for Neural Dialogue Generation with Adversarial\n  Learning", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems play an increasingly important role in various aspects of\nour daily life. It is evident from recent research that dialogue systems\ntrained on human conversation data are biased. In particular, they can produce\nresponses that reflect people's gender prejudice. Many debiasing methods have\nbeen developed for various NLP tasks, such as word embedding. However, they are\nnot directly applicable to dialogue systems because they are likely to force\ndialogue models to generate similar responses for different genders. This\ngreatly degrades the diversity of the generated responses and immensely hurts\nthe performance of the dialogue models. In this paper, we propose a novel\nadversarial learning framework Debiased-Chat to train dialogue models free from\ngender bias while keeping their performance. Extensive experiments on two\nreal-world conversation datasets show that our framework significantly reduces\ngender bias in dialogue models while maintaining the response quality. The\nimplementation of the proposed framework is released.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:46:59 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 19:36:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Wang", "Wentao", ""], ["Wang", "Yiqi", ""], ["Liu", "Hui", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "2009.13033", "submitter": "Chang Liao", "authors": "Chang Liao, Yao Cheng, Chengfang Fang, Jie Shi", "title": "Where Does the Robustness Come from? A Study of the Transformation-based\n  Ensemble Defence", "comments": "The 27th ACM Conference on Computer and Communications Security (CCS)\n  Workshop, AISec 2020", "journal-ref": "the 13th ACM Workshop on Artificial Intelligence and Security 2020", "doi": "10.1145/3411508.3421380", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to provide a thorough study on the effectiveness of the\ntransformation-based ensemble defence for image classification and its reasons.\nIt has been empirically shown that they can enhance the robustness against\nevasion attacks, while there is little analysis on the reasons. In particular,\nit is not clear whether the robustness improvement is a result of\ntransformation or ensemble. In this paper, we design two adaptive attacks to\nbetter evaluate the transformation-based ensemble defence. We conduct\nexperiments to show that 1) the transferability of adversarial examples exists\namong the models trained on data records after different reversible\ntransformations; 2) the robustness gained through transformation-based ensemble\nis limited; 3) this limited robustness is mainly from the irreversible\ntransformations rather than the ensemble of a number of models; and 4) blindly\nincreasing the number of sub-models in a transformation-based ensemble does not\nbring extra robustness gain.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:55:56 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 09:16:18 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Liao", "Chang", ""], ["Cheng", "Yao", ""], ["Fang", "Chengfang", ""], ["Shi", "Jie", ""]]}, {"id": "2009.13051", "submitter": "Justin Terry", "authors": "Justin K Terry, Nathaniel Grammel, Benjamin Black, Ananth Hari,\n  Caroline Horsch, Luis Santos", "title": "Agent Environment Cycle Games", "comments": "This work of this paper has been merged into the paper \"PettingZoo:\n  Gym for Multi-Agent Reinforcement Learning\" arXiv:2009.14471", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially Observable Stochastic Games (POSGs) are the most general and common\nmodel of games used in Multi-Agent Reinforcement Learning (MARL). We argue that\nthe POSG model is conceptually ill suited to software MARL environments, and\noffer case studies from the literature where this mismatch has led to severely\nunexpected behavior. In response to this, we introduce the Agent Environment\nCycle Games (AEC Games) model, which is more representative of software\nimplementation. We then prove it's as an equivalent model to POSGs. The AEC\ngames model is also uniquely useful in that it can elegantly represent both all\nforms of MARL environments, whereas for example POSGs cannot elegantly\nrepresent strictly turn based games like chess.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:02:08 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 19:06:59 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 14:24:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Terry", "Justin K", ""], ["Grammel", "Nathaniel", ""], ["Black", "Benjamin", ""], ["Hari", "Ananth", ""], ["Horsch", "Caroline", ""], ["Santos", "Luis", ""]]}, {"id": "2009.13058", "submitter": "Luis A. Pineda", "authors": "Luis A. Pineda and Gibr\\'an Fuentes and Rafael Morales", "title": "An Entropic Associative Memory", "comments": "25 pages, 6 figures, 17 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural memories are associative, declarative and distributed. Symbolic\ncomputing memories resemble natural memories in their declarative character,\nand information can be stored and recovered explicitly; however, they lack the\nassociative and distributed properties of natural memories. Sub-symbolic\nmemories developed within the connectionist or artificial neural networks\nparadigm are associative and distributed, but are unable to express symbolic\nstructure and information cannot be stored and retrieved explicitly; hence,\nthey lack the declarative property. To address this dilemma, we use\nRelational-Indeterminate Computing to model associative memory registers that\nhold distributed representations of individual objects. This mode of computing\nhas an intrinsic computing entropy which measures the indeterminacy of\nrepresentations. This parameter determines the operational characteristics of\nthe memory. Associative registers are embedded in an architecture that maps\nconcrete images expressed in modality-specific buffers into abstract\nrepresentations, and vice versa, and the memory system as a whole fulfills the\nthree properties of natural memories. The system has been used to model a\nvisual memory holding the representations of hand-written digits, and\nrecognition and recall experiments show that there is a range of entropy\nvalues, not too low and not too high, in which associative memory registers\nhave a satisfactory performance. The similarity between the cue and the object\nrecovered in memory retrieve operations depends on the entropy of the memory\nregister holding the representation of the corresponding object. The\nexperiments were implemented in a simulation using a standard computer, but a\nparallel architecture may be built where the memory operations would take a\nvery reduced number of computing steps.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:24:21 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Pineda", "Luis A.", ""], ["Fuentes", "Gibr\u00e1n", ""], ["Morales", "Rafael", ""]]}, {"id": "2009.13081", "submitter": "Di Jin", "authors": "Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang and\n  Peter Szolovits", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question\n  Answering Dataset from Medical Exams", "comments": "Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open domain question answering (OpenQA) tasks have been recently attracting\nmore and more attention from the natural language processing (NLP) community.\nIn this work, we present the first free-form multiple-choice OpenQA dataset for\nsolving medical problems, MedQA, collected from the professional medical board\nexams. It covers three languages: English, simplified Chinese, and traditional\nChinese, and contains 12,723, 34,251, and 14,123 questions for the three\nlanguages, respectively. We implement both rule-based and popular neural\nmethods by sequentially combining a document retriever and a machine\ncomprehension model. Through experiments, we find that even the current best\nmethod can only achieve 36.7\\%, 42.0\\%, and 70.1\\% of test accuracy on the\nEnglish, traditional Chinese, and simplified Chinese questions, respectively.\nWe expect MedQA to present great challenges to existing OpenQA systems and hope\nthat it can serve as a platform to promote much stronger OpenQA models from the\nNLP community in the future.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 05:07:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Jin", "Di", ""], ["Pan", "Eileen", ""], ["Oufattole", "Nassim", ""], ["Weng", "Wei-Hung", ""], ["Fang", "Hanyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2009.13161", "submitter": "Douglas Meneghetti", "authors": "Douglas De Rizzo Meneghetti and Reinaldo Augusto da Costa Bianchi", "title": "Towards Heterogeneous Multi-Agent Reinforcement Learning with Graph\n  Neural Networks", "comments": "Published and presented at the XVI Encontro Nacional de\n  Intelig\\^encia Artificial e Computacional (ENIAC). Fixed notation", "journal-ref": null, "doi": "10.5753/eniac.2020.12161", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a neural network architecture that learns policies for\nmultiple agent classes in a heterogeneous multi-agent reinforcement setting.\nThe proposed network uses directed labeled graph representations for states,\nencodes feature vectors of different sizes for different entity classes, uses\nrelational graph convolution layers to model different communication channels\nbetween entity types and learns distinct policies for different agent classes,\nsharing parameters wherever possible. Results have shown that specializing the\ncommunication channels between entity classes is a promising step to achieve\nhigher performance in environments composed of heterogeneous entities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:15:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 22:47:17 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 20:47:02 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Meneghetti", "Douglas De Rizzo", ""], ["Bianchi", "Reinaldo Augusto da Costa", ""]]}, {"id": "2009.13165", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Quantal synaptic dilution enhances sparse encoding and dropout\n  regularisation in deep networks", "comments": "23 pages, 8 figures, including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a technique that silences the activity of units stochastically\nwhile training deep networks to reduce overfitting. Here we introduce Quantal\nSynaptic Dilution (QSD), a biologically plausible model of dropout\nregularisation based on the quantal properties of neuronal synapses, that\nincorporates heterogeneities in response magnitudes and release probabilities\nfor vesicular quanta. QSD outperforms standard dropout in ReLU multilayer\nperceptrons, with enhanced sparse encoding at test time when dropout masks are\nreplaced with identity functions, without shifts in trainable weight or bias\ndistributions. For convolutional networks, the method also improves\ngeneralisation in computer vision tasks with and without inclusion of\nadditional forms of regularisation. QSD also outperforms standard dropout in\nrecurrent networks for language modelling and sentiment analysis. An advantage\nof QSD over many variations of dropout is that it can be implemented generally\nin all conventional deep networks where standard dropout is applicable.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:29:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "2009.13199", "submitter": "Zhihan Zhang", "authors": "Zhihan Zhang, Xiubo Geng, Tao Qin, Yunfang Wu, Daxin Jiang", "title": "Knowledge-Aware Procedural Text Understanding with Multi-Stage Training", "comments": "Published as full paper in Proceedings of the Web Conference 2021\n  (WWW'21)", "journal-ref": null, "doi": "10.1145/3442381.3450126", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural text describes dynamic state changes during a step-by-step natural\nprocess (e.g., photosynthesis). In this work, we focus on the task of\nprocedural text understanding, which aims to comprehend such documents and\ntrack entities' states and locations during a process. Although recent\napproaches have achieved substantial progress, their results are far behind\nhuman performance. Two challenges, the difficulty of commonsense reasoning and\ndata insufficiency, still remain unsolved, which require the incorporation of\nexternal knowledge bases. Previous works on external knowledge injection\nusually rely on noisy web mining tools and heuristic rules with limited\napplicable scenarios. In this paper, we propose a novel KnOwledge-Aware\nproceduraL text understAnding (KOALA) model, which effectively leverages\nmultiple forms of external knowledge in this task. Specifically, we retrieve\ninformative knowledge triples from ConceptNet and perform knowledge-aware\nreasoning while tracking the entities. Besides, we employ a multi-stage\ntraining schema which fine-tunes the BERT model over unlabeled data collected\nfrom Wikipedia before further fine-tuning it on the final model. Experimental\nresults on two procedural text datasets, ProPara and Recipes, verify the\neffectiveness of the proposed methods, in which our model achieves\nstate-of-the-art performance in comparison to various baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:28:40 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 14:28:25 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Zhihan", ""], ["Geng", "Xiubo", ""], ["Qin", "Tao", ""], ["Wu", "Yunfang", ""], ["Jiang", "Daxin", ""]]}, {"id": "2009.13200", "submitter": "Rita Borgo", "authors": "Rita Borgo and Darren J Edwards", "title": "The Development of Visualization Psychology Analysis Tools to Account\n  for Trust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Defining trust is an important endeavor given its applicability to assessing\npublic mood to much of the innovation in the newly formed autonomous industry,\nsuch as artificial intelligence (AI),medical bots, drones, autonomous vehicles,\nand smart factories [19].Through developing a reliable index or means to\nmeasure trust,this may have wide impact from fostering acceptance and adoption\nof smart systems to informing policy makers about the public atmosphere and\nwillingness to adopt innovate change, and has been identified as an important\nindicator in a recent UK policy brief [8].In this paper, we reflect on the\nimportance and potential impact of developing Visualization Psychology in the\ncontext of solving definitions and policy decision making problems for complex\nconstructs such as \"trust\".\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:30:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Borgo", "Rita", ""], ["Edwards", "Darren J", ""]]}, {"id": "2009.13251", "submitter": "Efr\\'en Rama-Maneiro", "authors": "Efr\\'en Rama-Maneiro, Juan C. Vidal, Manuel Lama", "title": "Deep Learning for Predictive Business Process Monitoring: Review and\n  Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive monitoring of business processes is concerned with the prediction\nof ongoing cases on a business process. Lately, the popularity of deep learning\ntechniques has propitiated an ever-growing set of approaches focused on\npredictive monitoring based on these techniques. However, the high disparity of\nprocess logs and experimental setups used to evaluate these approaches makes it\nespecially difficult to make a fair comparison. Furthermore, it also difficults\nthe selection of the most suitable approach to solve a specific problem. In\nthis paper, we provide both a systematic literature review of approaches that\nuse deep learning to tackle the predictive monitoring tasks. In addition, we\nperformed an exhaustive experimental evaluation of 10 different approaches over\n12 publicly available process logs.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 14:30:23 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 10:07:42 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 11:03:04 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Rama-Maneiro", "Efr\u00e9n", ""], ["Vidal", "Juan C.", ""], ["Lama", "Manuel", ""]]}, {"id": "2009.13252", "submitter": "Xueping Peng", "authors": "Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, Chengqi\n  Zhang", "title": "BiteNet: Bidirectional Temporal Encoder Network to Predict Medical\n  Outcomes", "comments": "10 pages, 8 figures, accepted by IEEE ICDM 2020. arXiv admin note:\n  substantial text overlap with arXiv:2006.10516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) are longitudinal records of a patient's\ninteractions with healthcare systems. A patient's EHR data is organized as a\nthree-level hierarchy from top to bottom: patient journey - all the experiences\nof diagnoses and treatments over a period of time; individual visit - a set of\nmedical codes in a particular visit; and medical code - a specific record in\nthe form of medical codes. As EHRs begin to amass in millions, the potential\nbenefits, which these data might hold for medical research and medical outcome\nprediction, are staggering - including, for example, predicting future\nadmissions to hospitals, diagnosing illnesses or determining the efficacy of\nmedical treatments. Each of these analytics tasks requires a domain knowledge\nextraction method to transform the hierarchical patient journey into a vector\nrepresentation for further prediction procedure. The representations should\nembed a sequence of visits and a set of medical codes with a specific\ntimestamp, which are crucial to any downstream prediction tasks. Hence,\nexpressively powerful representations are appealing to boost learning\nperformance. To this end, we propose a novel self-attention mechanism that\ncaptures the contextual dependency and temporal relationships within a\npatient's healthcare journey. An end-to-end bidirectional temporal encoder\nnetwork (BiteNet) then learns representations of the patient's journeys, based\nsolely on the proposed attention mechanism. We have evaluated the effectiveness\nof our methods on two supervised prediction and two unsupervised clustering\ntasks with a real-world EHR dataset. The empirical results demonstrate the\nproposed BiteNet model produces higher-quality representations than\nstate-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 00:42:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2009.13264", "submitter": "Tariq Khan Dr", "authors": "Tariq M. Khan and Antonio Robles-Kelly", "title": "A Derivative-free Method for Quantum Perceptron Training in\n  Multi-layered Neural Networks", "comments": "9 pages, 2 figures, Accepted in ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a gradient-free approach for training multi-layered\nneural networks based upon quantum perceptrons. Here, we depart from the\nclassical perceptron and the elemental operations on quantum bits, i.e. qubits,\nso as to formulate the problem in terms of quantum perceptrons. We then make\nuse of measurable operators to define the states of the network in a manner\nconsistent with a Markov process. This yields a Dirac-Von Neumann formulation\nconsistent with quantum mechanics. Moreover, the formulation presented here has\nthe advantage of having a computational efficiency devoid of the number of\nlayers in the network. This, paired with the natural efficiency of quantum\ncomputing, can imply a significant improvement in efficiency, particularly for\ndeep networks. Finally, but not least, the developments here are quite general\nin nature since the approach presented here can also be used for\nquantum-inspired neural networks implemented on conventional computers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 01:38:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Khan", "Tariq M.", ""], ["Robles-Kelly", "Antonio", ""]]}, {"id": "2009.13275", "submitter": "Edgar Altszyler", "authors": "Edgar Altszyler, Pablo Brusco, Nikoletta Basiou, John Byrnes and\n  Dimitra Vergyri", "title": "Zero-shot Multi-Domain Dialog State Tracking Using Descriptive Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a framework for incorporating descriptive logical\nrules in state-of-the-art neural networks, enabling them to learn how to handle\nunseen labels without the introduction of any new training data. The rules are\nintegrated into existing networks without modifying their architecture, through\nan additional term in the network's loss function that penalizes states of the\nnetwork that do not obey the designed rules. As a case of study, the framework\nis applied to an existing neural-based Dialog State Tracker. Our experiments\ndemonstrate that the inclusion of logical rules allows the prediction of unseen\nlabels, without deteriorating the predictive capacity of the original system.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:14:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Altszyler", "Edgar", ""], ["Brusco", "Pablo", ""], ["Basiou", "Nikoletta", ""], ["Byrnes", "John", ""], ["Vergyri", "Dimitra", ""]]}, {"id": "2009.13284", "submitter": "Hongjin Qian", "authors": "Hongjin Qian, Xiaohe Li, Hanxun Zhong, Yu Guo, Yueyuan Ma, Yutao Zhu,\n  Zhanliang Liu, Zhicheng Dou, Ji-Rong Wen", "title": "Pchatbot: A Large-Scale Dataset for Personalized Chatbot", "comments": "Camera-ready version, SIGIR 2021 (Resource Track), the dataset and\n  codes are available at https://github.com/qhjqhj00/Pchatbot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language dialogue systems raise great attention recently. As many\ndialogue models are data-driven, high-quality datasets are essential to these\nsystems. In this paper, we introduce Pchatbot, a large-scale dialogue dataset\nthat contains two subsets collected from Weibo and Judicial forums\nrespectively. To adapt the raw dataset to dialogue systems, we elaborately\nnormalize the raw dataset via processes such as anonymization, deduplication,\nsegmentation, and filtering. The scale of Pchatbot is significantly larger than\nexisting Chinese datasets, which might benefit the data-driven models. Besides,\ncurrent dialogue datasets for personalized chatbot usually contain several\npersona sentences or attributes. Different from existing datasets, Pchatbot\nprovides anonymized user IDs and timestamps for both posts and responses. This\nenables the development of personalized dialogue models that directly learn\nimplicit user personality from the user's dialogue history. Our preliminary\nexperimental study benchmarks several state-of-the-art dialogue models to\nprovide a comparison for future work. The dataset can be publicly accessed at\nGithub.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:49:07 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 02:51:35 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 05:53:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Qian", "Hongjin", ""], ["Li", "Xiaohe", ""], ["Zhong", "Hanxun", ""], ["Guo", "Yu", ""], ["Ma", "Yueyuan", ""], ["Zhu", "Yutao", ""], ["Liu", "Zhanliang", ""], ["Dou", "Zhicheng", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2009.13301", "submitter": "El Mehdi Er Raqabi", "authors": "Akash Sambrekar, El Mehdi Er Raqabi", "title": "A Column Generation based Heuristic for the Tail Assignment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes an efficient heuristic in accelerating the column\ngeneration by parallel resolution of pricing problems for aircrafts in the tail\nassignment problem (TAP). The approach is able to achieve considerable\nimprovement in resolution time for real life test instances from two major\nIndian air carriers. The different restrictions on individual aircraft for\nmaintenance routing as per aviation regulatory bodies are considered in this\npaper. We also present a variable fixing heuristic to improve the integrality\nof the solution. The hybridization of constraint programming and column\ngeneration was substantial in accelerating the resolution process.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:41:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sambrekar", "Akash", ""], ["Raqabi", "El Mehdi Er", ""]]}, {"id": "2009.13371", "submitter": "Mehak Maniktala", "authors": "Mehak Maniktala, Christa Cody, Tiffany Barnes, and Min Chi", "title": "Avoiding Help Avoidance: Using Interface Design Changes to Promote\n  Unsolicited Hint Usage in an Intelligent Tutor", "comments": null, "journal-ref": "International Journal of Artificial Intelligence in Education 2020", "doi": "10.1007/s40593-020-00213-3", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within intelligent tutoring systems, considerable research has investigated\nhints, including how to generate data-driven hints, what hint content to\npresent, and when to provide hints for optimal learning outcomes. However, less\nattention has been paid to how hints are presented. In this paper, we propose a\nnew hint delivery mechanism called \"Assertions\" for providing unsolicited hints\nin a data-driven intelligent tutor. Assertions are partially-worked example\nsteps designed to appear within a student workspace, and in the same format as\nstudent-derived steps, to show students a possible subgoal leading to the\nsolution. We hypothesized that Assertions can help address the well-known hint\navoidance problem. In systems that only provide hints upon request, hint\navoidance results in students not receiving hints when they are needed. Our\nunsolicited Assertions do not seek to improve student help-seeking, but rather\nseek to ensure students receive the help they need. We contrast Assertions with\nMessages, text-based, unsolicited hints that appear after student inactivity.\nOur results show that Assertions significantly increase unsolicited hint usage\ncompared to Messages. Further, they show a significant aptitude-treatment\ninteraction between Assertions and prior proficiency, with Assertions leading\nstudents with low prior proficiency to generate shorter (more efficient)\nposttest solutions faster. We also present a clustering analysis that shows\npatterns of productive persistence among students with low prior knowledge when\nthe tutor provides unsolicited help in the form of Assertions. Overall, this\nwork provides encouraging evidence that hint presentation can significantly\nimpact how students use them and using Assertions can be an effective way to\naddress help avoidance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:39:11 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 16:28:55 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Maniktala", "Mehak", ""], ["Cody", "Christa", ""], ["Barnes", "Tiffany", ""], ["Chi", "Min", ""]]}, {"id": "2009.13472", "submitter": "Matthew Vowels", "authors": "Matthew James Vowels and Necati Cihan Camgoz and Richard Bowden", "title": "Targeted VAE: Variational and Targeted Learning for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undertaking causal inference with observational data is incredibly useful\nacross a wide range of tasks including the development of medical treatments,\nadvertisements and marketing, and policy making. There are two significant\nchallenges associated with undertaking causal inference using observational\ndata: treatment assignment heterogeneity (i.e., differences between the treated\nand untreated groups), and an absence of counterfactual data (i.e., not knowing\nwhat would have happened if an individual who did get treatment, were instead\nto have not been treated). We address these two challenges by combining\nstructured inference and targeted learning. In terms of structure, we factorize\nthe joint distribution into risk, confounding, instrumental, and miscellaneous\nfactors, and in terms of targeted learning, we apply a regularizer derived from\nthe influence curve in order to reduce residual bias. An ablation study is\nundertaken, and an evaluation on benchmark datasets demonstrates that TVAE has\ncompetitive and state of the art performance across.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:55:24 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 17:35:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vowels", "Matthew James", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2009.13504", "submitter": "Peiyuan Liao", "authors": "Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon,\n  Stefanie Jegelka, Ruslan Salakhutdinov", "title": "Information Obfuscation of Graph Neural Networks", "comments": "ICML 2021; Code is available at https://github.com/liaopeiyuan/GAL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the advent of Graph Neural Networks (GNNs) has greatly improved node\nand graph representation learning in many applications, the neighborhood\naggregation scheme exposes additional vulnerabilities to adversaries seeking to\nextract node-level information about sensitive attributes. In this paper, we\nstudy the problem of protecting sensitive attributes by information obfuscation\nwhen learning with graph structured data. We propose a framework to locally\nfilter out pre-determined sensitive attributes via adversarial training with\nthe total variation and the Wasserstein distance. Our method creates a strong\ndefense against inference attacks, while only suffering small loss in task\nperformance. Theoretically, we analyze the effectiveness of our framework\nagainst a worst-case adversary, and characterize an inherent trade-off between\nmaximizing predictive accuracy and minimizing information leakage. Experiments\nacross multiple datasets from recommender systems, knowledge graphs and quantum\nchemistry demonstrate that the proposed approach provides a robust defense\nacross various graph structures and tasks, while producing competitive GNN\nencoders for downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 17:55:04 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:34:52 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:27:46 GMT"}, {"version": "v4", "created": "Sun, 9 May 2021 06:25:27 GMT"}, {"version": "v5", "created": "Sun, 13 Jun 2021 05:35:04 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liao", "Peiyuan", ""], ["Zhao", "Han", ""], ["Xu", "Keyulu", ""], ["Jaakkola", "Tommi", ""], ["Gordon", "Geoffrey", ""], ["Jegelka", "Stefanie", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2009.13516", "submitter": "Chen Zhao", "authors": "Chen Zhao, Changbin Li, Jincheng Li, Feng Chen", "title": "Fair Meta-Learning For Few-Shot Classification", "comments": "2020 IEEE International Conference on Knowledge Graph (ICKG). arXiv\n  admin note: text overlap with arXiv:2009.11406", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence nowadays plays an increasingly prominent role in our\nlife since decisions that were once made by humans are now delegated to\nautomated systems. A machine learning algorithm trained based on biased data,\nhowever, tends to make unfair predictions. Developing classification algorithms\nthat are fair with respect to protected attributes of the data thus becomes an\nimportant problem. Motivated by concerns surrounding the fairness effects of\nsharing and few-shot machine learning tools, such as the Model Agnostic\nMeta-Learning framework, we propose a novel fair fast-adapted few-shot\nmeta-learning approach that efficiently mitigates biases during meta-train by\nensuring controlling the decision boundary covariance that between the\nprotected variable and the signed distance from the feature vectors to the\ndecision boundary. Through extensive experiments on two real-world image\nbenchmarks over three state-of-the-art meta-learning algorithms, we empirically\ndemonstrate that our proposed approach efficiently mitigates biases on model\noutput and generalizes both accuracy and fairness to unseen tasks with a\nlimited amount of training samples.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 22:33:47 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Chen", ""], ["Li", "Changbin", ""], ["Li", "Jincheng", ""], ["Chen", "Feng", ""]]}, {"id": "2009.13521", "submitter": "Ben Adler", "authors": "Ben Adler", "title": "Zero Knowledge Games", "comments": "27 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-knowledge strategies as a form of inference and reasoning operate using\nthe concept of zero-knowledge signaling, such that any imperfect recall or\nincomplete information can be attenuated for. The resulting effect of\nstructuring a continuous game within a zero-knowledge strategy demonstrates the\nability to infer, within acceptable probabilities, which approximate stage a\nplayer is in. This occurs only when an uninformed player attempts non-revealing\nstrategies, resulting in a higher probability of failing to appear informed.\nThus, an opposing player understanding their opponent is uninformed can choose\na more optimal strategy. In cases where an informed player chooses a\nnon-revealing strategy, introducing a hedge algebra as a doxastic heuristic\ninforms feasibility levels of trust. A counter strategy employing such a hedge\nalgebra facilitates optimal outcomes for both players, provided the trust is\nwell placed. Given indefinite, finite sub-games leading to continued\ninteractions based on trust, extensions to continuous games are feasible.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 16:04:52 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 19:50:06 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Adler", "Ben", ""]]}, {"id": "2009.13570", "submitter": "Mihail Eric", "authors": "Shikib Mehri, Mihail Eric, Dilek Hakkani-Tur", "title": "DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented\n  Dialogue", "comments": "Benchmark hosted on:\n  https://evalai.cloudcv.org/web/challenges/challenge-page/708/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A long-standing goal of task-oriented dialogue research is the ability to\nflexibly adapt dialogue models to new domains. To progress research in this\ndirection, we introduce DialoGLUE (Dialogue Language Understanding Evaluation),\na public benchmark consisting of 7 task-oriented dialogue datasets covering 4\ndistinct natural language understanding tasks, designed to encourage dialogue\nresearch in representation-based transfer, domain adaptation, and\nsample-efficient task learning. We release several strong baseline models,\ndemonstrating performance improvements over a vanilla BERT architecture and\nstate-of-the-art results on 5 out of 7 tasks, by pre-training on a large\nopen-domain dialogue corpus and task-adaptive self-supervised training. Through\nthe DialoGLUE benchmark, the baseline methods, and our evaluation scripts, we\nhope to facilitate progress towards the goal of developing more general\ntask-oriented dialogue models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:36:23 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 00:00:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mehri", "Shikib", ""], ["Eric", "Mihail", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2009.13580", "submitter": "Vikash Gupta", "authors": "Vikash Gupta and Clayton Taylor and Sarah Bonnet and Luciano M.\n  Prevedello and Jeffrey Hawley and Richard D White and Mona G Flores and\n  Barbaros Selnur Erdal", "title": "Deep Learning-Based Automatic Detection of Poorly Positioned Mammograms\n  to Minimize Patient Return Visits for Repeat Imaging: A Real-World\n  Application", "comments": "12 pages, 13 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Screening mammograms are a routine imaging exam performed to detect breast\ncancer in its early stages to reduce morbidity and mortality attributed to this\ndisease. In order to maximize the efficacy of breast cancer screening programs,\nproper mammographic positioning is paramount. Proper positioning ensures\nadequate visualization of breast tissue and is necessary for effective breast\ncancer detection. Therefore, breast-imaging radiologists must assess each\nmammogram for the adequacy of positioning before providing a final\ninterpretation of the examination; this often necessitates return patient\nvisits for additional imaging. In this paper, we propose a deep\nlearning-algorithm method that mimics and automates this decision-making\nprocess to identify poorly positioned mammograms. Our objective for this\nalgorithm is to assist mammography technologists in recognizing inadequately\npositioned mammograms real-time, improve the quality of mammographic\npositioning and performance, and ultimately reducing repeat visits for patients\nwith initially inadequate imaging. The proposed model showed a true positive\nrate for detecting correct positioning of 91.35% in the mediolateral oblique\nview and 95.11% in the craniocaudal view. In addition to these results, we also\npresent an automatically generated report which can aid the mammography\ntechnologist in taking corrective measures during the patient visit.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:54:53 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gupta", "Vikash", ""], ["Taylor", "Clayton", ""], ["Bonnet", "Sarah", ""], ["Prevedello", "Luciano M.", ""], ["Hawley", "Jeffrey", ""], ["White", "Richard D", ""], ["Flores", "Mona G", ""], ["Erdal", "Barbaros Selnur", ""]]}, {"id": "2009.13603", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Muhao Chen, Dan Roth, Nigel Collier", "title": "Visual Pivoting for (Unsupervised) Entity Alignment", "comments": "To appear at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the use of visual semantic representations to align\nentities in heterogeneous knowledge graphs (KGs). Images are natural components\nof many existing KGs. By combining visual knowledge with other auxiliary\ninformation, we show that the proposed new approach, EVA, creates a holistic\nentity representation that provides strong signals for cross-graph entity\nalignment. Besides, previous entity alignment methods require human labelled\nseed alignment, restricting availability. EVA provides a completely\nunsupervised solution by leveraging the visual similarity of entities to create\nan initial seed dictionary (visual pivots). Experiments on benchmark data sets\nDBP15k and DWY15k show that EVA offers state-of-the-art performance on both\nmonolingual and cross-lingual entity alignment tasks. Furthermore, we discover\nthat images are particularly useful to align long-tail KG entities, which\ninherently lack the structural contexts necessary for capturing the\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:09:40 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 02:18:41 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Liu", "Fangyu", ""], ["Chen", "Muhao", ""], ["Roth", "Dan", ""], ["Collier", "Nigel", ""]]}, {"id": "2009.13613", "submitter": "Danish Contractor", "authors": "Danish Contractor, Shashank Goel, Mausam, Parag Singla", "title": "Joint Spatio-Textual Reasoning for Answering Tourism Questions", "comments": "Updated version", "journal-ref": null, "doi": "10.1145/3442381.3449857", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to answer real-world tourism questions that seek\nPoints-of-Interest (POI) recommendations. Such questions express various kinds\nof spatial and non-spatial constraints, necessitating a combination of textual\nand spatial reasoning. In response, we develop the first joint spatio-textual\nreasoning model, which combines geo-spatial knowledge with information in\ntextual corpora to answer questions. We first develop a modular\nspatial-reasoning network that uses geo-coordinates of location names mentioned\nin a question, and of candidate answer POIs, to reason over only spatial\nconstraints. We then combine our spatial-reasoner with a textual reasoner in a\njoint model and present experiments on a real world POI recommendation task. We\nreport substantial improvements over existing models with-out joint\nspatio-textual reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:35:00 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 07:18:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Contractor", "Danish", ""], ["Goel", "Shashank", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "2009.13650", "submitter": "Joseph Near", "authors": "Krystal Maughan, Joseph P. Near", "title": "Towards a Measure of Individual Fairness for Deep Learning", "comments": "Presented at MD4SG '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has produced big advances in artificial intelligence, but\ntrained neural networks often reflect and amplify bias in their training data,\nand thus produce unfair predictions. We propose a novel measure of individual\nfairness, called prediction sensitivity, that approximates the extent to which\na particular prediction is dependent on a protected attribute. We show how to\ncompute prediction sensitivity using standard automatic differentiation\ncapabilities present in modern deep learning frameworks, and present\npreliminary empirical results suggesting that prediction sensitivity may be\neffective for measuring bias in individual predictions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 21:53:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Maughan", "Krystal", ""], ["Near", "Joseph P.", ""]]}, {"id": "2009.13656", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Samuel Cahyawijaya, Genta Indra Winata, Yan Xu, Zihan\n  Liu, Zhaojiang Lin, Pascale Fung", "title": "Learning Knowledge Bases with Parameters for Task-Oriented Dialogue\n  Systems", "comments": "Accepted EMNLP findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems are either modularized with separate dialogue\nstate tracking (DST) and management steps or end-to-end trainable. In either\ncase, the knowledge base (KB) plays an essential role in fulfilling user\nrequests. Modularized systems rely on DST to interact with the KB, which is\nexpensive in terms of annotation and inference time. End-to-end systems use the\nKB directly as input, but they cannot scale when the KB is larger than a few\nhundred entries. In this paper, we propose a method to embed the KB, of any\nsize, directly into the model parameters. The resulting model does not require\nany DST or template responses, nor the KB as input, and it can dynamically\nupdate its KB via fine-tuning. We evaluate our solution in five task-oriented\ndialogue datasets with small, medium, and large KB size. Our experiments show\nthat end-to-end models can effectively embed knowledge bases in their\nparameters and achieve competitive performance in all evaluated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:13:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Madotto", "Andrea", ""], ["Cahyawijaya", "Samuel", ""], ["Winata", "Genta Indra", ""], ["Xu", "Yan", ""], ["Liu", "Zihan", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.13664", "submitter": "Eugene Tam", "authors": "Eugene Tam, Shenfei Jiang, Paul Duan, Shawn Meng, Yue Pang, Cayden\n  Huang, Yi Han, Jacke Xie, Yuanjun Cui, Jinsong Yu, Minggui Lu", "title": "Breaking the Memory Wall for AI Chip with a New Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in deep learning have led to the widespread adoption of\nartificial intelligence (AI) in applications such as computer vision and\nnatural language processing. As neural networks become deeper and larger, AI\nmodeling demands outstrip the capabilities of conventional chip architectures.\nMemory bandwidth falls behind processing power. Energy consumption comes to\ndominate the total cost of ownership. Currently, memory capacity is\ninsufficient to support the most advanced NLP models. In this work, we present\na 3D AI chip, called Sunrise, with near-memory computing architecture to\naddress these three challenges. This distributed, near-memory computing\narchitecture allows us to tear down the performance-limiting memory wall with\nan abundance of data bandwidth. We achieve the same level of energy efficiency\non 40nm technology as competing chips on 7nm technology. By moving to similar\ntechnologies as other AI chips, we project to achieve more than ten times the\nenergy efficiency, seven times the performance of the current state-of-the-art\nchips, and twenty times of memory capacity as compared with the best chip in\neach benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:34:10 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Tam", "Eugene", ""], ["Jiang", "Shenfei", ""], ["Duan", "Paul", ""], ["Meng", "Shawn", ""], ["Pang", "Yue", ""], ["Huang", "Cayden", ""], ["Han", "Yi", ""], ["Xie", "Jacke", ""], ["Cui", "Yuanjun", ""], ["Yu", "Jinsong", ""], ["Lu", "Minggui", ""]]}, {"id": "2009.13714", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Parikshit Ram, Songtao Lu, Yuguang Yao, Djallel\n  Bouneffouf, Xue Lin", "title": "Learned Fine-Tuner for Incongruous Few-Shot Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model-agnostic meta-learning (MAML) effectively meta-learns an initialization\nof model parameters for few-shot learning where all learning problems share the\nsame format of model parameters -- congruous meta-learning. However, there are\nfew-shot learning scenarios, such as adversarial attack design, where different\nyet related few-shot learning problems may not share any optimizee variables,\nnecessitating incongruous meta-learning. We extend MAML to this setting -- a\nLearned Fine Tuner (LFT) is used to replace hand-designed optimizers (such as\nSGD) for the task-specific fine-tuning. Here, MAML instead meta-learns the\nparameters of this LFT across incongruous tasks leveraging the\nlearning-to-optimize (L2O) framework such that models fine-tuned with LFT (even\nfrom random initializations) adapt quickly to new tasks. As novel\ncontributions, we show that the use of LFT within MAML (i) offers the\ncapability to tackle few-shot learning tasks by meta-learning across\nincongruous yet related problems and (ii) can efficiently work with first-order\nand derivative-free few-shot learning problems. Theoretically, we quantify the\ndifference between LFT (for MAML) and L2O. Empirically, we demonstrate the\neffectiveness of LFT through a novel application of generating universal\nadversarial attacks across different image sources and sizes in the few-shot\nlearning regime.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:23:20 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 00:47:28 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 17:42:57 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ram", "Parikshit", ""], ["Lu", "Songtao", ""], ["Yao", "Yuguang", ""], ["Bouneffouf", "Djallel", ""], ["Lin", "Xue", ""]]}, {"id": "2009.13736", "submitter": "Yunshu Du", "authors": "Yunshu Du, Garrett Warnell, Assefaw Gebremedhin, Peter Stone, Matthew\n  E. Taylor", "title": "Lucid Dreaming for Experience Replay: Refreshing Past States with the\n  Current Policy", "comments": "29 pages (with appendices), 8 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay (ER) improves the data efficiency of off-policy\nreinforcement learning (RL) algorithms by allowing an agent to store and reuse\nits past experiences in a replay buffer. While many techniques have been\nproposed to enhance ER by biasing how experiences are sampled from the buffer,\nthus far they have not considered strategies for refreshing experiences inside\nthe buffer. In this work, we introduce Lucid Dreaming for Experience Replay\n(LiDER), a conceptually new framework that allows replay experiences to be\nrefreshed by leveraging the agent's current policy. LiDER consists of three\nsteps: First, LiDER moves an agent back to a past state. Second, from that\nstate, LiDER then lets the agent execute a sequence of actions by following its\ncurrent policy -- as if the agent were \"dreaming\" about the past and can try\nout different behaviors to encounter new experiences in the dream. Third, LiDER\nstores and reuses the new experience if it turned out better than what the\nagent previously experienced, i.e., to refresh its memories. LiDER is designed\nto be easily incorporated into off-policy, multi-worker RL algorithms that use\nER; we present in this work a case study of applying LiDER to an actor-critic\nbased algorithm. Results show LiDER consistently improves performance over the\nbaseline in six Atari 2600 games. Our open-source implementation of LiDER and\nthe data used to generate all plots in this work are available at\ngithub.com/duyunshu/lucid-dreaming-for-exp-replay.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 02:54:11 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 19:54:39 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 23:43:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Du", "Yunshu", ""], ["Warnell", "Garrett", ""], ["Gebremedhin", "Assefaw", ""], ["Stone", "Peter", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2009.13752", "submitter": "Shuang Zeng", "authors": "Shuang Zeng, Runxin Xu, Baobao Chang and Lei Li", "title": "Double Graph Based Reasoning for Document-level Relation Extraction", "comments": "Accepted as long paper to appear at the EMNLP 2020 main conference,\n  11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document-level relation extraction aims to extract relations among entities\nwithin a document. Different from sentence-level relation extraction, it\nrequires reasoning over multiple sentences across a document. In this paper, we\npropose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs.\nGAIN first constructs a heterogeneous mention-level graph (hMG) to model\ncomplex interaction among different mentions across the document. It also\nconstructs an entity-level graph (EG), based on which we propose a novel path\nreasoning mechanism to infer relations between entities. Experiments on the\npublic dataset, DocRED, show GAIN achieves a significant performance\nimprovement (2.85 on F1) over the previous state-of-the-art. Our code is\navailable at https://github.com/DreamInvoker/GAIN .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 03:41:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zeng", "Shuang", ""], ["Xu", "Runxin", ""], ["Chang", "Baobao", ""], ["Li", "Lei", ""]]}, {"id": "2009.13772", "submitter": "Kai-En Yang", "authors": "Kai-En Yang, Chia-Yu Tsai, Hung-Hao Shen, Chen-Feng Chiang, Feng-Ming\n  Tsai, Chung-An Wang, Yiju Ting, Chia-Shun Yeh, and Chin-Tang Lai", "title": "Fast Design Space Adaptation with Deep Reinforcement Learning for Analog\n  Circuit Sizing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for design space search on analog circuit sizing\nusing deep reinforcement learning (DRL). Nowadays, analog circuit design is a\nmanual routine that requires heavy design efforts due to the absence of\nautomation tools, motivating the urge to develop one. Prior approaches cast\nthis process as an optimization problem. They use global search strategies\nbased on DRL with complex network architectures. Nonetheless, the models are\nhard to converge and neglected various working conditions of PVT (process,\nvoltage, temperature).In this work, we reduce the problem to a constraint\nsatisfaction problem, where a local strategy is adopted. Thus, a simple\nfeed-forward network with few layers can be used to implement a model-based\nreinforcement learning agent. To evaluate the value of the our framework in\nproduction, we cooperate with R&Ds in an IC design company. On circuits with\nTSMC advanced 5 and 6nm process, our agents can deliver PPA (performance,\npower, area) beyond human level. Furthermore, the product will be taped out in\nthe near future.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:13:15 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 01:08:49 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 03:40:05 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Yang", "Kai-En", ""], ["Tsai", "Chia-Yu", ""], ["Shen", "Hung-Hao", ""], ["Chiang", "Chen-Feng", ""], ["Tsai", "Feng-Ming", ""], ["Wang", "Chung-An", ""], ["Ting", "Yiju", ""], ["Yeh", "Chia-Shun", ""], ["Lai", "Chin-Tang", ""]]}, {"id": "2009.13780", "submitter": "Xing Wang", "authors": "Xing Wang, Alexander Vinel", "title": "Cross Learning in Deep Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel cross Q-learning algorithm, aim at\nalleviating the well-known overestimation problem in value-based reinforcement\nlearning methods, particularly in the deep Q-networks where the overestimation\nis exaggerated by function approximation errors. Our algorithm builds on double\nQ-learning, by maintaining a set of parallel models and estimate the Q-value\nbased on a randomly selected network, which leads to reduced overestimation\nbias as well as the variance. We provide empirical evidence on the advantages\nof our method by evaluating on some benchmark environment, the experimental\nresults demonstrate significant improvement of performance in reducing the\noverestimation bias and stabilizing the training, further leading to better\nderived policies.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 04:58:17 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Xing", ""], ["Vinel", "Alexander", ""]]}, {"id": "2009.13792", "submitter": "K K Thyagharajan", "authors": "S. D. Lalitha, K. K. Thyagharajan", "title": "Micro-Facial Expression Recognition in Video Based on Optimal\n  Convolutional Neural Network (MFEOCNN) Algorithm", "comments": "19 pages, 10 figures, \"for published version see\n  https://www.ijeat.org/wp-content/uploads/papers/v9i1/A9802109119.pdf\"", "journal-ref": null, "doi": "10.35940/ijeat.A9802.109119", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expression is a standout amongst the most imperative features of human\nemotion recognition. For demonstrating the emotional states facial expressions\nare utilized by the people. In any case, recognition of facial expressions has\npersisted a testing and intriguing issue with regards to PC vision. Recognizing\nthe Micro-Facial expression in video sequence is the main objective of the\nproposed approach. For efficient recognition, the proposed method utilizes the\noptimal convolution neural network. Here the proposed method considering the\ninput dataset is the CK+ dataset. At first, by means of Adaptive median\nfiltering preprocessing is performed in the input image. From the preprocessed\noutput, the extracted features are Geometric features, Histogram of Oriented\nGradients features and Local binary pattern features. The novelty of the\nproposed method is, with the help of Modified Lion Optimization (MLO)\nalgorithm, the optimal features are selected from the extracted features. In a\nshorter computational time, it has the benefits of rapidly focalizing and\neffectively acknowledging with the aim of getting an overall arrangement or\nidea. Finally, the recognition is done by Convolution Neural network (CNN).\nThen the performance of the proposed MFEOCNN method is analysed in terms of\nfalse measures and recognition accuracy. This kind of emotion recognition is\nmainly used in medicine, marketing, E-learning, entertainment, law and\nmonitoring. From the simulation, we know that the proposed approach achieves\nmaximum recognition accuracy of 99.2% with minimum Mean Absolute Error (MAE)\nvalue. These results are compared with the existing for MicroFacial Expression\nBased Deep-Rooted Learning (MFEDRL), Convolutional Neural Network with Lion\nOptimization (CNN+LO) and Convolutional Neural Network (CNN) without\noptimization. The simulation of the proposed method is done in the working\nplatform of MATLAB.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 05:56:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lalitha", "S. D.", ""], ["Thyagharajan", "K. K.", ""]]}, {"id": "2009.13798", "submitter": "Naoto Masuzawa", "authors": "Naoto Masuzawa, Yoshiro Kitamura, Keigo Nakamura, Satoshi Iizuka,\n  Edgar Simo-Serra", "title": "Automatic Segmentation, Localization, and Identification of Vertebrae in\n  3D CT Images Using Cascaded Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for automatic segmentation, localization, and\nidentification of vertebrae in arbitrary 3D CT images. Many previous works do\nnot perform the three tasks simultaneously even though requiring a priori\nknowledge of which part of the anatomy is visible in the 3D CT images. Our\nmethod tackles all these tasks in a single multi-stage framework without any\nassumptions. In the first stage, we train a 3D Fully Convolutional Networks to\nfind the bounding boxes of the cervical, thoracic, and lumbar vertebrae. In the\nsecond stage, we train an iterative 3D Fully Convolutional Networks to segment\nindividual vertebrae in the bounding box. The input to the second networks have\nan auxiliary channel in addition to the 3D CT images. Given the segmented\nvertebra regions in the auxiliary channel, the networks output the next\nvertebra. The proposed method is evaluated in terms of segmentation,\nlocalization, and identification accuracy with two public datasets of 15 3D CT\nimages from the MICCAI CSI 2014 workshop challenge and 302 3D CT images with\nvarious pathologies introduced in [1]. Our method achieved a mean Dice score of\n96%, a mean localization error of 8.3 mm, and a mean identification rate of\n84%. In summary, our method achieved better performance than all existing works\nin all the three metrics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 06:11:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Masuzawa", "Naoto", ""], ["Kitamura", "Yoshiro", ""], ["Nakamura", "Keigo", ""], ["Iizuka", "Satoshi", ""], ["Simo-Serra", "Edgar", ""]]}, {"id": "2009.13818", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, Weizhu Chen", "title": "A Simple but Tough-to-Beat Data Augmentation Approach for Natural\n  Language Understanding and Generation", "comments": "Source code is available at: https://github.com/dinghanshen/cutoff", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been shown effective at endowing the learned\nrepresentations with stronger generalization ability. However, it typically\nrequires expensive computation to determine the direction of the injected\nperturbations. In this paper, we introduce a set of simple yet effective data\naugmentation strategies dubbed cutoff, where part of the information within an\ninput sentence is erased to yield its restricted views (during the fine-tuning\nstage). Notably, this process relies merely on stochastic sampling and thus\nadds little computational overhead. A Jensen-Shannon Divergence consistency\nloss is further utilized to incorporate these augmented samples into the\ntraining objective in a principled manner. To verify the effectiveness of the\nproposed strategies, we apply cutoff to both natural language understanding and\ngeneration problems. On the GLUE benchmark, it is demonstrated that cutoff, in\nspite of its simplicity, performs on par or better than several competitive\nadversarial-based approaches. We further extend cutoff to machine translation\nand observe significant gains in BLEU scores (based upon the Transformer Base\nmodel). Moreover, cutoff consistently outperforms adversarial training and\nachieves state-of-the-art results on the IWSLT2014 German-English dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:08:35 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 03:19:58 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Shen", "Dinghan", ""], ["Zheng", "Mingzhi", ""], ["Shen", "Yelong", ""], ["Qu", "Yanru", ""], ["Chen", "Weizhu", ""]]}, {"id": "2009.13824", "submitter": "Laura Doerr", "authors": "Laura D\\\"orr, Felix Brandt, Martin Pouls, Alexander Naumann", "title": "An Image Processing Pipeline for Automated Packaging Structure\n  Recognition", "comments": "To be published in: \"Forum Bildverarbeitung 2020\", KIT Scientific\n  Publishing, Karlsruhe", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dispatching and receiving logistics goods, as well as transportation itself,\ninvolve a high amount of manual efforts. The transported goods, including their\npackaging and labeling, need to be double-checked, verified or recognized at\nmany supply chain network points. These processes hold automation potentials,\nwhich we aim to exploit using computer vision techniques. More precisely, we\npropose a cognitive system for the fully automated recognition of packaging\nstructures for standardized logistics shipments based on single RGB images. Our\ncontribution contains descriptions of a suitable system design and its\nevaluation on relevant real-world data. Further, we discuss our algorithmic\nchoices.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:26:08 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["D\u00f6rr", "Laura", ""], ["Brandt", "Felix", ""], ["Pouls", "Martin", ""], ["Naumann", "Alexander", ""]]}, {"id": "2009.13827", "submitter": "Jiaming Shen", "authors": "Jiaming Shen and Wenda Qiu and Jingbo Shang and Michelle Vanni and\n  Xiang Ren and Jiawei Han", "title": "SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and\n  Synonym Discovery", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity set expansion and synonym discovery are two critical NLP tasks.\nPrevious studies accomplish them separately, without exploring their\ninterdependencies. In this work, we hypothesize that these two tasks are\ntightly coupled because two synonymous entities tend to have similar\nlikelihoods of belonging to various semantic classes. This motivates us to\ndesign SynSetExpan, a novel framework that enables two tasks to mutually\nenhance each other. SynSetExpan uses a synonym discovery model to include\npopular entities' infrequent synonyms into the set, which boosts the set\nexpansion recall. Meanwhile, the set expansion model, being able to determine\nwhether an entity belongs to a semantic class, can generate pseudo training\ndata to fine-tune the synonym discovery model towards better accuracy. To\nfacilitate the research on studying the interplays of these two tasks, we\ncreate the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via\ncrowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks\ndemonstrate the effectiveness of SynSetExpan for both entity set expansion and\nsynonym discovery tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:32:17 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shen", "Jiaming", ""], ["Qiu", "Wenda", ""], ["Shang", "Jingbo", ""], ["Vanni", "Michelle", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "2009.13828", "submitter": "Katharina Eggensperger", "authors": "Katharina Eggensperger, Kai Haase, Philipp M\\\"uller, Marius Lindauer\n  and Frank Hutter", "title": "Neural Model-based Optimization with Right-Censored Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields of study, we only observe lower bounds on the true response\nvalue of some experiments. When fitting a regression model to predict the\ndistribution of the outcomes, we cannot simply drop these right-censored\nobservations, but need to properly model them. In this work, we focus on the\nconcept of censored data in the light of model-based optimization where\nprematurely terminating evaluations (and thus generating right-censored data)\nis a key factor for efficiency, e.g., when searching for an algorithm\nconfiguration that minimizes runtime of the algorithm at hand. Neural networks\n(NNs) have been demonstrated to work well at the core of model-based\noptimization procedures and here we extend them to handle these censored\nobservations. We propose (i)~a loss function based on the Tobit model to\nincorporate censored samples into training and (ii) use an ensemble of networks\nto model the posterior distribution. To nevertheless be efficient in terms of\noptimization-overhead, we propose to use Thompson sampling s.t. we only need to\ntrain a single NN in each iteration. Our experiments show that our trained\nregression models achieve a better predictive quality than several baselines\nand that our approach achieves new state-of-the-art performance for model-based\noptimization on two optimization problems: minimizing the solution time of a\nSAT solver and the time-to-accuracy of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:32:30 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Eggensperger", "Katharina", ""], ["Haase", "Kai", ""], ["M\u00fcller", "Philipp", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2009.13836", "submitter": "Abon Chaudhuri", "authors": "Theban Stanley, Nihar Vanjara, Yanxin Pan, Ekaterina Pirogova, Swagata\n  Chakraborty, Abon Chaudhuri", "title": "SIR: Similar Image Retrieval for Product Search in E-Commerce", "comments": "Accepted in 13th International Conference on Similarity Search and\n  Applications, SISAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a similar image retrieval (SIR) platform that is used to quickly\ndiscover visually similar products in a catalog of millions. Given the size,\ndiversity, and dynamism of our catalog, product search poses many challenges.\nIt can be addressed by building supervised models to tagging product images\nwith labels representing themes and later retrieving them by labels. This\napproach suffices for common and perennial themes like \"white shirt\" or\n\"lifestyle image of TV\". It does not work for new themes such as\n\"e-cigarettes\", hard-to-define ones such as \"image with a promotional badge\",\nor the ones with short relevance span such as \"Halloween costumes\". SIR is\nideal for such cases because it allows us to search by an example, not a\npre-defined theme. We describe the steps - embedding computation, encoding, and\nindexing - that power the approximate nearest neighbor search back-end. We also\nhighlight two applications of SIR. The first one is related to the detection of\nproducts with various types of potentially objectionable themes. This\napplication is run with a sense of urgency, hence the typical time frame to\ntrain and bootstrap a model is not permitted. Also, these themes are often\nshort-lived based on current trends, hence spending resources to build a\nlasting model is not justified. The second application is a variant item\ndetection system where SIR helps discover visual variants that are hard to find\nthrough text search. We analyze the performance of SIR in the context of these\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:53:03 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Stanley", "Theban", ""], ["Vanjara", "Nihar", ""], ["Pan", "Yanxin", ""], ["Pirogova", "Ekaterina", ""], ["Chakraborty", "Swagata", ""], ["Chaudhuri", "Abon", ""]]}, {"id": "2009.13839", "submitter": "Saurabh Gupta", "authors": "Saurabh Gupta, Arun Balaji Buduru, Ponnurangam Kumaraguru", "title": "imdpGAN: Generating Private and Specific Data with Generative\n  Adversarial Networks", "comments": "9 pages, 7 figures, Accepted at IEEE TPS'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Network (GAN) and its variants have shown promising\nresults in generating synthetic data. However, the issues with GANs are: (i)\nthe learning happens around the training samples and the model often ends up\nremembering them, consequently, compromising the privacy of individual samples\n- this becomes a major concern when GANs are applied to training data including\npersonally identifiable information, (ii) the randomness in generated data -\nthere is no control over the specificity of generated samples. To address these\nissues, we propose imdpGAN - an information maximizing differentially private\nGenerative Adversarial Network. It is an end-to-end framework that\nsimultaneously achieves privacy protection and learns latent representations.\nWith experiments on MNIST dataset, we show that imdpGAN preserves the privacy\nof the individual data point, and learns latent codes to control the\nspecificity of the generated samples. We perform binary classification on digit\npairs to show the utility versus privacy trade-off. The classification accuracy\ndecreases as we increase privacy levels in the framework. We also\nexperimentally show that the training process of imdpGAN is stable but\nexperience a 10-fold time increase as compared with other GAN frameworks.\nFinally, we extend imdpGAN framework to CelebA dataset to show how the privacy\nand learned representations can be used to control the specificity of the\noutput.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:03:32 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gupta", "Saurabh", ""], ["Buduru", "Arun Balaji", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "2009.13845", "submitter": "Xi Victoria Lin", "authors": "Tao Yu and Chien-Sheng Wu and Xi Victoria Lin and Bailin Wang and Yi\n  Chern Tan and Xinyi Yang and Dragomir Radev and Richard Socher and Caiming\n  Xiong", "title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "comments": "16 pages; Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraPPa, an effective pre-training approach for table semantic\nparsing that learns a compositional inductive bias in the joint representations\nof textual and tabular data. We construct synthetic question-SQL pairs over\nhigh-quality tables via a synchronous context-free grammar (SCFG) induced from\nexisting text-to-SQL datasets. We pre-train our model on the synthetic data\nusing a novel text-schema linking objective that predicts the syntactic role of\na table field in the SQL for each question-SQL pair. To maintain the model's\nability to represent real-world data, we also include masked language modeling\n(MLM) over several existing table-and-language datasets to regularize the\npre-training process. On four popular fully supervised and weakly supervised\ntable semantic parsing benchmarks, GraPPa significantly outperforms\nRoBERTa-large as the feature representation layers and establishes new\nstate-of-the-art results on all of them.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:17:58 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 01:30:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yu", "Tao", ""], ["Wu", "Chien-Sheng", ""], ["Lin", "Xi Victoria", ""], ["Wang", "Bailin", ""], ["Tan", "Yi Chern", ""], ["Yang", "Xinyi", ""], ["Radev", "Dragomir", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2009.13849", "submitter": "Jukka Riekki", "authors": "Jukka Riekki and Aarne M\\\"ammel\\\"a", "title": "Research and Education Towards Smart and Sustainable World", "comments": "22 pages, 5 figures. This replacement has been edited based on the\n  reviewers' comments. Table 1 and Figure 2 have been added, otherwise only\n  minor changes to correct typos and improve clarity", "journal-ref": "IEEE Access, vol. 9, pp. 53156-53177, 2021", "doi": "10.1109/ACCESS.2021.3069902", "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a vision for directing research and education in the ICT field.\nOur Smart and Sustainable World vision targets at prosperity for the people and\nthe planet through better awareness and control of both human-made and natural\nenvironment. The needs of the society, individuals, and industries are\nfulfilled with intelligent systems that sense their environment, make proactive\ndecisions on actions advancing their goals, and perform the actions on the\nenvironment. We emphasize artificial intelligence, feedback loops, human\nacceptance and control, intelligent use of basic resources, performance\nparameters, mission-oriented interdisciplinary research, and a holistic systems\nview complementing the conventional analytical reductive view as a research\nparadigm especially for complex problems. To serve a broad audience, we explain\nthese concepts and list the essential literature. We suggest planning research\nand education by specifying, in a step-wise manner, scenarios, performance\ncriteria, system models, research problems and education content, resulting in\ncommon goals and a coherent project portfolio as well as education curricula.\nResearch and education produce feedback to support evolutionary development and\nencourage creativity in research. Finally, we propose concrete actions for\nrealizing this approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:25:33 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 07:06:37 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Riekki", "Jukka", ""], ["M\u00e4mmel\u00e4", "Aarne", ""]]}, {"id": "2009.13854", "submitter": "Saurabh Gupta", "authors": "Saurabh Gupta, Siddhant Bhambri, Karan Dhingra, Arun Balaji Buduru,\n  Ponnurangam Kumaraguru", "title": "Multi-objective Reinforcement Learning based approach for User-Centric\n  Power Optimization in Smart Home Environments", "comments": "8 pages, 7 figures, Accepted at IEEE SMDS'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart homes require every device inside them to be connected with each other\nat all times, which leads to a lot of power wastage on a daily basis. As the\ndevices inside a smart home increase, it becomes difficult for the user to\ncontrol or operate every individual device optimally. Therefore, users\ngenerally rely on power management systems for such optimization but often are\nnot satisfied with the results. In this paper, we present a novel\nmulti-objective reinforcement learning framework with two-fold objectives of\nminimizing power consumption and maximizing user satisfaction. The framework\nexplores the trade-off between the two objectives and converges to a better\npower management policy when both objectives are considered while finding an\noptimal policy. We experiment on real-world smart home data, and show that the\nmulti-objective approaches: i) establish trade-off between the two objectives,\nii) achieve better combined user satisfaction and power consumption than\nsingle-objective approaches. We also show that the devices that are used\nregularly and have several fluctuations in device modes at regular intervals\nshould be targeted for optimization, and the experiments on data from other\nsmart homes fetch similar results, hence ensuring transfer-ability of the\nproposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:28:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Gupta", "Saurabh", ""], ["Bhambri", "Siddhant", ""], ["Dhingra", "Karan", ""], ["Buduru", "Arun Balaji", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "2009.13856", "submitter": "Maayan Shuvi", "authors": "Maayan Shuvi, Noa Fish, Kfir Aberman, Ariel Shamir, Daniel Cohen-Or", "title": "Neural Alignment for Face De-pixelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple method to reconstruct a high-resolution video from a\nface-video, where the identity of a person is obscured by pixelization. This\nconcealment method is popular because the viewer can still perceive a human\nface figure and the overall head motion. However, we show in our experiments\nthat a fairly good approximation of the original video can be reconstructed in\na way that compromises anonymity. Our system exploits the simultaneous\nsimilarity and small disparity between close-by video frames depicting a human\nface, and employs a spatial transformation component that learns the alignment\nbetween the pixelated frames. Each frame, supported by its aligned surrounding\nframes, is first encoded, then decoded to a higher resolution. Reconstruction\nand perceptual losses promote adherence to the ground-truth, and an adversarial\nloss assists in maintaining domain faithfulness. There is no need for explicit\ntemporal coherency loss as it is maintained implicitly by the alignment of\nneighboring frames and reconstruction. Although simple, our framework\nsynthesizes high-quality face reconstructions, demonstrating that given the\nstatistical prior of a human face, multiple aligned pixelated frames contain\nsufficient information to reconstruct a high-quality approximation of the\noriginal signal.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:29:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shuvi", "Maayan", ""], ["Fish", "Noa", ""], ["Aberman", "Kfir", ""], ["Shamir", "Ariel", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2009.13862", "submitter": "Jiuniu Wang", "authors": "Wenjia Xu, Jiuniu Wang, Yang Wang, Guangluan Xu, Wei Dai, Yirong Wu", "title": "Where is the Model Looking At?--Concentrate and Explain the Network\n  Attention", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, vol. 14, no.\n  3, pp. 506-516, March 2020", "doi": "10.1109/JSTSP.2020.2987729", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification models have achieved satisfactory performance on many\ndatasets, sometimes even better than human. However, The model attention is\nunclear since the lack of interpretability. This paper investigates the\nfidelity and interpretability of model attention. We propose an Explainable\nAttribute-based Multi-task (EAT) framework to concentrate the model attention\non the discriminative image area and make the attention interpretable. We\nintroduce attributes prediction to the multi-task learning network, helping the\nnetwork to concentrate attention on the foreground objects. We generate\nattribute-based textual explanations for the network and ground the attributes\non the image to show visual explanations. The multi-model explanation can not\nonly improve user trust but also help to find the weakness of network and\ndataset. Our framework can be generalized to any basic model. We perform\nexperiments on three datasets and five basic models. Results indicate that the\nEAT framework can give multi-modal explanations that interpret the network\ndecision. The performance of several recognition approaches is improved by\nguiding network attention.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:36:18 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Wenjia", ""], ["Wang", "Jiuniu", ""], ["Wang", "Yang", ""], ["Xu", "Guangluan", ""], ["Dai", "Wei", ""], ["Wu", "Yirong", ""]]}, {"id": "2009.13888", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh, Dan Jurafsky", "title": "Utility is in the Eye of the User: A Critique of NLP Leaderboards", "comments": "EMNLP 2020 (updated with additional references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarks such as GLUE have helped drive advances in NLP by incentivizing\nthe creation of more accurate models. While this leaderboard paradigm has been\nremarkably successful, a historical focus on performance-based evaluation has\nbeen at the expense of other qualities that the NLP community values in models,\nsuch as compactness, fairness, and energy efficiency. In this opinion paper, we\nstudy the divergence between what is incentivized by leaderboards and what is\nuseful in practice through the lens of microeconomic theory. We frame both the\nleaderboard and NLP practitioners as consumers and the benefit they get from a\nmodel as its utility to them. With this framing, we formalize how leaderboards\n-- in their current form -- can be poor proxies for the NLP community at large.\nFor example, a highly inefficient model would provide less utility to\npractitioners but not to a leaderboard, since it is a cost that only the former\nmust bear. To allow practitioners to better estimate a model's utility to them,\nwe advocate for more transparency on leaderboards, such as the reporting of\nstatistics that are of practical concern (e.g., model size, energy efficiency,\nand inference latency).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:25:31 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:04:29 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 00:40:13 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 06:22:32 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2009.13891", "submitter": "Haotian Fu", "authors": "Haotian Fu, Hongyao Tang, Jianye Hao, Chen Chen, Xidong Feng, Dong Li,\n  Wulong Liu", "title": "Towards Effective Context for Meta-Reinforcement Learning: an Approach\n  based on Contrastive Learning", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context, the embedding of previous collected trajectories, is a powerful\nconstruct for Meta-Reinforcement Learning (Meta-RL) algorithms. By conditioning\non an effective context, Meta-RL policies can easily generalize to new tasks\nwithin a few adaptation steps. We argue that improving the quality of context\ninvolves answering two questions: 1. How to train a compact and sufficient\nencoder that can embed the task-specific information contained in prior\ntrajectories? 2. How to collect informative trajectories of which the\ncorresponding context reflects the specification of tasks? To this end, we\npropose a novel Meta-RL framework called CCM (Contrastive learning augmented\nContext-based Meta-RL). We first focus on the contrastive nature behind\ndifferent tasks and leverage it to train a compact and sufficient context\nencoder. Further, we train a separate exploration policy and theoretically\nderive a new information-gain-based objective which aims to collect informative\ntrajectories in a few steps. Empirically, we evaluate our approaches on common\nbenchmarks as well as several complex sparse-reward environments. The\nexperimental results show that CCM outperforms state-of-the-art algorithms by\naddressing previously mentioned problems respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:29:18 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:10:03 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 08:48:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fu", "Haotian", ""], ["Tang", "Hongyao", ""], ["Hao", "Jianye", ""], ["Chen", "Chen", ""], ["Feng", "Xidong", ""], ["Li", "Dong", ""], ["Liu", "Wulong", ""]]}, {"id": "2009.13895", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "Ben Day, C\\u{a}t\\u{a}lina Cangea, Arian R. Jamasb, Pietro Li\\`o", "title": "Message Passing Neural Processes", "comments": "18 pages, 6 figures. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Processes (NPs) are powerful and flexible models able to incorporate\nuncertainty when representing stochastic processes, while maintaining a linear\ntime complexity. However, NPs produce a latent description by aggregating\nindependent representations of context points and lack the ability to exploit\nrelational information present in many datasets. This renders NPs ineffective\nin settings where the stochastic process is primarily governed by neighbourhood\nrules, such as cellular automata (CA), and limits performance for any task\nwhere relational information remains unused. We address this shortcoming by\nintroducing Message Passing Neural Processes (MPNPs), the first class of NPs\nthat explicitly makes use of relational structure within the model. Our\nevaluation shows that MPNPs thrive at lower sampling rates, on existing\nbenchmarks and newly-proposed CA and Cora-Branched tasks. We further report\nstrong generalisation over density-based CA rule-sets and significant gains in\nchallenging arbitrary-labelling and few-shot learning setups.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:40:09 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Day", "Ben", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Jamasb", "Arian R.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2009.13922", "submitter": "Syed Muhammad Asad Zaidi", "authors": "Syed Muhammad Asad Zaidi, Marvin Manalastas, Hasan Farooq and Ali\n  Imran", "title": "Mobility Management in Emerging Ultra-Dense Cellular Networks: A Survey,\n  Outlook, and Future Research Directions", "comments": "in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3027258", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential rise in mobile traffic originating from mobile devices\nhighlights the need for making mobility management in future networks even more\nefficient and seamless than ever before. Ultra-Dense Cellular Network vision\nconsisting of cells of varying sizes with conventional and mmWave bands is\nbeing perceived as the panacea for the eminent capacity crunch. However,\nmobility challenges in an ultra-dense heterogeneous network with motley of high\nfrequency and mmWave band cells will be unprecedented due to plurality of\nhandover instances, and the resulting signaling overhead and data interruptions\nfor miscellany of devices. Similarly, issues like user tracking and cell\ndiscovery for mmWave with narrow beams need to be addressed before the\nambitious gains of emerging mobile networks can be realized. Mobility\nchallenges are further highlighted when considering the 5G deliverables of\nmulti-Gbps wireless connectivity, <1ms latency and support for devices moving\nat maximum speed of 500km/h, to name a few. Despite its significance, few\nmobility surveys exist with the majority focused on adhoc networks. This paper\nis the first to provide a comprehensive survey on the panorama of mobility\nchallenges in the emerging ultra-dense mobile networks. We not only present a\ndetailed tutorial on 5G mobility approaches and highlight key mobility risks of\nlegacy networks, but also review key findings from recent studies and highlight\nthe technical challenges and potential opportunities related to mobility from\nthe perspective of emerging ultra-dense cellular networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 10:42:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zaidi", "Syed Muhammad Asad", ""], ["Manalastas", "Marvin", ""], ["Farooq", "Hasan", ""], ["Imran", "Ali", ""]]}, {"id": "2009.13931", "submitter": "Yanhong Leng", "authors": "Xinquan Zhou, Yanhong Leng", "title": "Residual acoustic echo suppression based on efficient multi-task\n  convolutional neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic echo degrades the user experience in voice communication systems\nthus needs to be suppressed completely. We propose a real-time residual\nacoustic echo suppression (RAES) method using an efficient convolutional neural\nnetwork. The double talk detector is used as an auxiliary task to improve the\nperformance of RAES in the context of multi-task learning. The training\ncriterion is based on a novel loss function, which we call as the suppression\nloss, to balance the suppression of residual echo and the distortion of\nnear-end signals. The experimental results show that the proposed method can\nefficiently suppress the residual echo under different circumstances.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:26:25 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 03:33:36 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zhou", "Xinquan", ""], ["Leng", "Yanhong", ""]]}, {"id": "2009.13939", "submitter": "Diogo Pernes", "authors": "Diogo Pernes and Jaime S. Cardoso", "title": "Tackling unsupervised multi-source domain adaptation with optimism and\n  consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been known for a while that the problem of multi-source domain\nadaptation can be regarded as a single source domain adaptation task where the\nsource domain corresponds to a mixture of the original source domains.\nNonetheless, how to adjust the mixture distribution weights remains an open\nquestion. Moreover, most existing work on this topic focuses only on minimizing\nthe error on the source domains and achieving domain-invariant representations,\nwhich is insufficient to ensure low error on the target domain. In this work,\nwe present a novel framework that addresses both problems and beats the current\nstate of the art by using a mildly optimistic objective function and\nconsistency regularization on the target samples.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 11:55:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Pernes", "Diogo", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "2009.13953", "submitter": "Shivaank Agarwal", "authors": "Shivaank Agarwal, Ravindra Gudi, Paresh Saxena", "title": "One-Shot learning based classification for segregation of plastic waste", "comments": "Accepted in The International Conference on Digital Image Computing:\n  Techniques and Applications, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of segregating recyclable waste is fairly daunting for many\ncountries. This article presents an approach for image based classification of\nplastic waste using one-shot learning techniques. The proposed approach\nexploits discriminative features generated via the siamese and triplet loss\nconvolutional neural networks to help differentiate between 5 types of plastic\nwaste based on their resin codes. The approach achieves an accuracy of 99.74%\non the WaDaBa Database\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:16:50 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Agarwal", "Shivaank", ""], ["Gudi", "Ravindra", ""], ["Saxena", "Paresh", ""]]}, {"id": "2009.13954", "submitter": "Shixian Wen", "authors": "Shixian Wen, Amanda Rios, Yunhao Ge, Laurent Itti", "title": "Beneficial Perturbation Network for designing general adaptive\n  artificial intelligence systems", "comments": "Accepted at IEEE Transactions on Neural Networks and Learning Systems\n  Keyword: Adaptive artificial intelligence system , Switch modes , Beneficial\n  perturbations , Continual learning , Adversarial examples", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems 2021", "doi": "10.1109/TNNLS.2021.3054423", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is the gold standard of adaptive learning. It not only can\nlearn and benefit from experience, but also can adapt to new situations. In\ncontrast, deep neural networks only learn one sophisticated but fixed mapping\nfrom inputs to outputs. This limits their applicability to more dynamic\nsituations, where input to output mapping may change with different contexts. A\nsalient example is continual learning - learning new independent tasks\nsequentially without forgetting previous tasks. Continual learning of multiple\ntasks in artificial neural networks using gradient descent leads to\ncatastrophic forgetting, whereby a previously learned mapping of an old task is\nerased when learning new mappings for new tasks. Here, we propose a new\nbiologically plausible type of deep neural network with extra, out-of-network,\ntask-dependent biasing units to accommodate these dynamic situations. This\nallows, for the first time, a single network to learn potentially unlimited\nparallel input to output mappings, and to switch on the fly between them at\nruntime. Biasing units are programmed by leveraging beneficial perturbations\n(opposite to well-known adversarial perturbations) for each task. Beneficial\nperturbations for a given task bias the network toward that task, essentially\nswitching the network into a different mode to process that task. This largely\neliminates catastrophic interference between tasks. Our approach is\nmemory-efficient and parameter-efficient, can accommodate many tasks, and\nachieves state-of-the-art performance across different tasks and domains.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 01:28:10 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 02:12:37 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wen", "Shixian", ""], ["Rios", "Amanda", ""], ["Ge", "Yunhao", ""], ["Itti", "Laurent", ""]]}, {"id": "2009.13964", "submitter": "Yusheng Su", "authors": "Yusheng Su, Xu Han, Zhengyan Zhang, Peng Li, Zhiyuan Liu, Yankai Lin,\n  Jie Zhou and Maosong Sun", "title": "CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced\n  Pre-Trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent efforts have been devoted to enhancing pre-trained language\nmodels (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs\n(KGs) and achieved consistent improvements on various knowledge-driven NLP\ntasks. However, most of these knowledge-enhanced PLMs embed static sub-graphs\nof KGs (\"knowledge context\"), regardless of that the knowledge required by PLMs\nmay change dynamically according to specific text (\"textual context\"). In this\npaper, we propose a novel framework named Coke to dynamically select contextual\nknowledge and embed knowledge context according to textual context for PLMs,\nwhich can avoid the effect of redundant and ambiguous knowledge in KGs that\ncannot match the input text. Our experimental results show that Coke\noutperforms various baselines on typical knowledge-driven NLP tasks, indicating\nthe effectiveness of utilizing dynamic knowledge context for language\nunderstanding. Besides the performance improvements, the dynamically selected\nknowledge in Coke can describe the semantics of text-related knowledge in a\nmore interpretable form than the conventional PLMs. Our source code and\ndatasets will be available to provide more details for Coke.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:29:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:31:29 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 09:04:48 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 15:25:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Su", "Yusheng", ""], ["Han", "Xu", ""], ["Zhang", "Zhengyan", ""], ["Li", "Peng", ""], ["Liu", "Zhiyuan", ""], ["Lin", "Yankai", ""], ["Zhou", "Jie", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.13984", "submitter": "Raymond Lee", "authors": "Nuobei Shi, Qin Zeng and Raymond Lee", "title": "The design and implementation of Language Learning Chatbot with XAI\n  using Ontology and Transfer Learning", "comments": "19 pages, 20 figures, published paper in International Conference on\n  NLP & Big Data (NLPD 2020)", "journal-ref": "Dhinaharan Nagamalai et al. (Eds): CSEIT, WiMoNe, NCS, CIoT, CMLA,\n  DMSE, NLPD - 2020 pp. 305-323, 2020. CS & IT - CSCP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a transfer learning-based English language\nlearning chatbot, whose output generated by GPT-2 can be explained by\ncorresponding ontology graph rooted by fine-tuning dataset. We design three\nlevels for systematically English learning, including phonetics level for\nspeech recognition and pronunciation correction, semantic level for specific\ndomain conversation, and the simulation of free-style conversation in English -\nthe highest level of language chatbot communication as free-style conversation\nagent. For academic contribution, we implement the ontology graph to explain\nthe performance of free-style conversation, following the concept of XAI\n(Explainable Artificial Intelligence) to visualize the connections of neural\nnetwork in bionics, and explain the output sentence from language model. From\nimplementation perspective, our Language Learning agent integrated the\nmini-program in WeChat as front-end, and fine-tuned GPT-2 model of transfer\nlearning as back-end to interpret the responses by ontology graph.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:11:40 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shi", "Nuobei", ""], ["Zeng", "Qin", ""], ["Lee", "Raymond", ""]]}, {"id": "2009.13996", "submitter": "Kary Fr\\\"amling", "authors": "Kary Fr\\\"amling", "title": "Explainable AI without Interpretable Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability has been a challenge in AI for as long as AI has existed. With\nthe recently increased use of AI in society, it has become more important than\never that AI systems would be able to explain the reasoning behind their\nresults also to end-users in situations such as being eliminated from a\nrecruitment process or having a bank loan application refused by an AI system.\nEspecially if the AI system has been trained using Machine Learning, it tends\nto contain too many parameters for them to be analysed and understood, which\nhas caused them to be called `black-box' systems. Most Explainable AI (XAI)\nmethods are based on extracting an interpretable model that can be used for\nproducing explanations. However, the interpretable model does not necessarily\nmap accurately to the original black-box model. Furthermore, the\nunderstandability of interpretable models for an end-user remains questionable.\nThe notions of Contextual Importance and Utility (CIU) presented in this paper\nmake it possible to produce human-like explanations of black-box outcomes\ndirectly, without creating an interpretable model. Therefore, CIU explanations\nmap accurately to the black-box model itself. CIU is completely model-agnostic\nand can be used with any black-box system. In addition to feature importance,\nthe utility concept that is well-known in Decision Theory provides a new\ndimension to explanations compared to most existing XAI methods. Finally, CIU\ncan produce explanations at any level of abstraction and using different\nvocabularies and other means of interaction, which makes it possible to adjust\nexplanations and interaction according to the context and to the target users.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:29:44 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Fr\u00e4mling", "Kary", ""]]}, {"id": "2009.14050", "submitter": "Thomas Griffiths", "authors": "Thomas L. Griffiths", "title": "Understanding Human Intelligence through Human Limitations", "comments": "In press at Trends in Cognitive Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence provides the opportunity to ask\nthe question of what is unique about human intelligence, but with a new\ncomparison class. I argue that we can understand human intelligence, and the\nways in which it may differ from artificial intelligence, by considering the\ncharacteristics of the kind of computational problems that human minds have to\nsolve. I claim that these problems acquire their structure from three\nfundamental limitations that apply to human beings: limited time, limited\ncomputation, and limited communication. From these limitations we can derive\nmany of the properties we associate with human intelligence, such as rapid\nlearning, the ability to break down problems into parts, and the capacity for\ncumulative cultural evolution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 14:37:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Griffiths", "Thomas L.", ""]]}, {"id": "2009.14108", "submitter": "Markus Hofmarcher", "authors": "Vihang P. Patil, Markus Hofmarcher, Marius-Constantin Dinu, Matthias\n  Dorfer, Patrick M. Blies, Johannes Brandstetter, Jose A. Arjona-Medina, Sepp\n  Hochreiter", "title": "Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms require a large number of samples to solve\ncomplex tasks with sparse and delayed rewards. Complex tasks can often be\nhierarchically decomposed into sub-tasks. A step in the Q-function can be\nassociated with solving a sub-task, where the expectation of the return\nincreases. RUDDER has been introduced to identify these steps and then\nredistribute reward to them, thus immediately giving reward if sub-tasks are\nsolved. Since the problem of delayed rewards is mitigated, learning is\nconsiderably sped up. However, for complex tasks, current exploration\nstrategies as deployed in RUDDER struggle with discovering episodes with high\nrewards. Therefore, we assume that episodes with high rewards are given as\ndemonstrations and do not have to be discovered by exploration. Typically the\nnumber of demonstrations is small and RUDDER's LSTM model as a deep learning\nmethod does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER\nwith two major modifications. First, Align-RUDDER assumes that episodes with\nhigh rewards are given as demonstrations, replacing RUDDER's safe exploration\nand lessons replay buffer. Second, we replace RUDDER's LSTM model by a profile\nmodel that is obtained from multiple sequence alignment of demonstrations.\nProfile models can be constructed from as few as two demonstrations as known\nfrom bioinformatics. Align-RUDDER inherits the concept of reward\nredistribution, which considerably reduces the delay of rewards, thus speeding\nup learning. Align-RUDDER outperforms competitors on complex artificial tasks\nwith delayed reward and few demonstrations. On the MineCraft ObtainDiamond\ntask, Align-RUDDER is able to mine a diamond, though not frequently. Github:\nhttps://github.com/ml-jku/align-rudder, YouTube: https://youtu.be/HO-_8ZUl-UY\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:48:02 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Patil", "Vihang P.", ""], ["Hofmarcher", "Markus", ""], ["Dinu", "Marius-Constantin", ""], ["Dorfer", "Matthias", ""], ["Blies", "Patrick M.", ""], ["Brandstetter", "Johannes", ""], ["Arjona-Medina", "Jose A.", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2009.14187", "submitter": "Tobias Jacobs", "authors": "Luka Stopar, Luka Bradesko, Tobias Jacobs, Azur Kurba\\v{s}i\\'c, Miha\n  Cimperman", "title": "Large-Scale Cargo Distribution", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on the design and development of methods for generating\ncargo distribution plans for large-scale logistics networks. It uses data from\nthree large logistics operators while focusing on cross border logistics\noperations using one large graph.\n  The approach uses a three-step methodology to first represent the logistic\ninfrastructure as a graph, then partition the graph into smaller size regions,\nand finally generate cargo distribution plans for each individual region. The\ninitial graph representation has been extracted from regional graphs by\nspectral clustering and is then further used for computing the distribution\nplan.\n  The approach introduces methods for each of the modelling steps. The proposed\napproach on using regionalization of large logistics infrastructure for\ngenerating partial plans, enables scaling to thousands of drop-off locations.\nResults also show that the proposed approach scales better than the\nstate-of-the-art, while preserving the quality of the solution.\n  Our methodology is suited to address the main challenge in transforming rigid\nlarge logistics infrastructure into dynamic, just-in-time, and point-to-point\ndelivery-oriented logistics operations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:55:43 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Stopar", "Luka", ""], ["Bradesko", "Luka", ""], ["Jacobs", "Tobias", ""], ["Kurba\u0161i\u0107", "Azur", ""], ["Cimperman", "Miha", ""]]}, {"id": "2009.14192", "submitter": "Fl\\'avio Bernardini", "authors": "Flavio Amadeu Bernardini, Marcia Terra da Silva, Jair Minoro Abe, Luiz\n  Antonio de Lima and Kanstantsin Miatluk", "title": "Analysis of the displacement of terrestrial mobile robots in corridors\n  using paraconsistent annotated evidential logic e{\\tau}", "comments": null, "journal-ref": null, "doi": "10.5121/csit.2020.101115", "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes an algorithm for a servo motor that controls the\nmovement of an autonomous terrestrial mobile robot using Paraconsistent Logic.\nThe design process of mechatronic systems guided the robot construction phases.\nThe project intends to monitor the robot through its sensors that send\npositioning signals to the microcontroller. The signals are adjusted by an\nembedded technology interface maintained in the concepts of Paraconsistent\nAnnotated Logic acting directly on the servo steering motor. The electric\nsignals sent to the servo motor were analyzed, and it indicates that the\nalgorithm paraconsistent can contribute to the increase of precision of\nmovements of servo motors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:57:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Bernardini", "Flavio Amadeu", ""], ["da Silva", "Marcia Terra", ""], ["Abe", "Jair Minoro", ""], ["de Lima", "Luiz Antonio", ""], ["Miatluk", "Kanstantsin", ""]]}, {"id": "2009.14237", "submitter": "Andrew Head", "authors": "Andrew Head (UC Berkeley), Kyle Lo (Allen Institute for AI), Dongyeop\n  Kang (UC Berkeley), Raymond Fok (University of Washington), Sam Skjonsberg\n  (Allen Institute for AI), Daniel S. Weld (Allen Institute for AI, University\n  of Washington), Marti A. Hearst (UC Berkeley)", "title": "Augmenting Scientific Papers with Just-in-Time, Position-Sensitive\n  Definitions of Terms and Symbols", "comments": "18 pages, 17 figures, 2 tables. To appear at the 2021 ACM CHI\n  Conference on Human Factors in Computing Systems. For associated video, see\n  https://youtu.be/yYcQf-Yq8B0. v2 changes: expanded discussion of design\n  process and implementation; improved figure design. v3 changes: fixed typo in\n  cell of Table 2; updated HEDDEx and Schwarz-Hearst accuracy in Section 5.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite the central importance of research papers to scientific progress,\nthey can be difficult to read. Comprehension is often stymied when the\ninformation needed to understand a passage resides somewhere else: in another\nsection, or in another paper. In this work, we envision how interfaces can\nbring definitions of technical terms and symbols to readers when and where they\nneed them most. We introduce ScholarPhi, an augmented reading interface with\nfour novel features: (1) tooltips that surface position-sensitive definitions\nfrom elsewhere in a paper, (2) a filter over the paper that \"declutters\" it to\nreveal how the term or symbol is used across the paper, (3) automatic equation\ndiagrams that expose multiple definitions in parallel, and (4) an automatically\ngenerated glossary of important terms and symbols. A usability study showed\nthat the tool helps researchers of all experience levels read papers.\nFurthermore, researchers were eager to have ScholarPhi's definitions available\nto support their everyday reading.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:11:19 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:05:59 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 18:32:46 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Head", "Andrew", "", "UC Berkeley"], ["Lo", "Kyle", "", "Allen Institute for AI"], ["Kang", "Dongyeop", "", "UC Berkeley"], ["Fok", "Raymond", "", "University of Washington"], ["Skjonsberg", "Sam", "", "Allen Institute for AI"], ["Weld", "Daniel S.", "", "Allen Institute for AI, University\n  of Washington"], ["Hearst", "Marti A.", "", "UC Berkeley"]]}, {"id": "2009.14297", "submitter": "Xing Wang", "authors": "Xing Wang, Alexander Vinel", "title": "Reannealing of Decaying Exploration Based On Heuristic Measure in Deep\n  Q-Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing exploration strategies in reinforcement learning (RL) often either\nignore the history or feedback of search, or are complicated to implement.\nThere is also a very limited literature showing their effectiveness over\ndiverse domains. We propose an algorithm based on the idea of reannealing, that\naims at encouraging exploration only when it is needed, for example, when the\nalgorithm detects that the agent is stuck in a local optimum. The approach is\nsimple to implement. We perform an illustrative case study showing that it has\npotential to both accelerate training and obtain a better policy.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 20:40:00 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Xing", ""], ["Vinel", "Alexander", ""]]}, {"id": "2009.14365", "submitter": "Mojtaba Mozaffar", "authors": "Mojtaba Mozaffar, Ablodghani Ebrahimi, Jian Cao", "title": "Toolpath design for additive manufacturing using deep reinforcement\n  learning", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toolpath optimization of metal-based additive manufacturing processes is\ncurrently hampered by the high-dimensionality of its design space. In this\nwork, a reinforcement learning platform is proposed that dynamically learns\ntoolpath strategies to build an arbitrary part. To this end, three prominent\nmodel-free reinforcement learning formulations are investigated to design\nadditive manufacturing toolpaths and demonstrated for two cases of dense and\nsparse reward structures. The results indicate that this learning-based\ntoolpath design approach achieves high scores, especially when a dense reward\nstructure is present.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:03:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mozaffar", "Mojtaba", ""], ["Ebrahimi", "Ablodghani", ""], ["Cao", "Jian", ""]]}, {"id": "2009.14409", "submitter": "Seongmin Lee", "authors": "Hyun Dong Lee, Seongmin Lee and U Kang", "title": "AUBER: Automated BERT Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we effectively regularize BERT? Although BERT proves its\neffectiveness in various downstream natural language processing tasks, it often\noverfits when there are only a small number of training instances. A promising\ndirection to regularize BERT is based on pruning its attention heads based on a\nproxy score for head importance. However, heuristic-based methods are usually\nsuboptimal since they predetermine the order by which attention heads are\npruned. In order to overcome such a limitation, we propose AUBER, an effective\nregularization method that leverages reinforcement learning to automatically\nprune attention heads from BERT. Instead of depending on heuristics or\nrule-based policies, AUBER learns a pruning policy that determines which\nattention heads should or should not be pruned for regularization. Experimental\nresults show that AUBER outperforms existing pruning methods by achieving up to\n10% better accuracy. In addition, our ablation study empirically demonstrates\nthe effectiveness of our design choices for AUBER.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 03:32:55 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Lee", "Hyun Dong", ""], ["Lee", "Seongmin", ""], ["Kang", "U", ""]]}, {"id": "2009.14441", "submitter": "Shay Deutsch Dr.", "authors": "Shay Deutsch, Stefano Soatto", "title": "Spectral Embedding of Graph Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an unsupervised graph embedding that trades off local node\nsimilarity and connectivity, and global structure. The embedding is based on a\ngeneralized graph Laplacian, whose eigenvectors compactly capture both network\nstructure and neighborhood proximity in a single representation. The key idea\nis to transform the given graph into one whose weights measure the centrality\nof an edge by the fraction of the number of shortest paths that pass through\nthat edge, and employ its spectral proprieties in the representation. Testing\nthe resulting graph network representation shows significant improvement over\nthe sate of the art in data analysis tasks including social networks and\nmaterial science. We also test our method on node classification from the\nhuman-SARS CoV-2 protein-protein interactome.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 04:59:10 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Deutsch", "Shay", ""], ["Soatto", "Stefano", ""]]}, {"id": "2009.14452", "submitter": "Marco Pegoraro", "authors": "Marco Pegoraro, Merih Seran Uysal, Wil M.P. van der Aalst", "title": "Conformance Checking over Uncertain Event Data", "comments": "41 pages, 11 figures, 9 tables. arXiv admin note: substantial text\n  overlap with arXiv:1910.00089", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The strong impulse to digitize processes and operations in companies and\nenterprises have resulted in the creation and automatic recording of an\nincreasingly large amount of process data in information systems. These are\nmade available in the form of event logs. Process mining techniques enable the\nprocess-centric analysis of data, including automatically discovering process\nmodels and checking if event data conform to a given model. In this paper, we\nanalyze the previously unexplored setting of uncertain event logs. In such\nevent logs uncertainty is recorded explicitly, i.e., the time, activity and\ncase of an event may be unclear or imprecise. In this work, we define a\ntaxonomy of uncertain event logs and models, and we examine the challenges that\nuncertainty poses on process discovery and conformance checking. Finally, we\nshow how upper and lower bounds for conformance can be obtained by aligning an\nuncertain trace onto a regular process model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 14:27:30 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 10:33:21 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Pegoraro", "Marco", ""], ["Uysal", "Merih Seran", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "2009.14457", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Shashank Mujumdar, Hima Patel", "title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework\n  for Document Representation Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-task learning-based framework that utilizes\na combination of self-supervised and supervised pre-training tasks to learn a\ngeneric document representation. We design the network architecture and the\npre-training tasks to incorporate the multi-modal document information across\ntext, layout, and image dimensions and allow the network to work with\nmulti-page documents. We showcase the applicability of our pre-training\nframework on a variety of different real-world document tasks such as document\nclassification, document information extraction, and document retrieval. We\nconduct exhaustive experiments to compare performance against different\nablations of our framework and state-of-the-art baselines. We discuss the\ncurrent limitations and next steps for our work.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:39:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Mujumdar", "Shashank", ""], ["Patel", "Hima", ""]]}, {"id": "2009.14477", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Esther Villar-Rodriguez, Javier Del Ser", "title": "A Coevolutionary Variable Neighborhood Search Algorithm for Discrete\n  Multitasking (CoVNS): Application to Community Detection over Graphs", "comments": "7 pages, paper accepted for presentation in the 2020 IEEE Symposium\n  Series on Computational Intelligence (IEEE SSCI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of the multitasking optimization paradigm is to solve multiple\nand concurrent optimization tasks in a simultaneous way through a single search\nprocess. For attaining promising results, potential complementarities and\nsynergies between tasks are properly exploited, helping each other by virtue of\nthe exchange of genetic material. This paper is focused on Evolutionary\nMultitasking, which is a perspective for dealing with multitasking optimization\nscenarios by embracing concepts from Evolutionary Computation. This work\ncontributes to this field by presenting a new multitasking approach named as\nCoevolutionary Variable Neighborhood Search Algorithm, which finds its\ninspiration on both the Variable Neighborhood Search metaheuristic and\ncoevolutionary strategies. The second contribution of this paper is the\napplication field, which is the optimal partitioning of graph instances whose\nconnections among nodes are directed and weighted. This paper pioneers on the\nsimultaneous solving of this kind of tasks. Two different multitasking\nscenarios are considered, each comprising 11 graph instances. Results obtained\nby our method are compared to those issued by a parallel Variable Neighborhood\nSearch and independent executions of the basic Variable Neighborhood Search.\nThe discussion on such results support our hypothesis that the proposed method\nis a promising scheme for simultaneous solving community detection problems\nover graphs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 07:26:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Osaba", "Eneko", ""], ["Villar-Rodriguez", "Esther", ""], ["Del Ser", "Javier", ""]]}, {"id": "2009.14505", "submitter": "Somak Aditya", "authors": "Pratik Joshi, Somak Aditya, Aalok Sathe, Monojit Choudhury", "title": "TaxiNLI: Taking a Ride up the NLU Hill", "comments": "15 pages, 9 figures, 4 tables. Accepted at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-trained Transformer-based neural architectures have consistently achieved\nstate-of-the-art performance in the Natural Language Inference (NLI) task.\nSince NLI examples encompass a variety of linguistic, logical, and reasoning\nphenomena, it remains unclear as to which specific concepts are learnt by the\ntrained systems and where they can achieve strong generalization. To\ninvestigate this question, we propose a taxonomic hierarchy of categories that\nare relevant for the NLI task. We introduce TAXINLI, a new dataset, that has\n10k examples from the MNLI dataset (Williams et al., 2018) with these taxonomic\nlabels. Through various experiments on TAXINLI, we observe that whereas for\ncertain taxonomic categories SOTA neural models have achieved near perfect\naccuracies - a large jump over the previous models - some categories still\nremain difficult. Our work adds to the growing body of literature that shows\nthe gaps in the current NLI systems and datasets through a systematic\npresentation and analysis of reasoning categories.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:45:25 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 04:28:04 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 11:07:49 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Joshi", "Pratik", ""], ["Aditya", "Somak", ""], ["Sathe", "Aalok", ""], ["Choudhury", "Monojit", ""]]}, {"id": "2009.14519", "submitter": "Narjes Torabi", "authors": "Narjes Torabi, Nimar S. Arora, Emma Yu, Kinjal Shah, Wenshun Liu,\n  Michael Tingley", "title": "Uncertainty Estimation For Community Standards Violation In Online\n  Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Networks (OSNs) provide a platform for users to share their\nthoughts and opinions with their community of friends or to the general public.\nIn order to keep the platform safe for all users, as well as to keep it\ncompliant with local laws, OSNs typically create a set of community standards\norganized into policy groups, and use Machine Learning (ML) models to identify\nand remove content that violates any of the policies. However, out of the\nbillions of content that is uploaded on a daily basis only a small fraction is\nso unambiguously violating that it can be removed by the automated models.\nPrevalence estimation is the task of estimating the fraction of violating\ncontent in the residual items by sending a small sample of these items to human\nlabelers to get ground truth labels. This task is exceedingly hard because even\nthough we can easily get the ML scores or features for all of the billions of\nitems we can only get ground truth labels on a few thousands of these items due\nto practical considerations. Indeed the prevalence can be so low that even\nafter a judicious choice of items to be labeled there can be many days in which\nnot even a single item is labeled violating. A pragmatic choice for such low\nprevalence, $10^{-4}$ to $10^{-5}$, regimes is to report the upper bound, or\n$97.5\\%$ confidence interval, prevalence (UBP) that takes the uncertainties of\nthe sampling and labeling processes into account and gives a smoothed estimate.\nIn this work we present two novel techniques Bucketed-Beta-Binomial and a\nBucketed-Gaussian Process for this UBP task and demonstrate on real and\nsimulated data that it has much better coverage than the commonly used\nbootstrapping technique.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:10:22 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Torabi", "Narjes", ""], ["Arora", "Nimar S.", ""], ["Yu", "Emma", ""], ["Shah", "Kinjal", ""], ["Liu", "Wenshun", ""], ["Tingley", "Michael", ""]]}, {"id": "2009.14521", "submitter": "David Milec", "authors": "David Milec, Jakub \\v{C}ern\\'y, Viliam Lis\\'y, Bo An", "title": "Complexity and Algorithms for Exploiting Quantal Opponents in Large\n  Two-Player Games", "comments": "15 pages, 11 figures, submitted to AAAI 2021", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  35(6), 5575-5583 (2021)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solution concepts of traditional game theory assume entirely rational\nplayers; therefore, their ability to exploit subrational opponents is limited.\nOne type of subrationality that describes human behavior well is the quantal\nresponse. While there exist algorithms for computing solutions against quantal\nopponents, they either do not scale or may provide strategies that are even\nworse than the entirely-rational Nash strategies. This paper aims to analyze\nand propose scalable algorithms for computing effective and robust strategies\nagainst a quantal opponent in normal-form and extensive-form games. Our\ncontributions are: (1) we define two different solution concepts related to\nexploiting quantal opponents and analyze their properties; (2) we prove that\ncomputing these solutions is computationally hard; (3) therefore, we evaluate\nseveral heuristic approximations based on scalable counterfactual regret\nminimization (CFR); and (4) we identify a CFR variant that exploits the bounded\nopponents better than the previously used variants while being less exploitable\nby the worst-case perfectly-rational opponent.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:14:56 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 12:11:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Milec", "David", ""], ["\u010cern\u00fd", "Jakub", ""], ["Lis\u00fd", "Viliam", ""], ["An", "Bo", ""]]}, {"id": "2009.14525", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Edward Curry", "title": "Visual Semantic Multimedia Event Model for Complex Event Detection in\n  Video Streams", "comments": "15 pages, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimedia data is highly expressive and has traditionally been very\ndifficult for a machine to interpret. Middleware systems such as complex event\nprocessing (CEP) mine patterns from data streams and send notifications to\nusers in a timely fashion. Presently, CEP systems have inherent limitations to\nprocess multimedia streams due to its data complexity and the lack of an\nunderlying structured data model. In this work, we present a visual event\nspecification method to enable complex multimedia event processing by creating\na semantic knowledge representation derived from low-level media streams. The\nmethod enables the detection of high-level semantic concepts from the media\nstreams using an ensemble of pattern detection capabilities. The semantic model\nis aligned with a multimedia CEP engine deep learning models to give\nflexibility to end-users to build rules using spatiotemporal event calculus.\nThis enhances CEP capability to detect patterns from media streams and bridge\nthe semantic gap between highly expressive knowledge-centric user queries to\nthe low-level features of the multi-media data. We have built a small traffic\nevent ontology prototype to validate the approach and performance. The paper\ncontribution is threefold: i) we present a knowledge graph representation for\nmultimedia streams, ii) a hierarchical event network to detect visual patterns\nfrom media streams and iii) define complex pattern rules for complex multimedia\nevent reasoning using event calculus\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:22:23 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Yadav", "Piyush", ""], ["Curry", "Edward", ""]]}, {"id": "2009.14539", "submitter": "Marco Valentino", "authors": "Marco Valentino, Mokanarangan Thayaparan, Andr\\'e Freitas", "title": "Explainable Natural Language Reasoning via Conceptual Unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an abductive framework for multi-hop and interpretable\ntextual inference. The reasoning process is guided by the notions unification\npower and plausibility of an explanation, computed through the interaction of\ntwo major architectural components: (a) An analogical reasoning model that\nranks explanatory facts by leveraging unification patterns in a corpus of\nexplanations; (b) An abductive reasoning model that performs a search for the\nbest explanation, which is realised via conceptual abstraction and subsequent\nunification. We demonstrate that the Step-wise Conceptual Unification can be\neffective for unsupervised question answering, and as an explanation extractor\nin combination with state-of-the-art Transformers. An empirical evaluation on\nthe Worldtree corpus and the ARC Challenge resulted in the following\nconclusions: (1) The question answering model outperforms competitive neural\nand multi-hop baselines without requiring any explicit training on answer\nprediction; (2) When used as an explanation extractor, the proposed model\nsignificantly improves the performance of Transformers, leading to\nstate-of-the-art results on the Worldtree corpus; (3) Analogical and abductive\nreasoning are highly complementary for achieving sound explanatory inference, a\nfeature that demonstrates the impact of the unification patterns on performance\nand interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:50:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Valentino", "Marco", ""], ["Thayaparan", "Mokanarangan", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2009.14620", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Legal Judgment Prediction (LJP) Amid the Advent of Autonomous AI Legal\n  Reasoning", "comments": "39 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal Judgment Prediction (LJP) is a longstanding and open topic in the\ntheory and practice-of-law. Predicting the nature and outcomes of judicial\nmatters is abundantly warranted, keenly sought, and vigorously pursued by those\nwithin the legal industry and also by society as a whole. The tenuous act of\ngenerating judicially laden predictions has been limited in utility and\nexactitude, requiring further advancement. Various methods and techniques to\npredict legal cases and judicial actions have emerged over time, especially\narising via the advent of computer-based modeling. There has been a wide range\nof approaches attempted, including simple calculative methods to highly\nsophisticated and complex statistical models. Artificial Intelligence (AI)\nbased approaches have also been increasingly utilized. In this paper, a review\nof the literature encompassing Legal Judgment Prediction is undertaken, along\nwith innovatively proposing that the advent of AI Legal Reasoning (AILR) will\nhave a pronounced impact on how LJP is performed and its predictive accuracy.\nLegal Judgment Prediction is particularly examined using the Levels of Autonomy\n(LoA) of AI Legal Reasoning, plus, other considerations are explored including\nLJP probabilistic tendencies, biases handling, actor predictors, transparency,\njudicial reliance, legal case outcomes, and other crucial elements entailing\nthe overarching legal judicial milieu.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:12:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2009.14653", "submitter": "Youri Xu", "authors": "Youri Xu, E Haihong, Meina Song, Wenyu Song, Xiaodong Lv, Wang\n  Haotian, Yang Jinrui", "title": "RTFE: A Recursive Temporal Fact Embedding Framework for Temporal\n  Knowledge Graph Completion", "comments": "Accepted as a main conference paper at NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static knowledge graph (SKG) embedding (SKGE) has been studied intensively in\nthe past years. Recently, temporal knowledge graph (TKG) embedding (TKGE) has\nemerged. In this paper, we propose a Recursive Temporal Fact Embedding (RTFE)\nframework to transplant SKGE models to TKGs and to enhance the performance of\nexisting TKGE models for TKG completion. Different from previous work which\nignores the continuity of states of TKG in time evolution, we treat the\nsequence of graphs as a Markov chain, which transitions from the previous state\nto the next state. RTFE takes the SKGE to initialize the embeddings of TKG.\nThen it recursively tracks the state transition of TKG by passing updated\nparameters/features between timestamps. Specifically, at each timestamp, we\napproximate the state transition as the gradient update process. Since RTFE\nlearns each timestamp recursively, it can naturally transit to future\ntimestamps. Experiments on five TKG datasets show the effectiveness of RTFE.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 12:59:09 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 11:27:22 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 18:15:30 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 07:19:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Xu", "Youri", ""], ["Haihong", "E", ""], ["Song", "Meina", ""], ["Song", "Wenyu", ""], ["Lv", "Xiaodong", ""], ["Haotian", "Wang", ""], ["Jinrui", "Yang", ""]]}, {"id": "2009.14654", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen and Pan Hu and Ernesto Jimenez-Ruiz and Ole Magnus Holter\n  and Denvar Antonyrajah and Ian Horrocks", "title": "OWL2Vec*: Embedding of OWL Ontologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic embedding of knowledge graphs has been widely studied and used for\nprediction and statistical analysis tasks across various domains such as\nNatural Language Processing and the Semantic Web. However, less attention has\nbeen paid to developing robust methods for embedding OWL (Web Ontology\nLanguage) ontologies which can express a much wider range of semantics than\nknowledge graphs and have been widely adopted in domains such as\nbioinformatics. In this paper, we propose a random walk and word embedding\nbased ontology embedding method named OWL2Vec*, which encodes the semantics of\nan OWL ontology by taking into account its graph structure, lexical information\nand logical constructors. Our empirical evaluation with three real world\ndatasets suggests that OWL2Vec* benefits from these three different aspects of\nan ontology in class membership prediction and class subsumption prediction\ntasks. Furthermore, OWL2Vec* often significantly outperforms the\nstate-of-the-art methods in our experiments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:07:50 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 17:38:46 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Hu", "Pan", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Holter", "Ole Magnus", ""], ["Antonyrajah", "Denvar", ""], ["Horrocks", "Ian", ""]]}, {"id": "2009.14665", "submitter": "Yujie Li", "authors": "Jiqian Dong, Sikai Chen, Yujie Li, Runjia Du, Aaron Steinfeld, Samuel\n  Labi", "title": "Facilitating Connected Autonomous Vehicle Operations Using\n  Space-weighted Information Fusion and Deep Reinforcement Learning Based\n  Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectivity aspect of connected autonomous vehicles (CAV) is beneficial\nbecause it facilitates dissemination of traffic-related information to vehicles\nthrough Vehicle-to-External (V2X) communication. Onboard sensing equipment\nincluding LiDAR and camera can reasonably characterize the traffic environment\nin the immediate locality of the CAV. However, their performance is limited by\ntheir sensor range (SR). On the other hand, longer-range information is helpful\nfor characterizing imminent conditions downstream. By contemporaneously\ncoalescing the short- and long-range information, the CAV can construct\ncomprehensively its surrounding environment and thereby facilitate informed,\nsafe, and effective movement planning in the short-term (local decisions\nincluding lane change) and long-term (route choice). In this paper, we describe\na Deep Reinforcement Learning based approach that integrates the data collected\nthrough sensing and connectivity capabilities from other vehicles located in\nthe proximity of the CAV and from those located further downstream, and we use\nthe fused data to guide lane changing, a specific context of CAV operations. In\naddition, recognizing the importance of the connectivity range (CR) to the\nperformance of not only the algorithm but also of the vehicle in the actual\ndriving environment, the paper carried out a case study. The case study\ndemonstrates the application of the proposed algorithm and duly identifies the\nappropriate CR for each level of prevailing traffic density. It is expected\nthat implementation of the algorithm in CAVs can enhance the safety and\nmobility associated with CAV driving operations. From a general perspective,\nits implementation can provide guidance to connectivity equipment manufacturers\nand CAV operators, regarding the default CR settings for CAVs or the\nrecommended CR setting in a given traffic environment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:38:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Dong", "Jiqian", ""], ["Chen", "Sikai", ""], ["Li", "Yujie", ""], ["Du", "Runjia", ""], ["Steinfeld", "Aaron", ""], ["Labi", "Samuel", ""]]}, {"id": "2009.14681", "submitter": "J\\'ulia Borr\\`as Sol", "authors": "J\\'ulia Borr\\`as, Guillem Aleny\\`a and Carme Torras", "title": "Encoding cloth manipulations using a graph of states and transitions", "comments": "6 pages, 7 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloth manipulation is very relevant for domestic robotic tasks, but it\npresents many challenges due to the complexity of representing, recognizing and\npredicting behaviour of cloth under manipulation. In this work, we propose a\ngeneric, compact and simplified representation of the states of cloth\nmanipulation that allows for representing tasks as sequences of states and\ntransitions. We also define a graph of manipulation primitives that encodes all\nthe strategies to accomplish a task. Our novel representation is used to encode\nthe task of folding a napkin, learned from an experiment with human subjects\nwith video and motion data. We show how our simplified representation allows to\nobtain a map of meaningful motion primitives and to segment the motion data to\nobtain sets of trajectories, velocity and acceleration profiles corresponding\nto each manipulation primitive in the graph.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:56:13 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Borr\u00e0s", "J\u00falia", ""], ["Aleny\u00e0", "Guillem", ""], ["Torras", "Carme", ""]]}, {"id": "2009.14701", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski, Xiao Yu Wang, and Alexander Wong", "title": "Where Does Trust Break Down? A Quantitative Trust Analysis of Deep\n  Neural Networks via Trust Matrix and Conditional Trust Densities", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advances and successes in deep learning in recent years have led to\nconsiderable efforts and investments into its widespread ubiquitous adoption\nfor a wide variety of applications, ranging from personal assistants and\nintelligent navigation to search and product recommendation in e-commerce. With\nthis tremendous rise in deep learning adoption comes questions about the\ntrustworthiness of the deep neural networks that power these applications.\nMotivated to answer such questions, there has been a very recent interest in\ntrust quantification. In this work, we introduce the concept of trust matrix, a\nnovel trust quantification strategy that leverages the recently introduced\nquestion-answer trust metric by Wong et al. to provide deeper, more detailed\ninsights into where trust breaks down for a given deep neural network given a\nset of questions. More specifically, a trust matrix defines the expected\nquestion-answer trust for a given actor-oracle answer scenario, allowing one to\nquickly spot areas of low trust that needs to be addressed to improve the\ntrustworthiness of a deep neural network. The proposed trust matrix is simple\nto calculate, humanly interpretable, and to the best of the authors' knowledge\nis the first to study trust at the actor-oracle answer level. We further extend\nthe concept of trust densities with the notion of conditional trust densities.\nWe experimentally leverage trust matrices to study several well-known deep\nneural network architectures for image recognition, and further study the trust\ndensity and conditional trust densities for an interesting actor-oracle answer\nscenario. The results illustrate that trust matrices, along with conditional\ntrust densities, can be useful tools in addition to the existing suite of trust\nquantification metrics for guiding practitioners and regulators in creating and\ncertifying deep learning solutions for trusted operation.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:33:43 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wang", "Xiao Yu", ""], ["Wong", "Alexander", ""]]}, {"id": "2009.14715", "submitter": "Theodore Sumers", "authors": "Theodore R. Sumers, Mark K. Ho, Robert D. Hawkins, Karthik Narasimhan,\n  Thomas L. Griffiths", "title": "Learning Rewards from Linguistic Feedback", "comments": "9 pages, 4 figures. AAAI '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore unconstrained natural language feedback as a learning signal for\nartificial agents. Humans use rich and varied language to teach, yet most prior\nwork on interactive learning from language assumes a particular form of input\n(e.g., commands). We propose a general framework which does not make this\nassumption, using aspect-based sentiment analysis to decompose feedback into\nsentiment about the features of a Markov decision process. We then perform an\nanalogue of inverse reinforcement learning, regressing the sentiment on the\nfeatures to infer the teacher's latent reward function. To evaluate our\napproach, we first collect a corpus of teaching behavior in a cooperative task\nwhere both teacher and learner are human. We implement three artificial\nlearners: sentiment-based \"literal\" and \"pragmatic\" models, and an inference\nnetwork trained end-to-end to predict latent rewards. We then repeat our\ninitial experiment and pair them with human teachers. All three successfully\nlearn from interactive human feedback. The sentiment models outperform the\ninference network, with the \"pragmatic\" model approaching human performance.\nOur work thus provides insight into the information structure of naturalistic\nlinguistic feedback as well as methods to leverage it for reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:51:00 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 15:54:34 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 19:03:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sumers", "Theodore R.", ""], ["Ho", "Mark K.", ""], ["Hawkins", "Robert D.", ""], ["Narasimhan", "Karthik", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2009.14759", "submitter": "Yuxuan Wu", "authors": "Yuxuan Wu and Hideki Nakayama", "title": "Graph-based Heuristic Search for Module Selection Procedure in Neural\n  Module Network", "comments": "in Neural Module Network[C]//Proceedings of the Asian Conference on\n  Computer Vision. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Module Network (NMN) is a machine learning model for solving the\nvisual question answering tasks. NMN uses programs to encode modules'\nstructures, and its modularized architecture enables it to solve logical\nproblems more reasonably. However, because of the non-differentiable procedure\nof module selection, NMN is hard to be trained end-to-end. To overcome this\nproblem, existing work either included ground-truth program into training data\nor applied reinforcement learning to explore the program. However, both of\nthese methods still have weaknesses. In consideration of this, we proposed a\nnew learning framework for NMN. Graph-based Heuristic Search is the algorithm\nwe proposed to discover the optimal program through a heuristic search on the\ndata structure named Program Graph. Our experiments on FigureQA and CLEVR\ndataset show that our methods can realize the training of NMN without\nground-truth programs and achieve superior efficiency over existing\nreinforcement learning methods in program exploration.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:55:44 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wu", "Yuxuan", ""], ["Nakayama", "Hideki", ""]]}, {"id": "2009.14786", "submitter": "Nicolas Gontier", "authors": "Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Pal", "title": "Measuring Systematic Generalization in Neural Proof Generation with\n  Transformers", "comments": "NeurIPS 2020; 17 pages; 9 figures; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in understanding how well Transformer language models\n(TLMs) can perform reasoning tasks when trained on knowledge encoded in the\nform of natural language. We investigate their systematic generalization\nabilities on a logical reasoning task in natural language, which involves\nreasoning over relationships between entities grounded in first-order logical\nproofs. Specifically, we perform soft theorem-proving by leveraging TLMs to\ngenerate natural language proofs. We test the generated proofs for logical\nconsistency, along with the accuracy of the final inference. We observe\nlength-generalization issues when evaluated on longer-than-trained sequences.\nHowever, we observe TLMs improve their generalization performance after being\nexposed to longer, exhaustive proofs. In addition, we discover that TLMs are\nable to generalize better using backward-chaining proofs compared to their\nforward-chaining counterparts, while they find it easier to generate forward\nchaining proofs. We observe that models that are not trained to generate proofs\nare better at generalizing to problems based on longer proofs. This suggests\nthat Transformers have efficient internal reasoning strategies that are harder\nto interpret. These results highlight the systematic generalization behavior of\nTLMs in the context of logical reasoning, and we believe this work motivates\ndeeper inspection of their underlying reasoning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:54:37 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:31:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gontier", "Nicolas", ""], ["Sinha", "Koustuv", ""], ["Reddy", "Siva", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.14795", "submitter": "Shane Mueller", "authors": "Robert R. Hoffman, William J. Clancey, and Shane T. Mueller", "title": "Explaining AI as an Exploratory Process: The Peircean Abduction Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current discussions of \"Explainable AI\" (XAI) do not much consider the role\nof abduction in explanatory reasoning (see Mueller, et al., 2018). It might be\nworthwhile to pursue this, to develop intelligent systems that allow for the\nobservation and analysis of abductive reasoning and the assessment of abductive\nreasoning as a learnable skill. Abductive inference has been defined in many\nways. For example, it has been defined as the achievement of insight. Most\noften abduction is taken as a single, punctuated act of syllogistic reasoning,\nlike making a deductive or inductive inference from given premises. In\ncontrast, the originator of the concept of abduction---the American\nscientist/philosopher Charles Sanders Peirce---regarded abduction as an\nexploratory activity. In this regard, Peirce's insights about reasoning align\nwith conclusions from modern psychological research. Since abduction is often\ndefined as \"inferring the best explanation,\" the challenge of implementing\nabductive reasoning and the challenge of automating the explanation process are\nclosely linked. We explore these linkages in this report. This analysis\nprovides a theoretical framework for understanding what the XAI researchers are\nalready doing, it explains why some XAI projects are succeeding (or might\nsucceed), and it leads to design advice.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:10:37 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 16:43:24 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Hoffman", "Robert R.", ""], ["Clancey", "William J.", ""], ["Mueller", "Shane T.", ""]]}, {"id": "2009.14810", "submitter": "Luiz Pessoa", "authors": "Marwen Belkaid and Luiz Pessoa", "title": "Emotion in Future Intelligent Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past decades, research in cognitive and affective neuroscience has\nemphasized that emotion is crucial for human intelligence and in fact\ninseparable from cognition. Concurrently, there has been a significantly\ngrowing interest in simulating and modeling emotion in robots and artificial\nagents. Yet, existing models of emotion and their integration in cognitive\narchitectures remain quite limited and frequently disconnected from\nneuroscientific evidence. We argue that a stronger integration of emotion in\nrobot models is critical for the design of intelligent machines capable of\ntackling real world problems. Drawing from current neuroscientific knowledge,\nwe provide a set of guidelines for future research in artificial emotion and\nintelligent machines more generally.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:32:30 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Belkaid", "Marwen", ""], ["Pessoa", "Luiz", ""]]}, {"id": "2009.14817", "submitter": "Barbara K\\\"onig", "authors": "Rebecca Bernemann and Benjamin Cabrera and Reiko Heckel and Barbara\n  K\\\"onig", "title": "Uncertainty Reasoning for Probabilistic Petri Nets via Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper exploits extended Bayesian networks for uncertainty reasoning on\nPetri nets, where firing of transitions is probabilistic. In particular,\nBayesian networks are used as symbolic representations of probability\ndistributions, modelling the observer's knowledge about the tokens in the net.\nThe observer can study the net by monitoring successful and failed steps.\n  An update mechanism for Bayesian nets is enabled by relaxing some of their\nrestrictions, leading to modular Bayesian nets that can conveniently be\nrepresented and modified. As for every symbolic representation, the question is\nhow to derive information - in this case marginal probability distributions -\nfrom a modular Bayesian net. We show how to do this by generalizing the known\nmethod of variable elimination.\n  The approach is illustrated by examples about the spreading of diseases (SIR\nmodel) and information diffusion in social networks. We have implemented our\napproach and provide runtime results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:40:54 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Bernemann", "Rebecca", ""], ["Cabrera", "Benjamin", ""], ["Heckel", "Reiko", ""], ["K\u00f6nig", "Barbara", ""]]}]