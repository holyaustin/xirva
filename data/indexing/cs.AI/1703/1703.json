[{"id": "1703.00048", "submitter": "Lihong Li", "authors": "Lihong Li and Yu Lu and Dengyong Zhou", "title": "Provably Optimal Algorithms for Generalized Linear Contextual Bandits", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits are widely used in Internet services from news\nrecommendation to advertising, and to Web search. Generalized linear models\n(logistical regression in particular) have demonstrated stronger performance\nthan linear models in many applications where rewards are binary. However, most\ntheoretical analyses on contextual bandits so far are on linear bandits. In\nthis work, we propose an upper confidence bound based algorithm for generalized\nlinear contextual bandits, which achieves an $\\tilde{O}(\\sqrt{dT})$ regret over\n$T$ rounds with $d$ dimensional feature vectors. This regret matches the\nminimax lower bound, up to logarithmic terms, and improves on the best previous\nresult by a $\\sqrt{d}$ factor, assuming the number of arms is fixed. A key\ncomponent in our analysis is to establish a new, sharp finite-sample confidence\nbound for maximum-likelihood estimates in generalized linear models, which may\nbe of independent interest. We also analyze a simpler upper confidence bound\nalgorithm, which is useful in practice, and prove it to have optimal regret for\ncertain cases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:39:44 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 04:07:45 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Li", "Lihong", ""], ["Lu", "Yu", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1703.00099", "submitter": "Zhou Yu", "authors": "Zhou Yu, Alan W Black and Alexander I. Rudnicky", "title": "Learning Conversational Systems that Interleave Task and Non-Task\n  Content", "comments": "Dialog Systems, Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems have been applied in various tasks, such as\nautomated personal assistants, customer service providers and tutors. These\nsystems work well when users have clear and explicit intentions that are\nwell-aligned to the systems' capabilities. However, they fail if users\nintentions are not explicit. To address this shortcoming, we propose a\nframework to interleave non-task content (i.e. everyday social conversation)\ninto task conversations. When the task content fails, the system can still keep\nthe user engaged with the non-task content. We trained a policy using\nreinforcement learning algorithms to promote long-turn conversation coherence\nand consistency, so that the system can have smooth transitions between task\nand non-task content. To test the effectiveness of the proposed framework, we\ndeveloped a movie promotion dialog system. Experiments with human users\nindicate that a system that interleaves social and task content achieves a\nbetter task success rate and is also rated as more engaging compared to a pure\ntask-oriented system.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 01:27:32 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Yu", "Zhou", ""], ["Black", "Alan W", ""], ["Rudnicky", "Alexander I.", ""]]}, {"id": "1703.00247", "submitter": "S\\'ebastien Ehrhardt", "authors": "Sebastien Ehrhardt, Aron Monszpart, Niloy J. Mitra and Andrea Vedaldi", "title": "Learning A Physical Long-term Predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution has resulted in highly developed abilities in many natural\nintelligences to quickly and accurately predict mechanical phenomena. Humans\nhave successfully developed laws of physics to abstract and model such\nmechanical phenomena. In the context of artificial intelligence, a recent line\nof work has focused on estimating physical parameters based on sensory data and\nuse them in physical simulators to make long-term predictions. In contrast, we\ninvestigate the effectiveness of a single neural network for end-to-end\nlong-term prediction of mechanical phenomena. Based on extensive evaluation, we\ndemonstrate that such networks can outperform alternate approaches having even\naccess to ground-truth physical simulators, especially when some physical\nparameters are unobserved or not known a-priori. Further, our network outputs a\ndistribution of outcomes to capture the inherent uncertainty in the data. Our\napproach demonstrates for the first time the possibility of making actionable\nlong-term predictions from sensor data without requiring to explicitly model\nthe underlying physical laws.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 11:44:18 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Ehrhardt", "Sebastien", ""], ["Monszpart", "Aron", ""], ["Mitra", "Niloy J.", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1703.00317", "submitter": "Ceyda Sanli", "authors": "Ceyda Sanli, Anupam Mondal, Erik Cambria", "title": "Tracing Linguistic Relations in Winning and Losing Sides of Explicit\n  Opposing Groups", "comments": "Full paper, Proceedings of FLAIRS-2017 (30th Florida Artificial\n  Intelligence Research Society), Special Track, Artificial Intelligence for\n  Big Social Data Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic relations in oral conversations present how opinions are\nconstructed and developed in a restricted time. The relations bond ideas,\narguments, thoughts, and feelings, re-shape them during a speech, and finally\nbuild knowledge out of all information provided in the conversation. Speakers\nshare a common interest to discuss. It is expected that each speaker's reply\nincludes duplicated forms of words from previous speakers. However, linguistic\nadaptation is observed and evolves in a more complex path than just\ntransferring slightly modified versions of common concepts. A conversation\naiming a benefit at the end shows an emergent cooperation inducing the\nadaptation. Not only cooperation, but also competition drives the adaptation or\nan opposite scenario and one can capture the dynamic process by tracking how\nthe concepts are linguistically linked. To uncover salient complex dynamic\nevents in verbal communications, we attempt to discover self-organized\nlinguistic relations hidden in a conversation with explicitly stated winners\nand losers. We examine open access data of the United States Supreme Court. Our\nunderstanding is crucial in big data research to guide how transition states in\nopinion mining and decision-making should be modeled and how this required\nknowledge to guide the model should be pinpointed, by filtering large amount of\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 14:40:22 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Sanli", "Ceyda", ""], ["Mondal", "Anupam", ""], ["Cambria", "Erik", ""]]}, {"id": "1703.00320", "submitter": "Hadi Hosseini", "authors": "Hadi Hosseini, Kate Larson, Robin Cohen", "title": "Investigating the Characteristics of One-Sided Matching Mechanisms Under\n  Various Preferences and Risk Attitudes", "comments": "arXiv admin note: text overlap with arXiv:1503.01488", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-sided matching mechanisms are fundamental for assigning a set of\nindivisible objects to a set of self-interested agents when monetary transfers\nare not allowed. Two widely-studied randomized mechanisms in multiagent\nsettings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial\nRule (PS). Both mechanisms require only that agents specify ordinal preferences\nand have a number of desirable economic and computational properties. However,\nthe induced outcomes of the mechanisms are often incomparable and thus there\nare challenges when it comes to deciding which mechanism to adopt in practice.\nIn this paper, we first consider the space of general ordinal preferences and\nprovide empirical results on the (in)comparability of RSD and PS. We analyze\ntheir respective economic properties under general and lexicographic\npreferences. We then instantiate utility functions with the goal of gaining\ninsights on the manipulability, efficiency, and envyfreeness of the mechanisms\nunder different risk-attitude models. Our results hold under various preference\ndistribution models, which further confirm the broad use of RSD in most\npractical applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 14:42:20 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Hosseini", "Hadi", ""], ["Larson", "Kate", ""], ["Cohen", "Robin", ""]]}, {"id": "1703.00352", "submitter": "Claudio Mazzola", "authors": "Claudio Mazzola and Peter Evans", "title": "Do Reichenbachian Common Cause Systems of Arbitrary Finite Size Exist?", "comments": null, "journal-ref": null, "doi": "10.1007/s10701-017-0124-1", "report-no": null, "categories": "stat.OT cs.AI physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of common cause asserts that positive correlations between\ncausally unrelated events ought to be explained through the action of some\nshared causal factors. Reichenbachian common cause systems are probabilistic\nstructures aimed at accounting for cases where correlations of the aforesaid\nsort cannot be explained through the action of a single common cause. The\nexistence of Reichenbachian common cause systems of arbitrary finite size for\neach pair of non-causally correlated events was allegedly demonstrated by\nHofer-Szab\\'o and R\\'edei in 2006. This paper shows that their proof is\nlogically deficient, and we propose an improved proof.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 11:31:57 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Mazzola", "Claudio", ""], ["Evans", "Peter", ""]]}, {"id": "1703.00381", "submitter": "Junier Oliva", "authors": "Junier B. Oliva, Barnabas Poczos, Jeff Schneider", "title": "The Statistical Recurrent Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophisticated gated recurrent neural network architectures like LSTMs and\nGRUs have been shown to be highly effective in a myriad of applications. We\ndevelop an un-gated unit, the statistical recurrent unit (SRU), that is able to\nlearn long term dependencies in data by only keeping moving averages of\nstatistics. The SRU's architecture is simple, un-gated, and contains a\ncomparable number of parameters to LSTMs; yet, SRUs perform favorably to more\nsophisticated LSTM and GRU alternatives, often outperforming one or both in\nvarious tasks. We show the efficacy of SRUs as compared to LSTMs and GRUs in an\nunbiased manner by optimizing respective architectures' hyperparameters in a\nBayesian optimization scheme for both synthetic and real-world tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 16:50:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Oliva", "Junier B.", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""]]}, {"id": "1703.00391", "submitter": "Ilias Tachmazidis", "authors": "Ilias Tachmazidis, Sotiris Batsakis, John Davies, Alistair Duke, Mauro\n  Vallati, Grigoris Antoniou, Sandra Stincic Clarke", "title": "A Hypercat-enabled Semantic Internet of Things Data Hub: Technical\n  Report", "comments": "Technical report of an accepted ESWC-2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of information is generated from the rapidly increasing\nnumber of sensor networks and smart devices. A wide variety of sources generate\nand publish information in different formats, thus highlighting\ninteroperability as one of the key prerequisites for the success of Internet of\nThings (IoT). The BT Hypercat Data Hub provides a focal point for the sharing\nand consumption of available datasets from a wide range of sources. In this\nwork, we propose a semantic enrichment of the BT Hypercat Data Hub, using\nwell-accepted Semantic Web standards and tools. We propose an ontology that\ncaptures the semantics of the imported data and present the BT SPARQL Endpoint\nby means of a mapping between SPARQL and SQL queries. Furthermore, federated\nSPARQL queries allow queries over multiple hub-based and external data sources.\nFinally, we provide two use cases in order to illustrate the advantages\nafforded by our semantic approach.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 17:10:27 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 13:18:29 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Tachmazidis", "Ilias", ""], ["Batsakis", "Sotiris", ""], ["Davies", "John", ""], ["Duke", "Alistair", ""], ["Vallati", "Mauro", ""], ["Antoniou", "Grigoris", ""], ["Clarke", "Sandra Stincic", ""]]}, {"id": "1703.00420", "submitter": "Lei Tai", "authors": "Lei Tai, Giuseppe Paolo and Ming Liu", "title": "Virtual-to-real Deep Reinforcement Learning: Continuous Control of\n  Mobile Robots for Mapless Navigation", "comments": "video: https://www.youtube.com/watch?v=9AOIwBYIBbs, 6 pages, 9\n  figures, to appear in he 2017 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2017), final submission version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based mapless motion planner by taking the sparse\n10-dimensional range findings and the target position with respect to the\nmobile robot coordinate frame as input and the continuous steering commands as\noutput. Traditional motion planners for mobile ground robots with a laser range\nsensor mostly depend on the obstacle map of the navigation environment where\nboth the highly precise laser sensor and the obstacle map building work of the\nenvironment are indispensable. We show that, through an asynchronous deep\nreinforcement learning method, a mapless motion planner can be trained\nend-to-end without any manually designed features and prior demonstrations. The\ntrained planner can be directly applied in unseen virtual and real\nenvironments. The experiments show that the proposed mapless motion planner can\nnavigate the nonholonomic mobile robot to the desired targets without colliding\nwith any obstacles.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:10:20 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 08:09:19 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 09:56:05 GMT"}, {"version": "v4", "created": "Fri, 21 Jul 2017 17:26:00 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Tai", "Lei", ""], ["Paolo", "Giuseppe", ""], ["Liu", "Ming", ""]]}, {"id": "1703.00426", "submitter": "Francois Chollet", "authors": "Cezary Kaliszyk, Fran\\c{c}ois Chollet, Christian Szegedy", "title": "HolStep: A Machine Learning Dataset for Higher-order Logic Theorem\n  Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large computer-understandable proofs consist of millions of intermediate\nlogical steps. The vast majority of such steps originate from manually selected\nand manually guided heuristics applied to intermediate goals. So far, machine\nlearning has generally not been used to filter or generate these steps. In this\npaper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for\nthe purpose of developing new machine learning-based theorem-proving\nstrategies. We make this dataset publicly available under the BSD license. We\npropose various machine learning tasks that can be performed on this dataset,\nand discuss their significance for theorem proving. We also benchmark a set of\nsimple baseline machine learning models suited for the tasks (including\nlogistic regression, convolutional neural networks and recurrent neural\nnetworks). The results of our baseline models show the promise of applying\nmachine learning to HOL theorem proving.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:20:19 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Chollet", "Fran\u00e7ois", ""], ["Szegedy", "Christian", ""]]}, {"id": "1703.00440", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Fast k-Nearest Neighbour Search via Prioritized DCI", "comments": "14 pages, 6 figures; International Conference on Machine Learning\n  (ICML), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most exact methods for k-nearest neighbour search suffer from the curse of\ndimensionality; that is, their query times exhibit exponential dependence on\neither the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing\n(DCI) offers a promising way of circumventing the curse and successfully\nreduces the dependence of query time on intrinsic dimensionality from\nexponential to sublinear. In this paper, we propose a variant of DCI, which we\ncall Prioritized DCI, and show a remarkable improvement in the dependence of\nquery time on intrinsic dimensionality. In particular, a linear increase in\nintrinsic dimensionality, or equivalently, an exponential increase in the\nnumber of points near a query, can be mostly counteracted with just a linear\nincrease in space. We also demonstrate empirically that Prioritized DCI\nsignificantly outperforms prior methods. In particular, relative to\nLocality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of\ndistance evaluations by a factor of 14 to 116 and the memory consumption by a\nfactor of 21.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:51:13 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 17:46:04 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1703.00441", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Learning to Optimize Neural Nets", "comments": "10 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Optimize is a recently proposed framework for learning\noptimization algorithms using reinforcement learning. In this paper, we explore\nlearning an optimization algorithm for training shallow neural nets. Such\nhigh-dimensional stochastic optimization problems present interesting\nchallenges for existing reinforcement learning algorithms. We develop an\nextension that is suited to learning optimization algorithms in this setting\nand demonstrate that the learned optimization algorithm consistently\noutperforms other known optimization algorithms even on unseen tasks and is\nrobust to changes in stochasticity of gradients and the neural net\narchitecture. More specifically, we show that an optimization algorithm trained\nwith the proposed method on the problem of training a neural net on MNIST\ngeneralizes to the problems of training neural nets on the Toronto Faces\nDataset, CIFAR-10 and CIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:52:23 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 18:59:01 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1703.00443", "submitter": "Brandon Amos", "authors": "Brandon Amos, J. Zico Kolter", "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents OptNet, a network architecture that integrates\noptimization problems (here, specifically in the form of quadratic programs) as\nindividual layers in larger end-to-end trainable deep networks. These layers\nencode constraints and complex dependencies between the hidden states that\ntraditional convolutional and fully-connected layers often cannot capture. In\nthis paper, we explore the foundations for such an architecture: we show how\ntechniques from sensitivity analysis, bilevel optimization, and implicit\ndifferentiation can be used to exactly differentiate through these layers and\nwith respect to layer parameters; we develop a highly efficient solver for\nthese layers that exploits fast GPU-based batch solves within a primal-dual\ninterior point method, and which provides backpropagation gradients with\nvirtually no additional cost on top of the solve; and we highlight the\napplication of these approaches in several problems. In one notable example, we\nshow that the method is capable of learning to play mini-Sudoku (4x4) given\njust input and output games, with no a priori information about the rules of\nthe game; this highlights the ability of our architecture to learn hard\nconstraints better than other neural architectures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 18:58:48 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 17:59:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jan 2018 19:44:25 GMT"}, {"version": "v4", "created": "Mon, 14 Oct 2019 18:03:26 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Amos", "Brandon", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1703.00484", "submitter": "Rad Niazadeh", "authors": "Shuchi Chawla, Nikhil Devanur, Janardhan Kulkarni, Rad Niazadeh", "title": "Truth and Regret in Online Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scheduling problem where a cloud service provider has multiple\nunits of a resource available over time. Selfish clients submit jobs, each with\nan arrival time, deadline, length, and value. The service provider's goal is to\nimplement a truthful online mechanism for scheduling jobs so as to maximize the\nsocial welfare of the schedule. Recent work shows that under a stochastic\nassumption on job arrivals, there is a single-parameter family of mechanisms\nthat achieves near-optimal social welfare. We show that given any such family\nof near-optimal online mechanisms, there exists an online mechanism that in the\nworst case performs nearly as well as the best of the given mechanisms. Our\nmechanism is truthful whenever the mechanisms in the given family are truthful\nand prompt, and achieves optimal (within constant factors) regret.\n  We model the problem of competing against a family of online scheduling\nmechanisms as one of learning from expert advice. A primary challenge is that\nany scheduling decisions we make affect not only the payoff at the current\nstep, but also the resource availability and payoffs in future steps.\nFurthermore, switching from one algorithm (a.k.a. expert) to another in an\nonline fashion is challenging both because it requires synchronization with the\nstate of the latter algorithm as well as because it affects the incentive\nstructure of the algorithms. We further show how to adapt our algorithm to a\nnon-clairvoyant setting where job lengths are unknown until jobs are run to\ncompletion. Once again, in this setting, we obtain truthfulness along with\nasymptotically optimal regret (within poly-logarithmic factors).\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 20:09:43 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Chawla", "Shuchi", ""], ["Devanur", "Nikhil", ""], ["Kulkarni", "Janardhan", ""], ["Niazadeh", "Rad", ""]]}, {"id": "1703.00503", "submitter": "Tianmin Shu", "authors": "Tianmin Shu, Xiaofeng Gao, Michael S. Ryoo and Song-Chun Zhu", "title": "Learning Social Affordance Grammar from Videos: Transferring Human\n  Interactions to Human-Robot Interactions", "comments": "The 2017 IEEE International Conference on Robotics and Automation\n  (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general framework for learning social affordance\ngrammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human\ninteractions, and transfer the grammar to humanoids to enable a real-time\nmotion inference for human-robot interaction (HRI). Based on Gibbs sampling,\nour weakly supervised grammar learning can automatically construct a\nhierarchical representation of an interaction with long-term joint sub-tasks of\nboth agents and short term atomic actions of individual agents. Based on a new\nRGB-D video dataset with rich instances of human interactions, our experiments\nof Baxter simulation, human evaluation, and real Baxter test demonstrate that\nthe model learned from limited training data successfully generates human-like\nbehaviors in unseen scenarios and outperforms both baselines.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 21:05:10 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Shu", "Tianmin", ""], ["Gao", "Xiaofeng", ""], ["Ryoo", "Michael S.", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1703.00512", "submitter": "Randal Olson", "authors": "Randal S. Olson, William La Cava, Patryk Orzechowski, Ryan J.\n  Urbanowicz, Jason H. Moore", "title": "PMLB: A Large Benchmark Suite for Machine Learning Evaluation and\n  Comparison", "comments": "14 pages, 5 figures, submitted for review to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection, development, or comparison of machine learning methods in data\nmining can be a difficult task based on the target problem and goals of a\nparticular study. Numerous publicly available real-world and simulated\nbenchmark datasets have emerged from different sources, but their organization\nand adoption as standards have been inconsistent. As such, selecting and\ncurating specific benchmarks remains an unnecessary burden on machine learning\npractitioners and data scientists. The present study introduces an accessible,\ncurated, and developing public benchmark resource to facilitate identification\nof the strengths and weaknesses of different machine learning methodologies. We\ncompare meta-features among the current set of benchmark datasets in this\nresource to characterize the diversity of available data. Finally, we apply a\nnumber of established machine learning methods to the entire benchmark suite\nand analyze how datasets and algorithms cluster in terms of performance. This\nwork is an important first step towards understanding the limitations of\npopular benchmarking suites and developing a resource that connects existing\nbenchmarking standards to more diverse and efficient standards in the future.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 21:20:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Olson", "Randal S.", ""], ["La Cava", "William", ""], ["Orzechowski", "Patryk", ""], ["Urbanowicz", "Ryan J.", ""], ["Moore", "Jason H.", ""]]}, {"id": "1703.00548", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Dan\n  Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel\n  Duffy, Babak Hodjat", "title": "Evolving Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning depends on finding an architecture to fit the\ntask. As deep learning has scaled up to more challenging tasks, the\narchitectures have become difficult to design by hand. This paper proposes an\nautomated method, CoDeepNEAT, for optimizing deep learning architectures\nthrough evolution. By extending existing neuroevolution methods to topology,\ncomponents, and hyperparameters, this method achieves results comparable to\nbest human designs in standard benchmarks in object recognition and language\nmodeling. It also supports building a real-world application of automated image\ncaptioning on a magazine website. Given the anticipated increases in available\ncomputing power, evolution of deep networks is promising approach to\nconstructing deep learning applications in the future.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 23:40:42 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 23:13:05 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Liang", "Jason", ""], ["Meyerson", "Elliot", ""], ["Rawal", "Aditya", ""], ["Fink", "Dan", ""], ["Francon", "Olivier", ""], ["Raju", "Bala", ""], ["Shahrzad", "Hormoz", ""], ["Navruzyan", "Arshak", ""], ["Duffy", "Nigel", ""], ["Hodjat", "Babak", ""]]}, {"id": "1703.00556", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Neil Iscoe, Aaron Shagrin, Ron Cordell, Sam\n  Nazari, Cory Schoolland, Myles Brundage, Jonathan Epstein, Randy Dean,\n  Gurmeet Lamba", "title": "Conversion Rate Optimization through Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion optimization means designing a web interface so that as many users\nas possible take a desired action on it, such as register or purchase. Such\ndesign is usually done by hand, testing one change at a time through A/B\ntesting, or a limited number of combinations through multivariate testing,\nmaking it possible to evaluate only a small fraction of designs in a vast\ndesign space. This paper describes Sentient Ascend, an automatic conversion\noptimization system that uses evolutionary optimization to create effective web\ninterface designs. Ascend makes it possible to discover and utilize\ninteractions between the design elements that are difficult to identify\notherwise. Moreover, evaluation of design candidates is done in parallel\nonline, i.e. with a large number of real users interacting with the system. A\ncase study on an existing media site shows that significant improvements (i.e.\nover 43%) are possible beyond human design. Ascend can therefore be seen as an\napproach to massively multivariate conversion optimization, based on a\nmassively parallel interactive evolution.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 23:54:28 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 21:16:02 GMT"}, {"version": "v3", "created": "Mon, 27 Mar 2017 18:30:16 GMT"}, {"version": "v4", "created": "Sun, 30 Apr 2017 20:51:21 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Iscoe", "Neil", ""], ["Shagrin", "Aaron", ""], ["Cordell", "Ron", ""], ["Nazari", "Sam", ""], ["Schoolland", "Cory", ""], ["Brundage", "Myles", ""], ["Epstein", "Jonathan", ""], ["Dean", "Randy", ""], ["Lamba", "Gurmeet", ""]]}, {"id": "1703.00674", "submitter": "Virag Shah", "authors": "Virag Shah, Lennart Gulikers, Laurent Massoulie, Milan Vojnovic", "title": "Adaptive Matching for Expert Systems with Uncertain Task Types", "comments": "A part of it presented at Allerton Conference 2017, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A matching in a two-sided market often incurs an externality: a matched\nresource may become unavailable to the other side of the market, at least for a\nwhile. This is especially an issue in online platforms involving human experts\nas the expert resources are often scarce. The efficient utilization of experts\nin these platforms is made challenging by the fact that the information\navailable about the parties involved is usually limited.\n  To address this challenge, we develop a model of a task-expert matching\nsystem where a task is matched to an expert using not only the prior\ninformation about the task but also the feedback obtained from the past\nmatches. In our model the tasks arrive online while the experts are fixed and\nconstrained by a finite service capacity. For this model, we characterize the\nmaximum task resolution throughput a platform can achieve. We show that the\nnatural greedy approaches where each expert is assigned a task most suitable to\nher skill is suboptimal, as it does not internalize the above externality. We\ndevelop a throughput optimal backpressure algorithm which does so by accounting\nfor the `congestion' among different task types. Finally, we validate our model\nand confirm our theoretical findings with data-driven simulations via logs of\nMath.StackExchange, a StackOverflow forum dedicated to mathematics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 09:11:32 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 13:04:57 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 22:59:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Shah", "Virag", ""], ["Gulikers", "Lennart", ""], ["Massoulie", "Laurent", ""], ["Vojnovic", "Milan", ""]]}, {"id": "1703.00760", "submitter": "Pierre Roy", "authors": "Pierre Roy, Alexandre Papadopoulos, Fran\\c{c}ois Pachet", "title": "Sampling Variations of Lead Sheets", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning techniques have been recently used with spectacular results\nto generate artefacts such as music or text. However, these techniques are\nstill unable to capture and generate artefacts that are convincingly\nstructured. In this paper we present an approach to generate structured musical\nsequences. We introduce a mechanism for sampling efficiently variations of\nmusical sequences. Given a input sequence and a statistical model, this\nmechanism samples a set of sequences whose distance to the input sequence is\napproximately within specified bounds. This mechanism is implemented as an\nextension of belief propagation, and uses local fields to bias the generation.\nWe show experimentally that sampled sequences are indeed closely correlated to\nthe standard musical similarity measure defined by Mongeau and Sankoff. We then\nshow how this mechanism can used to implement composition strategies that\nenforce arbitrary structure on a musical lead sheet generation problem.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 12:33:28 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Roy", "Pierre", ""], ["Papadopoulos", "Alexandre", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1703.00838", "submitter": "Reuth Mirsky", "authors": "Retuh Mirsky and Ya'akov (Kobi) Gal", "title": "SLIM: Semi-Lazy Inference Mechanism for Plan Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plan Recognition algorithms require to recognize a complete hierarchy\nexplaining the agent's actions and goals. While the output of such algorithms\nis informative to the recognizer, the cost of its calculation is high in\nrun-time, space, and completeness. Moreover, performing plan recognition online\nrequires the observing agent to reason about future actions that have not yet\nbeen seen and maintain a set of hypotheses to support all possible options.\nThis paper presents a new and efficient algorithm for online plan recognition\ncalled SLIM (Semi-Lazy Inference Mechanism). It combines both a bottom-up and\ntop-down parsing processes, which allow it to commit only to the minimum\nnecessary actions in real-time, but still provide complete hypotheses post\nfactum. We show both theoretically and empirically that although the\ncomputational cost of this process is still exponential, there is a significant\nimprovement in run-time when compared to a state of the art of plan recognition\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 15:53:19 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Mirsky", "Retuh", "", "Kobi"], ["Ya'akov", "", "", "Kobi"], ["Gal", "", ""]]}, {"id": "1703.00848", "submitter": "Ming-Yu Liu", "authors": "Ming-Yu Liu and Thomas Breuel and Jan Kautz", "title": "Unsupervised Image-to-Image Translation Networks", "comments": "NIPS 2017, 11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation aims at learning a joint distribution\nof images in different domains by using images from the marginal distributions\nin individual domains. Since there exists an infinite set of joint\ndistributions that can arrive the given marginal distributions, one could infer\nnothing about the joint distribution from the marginal distributions without\nadditional assumptions. To address the problem, we make a shared-latent space\nassumption and propose an unsupervised image-to-image translation framework\nbased on Coupled GANs. We compare the proposed framework with competing\napproaches and present high quality image translation results on various\nchallenging unsupervised image translation tasks, including street scene image\ntranslation, animal image translation, and face image translation. We also\napply the proposed framework to domain adaptation and achieve state-of-the-art\nperformance on benchmark datasets. Code and additional results are available in\nhttps://github.com/mingyuliutw/unit .\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 16:29:30 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 17:55:21 GMT"}, {"version": "v3", "created": "Fri, 6 Oct 2017 03:14:21 GMT"}, {"version": "v4", "created": "Mon, 9 Oct 2017 18:14:27 GMT"}, {"version": "v5", "created": "Thu, 15 Feb 2018 15:33:48 GMT"}, {"version": "v6", "created": "Mon, 23 Jul 2018 03:39:28 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Liu", "Ming-Yu", ""], ["Breuel", "Thomas", ""], ["Kautz", "Jan", ""]]}, {"id": "1703.00948", "submitter": "Preeti Bhargava", "authors": "Nemanja Spasojevic, Preeti Bhargava, Guoning Hu", "title": "DAWT: Densely Annotated Wikipedia Texts across multiple languages", "comments": "8 pages, 3 figures, 7 tables, WWW2017, WWW 2017 Companion proceedings", "journal-ref": null, "doi": "10.1145/3041021.3053367", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we open up the DAWT dataset - Densely Annotated Wikipedia Texts\nacross multiple languages. The annotations include labeled text mentions\nmapping to entities (represented by their Freebase machine ids) as well as the\ntype of the entity. The data set contains total of 13.6M articles, 5.0B tokens,\n13.8M mention entity co-occurrences. DAWT contains 4.8 times more anchor text\nto entity links than originally present in the Wikipedia markup. Moreover, it\nspans several languages including English, Spanish, Italian, German, French and\nArabic. We also present the methodology used to generate the dataset which\nenriches Wikipedia markup in order to increase number of links. In addition to\nthe main dataset, we open up several derived datasets including mention entity\nco-occurrence counts and entity embeddings, as well as mappings between\nFreebase ids and Wikidata item ids. We also discuss two applications of these\ndatasets and hope that opening them up would prove useful for the Natural\nLanguage Processing and Information Retrieval communities, as well as\nfacilitate multi-lingual research.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 20:55:20 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Spasojevic", "Nemanja", ""], ["Bhargava", "Preeti", ""], ["Hu", "Guoning", ""]]}, {"id": "1703.00955", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric P.\n  Xing", "title": "Toward Controlled Generation of Text", "comments": "Code adapted for text style transfer is released at:\n  https://github.com/asyml/texar/tree/master/examples/text_style_transfer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 21:23:47 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 21:15:43 GMT"}, {"version": "v3", "created": "Tue, 23 Jan 2018 08:01:18 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 02:16:40 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Liang", "Xiaodan", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.00956", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado and Marc G. Bellemare and Michael Bowling", "title": "A Laplacian Framework for Option Discovery in Reinforcement Learning", "comments": "Appearing in the Proceedings of the 34th International Conference on\n  Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning and option discovery are two of the biggest\nchallenges in reinforcement learning (RL). Proto-value functions (PVFs) are a\nwell-known approach for representation learning in MDPs. In this paper we\naddress the option discovery problem by showing how PVFs implicitly define\noptions. We do it by introducing eigenpurposes, intrinsic reward functions\nderived from the learned representations. The options discovered from\neigenpurposes traverse the principal directions of the state space. They are\nuseful for multiple tasks because they are discovered without taking the\nenvironment's rewards into consideration. Moreover, different options act at\ndifferent time scales, making them helpful for exploration. We demonstrate\nfeatures of eigenpurposes in traditional tabular domains as well as in Atari\n2600 games.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 21:31:29 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 02:52:21 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1703.01008", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yun-Nung Chen and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz", "title": "End-to-End Task-Completion Neural Dialogue Systems", "comments": "11 pages, IJCNLP 2017, arXiv admin note: substantial text overlap\n  with arXiv:1703.07055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major drawbacks of modularized task-completion dialogue systems is\nthat each module is trained individually, which presents several challenges.\nFor example, downstream modules are affected by earlier modules, and the\nperformance of the entire system is not robust to the accumulated errors. This\npaper presents a novel end-to-end learning framework for task-completion\ndialogue systems to tackle such issues. Our neural dialogue system can directly\ninteract with a structured database to assist users in accessing information\nand accomplishing certain tasks. The reinforcement learning based dialogue\nmanager offers robust capabilities to handle noises caused by other components\nof the dialogue system. Our experiments in a movie-ticket booking domain show\nthat our end-to-end system not only outperforms modularized dialogue system\nbaselines for both objective and subjective evaluation, but also is robust to\nnoises as demonstrated by several systematic experiments with different error\ngranularity and rates specific to the language understanding module.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 01:29:11 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 05:50:21 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 17:47:23 GMT"}, {"version": "v4", "created": "Sun, 11 Feb 2018 23:19:21 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Li", "Xiujun", ""], ["Chen", "Yun-Nung", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1703.01026", "submitter": "Edward Barker", "authors": "Edward W. Barker and Charl J. Ras", "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning", "comments": "Extended abstract submitted (3 March 2017) for 3rd Multidisciplinary\n  Conference on Reinforcement Learning and Decision Making (RLDM) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using reinforcement learning (RL) algorithms to evaluate a policy it is\ncommon, given a large state space, to introduce some form of approximation\narchitecture for the value function (VF). The exact form of this architecture\ncan have a significant effect on the accuracy of the VF estimate, however, and\ndetermining a suitable approximation architecture can often be a highly complex\ntask. Consequently there is a large amount of interest in the potential for\nallowing RL algorithms to adaptively generate approximation architectures.\n  We investigate a method of adapting approximation architectures which uses\nfeedback regarding the frequency with which an agent has visited certain states\nto guide which areas of the state space to approximate with greater detail.\nThis method is \"unsupervised\" in the sense that it makes no direct reference to\nreward or the VF estimate. We introduce an algorithm based upon this idea which\nadapts a state aggregation approximation architecture on-line.\n  A common method of scoring a VF estimate is to weight the squared Bellman\nerror of each state-action by the probability of that state-action occurring.\nAdopting this scoring method, and assuming $S$ states, we demonstrate\ntheoretically that - provided (1) the number of cells $X$ in the state\naggregation architecture is of order $\\sqrt{S}\\log_2{S}\\ln{S}$ or greater, (2)\nthe policy and transition function are close to deterministic, and (3) the\nprior for the transition function is uniformly distributed - our algorithm,\nused in conjunction with a suitable RL algorithm, can guarantee a score which\nis arbitrarily close to zero as $S$ becomes large. It is able to do this\ndespite having only $O(X \\log_2S)$ space complexity and negligible time\ncomplexity. The results take advantage of certain properties of the stationary\ndistributions of Markov chains.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 03:24:03 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Barker", "Edward W.", ""], ["Ras", "Charl J.", ""]]}, {"id": "1703.01040", "submitter": "Jangwon Lee", "authors": "Jangwon Lee and Michael S. Ryoo", "title": "Learning Robot Activities from First-Person Human Videos Using\n  Convolutional Future Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new approach that allows robot learning of new activities from\nunlabeled human example videos. Given videos of humans executing the same\nactivity from a human's viewpoint (i.e., first-person videos), our objective is\nto make the robot learn the temporal structure of the activity as its future\nregression network, and learn to transfer such model for its own motor\nexecution. We present a new deep learning model: We extend the state-of-the-art\nconvolutional object detection network for the representation/estimation of\nhuman hands in training videos, and newly introduce the concept of using a\nfully convolutional network to regress (i.e., predict) the intermediate scene\nrepresentation corresponding to the future frame (e.g., 1-2 seconds later).\nCombining these allows direct prediction of future locations of human hands and\nobjects, which enables the robot to infer the motor control plan using our\nmanipulation network. We experimentally confirm that our approach makes\nlearning of robot activities from unlabeled human interaction videos possible,\nand demonstrate that our robot is able to execute the learned collaborative\nactivities in real-time directly based on its camera input.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 05:27:50 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 08:02:11 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Lee", "Jangwon", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "1703.01041", "submitter": "Esteban Real", "authors": "Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon\n  Suematsu, Jie Tan, Quoc Le, Alex Kurakin", "title": "Large-Scale Evolution of Image Classifiers", "comments": "Accepted for publication at ICML 2017 (34th International Conference\n  on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven effective at solving difficult problems but\ndesigning their architectures can be challenging, even for image classification\nproblems alone. Our goal is to minimize human participation, so we employ\nevolutionary algorithms to discover such networks automatically. Despite\nsignificant computational requirements, we show that it is now possible to\nevolve models with accuracies within the range of those published in the last\nyear. Specifically, we employ simple evolutionary techniques at unprecedented\nscales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting\nfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% for\nensemble) and 77.0%, respectively. To do this, we use novel and intuitive\nmutation operators that navigate large search spaces; we stress that no human\nparticipation is required once evolution starts and that the output is a\nfully-trained model. Throughout this work, we place special emphasis on the\nrepeatability of results, the variability in the outcomes and the computational\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 05:41:30 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 08:42:28 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Real", "Esteban", ""], ["Moore", "Sherry", ""], ["Selle", "Andrew", ""], ["Saxena", "Saurabh", ""], ["Suematsu", "Yutaka Leon", ""], ["Tan", "Jie", ""], ["Le", "Quoc", ""], ["Kurakin", "Alex", ""]]}, {"id": "1703.01083", "submitter": "Reuth Mirsky", "authors": "Reuth Mirsky and Roni Stern and Ya'akov (Kobi) Gal and Meir Kalech", "title": "Sequential Plan Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plan recognition algorithms infer agents' plans from their observed actions.\nDue to imperfect knowledge about the agent's behavior and the environment, it\nis often the case that there are multiple hypotheses about an agent's plans\nthat are consistent with the observations, though only one of these hypotheses\nis correct. This paper addresses the problem of how to disambiguate between\nhypotheses, by querying the acting agent about whether a candidate plan in one\nof the hypotheses matches its intentions. This process is performed\nsequentially and used to update the set of possible hypotheses during the\nrecognition process. The paper defines the sequential plan recognition process\n(SPRP), which seeks to reduce the number of hypotheses using a minimal number\nof queries. We propose a number of policies for the SPRP which use maximum\nlikelihood and information gain to choose which plan to query. We show this\napproach works well in practice on two domains from the literature,\nsignificantly reducing the number of hypotheses using fewer queries than a\nbaseline approach. Our results can inform the design of future plan recognition\nsystems that interleave the recognition process with intelligent interventions\nof their users.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 09:03:46 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Mirsky", "Reuth", "", "Kobi"], ["Stern", "Roni", "", "Kobi"], ["Ya'akov", "", "", "Kobi"], ["Gal", "", ""], ["Kalech", "Meir", ""]]}, {"id": "1703.01127", "submitter": "Dario Garcia-Gasulla PhD", "authors": "Dario Garcia-Gasulla, Ferran Par\\'es, Armand Vilalta, Jonatan Moreno,\n  Eduard Ayguad\\'e, Jes\\'us Labarta, Ulises Cort\\'es, Toyotaro Suzumura", "title": "On the Behavior of Convolutional Nets for Feature Extraction", "comments": "Published in the Journal of Artificial Intelligence Research (JAIR),\n  Special Track on Deep Learning, Knowledge Representation, and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are representation learning techniques. During training,\na deep net is capable of generating a descriptive language of unprecedented\nsize and detail in machine learning. Extracting the descriptive language coded\nwithin a trained CNN model (in the case of image data), and reusing it for\nother purposes is a field of interest, as it provides access to the visual\ndescriptors previously learnt by the CNN after processing millions of images,\nwithout requiring an expensive training phase. Contributions to this field\n(commonly known as feature representation transfer or transfer learning) have\nbeen purely empirical so far, extracting all CNN features from a single layer\nclose to the output and testing their performance by feeding them to a\nclassifier. This approach has provided consistent results, although its\nrelevance is limited to classification tasks. In a completely different\napproach, in this paper we statistically measure the discriminative power of\nevery single feature found within a deep CNN, when used for characterizing\nevery class of 11 datasets. We seek to provide new insights into the behavior\nof CNN features, particularly the ones from convolutional layers, as this can\nbe relevant for their application to knowledge representation and reasoning.\nOur results confirm that low and middle level features may behave differently\nto high level features, but only under certain conditions. We find that all CNN\nfeatures can be used for knowledge representation purposes both by their\npresence or by their absence, doubling the information a single CNN feature may\nprovide. We also study how much noise these features may include, and propose a\nthresholding approach to discard most of it. All these insights have a direct\napplication to the generation of CNN embedding spaces.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 12:23:13 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 14:22:30 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 16:44:14 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 11:56:36 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Garcia-Gasulla", "Dario", ""], ["Par\u00e9s", "Ferran", ""], ["Vilalta", "Armand", ""], ["Moreno", "Jonatan", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jes\u00fas", ""], ["Cort\u00e9s", "Ulises", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "1703.01161", "submitter": "Alexander Vezhnevets", "authors": "Alexander Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess,\n  Max Jaderberg, David Silver, Koray Kavukcuoglu", "title": "FeUdal Networks for Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical\nreinforcement learning. Our approach is inspired by the feudal reinforcement\nlearning proposal of Dayan and Hinton, and gains power and efficacy by\ndecoupling end-to-end learning across multiple levels -- allowing it to utilise\ndifferent resolutions of time. Our framework employs a Manager module and a\nWorker module. The Manager operates at a lower temporal resolution and sets\nabstract goals which are conveyed to and enacted by the Worker. The Worker\ngenerates primitive actions at every tick of the environment. The decoupled\nstructure of FuN conveys several benefits -- in addition to facilitating very\nlong timescale credit assignment it also encourages the emergence of\nsub-policies associated with different goals set by the Manager. These\nproperties allow FuN to dramatically outperform a strong baseline agent on\ntasks that involve long-term credit assignment or memorisation. We demonstrate\nthe performance of our proposed system on a range of tasks from the ATARI suite\nand also from a 3D DeepMind Lab environment.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 14:05:11 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 18:17:18 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Vezhnevets", "Alexander Sasha", ""], ["Osindero", "Simon", ""], ["Schaul", "Tom", ""], ["Heess", "Nicolas", ""], ["Jaderberg", "Max", ""], ["Silver", "David", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1703.01203", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, I.Y. Tyukin", "title": "Stochastic Separation Theorems", "comments": "6 pages, accepted for publication in Neural Networks (Letter section)", "journal-ref": "Neural Networks 94 (2017), 255-259", "doi": "10.1016/j.neunet.2017.07.014", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of non-iterative one-shot and non-destructive correction of\nunavoidable mistakes arises in all Artificial Intelligence applications in the\nreal world. Its solution requires robust separation of samples with errors from\nsamples where the system works properly. We demonstrate that in (moderately)\nhigh dimension this separation could be achieved with probability close to one\nby linear discriminants. Surprisingly, separation of a new image from a very\nlarge set of known images is almost always possible even in moderately high\ndimensions by linear functionals, and coefficients of these functionals can be\nfound explicitly. Based on fundamental properties of measure concentration, we\nshow that for $M<a\\exp(b{n})$ random $M$-element sets in $\\mathbb{R}^n$ are\nlinearly separable with probability $p$, $p>1-\\vartheta$, where $1>\\vartheta>0$\nis a given small constant. Exact values of $a,b>0$ depend on the probability\ndistribution that determines how the random $M$-element sets are drawn, and on\nthe constant $\\vartheta$. These {\\em stochastic separation theorems} provide a\nnew instrument for the development, analysis, and assessment of machine\nlearning methods and algorithms in high dimension. Theoretical statements are\nillustrated with numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:27:38 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 16:47:51 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 17:37:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Gorban", "A. N.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1703.01274", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson and Patrick M. Pilarski", "title": "Actor-Critic Reinforcement Learning with Simultaneous Human Control and\n  Feedback", "comments": "10 pages, 2 pages of references, 8 figures. Under review for the 34th\n  International Conference on Machine Learning, Sydney, Australia, 2017.\n  Copyright 2017 by the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a first study into how different human users deliver\nsimultaneous control and feedback signals during human-robot interaction. As\npart of this work, we formalize and present a general interactive learning\nframework for online cooperation between humans and reinforcement learning\nagents. In many human-machine interaction settings, there is a growing gap\nbetween the degrees-of-freedom of complex semi-autonomous systems and the\nnumber of human control channels. Simple human control and feedback mechanisms\nare required to close this gap and allow for better collaboration between\nhumans and machines on complex tasks. To better inform the design of concurrent\ncontrol and feedback interfaces, we present experimental results from a\nhuman-robot collaborative domain wherein the human must simultaneously deliver\nboth control and feedback signals to interactively train an actor-critic\nreinforcement learning robot. We compare three experimental conditions: 1)\nhuman delivered control signals, 2) reward-shaping feedback signals, and 3)\nsimultaneous control and feedback. Our results suggest that subjects provide\nless feedback when simultaneously delivering feedback and control signals and\nthat control signal quality is not significantly diminished. Our data suggest\nthat subjects may also modify when and how they provide feedback. Through\nalgorithmic development and tuning informed by this study, we expect\nsemi-autonomous actions of robotic agents can be better shaped by human\nfeedback, allowing for seamless collaboration and improved performance in\ndifficult interactive domains.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 18:15:32 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 15:15:14 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1703.01310", "submitter": "Georg Ostrovski", "authors": "Georg Ostrovski, Marc G. Bellemare, Aaron van den Oord, Remi Munos", "title": "Count-Based Exploration with Neural Density Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bellemare et al. (2016) introduced the notion of a pseudo-count, derived from\na density model, to generalize count-based exploration to non-tabular\nreinforcement learning. This pseudo-count was used to generate an exploration\nbonus for a DQN agent and combined with a mixed Monte Carlo update was\nsufficient to achieve state of the art on the Atari 2600 game Montezuma's\nRevenge. We consider two questions left open by their work: First, how\nimportant is the quality of the density model for exploration? Second, what\nrole does the Monte Carlo update play in exploration? We answer the first\nquestion by demonstrating the use of PixelCNN, an advanced neural density model\nfor images, to supply a pseudo-count. In particular, we examine the intrinsic\ndifficulties in adapting Bellemare et al.'s approach when assumptions about the\nmodel are violated. The result is a more practical and general algorithm\nrequiring no special apparatus. We combine PixelCNN pseudo-counts with\ndifferent agent architectures to dramatically improve the state of the art on\nseveral hard Atari games. One surprising finding is that the mixed Monte Carlo\nupdate is a powerful facilitator of exploration in the sparsest of settings,\nincluding Montezuma's Revenge.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 19:07:53 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 13:56:28 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Ostrovski", "Georg", ""], ["Bellemare", "Marc G.", ""], ["Oord", "Aaron van den", ""], ["Munos", "Remi", ""]]}, {"id": "1703.01327", "submitter": "G. Zacharias Holland", "authors": "Kristopher De Asis, J. Fernando Hernandez-Garcia, G. Zacharias\n  Holland, Richard S. Sutton", "title": "Multi-step Reinforcement Learning: A Unifying Algorithm", "comments": "Appeared at the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18)", "journal-ref": "(2018). In AAAI Conference on Artificial Intelligence.\n  https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16294", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unifying seemingly disparate algorithmic ideas to produce better performing\nalgorithms has been a longstanding goal in reinforcement learning. As a primary\nexample, TD($\\lambda$) elegantly unifies one-step TD prediction with Monte\nCarlo methods through the use of eligibility traces and the trace-decay\nparameter $\\lambda$. Currently, there are a multitude of algorithms that can be\nused to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa.\nThese methods are often studied in the one-step case, but they can be extended\nacross multiple time steps to achieve better performance. Each of these\nalgorithms is seemingly distinct, and no one dominates the others for all\nproblems. In this paper, we study a new multi-step action-value algorithm\ncalled $Q(\\sigma)$ which unifies and generalizes these existing algorithms,\nwhile subsuming them as special cases. A new parameter, $\\sigma$, is introduced\nto allow the degree of sampling performed by the algorithm at each step during\nits backup to be continuously varied, with Sarsa existing at one extreme (full\nsampling), and Expected Sarsa existing at the other (pure expectation).\n$Q(\\sigma)$ is generally applicable to both on- and off-policy learning, but in\nthis work we focus on experiments in the on-policy case. Our results show that\nan intermediate value of $\\sigma$, which results in a mixture of the existing\nalgorithms, performs better than either extreme. The mixture can also be varied\ndynamically which can result in even greater performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 20:19:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:01:57 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["De Asis", "Kristopher", ""], ["Hernandez-Garcia", "J. Fernando", ""], ["Holland", "G. Zacharias", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1703.01333", "submitter": "Steve Jan", "authors": "Steve T.K. Jan and Chun Wang and Qing Zhang and Gang Wang", "title": "Towards Monetary Incentives in Social Q&A Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community-based question answering (CQA) services are facing key challenges\nto motivate domain experts to provide timely answers. Recently, CQA services\nare exploring new incentive models to engage experts and celebrities by\nallowing them to set a price on their answers. In this paper, we perform a\ndata-driven analysis on two emerging payment-based CQA systems: Fenda (China)\nand Whale (US). By analyzing a large dataset of 220K questions (worth 1 million\nUSD collectively), we examine how monetary incentives affect different players\nin the system. We find that, while monetary incentive enables quick answers\nfrom experts, it also drives certain users to aggressively game the system for\nprofits. In addition, in this supplier-driven marketplace, users need to\nproactively adjust their price to make profits. Famous people are unwilling to\nlower their price, which in turn hurts their income and engagement over time.\nFinally, we discuss the key implications to future CQA design.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 20:36:38 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 01:48:18 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Jan", "Steve T. K.", ""], ["Wang", "Chun", ""], ["Zhang", "Qing", ""], ["Wang", "Gang", ""]]}, {"id": "1703.01347", "submitter": "Seyoung Yun", "authors": "Se-Young Yun and Jun Hyun Nam and Sangwoo Mo and Jinwoo Shin", "title": "Contextual Multi-armed Bandits under Feature Uncertainty", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual multi-armed bandit problems under linear realizability on\nrewards and uncertainty (or noise) on features. For the case of identical noise\non features across actions, we propose an algorithm, coined {\\em NLinRel},\nhaving $O\\left(T^{\\frac{7}{8}} \\left(\\log{(dT)}+K\\sqrt{d}\\right)\\right)$ regret\nbound for $T$ rounds, $K$ actions, and $d$-dimensional feature vectors. Next,\nfor the case of non-identical noise, we observe that popular linear hypotheses\nincluding {\\em NLinRel} are impossible to achieve such sub-linear regret.\nInstead, under assumption of Gaussian feature vectors, we prove that a greedy\nalgorithm has $O\\left(T^{\\frac23}\\sqrt{\\log d}\\right)$ regret bound with\nrespect to the optimal linear hypothesis. Utilizing our theoretical\nunderstanding on the Gaussian case, we also design a practical variant of {\\em\nNLinRel}, coined {\\em Universal-NLinRel}, for arbitrary feature distributions.\nIt first runs {\\em NLinRel} for finding the `true' coefficient vector using\nfeature uncertainties and then adjust it to minimize its regret using the\nstatistical feature information. We justify the performance of {\\em\nUniversal-NLinRel} on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 21:39:56 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yun", "Se-Young", ""], ["Nam", "Jun Hyun", ""], ["Mo", "Sangwoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1703.01358", "submitter": "Marcus Hutter", "authors": "Sean Lamont and John Aslanides and Jan Leike and Marcus Hutter", "title": "Generalised Discount Functions applied to a Monte-Carlo AImu\n  Implementation", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, work has been done to develop the theory of General\nReinforcement Learning (GRL). However, there are few examples demonstrating\nthese results in a concrete way. In particular, there are no examples\ndemonstrating the known results regarding gener- alised discounting. We have\nadded to the GRL simulation platform AIXIjs the functionality to assign an\nagent arbitrary discount functions, and an environment which can be used to\ndetermine the effect of discounting on an agent's policy. Using this, we\ninvestigate how geometric, hyperbolic and power discounting affect an informed\nagent in a simple MDP. We experimentally reproduce a number of theoretical\nresults, and discuss some related subtleties. It was found that the agent's\nbehaviour followed what is expected theoretically, assuming appropriate\nparameters were chosen for the Monte-Carlo Tree Search (MCTS) planning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 23:25:38 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Lamont", "Sean", ""], ["Aslanides", "John", ""], ["Leike", "Jan", ""], ["Hutter", "Marcus", ""]]}, {"id": "1703.01398", "submitter": "Fangchang Ma", "authors": "Fangchang Ma, Luca Carlone, Ulas Ayaz, Sertac Karaman", "title": "Sparse Depth Sensing for Resource-Constrained Robots", "comments": "35 pages, 31 figures, 2 tables; added new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the case in which a robot has to navigate in an unknown\nenvironment but does not have enough on-board power or payload to carry a\ntraditional depth sensor (e.g., a 3D lidar) and thus can only acquire a few\n(point-wise) depth measurements. We address the following question: is it\npossible to reconstruct the geometry of an unknown environment using sparse and\nincomplete depth measurements? Reconstruction from incomplete data is not\npossible in general, but when the robot operates in man-made environments, the\ndepth exhibits some regularity (e.g., many planar surfaces with only a few\nedges); we leverage this regularity to infer depth from a small number of\nmeasurements. Our first contribution is a formulation of the depth\nreconstruction problem that bridges robot perception with the compressive\nsensing literature in signal processing. The second contribution includes a set\nof formal results that ascertain the exactness and stability of the depth\nreconstruction in 2D and 3D problems, and completely characterize the geometry\nof the profiles that we can reconstruct. Our third contribution is a set of\npractical algorithms for depth reconstruction: our formulation directly\ntranslates into algorithms for depth estimation based on convex programming. In\nreal-world problems, these convex programs are very large and general-purpose\nsolvers are relatively slow. For this reason, we discuss ad-hoc solvers that\nenable fast depth reconstruction in real problems. The last contribution is an\nextensive experimental evaluation in 2D and 3D problems, including Monte Carlo\nruns on simulated instances and testing on multiple real datasets. Empirical\nresults confirm that the proposed approach ensures accurate depth\nreconstruction, outperforms interpolation-based strategies, and performs well\neven when the assumption of structured environment is violated.\n", "versions": [{"version": "v1", "created": "Sat, 4 Mar 2017 05:20:30 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 04:12:34 GMT"}, {"version": "v3", "created": "Sun, 15 Oct 2017 05:02:51 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Ma", "Fangchang", ""], ["Carlone", "Luca", ""], ["Ayaz", "Ulas", ""], ["Karaman", "Sertac", ""]]}, {"id": "1703.01671", "submitter": "Virgile Landeiro", "authors": "Virgile Landeiro, Aron Culotta", "title": "Controlling for Unobserved Confounds in Classification Using\n  Correlational Constraints", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As statistical classifiers become integrated into real-world applications, it\nis important to consider not only their accuracy but also their robustness to\nchanges in the data distribution. In this paper, we consider the case where\nthere is an unobserved confounding variable $z$ that influences both the\nfeatures $\\mathbf{x}$ and the class variable $y$. When the influence of $z$\nchanges from training to testing data, we find that the classifier accuracy can\ndegrade rapidly. In our approach, we assume that we can predict the value of\n$z$ at training time with some error. The prediction for $z$ is then fed to\nPearl's back-door adjustment to build our model. Because of the attenuation\nbias caused by measurement error in $z$, standard approaches to controlling for\n$z$ are ineffective. In response, we propose a method to properly control for\nthe influence of $z$ by first estimating its relationship with the class\nvariable $y$, then updating predictions for $z$ to match that estimated\nrelationship. By adjusting the influence of $z$, we show that we can build a\nmodel that exceeds competing baselines on accuracy as well as on robustness\nover a range of confounding relationships.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 21:57:25 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 15:35:43 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Landeiro", "Virgile", ""], ["Culotta", "Aron", ""]]}, {"id": "1703.01697", "submitter": "David Billington", "authors": "David Billington", "title": "Principles and Examples of Plausible Reasoning and Propositional\n  Plausible Logic", "comments": "58 pages. Updated n-die examples to n-lottery examples. Example 3.4\n  simplified. In Section 4 counter-example to the Or-rule changed and\n  corrected, and a new logic (PTL) considered", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plausible reasoning concerns situations whose inherent lack of precision is\nnot quantified; that is, there are no degrees or levels of precision, and hence\nno use of numbers like probabilities. A hopefully comprehensive set of\nprinciples that clarifies what it means for a formal logic to do plausible\nreasoning is presented. A new propositional logic, called Propositional\nPlausible Logic (PPL), is defined and applied to some important examples. PPL\nis the only non-numeric non-monotonic logic we know of that satisfies all the\nprinciples and correctly reasons with all the examples. Some important results\nabout PPL are proved.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 00:53:04 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 23:42:12 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Billington", "David", ""]]}, {"id": "1703.01720", "submitter": "Ashwin Vijayakumar", "authors": "Ashwin K Vijayakumar, Ramakrishna Vedantam, Devi Parikh", "title": "Sound-Word2Vec: Learning Word Representations Grounded in Sounds", "comments": "Accepted at EMNLP 2017. Contains 6 pages; 3 tables; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be able to interact better with humans, it is crucial for machines to\nunderstand sound - a primary modality of human perception. Previous works have\nused sound to learn embeddings for improved generic textual similarity\nassessment. In this work, we treat sound as a first-class citizen, studying\ndownstream textual tasks which require aural grounding. To this end, we propose\nsound-word2vec - a new embedding scheme that learns specialized word embeddings\ngrounded in sounds. For example, we learn that two seemingly (semantically)\nunrelated concepts, like leaves and paper are similar due to the similar\nrustling sounds they make. Our embeddings prove useful in textual tasks\nrequiring aural reasoning like text-based sound retrieval and discovering foley\nsound effects (used in movies). Moreover, our embedding space captures\ninteresting dependencies between words and onomatopoeia and outperforms prior\nwork on aurally-relevant word relatedness datasets such as AMEN and ASLex.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 04:30:12 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 06:35:16 GMT"}, {"version": "v3", "created": "Thu, 10 Aug 2017 04:26:57 GMT"}, {"version": "v4", "created": "Tue, 29 Aug 2017 15:54:31 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Vijayakumar", "Ashwin K", ""], ["Vedantam", "Ramakrishna", ""], ["Parikh", "Devi", ""]]}, {"id": "1703.01893", "submitter": "He Jiang", "authors": "He Jiang, Shuwei Zhang, Zhilei Ren, Xiaochen Lai, Yong Piao", "title": "Approximate Muscle Guided Beam Search for Three-Index Assignment Problem", "comments": "9 pages, 3 figures, Proceedings of the Fifth International Conference\n  on Swarm Intelligence, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a well-known NP-hard problem, the Three-Index Assignment Problem (AP3) has\nattracted lots of research efforts for developing heuristics. However, existing\nheuristics either obtain less competitive solutions or consume too much time.\nIn this paper, a new heuristic named Approximate Muscle guided Beam Search\n(AMBS) is developed to achieve a good trade-off between solution quality and\nrunning time. By combining the approximate muscle with beam search, the\nsolution space size can be significantly decreased, thus the time for searching\nthe solution can be sharply reduced. Extensive experimental results on the\nbenchmark indicate that the new algorithm is able to obtain solutions with\ncompetitive quality and it can be employed on instances with largescale. Work\nof this paper not only proposes a new efficient heuristic, but also provides a\npromising method to improve the efficiency of beam search.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:30:06 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Jiang", "He", ""], ["Zhang", "Shuwei", ""], ["Ren", "Zhilei", ""], ["Lai", "Xiaochen", ""], ["Piao", "Yong", ""]]}, {"id": "1703.01908", "submitter": "Christopher A. Tucker", "authors": "Christopher A. Tucker", "title": "A proposal for ethically traceable artificial intelligence", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the problem of a critique of robotic behavior in near-unanimous\nagreement to human norms seems intractable, a starting point of such an\nambition is a framework of the collection of knowledge a priori and experience\na posteriori categorized as a set of synthetical judgments available to the\nintelligence, translated into computer code. If such a proposal were\nsuccessful, an algorithm with ethically traceable behavior and cogent\nequivalence to human cognition is established. This paper will propose the\napplication of Kant's critique of reason to current programming constructs of\nan autonomous intelligent system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:54:19 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 09:15:49 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Tucker", "Christopher A.", ""]]}, {"id": "1703.01918", "submitter": "Ronald Kemker", "authors": "Ronald Kemker, Carl Salvaggio, and Christopher Kanan", "title": "High-Resolution Multispectral Dataset for Semantic Segmentation", "comments": "9 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aircraft have decreased the cost required to collect remote sensing\nimagery, which has enabled researchers to collect high-spatial resolution data\nfrom multiple sensor modalities more frequently and easily. The increase in\ndata will push the need for semantic segmentation frameworks that are able to\nclassify non-RGB imagery, but this type of algorithmic development requires an\nincrease in publicly available benchmark datasets with class labels. In this\npaper, we introduce a high-resolution multispectral dataset with image labels.\nThis new benchmark dataset has been pre-split into training/testing folds in\norder to standardize evaluation and continue to push state-of-the-art\nclassification frameworks for non-RGB imagery.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:16:56 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Kemker", "Ronald", ""], ["Salvaggio", "Carl", ""], ["Kanan", "Christopher", ""]]}, {"id": "1703.01924", "submitter": "Arthur Van Camp", "authors": "Arthur Van Camp, Gert de Cooman", "title": "Exchangeable choice functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how to model exchangeability with choice functions.\nExchangeability is a structural assessment on a sequence of uncertain\nvariables. We show how such assessments are a special indifference assessment,\nand how that leads to a counterpart of de Finetti's Representation Theorem,\nboth in a finite and a countable context.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:34:54 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Van Camp", "Arthur", ""], ["de Cooman", "Gert", ""]]}, {"id": "1703.01946", "submitter": "Oier Mees", "authors": "Oier Mees, Nichola Abdo, Mladen Mazuran, Wolfram Burgard", "title": "Metric Learning for Generalizing Spatial Relations to New Objects", "comments": "Accepted at the 2017 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems. The new Freiburg Spatial Relations Dataset and a demo\n  video of our approach running on the PR-2 robot are available at our project\n  website: http://spatialrelations.cs.uni-freiburg.de", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-centered environments are rich with a wide variety of spatial relations\nbetween everyday objects. For autonomous robots to operate effectively in such\nenvironments, they should be able to reason about these relations and\ngeneralize them to objects with different shapes and sizes. For example, having\nlearned to place a toy inside a basket, a robot should be able to generalize\nthis concept using a spoon and a cup. This requires a robot to have the\nflexibility to learn arbitrary relations in a lifelong manner, making it\nchallenging for an expert to pre-program it with sufficient knowledge to do so\nbeforehand. In this paper, we address the problem of learning spatial relations\nby introducing a novel method from the perspective of distance metric learning.\nOur approach enables a robot to reason about the similarity between pairwise\nspatial relations, thereby enabling it to use its previous knowledge when\npresented with a new relation to imitate. We show how this makes it possible to\nlearn arbitrary spatial relations from non-expert users using a small number of\nexamples and in an interactive manner. Our extensive evaluation with real-world\ndata demonstrates the effectiveness of our method in reasoning about a\ncontinuous spectrum of spatial relations and generalizing them to new objects.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:13:17 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 12:47:56 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 12:24:31 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Mees", "Oier", ""], ["Abdo", "Nichola", ""], ["Mazuran", "Mladen", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1703.01963", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "A new belief Markov chain model and its application in inventory\n  prediction", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov chain model is widely applied in many fields, especially the field of\nprediction. The classical Discrete-time Markov chain(DTMC) is a widely used\nmethod for prediction. However, the classical DTMC model has some limitation\nwhen the system is complex with uncertain information or state space is not\ndiscrete. To address it, a new belief Markov chain model is proposed by\ncombining Dempster-Shafer evidence theory with Markov chain. In our model, the\nuncertain data is allowed to be handle in the form of interval number and the\nbasic probability assignment(BPA) is generated based on the distance between\ninterval numbers. The new belief Markov chain model overcomes the shortcomings\nof classical Markov chain and has an efficient ability in dealing with\nuncertain information. Moreover, an example of inventory prediction and the\ncomparison between our model and classical DTMC model can show the\neffectiveness and rationality of our proposed model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:43:13 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.01971", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "Evidential supplier selection based on interval data fusion", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supplier selection is a typical multi-criteria decision making (MCDM) problem\nand lots of uncertain information exist inevitably. To address this issue, a\nnew method was proposed based on interval data fusion. Our method follows the\noriginal way to generate classical basic probability assignment(BPA) determined\nby the distance among the evidences. However, the weights of criteria are kept\nas interval numbers to generate interval BPAs and do the fusion of interval\nBPAs. Finally, the order is ranked and the decision is made according to the\nobtained interval BPAs. In this paper, a numerical example of supplier\nselection is applied to verify the feasibility and validity of our method. The\nnew method is presented aiming at solving multiple-criteria decision-making\nproblems in which the weights of criteria or experts are described in fuzzy\ndata like linguistic terms or interval data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:54:12 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.02000", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang,\n  Yong Yu, Jun Wang", "title": "Activation Maximization Generative Adversarial Nets", "comments": "Accepted as a conference paper on ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class labels have been empirically shown useful in improving the sample\nquality of generative adversarial nets (GANs). In this paper, we mathematically\nstudy the properties of the current variants of GANs that make use of class\nlabel information. With class aware gradient and cross-entropy decomposition,\nwe reveal how class labels and associated losses influence GAN's training.\nBased on that, we propose Activation Maximization Generative Adversarial\nNetworks (AM-GAN) as an advanced solution. Comprehensive experiments have been\nconducted to validate our analysis and evaluate the effectiveness of our\nsolution, where AM-GAN outperforms other strong baselines and achieves\nstate-of-the-art Inception Score (8.91) on CIFAR-10. In addition, we\ndemonstrate that, with the Inception ImageNet classifier, Inception Score\nmainly tracks the diversity of the generator, and there is, however, no\nreliable evidence that it can reflect the true sample quality. We thus propose\na new metric, called AM Score, to provide a more accurate estimation of the\nsample quality. Our proposed model also outperforms the baseline methods in the\nnew metric.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:42:55 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 16:33:55 GMT"}, {"version": "v3", "created": "Tue, 1 Aug 2017 15:32:29 GMT"}, {"version": "v4", "created": "Wed, 2 Aug 2017 16:56:07 GMT"}, {"version": "v5", "created": "Sat, 5 Aug 2017 08:17:04 GMT"}, {"version": "v6", "created": "Wed, 8 Nov 2017 13:49:19 GMT"}, {"version": "v7", "created": "Tue, 30 Jan 2018 18:28:35 GMT"}, {"version": "v8", "created": "Wed, 11 Jul 2018 05:43:27 GMT"}, {"version": "v9", "created": "Fri, 16 Nov 2018 07:18:19 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Zhou", "Zhiming", ""], ["Cai", "Han", ""], ["Rong", "Shu", ""], ["Song", "Yuxuan", ""], ["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1703.02100", "submitter": "Yatao A. Bian", "authors": "Andrew An Bian, Joachim M. Buhmann, Andreas Krause, Sebastian\n  Tschiatschek", "title": "Guarantees for Greedy Maximization of Non-submodular Functions with\n  Applications", "comments": "published at ICML 2017. First author is now known as Yatao Bian\n  <ybian@inf.ethz.ch>. ORCID: https://orcid.org/0000-0002-2368-4084", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance of the standard Greedy algorithm for\ncardinality constrained maximization of non-submodular nondecreasing set\nfunctions. While there are strong theoretical guarantees on the performance of\nGreedy for maximizing submodular functions, there are few guarantees for\nnon-submodular ones. However, Greedy enjoys strong empirical performance for\nmany important non-submodular functions, e.g., the Bayesian A-optimality\nobjective in experimental design. We prove theoretical guarantees supporting\nthe empirical performance. Our guarantees are characterized by a combination of\nthe (generalized) curvature $\\alpha$ and the submodularity ratio $\\gamma$. In\nparticular, we prove that Greedy enjoys a tight approximation guarantee of\n$\\frac{1}{\\alpha}(1- e^{-\\gamma\\alpha})$ for cardinality constrained\nmaximization. In addition, we bound the submodularity ratio and curvature for\nseveral important real-world objectives, including the Bayesian A-optimality\nobjective, the determinantal function of a square submatrix and certain linear\nprograms with combinatorial constraints. We experimentally validate our\ntheoretical findings for both synthetic and real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 20:28:23 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 07:51:03 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 08:22:12 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 12:37:18 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bian", "Andrew An", ""], ["Buhmann", "Joachim M.", ""], ["Krause", "Andreas", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "1703.02156", "submitter": "Jiaming Song", "authors": "Jiaming Song, Russell Stewart, Shengjia Zhao and Stefano Ermon", "title": "On the Limits of Learning Representations with Label-Based Supervision", "comments": "Submitted to ICLR 2017 Workshop Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in neural network based classifiers have transformed automatic\nfeature learning from a pipe dream of stronger AI to a routine and expected\nproperty of practical systems. Since the emergence of AlexNet every winning\nsubmission of the ImageNet challenge has employed end-to-end representation\nlearning, and due to the utility of good representations for transfer learning,\nrepresentation learning has become as an important and distinct task from\nsupervised learning. At present, this distinction is inconsequential, as\nsupervised methods are state-of-the-art in learning transferable\nrepresentations. But recent work has shown that generative models can also be\npowerful agents of representation learning. Will the representations learned\nfrom these generative methods ever rival the quality of those from their\nsupervised competitors? In this work, we argue in the affirmative, that from an\ninformation theoretic perspective, generative models have greater potential for\nrepresentation learning. Based on several experimentally validated assumptions,\nwe show that supervised learning is upper bounded in its capacity for\nrepresentation learning in ways that certain generative models, such as\nGenerative Adversarial Networks (GANs) are not. We hope that our analysis will\nprovide a rigorous motivation for further exploration of generative\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 00:09:31 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Song", "Jiaming", ""], ["Stewart", "Russell", ""], ["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "1703.02192", "submitter": "EPTCS", "authors": "Thomas Bolander", "title": "A Gentle Introduction to Epistemic Planning: The DEL Approach", "comments": "In Proceedings M4M9 2017, arXiv:1703.01736", "journal-ref": "EPTCS 243, 2017, pp. 1-22", "doi": "10.4204/EPTCS.243.1", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic planning can be used for decision making in multi-agent situations\nwith distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has\nbeen shown to provide a very natural and expressive framework for epistemic\nplanning. In this paper, we aim to give an accessible introduction to DEL-based\nepistemic planning. The paper starts with the most classical framework for\nplanning, STRIPS, and then moves towards epistemic planning in a number of\nsmaller steps, where each step is motivated by the need to be able to model\nmore complex planning scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:15:08 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Bolander", "Thomas", ""]]}, {"id": "1703.02196", "submitter": "EPTCS", "authors": "Thorsten Engesser (Albert-Ludwigs-Universit\\\"at Freiburg), Thomas\n  Bolander (Technical University of Denmark), Robert Mattm\\\"uller\n  (Albert-Ludwigs-Universit\\\"at Freiburg), Bernhard Nebel\n  (Albert-Ludwigs-Universit\\\"at Freiburg)", "title": "Cooperative Epistemic Multi-Agent Planning for Implicit Coordination", "comments": "In Proceedings M4M9 2017, arXiv:1703.01736", "journal-ref": "EPTCS 243, 2017, pp. 75-90", "doi": "10.4204/EPTCS.243.6", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epistemic planning can be used for decision making in multi-agent situations\nwith distributed knowledge and capabilities. Recently, Dynamic Epistemic Logic\n(DEL) has been shown to provide a very natural and expressive framework for\nepistemic planning. We extend the DEL-based epistemic planning framework to\ninclude perspective shifts, allowing us to define new notions of sequential and\nconditional planning with implicit coordination. With these, it is possible to\nsolve planning tasks with joint goals in a decentralized manner without the\nagents having to negotiate about and commit to a joint policy at plan time.\nFirst we define the central planning notions and sketch the implementation of a\nplanning system built on those notions. Afterwards we provide some case studies\nin order to evaluate the planner empirically and to show that the concept is\nuseful for multi-agent systems in practice.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 03:16:22 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Engesser", "Thorsten", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"], ["Bolander", "Thomas", "", "Technical University of Denmark"], ["Mattm\u00fcller", "Robert", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"], ["Nebel", "Bernhard", "", "Albert-Ludwigs-Universit\u00e4t Freiburg"]]}, {"id": "1703.02239", "submitter": "Katsunari Shibata", "authors": "Katsunari Shibata", "title": "Functions that Emerge through End-to-End Reinforcement Learning - The\n  Direction for Artificial General Intelligence -", "comments": "The Multi-disciplinary Conference on Reinforcement Learning and\n  Decision Making (RLDM) 2017, 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, triggered by the impressive results in TV-games or game of Go by\nGoogle DeepMind, end-to-end reinforcement learning (RL) is collecting\nattentions. Although little is known, the author's group has propounded this\nframework for around 20 years and already has shown various functions that\nemerge in a neural network (NN) through RL. In this paper, they are introduced\nagain at this timing.\n  \"Function Modularization\" approach is deeply penetrated subconsciously. The\ninputs and outputs for a learning system can be raw sensor signals and motor\ncommands. \"State space\" or \"action space\" generally used in RL show the\nexistence of functional modules. That has limited reinforcement learning to\nlearning only for the action-planning module. In order to extend reinforcement\nlearning to learning of the entire function on a huge degree of freedom of a\nmassively parallel learning system and to explain or develop human-like\nintelligence, the author has believed that end-to-end RL from sensors to motors\nusing a recurrent NN (RNN) becomes an essential key. Especially in the higher\nfunctions, this approach is very effective by being free from the need to\ndecide their inputs and outputs.\n  The functions that emerge, we have confirmed, through RL using a NN cover a\nbroad range from real robot learning with raw camera pixel inputs to\nacquisition of dynamic functions in a RNN. Those are (1)image recognition,\n(2)color constancy (optical illusion), (3)sensor motion (active recognition),\n(4)hand-eye coordination and hand reaching movement, (5)explanation of brain\nactivities, (6)communication, (7)knowledge transfer, (8)memory, (9)selective\nattention, (10)prediction, (11)exploration. The end-to-end RL enables the\nemergence of very flexible comprehensive functions that consider many things in\nparallel although it is difficult to give the boundary of each function\nclearly.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 06:51:19 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 07:22:07 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Shibata", "Katsunari", ""]]}, {"id": "1703.02245", "submitter": "Nima Dehghani", "authors": "Nima Dehghani", "title": "Design of the Artificial: lessons from the biological roots of general\n  intelligence", "comments": "Theoretical perspective on AGI (Artificial General Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our desire and fascination with intelligent machines dates back to the\nantiquity's mythical automaton Talos, Aristotle's mode of mechanical thought\n(syllogism) and Heron of Alexandria's mechanical machines and automata.\nHowever, the quest for Artificial General Intelligence (AGI) is troubled with\nrepeated failures of strategies and approaches throughout the history. This\ndecade has seen a shift in interest towards bio-inspired software and hardware,\nwith the assumption that such mimicry entails intelligence. Though these steps\nare fruitful in certain directions and have advanced automation, their singular\ndesign focus renders them highly inefficient in achieving AGI. Which set of\nrequirements have to be met in the design of AGI? What are the limits in the\ndesign of the artificial? Here, a careful examination of computation in\nbiological systems hints that evolutionary tinkering of contextual processing\nof information enabled by a hierarchical architecture is the key to build AGI.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:20:30 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 15:29:05 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Dehghani", "Nima", ""]]}, {"id": "1703.02310", "submitter": "Shirli Di-Castro Shashua", "authors": "Shirli Di-Castro Shashua, Shie Mannor", "title": "Deep Robust Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Robust Markov Decision Process (RMDP) is a sequential decision making model\nthat accounts for uncertainty in the parameters of dynamic systems. This\nuncertainty introduces difficulties in learning an optimal policy, especially\nfor environments with large state spaces. We propose two algorithms, RTD-DQN\nand Deep-RoK, for solving large-scale RMDPs using nonlinear approximation\nschemes such as deep neural networks. The RTD-DQN algorithm incorporates the\nrobust Bellman temporal difference error into a robust loss function, yielding\nrobust policies for the agent. The Deep-RoK algorithm is a robust Bayesian\nmethod, based on the Extended Kalman Filter (EKF), that accounts for both the\nuncertainty in the weights of the approximated value function and the\nuncertainty in the transition probabilities, improving the robustness of the\nagent. We provide theoretical results for our approach and test the proposed\nalgorithms on a continuous state domain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 10:16:45 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Shashua", "Shirli Di-Castro", ""], ["Mannor", "Shie", ""]]}, {"id": "1703.02386", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "A quantum dynamic belief decision making model", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sure thing principle and the law of total probability are basic laws in\nclassic probability theory. A disjunction fallacy leads to the violation of\nthese two classical probability laws. In this paper, a new quantum dynamic\nbelief decision making model based on quantum dynamic modelling and\nDempster-Shafer (D-S) evidence theory is proposed to address this issue and\nmodel the real human decision-making process. Some mathematical techniques are\nborrowed from quantum mathematics. Generally, belief and action are two parts\nin a decision making process. The uncertainty in belief part is represented by\na superposition of certain states. The uncertainty in actions is represented as\nan extra uncertainty state. The interference effect is produced due to the\nentanglement between beliefs and actions. Basic probability assignment (BPA) of\ndecisions is generated by quantum dynamic modelling. Then BPA of the extra\nuncertain state and an entanglement degree defined by an entropy function named\nDeng entropy are used to measure the interference effect. Compared the existing\nmodel, the number of free parameters is less in our model. Finally, a classical\ncategorization decision-making experiment is illustrated to show the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:30:08 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.02507", "submitter": "Martin Jaggi", "authors": "Matteo Pagliardini, Prakhar Gupta, Martin Jaggi", "title": "Unsupervised Learning of Sentence Embeddings using Compositional n-Gram\n  Features", "comments": "NAACL 2018", "journal-ref": "NAACL 2018 - Conference of the North American Chapter of the\n  Association for Computational Linguistics, pages 528-540", "doi": "10.18653/v1/N18-1049", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent tremendous success of unsupervised word embeddings in a multitude\nof applications raises the obvious question if similar methods could be derived\nto improve embeddings (i.e. semantic representations) of word sequences as\nwell. We present a simple but efficient unsupervised objective to train\ndistributed representations of sentences. Our method outperforms the\nstate-of-the-art unsupervised models on most benchmark tasks, highlighting the\nrobustness of the produced general-purpose sentence embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 18:19:11 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 18:05:48 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 15:12:58 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Pagliardini", "Matteo", ""], ["Gupta", "Prakhar", ""], ["Jaggi", "Martin", ""]]}, {"id": "1703.02610", "submitter": "Mikko Lauri", "authors": "Mikko Lauri, Eero Hein\\\"anen, Simone Frintrop", "title": "Multi-Robot Active Information Gathering with Periodic Communication", "comments": "IEEE International Conference on Robotics and Automation (ICRA), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A team of robots sharing a common goal can benefit from coordination of the\nactivities of team members, helping the team to reach the goal more reliably or\nquickly. We address the problem of coordinating the actions of a team of robots\nwith periodic communication capability executing an information gathering task.\nWe cast the problem as a multi-agent optimal decision-making problem with an\ninformation theoretic objective function. We show that appropriate techniques\nfor solving decentralized partially observable Markov decision processes\n(Dec-POMDPs) are applicable in such information gathering problems. We quantify\nthe usefulness of coordinated information gathering through simulation studies,\nand demonstrate the feasibility of the method in a real-world target tracking\ndomain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 21:53:44 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Lauri", "Mikko", ""], ["Hein\u00e4nen", "Eero", ""], ["Frintrop", "Simone", ""]]}, {"id": "1703.02645", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Alexandros G. Dimakis and Sriram Vishwanath", "title": "Cost-Optimal Learning of Causal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a causal graph over a set of variables\nwith interventions. We study the cost-optimal causal graph learning problem:\nFor a given skeleton (undirected version of the causal graph), design the set\nof interventions with minimum total cost, that can uniquely identify any causal\ngraph with the given skeleton. We show that this problem is solvable in\npolynomial time. Later, we consider the case when the number of interventions\nis limited. For this case, we provide polynomial time algorithms when the\nskeleton is a tree or a clique tree. For a general chordal skeleton, we develop\nan efficient greedy algorithm, which can be improved when the causal graph\nskeleton is an interval graph.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 00:15:54 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1703.02660", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Kendall Lowrey, Emanuel Todorov, Sham Kakade", "title": "Towards Generalization and Simplicity in Continuous Control", "comments": "NIPS 2017, Project page: https://sites.google.com/view/simple-pol", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows that policies with simple linear and RBF parameterizations\ncan be trained to solve a variety of continuous control tasks, including the\nOpenAI gym benchmarks. The performance of these trained policies are\ncompetitive with state of the art results, obtained with more elaborate\nparameterizations such as fully connected neural networks. Furthermore,\nexisting training and testing scenarios are shown to be very limited and prone\nto over-fitting, thus giving rise to only trajectory-centric policies. Training\nwith a diverse initial state distribution is shown to produce more global\npolicies with better generalization. This allows for interactive control\nscenarios where the system recovers from large on-line perturbations; as shown\nin the supplementary video.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 01:33:51 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 05:17:11 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Lowrey", "Kendall", ""], ["Todorov", "Emanuel", ""], ["Kakade", "Sham", ""]]}, {"id": "1703.02702", "submitter": "Lerrel Pinto Mr", "authors": "Lerrel Pinto, James Davidson, Rahul Sukthankar and Abhinav Gupta", "title": "Robust Adversarial Reinforcement Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks coupled with fast simulation and improved computation\nhave led to recent successes in the field of reinforcement learning (RL).\nHowever, most current RL-based approaches fail to generalize since: (a) the gap\nbetween simulation and real world is so large that policy-learning approaches\nfail to transfer; (b) even if policy learning is done in real world, the data\nscarcity leads to failed generalization from training to test scenarios (e.g.,\ndue to different friction or object masses). Inspired from H-infinity control\nmethods, we note that both modeling errors and differences in training and test\nscenarios can be viewed as extra forces/disturbances in the system. This paper\nproposes the idea of robust adversarial reinforcement learning (RARL), where we\ntrain an agent to operate in the presence of a destabilizing adversary that\napplies disturbance forces to the system. The jointly trained adversary is\nreinforced -- that is, it learns an optimal destabilization policy. We\nformulate the policy learning as a zero-sum, minimax objective function.\nExtensive experiments in multiple environments (InvertedPendulum, HalfCheetah,\nSwimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)\nimproves training stability; (b) is robust to differences in training/test\nconditions; and c) outperform the baseline even in the absence of the\nadversary.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 04:58:51 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Pinto", "Lerrel", ""], ["Davidson", "James", ""], ["Sukthankar", "Rahul", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1703.02810", "submitter": "Evangelos Michelioudakis", "authors": "Alain Kibangou and Alexander Artikis and Evangelos Michelioudakis and\n  Georgios Paliouras and Marius Schmitt and John Lygeros and Chris Baber and\n  Natan Morar and Fabiana Fournier and Inna Skarbovsky", "title": "An Integrated and Scalable Platform for Proactive Event-Driven Traffic\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic on freeways can be managed by means of ramp meters from Road Traffic\nControl rooms. Human operators cannot efficiently manage a network of ramp\nmeters. To support them, we present an intelligent platform for traffic\nmanagement which includes a new ramp metering coordination scheme in the\ndecision making module, an efficient dashboard for interacting with human\noperators, machine learning tools for learning event definitions and Complex\nEvent Processing tools able to deal with uncertainties inherent to the traffic\nuse case. Unlike the usual approach, the devised event-driven platform is able\nto predict a congestion up to 4 minutes before it really happens. Proactive\ndecision making can then be established leading to significant improvement of\ntraffic conditions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 12:35:52 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Kibangou", "Alain", ""], ["Artikis", "Alexander", ""], ["Michelioudakis", "Evangelos", ""], ["Paliouras", "Georgios", ""], ["Schmitt", "Marius", ""], ["Lygeros", "John", ""], ["Baber", "Chris", ""], ["Morar", "Natan", ""], ["Fournier", "Fabiana", ""], ["Skarbovsky", "Inna", ""]]}, {"id": "1703.02819", "submitter": "Dmitry Ignatov", "authors": "Dmitry I. Ignatov", "title": "Introduction to Formal Concept Analysis and Its Applications in\n  Information Retrieval and Related Fields", "comments": null, "journal-ref": "RuSSIR 2014, Nizhniy Novgorod, Russia, CCIS vol. 505, Springer\n  42-141", "doi": "10.1007/978-3-319-25485-2_3", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a tutorial on Formal Concept Analysis (FCA) and its\napplications. FCA is an applied branch of Lattice Theory, a mathematical\ndiscipline which enables formalisation of concepts as basic units of human\nthinking and analysing data in the object-attribute form. Originated in early\n80s, during the last three decades, it became a popular human-centred tool for\nknowledge representation and data analysis with numerous applications. Since\nthe tutorial was specially prepared for RuSSIR 2014, the covered FCA topics\ninclude Information Retrieval with a focus on visualisation aspects, Machine\nLearning, Data Mining and Knowledge Discovery, Text Mining and several others.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 12:53:21 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Ignatov", "Dmitry I.", ""]]}, {"id": "1703.02883", "submitter": "Hadi Zare", "authors": "Kayvan Bijari, Hadi Zare, Hadi Veisi, Hossein Bobarshad", "title": "Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data\n  Clustering", "comments": "17 pages, 3 figures, 8 tables", "journal-ref": "Neural Comput & Applic (2016)", "doi": "10.1007/s00521-016-2528-9", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis plays an important role in decision making process for many\nknowledge-based systems. There exist a wide variety of different approaches for\nclustering applications including the heuristic techniques, probabilistic\nmodels, and traditional hierarchical algorithms. In this paper, a novel\nheuristic approach based on big bang-big crunch algorithm is proposed for\nclustering problems. The proposed method not only takes advantage of heuristic\nnature to alleviate typical clustering algorithms such as k-means, but it also\nbenefits from the memory based scheme as compared to its similar heuristic\ntechniques. Furthermore, the performance of the proposed algorithm is\ninvestigated based on several benchmark test functions as well as on the\nwell-known datasets. The experimental results show the significant superiority\nof the proposed method over the similar algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 15:50:35 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Bijari", "Kayvan", ""], ["Zare", "Hadi", ""], ["Veisi", "Hadi", ""], ["Bobarshad", "Hossein", ""]]}, {"id": "1703.02894", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "A quantum dynamic belief model to explain the interference effects of\n  categorization on decision making", "comments": "28 pages. arXiv admin note: text overlap with arXiv:1703.02386", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Categorization is necessary for many decision making tasks. However, the\ncategorization process may interfere the decision making result and the law of\ntotal probability can be violated in some situations. To predict the\ninterference effect of categorization, some model based on quantum probability\nhas been proposed. In this paper, a new quantum dynamic belief (QDB) model is\nproposed. Considering the precise decision may not be made during the process,\nthe concept of uncertainty is introduced in our model to simulate real human\nthinking process. Then the interference effect categorization can be predicted\nby handling the uncertain information. The proposed model is applied to a\ncategorization decision-making experiment to explain the interference effect of\ncategorization. Compared with other models, our model is relatively more\nsuccinct and the result shows the correctness and effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:52:07 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.02905", "submitter": "Visak Chadalavada Vijay Kumar", "authors": "Visak CV Kumar, Sehoon Ha and C Karen Liu", "title": "Learning a Unified Control Policy for Safe Falling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to fall safely is a necessary motor skill for humanoids performing\nhighly dynamic tasks, such as running and jumping. We propose a new method to\nlearn a policy that minimizes the maximal impulse during the fall. The\noptimization solves for both a discrete contact planning problem and a\ncontinuous optimal control problem. Once trained, the policy can compute the\noptimal next contacting body part (e.g. left foot, right foot, or hands),\ncontact location and timing, and the required joint actuation. We represent the\npolicy as a mixture of actor-critic neural network, which consists of n control\npolicies and the corresponding value functions. Each pair of actor-critic is\nassociated with one of the n possible contacting body parts. During execution,\nthe policy corresponding to the highest value function will be executed while\nthe associated body part will be the next contact with the ground. With this\nmixture of actor-critic architecture, the discrete contact sequence planning is\nsolved through the selection of the best critics while the continuous control\nproblem is solved by the optimization of actors. We show that our policy can\nachieve comparable, sometimes even higher, rewards than a recursive search of\nthe action space using dynamic programming, while enjoying 50 to 400 times of\nspeed gain during online execution.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 16:38:21 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 15:17:35 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Kumar", "Visak CV", ""], ["Ha", "Sehoon", ""], ["Liu", "C Karen", ""]]}, {"id": "1703.02949", "submitter": "Coline Devin", "authors": "Abhishek Gupta, Coline Devin, YuXuan Liu, Pieter Abbeel, Sergey Levine", "title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement\n  Learning", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People can learn a wide range of tasks from their own experience, but can\nalso learn from observing other creatures. This can accelerate acquisition of\nnew skills even when the observed agent differs substantially from the learning\nagent in terms of morphology. In this paper, we examine how reinforcement\nlearning algorithms can transfer knowledge between morphologically different\nagents (e.g., different robots). We introduce a problem formulation where two\nagents are tasked with learning multiple skills by sharing information. Our\nmethod uses the skills that were learned by both agents to train invariant\nfeature spaces that can then be used to transfer other skills from one agent to\nanother. The process of learning these invariant feature spaces can be viewed\nas a kind of \"analogy making\", or implicit learning of partial correspondences\nbetween two distinct domains. We evaluate our transfer learning algorithm in\ntwo simulated robotic manipulation skills, and illustrate that we can transfer\nknowledge between simulated robotic arms with different numbers of links, as\nwell as simulated arms with different actuation mechanisms, where one robot is\ntorque-driven while the other is tendon-driven.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 18:09:32 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Gupta", "Abhishek", ""], ["Devin", "Coline", ""], ["Liu", "YuXuan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.03041", "submitter": "Daniele Ramazzotti", "authors": "Stefano Beretta and Mauro Castelli and Ivo Goncalves and Ivan Merelli\n  and Daniele Ramazzotti", "title": "Combining Bayesian Approaches and Evolutionary Techniques for the\n  Inference of Breast Cancer Networks", "comments": null, "journal-ref": null, "doi": "10.5220/0006064102170224", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene and protein networks are very important to model complex large-scale\nsystems in molecular biology. Inferring or reverseengineering such networks can\nbe defined as the process of identifying gene/protein interactions from\nexperimental data through computational analysis. However, this task is\ntypically complicated by the enormously large scale of the unknowns in a rather\nsmall sample size. Furthermore, when the goal is to study causal relationships\nwithin the network, tools capable of overcoming the limitations of correlation\nnetworks are required. In this work, we make use of Bayesian Graphical Models\nto attach this problem and, specifically, we perform a comparative study of\ndifferent state-of-the-art heuristics, analyzing their performance in inferring\nthe structure of the Bayesian Network from breast cancer data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 21:36:01 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Beretta", "Stefano", ""], ["Castelli", "Mauro", ""], ["Goncalves", "Ivo", ""], ["Merelli", "Ivan", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1703.03054", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang and Lisa Lee and Eric P. Xing", "title": "Deep Variation-structured Reinforcement Learning for Visual Relationship\n  and Attribute Detection", "comments": "This manuscript is accepted by CVPR 2017 as a spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite progress in visual perception tasks such as image classification and\ndetection, computers still struggle to understand the interdependency of\nobjects in the scene as a whole, e.g., relations between objects or their\nattributes. Existing methods often ignore global context cues capturing the\ninteractions among different object instances, and can only recognize a handful\nof types by exhaustively training individual detectors for all possible\nrelationships. To capture such global interdependency, we propose a deep\nVariation-structured Reinforcement Learning (VRL) framework to sequentially\ndiscover object relationships and attributes in the whole image. First, a\ndirected semantic action graph is built using language priors to provide a rich\nand compact representation of semantic correlations between object categories,\npredicates, and attributes. Next, we use a variation-structured traversal over\nthe action graph to construct a small, adaptive action set for each step based\non the current state and historical actions. In particular, an ambiguity-aware\nobject mining scheme is used to resolve semantic ambiguity among object\ncategories that the object detector fails to distinguish. We then make\nsequential predictions using a deep RL framework, incorporating global context\ncues and semantic embeddings of previously extracted phrases in the state\nvector. Our experiments on the Visual Relationship Detection (VRD) dataset and\nthe large-scale Visual Genome dataset validate the superiority of VRL, which\ncan achieve significantly better detection results on datasets involving\nthousands of relationship and attribute types. We also demonstrate that VRL is\nable to predict unseen types embedded in our action graph by learning\ncorrelations on shared graph nodes.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 22:09:10 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Liang", "Xiaodan", ""], ["Lee", "Lisa", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.03055", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang and Liang Lin and Xiaohui Shen and Jiashi Feng and\n  Shuicheng Yan and Eric P. Xing", "title": "Interpretable Structure-Evolving LSTM", "comments": "To appear in CVPR 2017 as a spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a general framework for learning interpretable data\nrepresentation via Long Short-Term Memory (LSTM) recurrent neural networks over\nhierarchal graph structures. Instead of learning LSTM models over the pre-fixed\nstructures, we propose to further learn the intermediate interpretable\nmulti-level graph structures in a progressive and stochastic way from data\nduring the LSTM network optimization. We thus call this model the\nstructure-evolving LSTM. In particular, starting with an initial element-level\ngraph representation where each node is a small data element, the\nstructure-evolving LSTM gradually evolves the multi-level graph representations\nby stochastically merging the graph nodes with high compatibilities along the\nstacked LSTM layers. In each LSTM layer, we estimate the compatibility of two\nconnected nodes from their corresponding LSTM gate outputs, which is used to\ngenerate a merging probability. The candidate graph structures are accordingly\ngenerated where the nodes are grouped into cliques with their merging\nprobabilities. We then produce the new graph structure with a\nMetropolis-Hasting algorithm, which alleviates the risk of getting stuck in\nlocal optimums by stochastic sampling with an acceptance probability. Once a\ngraph structure is accepted, a higher-level graph is then constructed by taking\nthe partitioned cliques as its nodes. During the evolving process,\nrepresentation becomes more abstracted in higher-levels where redundant\ninformation is filtered out, allowing more efficient propagation of long-range\ndata dependencies. We evaluate the effectiveness of structure-evolving LSTM in\nthe application of semantic object parsing and demonstrate its advantage over\nstate-of-the-art LSTM models on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 22:09:38 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Liang", "Xiaodan", ""], ["Lin", "Liang", ""], ["Shen", "Xiaohui", ""], ["Feng", "Jiashi", ""], ["Yan", "Shuicheng", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.03074", "submitter": "Daniele Ramazzotti", "authors": "Daniele Ramazzotti and Marco S. Nobile and Marco Antoniotti and Alex\n  Graudenzi", "title": "Efficient computational strategies to learn the structure of\n  probabilistic graphical models of cumulative phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural learning of Bayesian Networks (BNs) is a NP-hard problem, which is\nfurther complicated by many theoretical issues, such as the I-equivalence among\ndifferent structures. In this work, we focus on a specific subclass of BNs,\nnamed Suppes-Bayes Causal Networks (SBCNs), which include specific structural\nconstraints based on Suppes' probabilistic causation to efficiently model\ncumulative phenomena. Here we compare the performance, via extensive\nsimulations, of various state-of-the-art search strategies, such as local\nsearch techniques and Genetic Algorithms, as well as of distinct regularization\nmethods. The assessment is performed on a large number of simulated datasets\nfrom topologies with distinct levels of complexity, various sample size and\ndifferent rates of errors in the data. Among the main results, we show that the\nintroduction of Suppes' constraints dramatically improve the inference\naccuracy, by reducing the solution space and providing a temporal ordering on\nthe variables. We also report on trade-offs among different search techniques\nthat can be efficiently employed in distinct experimental settings. This\nmanuscript is an extended version of the paper \"Structural Learning of\nProbabilistic Graphical Models of Cumulative Phenomena\" presented at the 2018\nInternational Conference on Computational Science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 23:50:19 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 16:08:37 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 02:41:30 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 17:43:54 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ramazzotti", "Daniele", ""], ["Nobile", "Marco S.", ""], ["Antoniotti", "Marco", ""], ["Graudenzi", "Alex", ""]]}, {"id": "1703.03076", "submitter": "Daniele Ramazzotti", "authors": "Gelin Gao and Bud Mishra and Daniele Ramazzotti", "title": "Causal Data Science for Financial Stress Testing", "comments": null, "journal-ref": null, "doi": "10.1016/j.jocs.2018.04.003", "report-no": null, "categories": "cs.LG cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most recent financial upheavals have cast doubt on the adequacy of some\nof the conventional quantitative risk management strategies, such as VaR (Value\nat Risk), in many common situations. Consequently, there has been an increasing\nneed for verisimilar financial stress testings, namely simulating and analyzing\nfinancial portfolios in extreme, albeit rare scenarios. Unlike conventional\nrisk management which exploits statistical correlations among financial\ninstruments, here we focus our analysis on the notion of probabilistic\ncausation, which is embodied by Suppes-Bayes Causal Networks (SBCNs); SBCNs are\nprobabilistic graphical models that have many attractive features in terms of\nmore accurate causal analysis for generating financial stress scenarios. In\nthis paper, we present a novel approach for conducting stress testing of\nfinancial portfolios based on SBCNs in combination with classical machine\nlearning classification tools. The resulting method is shown to be capable of\ncorrectly discovering the causal relationships among financial factors that\naffect the portfolios and thus, simulating stress testing scenarios with a\nhigher accuracy and lower computational complexity than conventional Monte\nCarlo Simulations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 23:54:09 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 14:08:44 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gao", "Gelin", ""], ["Mishra", "Bud", ""], ["Ramazzotti", "Daniele", ""]]}, {"id": "1703.03097", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Pedro Szekely", "title": "Information Extraction in Illicit Domains", "comments": "10 pages, ACM WWW 2017", "journal-ref": null, "doi": "10.1145/3038912.3052642", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting useful entities and attribute values from illicit domains such as\nhuman trafficking is a challenging problem with the potential for widespread\nsocial impact. Such domains employ atypical language models, have `long tails'\nand suffer from the problem of concept drift. In this paper, we propose a\nlightweight, feature-agnostic Information Extraction (IE) paradigm specifically\ndesigned for such domains. Our approach uses raw, unlabeled text from an\ninitial corpus, and a few (12-120) seed annotations per domain-specific\nattribute, to learn robust IE models for unobserved pages and websites.\nEmpirically, we demonstrate that our approach can outperform feature-centric\nConditional Random Field baselines by over 18\\% F-Measure on five annotated\nsets of real-world human trafficking datasets in both low-supervision and\nhigh-supervision settings. We also show that our approach is demonstrably\nrobust to concept drift, and can be efficiently bootstrapped even in a serial\ncomputing environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 01:28:00 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Szekely", "Pedro", ""]]}, {"id": "1703.03130", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing\n  Xiang, Bowen Zhou, Yoshua Bengio", "title": "A Structured Self-attentive Sentence Embedding", "comments": "15 pages with appendix, 7 figures, 4 tables. Conference paper in 5th\n  International Conference on Learning Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:42:30 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lin", "Zhouhan", ""], ["Feng", "Minwei", ""], ["Santos", "Cicero Nogueira dos", ""], ["Yu", "Mo", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.03161", "submitter": "Manh Duong Phung", "authors": "Thi Thanh Van Nguyen, Manh Duong Phung and Quang Vinh Tran", "title": "Behavior-based Navigation of Mobile Robot in Unknown Environments Using\n  Fuzzy Logic and Multi-Objective Optimization", "comments": null, "journal-ref": "International Journal of Control and Automation, Vol. 10, No. 2\n  (2017), pp.349-364", "doi": "10.14257/ijca.2017.10.2.29", "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes behavior-based navigation architecture, named BBFM, to\ndeal with the problem of navigating the mobile robot in unknown environments in\nthe presence of obstacles and local minimum regions. In the architecture, the\ncomplex navigation task is split into principal sub-tasks or behaviors. Each\nbehavior is implemented by a fuzzy controller and executed independently to\ndeal with a specific problem of navigation. The fuzzy controller is modified to\ncontain only the fuzzification and inference procedures so that its output is a\nmembership function representing the behavior's objective. The membership\nfunctions of all controllers are then used as the objective functions for a\nmulti-objective optimization process to coordinate all behaviors. The result of\nthis process is an overall control signal, which is Pareto-optimal, used to\ncontrol the robot. A number of simulations, comparisons, and experiments were\nconducted. The results show that the proposed architecture outperforms some\npopular behavior-based architectures in term of accuracy, smoothness, traveled\ndistance, and time response.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 07:05:28 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Van Nguyen", "Thi Thanh", ""], ["Phung", "Manh Duong", ""], ["Tran", "Quang Vinh", ""]]}, {"id": "1703.03193", "submitter": "Taisuke Sato", "authors": "Taisuke Sato", "title": "Embedding Tarskian Semantics in Vector Spaces", "comments": "7 pages, AAAI-17 Workshop on Symbolic Inference and Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new linear algebraic approach to the computation of Tarskian\nsemantics in logic. We embed a finite model M in first-order logic with N\nentities in N-dimensional Euclidean space R^N by mapping entities of M to N\ndimensional one-hot vectors and k-ary relations to order-k adjacency tensors\n(multi-way arrays). Second given a logical formula F in prenex normal form, we\ncompile F into a set Sigma_F of algebraic formulas in multi-linear algebra with\na nonlinear operation. In this compilation, existential quantifiers are\ncompiled into a specific type of tensors, e.g., identity matrices in the case\nof quantifying two occurrences of a variable. It is shown that a systematic\nevaluation of Sigma_F in R^N gives the truth value, 1(true) or 0(false), of F\nin M. Based on this framework, we also propose an unprecedented way of\ncomputing the least models defined by Datalog programs in linear spaces via\nmatrix equations and empirically show its effectiveness compared to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 09:30:01 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Sato", "Taisuke", ""]]}, {"id": "1703.03233", "submitter": "Niki Pfeifer", "authors": "Niki Pfeifer and Hanna Pankka", "title": "Modeling the Ellsberg Paradox by Argument Strength", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formal measure of argument strength, which combines the ideas\nthat conclusions of strong arguments are (i) highly probable and (ii) their\nuncertainty is relatively precise. Likewise, arguments are weak when their\nconclusion probability is low or when it is highly imprecise. We show how the\nproposed measure provides a new model of the Ellsberg paradox. Moreover, we\nfurther substantiate the psychological plausibility of our approach by an\nexperiment (N = 60). The data show that the proposed measure predicts human\ninferences in the original Ellsberg task and in corresponding argument strength\ntasks. Finally, we report qualitative data taken from structured interviews on\nfolk psychological conceptions on what argument strength means.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 11:31:38 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Pfeifer", "Niki", ""], ["Pankka", "Hanna", ""]]}, {"id": "1703.03254", "submitter": "Niki Pfeifer", "authors": "Niki Pfeifer and Leena Tulkki", "title": "Abductive, Causal, and Counterfactual Conditionals Under Incomplete\n  Probabilistic Knowledge", "comments": "typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study abductive, causal, and non-causal conditionals in indicative and\ncounterfactual formulations using probabilistic truth table tasks under\nincomplete probabilistic knowledge (N = 80). We frame the task as a\nprobability-logical inference problem. The most frequently observed response\ntype across all conditions was a class of conditional event interpretations of\nconditionals; it was followed by conjunction interpretations. An interesting\nminority of participants neglected some of the relevant imprecision involved in\nthe premises when inferring lower or upper probability bounds on the target\nconditional/counterfactual (\"halfway responses\"). We discuss the results in the\nlight of coherence-based probability logic and the new paradigm psychology of\nreasoning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 13:16:27 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 19:52:18 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Pfeifer", "Niki", ""], ["Tulkki", "Leena", ""]]}, {"id": "1703.03255", "submitter": "Niki Pfeifer", "authors": "Niki Pfeifer and Hiroshi Yama", "title": "Counterfactuals, indicative conditionals, and negation under\n  uncertainty: Are there cross-cultural differences?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study selected argument forms involving counterfactuals and\nindicative conditionals under uncertainty. We selected argument forms to\nexplore whether people with an Eastern cultural background reason differently\nabout conditionals compared to Westerners, because of the differences in the\nlocation of negations. In a 2x2 between-participants design, 63 Japanese\nuniversity students were allocated to four groups, crossing indicative\nconditionals and counterfactuals, and each presented in two random task orders.\nThe data show close agreement between the responses of Easterners and\nWesterners. The modal responses provide strong support for the hypothesis that\nconditional probability is the best predictor for counterfactuals and\nindicative conditionals. Finally, the grand majority of the responses are\nprobabilistically coherent, which endorses the psychological plausibility of\nchoosing coherence-based probability logic as a rationality framework for\npsychological reasoning research.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 13:22:48 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Pfeifer", "Niki", ""], ["Yama", "Hiroshi", ""]]}, {"id": "1703.03372", "submitter": "Dhanesh Ramachandram", "authors": "Dhanesh Ramachandram and Terrance DeVries", "title": "LesionSeg: Semantic segmentation of skin lesions using Deep\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for skin lesion segmentation for the ISIC 2017 Skin\nLesion Segmentation Challenge. Our approach is based on a Fully Convolutional\nNetwork architecture which is trained end to end, from scratch, on a limited\ndataset. Our semantic segmentation architecture utilizes several recent\ninnovations in particularly in the combined use of (i) use of atrous\nconvolutions to increase the effective field of view of the network's receptive\nfield without increasing the number of parameters, (ii) the use of\nnetwork-in-network $1\\times1$ convolution layers to add capacity to the network\nand (iii) state-of-art super-resolution upsampling of predictions using\nsubpixel CNN layers. We reported a mean IOU score of 0.642 on the validation\nset provided by the organisers.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 17:52:28 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 19:56:40 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 01:37:18 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Ramachandram", "Dhanesh", ""], ["DeVries", "Terrance", ""]]}, {"id": "1703.03400", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Pieter Abbeel, Sergey Levine", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "comments": "ICML 2017. Code at https://github.com/cbfinn/maml, Videos of RL\n  results at https://sites.google.com/view/maml, Blog post at\n  http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for meta-learning that is model-agnostic, in the\nsense that it is compatible with any model trained with gradient descent and\napplicable to a variety of different learning problems, including\nclassification, regression, and reinforcement learning. The goal of\nmeta-learning is to train a model on a variety of learning tasks, such that it\ncan solve new learning tasks using only a small number of training samples. In\nour approach, the parameters of the model are explicitly trained such that a\nsmall number of gradient steps with a small amount of training data from a new\ntask will produce good generalization performance on that task. In effect, our\nmethod trains the model to be easy to fine-tune. We demonstrate that this\napproach leads to state-of-the-art performance on two few-shot image\nclassification benchmarks, produces good results on few-shot regression, and\naccelerates fine-tuning for policy gradient reinforcement learning with neural\nnetwork policies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:58:03 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 17:14:08 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 16:45:29 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Finn", "Chelsea", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.03429", "submitter": "Nancy Fulda", "authors": "Nancy Fulda and Daniel Ricks and Ben Murdoch and David Wingate", "title": "What can you do with a rock? Affordance extraction via word embeddings", "comments": "7 pages, 7 figures, 2 algorithms, data runs were performed using the\n  Autoplay learning environment for interactive fiction", "journal-ref": "Proceedings of the Twenty-Sixth International Joint Conference on\n  Artificial Intelligence (IJCAI), Pages 1039-1045, 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must often detect affordances: the set of behaviors enabled\nby a situation. Affordance detection is particularly helpful in domains with\nlarge action spaces, allowing the agent to prune its search space by avoiding\nfutile behaviors. This paper presents a method for affordance extraction via\nword embeddings trained on a Wikipedia corpus. The resulting word vectors are\ntreated as a common knowledge database which can be queried using linear\nalgebra. We apply this method to a reinforcement learning agent in a text-only\nenvironment and show that affordance-based action selection improves\nperformance most of the time. Our method increases the computational complexity\nof each learning step but significantly reduces the total number of steps\nneeded. In addition, the agent's action selections begin to resemble those a\nhuman would choose.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 19:16:14 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Fulda", "Nancy", ""], ["Ricks", "Daniel", ""], ["Murdoch", "Ben", ""], ["Wingate", "David", ""]]}, {"id": "1703.03453", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Philip S. Thomas, Emma Brunskill", "title": "Using Options and Covariance Testing for Long Horizon Off-Policy Policy\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating a policy by deploying it in the real world can be risky and\ncostly. Off-policy policy evaluation (OPE) algorithms use historical data\ncollected from running a previous policy to evaluate a new policy, which\nprovides a means for evaluating a policy without requiring it to ever be\ndeployed. Importance sampling is a popular OPE method because it is robust to\npartial observability and works with continuous states and actions. However,\nthe amount of historical data required by importance sampling can scale\nexponentially with the horizon of the problem: the number of sequential\ndecisions that are made. We propose using policies over temporally extended\nactions, called options, and show that combining these policies with importance\nsampling can significantly improve performance for long-horizon problems. In\naddition, we can take advantage of special cases that arise due to\noptions-based policies to further improve the performance of importance\nsampling. We further generalize these special cases to a general covariance\ntesting rule that can be used to decide which weights to drop in an IS\nestimate, and derive a new IS algorithm called Incremental Importance Sampling\nthat can provide significantly more accurate estimates for a broad class of\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 20:21:36 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 23:47:59 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Thomas", "Philip S.", ""], ["Brunskill", "Emma", ""]]}, {"id": "1703.03524", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Mostafa Milani", "title": "The Ontological Multidimensional Data Model", "comments": "Extended abstract. This version with minor revisions and slightly\n  extended. To appear in Proc. AMW'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this extended abstract we describe, mainly by examples, the main elements\nof the Ontological Multidimensional Data Model, which considerably extends a\nrelational reconstruction of the multidimensional data model proposed by\nHurtado and Mendelzon by means of tuple-generating dependencies,\nequality-generating dependencies, and negative constraints as found in\nDatalog+-. We briefly mention some good computational properties of the model.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 02:48:29 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 01:01:48 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Milani", "Mostafa", ""]]}, {"id": "1703.03543", "submitter": "Katsunari Shibata", "authors": "Katsunari Shibata", "title": "Communications that Emerge through Reinforcement Learning Using a\n  (Recurrent) Neural Network", "comments": "The Multi-disciplinary Conference on Reinforcement Learning and\n  Decision Making (RLDM) 2017, 5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is not only an action of choosing a signal, but needs to\nconsider the context and sensor signals. It also needs to decide what\ninformation is communicated and how it is represented in or understood from\nsignals. Therefore, communication should be realized comprehensively together\nwith its purpose and other functions.\n  The recent successful results in end-to-end reinforcement learning (RL) show\nthe importance of comprehensive learning and the usefulness of end-to-end RL.\nAlthough little is known, we have shown that a variety of communications emerge\nthrough RL using a (recurrent) neural network (NN). Here, three of them are\nintroduced.\n  In the 1st one, negotiation to avoid conflicts among 4 randomly-picked agents\nwas learned. Each agent generates a binary signal from the output of its\nrecurrent NN (RNN), and receives 4 signals from the agents three times. After\nlearning, each agent made an appropriate final decision after negotiation for\nany combination of 4 agents. Differentiation of individuality among the agents\nalso could be seen.\n  The 2nd one focused on discretization of communication signal. A sender agent\nperceives the receiver's location and generates a continuous signal twice by\nits RNN. A receiver agent receives them sequentially, and moves according to\nits RNN's output to reach the sender's location. When noises were added to the\nsignal, it was binarized through learning and 2-bit communication was\nestablished.\n  The 3rd one focused on end-to-end comprehensive communication. A sender\nreceives 1,785-pixel real camera image on which a real robot can be seen, and\nsends two sounds whose frequencies are computed by its NN. A receiver receives\nthem, and two motion commands for the robot are generated by its NN. After\nlearning, though some preliminary learning was necessary for the sender, the\nrobot could reach the goal from any initial location.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 04:41:29 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 07:27:12 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Shibata", "Katsunari", ""]]}, {"id": "1703.03633", "submitter": "Kaifeng Lv", "authors": "Kaifeng Lv, Shunhua Jiang, Jian Li", "title": "Learning Gradient Descent: Better Generalization and Longer Horizons", "comments": "Accepted to ICML 2017, 9 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks is a highly nontrivial task, involving\ncarefully selecting appropriate training algorithms, scheduling step sizes and\ntuning other hyperparameters. Trying different combinations can be quite\nlabor-intensive and time consuming. Recently, researchers have tried to use\ndeep learning algorithms to exploit the landscape of the loss function of the\ntraining problem of interest, and learn how to optimize over it in an automatic\nway. In this paper, we propose a new learning-to-learn model and some useful\nand practical tricks. Our optimizer outperforms generic, hand-crafted\noptimization algorithms and state-of-the-art learning-to-learn optimizers by\nDeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a\nnumber of tasks, including deep MLPs, CNNs, and simple LSTMs.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 11:30:03 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 02:45:49 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 16:25:37 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Lv", "Kaifeng", ""], ["Jiang", "Shunhua", ""], ["Li", "Jian", ""]]}, {"id": "1703.03693", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "On Quantum Decision Trees", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum decision systems are being increasingly considered for use in\nartificial intelligence applications. Classical and quantum nodes can be\ndistinguished based on certain correlations in their states. This paper\ninvestigates some properties of the states obtained in a decision tree\nstructure. How these correlations may be mapped to the decision tree is\nconsidered. Classical tree representations and approximations to quantum states\nare provided.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 21:39:52 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1703.03714", "submitter": "Matthew Marge", "authors": "Matthew Marge, Claire Bonial, Brendan Byrne, Taylor Cassidy, A.\n  William Evans, Susan G. Hill, Clare Voss", "title": "Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue", "comments": "Presented at the 2016 IEEE International Symposium on Robot and Human\n  Interactive Communication (RO-MAN), Interactive Session, August 26-31, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our overall program objective is to provide more natural ways for soldiers to\ninteract and communicate with robots, much like how soldiers communicate with\nother soldiers today. We describe how the Wizard-of-Oz (WOz) method can be\napplied to multimodal human-robot dialogue in a collaborative exploration task.\nWhile the WOz method can help design robot behaviors, traditional approaches\nplace the burden of decisions on a single wizard. In this work, we consider two\nwizards to stand in for robot navigation and dialogue management software\ncomponents. The scenario used to elicit data is one in which a human-robot team\nis tasked with exploring an unknown environment: a human gives verbal\ninstructions from a remote location and the robot follows them, clarifying\npossible misunderstandings as needed via dialogue. We found the division of\nlabor between wizards to be workable, which holds promise for future software\ndevelopment.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 15:27:45 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Marge", "Matthew", ""], ["Bonial", "Claire", ""], ["Byrne", "Brendan", ""], ["Cassidy", "Taylor", ""], ["Evans", "A. William", ""], ["Hill", "Susan G.", ""], ["Voss", "Clare", ""]]}, {"id": "1703.03717", "submitter": "Andrew Ross", "authors": "Andrew Slavin Ross, Michael C. Hughes, Finale Doshi-Velez", "title": "Right for the Right Reasons: Training Differentiable Models by\n  Constraining their Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are among the most accurate supervised learning methods in\nuse today, but their opacity makes them difficult to trust in critical\napplications, especially when conditions in training differ from those in test.\nRecent work on explanations for black-box models has produced tools (e.g. LIME)\nto show the implicit rules behind predictions, which can help us identify when\nmodels are right for the wrong reasons. However, these methods do not scale to\nexplaining entire datasets and cannot correct the problems they reveal. We\nintroduce a method for efficiently explaining and regularizing differentiable\nmodels by examining and selectively penalizing their input gradients, which\nprovide a normal to the decision boundary. We apply these penalties both based\non expert annotation and in an unsupervised fashion that encourages diverse\nmodels with qualitatively different decision boundaries for the same\nclassification problem. On multiple datasets, we show our approach generates\nfaithful explanations and models that generalize much better when conditions\ndiffer between training and test.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 15:35:32 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 05:38:45 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Ross", "Andrew Slavin", ""], ["Hughes", "Michael C.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1703.03854", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Gopalakrishnan Srinivasan, and Kaushik Roy", "title": "Convolutional Spike Timing Dependent Plasticity based Feature Learning\n  in Spiking Neural Networks", "comments": "11 pages, 10 figures, Under Consideration in Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-inspired learning models attempt to mimic the cortical architecture and\ncomputations performed in the neurons and synapses constituting the human brain\nto achieve its efficiency in cognitive tasks. In this work, we present\nconvolutional spike timing dependent plasticity based feature learning with\nbiologically plausible leaky-integrate-and-fire neurons in Spiking Neural\nNetworks (SNNs). We use shared weight kernels that are trained to encode\nrepresentative features underlying the input patterns thereby improving the\nsparsity as well as the robustness of the learning model. We demonstrate that\nthe proposed unsupervised learning methodology learns several visual categories\nfor object recognition with fewer number of examples and outperforms\ntraditional fully-connected SNN architectures while yielding competitive\naccuracy. Additionally, we observe that the learning model performs out-of-set\ngeneralization further making the proposed biologically plausible framework a\nviable and efficient architecture for future neuromorphic applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 22:09:20 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 15:06:10 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Roy", "Kaushik", ""]]}, {"id": "1703.03864", "submitter": "Tim Salimans", "authors": "Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, Ilya Sutskever", "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of Evolution Strategies (ES), a class of black box\noptimization algorithms, as an alternative to popular MDP-based RL techniques\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\nthat ES is a viable solution strategy that scales extremely well with the\nnumber of CPUs available: By using a novel communication strategy based on\ncommon random numbers, our ES implementation only needs to communicate scalars,\nmaking it possible to scale to over a thousand parallel workers. This allows us\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\nmost Atari games after one hour of training. In addition, we highlight several\nadvantages of ES as a black box optimization technique: it is invariant to\naction frequency and delayed rewards, tolerant of extremely long horizons, and\ndoes not need temporal discounting or value function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 23:02:19 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 23:28:48 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Salimans", "Tim", ""], ["Ho", "Jonathan", ""], ["Chen", "Xi", ""], ["Sidor", "Szymon", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1703.03868", "submitter": "Nathan Sturtevant", "authors": "Jingwei Chen, Robert C. Holte, Sandra Zilles, Nathan R. Sturtevant", "title": "Front-to-End Bidirectional Heuristic Search with Near-Optimal Node\n  Expansions", "comments": "Accepted to IJCAI 2017. Camera ready version with new timing results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that any admissible unidirectional heuristic search\nalgorithm must expand all states whose $f$-value is smaller than the optimal\nsolution cost when using a consistent heuristic. Such states are called \"surely\nexpanded\" (s.e.). A recent study characterized s.e. pairs of states for\nbidirectional search with consistent heuristics: if a pair of states is s.e.\nthen at least one of the two states must be expanded. This paper derives a\nlower bound, VC, on the minimum number of expansions required to cover all s.e.\npairs, and present a new admissible front-to-end bidirectional heuristic search\nalgorithm, Near-Optimal Bidirectional Search (NBS), that is guaranteed to do no\nmore than 2VC expansions. We further prove that no admissible front-to-end\nalgorithm has a worst case better than 2VC. Experimental results show that NBS\ncompetes with or outperforms existing bidirectional search algorithms, and\noften outperforms A* as well.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 23:19:50 GMT"}, {"version": "v2", "created": "Tue, 23 May 2017 17:33:21 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Chen", "Jingwei", ""], ["Holte", "Robert C.", ""], ["Zilles", "Sandra", ""], ["Sturtevant", "Nathan R.", ""]]}, {"id": "1703.03888", "submitter": "Jose Luis Garcia-Arroyo", "authors": "Jose Luis Garcia-Arroyo and Begonya Garcia-Zapirain", "title": "Segmentation of skin lesions based on fuzzy classification of pixels and\n  histogram thresholding", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an innovative method for segmentation of skin lesions in\ndermoscopy images developed by the authors, based on fuzzy classification of\npixels and histogram thresholding.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 01:18:14 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Garcia-Arroyo", "Jose Luis", ""], ["Garcia-Zapirain", "Begonya", ""]]}, {"id": "1703.03912", "submitter": "Haifeng Xu", "authors": "Haifeng Xu, Milind Tambe, Shaddin Dughmi, Venil Loyd Noronha", "title": "Mitigating the Curse of Correlation in Security Games by Entropy\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Stackelberg security games, a defender seeks to randomly allocate limited\nsecurity resources to protect critical targets from an attack. In this paper,\nwe study a fundamental, yet underexplored, phenomenon in security games, which\nwe term the \\emph{Curse of Correlation} (CoC). Specifically, we observe that\nthere are inevitable correlations among the protection status of different\ntargets. Such correlation is a crucial concern, especially in\n\\emph{spatio-temporal} domains like conservation area patrolling, where\nattackers can surveil patrollers at certain areas and then infer their\npatrolling routes using such correlations. To mitigate this issue, we propose\nto design entropy-maximizing defending strategies for spatio-temporal security\ngames, which frequently suffer from CoC. We prove that the problem is \\#P-hard\nin general. However, it admits efficient algorithms in well-motivated special\nsettings. Our experiments show significant advantages of max-entropy algorithms\nover previous algorithms. A scalable implementation of our algorithm is\ncurrently under pre-deployment testing for integration into FAMS software to\nimprove the scheduling of US federal air marshals.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 05:35:09 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 20:09:52 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Xu", "Haifeng", ""], ["Tambe", "Milind", ""], ["Dughmi", "Shaddin", ""], ["Noronha", "Venil Loyd", ""]]}, {"id": "1703.03916", "submitter": "Shuwa Miura", "authors": "Shuwa Miura and Alex Fukunaga", "title": "Axioms in Model-based Planners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axioms can be used to model derived predicates in domain- independent\nplanning models. Formulating models which use axioms can sometimes result in\nproblems with much smaller search spaces and shorter plans than the original\nmodel. Previous work on axiom-aware planners focused solely on state- space\nsearch planners. We propose axiom-aware planners based on answer set\nprogramming and integer programming. We evaluate them on PDDL domains with\naxioms and show that they can exploit additional expressivity of axioms.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 06:37:09 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 02:48:15 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Miura", "Shuwa", ""], ["Fukunaga", "Alex", ""]]}, {"id": "1703.03921", "submitter": "Vahid Alizadeh", "authors": "Vahid Alizadeh", "title": "Gait Pattern Recognition Using Accelerometers", "comments": "6 pages, project report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion ability is one of the most important human properties, including gait\nas a basis of human transitional movement. Gait, as a biometric for recognizing\nhuman identities, can be non-intrusively captured signals using wearable or\nportable smart devices. In this study gait patterns is collected using a\nwireless platform of two sensors located at chest and right ankle of the\nsubjects. Then the raw data has undergone some preprocessing methods and\nsegmented into 5 seconds windows. Some time and frequency domain features is\nextracted and the performance evaluated by 5 different classifiers. Decision\nTree (with all features) and K-Nearest Neighbors (with 10 selected features)\nclassifiers reached 99.4% and 100% respectively.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:32:01 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Alizadeh", "Vahid", ""]]}, {"id": "1703.03924", "submitter": "Robert Nishihara", "authors": "Robert Nishihara, Philipp Moritz, Stephanie Wang, Alexey Tumanov,\n  William Paul, Johann Schleier-Smith, Richard Liaw, Mehrdad Niknami, Michael\n  I. Jordan, Ion Stoica", "title": "Real-Time Machine Learning: The Missing Pieces", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications are increasingly deployed not only to serve\npredictions using static models, but also as tightly-integrated components of\nfeedback loops involving dynamic, real-time decision making. These applications\npose a new set of requirements, none of which are difficult to achieve in\nisolation, but the combination of which creates a challenge for existing\ndistributed execution frameworks: computation with millisecond latency at high\nthroughput, adaptive construction of arbitrary task graphs, and execution of\nheterogeneous kernels over diverse sets of resources. We assert that a new\ndistributed execution framework is needed for such ML applications and propose\na candidate approach with a proof-of-concept architecture that achieves a 63x\nperformance improvement over a state-of-the-art execution framework for a\nrepresentative application.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:46:51 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 22:52:32 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Wang", "Stephanie", ""], ["Tumanov", "Alexey", ""], ["Paul", "William", ""], ["Schleier-Smith", "Johann", ""], ["Liaw", "Richard", ""], ["Niknami", "Mehrdad", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1703.03933", "submitter": "Sungtae Lee", "authors": "Sungtae Lee, Sang-Woo Lee, Jinyoung Choi, Dong-Hyun Kwak and\n  Byoung-Tak Zhang", "title": "Micro-Objective Learning : Accelerating Deep Reinforcement Learning\n  through the Discovery of Continuous Subgoals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning has been successfully applied to the logical\ngame of Go, various Atari games, and even a 3D game, Labyrinth, though it\ncontinues to have problems in sparse reward settings. It is difficult to\nexplore, but also difficult to exploit, a small number of successes when\nlearning policy. To solve this issue, the subgoal and option framework have\nbeen proposed. However, discovering subgoals online is too expensive to be used\nto learn options in large state spaces. We propose Micro-objective learning\n(MOL) to solve this problem. The main idea is to estimate how important a state\nis while training and to give an additional reward proportional to its\nimportance. We evaluated our algorithm in two Atari games: Montezuma's Revenge\nand Seaquest. With three experiments to each game, MOL significantly improved\nthe baseline scores. Especially in Montezuma's Revenge, MOL achieved two times\nbetter results than the previous state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 09:08:48 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Lee", "Sungtae", ""], ["Lee", "Sang-Woo", ""], ["Choi", "Jinyoung", ""], ["Kwak", "Dong-Hyun", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1703.04070", "submitter": "Nikhil Mishra", "authors": "Nikhil Mishra, Pieter Abbeel, Igor Mordatch", "title": "Prediction and Control with Temporal Segment Models", "comments": "camera-ready version, ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for learning the dynamics of complex nonlinear systems\nbased on deep generative models over temporal segments of states and actions.\nUnlike dynamics models that operate over individual discrete timesteps, we\nlearn the distribution over future state trajectories conditioned on past\nstate, past action, and planned future action trajectories, as well as a latent\nprior over action trajectories. Our approach is based on convolutional\nautoregressive models and variational autoencoders. It makes stable and\naccurate predictions over long horizons for complex, stochastic systems,\neffectively expressing uncertainty and modeling the effects of collisions,\nsensory noise, and action delays. The learned dynamics model and action prior\ncan be used for end-to-end, fully differentiable trajectory optimization and\nmodel-based policy optimization, which we use to evaluate the performance and\nsample-efficiency of our method.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 04:59:15 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 04:54:00 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Mishra", "Nikhil", ""], ["Abbeel", "Pieter", ""], ["Mordatch", "Igor", ""]]}, {"id": "1703.04071", "submitter": "Chunpeng Wu", "authors": "Chunpeng Wu, Wei Wen, Tariq Afzal, Yongmei Zhang, Yiran Chen, and Hai\n  Li", "title": "A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification\n  and Domain Adaptation", "comments": "2017 IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, DNN model compression based on network architecture design, e.g.,\nSqueezeNet, attracted a lot attention. No accuracy drop on image classification\nis observed on these extremely compact networks, compared to well-known models.\nAn emerging question, however, is whether these model compression techniques\nhurt DNN's learning ability other than classifying images on a single dataset.\nOur preliminary experiment shows that these compression methods could degrade\ndomain adaptation (DA) ability, though the classification performance is\npreserved. Therefore, we propose a new compact network architecture and\nunsupervised DA method in this paper. The DNN is built on a new basic module\nConv-M which provides more diverse feature extractors without significantly\nincreasing parameters. The unified framework of our DA method will\nsimultaneously learn invariance across domains, reduce divergence of feature\nrepresentations, and adapt label prediction. Our DNN has 4.1M parameters, which\nis only 6.7% of AlexNet or 59% of GoogLeNet. Experiments show that our DNN\nobtains GoogLeNet-level accuracy both on classification and DA, and our DA\nmethod slightly outperforms previous competitive ones. Put all together, our DA\nstrategy based on our DNN achieves state-of-the-art on sixteen of total\neighteen DA tasks on popular Office-31 and Office-Caltech datasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 05:07:00 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 03:21:57 GMT"}, {"version": "v3", "created": "Wed, 29 Mar 2017 05:40:52 GMT"}, {"version": "v4", "created": "Mon, 3 Apr 2017 05:17:42 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Wu", "Chunpeng", ""], ["Wen", "Wei", ""], ["Afzal", "Tariq", ""], ["Zhang", "Yongmei", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1703.04115", "submitter": "Oliver Obst", "authors": "Olivia Michael and Oliver Obst", "title": "BetaRun Soccer Simulation League Team: Variety, Complexity, and Learning", "comments": "A sketch for a new team for RoboCup 2D simulation league, currently\n  planned for 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RoboCup offers a set of benchmark problems for Artificial Intelligence in\nform of official world championships since 1997. The most tactical advanced and\nrichest in terms of behavioural complexity of these is the 2D Soccer Simulation\nLeague, a simulated robotic soccer competition. BetaRun is a new attempt\ncombining both machine learning and manual programming approaches, with the\nultimate goal to arrive at a team that is trained entirely from observing and\nplaying games, and a new development based on agent2D.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 13:17:08 GMT"}, {"version": "v2", "created": "Sat, 19 Aug 2017 07:15:22 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Michael", "Olivia", ""], ["Obst", "Oliver", ""]]}, {"id": "1703.04159", "submitter": "Konstantin Yakovlev S", "authors": "Konstantin Yakovlev and Anton Andreychuk", "title": "Any-Angle Pathfinding for Multiple Agents Based on SIPP Algorithm", "comments": "Final version as submitted to ICAPS-2017 (main track); 8 pages; 4\n  figures; 1 algorithm; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding conflict-free trajectories for multiple agents of\nidentical circular shape, operating in shared 2D workspace, is addressed in the\npaper and decoupled, e.g., prioritized, approach is used to solve this problem.\nAgents' workspace is tessellated into the square grid on which any-angle moves\nare allowed, e.g. each agent can move into an arbitrary direction as long as\nthis move follows the straight line segment whose endpoints are tied to the\ndistinct grid elements. A novel any-angle planner based on Safe Interval Path\nPlanning (SIPP) algorithm is proposed to find trajectories for an agent moving\namidst dynamic obstacles (other agents) on a grid. This algorithm is then used\nas part of a prioritized multi-agent planner AA-SIPP(m). On the theoretical,\nside we show that AA-SIPP(m) is complete under well-defined conditions. On the\nexperimental side, in simulation tests with up to 200 agents involved, we show\nthat our planner finds much better solutions in terms of cost (up to 20%)\ncompared to the planners relying on cardinal moves only.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 18:43:28 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 08:16:37 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Yakovlev", "Konstantin", ""], ["Andreychuk", "Anton", ""]]}, {"id": "1703.04221", "submitter": "Zhe Li", "authors": "Ning Liu and Zhe Li and Zhiyuan Xu and Jielong Xu and Sheng Lin and\n  Qinru Qiu and Jian Tang and Yanzhi Wang", "title": "A Hierarchical Framework of Cloud Resource Allocation and Power\n  Management Using Deep Reinforcement Learning", "comments": "accepted by 37th IEEE International Conference on Distributed\n  Computing (ICDCS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic decision-making approaches, such as reinforcement learning (RL),\nhave been applied to (partially) solve the resource allocation problem\nadaptively in the cloud computing system. However, a complete cloud resource\nallocation framework exhibits high dimensions in state and action spaces, which\nprohibit the usefulness of traditional RL techniques. In addition, high power\nconsumption has become one of the critical concerns in design and control of\ncloud computing systems, which degrades system reliability and increases\ncooling cost. An effective dynamic power management (DPM) policy should\nminimize power consumption while maintaining performance degradation within an\nacceptable level. Thus, a joint virtual machine (VM) resource allocation and\npower management framework is critical to the overall cloud computing system.\nMoreover, novel solution framework is necessary to address the even higher\ndimensions in state and action spaces. In this paper, we propose a novel\nhierarchical framework for solving the overall resource allocation and power\nmanagement problem in cloud computing systems. The proposed hierarchical\nframework comprises a global tier for VM resource allocation to the servers and\na local tier for distributed power management of local servers. The emerging\ndeep reinforcement learning (DRL) technique, which can deal with complicated\ncontrol problems with large state space, is adopted to solve the global tier\nproblem. Furthermore, an autoencoder and a novel weight sharing structure are\nadopted to handle the high-dimensional state space and accelerate the\nconvergence speed. On the other hand, the local tier of distributed server\npower managements comprises an LSTM based workload predictor and a model-free\nRL based power manager, operating in a distributed manner.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:49:27 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 18:58:12 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liu", "Ning", ""], ["Li", "Zhe", ""], ["Xu", "Zhiyuan", ""], ["Xu", "Jielong", ""], ["Lin", "Sheng", ""], ["Qiu", "Qinru", ""], ["Tang", "Jian", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1703.04232", "submitter": "Miquel Ramirez", "authors": "Miquel Ramirez, Enrico Scala, Patrik Haslum and Sylvie Thiebaux", "title": "Numerical Integration and Dynamic Discretization in Heuristic Search\n  Planning over Hybrid Domains", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we look into the problem of planning over hybrid domains, where\nchange can be both discrete and instantaneous, or continuous over time. In\naddition, it is required that each state on the trajectory induced by the\nexecution of plans complies with a given set of global constraints. We approach\nthe computation of plans for such domains as the problem of searching over a\ndeterministic state model. In this model, some of the successor states are\nobtained by solving numerically the so-called initial value problem over a set\nof ordinary differential equations (ODE) given by the current plan prefix.\nThese equations hold over time intervals whose duration is determined\ndynamically, according to whether zero crossing events take place for a set of\ninvariant conditions. The resulting planner, FS+, incorporates these features\ntogether with effective heuristic guidance. FS+ does not impose any of the\nsyntactic restrictions on process effects often found on the existing\nliterature on Hybrid Planning. A key concept of our approach is that a clear\nseparation is struck between planning and simulation time steps. The former is\nthe time allowed to observe the evolution of a given dynamical system before\ncommitting to a future course of action, whilst the later is part of the model\nof the environment. FS+ is shown to be a robust planner over a diverse set of\nhybrid domains, taken from the existing literature on hybrid planning and\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 03:29:23 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Ramirez", "Miquel", ""], ["Scala", "Enrico", ""], ["Haslum", "Patrik", ""], ["Thiebaux", "Sylvie", ""]]}, {"id": "1703.04361", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Toward a Formal Model of Cognitive Synergy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Cognitive synergy\" refers to a dynamic in which multiple cognitive\nprocesses, cooperating to control the same cognitive system, assist each other\nin overcoming bottlenecks encountered during their internal processing.\nCognitive synergy has been posited as a key feature of real-world general\nintelligence, and has been used explicitly in the design of the OpenCog\ncognitive architecture. Here category theory and related concepts are used to\ngive a formalization of the cognitive synergy concept.\n  A series of formal models of intelligent agents is proposed, with increasing\nspecificity and complexity: simple reinforcement learning agents; \"cognit\"\nagents with an abstract memory and processing model; hypergraph-based agents\n(in which \"cognit\" operations are carried out via hypergraphs); hypergraph\nagents with a rich language of nodes and hyperlinks (such as the OpenCog\nframework provides); \"PGMC\" agents whose rich hypergraphs are endowed with\ncognitive processes guided via Probabilistic Growth and Mining of Combinations;\nand finally variations of the PrimeAGI design, which is currently being built\non top of OpenCog.\n  A notion of cognitive synergy is developed for cognitive processes acting\nwithin PGMC agents, based on developing a formal notion of \"stuckness,\" and\ndefining synergy as a relationship between cognitive processes in which they\ncan help each other out when they get stuck. It is proposed that cognitive\nprocesses relating to each other synergetically, associate in a certain way\nwith functors that map into each other via natural transformations. Cognitive\nsynergy is proposed to correspond to a certain inequality regarding the\nrelative costs of different paths through certain commutation diagrams.\n  Applications of this notion of cognitive synergy to particular cognitive\nphenomena, and specific cognitive processes in the PrimeAGI design, are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 12:48:15 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "1703.04363", "submitter": "Michael Gygli", "authors": "Michael Gygli, Mohammad Norouzi, Anelia Angelova", "title": "Deep Value Networks Learn to Evaluate and Iteratively Refine Structured\n  Outputs", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach structured output prediction by optimizing a deep value network\n(DVN) to precisely estimate the task loss on different output configurations\nfor a given input. Once the model is trained, we perform inference by gradient\ndescent on the continuous relaxations of the output variables to find outputs\nwith promising scores from the value network. When applied to image\nsegmentation, the value network takes an image and a segmentation mask as\ninputs and predicts a scalar estimating the intersection over union between the\ninput and ground truth masks. For multi-label classification, the DVN's\nobjective is to correctly predict the F1 score for any potential label\nconfiguration. The DVN framework achieves the state-of-the-art results on\nmulti-label prediction and image segmentation benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 12:49:20 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 08:10:34 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Gygli", "Michael", ""], ["Norouzi", "Mohammad", ""], ["Angelova", "Anelia", ""]]}, {"id": "1703.04368", "submitter": "Benjamin Goertzel", "authors": "Ruiting Lian and Ben Goertzel and Linas Vepstas and David Hanson and\n  Changle Zhou", "title": "Symbol Grounding via Chaining of Morphisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new model of symbol grounding is presented, in which the structures of\nnatural language, logical semantics, perception and action are represented\ncategorically, and symbol grounding is modeled via the composition of morphisms\nbetween the relevant categories. This model gives conceptual insight into the\nfundamentally systematic nature of symbol grounding, and also connects\nnaturally to practical real-world AI systems in current research and commercial\nuse. Specifically, it is argued that the structure of linguistic syntax can be\nmodeled as a certain asymmetric monoidal category, as e.g. implicit in the link\ngrammar formalism; the structure of spatiotemporal relationships and action\nplans can be modeled similarly using \"image grammars\" and \"action grammars\";\nand common-sense logical semantic structure can be modeled using\ndependently-typed lambda calculus with uncertain truth values. Given these\nformalisms, the grounding of linguistic descriptions in spatiotemporal\nperceptions and coordinated actions consists of following morphisms from\nlanguage to logic through to spacetime and body (for comprehension), and vice\nversa (for generation). The mapping is indicated between the spatial\nrelationships in the Region Connection Calculus and Allen Interval Algebra and\ncorresponding entries in the link grammar syntax parsing dictionary. Further,\nthe abstractions introduced here are shown to naturally model the structures\nand systems currently being deployed in the context of using the OpenCog\ncognitive architecture to control Hanson Robotics humanoid robots.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:06:49 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Lian", "Ruiting", ""], ["Goertzel", "Ben", ""], ["Vepstas", "Linas", ""], ["Hanson", "David", ""], ["Zhou", "Changle", ""]]}, {"id": "1703.04382", "submitter": "Benjamin Goertzel", "authors": "Ben Goertzel", "title": "Cost-Based Intuitionist Probabilities on Spaces of Graphs, Hypergraphs\n  and Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel partial order is defined on the space of digraphs or hypergraphs,\nbased on assessing the cost of producing a graph via a sequence of elementary\ntransformations. Leveraging work by Knuth and Skilling on the foundations of\ninference, and the structure of Heyting algebras on graph space, this partial\norder is used to construct an intuitionistic probability measure that applies\nto either digraphs or hypergraphs. As logical inference steps can be\nrepresented as transformations on hypergraphs representing logical statements,\nthis also yields an intuitionistic probability measure on spaces of theorems.\nThe central result is also extended to yield intuitionistic probabilities based\non more general weighted rule systems defined over bicartesian closed\ncategories.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:32:46 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Goertzel", "Ben", ""]]}, {"id": "1703.04389", "submitter": "Jian Wu", "authors": "Jian Wu, Matthias Poloczek, Andrew Gordon Wilson, and Peter I. Frazier", "title": "Bayesian Optimization with Gradients", "comments": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has been successful at global optimization of\nexpensive-to-evaluate multimodal objective functions. However, unlike most\noptimization methods, Bayesian optimization typically does not use derivative\ninformation. In this paper we show how Bayesian optimization can exploit\nderivative information to decrease the number of objective function evaluations\nrequired for good performance. In particular, we develop a novel Bayesian\noptimization algorithm, the derivative-enabled knowledge-gradient (dKG), for\nwhich we show one-step Bayes-optimality, asymptotic consistency, and greater\none-step value of information than is possible in the derivative-free setting.\nOur procedure accommodates noisy and incomplete derivative information, comes\nin both sequential and batch forms, and can optionally reduce the computational\ncost of inference through automatically selected retention of a single\ndirectional derivative. We also compute the d-KG acquisition function and its\ngradient using a novel fast discretization-free technique. We show d-KG\nprovides state-of-the-art performance compared to a wide range of optimization\nprocedures with and without gradients, on benchmarks including logistic\nregression, deep learning, kernel learning, and k-nearest neighbors.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:45:13 GMT"}, {"version": "v2", "created": "Wed, 1 Nov 2017 13:27:45 GMT"}, {"version": "v3", "created": "Wed, 7 Feb 2018 04:05:29 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Wu", "Jian", ""], ["Poloczek", "Matthias", ""], ["Wilson", "Andrew Gordon", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1703.04489", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Wael Hamza and Radu Florian", "title": "Reinforcement Learning for Transition-Based Mention Detection", "comments": "Deep Reinforcement Learning Workshop, NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an application of reinforcement learning to the mention\ndetection task. We define a novel action-based formulation for the mention\ndetection task, in which a model can flexibly revise past labeling decisions by\ngrouping together tokens and assigning partial mention labels. We devise a\nmethod to create mention-level episodes and we train a model by rewarding\ncorrectly labeled complete mentions, irrespective of the inner structure\ncreated. The model yields results which are on par with a competitive\nsupervised counterpart while being more flexible in terms of achieving targeted\nbehavior through reward modeling and generating internal mention structure,\nespecially on longer mentions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:13:51 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Dinu", "Georgiana", ""], ["Hamza", "Wael", ""], ["Florian", "Radu", ""]]}, {"id": "1703.04498", "submitter": "Preeti Bhargava", "authors": "Preeti Bhargava, Nemanja Spasojevic, Guoning Hu", "title": "High-Throughput and Language-Agnostic Entity Disambiguation and Linking\n  on User Generated Data", "comments": "10 pages, 7 figures, 5 tables, WWW2017, Linked Data on the Web\n  workshop 2017, LDOW'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Entity Disambiguation and Linking (EDL) task matches entity mentions in\ntext to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase\nid. It plays a critical role in the construction of a high quality information\nnetwork, and can be further leveraged for a variety of information retrieval\nand NLP tasks such as text categorization and document tagging. EDL is a\ncomplex and challenging problem due to ambiguity of the mentions and real world\ntext being multi-lingual. Moreover, EDL systems need to have high throughput\nand should be lightweight in order to scale to large datasets and run on\noff-the-shelf machines. More importantly, these systems need to be able to\nextract and disambiguate dense annotations from the data in order to enable an\nInformation Retrieval or Extraction task running on the data to be more\nefficient and accurate. In order to address all these challenges, we present\nthe Lithium EDL system and algorithm - a high-throughput, lightweight,\nlanguage-agnostic EDL system that extracts and correctly disambiguates 75% more\nentities than state-of-the-art EDL systems and is significantly faster than\nthem.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:34:18 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Bhargava", "Preeti", ""], ["Spasojevic", "Nemanja", ""], ["Hu", "Guoning", ""]]}, {"id": "1703.04529", "submitter": "Priya Donti", "authors": "Priya L. Donti and Brandon Amos and J. Zico Kolter", "title": "Task-based End-to-end Model Learning in Stochastic Optimization", "comments": "In NIPS 2017. Code available at\n  https://github.com/locuslab/e2e-model-learning", "journal-ref": "Advances in Neural Information Processing Systems (pp. 5484-5494)\n  (2017)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of machine learning techniques, it has become\ncommon to see prediction algorithms operating within some larger process.\nHowever, the criteria by which we train these algorithms often differ from the\nultimate criteria on which we evaluate them. This paper proposes an end-to-end\napproach for learning probabilistic machine learning models in a manner that\ndirectly captures the ultimate task-based objective for which they will be\nused, within the context of stochastic programming. We present three\nexperimental evaluations of the proposed approach: a classical inventory stock\nproblem, a real-world electrical grid scheduling task, and a real-world energy\nstorage arbitrage task. We show that the proposed approach can outperform both\ntraditional modeling and purely black-box policy optimization approaches in\nthese applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:58:36 GMT"}, {"version": "v2", "created": "Sat, 25 Nov 2017 22:40:01 GMT"}, {"version": "v3", "created": "Tue, 3 Apr 2018 20:06:07 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2019 15:39:04 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Donti", "Priya L.", ""], ["Amos", "Brandon", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1703.04565", "submitter": "Mohammad Azzeh", "authors": "Mohammad Azzeh, Ali Bou Nassif", "title": "Fuzzy Model Tree For Early Effort Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use Case Points (UCP) is a well-known method to estimate the project size,\nbased on Use Case diagram, at early phases of software development. Although\nthe Use Case diagram is widely accepted as a de-facto model for analyzing\nobject oriented software requirements over the world, UCP method did not take\nsufficient amount of attention because, as yet, there is no consensus on how to\nproduce software effort from UCP. This paper aims to study the potential of\nusing Fuzzy Model Tree to derive effort estimates based on UCP size measure\nusing a dataset collected for that purpose. The proposed approach has been\nvalidated against Treeboost model, Multiple Linear Regression and classical\neffort estimation based on the UCP model. The obtained results are promising\nand show better performance than those obtained by classical UCP, Multiple\nLinear Regression and slightly better than those obtained by Tree boost model.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 20:24:06 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Azzeh", "Mohammad", ""], ["Nassif", "Ali Bou", ""]]}, {"id": "1703.04567", "submitter": "Mohammad Azzeh", "authors": "Mohammad Azzeh, Yousef Elsheikh", "title": "Learning best K analogies from data distribution for case-based software\n  effort estimation", "comments": "arXiv admin note: substantial text overlap with arXiv: 1703.04564", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Case-Based Reasoning (CBR) has been widely used to generate good software\neffort estimates. The predictive performance of CBR is a dataset dependent and\nsubject to extremely large space of configuration possibilities. Regardless of\nthe type of adaptation technique, deciding on the optimal number of similar\ncases to be used before applying CBR is a key challenge. In this paper we\npropose a new technique based on Bisecting k-medoids clustering algorithm to\nbetter understanding the structure of a dataset and discovering the the optimal\ncases for each individual project by excluding irrelevant cases. Results\nobtained showed that understanding of the data characteristic prior prediction\nstage can help in automatically finding the best number of cases for each test\nproject. Performance figures of the proposed estimation method are better than\nthose of other regular K-based CBR methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 20:19:05 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Azzeh", "Mohammad", ""], ["Elsheikh", "Yousef", ""]]}, {"id": "1703.04587", "submitter": "Qi Zhang", "authors": "Qi Zhang, Satinder Singh, Edmund Durfee", "title": "Minimizing Maximum Regret in Commitment Constrained Sequential Decision\n  Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cooperative multiagent planning, it can often be beneficial for an agent\nto make commitments about aspects of its behavior to others, allowing them in\nturn to plan their own behaviors without taking the agent's detailed behavior\ninto account. Extending previous work in the Bayesian setting, we consider\ninstead a worst-case setting in which the agent has a set of possible\nenvironments (MDPs) it could be in, and develop a commitment semantics that\nallows for probabilistic guarantees on the agent's behavior in any of the\nenvironments it could end up facing. Crucially, an agent receives observations\n(of reward and state transitions) that allow it to potentially eliminate\npossible environments and thus obtain higher utility by adapting its policy to\nthe history of observations. We develop algorithms and provide theory and some\npreliminary empirical results showing that they ensure an agent meets its\ncommitments with history-dependent policies while minimizing maximum regret\nover the possible environments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 17:15:42 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Zhang", "Qi", ""], ["Singh", "Satinder", ""], ["Durfee", "Edmund", ""]]}, {"id": "1703.04677", "submitter": "Paul M\\\"atzig", "authors": "Paul M\\\"atzig, Shravan Vasishth, Felix Engelmann, David Caplan", "title": "A computational investigation of sources of variability in sentence\n  comprehension difficulty in aphasia", "comments": "6 pages, 4 tables, to appear in Proceedings of MathPsych/ICCM 2017,\n  Warwick, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational evaluation of three hypotheses about sources of\ndeficit in sentence comprehension in aphasia: slowed processing, intermittent\ndeficiency, and resource reduction. The ACT-R based Lewis and Vasishth (2005)\nmodel is used to implement these three proposals. Slowed processing is\nimplemented as slowed default production-rule firing time; intermittent\ndeficiency as increased random noise in activation of chunks in memory; and\nresource reduction as reduced goal activation. As data, we considered subject\nvs. object rela- tives whose matrix clause contained either an NP or a\nreflexive, presented in a self-paced listening modality to 56 individuals with\naphasia (IWA) and 46 matched controls. The participants heard the sentences and\ncarried out a picture verification task to decide on an interpretation of the\nsentence. These response accuracies are used to identify the best parameters\n(for each participant) that correspond to the three hypotheses mentioned above.\nWe show that controls have more tightly clustered (less variable) parameter\nvalues than IWA; specifically, compared to controls, among IWA there are more\nindividuals with low goal activations, high noise, and slow default action\ntimes. This suggests that (i) individual patients show differential amounts of\ndeficit along the three dimensions of slowed processing, intermittent\ndeficient, and resource reduction, (ii) overall, there is evidence for all\nthree sources of deficit playing a role, and (iii) IWA have a more variable\nrange of parameter values than controls. In sum, this study contributes a proof\nof concept of a quantitative implementation of, and evidence for, these three\naccounts of comprehension deficits in aphasia.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 19:14:32 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 11:53:01 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["M\u00e4tzig", "Paul", ""], ["Vasishth", "Shravan", ""], ["Engelmann", "Felix", ""], ["Caplan", "David", ""]]}, {"id": "1703.04730", "submitter": "Pang Wei Koh", "authors": "Pang Wei Koh and Percy Liang", "title": "Understanding Black-box Predictions via Influence Functions", "comments": "International Conference on Machine Learning, 2017. (This version\n  adds more historical references and fixes typos.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we explain the predictions of a black-box model? In this paper, we\nuse influence functions -- a classic technique from robust statistics -- to\ntrace a model's prediction through the learning algorithm and back to its\ntraining data, thereby identifying training points most responsible for a given\nprediction. To scale up influence functions to modern machine learning\nsettings, we develop a simple, efficient implementation that requires only\noracle access to gradients and Hessian-vector products. We show that even on\nnon-convex and non-differentiable models where the theory breaks down,\napproximations to influence functions can still provide valuable information.\nOn linear models and convolutional neural networks, we demonstrate that\ninfluence functions are useful for multiple purposes: understanding model\nbehavior, debugging models, detecting dataset errors, and even creating\nvisually-indistinguishable training-set attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 21:07:01 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 02:31:54 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 22:40:43 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Koh", "Pang Wei", ""], ["Liang", "Percy", ""]]}, {"id": "1703.04741", "submitter": "Marija Slavkovik", "authors": "Vicky Charisi and Louise Dennis and Michael Fisher and Robert Lieck\n  and Andreas Matthias and Marija Slavkovik and Janina Sombetzki and Alan F. T.\n  Winfield and Roman Yampolskiy", "title": "Towards Moral Autonomous Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both the ethics of autonomous systems and the problems of their technical\nimplementation have by now been studied in some detail. Less attention has been\ngiven to the areas in which these two separate concerns meet. This paper,\nwritten by both philosophers and engineers of autonomous systems, addresses a\nnumber of issues in machine ethics that are located at precisely the\nintersection between ethics and engineering. We first discuss the main\nchallenges which, in our view, machine ethics posses to moral philosophy. We\nthem consider different approaches towards the conceptual design of autonomous\nsystems and their implications on the ethics implementation in such systems.\nThen we examine problematic areas regarding the specification and verification\nof ethical behavior in autonomous systems, particularly with a view towards the\nrequirements of future legislation. We discuss transparency and accountability\nissues that will be crucial for any future wide deployment of autonomous\nsystems in society. Finally we consider the, often overlooked, possibility of\nintentional misuse of AI systems and the possible dangers arising out of\ndeliberately unethical design, implementation, and use of autonomous robots.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 21:46:04 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 08:12:10 GMT"}, {"version": "v3", "created": "Tue, 31 Oct 2017 13:12:16 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Charisi", "Vicky", ""], ["Dennis", "Louise", ""], ["Fisher", "Michael", ""], ["Lieck", "Robert", ""], ["Matthias", "Andreas", ""], ["Slavkovik", "Marija", ""], ["Sombetzki", "Janina", ""], ["Winfield", "Alan F. T.", ""], ["Yampolskiy", "Roman", ""]]}, {"id": "1703.04756", "submitter": "Nika Haghtalab", "authors": "Nika Haghtalab, Ritesh Noothigattu, Ariel D. Procaccia", "title": "Weighted Voting Via No-Regret Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting systems typically treat all voters equally. We argue that perhaps they\nshould not: Voters who have supported good choices in the past should be given\nhigher weight than voters who have supported bad ones. To develop a formal\nframework for desirable weighting schemes, we draw on no-regret learning.\nSpecifically, given a voting rule, we wish to design a weighting scheme such\nthat applying the voting rule, with voters weighted by the scheme, leads to\nchoices that are almost as good as those endorsed by the best voter in\nhindsight. We derive possibility and impossibility results for the existence of\nsuch weighting schemes, depending on whether the voting rule and the weighting\nscheme are deterministic or randomized, as well as on the social choice axioms\nsatisfied by the voting rule.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:13:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Haghtalab", "Nika", ""], ["Noothigattu", "Ritesh", ""], ["Procaccia", "Ariel D.", ""]]}, {"id": "1703.04816", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn and Georg Wiese and Laura Seiffe", "title": "Making Neural QA as Simple as Possible but not Simpler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent development of large-scale question answering (QA) datasets triggered\na substantial amount of research into end-to-end neural architectures for QA.\nIncreasingly complex systems have been conceived without comparison to simpler\nneural baseline systems that would justify their complexity. In this work, we\npropose a simple heuristic that guides the development of neural baseline\nsystems for the extractive QA task. We find that there are two ingredients\nnecessary for building a high-performing neural QA system: first, the awareness\nof question words while processing the context and second, a composition\nfunction that goes beyond simple bag-of-words modeling, such as recurrent\nneural networks. Our results show that FastQA, a system that meets these two\nrequirements, can achieve very competitive performance compared with existing\nmodels. We argue that this surprising finding puts results of previous systems\nand the complexity of recent QA datasets into perspective.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:09:45 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:40:23 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 14:12:35 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Wiese", "Georg", ""], ["Seiffe", "Laura", ""]]}, {"id": "1703.04862", "submitter": "Xinyang Deng", "authors": "Xinyang Deng and Wen Jiang", "title": "Exploring the Combination Rules of D Numbers From a Perspective of\n  Conflict Redistribution", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dempster-Shafer theory of evidence is widely applied to uncertainty modelling\nand knowledge reasoning because of its advantages in dealing with uncertain\ninformation. But some conditions or requirements, such as exclusiveness\nhypothesis and completeness constraint, limit the development and application\nof that theory to a large extend. To overcome the shortcomings and enhance its\ncapability of representing the uncertainty, a novel model, called D numbers,\nhas been proposed recently. However, many key issues, for example how to\nimplement the combination of D numbers, remain unsolved. In the paper, we have\nexplored the combination of D Numbers from a perspective of conflict\nredistribution, and proposed two combination rules being suitable for different\nsituations for the fusion of two D numbers. The proposed combination rules can\nreduce to the classical Dempster's rule in Dempster-Shafer theory under a\ncertain conditions. Numerical examples and discussion about the proposed rules\nare also given in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 01:04:49 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Deng", "Xinyang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.04908", "submitter": "Igor Mordatch", "authors": "Igor Mordatch, Pieter Abbeel", "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By capturing statistical patterns in large corpora, machine learning has\nenabled significant advances in natural language processing, including in\nmachine translation, question answering, and sentiment analysis. However, for\nagents to intelligently interact with humans, simply capturing the statistical\npatterns is insufficient. In this paper we investigate if, and how, grounded\ncompositional language can emerge as a means to achieve goals in multi-agent\npopulations. Towards this end, we propose a multi-agent learning environment\nand learning methods that bring about emergence of a basic compositional\nlanguage. This language is represented as streams of abstract discrete symbols\nuttered by agents over time, but nonetheless has a coherent structure that\npossesses a defined vocabulary and syntax. We also observe emergence of\nnon-verbal communication such as pointing and guiding when language\ncommunication is unavailable.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 03:30:13 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 04:13:05 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1703.04912", "submitter": "Sebastian Binnewies", "authors": "Sebastian Binnewies, Zhiqiang Zhuang, Kewen Wang, Bela Stantic", "title": "Syntax-Preserving Belief Change Operators for Logic Programs", "comments": "44 pages, submitted to ACM Transactions on Computational Logic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent methods have adapted the well-established AGM and belief base\nframeworks for belief change to cover belief revision in logic programs. In\nthis study here, we present two new sets of belief change operators for logic\nprograms. They focus on preserving the explicit relationships expressed in the\nrules of a program, a feature that is missing in purely semantic approaches\nthat consider programs only in their entirety. In particular, operators of the\nlatter class fail to satisfy preservation and support, two important properties\nfor belief change in logic programs required to ensure intuitive results.\n  We address this shortcoming of existing approaches by introducing partial\nmeet and ensconcement constructions for logic program belief change, which\nallow us to define syntax-preserving operators that satisfy preservation and\nsupport. Our work is novel in that our constructions not only preserve more\ninformation from a logic program during a change operation than existing ones,\nbut they also facilitate natural definitions of contraction operators, the\nfirst in the field to the best of our knowledge.\n  In order to evaluate the rationality of our operators, we translate the\nrevision and contraction postulates from the AGM and belief base frameworks to\nthe logic programming setting. We show that our operators fully comply with the\nbelief base framework and formally state the interdefinability between our\noperators. We further propose an algorithm that is based on modularising a\nlogic program to reduce partial meet and ensconcement revisions or contractions\nto performing the operation only on the relevant modules of that program.\nFinally, we compare our approach to two state-of-the-art logic program revision\nmethods and demonstrate that our operators address the shortcomings of one and\ngeneralise the other method.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 03:53:25 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 00:56:18 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Binnewies", "Sebastian", ""], ["Zhuang", "Zhiqiang", ""], ["Wang", "Kewen", ""], ["Stantic", "Bela", ""]]}, {"id": "1703.04940", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt and Moses Charikar and Gregory Valiant", "title": "Resilience: A Criterion for Learning in the Presence of Arbitrary\n  Outliers", "comments": "32 pages, full version of ITCS2018 paper (minor citation edit from\n  v2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a criterion, resilience, which allows properties of a dataset\n(such as its mean or best low rank approximation) to be robustly computed, even\nin the presence of a large fraction of arbitrary additional data. Resilience is\na weaker condition than most other properties considered so far in the\nliterature, and yet enables robust estimation in a broader variety of settings.\nWe provide new information-theoretic results on robust distribution learning,\nrobust estimation of stochastic block models, and robust mean estimation under\nbounded $k$th moments. We also provide new algorithmic results on robust\ndistribution learning, as well as robust mean estimation in $\\ell_p$-norms.\nAmong our proof techniques is a method for pruning a high-dimensional\ndistribution with bounded $1$st moments to a stable \"core\" with bounded $2$nd\nmoments, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 05:43:48 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 07:22:21 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 03:16:54 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Steinhardt", "Jacob", ""], ["Charikar", "Moses", ""], ["Valiant", "Gregory", ""]]}, {"id": "1703.04990", "submitter": "Chengxun Shu", "authors": "Chengxun Shu, Hongyu Zhang", "title": "Neural Programming by Example", "comments": "7 pages, Association for the Advancement of Artificial Intelligence\n  (AAAI)", "journal-ref": "AAAI-2017", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by Example (PBE) targets at automatically inferring a computer\nprogram for accomplishing a certain task from sample input and output. In this\npaper, we propose a deep neural networks (DNN) based PBE model called Neural\nProgramming by Example (NPBE), which can learn from input-output strings and\ninduce programs that solve the string manipulation problems. Our NPBE model has\nfour neural network based components: a string encoder, an input-output\nanalyzer, a program generator, and a symbol selector. We demonstrate the\neffectiveness of NPBE by training it end-to-end to solve some common string\nmanipulation problems in spreadsheet systems. The results show that our model\ncan induce string manipulation programs effectively. Our work is one step\ntowards teaching DNN to generate computer programs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 07:57:51 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Shu", "Chengxun", ""], ["Zhang", "Hongyu", ""]]}, {"id": "1703.05201", "submitter": "Mazurek Ji\\v{r}\\'i", "authors": "Ji\\v{r}\\'i Mazurek", "title": "Fuzzy Rankings: Properties and Applications", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, a ranking of objects with respect to given set of criteria is of\nconsiderable importance. However, due to lack of knowledge, information of time\npressure, decision makers might not be able to provide a (crisp) ranking of\nobjects from the top to the bottom. Instead, some objects might be ranked\nequally, or better than other objects only to some degree. In such cases, a\ngeneralization of crisp rankings to fuzzy rankings can be more useful. The aim\nof the article is to introduce the notion of a fuzzy ranking and to discuss its\nseveral properties, namely orderings, similarity and indecisiveness. The\nproposed approach can be used both for group decision making or multiple\ncriteria decision making when uncertainty is involved.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 15:13:42 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Mazurek", "Ji\u0159\u00ed", ""]]}, {"id": "1703.05204", "submitter": "Mazurek Ji\\v{r}\\'i", "authors": "Jiri Mazurek", "title": "On Inconsistency Indices and Inconsistency Axioms in Pairwise\n  Comparisons", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparisons are an important tool of modern (multiple criteria)\ndecision making. Since human judgments are often inconsistent, many studies\nfocused on the ways how to express and measure this inconsistency, and several\ninconsistency indices were proposed as an alternative to Saaty inconsistency\nindex and inconsistency ratio for reciprocal pairwise comparisons matrices.\nThis paper aims to: firstly, introduce a new measure of inconsistency of\npairwise comparisons and to prove its basic properties; secondly, to postulate\nan additional axiom, an upper boundary axiom, to an existing set of axioms; and\nthe last, but not least, the paper provides proofs of satisfaction of this\nadditional axiom by selected inconsistency indices as well as it provides their\nnumerical comparison.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 15:19:28 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 07:46:02 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Mazurek", "Jiri", ""]]}, {"id": "1703.05260", "submitter": "Ashutosh Modi", "authors": "Ashutosh Modi and Tatjana Anikina and Simon Ostermann and Manfred\n  Pinkal", "title": "InScript: Narrative texts annotated with script information", "comments": "Paper accepted at LREC 2016, 9 pages, The corpus can be downloaded\n  at: http://www.sfb1102.uni-saarland.de/?page_id=2582", "journal-ref": "LREC 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the InScript corpus (Narrative Texts Instantiating Script\nstructure). InScript is a corpus of 1,000 stories centered around 10 different\nscenarios. Verbs and noun phrases are annotated with event and participant\ntypes, respectively. Additionally, the text is annotated with coreference\ninformation. The corpus shows rich lexical variation and will serve as a unique\nresource for the study of the role of script knowledge in natural language\nprocessing.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 17:01:20 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Modi", "Ashutosh", ""], ["Anikina", "Tatjana", ""], ["Ostermann", "Simon", ""], ["Pinkal", "Manfred", ""]]}, {"id": "1703.05320", "submitter": "Phong Do Khac", "authors": "Phong-Khac Do, Huy-Tien Nguyen, Chien-Xuan Tran, Minh-Tien Nguyen, and\n  Minh-Le Nguyen", "title": "Legal Question Answering using Ranking SVM and Deep Convolutional Neural\n  Network", "comments": "15 pages, 2 figures, Tenth International Workshop on\n  Juris-informatics (JURISIN 2016) associated with JSAI International Symposia\n  on AI 2016 (IsAI-2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of employing Ranking SVM and Convolutional Neural\nNetwork for two missions: legal information retrieval and question answering in\nthe Competition on Legal Information Extraction/Entailment. For the first task,\nour proposed model used a triple of features (LSI, Manhattan, Jaccard), and is\nbased on paragraph level instead of article level as in previous studies. In\nfact, each single-paragraph article corresponds to a particular paragraph in a\nhuge multiple-paragraph article. For the legal question answering task,\nadditional statistical features from information retrieval task integrated into\nConvolutional Neural Network contribute to higher accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:06:07 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Do", "Phong-Khac", ""], ["Nguyen", "Huy-Tien", ""], ["Tran", "Chien-Xuan", ""], ["Nguyen", "Minh-Tien", ""], ["Nguyen", "Minh-Le", ""]]}, {"id": "1703.05376", "submitter": "Gal Dalal", "authors": "Gal Dalal, Balazs Szorenyi, Gugan Thoppe, Shie Mannor", "title": "Finite Sample Analysis of Two-Timescale Stochastic Approximation with\n  Applications to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-timescale Stochastic Approximation (SA) algorithms are widely used in\nReinforcement Learning (RL). Their iterates have two parts that are updated\nusing distinct stepsizes. In this work, we develop a novel recipe for their\nfinite sample analysis. Using this, we provide a concentration bound, which is\nthe first such result for a two-timescale SA. The type of bound we obtain is\nknown as `lock-in probability'. We also introduce a new projection scheme, in\nwhich the time between successive projections increases exponentially. This\nscheme allows one to elegantly transform a lock-in probability into a\nconvergence rate result for projected two-timescale SA. From this latter\nresult, we then extract key insights on stepsize selection. As an application,\nwe finally obtain convergence rates for the projected two-timescale RL\nalgorithms GTD(0), GTD2, and TDC.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 20:23:45 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 16:35:17 GMT"}, {"version": "v3", "created": "Thu, 7 Sep 2017 07:12:14 GMT"}, {"version": "v4", "created": "Wed, 28 Feb 2018 12:13:00 GMT"}, {"version": "v5", "created": "Mon, 4 Jun 2018 18:33:57 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Dalal", "Gal", ""], ["Szorenyi", "Balazs", ""], ["Thoppe", "Gugan", ""], ["Mannor", "Shie", ""]]}, {"id": "1703.05390", "submitter": "Sercan Arik", "authors": "Sercan O. Arik, Markus Kliegl, Rewon Child, Joel Hestness, Andrew\n  Gibiansky, Chris Fougner, Ryan Prenger, Adam Coates", "title": "Convolutional Recurrent Neural Networks for Small-Footprint Keyword\n  Spotting", "comments": "Accepted to Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) constitutes a major component of human-technology\ninterfaces. Maximizing the detection accuracy at a low false alarm (FA) rate,\nwhile minimizing the footprint size, latency and complexity are the goals for\nKWS. Towards achieving them, we study Convolutional Recurrent Neural Networks\n(CRNNs). Inspired by large-scale state-of-the-art speech recognition systems,\nwe combine the strengths of convolutional layers and recurrent layers to\nexploit local structure and long-range context. We analyze the effect of\narchitecture parameters, and propose training strategies to improve\nperformance. With only ~230k parameters, our CRNN model yields acceptably low\nlatency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise\nratio.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 21:20:44 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 00:37:05 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 22:49:18 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Arik", "Sercan O.", ""], ["Kliegl", "Markus", ""], ["Child", "Rewon", ""], ["Hestness", "Joel", ""], ["Gibiansky", "Andrew", ""], ["Fougner", "Chris", ""], ["Prenger", "Ryan", ""], ["Coates", "Adam", ""]]}, {"id": "1703.05446", "submitter": "Ke Gong", "authors": "Ke Gong, Xiaodan Liang, Dongyu Zhang, Xiaohui Shen, Liang Lin", "title": "Look into Person: Self-supervised Structure-sensitive Learning and A New\n  Benchmark for Human Parsing", "comments": "Accepted to appear in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human parsing has recently attracted a lot of research interests due to its\nhuge application potentials. However existing datasets have limited number of\nimages and annotations, and lack the variety of human appearances and the\ncoverage of challenging cases in unconstrained environment. In this paper, we\nintroduce a new benchmark \"Look into Person (LIP)\" that makes a significant\nadvance in terms of scalability, diversity and difficulty, a contribution that\nwe feel is crucial for future developments in human-centric analysis. This\ncomprehensive dataset contains over 50,000 elaborately annotated images with 19\nsemantic part labels, which are captured from a wider range of viewpoints,\nocclusions and background complexity. Given these rich annotations we perform\ndetailed analyses of the leading human parsing approaches, gaining insights\ninto the success and failures of these methods. Furthermore, in contrast to the\nexisting efforts on improving the feature discriminative capability, we solve\nhuman parsing by exploring a novel self-supervised structure-sensitive learning\napproach, which imposes human pose structures into parsing results without\nresorting to extra supervision (i.e., no need for specifically labeling human\njoints in model training). Our self-supervised learning framework can be\ninjected into any advanced neural networks to help incorporate rich high-level\nknowledge regarding human joints from a global perspective and improve the\nparsing results. Extensive evaluations on our LIP and the public\nPASCAL-Person-Part dataset demonstrate the superiority of our method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:14:36 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 01:41:39 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Gong", "Ke", ""], ["Liang", "Xiaodan", ""], ["Zhang", "Dongyu", ""], ["Shen", "Xiaohui", ""], ["Lin", "Liang", ""]]}, {"id": "1703.05449", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Mohammad Gheshlaghi Azar and Ian Osband and R\\'emi Munos", "title": "Minimax Regret Bounds for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of provably optimal exploration in reinforcement\nlearning for finite horizon MDPs. We show that an optimistic modification to\nvalue iteration achieves a regret bound of $\\tilde{O}( \\sqrt{HSAT} +\nH^2S^2A+H\\sqrt{T})$ where $H$ is the time horizon, $S$ the number of states,\n$A$ the number of actions and $T$ the number of time-steps. This result\nimproves over the best previous known bound $\\tilde{O}(HS \\sqrt{AT})$ achieved\nby the UCRL2 algorithm of Jaksch et al., 2010. The key significance of our new\nresults is that when $T\\geq H^3S^3A$ and $SA\\geq H$, it leads to a regret of\n$\\tilde{O}(\\sqrt{HSAT})$ that matches the established lower bound of\n$\\Omega(\\sqrt{HSAT})$ up to a logarithmic factor. Our analysis contains two key\ninsights. We use careful application of concentration inequalities to the\noptimal value function as a whole, rather than to the transitions probabilities\n(to improve scaling in $S$), and we define Bernstein-based \"exploration\nbonuses\" that use the empirical variance of the estimated values at the next\nstates (to improve scaling in $H$).\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:31:33 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 13:00:06 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Azar", "Mohammad Gheshlaghi", ""], ["Osband", "Ian", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1703.05452", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Jean-Michel Renders, Morteza Haghir Chehreghani, Andreas\n  Krause", "title": "Efficient Online Learning for Optimizing Value of Information: Theory\n  and Application to Interactive Troubleshooting", "comments": "18 pages, 6 figures, to appear in the Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimal value of information (VoI) problem, where the goal is\nto sequentially select a set of tests with a minimal cost, so that one can\nefficiently make the best decision based on the observed outcomes. Existing\nalgorithms are either heuristics with no guarantees, or scale poorly (with\nexponential run time in terms of the number of available tests). Moreover,\nthese methods assume a known distribution over the test outcomes, which is\noften not the case in practice. We propose an efficient sampling-based online\nlearning framework to address the above issues. First, assuming the\ndistribution over hypotheses is known, we propose a dynamic hypothesis\nenumeration strategy, which allows efficient information gathering with strong\ntheoretical guarantees. We show that with sufficient amount of samples, one can\nidentify a near-optimal decision with high probability. Second, when the\nparameters of the hypotheses distribution are unknown, we propose an algorithm\nwhich learns the parameters progressively via posterior sampling in an online\nfashion. We further establish a rigorous bound on the expected regret. We\ndemonstrate the effectiveness of our approach on a real-world interactive\ntroubleshooting application and show that one can efficiently make high-quality\ndecisions with low cost.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 01:37:25 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 16:53:10 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Chen", "Yuxin", ""], ["Renders", "Jean-Michel", ""], ["Chehreghani", "Morteza Haghir", ""], ["Krause", "Andreas", ""]]}, {"id": "1703.05468", "submitter": "Yongjoo Park", "authors": "Yongjoo Park, Ahmad Shahab Tajik, Michael Cafarella, Barzan Mozafari", "title": "Database Learning: Toward a Database that Becomes Smarter Every Time", "comments": "This manuscript is an extended report of the work published in ACM\n  SIGMOD conference 2017", "journal-ref": null, "doi": "10.1145/3035918.3064013", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's databases, previous query answers rarely benefit answering future\nqueries. For the first time, to the best of our knowledge, we change this\nparadigm in an approximate query processing (AQP) context. We make the\nfollowing observation: the answer to each query reveals some degree of\nknowledge about the answer to another query because their answers stem from the\nsame underlying distribution that has produced the entire dataset. Exploiting\nand refining this knowledge should allow us to answer queries more\nanalytically, rather than by reading enormous amounts of raw data. Also,\nprocessing more queries should continuously enhance our knowledge of the\nunderlying distribution, and hence lead to increasingly faster response times\nfor future queries.\n  We call this novel idea---learning from past query answers---Database\nLearning. We exploit the principle of maximum entropy to produce answers, which\nare in expectation guaranteed to be more accurate than existing sample-based\napproximations. Empowered by this idea, we build a query engine on top of Spark\nSQL, called Verdict. We conduct extensive experiments on real-world query\ntraces from a large customer of a major database vendor. Our results\ndemonstrate that Verdict supports 73.7% of these queries, speeding them up by\nup to 23.0x for the same accuracy level compared to existing AQP systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 03:36:28 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 21:47:25 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Park", "Yongjoo", ""], ["Tajik", "Ahmad Shahab", ""], ["Cafarella", "Michael", ""], ["Mozafari", "Barzan", ""]]}, {"id": "1703.05614", "submitter": "Xiao-Fan Niu", "authors": "Xiao-Fan Niu, Wu-Jun Li", "title": "ParaGraphE: A Library for Parallel Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding aims at translating the knowledge graph into\nnumerical representations by transforming the entities and relations into\ncontinuous low-dimensional vectors. Recently, many methods [1, 5, 3, 2, 6] have\nbeen proposed to deal with this problem, but existing single-thread\nimplementations of them are time-consuming for large-scale knowledge graphs.\nHere, we design a unified parallel framework to parallelize these methods,\nwhich achieves a significant time reduction without influencing the accuracy.\nWe name our framework as ParaGraphE, which provides a library for parallel\nknowledge graph embedding. The source code can be downloaded from\nhttps://github.com/LIBBLE/LIBBLE-MultiThread/tree/master/ParaGraphE .\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 13:36:41 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 06:15:48 GMT"}, {"version": "v3", "created": "Wed, 5 Apr 2017 02:56:45 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Niu", "Xiao-Fan", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1703.05820", "submitter": "Chris J. Maddison", "authors": "Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess,\n  Arnaud Doucet, Andriy Mnih, Yee Whye Teh", "title": "Particle Value Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradients of the expected return objective can react slowly to\nrare rewards. Yet, in some cases agents may wish to emphasize the low or high\nreturns regardless of their probability. Borrowing from the economics and\ncontrol literature, we review the risk-sensitive value function that arises\nfrom an exponential utility and illustrate its effects on an example. This\nrisk-sensitive value function is not always applicable to reinforcement\nlearning problems, so we introduce the particle value function defined by a\nparticle filter over the distributions of an agent's experience, which bounds\nthe risk-sensitive one. We illustrate the benefit of the policy gradients of\nthis objective in Cliffworld.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 21:08:31 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Maddison", "Chris J.", ""], ["Lawson", "Dieterich", ""], ["Tucker", "George", ""], ["Heess", "Nicolas", ""], ["Doucet", "Arnaud", ""], ["Mnih", "Andriy", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1703.06042", "submitter": "Sascha Van Cauwelaert", "authors": "Sascha Van Cauwelaert, Michele Lombardi and Pierre Schaus", "title": "A Visual Web Tool to Perform What-If Analysis of Optimization Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Operation Research, practical evaluation is essential to validate the\nefficacy of optimization approaches. This paper promotes the usage of\nperformance profiles as a standard practice to visualize and analyze\nexperimental results. It introduces a Web tool to construct and export\nperformance profiles as SVG or HTML files. In addition, the application relies\non a methodology to estimate the benefit of hypothetical solver improvements.\nTherefore, the tool allows one to employ what-if analysis to screen possible\nresearch directions, and identify those having the best potential. The approach\nis showcased on two Operation Research technologies: Constraint Programming and\nMixed Integer Linear Programming.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 12:53:52 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Van Cauwelaert", "Sascha", ""], ["Lombardi", "Michele", ""], ["Schaus", "Pierre", ""]]}, {"id": "1703.06045", "submitter": "Denis Deratani Mau\\'a Dr.", "authors": "Diarmaid Conaty, Denis D. Mau\\'a and Cassio P. de Campos", "title": "Approximation Complexity of Maximum A Posteriori Inference in\n  Sum-Product Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the computational complexity of approximating maximum a posteriori\ninference in sum-product networks. We first show NP-hardness in trees of height\ntwo by a reduction from maximum independent set; this implies\nnon-approximability within a sublinear factor. We show that this is a tight\nbound, as we can find an approximation within a linear factor in networks of\nheight two. We then show that, in trees of height three, it is NP-hard to\napproximate the problem within a factor $2^{f(n)}$ for any sublinear function\n$f$ of the size of the input $n$. Again, this bound is tight, as we prove that\nthe usual max-product algorithm finds (in any network) approximations within\nfactor $2^{c \\cdot n}$ for some constant $c < 1$. Last, we present a simple\nalgorithm, and show that it provably produces solutions at least as good as,\nand potentially much better than, the max-product algorithm. We empirically\nanalyze the proposed algorithm against max-product using synthetic and\nrealistic networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 15:00:03 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 21:52:38 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 17:30:18 GMT"}, {"version": "v4", "created": "Wed, 23 Aug 2017 16:44:28 GMT"}, {"version": "v5", "created": "Tue, 5 Sep 2017 14:15:44 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Conaty", "Diarmaid", ""], ["Mau\u00e1", "Denis D.", ""], ["de Campos", "Cassio P.", ""]]}, {"id": "1703.06103", "submitter": "Thomas Kipf", "authors": "Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den\n  Berg, Ivan Titov, Max Welling", "title": "Modeling Relational Data with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs enable a wide variety of applications, including question\nanswering and information retrieval. Despite the great effort invested in their\ncreation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata)\nremain incomplete. We introduce Relational Graph Convolutional Networks\n(R-GCNs) and apply them to two standard knowledge base completion tasks: Link\nprediction (recovery of missing facts, i.e. subject-predicate-object triples)\nand entity classification (recovery of missing entity attributes). R-GCNs are\nrelated to a recent class of neural networks operating on graphs, and are\ndeveloped specifically to deal with the highly multi-relational data\ncharacteristic of realistic knowledge bases. We demonstrate the effectiveness\nof R-GCNs as a stand-alone model for entity classification. We further show\nthat factorization models for link prediction such as DistMult can be\nsignificantly improved by enriching them with an encoder model to accumulate\nevidence over multiple inference steps in the relational graph, demonstrating a\nlarge improvement of 29.8% on FB15k-237 over a decoder-only baseline.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 17:09:14 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 13:43:41 GMT"}, {"version": "v3", "created": "Tue, 6 Jun 2017 15:49:12 GMT"}, {"version": "v4", "created": "Thu, 26 Oct 2017 19:53:49 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Schlichtkrull", "Michael", ""], ["Kipf", "Thomas N.", ""], ["Bloem", "Peter", ""], ["Berg", "Rianne van den", ""], ["Titov", "Ivan", ""], ["Welling", "Max", ""]]}, {"id": "1703.06109", "submitter": "Claudio Mazzola", "authors": "Claudio Mazzola", "title": "Generalised Reichenbachian Common Cause Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of the common cause claims that if an improbable coincidence\nhas occurred, there must exist a common cause. This is generally taken to mean\nthat positive correlations between non-causally related events should disappear\nwhen conditioning on the action of some underlying common cause. The extended\ninterpretation of the principle, by contrast, urges that common causes should\nbe called for in order to explain positive deviations between the estimated\ncorrelation of two events and the expected value of their correlation. The aim\nof this paper is to provide the extended reading of the principle with a\ngeneral probabilistic model, capturing the simultaneous action of a system of\nmultiple common causes. To this end, two distinct models are elaborated, and\nthe necessary and sufficient conditions for their existence are determined.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 13:07:54 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Mazzola", "Claudio", ""]]}, {"id": "1703.06182", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan P. How,\n  John Vian", "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under\n  Partial Observability", "comments": "Accepted to ICML 2017", "journal-ref": "Proceedings of the 34th International Conference on Machine\n  Learning (ICML 2017), Sydney, Australia, PMLR 70:2681-2690, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks involve multiple agents with partial observability and\nlimited communication. Learning is challenging in these settings due to local\nviewpoints of agents, which perceive the world as non-stationary due to\nconcurrently-exploring teammates. Approaches that learn specialized policies\nfor individual tasks face problems when applied to the real world: not only do\nagents have to learn and store distinct policies for each task, but in practice\nidentities of tasks are often non-observable, making these approaches\ninapplicable. This paper formalizes and addresses the problem of multi-task\nmulti-agent reinforcement learning under partial observability. We introduce a\ndecentralized single-task learning approach that is robust to concurrent\ninteractions of teammates, and present an approach for distilling single-task\npolicies into a unified policy that performs well across multiple related\ntasks, without explicit provision of task identity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 19:32:38 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 15:54:36 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 16:09:39 GMT"}, {"version": "v4", "created": "Thu, 13 Jul 2017 17:34:34 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Pazis", "Jason", ""], ["Amato", "Christopher", ""], ["How", "Jonathan P.", ""], ["Vian", "John", ""]]}, {"id": "1703.06207", "submitter": "Jacob Crandall", "authors": "Jacob W. Crandall, Mayada Oudah, Tennom, Fatimah Ishowo-Oloko, Sherief\n  Abdallah, Jean-Fran\\c{c}ois Bonnefon, Manuel Cebrian, Azim Shariff, Michael\n  A. Goodrich, and Iyad Rahwan", "title": "Cooperating with Machines", "comments": "An updated version of this paper was published in Nature\n  Communications", "journal-ref": "Nature Communications, Vol. 9, Article No. 233, 2018", "doi": "10.1038/s41467-017-02597-8", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since Alan Turing envisioned Artificial Intelligence (AI) [1], a major\ndriving force behind technical progress has been competition with human\ncognition. Historical milestones have been frequently associated with computers\nmatching or outperforming humans in difficult cognitive tasks (e.g. face\nrecognition [2], personality classification [3], driving cars [4], or playing\nvideo games [5]), or defeating humans in strategic zero-sum encounters (e.g.\nChess [6], Checkers [7], Jeopardy! [8], Poker [9], or Go [10]). In contrast,\nless attention has been given to developing autonomous machines that establish\nmutually cooperative relationships with people who may not share the machine's\npreferences. A main challenge has been that human cooperation does not require\nsheer computational power, but rather relies on intuition [11], cultural norms\n[12], emotions and signals [13, 14, 15, 16], and pre-evolved dispositions\ntoward cooperation [17], common-sense mechanisms that are difficult to encode\nin machines for arbitrary contexts. Here, we combine a state-of-the-art\nmachine-learning algorithm with novel mechanisms for generating and acting on\nsignals to produce a new learning algorithm that cooperates with people and\nother machines at levels that rival human cooperation in a variety of\ntwo-player repeated stochastic games. This is the first general-purpose\nalgorithm that is capable, given a description of a previously unseen game\nenvironment, of learning to cooperate with people within short timescales in\nscenarios previously unanticipated by algorithm designers. This is achieved\nwithout complex opponent modeling or higher-order theories of mind, thus\nshowing that flexible, fast, and general human-machine cooperation is\ncomputationally achievable using a non-trivial, but ultimately simple, set of\nalgorithmic mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 21:50:16 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 14:26:33 GMT"}, {"version": "v3", "created": "Tue, 17 Oct 2017 01:04:09 GMT"}, {"version": "v4", "created": "Tue, 16 Jan 2018 15:17:33 GMT"}, {"version": "v5", "created": "Wed, 21 Feb 2018 15:50:19 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Crandall", "Jacob W.", ""], ["Oudah", "Mayada", ""], ["Tennom", "", ""], ["Ishowo-Oloko", "Fatimah", ""], ["Abdallah", "Sherief", ""], ["Bonnefon", "Jean-Fran\u00e7ois", ""], ["Cebrian", "Manuel", ""], ["Shariff", "Azim", ""], ["Goodrich", "Michael A.", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1703.06275", "submitter": "Jialin Liu Ph.D", "authors": "Jialin Liu, Julian Togelius, Diego Perez-Liebana, Simon M. Lucas", "title": "Evolving Game Skill-Depth using General Video Game AI Agents", "comments": "9 pages, 17 figures, CEC2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most games have, or can be generalised to have, a number of parameters that\nmay be varied in order to provide instances of games that lead to very\ndifferent player experiences. The space of possible parameter settings can be\nseen as a search space, and we can therefore use a Random Mutation Hill\nClimbing algorithm or other search methods to find the parameter settings that\ninduce the best games. One of the hardest parts of this approach is defining a\nsuitable fitness function. In this paper we explore the possibility of using\none of a growing set of General Video Game AI agents to perform automatic\nplay-testing. This enables a very general approach to game evaluation based on\nestimating the skill-depth of a game. Agent-based play-testing is\ncomputationally expensive, so we compare two simple but efficient optimisation\nalgorithms: the Random Mutation Hill-Climber and the Multi-Armed Bandit Random\nMutation Hill-Climber. For the test game we use a space-battle game in order to\nprovide a suitable balance between simulation speed and potential skill-depth.\nResults show that both algorithms are able to rapidly evolve game versions with\nsignificant skill-depth, but that choosing a suitable resampling number is\nessential in order to combat the effects of noise.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 09:04:05 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Liu", "Jialin", ""], ["Togelius", "Julian", ""], ["Perez-Liebana", "Diego", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1703.06283", "submitter": "Shiyu Huang", "authors": "Shiyu Huang and Deva Ramanan", "title": "Expecting the Unexpected: Training Detectors for Unusual Pedestrians\n  with Adversarial Imposters", "comments": "To appear in CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomous vehicles become an every-day reality, high-accuracy pedestrian\ndetection is of paramount practical importance. Pedestrian detection is a\nhighly researched topic with mature methods, but most datasets focus on common\nscenes of people engaged in typical walking poses on sidewalks. But performance\nis most crucial for dangerous scenarios, such as children playing in the street\nor people using bicycles/skateboards in unexpected ways. Such \"in-the-tail\"\ndata is notoriously hard to observe, making both training and testing\ndifficult. To analyze this problem, we have collected a novel annotated dataset\nof dangerous scenarios called the Precarious Pedestrian dataset. Even given a\ndedicated collection effort, it is relatively small by contemporary standards\n(around 1000 images). To allow for large-scale data-driven learning, we explore\nthe use of synthetic data generated by a game engine. A significant challenge\nis selected the right \"priors\" or parameters for synthesis: we would like\nrealistic data with poses and object configurations that mimic true Precarious\nPedestrians. Inspired by Generative Adversarial Networks (GANs), we generate a\nmassive amount of synthetic data and train a discriminative classifier to\nselect a realistic subset, which we deem the Adversarial Imposters. We\ndemonstrate that this simple pipeline allows one to synthesize realistic\ntraining data by making use of rendering/animation engines within a GAN\nframework. Interestingly, we also demonstrate that such data can be used to\nrank algorithms, suggesting that Adversarial Imposters can also be used for\n\"in-the-tail\" validation at test-time, a notoriously difficult challenge for\nreal-world deployment.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 10:52:53 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 14:59:25 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Huang", "Shiyu", ""], ["Ramanan", "Deva", ""]]}, {"id": "1703.06321", "submitter": "Ji\\v{r}\\'i Vomlel", "authors": "Ji\\v{r}\\'i Vomlel and V\\'aclav Kratochv\\'il", "title": "Solving the Goddard problem by an influence diagram", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence diagrams are a decision-theoretic extension of probabilistic\ngraphical models. In this paper we show how they can be used to solve the\nGoddard problem. We present results of numerical experiments with this problem\nand compare the solutions provided by influence diagrams with the optimal\nsolution.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 17:25:55 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 08:11:19 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Vomlel", "Ji\u0159\u00ed", ""], ["Kratochv\u00edl", "V\u00e1clav", ""]]}, {"id": "1703.06354", "submitter": "Mark Muraven", "authors": "Mark Muraven", "title": "Goal Conflict in Designing an Autonomous Artificial System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on human self-regulation has shown that people hold many goals\nsimultaneously and have complex self-regulation mechanisms to deal with this\ngoal conflict. Artificial autonomous systems may also need to find ways to cope\nwith conflicting goals. Indeed, the intricate interplay among different goals\nmay be critical to the design as well as long-term safety and stability of\nartificial autonomous systems. I discuss some of the critical features of the\nhuman self-regulation system and how it might be applied to an artificial\nsystem. Furthermore, the implications of goal conflict for the reliability and\nstability of artificial autonomous systems and ensuring their alignment with\nhuman goals and ethics is examined.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 21:25:29 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Muraven", "Mark", ""]]}, {"id": "1703.06452", "submitter": "Ronald Kemker", "authors": "Ronald Kemker and Carl Salvaggio and Christopher Kanan", "title": "Algorithms for Semantic Segmentation of Multispectral Remote Sensing\n  Imagery using Deep Learning", "comments": "45 pages", "journal-ref": "Published in ISPRS Journal of Photogrammetry and Remote Sensing\n  2018", "doi": "10.1016/j.isprsjprs.2018.04.014", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (DCNNs) have been used to achieve\nstate-of-the-art performance on many computer vision tasks (e.g., object\nrecognition, object detection, semantic segmentation) thanks to a large\nrepository of annotated image data. Large labeled datasets for other sensor\nmodalities, e.g., multispectral imagery (MSI), are not available due to the\nlarge cost and manpower required. In this paper, we adapt state-of-the-art DCNN\nframeworks in computer vision for semantic segmentation for MSI imagery. To\novercome label scarcity for MSI data, we substitute real MSI for generated\nsynthetic MSI in order to initialize a DCNN framework. We evaluate our network\ninitialization scheme on the new RIT-18 dataset that we present in this paper.\nThis dataset contains very-high resolution MSI collected by an unmanned\naircraft system. The models initialized with synthetic imagery were less prone\nto over-fitting and provide a state-of-the-art baseline for future work.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 15:21:32 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 13:45:12 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:59:31 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Kemker", "Ronald", ""], ["Salvaggio", "Carl", ""], ["Kanan", "Christopher", ""]]}, {"id": "1703.06471", "submitter": "Peeyush Kumar", "authors": "Peeyush Kumar and Doina Precup", "title": "Multi-Timescale, Gradient Descent, Temporal Difference Learning with\n  Linear Options", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deliberating on large or continuous state spaces have been long standing\nchallenges in reinforcement learning. Temporal Abstraction have somewhat made\nthis possible, but efficiently planing using temporal abstraction still remains\nan issue. Moreover using spatial abstractions to learn policies for various\nsituations at once while using temporal abstraction models is an open problem.\nWe propose here an efficient algorithm which is convergent under linear\nfunction approximation while planning using temporally abstract actions. We\nshow how this algorithm can be used along with randomly generated option models\nover multiple time scales to plan agents which need to act real time. Using\nthese randomly generated option models over multiple time scales are shown to\nreduce number of decision epochs required to solve the given task, hence\neffectively reducing the time needed for deliberation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 17:31:13 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Kumar", "Peeyush", ""], ["Precup", "Doina", ""]]}, {"id": "1703.06503", "submitter": "Cedric Nugteren", "authors": "Cedric Nugteren and Valeriu Codreanu", "title": "CLTune: A Generic Auto-Tuner for OpenCL Kernels", "comments": "8 pages, published in MCSoC '15, IEEE 9th International Symposium on\n  Embedded Multicore/Many-core Systems-on-Chip (MCSoC), 2015", "journal-ref": null, "doi": "10.1109/MCSoC.2015.10", "report-no": null, "categories": "cs.PF cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CLTune, an auto-tuner for OpenCL kernels. It evaluates and\ntunes kernel performance of a generic, user-defined search space of possible\nparameter-value combinations. Example parameters include the OpenCL workgroup\nsize, vector data-types, tile sizes, and loop unrolling factors. CLTune can be\nused in the following scenarios: 1) when there are too many tunable parameters\nto explore manually, 2) when performance portability across OpenCL devices is\ndesired, or 3) when the optimal parameters change based on input argument\nvalues (e.g. matrix dimensions). The auto-tuner is generic, easy to use,\nopen-source, and supports multiple search strategies including simulated\nannealing and particle swarm optimisation. CLTune is evaluated on two GPU\ncase-studies inspired by the recent successes in deep learning: 2D convolution\nand matrix-multiplication (GEMM). For 2D convolution, we demonstrate the need\nfor auto-tuning by optimizing for different filter sizes, achieving performance\non-par or better than the state-of-the-art. For matrix-multiplication, we use\nCLTune to explore a parameter space of more than two-hundred thousand\nconfigurations, we show the need for device-specific tuning, and outperform the\nclBLAS library on NVIDIA, AMD and Intel GPUs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 20:10:00 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Nugteren", "Cedric", ""], ["Codreanu", "Valeriu", ""]]}, {"id": "1703.06554", "submitter": "Ravi Kiran Sarvadevabhatla", "authors": "Ravi Kiran Sarvadevabhatla and Sudharshan Suresh and R. Venkatesh Babu", "title": "Object category understanding via eye fixations on freehand sketches", "comments": "Accepted for publication in Transactions on Image Processing\n  (http://ieeexplore.ieee.org/document/7866001/)", "journal-ref": null, "doi": "10.1109/TIP.2017.2675539", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of eye gaze fixations on photographic images is an active research\narea. In contrast, the image subcategory of freehand sketches has not received\nas much attention for such studies. In this paper, we analyze the results of a\nfree-viewing gaze fixation study conducted on 3904 freehand sketches\ndistributed across 160 object categories. Our analysis shows that fixation\nsequences exhibit marked consistency within a sketch, across sketches of a\ncategory and even across suitably grouped sets of categories. This multi-level\nconsistency is remarkable given the variability in depiction and extreme image\ncontent sparsity that characterizes hand-drawn object sketches. In our paper,\nwe show that the multi-level consistency in the fixation data can be exploited\nto (a) predict a test sketch's category given only its fixation sequence and\n(b) build a computational model which predicts part-labels underlying fixations\non objects. We hope that our findings motivate the community to deem\nsketch-like representations worthy of gaze-based studies vis-a-vis photographic\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 01:13:33 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Sarvadevabhatla", "Ravi Kiran", ""], ["Suresh", "Sudharshan", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1703.06565", "submitter": "Thanuka Wickramarathne", "authors": "Thanuka Wickramarathne", "title": "Evidence Updating for Stream-Processing in Big-Data: Robust Conditioning\n  in Soft and Hard Fusion Environments", "comments": "The 20th IEEE International Conference on Information Fusion\n  (Fusion'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust belief revision methods are crucial in streaming data situations for\nupdating existing knowledge or beliefs with new incoming evidence. Bayes\nconditioning is the primary mechanism in use for belief revision in data fusion\nsystems that use probabilistic inference. However, traditional conditioning\nmethods face several challenges due to inherent data/source imperfections in\nbig-data environments that harness soft (i.e., human or human-based) sources in\naddition to hard (i.e., physics-based) sensors. The objective of this paper is\nto investigate the most natural extension of Bayes conditioning that is\nsuitable for evidence updating in the presence of such uncertainties. By\nviewing the evidence updating process as a thought experiment, an elegant\nstrategy is derived for robust evidence updating in the presence of extreme\nuncertainties that are characteristic of big-data environments. In particular,\nutilizing the Fagin-Halpern conditional notions, a natural extension to Bayes\nconditioning is derived for evidence that takes the form of a general belief\nfunction. The presented work differs fundamentally from the Conditional Update\nEquation (CUE) and authors own extensions of it. An overview of this\ndevelopment is provided via illustrative examples. Furthermore, insights into\nparameter selection under various fusion contexts are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:29:53 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 12:28:43 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Wickramarathne", "Thanuka", ""]]}, {"id": "1703.06585", "submitter": "Abhishek Das", "authors": "Abhishek Das, Satwik Kottur, Jos\\'e M. F. Moura, Stefan Lee, Dhruv\n  Batra", "title": "Learning Cooperative Visual Dialog Agents with Deep Reinforcement\n  Learning", "comments": "11 pages, 4 figures, 2 tables, webpage: http://visualdialog.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first goal-driven training for visual question answering and\ndialog agents. Specifically, we pose a cooperative 'image guessing' game\nbetween two agents -- Qbot and Abot -- who communicate in natural language\ndialog so that Qbot can select an unseen image from a lineup of images. We use\ndeep reinforcement learning (RL) to learn the policies of these agents\nend-to-end -- from pixels to multi-agent multi-round dialog to game reward.\n  We demonstrate two experimental results.\n  First, as a 'sanity check' demonstration of pure RL (from scratch), we show\nresults on a synthetic world, where the agents communicate in ungrounded\nvocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find\nthat two bots invent their own communication protocol and start using certain\nsymbols to ask/answer about certain visual attributes (shape/color/style).\nThus, we demonstrate the emergence of grounded language and communication among\n'visual' dialog agents with no human supervision.\n  Second, we conduct large-scale real-image experiments on the VisDial dataset,\nwhere we pretrain with supervised dialog data and show that the RL 'fine-tuned'\nagents significantly outperform SL agents. Interestingly, the RL Qbot learns to\nask questions that Abot is good at, ultimately resulting in more informative\ndialog and a better team.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 03:50:57 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:41:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Das", "Abhishek", ""], ["Kottur", "Satwik", ""], ["Moura", "Jos\u00e9 M. F.", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""]]}, {"id": "1703.06597", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala and Evan Hurwitz", "title": "Artificial Intelligence and Economic Theories", "comments": "Marwala, T. and Hurwitz, E. (2017) Artificial Intelligence and\n  Economic Theory: Skynet in the Market. Springer. (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of artificial intelligence has changed many disciplines such as\nengineering, social science and economics. Artificial intelligence is a\ncomputational technique which is inspired by natural intelligence such as the\nswarming of birds, the working of the brain and the pathfinding of the ants.\nThese techniques have impact on economic theories. This book studies the impact\nof artificial intelligence on economic theories, a subject that has not been\nextensively studied. The theories that are considered are: demand and supply,\nasymmetrical information, pricing, rational choice, rational expectation, game\ntheory, efficient market hypotheses, mechanism design, prospect, bounded\nrationality, portfolio theory, rational counterfactual and causality. The\nbenefit of this book is that it evaluates existing theories of economics and\nupdate them based on the developments in artificial intelligence field.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 04:47:14 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Marwala", "Tshilidzi", ""], ["Hurwitz", "Evan", ""]]}, {"id": "1703.06642", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Jonito Aerts Arguelles, Lester Beltran, Lyneth\n  Beltran, Isaac Distrito, Massimiliano Sassoli de Bianchi, Sandro Sozzo and\n  Tomas Veloz", "title": "Towards a Quantum World Wide Web", "comments": "24 pages, no figures", "journal-ref": "Theoretical Computer Science, 752, pp. 116-131 (2018)", "doi": "10.1016/j.tcs.2018.03.019", "report-no": null, "categories": "cs.AI cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We elaborate a quantum model for the meaning associated with corpora of\nwritten documents, like the pages forming the World Wide Web. To that end, we\nare guided by how physicists constructed quantum theory for microscopic\nentities, which unlike classical objects cannot be fully represented in our\nspatial theater. We suggest that a similar construction needs to be carried out\nby linguists and computational scientists, to capture the full meaning carried\nby collections of documental entities. More precisely, we show how to associate\na quantum-like 'entity of meaning' to a 'language entity formed by printed\ndocuments', considering the latter as the collection of traces that are left by\nthe former, in specific results of search actions that we describe as\nmeasurements. In other words, we offer a perspective where a collection of\ndocuments, like the Web, is described as the space of manifestation of a more\ncomplex entity - the QWeb - which is the object of our modeling, drawing its\ninspiration from previous studies on operational-realistic approaches to\nquantum physics and quantum modeling of human cognition and decision-making. We\nemphasize that a consistent QWeb model needs to account for the observed\ncorrelations between words appearing in printed documents, e.g.,\nco-occurrences, as the latter would depend on the 'meaning connections'\nexisting between the concepts that are associated with these words. In that\nrespect, we show that both 'context and interference (quantum) effects' are\nrequired to explain the probabilities calculated by counting the relative\nnumber of documents containing certain words and co-ocurrrences of words.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 09:28:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 20:00:49 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["Arguelles", "Jonito Aerts", ""], ["Beltran", "Lester", ""], ["Beltran", "Lyneth", ""], ["Distrito", "Isaac", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1703.06692", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu, Wee Sun Lee", "title": "QMDP-Net: Deep Learning for Planning under Partial Observability", "comments": "NIPS 2017 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the QMDP-net, a neural network architecture for\nplanning under partial observability. The QMDP-net combines the strengths of\nmodel-free learning and model-based planning. It is a recurrent policy network,\nbut it represents a policy for a parameterized set of tasks by connecting a\nmodel with a planning algorithm that solves the model, thus embedding the\nsolution structure of planning in a network learning architecture. The QMDP-net\nis fully differentiable and allows for end-to-end training. We train a QMDP-net\non different tasks so that it can generalize to new ones in the parameterized\ntask set and \"transfer\" to other similar tasks beyond the set. In preliminary\nexperiments, QMDP-net showed strong performance on several robotic tasks in\nsimulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it\nsometimes outperforms the QMDP algorithm in the experiments, as a result of\nend-to-end learning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:44:00 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 12:59:39 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 03:31:43 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1703.06815", "submitter": "Fabio Aurelio D'Asaro", "authors": "Fabio Aurelio D'Asaro, Antonis Bikakis, Luke Dickens, Rob Miller", "title": "Foundations for a Probabilistic Event Calculus", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PEC, an Event Calculus (EC) style action language for reasoning\nabout probabilistic causal and narrative information. It has an action language\nstyle syntax similar to that of the EC variant Modular-E. Its semantics is\ngiven in terms of possible worlds which constitute possible evolutions of the\ndomain, and builds on that of EFEC, an epistemic extension of EC. We also\ndescribe an ASP implementation of PEC and show the sense in which this is sound\nand complete.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 16:03:36 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 16:17:11 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["D'Asaro", "Fabio Aurelio", ""], ["Bikakis", "Antonis", ""], ["Dickens", "Luke", ""], ["Miller", "Rob", ""]]}, {"id": "1703.06931", "submitter": "Weiyao Lin", "authors": "Weiyao Lin, Yang Shen, Junchi Yan, Mingliang Xu, Jianxin Wu, Jingdong\n  Wang, Ke Lu", "title": "Learning Correspondence Structures for Person Re-identification", "comments": "IEEE Trans. Image Processing, vol. 26, no. 5, pp. 2438-2453, 2017.\n  The project page for this paper is available at\n  http://min.sjtu.edu.cn/lwydemo/personReID.htm arXiv admin note: text overlap\n  with arXiv:1504.06243", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of handling spatial misalignments due to\ncamera-view changes or human-pose variations in person re-identification. We\nfirst introduce a boosting-based approach to learn a correspondence structure\nwhich indicates the patch-wise matching probabilities between images from a\ntarget camera pair. The learned correspondence structure can not only capture\nthe spatial correspondence pattern between cameras but also handle the\nviewpoint or human-pose variation in individual images. We further introduce a\nglobal constraint-based matching process. It integrates a global matching\nconstraint over the learned correspondence structure to exclude cross-view\nmisalignments during the image patch matching process, hence achieving a more\nreliable matching score between images. Finally, we also extend our approach by\nintroducing a multi-structure scheme, which learns a set of local\ncorrespondence structures to capture the spatial correspondence sub-patterns\nbetween a camera pair, so as to handle the spatial misalignments between\nindividual images in a more precise way. Experimental results on various\ndatasets demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:17:14 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 12:31:28 GMT"}, {"version": "v3", "created": "Thu, 27 Apr 2017 16:15:30 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Lin", "Weiyao", ""], ["Shen", "Yang", ""], ["Yan", "Junchi", ""], ["Xu", "Mingliang", ""], ["Wu", "Jianxin", ""], ["Wang", "Jingdong", ""], ["Lu", "Ke", ""]]}, {"id": "1703.06939", "submitter": "Julien Savaux", "authors": "Julien Savaux, Julien Vion, Sylvain Piechowiak, Ren\\'e Mandiau,\n  Toshihiro Matsui, Katsutoshi Hirayama, Makoto Yokoo, Shakre Elmane, Marius\n  Silaghi", "title": "Distributed Constraint Problems for Utilitarian Agents with Privacy\n  Concerns, Recast as POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has traditionally been a major motivation for distributed problem\nsolving. Distributed Constraint Satisfaction Problem (DisCSP) as well as\nDistributed Constraint Optimization Problem (DCOP) are fundamental models used\nto solve various families of distributed problems. Even though several\napproaches have been proposed to quantify and preserve privacy in such\nproblems, none of them is exempt from limitations. Here we approach the problem\nby assuming that computation is performed among utilitarian agents. We\nintroduce a utilitarian approach where the utility of each state is estimated\nas the difference between the reward for reaching an agreement on assignments\nof shared variables and the cost of privacy loss. We investigate extensions to\nsolvers where agents integrate the utility function to guide their search and\ndecide which action to perform, defining thereby their policy. We show that\nthese extended solvers succeed in significantly reducing privacy loss without\nsignificant degradation of the solution quality.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:32:40 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Savaux", "Julien", ""], ["Vion", "Julien", ""], ["Piechowiak", "Sylvain", ""], ["Mandiau", "Ren\u00e9", ""], ["Matsui", "Toshihiro", ""], ["Hirayama", "Katsutoshi", ""], ["Yokoo", "Makoto", ""], ["Elmane", "Shakre", ""], ["Silaghi", "Marius", ""]]}, {"id": "1703.07022", "submitter": "Xiaodan Liang", "authors": "Xiaodan Liang, Zhiting Hu, Hao Zhang, Chuang Gan, Eric P. Xing", "title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural image usually conveys rich semantic content and can be viewed from\ndifferent angles. Existing image description methods are largely restricted by\nsmall sets of biased visual paragraph annotations, and fail to cover rich\nunderlying semantics. In this paper, we investigate a semi-supervised paragraph\ngenerative framework that is able to synthesize diverse and semantically\ncoherent paragraph descriptions by reasoning over local semantic regions and\nexploiting linguistic knowledge. The proposed Recurrent Topic-Transition\nGenerative Adversarial Network (RTT-GAN) builds an adversarial framework\nbetween a structured paragraph generator and multi-level paragraph\ndiscriminators. The paragraph generator generates sentences recurrently by\nincorporating region-based visual and language attention mechanisms at each\nstep. The quality of generated paragraph sentences is assessed by multi-level\nadversarial discriminators from two aspects, namely, plausibility at sentence\nlevel and topic-transition coherence at paragraph level. The joint adversarial\ntraining of RTT-GAN drives the model to generate realistic paragraphs with\nsmooth logical transition between sentence topics. Extensive quantitative\nexperiments on image and video paragraph datasets demonstrate the effectiveness\nof our RTT-GAN in both supervised and semi-supervised settings. Qualitative\nresults on telling diverse stories for an image also verify the\ninterpretability of RTT-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 01:43:12 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 20:06:15 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Liang", "Xiaodan", ""], ["Hu", "Zhiting", ""], ["Zhang", "Hao", ""], ["Gan", "Chuang", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.07055", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yun-Nung Chen and Lihong Li and Jianfeng Gao and Asli\n  Celikyilmaz", "title": "Investigation of Language Understanding Impact for Reinforcement\n  Learning Based Dialogue Systems", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding is a key component in a spoken dialogue system. In\nthis paper, we investigate how the language understanding module influences the\ndialogue system performance by conducting a series of systematic experiments on\na task-oriented neural dialogue system in a reinforcement learning based\nsetting. The empirical study shows that among different types of language\nunderstanding errors, slot-level errors can have more impact on the overall\nperformance of a dialogue system compared to intent-level errors. In addition,\nour experiments demonstrate that the reinforcement learning based dialogue\nsystem is able to learn when and what to confirm in order to achieve better\nperformance and greater robustness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 04:56:14 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Li", "Xiujun", ""], ["Chen", "Yun-Nung", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Celikyilmaz", "Asli", ""]]}, {"id": "1703.07075", "submitter": "Manuel Mazzara", "authors": "Vladimir Marochko, Leonard Johard, Manuel Mazzara", "title": "Pseudorehearsal in value function approximation", "comments": null, "journal-ref": "11th International Conference on Agents and Multi-agent Systems\n  Technologies and Applications, 2017", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is of special importance in reinforcement learning,\nas the data distribution is generally non-stationary over time. We study and\ncompare several pseudorehearsal approaches for Q-learning with function\napproximation in a pole balancing task. We have found that pseudorehearsal\nseems to assist learning even in such very simple problems, given proper\ninitialization of the rehearsal parameters.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 07:09:27 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Marochko", "Vladimir", ""], ["Johard", "Leonard", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1703.07116", "submitter": "Niek Tax", "authors": "Niek Tax and Benjamin Dalmas and Natalia Sidorova and Wil M P van der\n  Aalst and Sylvie Norre", "title": "Interest-Driven Discovery of Local Process Models", "comments": "submitted to the International Conference on Business Process\n  Management (BPM) 2017", "journal-ref": "Information Systems (2018), 1-31", "doi": "10.1016/j.is.2018.04.006", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Process Models (LPM) describe structured fragments of process behavior\noccurring in the context of less structured business processes. Traditional LPM\ndiscovery aims to generate a collection of process models that describe highly\nfrequent behavior, but these models do not always provide useful answers for\nquestions posed by process analysts aiming at business process improvement. We\npropose a framework for goal-driven LPM discovery, based on utility functions\nand constraints. We describe four scopes on which these utility functions and\nconstrains can be defined, and show that utility functions and constraints on\ndifferent scopes can be combined to form composite utility\nfunctions/constraints. Finally, we demonstrate the applicability of our\napproach by presenting several actionable business insights discovered with LPM\ndiscovery on two real life data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 09:57:59 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Tax", "Niek", ""], ["Dalmas", "Benjamin", ""], ["Sidorova", "Natalia", ""], ["van der Aalst", "Wil M P", ""], ["Norre", "Sylvie", ""]]}, {"id": "1703.07255", "submitter": "Hao Wang", "authors": "Hao Wang, Xiaodan Liang, Hao Zhang, Dit-Yan Yeung, Eric P. Xing", "title": "ZM-Net: Real-time Zero-shot Image Manipulation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in image processing and computer vision (e.g. colorization,\nstyle transfer) can be posed as 'manipulating' an input image into a\ncorresponding output image given a user-specified guiding signal. A holy-grail\nsolution towards generic image manipulation should be able to efficiently alter\nan input image with any personalized signals (even signals unseen during\ntraining), such as diverse paintings and arbitrary descriptive attributes.\nHowever, existing methods are either inefficient to simultaneously process\nmultiple signals (let alone generalize to unseen signals), or unable to handle\nsignals from other modalities. In this paper, we make the first attempt to\naddress the zero-shot image manipulation task. We cast this problem as\nmanipulating an input image according to a parametric model whose key\nparameters can be conditionally generated from any guiding signal (even unseen\nones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a\nfully-differentiable architecture that jointly optimizes an\nimage-transformation network (TNet) and a parameter network (PNet). The PNet\nlearns to generate key transformation parameters for the TNet given any guiding\nsignal while the TNet performs fast zero-shot image manipulation according to\nboth signal-dependent parameters from the PNet and signal-invariant parameters\nfrom the TNet itself. Extensive experiments show that our ZM-Net can perform\nhigh-quality image manipulation conditioned on different forms of guiding\nsignals (e.g. style images and attributes) in real-time (tens of milliseconds\nper image) even for unseen signals. Moreover, a large-scale style dataset with\nover 20,000 style images is also constructed to promote further research.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:01:59 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:08:40 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Wang", "Hao", ""], ["Liang", "Xiaodan", ""], ["Zhang", "Hao", ""], ["Yeung", "Dit-Yan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1703.07326", "submitter": "Yan Duan", "authors": "Yan Duan, Marcin Andrychowicz, Bradly C. Stadie, Jonathan Ho, Jonas\n  Schneider, Ilya Sutskever, Pieter Abbeel, Wojciech Zaremba", "title": "One-Shot Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has been commonly applied to solve different tasks in\nisolation. This usually requires either careful feature engineering, or a\nsignificant number of samples. This is far from what we desire: ideally, robots\nshould be able to learn from very few demonstrations of any given task, and\ninstantly generalize to new situations of the same task, without requiring\ntask-specific engineering. In this paper, we propose a meta-learning framework\nfor achieving such capability, which we call one-shot imitation learning.\n  Specifically, we consider the setting where there is a very large set of\ntasks, and each task has many instantiations. For example, a task could be to\nstack all blocks on a table into a single tower, another task could be to place\nall blocks on a table into two-block towers, etc. In each case, different\ninstances of the task would consist of different sets of blocks with different\ninitial states. At training time, our algorithm is presented with pairs of\ndemonstrations for a subset of all tasks. A neural net is trained that takes as\ninput one demonstration and the current state (which initially is the initial\nstate of the other demonstration of the pair), and outputs an action with the\ngoal that the resulting sequence of states and actions matches as closely as\npossible with the second demonstration. At test time, a demonstration of a\nsingle instance of a new task is presented, and the neural net is expected to\nperform well on new instances of this new task. The use of soft attention\nallows the model to generalize to conditions and tasks unseen in the training\ndata. We anticipate that by training this model on a much greater variety of\ntasks and settings, we will obtain a general system that can turn any\ndemonstrations into robust policies that can accomplish an overwhelming variety\nof tasks.\n  Videos available at https://bit.ly/nips2017-oneshot .\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 17:22:29 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 00:24:03 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 21:53:23 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Duan", "Yan", ""], ["Andrychowicz", "Marcin", ""], ["Stadie", "Bradly C.", ""], ["Ho", "Jonathan", ""], ["Schneider", "Jonas", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1703.07381", "submitter": "Vishal Jain", "authors": "Gagandeep Singh Narula, Vishal Jain", "title": "Improving Statistical Multimedia Information Retrieval Model by using\n  Ontology", "comments": null, "journal-ref": "International Journal of Computer Applications ISSN No 0975 8887\n  Volume 94 No 2, May 2014", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical IR system that delivers and stores information is affected by\nproblem of matching between user query and available content on web. Use of\nOntology represents the extracted terms in form of network graph consisting of\nnodes, edges, index terms etc. The above mentioned IR approaches provide\nrelevance thus satisfying users query. The paper also emphasis on analyzing\nmultimedia documents and performs calculation for extracted terms using\ndifferent statistical formulas. The proposed model developed reduces semantic\ngap and satisfies user needs efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 18:29:05 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Narula", "Gagandeep Singh", ""], ["Jain", "Vishal", ""]]}, {"id": "1703.07384", "submitter": "Vishal Jain", "authors": "Vishal Jain and Dr. Mayank Singh", "title": "Ontology Based Pivoted normalization using Vector Based Approach for\n  information Retrieval", "comments": null, "journal-ref": "7th International Conference on Advanced Computing and\n  Communication Technologies, 16th November, 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proposed methodology is procedural i.e. it follows finite number of steps\nthat extracts relevant documents according to users query. It is based on\nprinciples of Data Mining for analyzing web data. Data Mining first adapts\nintegration of data to generate warehouse. Then, it extracts useful information\nwith the help of algorithm. The task of representing extracted documents is\ndone by using Vector Based Statistical Approach that represents each document\nin set of Terms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 18:34:34 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Jain", "Vishal", ""], ["Singh", "Dr. Mayank", ""]]}, {"id": "1703.07394", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja", "title": "Deep Learning for Explicitly Modeling Optimization Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In all but the most trivial optimization problems, the structure of the\nsolutions exhibit complex interdependencies between the input parameters.\nDecades of research with stochastic search techniques has shown the benefit of\nexplicitly modeling the interactions between sets of parameters and the overall\nquality of the solutions discovered. We demonstrate a novel method, based on\nlearning deep networks, to model the global landscapes of optimization\nproblems. To represent the search space concisely and accurately, the deep\nnetworks must encode information about the underlying parameter interactions\nand their contributions to the quality of the solution. Once the networks are\ntrained, the networks are probed to reveal parameter combinations with high\nexpected performance with respect to the optimization task. These estimates are\nused to initialize fast, randomized, local search algorithms, which in turn\nexpose more information about the search space that is subsequently used to\nrefine the models. We demonstrate the technique on multiple optimization\nproblems that have arisen in a variety of real-world domains, including:\npacking, graphics, job scheduling, layout and compression. The problems include\ncombinatoric search spaces, discontinuous and highly non-linear spaces, and\nspan binary, higher-cardinality discrete, as well as continuous parameters.\nStrengths, limitations, and extensions of the approach are extensively\ndiscussed and demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 19:12:35 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Baluja", "Shumeet", ""]]}, {"id": "1703.07469", "submitter": "Jacob Devlin", "authors": "Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh,\n  Abdel-rahman Mohamed, Pushmeet Kohli", "title": "RobustFill: Neural Program Learning under Noisy I/O", "comments": "8 pages + 9 pages of supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatically generating a computer program from some\nspecification has been studied since the early days of AI. Recently, two\ncompeting approaches for automatic program learning have received significant\nattention: (1) neural program synthesis, where a neural network is conditioned\non input/output (I/O) examples and learns to generate a program, and (2) neural\nprogram induction, where a neural network generates new outputs directly using\na latent program representation.\n  Here, for the first time, we directly compare both approaches on a\nlarge-scale, real-world learning task. We additionally contrast to rule-based\nprogram synthesis, which uses hand-crafted semantics to guide the program\ngeneration. Our neural models use a modified attention RNN to allow encoding of\nvariable-sized sets of I/O pairs. Our best synthesis model achieves 92%\naccuracy on a real-world test set, compared to the 34% accuracy of the previous\nbest neural synthesis approach. The synthesis model also outperforms a\ncomparable induction model on this task, but we more importantly demonstrate\nthat the strength of each approach is highly dependent on the evaluation metric\nand end-user application. Finally, we show that we can train our neural models\nto remain very robust to the type of noise expected in real-world data (e.g.,\ntypos), while a highly-engineered rule-based system fails entirely.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 23:29:47 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Devlin", "Jacob", ""], ["Uesato", "Jonathan", ""], ["Bhupatiraju", "Surya", ""], ["Singh", "Rishabh", ""], ["Mohamed", "Abdel-rahman", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1703.07608", "submitter": "Ian Osband", "authors": "Ian Osband, Benjamin Van Roy, Daniel Russo, Zheng Wen", "title": "Deep Exploration via Randomized Value Functions", "comments": "Accepted for publication in Journal of Machine Learning Research 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of randomized value functions to guide deep exploration in\nreinforcement learning. This offers an elegant means for synthesizing\nstatistically and computationally efficient exploration with common practical\napproaches to value function learning. We present several reinforcement\nlearning algorithms that leverage randomized value functions and demonstrate\ntheir efficacy through computational studies. We also prove a regret bound that\nestablishes statistical efficiency with a tabular representation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 11:53:53 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 17:13:06 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 09:17:37 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 23:48:32 GMT"}, {"version": "v5", "created": "Mon, 23 Sep 2019 18:29:02 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""], ["Russo", "Daniel", ""], ["Wen", "Zheng", ""]]}, {"id": "1703.07710", "submitter": "Christoph Dann", "authors": "Christoph Dann, Tor Lattimore, Emma Brunskill", "title": "Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement\n  Learning", "comments": "appears in Neural Information Processing Systems 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical performance bounds for reinforcement learning (RL) algorithms can\nbe critical for high-stakes applications like healthcare. This paper introduces\na new framework for theoretically measuring the performance of such algorithms\ncalled Uniform-PAC, which is a strengthening of the classical Probably\nApproximately Correct (PAC) framework. In contrast to the PAC framework, the\nuniform version may be used to derive high probability regret guarantees and so\nforms a bridge between the two setups that has been missing in the literature.\nWe demonstrate the benefits of the new framework for finite-state episodic MDPs\nwith a new algorithm that is Uniform-PAC and simultaneously achieves optimal\nregret and PAC guarantees except for a factor of the horizon.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 15:34:23 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 21:04:38 GMT"}, {"version": "v3", "created": "Tue, 2 Jan 2018 13:25:46 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Dann", "Christoph", ""], ["Lattimore", "Tor", ""], ["Brunskill", "Emma", ""]]}, {"id": "1703.07726", "submitter": "Tao Ding", "authors": "Tao Ding, Warren K. Bickel, Shimei Pan", "title": "\\$1 Today or \\$2 Tomorrow? The Answer is in Your Facebook Likes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In economics and psychology, delay discounting is often used to characterize\nhow individuals choose between a smaller immediate reward and a larger delayed\nreward. People with higher delay discounting rate (DDR) often choose smaller\nbut more immediate rewards (a \"today person\"). In contrast, people with a lower\ndiscounting rate often choose a larger future rewards (a \"tomorrow person\").\nSince the ability to modulate the desire of immediate gratification for long\nterm rewards plays an important role in our decision-making, the lower\ndiscounting rate often predicts better social, academic and health outcomes. In\ncontrast, the higher discounting rate is often associated with problematic\nbehaviors such as alcohol/drug abuse, pathological gambling and credit card\ndefault. Thus, research on understanding and moderating delay discounting has\nthe potential to produce substantial societal benefits.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 16:16:09 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 05:27:59 GMT"}, {"version": "v3", "created": "Fri, 24 Mar 2017 01:00:03 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Ding", "Tao", ""], ["Bickel", "Warren K.", ""], ["Pan", "Shimei", ""]]}, {"id": "1703.07758", "submitter": "Hongyang Zhang", "authors": "Maria-Florina Balcan and Hongyang Zhang", "title": "Sample and Computationally Efficient Learning Algorithms under S-Concave\n  Distributions", "comments": "Appear in NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new results for noise-tolerant and sample-efficient learning\nalgorithms under $s$-concave distributions. The new class of $s$-concave\ndistributions is a broad and natural generalization of log-concavity, and\nincludes many important additional distributions, e.g., the Pareto distribution\nand $t$-distribution. This class has been studied in the context of efficient\nsampling, integration, and optimization, but much remains unknown about the\ngeometry of this class of distributions and their applications in the context\nof learning. The challenge is that unlike the commonly used distributions in\nlearning (uniform or more generally log-concave distributions), this broader\nclass is not closed under the marginalization operator and many such\ndistributions are fat-tailed. In this work, we introduce new convex geometry\ntools to study the properties of $s$-concave distributions and use these\nproperties to provide bounds on quantities of interest to learning including\nthe probability of disagreement between two halfspaces, disagreement outside a\nband, and the disagreement coefficient. We use these results to significantly\ngeneralize prior results for margin-based active learning, disagreement-based\nactive learning, and passive learning of intersections of halfspaces. Our\nanalysis of geometric properties of $s$-concave distributions might be of\nindependent interest to optimization more broadly.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:27:57 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 21:10:19 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Zhang", "Hongyang", ""]]}, {"id": "1703.07805", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Pedro Szekely", "title": "Supervised Typing of Big Graphs using Semantic Embeddings", "comments": "6 pages, to be published in Semantic Big Data Workshop at ACM, SIGMOD\n  2017; extended version in preparation for Open Journal of Semantic Web (OJSW)", "journal-ref": null, "doi": "10.1145/3066911.3066918", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised algorithm for generating type embeddings in the same\nsemantic vector space as a given set of entity embeddings. The algorithm is\nagnostic to the derivation of the underlying entity embeddings. It does not\nrequire any manual feature engineering, generalizes well to hundreds of types\nand achieves near-linear scaling on Big Graphs containing many millions of\ntriples and instances by virtue of an incremental execution. We demonstrate the\nutility of the embeddings on a type recommendation task, outperforming a\nnon-parametric feature-agnostic baseline while achieving 15x speedup and\nnear-constant memory usage on a full partition of DBpedia. Using\nstate-of-the-art visualization, we illustrate the agreement of our\nextensionally derived DBpedia type embeddings with the manually curated domain\nontology. Finally, we use the embeddings to probabilistically cluster about 4\nmillion DBpedia instances into 415 types in the DBpedia ontology.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 18:20:07 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Szekely", "Pedro", ""]]}, {"id": "1703.07822", "submitter": "Shaojun Zhu", "authors": "Shaojun Zhu, Andrew Kimmel, Abdeslam Boularias", "title": "Information-theoretic Model Identification and Policy Search using\n  Physics Engines with Application to Robotic Manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of a robot learning the mechanical properties of\nobjects through physical interaction with the object, and introduce a\npractical, data-efficient approach for identifying the motion models of these\nobjects. The proposed method utilizes a physics engine, where the robot seeks\nto identify the inertial and friction parameters of the object by simulating\nits motion under different values of the parameters and identifying those that\nresult in a simulation which matches the observed real motions. The problem is\nsolved in a Bayesian optimization framework. The same framework is used for\nboth identifying the model of an object online and searching for a policy that\nwould minimize a given cost function according to the identified model.\nExperimental results both in simulation and using a real robot indicate that\nthe proposed method outperforms state-of-the-art model-free reinforcement\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 19:08:48 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Zhu", "Shaojun", ""], ["Kimmel", "Andrew", ""], ["Boularias", "Abdeslam", ""]]}, {"id": "1703.07928", "submitter": "Swami Sankaranarayanan", "authors": "Swami Sankaranarayanan, Arpit Jain, Ser Nam Lim", "title": "Self corrective Perturbations for Semantic Segmentation and\n  Classification", "comments": "Accepted to ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have been a subject of great importance over\nthe past decade and great strides have been made in their utility for producing\nstate of the art performance in many computer vision problems. However, the\nbehavior of deep networks is yet to be fully understood and is still an active\narea of research. In this work, we present an intriguing behavior: pre-trained\nCNNs can be made to improve their predictions by structurally perturbing the\ninput. We observe that these perturbations - referred as Guided Perturbations -\nenable a trained network to improve its prediction performance without any\nlearning or change in network weights. We perform various ablative experiments\nto understand how these perturbations affect the local context and feature\nrepresentations. Furthermore, we demonstrate that this idea can improve\nperformance of several existing approaches on semantic segmentation and scene\nlabeling tasks on the PASCAL VOC dataset and supervised classification tasks on\nMNIST and CIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 04:25:48 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 15:42:06 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Sankaranarayanan", "Swami", ""], ["Jain", "Arpit", ""], ["Lim", "Ser Nam", ""]]}, {"id": "1703.07929", "submitter": "Fred Glover", "authors": "Fred Glover and Jin-Kao Hao", "title": "Diversification-Based Learning in Computing and Optimization", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversification-Based Learning (DBL) derives from a collection of principles\nand methods introduced in the field of metaheuristics that have broad\napplications in computing and optimization. We show that the DBL framework goes\nsignificantly beyond that of the more recent Opposition-based learning (OBL)\nframework introduced in Tizhoosh (2005), which has become the focus of numerous\nresearch initiatives in machine learning and metaheuristic optimization. We\nunify and extend earlier proposals in metaheuristic search (Glover, 1997,\nGlover and Laguna, 1997) to give a collection of approaches that are more\nflexible and comprehensive than OBL for creating intensification and\ndiversification strategies in metaheuristic search. We also describe potential\napplications of DBL to various subfields of machine learning and optimization.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 04:26:46 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Glover", "Fred", ""], ["Hao", "Jin-Kao", ""]]}, {"id": "1703.07940", "submitter": "Edward Barker", "authors": "Edward Barker and Charl Ras", "title": "Unsupervised Basis Function Adaptation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using reinforcement learning (RL) algorithms it is common, given a large\nstate space, to introduce some form of approximation architecture for the value\nfunction (VF). The exact form of this architecture can have a significant\neffect on an agent's performance, however, and determining a suitable\napproximation architecture can often be a highly complex task. Consequently\nthere is currently interest among researchers in the potential for allowing RL\nalgorithms to adaptively generate (i.e. to learn) approximation architectures.\nOne relatively unexplored method of adapting approximation architectures\ninvolves using feedback regarding the frequency with which an agent has visited\ncertain states to guide which areas of the state space to approximate with\ngreater detail. In this article we will: (a) informally discuss the potential\nadvantages offered by such methods; (b) introduce a new algorithm based on such\nmethods which adapts a state aggregation approximation architecture on-line and\nis designed for use in conjunction with SARSA; (c) provide theoretical results,\nin a policy evaluation setting, regarding this particular algorithm's\ncomplexity, convergence properties and potential to reduce VF error; and\nfinally (d) test experimentally the extent to which this algorithm can improve\nperformance given a number of different test problems. Taken together our\nresults suggest that our algorithm (and potentially such methods more\ngenerally) can provide a versatile and computationally lightweight means of\nsignificantly boosting RL performance given suitable conditions which are\ncommonly encountered in practice.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 05:23:34 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:26:30 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 23:14:40 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Barker", "Edward", ""], ["Ras", "Charl", ""]]}, {"id": "1703.07948", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Yuanyuan Liu, James Cheng, and Jiacheng Zhuo", "title": "Fast Stochastic Variance Reduced Gradient Method with Momentum\n  Acceleration for Machine Learning", "comments": "Corrected a few typos in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, research on accelerated stochastic gradient descent methods (e.g.,\nSVRG) has made exciting progress (e.g., linear convergence for strongly convex\nproblems). However, the best-known methods (e.g., Katyusha) requires at least\ntwo auxiliary variables and two momentum parameters. In this paper, we propose\na fast stochastic variance reduction gradient (FSVRG) method, in which we\ndesign a novel update rule with the Nesterov's momentum and incorporate the\ntechnique of growing epoch size. FSVRG has only one auxiliary variable and one\nmomentum weight, and thus it is much simpler and has much lower per-iteration\ncomplexity. We prove that FSVRG achieves linear convergence for strongly convex\nproblems and the optimal $\\mathcal{O}(1/T^2)$ convergence rate for non-strongly\nconvex problems, where $T$ is the number of outer-iterations. We also extend\nFSVRG to directly solve the problems with non-smooth component functions, such\nas SVM. Finally, we empirically study the performance of FSVRG for solving\nvarious machine learning problems such as logistic regression, ridge\nregression, Lasso and SVM. Our results show that FSVRG outperforms the\nstate-of-the-art stochastic methods, including Katyusha.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 07:13:28 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 17:16:49 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""], ["Zhuo", "Jiacheng", ""]]}, {"id": "1703.07994", "submitter": "Andreas Pieris", "authors": "Pablo Barcelo, Gerald Berger, Andreas Pieris", "title": "Containment for Rule-Based Ontology-Mediated Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many efforts have been dedicated to identifying restrictions on ontologies\nexpressed as tuple-generating dependencies (tgds), a.k.a. existential rules,\nthat lead to the decidability for the problem of answering ontology-mediated\nqueries (OMQs). This has given rise to three families of formalisms: guarded,\nnon-recursive, and sticky sets of tgds. In this work, we study the containment\nproblem for OMQs expressed in such formalisms, which is a key ingredient for\nsolving static analysis tasks associated with them. Our main contribution is\nthe development of specially tailored techniques for OMQ containment under the\nclasses of tgds stated above. This enables us to obtain sharp complexity bounds\nfor the problems at hand, which in turn allow us to delimitate its practical\napplicability. We also apply our techniques to pinpoint the complexity of\nproblems associated with two emerging applications of OMQ containment:\ndistribution over components and UCQ rewritability of OMQs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 10:44:18 GMT"}, {"version": "v2", "created": "Sun, 2 Apr 2017 16:13:16 GMT"}, {"version": "v3", "created": "Wed, 19 Apr 2017 00:26:02 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Barcelo", "Pablo", ""], ["Berger", "Gerald", ""], ["Pieris", "Andreas", ""]]}, {"id": "1703.08041", "submitter": "Palash Dey", "authors": "Palash Dey", "title": "Resolving the Complexity of Some Fundamental Problems in Computational\n  Social Choice", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is in the area called computational social choice which is an\nintersection area of algorithms and social choice theory.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 12:32:10 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Dey", "Palash", ""]]}, {"id": "1703.08098", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen", "title": "A survey of embedding models of entities and relationships for knowledge\n  graph completion", "comments": "In Proceedings of the 14th Workshop on Graph-Based Natural Language\n  Processing (TextGraphs 2020); 16 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) of real-world facts about entities and their\nrelationships are useful resources for a variety of natural language processing\ntasks. However, because knowledge graphs are typically incomplete, it is useful\nto perform knowledge graph completion or link prediction, i.e. predict whether\na relationship not in the knowledge graph is likely to be true. This paper\nserves as a comprehensive survey of embedding models of entities and\nrelationships for knowledge graph completion, summarizing up-to-date\nexperimental results on standard benchmark datasets and pointing out potential\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 15:15:26 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 15:28:08 GMT"}, {"version": "v3", "created": "Sat, 3 Feb 2018 04:39:45 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2019 02:26:26 GMT"}, {"version": "v5", "created": "Sat, 27 Apr 2019 13:33:30 GMT"}, {"version": "v6", "created": "Fri, 28 Feb 2020 07:06:36 GMT"}, {"version": "v7", "created": "Wed, 22 Apr 2020 11:58:35 GMT"}, {"version": "v8", "created": "Mon, 10 Aug 2020 08:35:07 GMT"}, {"version": "v9", "created": "Tue, 27 Oct 2020 04:11:25 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nguyen", "Dat Quoc", ""]]}, {"id": "1703.08100", "submitter": "Jiongqian Liang", "authors": "Jiongqian Liang, Peter Jacobs, Jiankai Sun, Srinivasan Parthasarathy", "title": "Semi-supervised Embedding in Attributed Networks with Outliers", "comments": "in Proceedings of SIAM International Conference on Data Mining\n  (SDM'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework, called Semi-supervised Embedding\nin Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector\nrepresentation that systematically captures the topological proximity,\nattribute affinity and label similarity of vertices in a partially labeled\nattributed network (PLAN). Our method is designed to work in both transductive\nand inductive settings while explicitly alleviating noise effects from\noutliers. Experimental results on various datasets drawn from the web, text and\nimage domains demonstrate the advantages of SEANO over state-of-the-art methods\nin semi-supervised classification under transductive as well as inductive\nsettings. We also show that a subset of parameters in SEANO is interpretable as\noutlier score and can significantly outperform baseline methods when applied\nfor detecting network outliers. Finally, we present the use of SEANO in a\nchallenging real-world setting -- flood mapping of satellite images and show\nthat it is able to outperform modern remote sensing algorithms for this task.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 15:15:53 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 20:51:05 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2018 19:14:14 GMT"}, {"version": "v4", "created": "Thu, 26 Apr 2018 21:54:52 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Liang", "Jiongqian", ""], ["Jacobs", "Peter", ""], ["Sun", "Jiankai", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1703.08144", "submitter": "Eita Nakamura", "authors": "Eita Nakamura, Kazuyoshi Yoshii, Simon Dixon", "title": "Note Value Recognition for Piano Transcription Using Markov Random\n  Fields", "comments": "13 pages, 16 figures, version accepted to IEEE/ACM TASLP, minor\n  revision", "journal-ref": null, "doi": "10.1109/TASLP.2017.2722103", "report-no": null, "categories": "cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a statistical method for use in music transcription that\ncan estimate score times of note onsets and offsets from polyphonic MIDI\nperformance signals. Because performed note durations can deviate largely from\nscore-indicated values, previous methods had the problem of not being able to\naccurately estimate offset score times (or note values) and thus could only\noutput incomplete musical scores. Based on observations that the pitch context\nand onset score times are influential on the configuration of note values, we\nconstruct a context-tree model that provides prior distributions of note values\nusing these features and combine it with a performance model in the framework\nof Markov random fields. Evaluation results show that our method reduces the\naverage error rate by around 40 percent compared to existing/simple methods. We\nalso confirmed that, in our model, the score model plays a more important role\nthan the performance model, and it automatically captures the voice structure\nby unsupervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 17:07:14 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 22:26:42 GMT"}, {"version": "v3", "created": "Fri, 7 Jul 2017 13:10:15 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Nakamura", "Eita", ""], ["Yoshii", "Kazuyoshi", ""], ["Dixon", "Simon", ""]]}, {"id": "1703.08262", "submitter": "Xiaobin Zhang", "authors": "Xiaobin Zhang, Bo Wu, Hai Lin", "title": "Supervisor Synthesis of POMDP based on Automata Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a general and thus popular model for autonomous systems, partially\nobservable Markov decision process (POMDP) can capture uncertainties from\ndifferent sources like sensing noises, actuation errors, and uncertain\nenvironments. However, its comprehensiveness makes the planning and control in\nPOMDP difficult. Traditional POMDP planning problems target to find the optimal\npolicy to maximize the expectation of accumulated rewards. But for safety\ncritical applications, guarantees of system performance described by formal\nspecifications are desired, which motivates us to consider formal methods to\nsynthesize supervisor for POMDP. With system specifications given by\nProbabilistic Computation Tree Logic (PCTL), we propose a supervisory control\nframework with a type of deterministic finite automata (DFA), za-DFA, as the\ncontroller form. While the existing work mainly relies on optimization\ntechniques to learn fixed-size finite state controllers (FSCs), we develop an\n$L^*$ learning based algorithm to determine both space and transitions of\nza-DFA. Membership queries and different oracles for conjectures are defined.\nThe learning algorithm is sound and complete. An example is given in detailed\nsteps to illustrate the supervisor synthesis algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 01:59:11 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Zhang", "Xiaobin", ""], ["Wu", "Bo", ""], ["Lin", "Hai", ""]]}, {"id": "1703.08383", "submitter": "Joseph Lemley", "authors": "Joseph Lemley, Shabab Bazrafkan, Peter Corcoran", "title": "Smart Augmentation - Learning an Optimal Data Augmentation Strategy", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2017.2696121", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recurring problem faced when training neural networks is that there is\ntypically not enough data to maximize the generalization capability of deep\nneural networks(DNN). There are many techniques to address this, including data\naugmentation, dropout, and transfer learning. In this paper, we introduce an\nadditional method which we call Smart Augmentation and we show how to use it to\nincrease the accuracy and reduce overfitting on a target network. Smart\nAugmentation works by creating a network that learns how to generate augmented\ndata during the training process of a target network in a way that reduces that\nnetworks loss. This allows us to learn augmentations that minimize the error of\nthat network.\n  Smart Augmentation has shown the potential to increase accuracy by\ndemonstrably significant measures on all datasets tested. In addition, it has\nshown potential to achieve similar or improved performance levels with\nsignificantly smaller network sizes in a number of tested cases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 12:07:34 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Lemley", "Joseph", ""], ["Bazrafkan", "Shabab", ""], ["Corcoran", "Peter", ""]]}, {"id": "1703.08397", "submitter": "Christian Stra{\\ss}er", "authors": "Mathieu Beirlaen and Jesse Heyninck and Christian Stra{\\ss}er", "title": "Reasoning by Cases in Structured Argumentation", "comments": "Proceedings of SAC/KRR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the $ASPIC^+$ framework for structured argumentation so as to allow\napplications of the reasoning by cases inference scheme for defeasible\narguments. Given an argument with conclusion `$A$ or $B$', an argument based on\n$A$ with conclusion $C$, and an argument based on $B$ with conclusion $C$, we\nallow the construction of an argument with conclusion $C$. We show how our\nframework leads to different results than other approaches in non-monotonic\nlogic for dealing with disjunctive information, such as disjunctive default\ntheory or approaches based on the OR-rule (which allows to derive a defeasible\nrule `If ($A$ or $B$) then $C$', given two defeasible rules `If $A$ then $C$'\nand `If $B$ then $C$'). We raise new questions regarding the subtleties of\nreasoning defeasibly with disjunctive information, and show that its\nformalization is more intricate than one would presume.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 13:00:52 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Beirlaen", "Mathieu", ""], ["Heyninck", "Jesse", ""], ["Stra\u00dfer", "Christian", ""]]}, {"id": "1703.08428", "submitter": "Justin Cranshaw", "authors": "Justin Cranshaw, Emad Elwany, Todd Newman, Rafal Kocielnik, Bowen Yu,\n  Sandeep Soni, Jaime Teevan, Andr\\'es Monroy-Hern\\'andez", "title": "Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans\n  in the Loop", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3025453.3025780", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although information workers may complain about meetings, they are an\nessential part of their work life. Consequently, busy people spend a\nsignificant amount of time scheduling meetings. We present Calendar.help, a\nsystem that provides fast, efficient scheduling through structured workflows.\nUsers interact with the system via email, delegating their scheduling needs to\nthe system as if it were a human personal assistant. Common scheduling\nscenarios are broken down using well-defined workflows and completed as a\nseries of microtasks that are automated when possible and executed by a human\notherwise. Unusual scenarios fall back to a trained human assistant who\nexecutes them as unstructured macrotasks. We describe the iterative approach we\nused to develop Calendar.help, and share the lessons learned from scheduling\nthousands of meetings during a year of real-world deployments. Our findings\nprovide insight into how complex information tasks can be broken down into\nrepeatable components that can be executed efficiently to improve productivity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 14:40:31 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Cranshaw", "Justin", ""], ["Elwany", "Emad", ""], ["Newman", "Todd", ""], ["Kocielnik", "Rafal", ""], ["Yu", "Bowen", ""], ["Soni", "Sandeep", ""], ["Teevan", "Jaime", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1703.08475", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, Byoung-Tak Zhang", "title": "Overcoming Catastrophic Forgetting by Incremental Moment Matching", "comments": "Accepted for NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a problem of neural networks that loses the\ninformation of the first task after training the second task. Here, we propose\na method, i.e. incremental moment matching (IMM), to resolve this problem. IMM\nincrementally matches the moment of the posterior distribution of the neural\nnetwork which is trained on the first and the second task, respectively. To\nmake the search space of posterior parameter smooth, the IMM procedure is\ncomplemented by various transfer learning techniques including weight transfer,\nL2-norm of the old and the new parameter, and a variant of dropout with the old\nparameter. We analyze our approach on a variety of datasets including the\nMNIST, CIFAR-10, Caltech-UCSD-Birds, and Lifelog datasets. The experimental\nresults show that IMM achieves state-of-the-art performance by balancing the\ninformation between an old and a new network.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:43:39 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 13:01:46 GMT"}, {"version": "v3", "created": "Tue, 30 Jan 2018 05:01:28 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Kim", "Jin-Hwa", ""], ["Jun", "Jaehyun", ""], ["Ha", "Jung-Woo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1703.08705", "submitter": "Franck Dernoncourt", "authors": "Sebastian Gehrmann, Franck Dernoncourt, Yeran Li, Eric T. Carlson, Joy\n  T. Wu, Jonathan Welt, John Foote Jr., Edward T. Moseley, David W. Grant,\n  Patrick D. Tyler, Leo Anthony Celi", "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 15:37:09 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Dernoncourt", "Franck", ""], ["Li", "Yeran", ""], ["Carlson", "Eric T.", ""], ["Wu", "Joy T.", ""], ["Welt", "Jonathan", ""], ["Foote", "John", "Jr."], ["Moseley", "Edward T.", ""], ["Grant", "David W.", ""], ["Tyler", "Patrick D.", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "1703.08762", "submitter": "Sanaz Bahargam Sanaz Bahargam", "authors": "Sanaz Bahargam, D\\'ora Erdos, Azer Bestavros, Evimaria Terzi", "title": "Team Formation for Scheduling Educational Material in Massive Online\n  Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether teaching in a classroom or a Massive Online Open Course it is crucial\nto present the material in a way that benefits the audience as a whole. We\nidentify two important tasks to solve towards this objective, 1 group students\nso that they can maximally benefit from peer interaction and 2 find an optimal\nschedule of the educational material for each group. Thus, in this paper, we\nsolve the problem of team formation and content scheduling for education. Given\na time frame d, a set of students S with their required need to learn different\nactivities T and given k as the number of desired groups, we study the problem\nof finding k group of students. The goal is to teach students within time frame\nd such that their potential for learning is maximized and find the best\nschedule for each group. We show this problem to be NP-hard and develop a\npolynomial algorithm for it. We show our algorithm to be effective both on\nsynthetic as well as a real data set. For our experiments, we use real data on\nstudents' grades in a Computer Science department. As part of our contribution,\nwe release a semi-synthetic dataset that mimics the properties of the real\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 03:47:54 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Bahargam", "Sanaz", ""], ["Erdos", "D\u00f3ra", ""], ["Bestavros", "Azer", ""], ["Terzi", "Evimaria", ""]]}, {"id": "1703.08769", "submitter": "Hang Zhao", "authors": "Hang Zhao, Xavier Puig, Bolei Zhou, Sanja Fidler, Antonio Torralba", "title": "Open Vocabulary Scene Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing arbitrary objects in the wild has been a challenging problem due\nto the limitations of existing classification models and datasets. In this\npaper, we propose a new task that aims at parsing scenes with a large and open\nvocabulary, and several evaluation metrics are explored for this problem. Our\nproposed approach to this problem is a joint image pixel and word concept\nembeddings framework, where word concepts are connected by semantic relations.\nWe validate the open vocabulary prediction ability of our framework on ADE20K\ndataset which covers a wide variety of scenes and objects. We further explore\nthe trained joint embedding space to show its interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 05:44:56 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 18:28:20 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Zhao", "Hang", ""], ["Puig", "Xavier", ""], ["Zhou", "Bolei", ""], ["Fidler", "Sanja", ""], ["Torralba", "Antonio", ""]]}, {"id": "1703.08825", "submitter": "Ricardo Bessa Dr.", "authors": "Rui Pinto, Ricardo Bessa and Manuel Matos", "title": "Multi-Period Flexibility Forecast for Low Voltage Prosumers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-future electric distribution grids operation will have to rely on\ndemand-side flexibility, both by implementation of demand response strategies\nand by taking advantage of the intelligent management of increasingly common\nsmall-scale energy storage. The Home energy management system (HEMS), installed\nat low voltage residential clients, will play a crucial role on the flexibility\nprovision to both system operators and market players like aggregators.\nModeling and forecasting multi-period flexibility from residential prosumers,\nsuch as battery storage and electric water heater, while complying with\ninternal constraints (comfort levels, data privacy) and uncertainty is a\ncomplex task. This papers describes a computational method that is capable of\nefficiently learn and define the feasibility flexibility space from\ncontrollable resources connected to a HEMS. An Evolutionary Particle Swarm\nOptimization (EPSO) algorithm is adopted and reshaped to derive a set of\nfeasible temporal trajectories for the residential net-load, considering\nstorage, flexible appliances, and predefined costumer preferences, as well as\nload and photovoltaic (PV) forecast uncertainty. A support vector data\ndescription (SVDD) algorithm is used to build models capable of classifying\nfeasible and non-feasible HEMS operating trajectories upon request from an\noptimization/control algorithm operated by a DSO or market player.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 15:26:34 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 22:05:54 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 11:19:47 GMT"}, {"version": "v4", "created": "Wed, 8 Nov 2017 17:28:50 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Pinto", "Rui", ""], ["Bessa", "Ricardo", ""], ["Matos", "Manuel", ""]]}, {"id": "1703.08840", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Jiaming Song, Stefano Ermon", "title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations", "comments": "14 pages, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of imitation learning is to mimic expert behavior without access to\nan explicit reward signal. Expert demonstrations provided by humans, however,\noften show significant variability due to latent factors that are typically not\nexplicitly modeled. In this paper, we propose a new algorithm that can infer\nthe latent structure of expert demonstrations in an unsupervised way. Our\nmethod, built on top of Generative Adversarial Imitation Learning, can not only\nimitate complex behaviors, but also learn interpretable and meaningful\nrepresentations of complex behavioral data, including visual demonstrations. In\nthe driving domain, we show that a model learned from human demonstrations is\nable to both accurately reproduce a variety of behaviors and accurately\nanticipate human actions using raw visual inputs. Compared with various\nbaselines, our method can better capture the latent structure underlying expert\ndemonstrations, often recovering semantically meaningful factors of variation\nin the data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:20:36 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 21:51:21 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Li", "Yunzhu", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1703.08862", "submitter": "Michael Everett", "authors": "Yu Fan Chen, Michael Everett, Miao Liu, and Jonathan P. How", "title": "Socially Aware Motion Planning with Deep Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For robotic vehicles to navigate safely and efficiently in pedestrian-rich\nenvironments, it is important to model subtle human behaviors and navigation\nrules (e.g., passing on the right). However, while instinctive to humans,\nsocially compliant navigation is still difficult to quantify due to the\nstochasticity in people's behaviors. Existing works are mostly focused on using\nfeature-matching techniques to describe and imitate human paths, but often do\nnot generalize well since the feature values can vary from person to person,\nand even run to run. This work notes that while it is challenging to directly\nspecify the details of what to do (precise mechanisms of human navigation), it\nis straightforward to specify what not to do (violations of social norms).\nSpecifically, using deep reinforcement learning, this work develops a\ntime-efficient navigation policy that respects common social norms. The\nproposed method is shown to enable fully autonomous navigation of a robotic\nvehicle moving at human walking speed in an environment with many pedestrians.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 19:39:50 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 23:35:25 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Chen", "Yu Fan", ""], ["Everett", "Michael", ""], ["Liu", "Miao", ""], ["How", "Jonathan P.", ""]]}, {"id": "1703.08922", "submitter": "Naveen Sundar Govindarajulu", "authors": "Naveen Sundar Govindarajulu, Selmer Bringsjord", "title": "On Automating the Doctrine of Double Effect", "comments": "26th International Joint Conference on Artificial Intelligence 2017;\n  Special Track on AI & Autonomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The doctrine of double effect ($\\mathcal{DDE}$) is a long-studied ethical\nprinciple that governs when actions that have both positive and negative\neffects are to be allowed. The goal in this paper is to automate\n$\\mathcal{DDE}$. We briefly present $\\mathcal{DDE}$, and use a first-order\nmodal logic, the deontic cognitive event calculus, as our framework to\nformalize the doctrine. We present formalizations of increasingly stronger\nversions of the principle, including what is known as the doctrine of triple\neffect. We then use our framework to simulate successfully scenarios that have\nbeen used to test for the presence of the principle in human subjects. Our\nframework can be used in two different modes: One can use it to build\n$\\mathcal{DDE}$-compliant autonomous systems from scratch, or one can use it to\nverify that a given AI system is $\\mathcal{DDE}$-compliant, by applying a\n$\\mathcal{DDE}$ layer on an existing system or model. For the latter mode, the\nunderlying AI system can be built using any architecture (planners, deep neural\nnetworks, bayesian networks, knowledge-representation systems, or a hybrid); as\nlong as the system exposes a few parameters in its model, such verification is\npossible. The role of the $\\mathcal{DDE}$ layer here is akin to a (dynamic or\nstatic) software verifier that examines existing software modules. Finally, we\nend by presenting initial work on how one can apply our $\\mathcal{DDE}$ layer\nto the STRIPS-style planning model, and to a modified POMDP model.This is\npreliminary work to illustrate the feasibility of the second mode, and we hope\nthat our initial sketches can be useful for other researchers in incorporating\nDDE in their own frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 04:03:56 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 22:20:23 GMT"}, {"version": "v3", "created": "Mon, 29 May 2017 18:10:53 GMT"}, {"version": "v4", "created": "Thu, 22 Jun 2017 22:11:32 GMT"}, {"version": "v5", "created": "Mon, 17 Jul 2017 23:12:54 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Govindarajulu", "Naveen Sundar", ""], ["Bringsjord", "Selmer", ""]]}, {"id": "1703.08944", "submitter": "Ahmed Qureshi", "authors": "Ahmed Hussain Qureshi and Yasar Ayaz", "title": "Intelligent bidirectional rapidly-exploring random trees for optimal\n  motion planning in complex cluttered environments", "comments": "The article is published in Elsevier Journal of Robotics and\n  Autonomous Systems", "journal-ref": "Robotics and Autonomous Systems 68 (2015): 1-11", "doi": "10.1016/j.robot.2015.02.007", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sampling based motion planning algorithm known as Rapidly-exploring\nRandom Trees (RRT) has gained the attention of many researchers due to their\ncomputational efficiency and effectiveness. Recently, a variant of RRT called\nRRT* has been proposed that ensures asymptotic optimality. Subsequently its\nbidirectional version has also been introduced in the literature known as\nBidirectional-RRT* (B-RRT*). We introduce a new variant called Intelligent\nBidirectional-RRT* (IB-RRT*) which is an improved variant of the optimal RRT*\nand bidirectional version of RRT* (B-RRT*) algorithms and is specially designed\nfor complex cluttered environments. IB-RRT* utilizes the bidirectional trees\napproach and introduces intelligent sample insertion heuristic for fast\nconvergence to the optimal path solution using uniform sampling heuristics. The\nproposed algorithm is evaluated theoretically and experimental results are\npresented that compares IB-RRT* with RRT* and B-RRT*. Moreover, experimental\nresults demonstrate the superior efficiency of IB-RRT* in comparison with RRT*\nand B-RRT in complex cluttered environments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 06:19:38 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Qureshi", "Ahmed Hussain", ""], ["Ayaz", "Yasar", ""]]}, {"id": "1703.09179", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi, Gy\\\"orgy Fazekas, Mark Sandler and Kyunghyun Cho", "title": "Transfer learning for music classification and regression tasks", "comments": "18th International Society of Music Information Retrieval (ISMIR)\n  Conference, Suzhou, China, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a transfer learning approach for music\nclassification and regression tasks. We propose to use a pre-trained convnet\nfeature, a concatenated feature vector using the activations of feature maps of\nmultiple layers in a trained convolutional network. We show how this convnet\nfeature can serve as general-purpose music representation. In the experiments,\na convnet is trained for music tagging and then transferred to other\nmusic-related classification and regression tasks. The convnet feature\noutperforms the baseline MFCC feature in all the considered tasks and several\nprevious approaches that are aggregating MFCCs as well as low- and high-level\nmusic features.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 16:48:03 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 15:58:38 GMT"}, {"version": "v3", "created": "Sat, 15 Jul 2017 13:36:05 GMT"}, {"version": "v4", "created": "Wed, 13 Sep 2017 16:20:26 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Choi", "Keunwoo", ""], ["Fazekas", "Gy\u00f6rgy", ""], ["Sandler", "Mark", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1703.09310", "submitter": "Brett Israelsen", "authors": "Brett W. Israelsen, Nisar Ahmed, Kenneth Center, Roderick Green,\n  Winston Bennett Jr", "title": "Adaptive Simulation-based Training of AI Decision-makers using Bayesian\n  Optimization", "comments": "submitted to JAIS for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies how an AI-controlled dog-fighting agent with tunable\ndecision-making parameters can learn to optimize performance against an\nintelligent adversary, as measured by a stochastic objective function evaluated\non simulated combat engagements. Gaussian process Bayesian optimization (GPBO)\ntechniques are developed to automatically learn global Gaussian Process (GP)\nsurrogate models, which provide statistical performance predictions in both\nexplored and unexplored areas of the parameter space. This allows a learning\nengine to sample full-combat simulations at parameter values that are most\nlikely to optimize performance and also provide highly informative data points\nfor improving future predictions. However, standard GPBO methods do not provide\na reliable surrogate model for the highly volatile objective functions found in\naerial combat, and thus do not reliably identify global maxima. These issues\nare addressed by novel Repeat Sampling (RS) and Hybrid Repeat/Multi-point\nSampling (HRMS) techniques. Simulation studies show that HRMS improves the\naccuracy of GP surrogate models, allowing AI decision-makers to more accurately\npredict performance and efficiently tune parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 21:05:15 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 22:54:26 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Israelsen", "Brett W.", ""], ["Ahmed", "Nisar", ""], ["Center", "Kenneth", ""], ["Green", "Roderick", ""], ["Bennett", "Winston", "Jr"]]}, {"id": "1703.09368", "submitter": "Jingchi Jiang", "authors": "Jingchi Jiang and Chao Zhao and Yi Guan and Qiubin Yu", "title": "Learning and inference in knowledge-based probabilistic model for\n  medical diagnosis", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a weighted knowledge graph to represent first-order knowledge and\ncombining it with a probabilistic model, we propose a methodology for the\ncreation of a medical knowledge network (MKN) in medical diagnosis. When a set\nof symptoms is activated for a specific patient, we can generate a ground\nmedical knowledge network composed of symptom nodes and potential disease\nnodes. By Incorporating a Boltzmann machine into the potential function of a\nMarkov network, we investigated the joint probability distribution of the MKN.\nIn order to deal with numerical symptoms, a multivariate inference model is\npresented that uses conditional probability. In addition, the weights for the\nknowledge graph were efficiently learned from manually annotated Chinese\nElectronic Medical Records (CEMRs). In our experiments, we found numerically\nthat the optimum choice of the quality of disease node and the expression of\nsymptom variable can improve the effectiveness of medical diagnosis. Our\nexperimental results comparing a Markov logic network and the logistic\nregression algorithm on an actual CEMR database indicate that our method holds\npromise and that MKN can facilitate studies of intelligent diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 01:51:34 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Jiang", "Jingchi", ""], ["Zhao", "Chao", ""], ["Guan", "Yi", ""], ["Yu", "Qiubin", ""]]}, {"id": "1703.09370", "submitter": "Thomas Ploetz", "authors": "Yu Guan and Thomas Ploetz", "title": "Ensembles of Deep LSTM Learners for Activity Recognition using Wearables", "comments": "accepted for publication in ACM IMWUT (Ubicomp) 2017", "journal-ref": null, "doi": "10.1145/3090076", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning (DL) methods have been introduced very successfully\ninto human activity recognition (HAR) scenarios in ubiquitous and wearable\ncomputing. Especially the prospect of overcoming the need for manual feature\ndesign combined with superior classification capabilities render deep neural\nnetworks very attractive for real-life HAR application. Even though DL-based\napproaches now outperform the state-of-the-art in a number of recognitions\ntasks of the field, yet substantial challenges remain. Most prominently, issues\nwith real-life datasets, typically including imbalanced datasets and\nproblematic data quality, still limit the effectiveness of activity recognition\nusing wearables. In this paper we tackle such challenges through Ensembles of\ndeep Long Short Term Memory (LSTM) networks. We have developed modified\ntraining procedures for LSTM networks and combine sets of diverse LSTM learners\ninto classifier collectives. We demonstrate, both formally and empirically,\nthat Ensembles of deep LSTM learners outperform the individual LSTM networks.\nThrough an extensive experimental evaluation on three standard benchmarks\n(Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition\ncapabilities of our approach and its potential for real-life applications of\nhuman activity recognition.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 02:00:47 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Guan", "Yu", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1703.09387", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja, Ian Fischer", "title": "Adversarial Transformation Networks: Learning to Generate Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple different approaches of generating adversarial examples have been\nproposed to attack deep neural networks. These approaches involve either\ndirectly computing gradients with respect to the image pixels, or directly\nsolving an optimization on the image pixels. In this work, we present a\nfundamentally new method for generating adversarial examples that is fast to\nexecute and provides exceptional diversity of output. We efficiently train\nfeed-forward neural networks in a self-supervised manner to generate\nadversarial examples against a target network or set of networks. We call such\na network an Adversarial Transformation Network (ATN). ATNs are trained to\ngenerate adversarial examples that minimally modify the classifier's outputs\ngiven the original input, while constraining the new classification to match an\nadversarial target class. We present methods to train ATNs and analyze their\neffectiveness targeting a variety of MNIST classifiers as well as the latest\nstate-of-the-art ImageNet classifier Inception ResNet v2.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 03:24:33 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Baluja", "Shumeet", ""], ["Fischer", "Ian", ""]]}, {"id": "1703.09513", "submitter": "Aleksey Buzmakov", "authors": "Aleksey Buzmakov and Sergei O. Kuznetsov and Amedeo Napoli", "title": "Mining Best Closed Itemsets for Projection-antimonotonic Constraints in\n  Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential explosion of the set of patterns is one of the main\nchallenges in pattern mining. This challenge is approached by introducing a\nconstraint for pattern selection. One of the first constraints proposed in\npattern mining is support (frequency) of a pattern in a dataset. Frequency is\nan anti-monotonic function, i.e., given an infrequent pattern, all its\nsuperpatterns are not frequent. However, many other constraints for pattern\nselection are neither monotonic nor anti-monotonic, which makes it difficult to\ngenerate patterns satisfying these constraints.\n  In order to deal with nonmonotonic constraints we introduce the notion of\n\"projection antimonotonicity\" and SOFIA algorithm that allow generating best\npatterns for a class of nonmonotonic constraints. Cosine interest, robustness,\nstability of closed itemsets, and the associated delta-measure are among these\nconstraints. SOFIA starts from light descriptions of transactions in dataset (a\nsmall set of items in the case of itemset description) and then iteratively\nadds more information to these descriptions (more items with indication of\ntidsets they describe).\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 11:40:44 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Buzmakov", "Aleksey", ""], ["Kuznetsov", "Sergei O.", ""], ["Napoli", "Amedeo", ""]]}, {"id": "1703.09527", "submitter": "Santiago Castro", "authors": "Santiago Castro and Mat\\'ias Cubero and Diego Garat and Guillermo\n  Moncecchi", "title": "Is This a Joke? Detecting Humor in Spanish Tweets", "comments": "Preprint version, without referral", "journal-ref": "Presented in Iberamia 2016. The final publication is available at\n  link.springer.com:\n  https://link.springer.com/chapter/10.1007%2F978-3-319-47955-2_12", "doi": "10.1007/978-3-319-47955-2_12", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While humor has been historically studied from a psychological, cognitive and\nlinguistic standpoint, its study from a computational perspective is an area\nyet to be explored in Computational Linguistics. There exist some previous\nworks, but a characterization of humor that allows its automatic recognition\nand generation is far from being specified. In this work we build a\ncrowdsourced corpus of labeled tweets, annotated according to its humor value,\nletting the annotators subjectively decide which are humorous. A humor\nclassifier for Spanish tweets is assembled based on supervised learning,\nreaching a precision of 84% and a recall of 69%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 12:08:46 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Castro", "Santiago", ""], ["Cubero", "Mat\u00edas", ""], ["Garat", "Diego", ""], ["Moncecchi", "Guillermo", ""]]}, {"id": "1703.09620", "submitter": "Christoph Benzm\\\"uller", "authors": "Christoph Benzm\\\"uller", "title": "Universal Reasoning, Rational Argumentation and Human-Machine\n  Interaction", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical higher-order logic, when utilized as a meta-logic in which various\nother (classical and non-classical) logics can be shallowly embedded, is well\nsuited for realising a universal logic reasoning approach. Universal logic\nreasoning in turn, as envisioned already by Leibniz, may support the rigorous\nformalisation and deep logical analysis of rational arguments within machines.\nA respective universal logic reasoning framework is described and a range of\nexemplary applications are discussed. In the future, universal logic reasoning\nin combination with appropriate, controlled forms of rational argumentation may\nserve as a communication layer between humans and intelligent machines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 15:00:57 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""]]}, {"id": "1703.09684", "submitter": "Kushal Kafle", "authors": "Kushal Kafle and Christopher Kanan", "title": "An Analysis of Visual Question Answering Algorithms", "comments": "To appear in ICCV 2017. Visit http://kushalkafle.com/projects/tdiuc\n  to download the dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual question answering (VQA), an algorithm must answer text-based\nquestions about images. While multiple datasets for VQA have been created since\nlate 2014, they all have flaws in both their content and the way algorithms are\nevaluated on them. As a result, evaluation scores are inflated and\npredominantly determined by answering easier questions, making it difficult to\ncompare different methods. In this paper, we analyze existing VQA algorithms\nusing a new dataset. It contains over 1.6 million questions organized into 12\ndifferent categories. We also introduce questions that are meaningless for a\ngiven image to force a VQA system to reason about image content. We propose new\nevaluation schemes that compensate for over-represented question-types and make\nit easier to study the strengths and weaknesses of algorithms. We analyze the\nperformance of both baseline and state-of-the-art VQA models, including\nmulti-modal compact bilinear pooling (MCB), neural module networks, and\nrecurrent answering units. Our experiments establish how attention helps\ncertain categories more than others, determine which models work better than\nothers, and explain how simple models (e.g. MLP) can surpass more complex\nmodels (MCB) by simply learning to answer large, easy question categories.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 17:48:07 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 18:56:45 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "1703.09700", "submitter": "Antti Kangasr\\\"a\\\"asi\\\"o", "authors": "Antti Kangasr\\\"a\\\"asi\\\"o, Samuel Kaski", "title": "Inverse Reinforcement Learning from Summary Data", "comments": "To appear in ECMLPKDD'2018", "journal-ref": null, "doi": "10.1007/s10994-018-5730-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) aims to explain observed strategic\nbehavior by fitting reinforcement learning models to behavioral data. However,\ntraditional IRL methods are only applicable when the observations are in the\nform of state-action paths. This assumption may not hold in many real-world\nmodeling settings, where only partial or summarized observations are available.\nIn general, we may assume that there is a summarizing function $\\sigma$, which\nacts as a filter between us and the true state-action paths that constitute the\ndemonstration. Some initial approaches to extending IRL to such situations have\nbeen presented, but with very specific assumptions about the structure of\n$\\sigma$, such as that only certain state observations are missing. This paper\ninstead focuses on the most general case of the problem, where no assumptions\nare made about the summarizing function, except that it can be evaluated. We\ndemonstrate that inference is still possible. The paper presents exact and\napproximate inference algorithms that allow full posterior inference, which is\nparticularly important for assessing parameter uncertainty in this challenging\ninference situation. Empirical scalability is demonstrated to reasonably sized\nproblems, and practical applicability is demonstrated by estimating the\nposterior for a cognitive science RL model based on an observed user's task\ncompletion time only.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 16:13:23 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 14:55:11 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 06:46:22 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kangasr\u00e4\u00e4si\u00f6", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "1703.09784", "submitter": "Yanhai Gan", "authors": "Yanhai Gan, Huifang Chi, Ying Gao, Jun Liu, Guoqiang Zhong, Junyu Dong", "title": "Perception Driven Texture Generation", "comments": "7 pages, 4 figures, icme2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a novel task of generating texture images from\nperceptual descriptions. Previous work on texture generation focused on either\nsynthesis from examples or generation from procedural models. Generating\ntextures from perceptual attributes have not been well studied yet. Meanwhile,\nperceptual attributes, such as directionality, regularity and roughness are\nimportant factors for human observers to describe a texture. In this paper, we\npropose a joint deep network model that combines adversarial training and\nperceptual feature regression for texture generation, while only random noise\nand user-defined perceptual attributes are required as input. In this model, a\npreliminary trained convolutional neural network is essentially integrated with\nthe adversarial framework, which can drive the generated textures to possess\ngiven perceptual attributes. An important aspect of the proposed model is that,\nif we change one of the input perceptual features, the corresponding appearance\nof the generated textures will also be changed. We design several experiments\nto validate the effectiveness of the proposed method. The results show that the\nproposed method can produce high quality texture images with desired perceptual\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 01:25:30 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Gan", "Yanhai", ""], ["Chi", "Huifang", ""], ["Gao", "Ying", ""], ["Liu", "Jun", ""], ["Zhong", "Guoqiang", ""], ["Dong", "Junyu", ""]]}, {"id": "1703.09794", "submitter": "Martin Plajner", "authors": "Martin Plajner", "title": "Probabilistic Models for Computerized Adaptive Testing", "comments": "Study for Dissertation Thesis. Supervisor: Ji\\v{r}\\'i Vomlel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we follow our previous research in the area of Computerized\nAdaptive Testing (CAT). We present three different methods for CAT. One of\nthem, the item response theory, is a well established method, while the other\ntwo, Bayesian and neural networks, are new in the area of educational testing.\nIn the first part of this paper, we present the concept of CAT and its\nadvantages and disadvantages. We collected data from paper tests performed with\ngrammar school students. We provide the summary of data used for our\nexperiments in the second part. Next, we present three different model types\nfor CAT. They are based on the item response theory, Bayesian networks, and\nneural networks. The general theory associated with each type is briefly\nexplained and the utilization of these models for CAT is analyzed. Future\nresearch is outlined in the concluding part of the paper. It shows many\ninteresting research paths that are important not only for CAT but also for\nother areas of artificial intelligence.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 19:40:07 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Plajner", "Martin", ""]]}, {"id": "1703.09845", "submitter": "Krishnaram Kenthapadi", "authors": "Krishnaram Kenthapadi, Stuart Ambler, Liang Zhang, Deepak Agarwal", "title": "Bringing Salary Transparency to the World: Computing Robust Compensation\n  Insights via LinkedIn Salary", "comments": "Conference information: ACM International Conference on Information\n  and Knowledge Management (CIKM 2017)", "journal-ref": null, "doi": "10.1145/3132847.3132863", "report-no": null, "categories": "cs.SI cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently launched LinkedIn Salary product has been designed with the goal\nof providing compensation insights to the world's professionals and thereby\nhelping them optimize their earning potential. We describe the overall design\nand architecture of the statistical modeling system underlying this product. We\nfocus on the unique data mining challenges while designing and implementing the\nsystem, and describe the modeling components such as Bayesian hierarchical\nsmoothing that help to compute and present robust compensation insights to\nusers. We report on extensive evaluation with nearly one year of de-identified\ncompensation data collected from over one million LinkedIn users, thereby\ndemonstrating the efficacy of the statistical models. We also highlight the\nlessons learned through the deployment of our system at LinkedIn.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 00:21:02 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 16:49:58 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 18:24:08 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Kenthapadi", "Krishnaram", ""], ["Ambler", "Stuart", ""], ["Zhang", "Liang", ""], ["Agarwal", "Deepak", ""]]}, {"id": "1703.09891", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Zhiwei Deng, Guang-Tong Zhou, Fei Sha, Greg Mori", "title": "LabelBank: Revisiting Global Perspectives for Semantic Segmentation", "comments": "Pre-prints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation requires a detailed labeling of image pixels by object\ncategory. Information derived from local image patches is necessary to describe\nthe detailed shape of individual objects. However, this information is\nambiguous and can result in noisy labels. Global inference of image content can\ninstead capture the general semantic concepts present. We advocate that\nholistic inference of image concepts provides valuable information for detailed\npixel labeling. We propose a generic framework to leverage holistic information\nin the form of a LabelBank for pixel-level segmentation.\n  We show the ability of our framework to improve semantic segmentation\nperformance in a variety of settings. We learn models for extracting a holistic\nLabelBank from visual cues, attributes, and/or textual descriptions. We\ndemonstrate improvements in semantic segmentation accuracy on standard datasets\nacross a range of state-of-the-art segmentation architectures and holistic\ninference approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 05:58:21 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Hu", "Hexiang", ""], ["Deng", "Zhiwei", ""], ["Zhou", "Guang-Tong", ""], ["Sha", "Fei", ""], ["Mori", "Greg", ""]]}, {"id": "1703.09902", "submitter": "Albert Gatt", "authors": "Albert Gatt and Emiel Krahmer", "title": "Survey of the State of the Art in Natural Language Generation: Core\n  tasks, applications and evaluation", "comments": "Published in Journal of AI Research (JAIR), volume 61, pp 75-170. 118\n  pages, 8 figures, 1 table", "journal-ref": "Journal of AI Research, volume 60, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the current state of the art in Natural Language\nGeneration (NLG), defined as the task of generating text or speech from\nnon-linguistic input. A survey of NLG is timely in view of the changes that the\nfield has undergone over the past decade or so, especially in relation to new\n(usually data-driven) methods, as well as new applications of NLG technology.\nThis survey therefore aims to (a) give an up-to-date synthesis of research on\nthe core tasks in NLG and the architectures adopted in which such tasks are\norganised; (b) highlight a number of relatively recent research topics that\nhave arisen partly as a result of growing synergies between NLG and other areas\nof artificial intelligence; (c) draw attention to the challenges in NLG\nevaluation, relating them to similar challenges faced in other areas of Natural\nLanguage Processing, with an emphasis on different evaluation methods and the\nrelationships between them.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 06:51:00 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 18:13:29 GMT"}, {"version": "v3", "created": "Tue, 19 Dec 2017 20:11:03 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 16:09:38 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Gatt", "Albert", ""], ["Krahmer", "Emiel", ""]]}, {"id": "1703.09923", "submitter": "Deyu Meng", "authors": "Zilu Ma and Shiqi Liu and Deyu Meng", "title": "On Convergence Property of Implicit Self-paced Objective", "comments": "9 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-paced learning (SPL) is a new methodology that simulates the learning\nprinciple of humans/animals to start learning easier aspects of a learning\ntask, and then gradually take more complex examples into training. This\nnew-coming learning regime has been empirically substantiated to be effective\nin various computer vision and pattern recognition tasks. Recently, it has been\nproved that the SPL regime has a close relationship to a implicit self-paced\nobjective function. While this implicit objective could provide helpful\ninterpretations to the effectiveness, especially the robustness, insights under\nthe SPL paradigms, there are still no theoretical results strictly proved to\nverify such relationship. To this issue, in this paper, we provide some\nconvergence results on this implicit objective of SPL. Specifically, we prove\nthat the learning process of SPL always converges to critical points of this\nimplicit objective under some mild conditions. This result verifies the\nintrinsic relationship between SPL and this implicit objective, and makes the\nprevious robustness analysis on SPL complete and theoretically rational.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 07:53:43 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Ma", "Zilu", ""], ["Liu", "Shiqi", ""], ["Meng", "Deyu", ""]]}, {"id": "1703.09962", "submitter": "Mitra Baratchi Mitra Baratchi", "authors": "Mitra Baratchi, Geert Heijenk, Maarten van Steen", "title": "Spaceprint: a Mobility-based Fingerprinting Scheme for Public Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of how automated situation-awareness\ncan be achieved by learning real-world situations from ubiquitously generated\nmobility data. Without semantic input about the time and space where situations\ntake place, this turns out to be a fundamental challenging problem.\nUncertainties also introduce technical challenges when data is generated in\nirregular time intervals, being mixed with noise, and errors. Purely relying on\ntemporal patterns observable in mobility data, in this paper, we propose\nSpaceprint, a fully automated algorithm for finding the repetitive pattern of\nsimilar situations in spaces. We evaluate this technique by showing how the\nlatent variables describing the category, and the actual identity of a space\ncan be discovered from the extracted situation patterns. Doing so, we use\ndifferent real-world mobility datasets with data about the presence of mobile\nentities in a variety of spaces. We also evaluate the performance of this\ntechnique by showing its robustness against uncertainties.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 10:31:04 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Baratchi", "Mitra", ""], ["Heijenk", "Geert", ""], ["van Steen", "Maarten", ""]]}, {"id": "1703.10069", "submitter": "Ying Wen", "authors": "Peng Peng, Ying Wen, Yaodong Yang, Quan Yuan, Zhenkun Tang, Haitao\n  Long, Jun Wang", "title": "Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level\n  Coordination in Learning to Play StarCraft Combat Games", "comments": "10 pages, 10 figures. Previously as title: \"Multiagent\n  Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat\n  Games\", Mar 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many artificial intelligence (AI) applications often require multiple\nintelligent agents to work in a collaborative effort. Efficient learning for\nintra-agent communication and coordination is an indispensable step towards\ngeneral AI. In this paper, we take StarCraft combat game as a case study, where\nthe task is to coordinate multiple agents as a team to defeat their enemies. To\nmaintain a scalable yet effective communication protocol, we introduce a\nMultiagent Bidirectionally-Coordinated Network (BiCNet ['bIknet]) with a\nvectorised extension of actor-critic formulation. We show that BiCNet can\nhandle different types of combats with arbitrary numbers of AI agents for both\nsides. Our analysis demonstrates that without any supervisions such as human\ndemonstrations or labelled data, BiCNet could learn various types of advanced\ncoordination strategies that have been commonly used by experienced game\nplayers. In our experiments, we evaluate our approach against multiple\nbaselines under different scenarios; it shows state-of-the-art performance, and\npossesses potential values for large-scale real-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:37:25 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 07:01:31 GMT"}, {"version": "v3", "created": "Tue, 20 Jun 2017 10:08:42 GMT"}, {"version": "v4", "created": "Thu, 14 Sep 2017 12:45:46 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Peng", "Peng", ""], ["Wen", "Ying", ""], ["Yang", "Yaodong", ""], ["Yuan", "Quan", ""], ["Tang", "Zhenkun", ""], ["Long", "Haitao", ""], ["Wang", "Jun", ""]]}, {"id": "1703.10098", "submitter": "Tshilidzi Marwala", "authors": "Tshilidzi Marwala", "title": "Rational Choice and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of rational choice assumes that when people make decisions they do\nso in order to maximize their utility. In order to achieve this goal they ought\nto use all the information available and consider all the choices available to\nchoose an optimal choice. This paper investigates what happens when decisions\nare made by artificially intelligent machines in the market rather than human\nbeings. Firstly, the expectations of the future are more consistent if they are\nmade by an artificially intelligent machine and the decisions are more rational\nand thus marketplace becomes more rational.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:30:40 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Marwala", "Tshilidzi", ""]]}, {"id": "1703.10121", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel\n  Lopez Andrade, Jorge Meira, Petko Valtchev, Radu State", "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative\n  Meta-Study", "comments": null, "journal-ref": "Proceedings of the 25th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2017)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which topics of machine learning are most commonly addressed in research?\nThis question was initially answered in 2007 by doing a qualitative survey\namong distinguished researchers. In our study, we revisit this question from a\nquantitative perspective. Concretely, we collect 54K abstracts of papers\npublished between 2007 and 2016 in leading machine learning journals and\nconferences. We then use machine learning in order to determine the top 10\ntopics in machine learning. We not only include models, but provide a holistic\nview across optimization, data, features, etc. This quantitative approach\nallows reducing the bias of surveys. It reveals new and up-to-date insights\ninto what the 10 most prolific topics in machine learning research are. This\nallows researchers to identify popular topics as well as new and rising topics\nfor their research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 16:29:04 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Glauner", "Patrick", ""], ["Du", "Manxing", ""], ["Paraschiv", "Victor", ""], ["Boytsov", "Andrey", ""], ["Andrade", "Isabel Lopez", ""], ["Meira", "Jorge", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""]]}, {"id": "1703.10251", "submitter": "Mani A", "authors": "A. Mani", "title": "Dialectical Rough Sets, Parthood and Figures of Opposition-1", "comments": "41 pages. The second part will appear soon", "journal-ref": "Transactions on Rough Sets, Vol-XXI, 2018, 53pp", "doi": null, "report-no": null, "categories": "math.LO cs.AI cs.IT cs.LO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In one perspective, the main theme of this research revolves around the\ninverse problem in the context of general rough sets that concerns the\nexistence of rough basis for given approximations in a context. Granular\noperator spaces and variants were recently introduced by the present author as\nan optimal framework for anti-chain based algebraic semantics of general rough\nsets and the inverse problem. In the framework, various sub-types of crisp and\nnon-crisp objects are identifiable that may be missed in more restrictive\nformalism. This is also because in the latter cases concepts of complementation\nand negation are taken for granted - while in reality they have a complicated\ndialectical basis. This motivates a general approach to dialectical rough sets\nbuilding on previous work of the present author and figures of opposition. In\nthis paper dialectical rough logics are invented from a semantic perspective, a\nconcept of dialectical predicates is formalised, connection with dialetheias\nand glutty negation are established, parthood analyzed and studied from the\nviewpoint of classical and dialectical figures of opposition by the present\nauthor. Her methods become more geometrical and encompass parthood as a primary\nrelation (as opposed to roughly equivalent objects) for algebraic semantics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 21:52:52 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 19:56:43 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Mani", "A.", ""]]}, {"id": "1703.10254", "submitter": "Dale McConachie Dale McConachie", "authors": "Dale McConachie and Dmitry Berenson", "title": "Bandit-Based Model Selection for Deformable Object Manipulation", "comments": "Presented at the Workshop on the Algorithmic Foundations of Robotics,\n  2016, San Francisco, CA", "journal-ref": "Algorithmic Foundations of Robotics XII. Springer Proceedings in\n  Advanced Robotics, vol 13 (2020)", "doi": "10.1007/978-3-030-43089-4_45", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to deformable object manipulation that does not\nrely on highly-accurate modeling. The key contribution of this paper is to\nformulate the task as a Multi-Armed Bandit problem, with each arm representing\na model of the deformable object. To \"pull\" an arm and evaluate its utility, we\nuse the arm's model to generate a velocity command for the gripper(s) holding\nthe object and execute it. As the task proceeds and the object deforms, the\nutility of each model can change. Our framework estimates these changes and\nbalances exploration of the model set with exploitation of high-utility models.\nWe also propose an approach based on Kalman Filtering for Non-stationary\nMulti-armed Normal Bandits (KF-MANB) to leverage the coupling between models to\nlearn more from each arm pull. We demonstrate that our method outperforms\nprevious methods on synthetic trials, and performs competitively on several\nmanipulation tasks in simulation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 22:15:46 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["McConachie", "Dale", ""], ["Berenson", "Dmitry", ""]]}, {"id": "1703.10284", "submitter": "Mark Riedl", "authors": "Mark O. Riedl, Brent Harrison", "title": "Enter the Matrix: Safely Interruptible Autonomous Systems via\n  Virtualization", "comments": "6 pages; 1 figure; title, abstract updated; new experimental results", "journal-ref": "Proceedings of the AAAI 2019 Workshop on SafeAI", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems that operate around humans will likely always rely on kill\nswitches that stop their execution and allow them to be remote-controlled for\nthe safety of humans or to prevent damage to the system. It is theoretically\npossible for an autonomous system with sufficient sensor and effector\ncapability that learn online using reinforcement learning to discover that the\nkill switch deprives it of long-term reward and thus learn to disable the\nswitch or otherwise prevent a human operator from using the switch. This is\nreferred to as the big red button problem. We present a technique that prevents\na reinforcement learning agent from learning to disable the kill switch. We\nintroduce an interruption process in which the agent's sensors and effectors\nare redirected to a virtual simulation where it continues to believe it is\nreceiving reward. We illustrate our technique in a simple grid world\nenvironment.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 01:35:01 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 01:39:36 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Riedl", "Mark O.", ""], ["Harrison", "Brent", ""]]}, {"id": "1703.10316", "submitter": "Yantao Jia", "authors": "Denghui Zhang, Manling Li, Yantao Jia, Yuanzhuo Wang, Xueqi Cheng", "title": "Efficient Parallel Translating Embedding For Knowledge Graphs", "comments": "WI 2017: 460-468", "journal-ref": null, "doi": "10.1145/3106426.3106447", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graph embedding aims to embed entities and relations of knowledge\ngraphs into low-dimensional vector spaces. Translating embedding methods regard\nrelations as the translation from head entities to tail entities, which achieve\nthe state-of-the-art results among knowledge graph embedding methods. However,\na major limitation of these methods is the time consuming training process,\nwhich may take several days or even weeks for large knowledge graphs, and\nresult in great difficulty in practical applications. In this paper, we propose\nan efficient parallel framework for translating embedding methods, called\nParTrans-X, which enables the methods to be paralleled without locks by\nutilizing the distinguished structures of knowledge graphs. Experiments on two\ndatasets with three typical translating embedding methods, i.e., TransE [3],\nTransH [17], and a more efficient variant TransE- AdaGrad [10] validate that\nParTrans-X can speed up the training process by more than an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 05:20:18 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 10:52:29 GMT"}, {"version": "v3", "created": "Mon, 27 Nov 2017 09:09:01 GMT"}, {"version": "v4", "created": "Tue, 9 Jan 2018 02:40:30 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Zhang", "Denghui", ""], ["Li", "Manling", ""], ["Jia", "Yantao", ""], ["Wang", "Yuanzhuo", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1703.10342", "submitter": "Katharina Eggensperger", "authors": "Katharina Eggensperger and Marius Lindauer and Holger H. Hoos and\n  Frank Hutter and Kevin Leyton-Brown", "title": "Efficient Benchmarking of Algorithm Configuration Procedures via\n  Model-Based Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of algorithm (hyper-)parameters is crucial for achieving\npeak performance across a wide range of domains, ranging from deep neural\nnetworks to solvers for hard combinatorial problems. The resulting algorithm\nconfiguration (AC) problem has attracted much attention from the machine\nlearning community. However, the proper evaluation of new AC procedures is\nhindered by two key hurdles. First, AC benchmarks are hard to set up. Second\nand even more significantly, they are computationally expensive: a single run\nof an AC procedure involves many costly runs of the target algorithm whose\nperformance is to be optimized in a given AC benchmark scenario. One common\nworkaround is to optimize cheap-to-evaluate artificial benchmark functions\n(e.g., Branin) instead of actual algorithms; however, these have different\nproperties than realistic AC problems. Here, we propose an alternative\nbenchmarking approach that is similarly cheap to evaluate but much closer to\nthe original AC problem: replacing expensive benchmarks by surrogate benchmarks\nconstructed from AC benchmarks. These surrogate benchmarks approximate the\nresponse surface corresponding to true target algorithm performance using a\nregression model, and the original and surrogate benchmark share the same\n(hyper-)parameter space. In our experiments, we construct and evaluate\nsurrogate benchmarks for hyperparameter optimization as well as for AC problems\nthat involve performance optimization of solvers for hard combinatorial\nproblems, drawing training data from the runs of existing AC procedures. We\nshow that our surrogate benchmarks capture overall important characteristics of\nthe AC scenarios, such as high- and low-performing regions, from which they\nwere derived, while being much easier to use and orders of magnitude cheaper to\nevaluate.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 07:50:15 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Eggensperger", "Katharina", ""], ["Lindauer", "Marius", ""], ["Hoos", "Holger H.", ""], ["Hutter", "Frank", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "1703.10371", "submitter": "Andrea Soltoggio", "authors": "Andrea Soltoggio, Kenneth O. Stanley, Sebastian Risi", "title": "Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic\n  Artificial Neural Networks", "comments": null, "journal-ref": "Neural Networks, 2018", "doi": "10.1016/j.neunet.2018.07.013", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological plastic neural networks are systems of extraordinary computational\ncapabilities shaped by evolution, development, and lifetime learning. The\ninterplay of these elements leads to the emergence of adaptive behavior and\nintelligence. Inspired by such intricate natural phenomena, Evolved Plastic\nArtificial Neural Networks (EPANNs) use simulated evolution in-silico to breed\nplastic neural networks with a large variety of dynamics, architectures, and\nplasticity rules: these artificial systems are composed of inputs, outputs, and\nplastic components that change in response to experiences in an environment.\nThese systems may autonomously discover novel adaptive algorithms, and lead to\nhypotheses on the emergence of biological adaptation. EPANNs have seen\nconsiderable progress over the last two decades. Current scientific and\ntechnological advances in artificial neural networks are now setting the\nconditions for radically new approaches and results. In particular, the\nlimitations of hand-designed networks could be overcome by more flexible and\ninnovative solutions. This paper brings together a variety of inspiring ideas\nthat define the field of EPANNs. The main methods and results are reviewed.\nFinally, new opportunities and developments are presented.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 09:10:09 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 19:10:46 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 09:33:24 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Soltoggio", "Andrea", ""], ["Stanley", "Kenneth O.", ""], ["Risi", "Sebastian", ""]]}, {"id": "1703.10429", "submitter": "Alejandro Ramos Soto", "authors": "Alejandro Ramos-Soto, Jose M. Alonso, Ehud Reiter, Kees van Deemter,\n  Albert Gatt", "title": "An Empirical Approach for Modeling Fuzzy Geographical Descriptors", "comments": "Conference paper: Accepted for FUZZIEEE-2017. One column version for\n  arXiv (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel heuristic approach that defines fuzzy geographical\ndescriptors using data gathered from a survey with human subjects. The\nparticipants were asked to provide graphical interpretations of the descriptors\n`north' and `south' for the Galician region (Spain). Based on these\ninterpretations, our approach builds fuzzy descriptors that are able to compute\nmembership degrees for geographical locations. We evaluated our approach in\nterms of efficiency and precision. The fuzzy descriptors are meant to be used\nas the cornerstones of a geographical referring expression generation algorithm\nthat is able to linguistically characterize geographical locations and regions.\nThis work is also part of a general research effort that intends to establish a\nmethodology which reunites the empirical studies traditionally practiced in\ndata-to-text and the use of fuzzy sets to model imprecision and vagueness in\nwords and expressions for text generation purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 12:06:15 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Ramos-Soto", "Alejandro", ""], ["Alonso", "Jose M.", ""], ["Reiter", "Ehud", ""], ["van Deemter", "Kees", ""], ["Gatt", "Albert", ""]]}, {"id": "1703.10476", "submitter": "Rakshith Shetty", "authors": "Rakshith Shetty, Marcus Rohrbach, Lisa Anne Hendricks, Mario Fritz,\n  Bernt Schiele", "title": "Speaking the Same Language: Matching Machine to Human Captions by\n  Adversarial Training", "comments": "16 pages, Published in ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While strong progress has been made in image captioning over the last years,\nmachine and human captions are still quite distinct. A closer look reveals that\nthis is due to the deficiencies in the generated word distribution, vocabulary\nsize, and strong bias in the generators towards frequent captions. Furthermore,\nhumans -- rightfully so -- generate multiple, diverse captions, due to the\ninherent ambiguity in the captioning task which is not considered in today's\nsystems.\n  To address these challenges, we change the training objective of the caption\ngenerator from reproducing groundtruth captions to generating a set of captions\nthat is indistinguishable from human generated captions. Instead of\nhandcrafting such a learning target, we employ adversarial training in\ncombination with an approximate Gumbel sampler to implicitly match the\ngenerated distribution to the human one. While our method achieves comparable\nperformance to the state-of-the-art in terms of the correctness of the\ncaptions, we generate a set of diverse captions, that are significantly less\nbiased and match the word statistics better in several aspects.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 13:54:51 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 15:43:47 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Shetty", "Rakshith", ""], ["Rohrbach", "Marcus", ""], ["Hendricks", "Lisa Anne", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1703.10545", "submitter": "Srijan Kumar", "authors": "Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos\n  Faloutsos, V.S. Subrahamanian", "title": "FairJudge: Trustworthy User Prediction in Rating Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rating platforms enable large-scale collection of user opinion about items\n(products, other users, etc.). However, many untrustworthy users give\nfraudulent ratings for excessive monetary gains. In the paper, we present\nFairJudge, a system to identify such fraudulent users. We propose three\nmetrics: (i) the fairness of a user that quantifies how trustworthy the user is\nin rating the products, (ii) the reliability of a rating that measures how\nreliable the rating is, and (iii) the goodness of a product that measures the\nquality of the product. Intuitively, a user is fair if it provides reliable\nratings that are close to the goodness of the product. We formulate a mutually\nrecursive definition of these metrics, and further address cold start problems\nand incorporate behavioral properties of users and products in the formulation.\nWe propose an iterative algorithm, FairJudge, to predict the values of the\nthree metrics. We prove that FairJudge is guaranteed to converge in a bounded\nnumber of iterations, with linear time complexity. By conducting five different\nexperiments on five rating platforms, we show that FairJudge significantly\noutperforms nine existing algorithms in predicting fair and unfair users. We\nreported the 100 most unfair users in the Flipkart network to their review\nfraud investigators, and 80 users were correctly identified (80% accuracy). The\nFairJudge algorithm is already being deployed at Flipkart.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 16:02:25 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Kumar", "Srijan", ""], ["Hooi", "Bryan", ""], ["Makhija", "Disha", ""], ["Kumar", "Mohit", ""], ["Faloutsos", "Christos", ""], ["Subrahamanian", "V. S.", ""]]}, {"id": "1703.10571", "submitter": "Alex Ter-Sarkisov", "authors": "Aram Ter-Sarkisov and Robert Ross and John Kelleher", "title": "Bootstrapping Labelled Dataset Construction for Cow Tracking and\n  Behavior Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach to the long-term tracking of an object\nin a challenging environment. The object is a cow and the environment is an\nenclosure in a cowshed. Some of the key challenges in this domain are a\ncluttered background, low contrast and high similarity between moving objects\nwhich greatly reduces the efficiency of most existing approaches, including\nthose based on background subtraction. Our approach is split into object\nlocalization, instance segmentation, learning and tracking stages. Our solution\nis compared to a range of semi-supervised object tracking algorithms and we\nshow that the performance is strong and well suited to subsequent analysis. We\npresent our solution as a first step towards broader tracking and behavior\nmonitoring for cows in precision agriculture with the ultimate objective of\nearly detection of lameness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 17:09:39 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Ter-Sarkisov", "Aram", ""], ["Ross", "Robert", ""], ["Kelleher", "John", ""]]}, {"id": "1703.10579", "submitter": "Lingyu Lyu", "authors": "Lingyu Lyu, Mehmed Kantardzic", "title": "Evaluating Complex Task through Crowdsourcing: Multiple Views Approach", "comments": "8 pages, 13 figures, the paper is accepted by ICCSE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of massive open online courses, grading through\ncrowdsourcing has become a prevalent approach towards large scale classes.\nHowever, for getting grades for complex tasks, which require specific skills\nand efforts for grading, crowdsourcing encounters a restriction of insufficient\nknowledge of the workers from the crowd. Due to knowledge limitation of the\ncrowd graders, grading based on partial perspectives becomes a big challenge\nfor evaluating complex tasks through crowdsourcing. Especially for those tasks\nwhich not only need specific knowledge for grading, but also should be graded\nas a whole instead of being decomposed into smaller and simpler subtasks. We\npropose a framework for grading complex tasks via multiple views, which are\ndifferent grading perspectives defined by experts for the task, to provide\nuniformity. Aggregation algorithm based on graders variances are used to\ncombine the grades for each view. We also detect bias patterns of the graders,\nand debias them regarding each view of the task. Bias pattern determines how\nthe behavior is biased among graders, which is detected by a statistical\ntechnique. The proposed approach is analyzed on a synthetic data set. We show\nthat our model gives more accurate results compared to the grading approaches\nwithout different views and debiasing algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 17:25:47 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Lyu", "Lingyu", ""], ["Kantardzic", "Mehmed", ""]]}, {"id": "1703.10651", "submitter": "Peter Schulam", "authors": "Peter Schulam and Suchi Saria", "title": "Reliable Decision Support using Counterfactual Models", "comments": "Published in the proceedings of Neural Information Processing Systems\n  (NIPS) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-makers are faced with the challenge of estimating what is likely to\nhappen when they take an action. For instance, if I choose not to treat this\npatient, are they likely to die? Practitioners commonly use supervised learning\nalgorithms to fit predictive models that help decision-makers reason about\nlikely future outcomes, but we show that this approach is unreliable, and\nsometimes even dangerous. The key issue is that supervised learning algorithms\nare highly sensitive to the policy used to choose actions in the training data,\nwhich causes the model to capture relationships that do not generalize. We\npropose using a different learning objective that predicts counterfactuals\ninstead of predicting outcomes under an existing action policy as in supervised\nlearning. To support decision-making in temporal settings, we introduce the\nCounterfactual Gaussian Process (CGP) to predict the counterfactual future\nprogression of continuous-time trajectories under sequences of future actions.\nWe demonstrate the benefits of the CGP on two important decision-support tasks:\nrisk prediction and \"what if?\" reasoning for individualized treatment planning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:51:03 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 18:05:23 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 14:28:13 GMT"}, {"version": "v4", "created": "Thu, 1 Feb 2018 13:40:16 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Schulam", "Peter", ""], ["Saria", "Suchi", ""]]}, {"id": "1703.10847", "submitter": "Li-Chia Yang", "authors": "Li-Chia Yang, Szu-Yu Chou, and Yi-Hsuan Yang", "title": "MidiNet: A Convolutional Generative Adversarial Network for\n  Symbolic-domain Music Generation", "comments": "8 pages, Accepted to ISMIR (International Society of Music\n  Information Retrieval) Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing neural network models for music generation use recurrent neural\nnetworks. However, the recent WaveNet model proposed by DeepMind shows that\nconvolutional neural networks (CNNs) can also generate realistic musical\nwaveforms in the audio domain. Following this light, we investigate using CNNs\nfor generating melody (a series of MIDI notes) one bar after another in the\nsymbolic domain. In addition to the generator, we use a discriminator to learn\nthe distributions of melodies, making it a generative adversarial network\n(GAN). Moreover, we propose a novel conditional mechanism to exploit available\nprior knowledge, so that the model can generate melodies either from scratch,\nby following a chord sequence, or by conditioning on the melody of previous\nbars (e.g. a priming melody), among other possibilities. The resulting model,\nnamed MidiNet, can be expanded to generate music with multiple MIDI channels\n(i.e. tracks). We conduct a user study to compare the melody of eight-bar long\ngenerated by MidiNet and by Google's MelodyRNN models, each time using the same\npriming melody. Result shows that MidiNet performs comparably with MelodyRNN\nmodels in being realistic and pleasant to listen to, yet MidiNet's melodies are\nreported to be much more interesting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 10:59:58 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 08:07:36 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Yang", "Li-Chia", ""], ["Chou", "Szu-Yu", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1703.10926", "submitter": "Suleiman Yerima", "authors": "Mohammed K. Alzaylaee, Suleiman Y. Yerima, Sakir Sezer", "title": "EMULATOR vs REAL PHONE: Android Malware Detection Using Machine Learning", "comments": "IWSPA 2017 Proceedings of the 3rd ACM International Workshop on\n  Security and Privacy Analytics, co-located with CODASPY'17, Scottsdale,\n  Arizona, USA - March 24 - 24, 2017, pages 65-72", "journal-ref": null, "doi": "10.1145/3041008.3041010", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Android operating system has become the most popular operating system for\nsmartphones and tablets leading to a rapid rise in malware. Sophisticated\nAndroid malware employ detection avoidance techniques in order to hide their\nmalicious activities from analysis tools. These include a wide range of\nanti-emulator techniques, where the malware programs attempt to hide their\nmalicious activities by detecting the emulator. For this reason,\ncountermeasures against antiemulation are becoming increasingly important in\nAndroid malware detection. Analysis and detection based on real devices can\nalleviate the problems of anti-emulation as well as improve the effectiveness\nof dynamic analysis. Hence, in this paper we present an investigation of\nmachine learning based malware detection using dynamic analysis on real\ndevices. A tool is implemented to automatically extract dynamic features from\nAndroid phones and through several experiments, a comparative analysis of\nemulator based vs. device based detection by means of several machine learning\nalgorithms is undertaken. Our study shows that several features could be\nextracted more effectively from the on-device dynamic analysis compared to\nemulators. It was also found that approximately 24% more apps were successfully\nanalysed on the phone. Furthermore, all of the studied machine learning based\ndetection performed better when applied to features extracted from the\non-device dynamic analysis.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 14:59:15 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Alzaylaee", "Mohammed K.", ""], ["Yerima", "Suleiman Y.", ""], ["Sezer", "Sakir", ""]]}, {"id": "1703.10960", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Ran Zhao and Maxine Eskenazi", "title": "Learning Discourse-level Diversity for Neural Dialog Models using\n  Conditional Variational Autoencoders", "comments": "Appeared in ACL2017 proceedings as a long paper. Correct a\n  calculation mistake in Table 1 E-bow & A-bow and results into higher scores", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural encoder-decoder models have shown great promise in\nmodeling open-domain conversations, they often generate dull and generic\nresponses. Unlike past work that has focused on diversifying the output of the\ndecoder at word-level to alleviate this problem, we present a novel framework\nbased on conditional variational autoencoders that captures the discourse-level\ndiversity in the encoder. Our model uses latent variables to learn a\ndistribution over potential conversational intents and generates diverse\nresponses using only greedy decoders. We have further developed a novel variant\nthat is integrated with linguistic prior knowledge for better performance.\nFinally, the training procedure is improved by introducing a bag-of-word loss.\nOur proposed models have been validated to generate significantly more diverse\nresponses than baseline approaches and exhibit competence in discourse-level\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:55:00 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 03:38:58 GMT"}, {"version": "v3", "created": "Sat, 21 Oct 2017 04:58:20 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Zhao", "Ran", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1703.10970", "submitter": "Pantelis  Pipergias Analytis", "authors": "Pantelis P. Analytis, Hrvoje Stojic, Alexandros Gelastopoulos and\n  Mehdi Moussa\\\"id", "title": "Diversity of preferences can increase collective welfare in sequential\n  exploration problems", "comments": "4 pages, 1 figure, originally presented at the collected intelligence\n  (CI) conference in June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In search engines, online marketplaces and other human-computer interfaces\nlarge collectives of individuals sequentially interact with numerous\nalternatives of varying quality. In these contexts, trial and error\n(exploration) is crucial for uncovering novel high-quality items or solutions,\nbut entails a high cost for individual users. Self-interested decision makers,\nare often better off imitating the choices of individuals who have already\nincurred the costs of exploration. Although imitation makes sense at the\nindividual level, it deprives the group of additional information that could\nhave been gleaned by individual explorers. In this paper we show that in such\nproblems, preference diversity can function as a welfare enhancing mechanism.\nIt leads to a consistent increase in the quality of the consumed alternatives\nthat outweighs the increased cost of search for the users.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:11:44 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 01:35:06 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Analytis", "Pantelis P.", ""], ["Stojic", "Hrvoje", ""], ["Gelastopoulos", "Alexandros", ""], ["Moussa\u00efd", "Mehdi", ""]]}, {"id": "1703.11000", "submitter": "Alex Lee", "authors": "Alex X. Lee, Sergey Levine, Pieter Abbeel", "title": "Learning Visual Servoing with Deep Features and Fitted Q-Iteration", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual servoing involves choosing actions that move a robot in response to\nobservations from a camera, in order to reach a goal configuration in the\nworld. Standard visual servoing approaches typically rely on manually designed\nfeatures and analytical dynamics models, which limits their generalization\ncapability and often requires extensive application-specific feature and model\nengineering. In this work, we study how learned visual features, learned\npredictive dynamics models, and reinforcement learning can be combined to learn\nvisual servoing mechanisms. We focus on target following, with the goal of\ndesigning algorithms that can learn a visual servo using low amounts of data of\nthe target in question, to enable quick adaptation to new targets. Our approach\nis based on servoing the camera in the space of learned visual features, rather\nthan image pixels or manually-designed keypoints. We demonstrate that standard\ndeep features, in our case taken from a model trained for object\nclassification, can be used together with a bilinear predictive model to learn\nan effective visual servo that is robust to visual variation, changes in\nviewing angle and appearance, and occlusions. A key component of our approach\nis to use a sample-efficient fitted Q-iteration algorithm to learn which\nfeatures are best suited for the task at hand. We show that we can learn an\neffective visual servo on a complex synthetic car following benchmark using\njust 20 training trajectory samples for reinforcement learning. We demonstrate\nsubstantial improvement over a conventional approach based on image pixels or\nhand-designed keypoints, and we show an improvement in sample-efficiency of\nmore than two orders of magnitude over standard model-free deep reinforcement\nlearning algorithms. Videos are available at\nhttp://rll.berkeley.edu/visual_servoing .\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:45:53 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 00:26:55 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lee", "Alex X.", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}]