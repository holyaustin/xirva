[{"id": "1807.00049", "submitter": "Atishay Jain", "authors": "Anand Venkatesan, Atishay Jain, Rakesh Grewal", "title": "AI in Game Playing: Sokoban Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence is becoming instrumental in a variety of\napplications. Games serve as a good breeding ground for trying and testing\nthese algorithms in a sandbox with simpler constraints in comparison to real\nlife. In this project, we aim to develop an AI agent that can solve the\nclassical Japanese game of Sokoban using various algorithms and heuristics and\ncompare their performances through standard metrics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 19:49:09 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Venkatesan", "Anand", ""], ["Jain", "Atishay", ""], ["Grewal", "Rakesh", ""]]}, {"id": "1807.00053", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Daniel Bear, Jonas Kubilius, Kohitij Kar, Surya Ganguli,\n  David Sussillo, James J. DiCarlo, Daniel L. K. Yamins", "title": "Task-Driven Convolutional Recurrent Models of the Visual System", "comments": "NIPS 2018 Camera Ready Version, 16 pages including supplementary\n  information, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward convolutional neural networks (CNNs) are currently\nstate-of-the-art for object classification tasks such as ImageNet. Further,\nthey are quantitatively accurate models of temporally-averaged responses of\nneurons in the primate brain's visual system. However, biological visual\nsystems have two ubiquitous architectural features not shared with typical\nCNNs: local recurrence within cortical areas, and long-range feedback from\ndownstream areas to upstream areas. Here we explored the role of recurrence in\nimproving classification performance. We found that standard forms of\nrecurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the\nImageNet task. In contrast, novel cells that incorporated two structural\nfeatures, bypassing and gating, were able to boost task accuracy substantially.\nWe extended these design principles in an automated search over thousands of\nmodel architectures, which identified novel local recurrent cells and\nlong-range feedback connections useful for object recognition. Moreover, these\ntask-optimized ConvRNNs matched the dynamics of neural activity in the primate\nvisual system better than feedforward networks, suggesting a role for the\nbrain's recurrent connections in performing difficult visual behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:27:23 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 03:49:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Nayebi", "Aran", ""], ["Bear", "Daniel", ""], ["Kubilius", "Jonas", ""], ["Kar", "Kohitij", ""], ["Ganguli", "Surya", ""], ["Sussillo", "David", ""], ["DiCarlo", "James J.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1807.00082", "submitter": "Thomas Dean", "authors": "Thomas Dean, Maurice Chiang, Marcus Gomez, Nate Gruver, Yousef Hindy,\n  Michelle Lam, Peter Lu, Sophia Sanchez, Rohun Saxena, Michael Smith, Lucy\n  Wang, Catherine Wong", "title": "Amanuensis: The Programmer's Apprentice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document provides an overview of the material covered in a course taught\nat Stanford in the spring quarter of 2018. The course draws upon insight from\ncognitive and systems neuroscience to implement hybrid connectionist and\nsymbolic reasoning systems that leverage and extend the state of the art in\nmachine learning by integrating human and machine intelligence. As a concrete\nexample we focus on digital assistants that learn from continuous dialog with\nan expert software engineer while providing initial value as powerful\nanalytical, computational and mathematical savants. Over time these savants\nlearn cognitive strategies (domain-relevant problem solving skills) and develop\nintuitions (heuristics and the experience necessary for applying them) by\nlearning from their expert associates. By doing so these savants elevate their\ninnate analytical skills allowing them to partner on an equal footing as\nversatile collaborators - effectively serving as cognitive extensions and\ndigital prostheses, thereby amplifying and emulating their human partner's\nconceptually-flexible thinking patterns and enabling improved access to and\ncontrol over powerful computing resources.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 22:59:08 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 13:33:18 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Dean", "Thomas", ""], ["Chiang", "Maurice", ""], ["Gomez", "Marcus", ""], ["Gruver", "Nate", ""], ["Hindy", "Yousef", ""], ["Lam", "Michelle", ""], ["Lu", "Peter", ""], ["Sanchez", "Sophia", ""], ["Saxena", "Rohun", ""], ["Smith", "Michael", ""], ["Wang", "Lucy", ""], ["Wong", "Catherine", ""]]}, {"id": "1807.00124", "submitter": "Willie Boag", "authors": "Willie Boag and Harini Suresh and Leo Anthony Celi and Peter Szolovits\n  and Marzyeh Ghassemi", "title": "Modeling Mistrust in End-of-Life Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we characterize the doctor-patient relationship using a machine\nlearning-derived trust score. We show that this score has statistically\nsignificant racial associations, and that by modeling trust directly we find\nstronger disparities in care than by stratifying on race. We further\ndemonstrate that mistrust is indicative of worse outcomes, but is only weakly\nassociated with physiologically-created severity scores. Finally, we describe\nsentiment analysis experiments indicating patients with higher levels of\nmistrust have worse experiences and interactions with their caregivers. This\nwork is a step towards measuring fairer machine learning in the healthcare\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 04:38:47 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 05:09:17 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Boag", "Willie", ""], ["Suresh", "Harini", ""], ["Celi", "Leo Anthony", ""], ["Szolovits", "Peter", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1807.00154", "submitter": "Kaska Porayska-Pomsta", "authors": "Cristina Conati, Kaska Porayska-Pomsta, Manolis Mavrikis", "title": "AI in Education needs interpretable machine learning: Lessons from Open\n  Learner Modelling", "comments": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of the underlying AI representations is a key raison\nd'\\^{e}tre for Open Learner Modelling (OLM) -- a branch of Intelligent Tutoring\nSystems (ITS) research. OLMs provide tools for 'opening' up the AI models of\nlearners' cognition and emotions for the purpose of supporting human learning\nand teaching. Over thirty years of research in ITS (also known as AI in\nEducation) produced important work, which informs about how AI can be used in\nEducation to best effects and, through the OLM research, what are the necessary\nconsiderations to make it interpretable and explainable for the benefit of\nlearning. We argue that this work can provide a valuable starting point for a\nframework of interpretable AI, and as such is of relevance to the application\nof both knowledge-based and machine learning systems in other high-stakes\ncontexts, beyond education.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 11:28:17 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Conati", "Cristina", ""], ["Porayska-Pomsta", "Kaska", ""], ["Mavrikis", "Manolis", ""]]}, {"id": "1807.00196", "submitter": "Pedro Alejandro Ortega", "authors": "Pedro A. Ortega, Shane Legg", "title": "Modeling Friends and Foes", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can one detect friendly and adversarial behavior from raw data? Detecting\nwhether an environment is a friend, a foe, or anything in between, remains a\npoorly understood yet desirable ability for safe and robust agents. This paper\nproposes a definition of these environmental \"attitudes\" based on an\ncharacterization of the environment's ability to react to the agent's private\nstrategy. We define an objective function for a one-shot game that allows\nderiving the environment's probability distribution under friendly and\nadversarial assumptions alongside the agent's optimal strategy. Furthermore, we\npresent an algorithm to compute these equilibrium strategies, and show\nexperimentally that both friendly and adversarial environments possess\nnon-trivial optimal strategies.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 16:07:43 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ortega", "Pedro A.", ""], ["Legg", "Shane", ""]]}, {"id": "1807.00228", "submitter": "Yunpu Ma", "authors": "Yunpu Ma, Volker Tresp, Erik Daxberger", "title": "Embedding Models for Episodic Knowledge Graphs", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years a number of large-scale triple-oriented knowledge graphs have\nbeen generated and various models have been proposed to perform learning in\nthose graphs. Most knowledge graphs are static and reflect the world in its\ncurrent state. In reality, of course, the state of the world is changing: a\nhealthy person becomes diagnosed with a disease and a new president is\ninaugurated. In this paper, we extend models for static knowledge graphs to\ntemporal knowledge graphs. This enables us to store episodic data and to\ngeneralize to new facts (inductive learning). We generalize leading learning\nmodels for static knowledge graphs (i.e., Tucker, RESCAL, HolE, ComplEx,\nDistMult) to temporal knowledge graphs. In particular, we introduce a new\ntensor model, ConT, with superior generalization performance. The performances\nof all proposed models are analyzed on two different datasets: the Global\nDatabase of Events, Language, and Tone (GDELT) and the database for Integrated\nConflict Early Warning System (ICEWS). We argue that temporal knowledge graph\nembeddings might be models also for cognitive episodic memory (facts we\nremember and can recollect) and that a semantic memory (current facts we know)\ncan be generated from episodic memory by a marginalization operation. We\nvalidate this episodic-to-semantic projection hypothesis with the ICEWS\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 21:25:04 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 19:20:25 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""], ["Daxberger", "Erik", ""]]}, {"id": "1807.00275", "submitter": "Fangchang Ma", "authors": "Fangchang Ma, Guilherme Venturelli Cavalheiro, Sertac Karaman", "title": "Self-supervised Sparse-to-Dense: Self-supervised Depth Completion from\n  LiDAR and Monocular Camera", "comments": "Software:\n  https://github.com/fangchangma/self-supervised-depth-completion . Video:\n  https://youtu.be/bGXfvF261pc . 12 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth completion, the technique of estimating a dense depth image from sparse\ndepth measurements, has a variety of applications in robotics and autonomous\ndriving. However, depth completion faces 3 main challenges: the irregularly\nspaced pattern in the sparse depth input, the difficulty in handling multiple\nsensor modalities (when color images are available), as well as the lack of\ndense, pixel-level ground truth depth labels. In this work, we address all\nthese challenges. Specifically, we develop a deep regression model to learn a\ndirect mapping from sparse depth (and color images) to dense depth. We also\npropose a self-supervised training framework that requires only sequences of\ncolor and sparse depth images, without the need for dense depth labels. Our\nexperiments demonstrate that our network, when trained with semi-dense\nannotations, attains state-of-the- art accuracy and is the winning approach on\nthe KITTI depth completion benchmark at the time of submission. Furthermore,\nthe self-supervised framework outperforms a number of existing solutions\ntrained with semi- dense annotations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 06:02:48 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 00:47:09 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Ma", "Fangchang", ""], ["Cavalheiro", "Guilherme Venturelli", ""], ["Karaman", "Sertac", ""]]}, {"id": "1807.00298", "submitter": "JunPing Wang", "authors": "JunPing Wang, WenSheng Zhang, Ian Thomas, ShiHui Duan, YouKang Shi", "title": "Multi-Task Generative Adversarial Nets with Shared Memory for\n  Cross-Domain Coordination Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generating sequential decision process from huge amounts of measured process\ndata is a future research direction for collaborative factory automation,\nmaking full use of those online or offline process data to directly design\nflexible make decisions policy, and evaluate performance. The key challenges\nfor the sequential decision process is to online generate sequential\ndecision-making policy directly, and transferring knowledge across tasks\ndomain. Most multi-task policy generating algorithms often suffer from\ninsufficient generating cross-task sharing structure at discrete-time nonlinear\nsystems with applications. This paper proposes the multi-task generative\nadversarial nets with shared memory for cross-domain coordination control,\nwhich can generate sequential decision policy directly from raw sensory input\nof all of tasks, and online evaluate performance of system actions in\ndiscrete-time nonlinear systems. Experiments have been undertaken using a\nprofessional flexible manufacturing testbed deployed within a smart factory of\nWeichai Power in China. Results on three groups of discrete-time nonlinear\ncontrol tasks show that our proposed model can availably improve the\nperformance of task with the help of other related tasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 09:07:04 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Wang", "JunPing", ""], ["Zhang", "WenSheng", ""], ["Thomas", "Ian", ""], ["Duan", "ShiHui", ""], ["Shi", "YouKang", ""]]}, {"id": "1807.00340", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Meng Tian", "title": "Towards Adversarial Training with Moderate Performance Improvement for\n  Neural Network Classification", "comments": "Accepted for publication in Uncertainty in Deep Learning Workshop at\n  Uncertainty in Artificial Intelligence (UAI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that deep neural networks are prone to noisy\nexamples particular adversarial samples during inference process. The gap\nbetween robust deep learning systems in real world applications and vulnerable\nneural networks is still large. Current adversarial training strategies improve\nthe robustness against adversarial samples. However, these methods lead to\naccuracy reduction when the input examples are clean thus hinders the\npracticability. In this paper, we investigate an approach that protects the\nneural network classification from the adversarial samples and improves its\naccuracy when the input examples are clean. We demonstrate the versatility and\neffectiveness of our proposed approach on a variety of different networks and\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 15:08:52 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Tian", "Meng", ""]]}, {"id": "1807.00366", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang, Tongfang Sun, Xianjun Sam Zheng", "title": "Beyond Winning and Losing: Modeling Human Motivations and Behaviors\n  Using Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, reinforcement learning (RL) methods have been applied to\nmodel gameplay with great success, achieving super-human performance in various\nenvironments, such as Atari, Go, and Poker. However, those studies mostly focus\non winning the game and have largely ignored the rich and complex human\nmotivations, which are essential for understanding different players' diverse\nbehaviors. In this paper, we present a novel method called Multi-Motivation\nBehavior Modeling (MMBM) that takes the multifaceted human motivations into\nconsideration and models the underlying value structure of the players using\ninverse RL. Our approach does not require the access to the dynamic of the\nsystem, making it feasible to model complex interactive environments such as\nmassively multiplayer online games. MMBM is tested on the World of Warcraft\nAvatar History dataset, which recorded over 70,000 users' gameplay spanning\nthree years period. Our model reveals the significant difference of value\nstructures among different player groups. Using the results of motivation\nmodeling, we also predict and explain their diverse gameplay behaviors and\nprovide a quantitative assessment of how the redesign of the game environment\nimpacts players' behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 18:20:23 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 09:14:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Wang", "Baoxiang", ""], ["Sun", "Tongfang", ""], ["Zheng", "Xianjun Sam", ""]]}, {"id": "1807.00381", "submitter": "Oliver Schulte", "authors": "Fatemeh Riahi and Oliver Schulte", "title": "Model-based Exception Mining for Object-Relational Data", "comments": "StarAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is based on a previous publication [29]. Our work extends\nexception mining and outlier detection to the case of object-relational data.\nObject-relational data represent a complex heterogeneous network [12], which\ncomprises objects of different types, links among these objects, also of\ndifferent types, and attributes of these links. This special structure\nprohibits a direct vectorial data representation. We follow the\nwell-established Exceptional Model Mining framework, which leverages machine\nlearning models for exception mining: A object is exceptional to the extent\nthat a model learned for the object data differs from a model learned for the\ngeneral population. Exceptional objects can be viewed as outliers. We apply\nstate of-the-art probabilistic modelling techniques for object-relational data\nthat construct a graphical model (Bayesian network), which compactly represents\nprobabilistic associations in the data. A new metric, derived from the learned\nobject-relational model, quantifies the extent to which the individual\nassociation pattern of a potential outlier deviates from that of the whole\npopulation. The metric is based on the likelihood ratio of two parameter\nvectors: One that represents the population associations, and another that\nrepresents the individual associations. Our method is validated on synthetic\ndatasets and on real-world data sets about soccer matches and movies. Compared\nto baseline methods, our novel transformed likelihood ratio achieved the best\ndetection accuracy on all datasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 19:42:02 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Riahi", "Fatemeh", ""], ["Schulte", "Oliver", ""]]}, {"id": "1807.00392", "submitter": "Edward Raff", "authors": "Edward Raff and Jared Sylvester", "title": "Gradient Reversal Against Discrimination", "comments": "Proceedings of the 5'th Workshop on Fairness, Accountability and\n  Transparency in Machine Learning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No methods currently exist for making arbitrary neural networks fair. In this\nwork we introduce GRAD, a new and simplified method to producing fair neural\nnetworks that can be used for auto-encoding fair representations or directly\nwith predictive networks. It is easy to implement and add to existing\narchitectures, has only one (insensitive) hyper-parameter, and provides\nimproved individual and group fairness. We use the flexibility of GRAD to\ndemonstrate multi-attribute protection.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 20:46:20 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""]]}, {"id": "1807.00401", "submitter": "Kalyan Veeramachaneni", "authors": "James Max Kanter, Benjamin Schreck, Kalyan Veeramachaneni", "title": "Machine learning 2.0 : Engineering Data Driven AI Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML 2.0: In this paper, we propose a paradigm shift from the current practice\nof creating machine learning models - which requires months-long discovery,\nexploration and \"feasibility report\" generation, followed by re-engineering for\ndeployment - in favor of a rapid, 8-week process of development, understanding,\nvalidation and deployment that can executed by developers or subject matter\nexperts (non-ML experts) using reusable APIs. This accomplishes what we call a\n\"minimum viable data-driven model,\" delivering a ready-to-use machine learning\nmodel for problems that haven't been solved before using machine learning. We\nprovide provisions for the refinement and adaptation of the \"model,\" with\nstrict enforcement and adherence to both the scaffolding/abstractions and the\nprocess. We imagine that this will bring forth the second phase in machine\nlearning, in which discovery is subsumed by more targeted goals of delivery and\nimpact.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:50:58 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Kanter", "James Max", ""], ["Schreck", "Benjamin", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1807.00403", "submitter": "Kumar Krishna Agrawal", "authors": "Surya Bhupatiraju, Kumar Krishna Agrawal, Rishabh Singh", "title": "Towards Mixed Optimization for Reinforcement Learning with Program\n  Synthesis", "comments": "Updated publication details, format. Accepted at NAMPI workshop, ICML\n  '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has led to several recent breakthroughs, though\nthe learned policies are often based on black-box neural networks. This makes\nthem difficult to interpret and to impose desired specification constraints\nduring learning. We present an iterative framework, MORL, for improving the\nlearned policies using program synthesis. Concretely, we propose to use\nsynthesis techniques to obtain a symbolic representation of the learned policy,\nwhich can then be debugged manually or automatically using program repair.\nAfter the repair step, we use behavior cloning to obtain the policy\ncorresponding to the repaired program, which is then further improved using\ngradient descent. This process continues until the learned policy satisfies\ndesired constraints. We instantiate MORL for the simple CartPole problem and\nshow that the programmatic representation allows for high-level modifications\nthat in turn lead to improved learning of the policies.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 21:52:07 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 22:08:06 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Bhupatiraju", "Surya", ""], ["Agrawal", "Kumar Krishna", ""], ["Singh", "Rishabh", ""]]}, {"id": "1807.00412", "submitter": "Alex Kendall", "authors": "Alex Kendall, Jeffrey Hawke, David Janz, Przemyslaw Mazur, Daniele\n  Reda, John-Mark Allen, Vinh-Dieu Lam, Alex Bewley and Amar Shah", "title": "Learning to Drive in a Day", "comments": "Further results and demo videos can be viewed at:\n  https://wayve.ai/blog/l2diad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first application of deep reinforcement learning to\nautonomous driving. From randomly initialised parameters, our model is able to\nlearn a policy for lane following in a handful of training episodes using a\nsingle monocular image as input. We provide a general and easy to obtain\nreward: the distance travelled by the vehicle without the safety driver taking\ncontrol. We use a continuous, model-free deep reinforcement learning algorithm,\nwith all exploration and optimisation performed on-vehicle. This demonstrates a\nnew framework for autonomous driving which moves away from reliance on defined\nlogical rules, mapping, and direct supervision. We discuss the challenges and\nopportunities to scale this approach to a broader range of autonomous driving\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 22:47:08 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 13:56:13 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Kendall", "Alex", ""], ["Hawke", "Jeffrey", ""], ["Janz", "David", ""], ["Mazur", "Przemyslaw", ""], ["Reda", "Daniele", ""], ["Allen", "John-Mark", ""], ["Lam", "Vinh-Dieu", ""], ["Bewley", "Alex", ""], ["Shah", "Amar", ""]]}, {"id": "1807.00425", "submitter": "Mark Harmon", "authors": "Mark Harmon, Diego Klabjan", "title": "Dynamic Prediction Length for Time Series with Sequence to Sequence\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks and sequence to sequence models require a\npredetermined length for prediction output length. Our model addresses this by\nallowing the network to predict a variable length output in inference. A new\nloss function with a tailored gradient computation is developed that trades off\nprediction accuracy and output length. The model utilizes a function to\ndetermine whether a particular output at a time should be evaluated or not\ngiven a predetermined threshold. We evaluate the model on the problem of\npredicting the prices of securities. We find that the model makes longer\npredictions for more stable securities and it naturally balances prediction\naccuracy and length.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 01:00:23 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 16:31:28 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Harmon", "Mark", ""], ["Klabjan", "Diego", ""]]}, {"id": "1807.00442", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu", "title": "Policy Optimization With Penalized Point Probability Distance: An\n  Alternative To Proximal Policy Optimization", "comments": "open source", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the most successful variant and improvement for Trust Region Policy\nOptimization (TRPO), proximal policy optimization (PPO) has been widely applied\nacross various domains with several advantages: efficient data utilization,\neasy implementation, and good parallelism. In this paper, a first-order\ngradient reinforcement learning algorithm called Policy Optimization with\nPenalized Point Probability Distance (POP3D), which is a lower bound to the\nsquare of total variance divergence is proposed as another powerful variant.\nFirstly, we talk about the shortcomings of several commonly used algorithms, by\nwhich our method is partly motivated. Secondly, we address to overcome these\nshortcomings by applying POP3D. Thirdly, we dive into its mechanism from the\nperspective of solution manifold. Finally, we make quantitative comparisons\namong several state-of-the-art algorithms based on common benchmarks.\nSimulation results show that POP3D is highly competitive compared with PPO.\nBesides, our code is released in https://github.com/paperwithcode/pop3d.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 02:49:36 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 06:47:30 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 07:20:32 GMT"}, {"version": "v4", "created": "Thu, 14 Feb 2019 08:51:28 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Chu", "Xiangxiang", ""]]}, {"id": "1807.00462", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Abhinav Vishnu, Aniket Chakrabarti, Charles Siegel, and\n  Srinivasan Parthasarathy", "title": "ColdRoute: Effective Routing of Cold Questions in Stack Exchange Sites", "comments": "Accepted to the Journal Track of The European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2018); Published by Springer:\n  https://link.springer.com/article/10.1007%2Fs10618-018-0577-7", "journal-ref": "@Article{Sun2018, author=\"Sun, Jiankai and Vishnu, A. and\n  Chakrabarti, A. and Siegel, C. and Parthasarathy, S.\", title=\"ColdRoute:\n  effective routing of cold questions in stack exchange sites\", journal=\"ECML\n  PKDD\", year=\"2018\"}", "doi": "10.1007/s10618-018-0577-7", "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing questions in Community Question Answer services (CQAs) such as Stack\nExchange sites is a well-studied problem. Yet, cold-start -- a phenomena\nobserved when a new question is posted is not well addressed by existing\napproaches. Additionally, cold questions posted by new askers present\nsignificant challenges to state-of-the-art approaches. We propose ColdRoute to\naddress these challenges. ColdRoute is able to handle the task of routing cold\nquestions posted by new or existing askers to matching experts. Specifically,\nwe use Factorization Machines on the one-hot encoding of critical features such\nas question tags and compare our approach to well-studied techniques such as\nCQARank and semantic matching (LDA, BoW, and Doc2Vec). Using data from eight\nstack exchange sites, we are able to improve upon the routing metrics\n(Precision$@1$, Accuracy, MRR) over the state-of-the-art models such as\nsemantic matching by $159.5\\%$,$31.84\\%$, and $40.36\\%$ for cold questions\nposted by existing askers, and $123.1\\%$, $27.03\\%$, and $34.81\\%$ for cold\nquestions posted by new askers respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 05:08:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Sun", "Jiankai", ""], ["Vishnu", "Abhinav", ""], ["Chakrabarti", "Aniket", ""], ["Siegel", "Charles", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1807.00468", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi, Pryanshu Arora, Sudipta Chattopadhyay", "title": "Automated Directed Fairness Testing", "comments": "In Proceedings of the 2018 33rd ACM/IEEE International Conference on\n  Automated Software Engineering (ASE 18), September 3-7, 2018, Montpellier,\n  France", "journal-ref": "Automated Directed Fairness Testing. In Proceedings of the 2018\n  33rd ACM/IEEE International Conference on Automated Software Engineering (ASE\n  18), September 3-7, 2018, Montpellier, France", "doi": "10.1145/3238147.3238165", "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fairness is a critical trait in decision making. As machine-learning models\nare increasingly being used in sensitive application domains (e.g. education\nand employment) for decision making, it is crucial that the decisions computed\nby such models are free of unintended bias. But how can we automatically\nvalidate the fairness of arbitrary machine-learning models? For a given\nmachine-learning model and a set of sensitive input parameters, our AEQUITAS\napproach automatically discovers discriminatory inputs that highlight fairness\nviolation. At the core of AEQUITAS are three novel strategies to employ\nprobabilistic search over the input space with the objective of uncovering\nfairness violation. Our AEQUITAS approach leverages inherent robustness\nproperty in common machine-learning models to design and implement scalable\ntest generation methodologies. An appealing feature of our generated test\ninputs is that they can be systematically added to the training set of the\nunderlying model and improve its fairness. To this end, we design a fully\nautomated module that guarantees to improve the fairness of the underlying\nmodel.\n  We implemented AEQUITAS and we have evaluated it on six state-of-the-art\nclassifiers, including a classifier that was designed with fairness\nconstraints. We show that AEQUITAS effectively generates inputs to uncover\nfairness violation in all the subject classifiers and systematically improves\nthe fairness of the respective models using the generated test inputs. In our\nevaluation, AEQUITAS generates up to 70% discriminatory inputs (w.r.t. the\ntotal number of inputs generated) and leverages these inputs to improve the\nfairness up to 94%.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 05:29:57 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 12:08:59 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Arora", "Pryanshu", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1807.00553", "submitter": "Roel Dobbe", "authors": "Roel Dobbe, Sarah Dean, Thomas Gilbert, Nitin Kohli", "title": "A Broader View on Bias in Automated Decision-Making: Reflecting on\n  Epistemology and Dynamics", "comments": "Presented at the 2018 Workshop on Fairness, Accountability and\n  Transparency in Machine Learning during ICML 2018, Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is increasingly deployed in real world contexts,\nsupplying actionable insights and forming the basis of automated\ndecision-making systems. While issues resulting from biases pre-existing in\ntraining data have been at the center of the fairness debate, these systems are\nalso affected by technical and emergent biases, which often arise as\ncontext-specific artifacts of implementation. This position paper interprets\ntechnical bias as an epistemological problem and emergent bias as a dynamical\nfeedback phenomenon. In order to stimulate debate on how to change machine\nlearning practice to effectively address these issues, we explore this broader\nview on bias, stress the need to reflect on epistemology, and point to\nvalue-sensitive design methodologies to revisit the design and implementation\nprocess of automated decision-making systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:23:38 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 07:51:10 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Dobbe", "Roel", ""], ["Dean", "Sarah", ""], ["Gilbert", "Thomas", ""], ["Kohli", "Nitin", ""]]}, {"id": "1807.00564", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger and Oliver Schulte", "title": "Inference, Learning, and Population Size: Projectivity for SRL Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subtle difference between propositional and relational data is that in many\nrelational models, marginal probabilities depend on the population or domain\nsize. This paper connects the dependence on population size to the classic\nnotion of projectivity from statistical theory: Projectivity implies that\nrelational predictions are robust with respect to changes in domain size. We\ndiscuss projectivity for a number of common SRL systems, and identify syntactic\nfragments that are guaranteed to yield projective models. The syntactic\nconditions are restrictive, which suggests that projectivity is difficult to\nachieve in SRL, and care must be taken when working with different domain\nsizes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 09:40:00 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Jaeger", "Manfred", ""], ["Schulte", "Oliver", ""]]}, {"id": "1807.00589", "submitter": "Vishal Sharma", "authors": "Vishal Sharma, Noman Ahmed Sheikh, Happy Mittal, Vibhav Gogate and\n  Parag Singla", "title": "Lifted Marginal MAP Inference", "comments": "Accepted in UAI-18. Corrected some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted inference reduces the complexity of inference in relational\nprobabilistic models by identifying groups of constants (or atoms) which behave\nsymmetric to each other. A number of techniques have been proposed in the\nliterature for lifting marginal as well MAP inference. We present the first\napplication of lifting rules for marginal-MAP (MMAP), an important inference\nproblem in models having latent (random) variables. Our main contribution is\ntwo fold: (1) we define a new equivalence class of (logical) variables, called\nSingle Occurrence for MAX (SOM), and show that solution lies at extreme with\nrespect to the SOM variables, i.e., predicate groundings differing only in the\ninstantiation of the SOM variables take the same truth value (2) we define a\nsub-class {\\em SOM-R} (SOM Reduce) and exploit properties of extreme\nassignments to show that MMAP inference can be performed by reducing the domain\nof SOM-R variables to a single constant.We refer to our lifting technique as\nthe {\\em SOM-R} rule for lifted MMAP. Combined with existing rules such as\ndecomposer and binomial, this results in a powerful framework for lifted MMAP.\nExperiments on three benchmark domains show significant gains in both time and\nmemory compared to ground inference as well as lifted approaches not using\nSOM-R.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 10:45:21 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 12:59:57 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Sharma", "Vishal", ""], ["Sheikh", "Noman Ahmed", ""], ["Mittal", "Happy", ""], ["Gogate", "Vibhav", ""], ["Singla", "Parag", ""]]}, {"id": "1807.00614", "submitter": "Pedro Zuidberg Dos Martires", "authors": "Pedro Zuidberg Dos Martires, Anton Dries, Luc De Raedt", "title": "Knowledge Compilation with Continuous Random Variables and its\n  Application in Hybrid Probabilistic Logic Programming", "comments": "8 pages, 2 figures, StarAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic reasoning, the traditionally discrete domain has been\nelevated to the hybrid domain encompassing additionally continuous random\nvariables. Inference in the hybrid domain, however, usually necessitates to\ncondone trade-offs on either the inference on discrete or continuous random\nvariables. We introduce a novel approach based on weighted model integration\nand algebraic model counting that circumvents these trade-offs. We then show\nhow it supports knowledge compilation and exact probabilistic inference.\nMoreover, we introduce the hybrid probabilistic logic programming language\nHAL-ProbLog, an extension of ProbLog, to which we apply our inference approach.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 12:04:59 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 13:34:35 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Martires", "Pedro Zuidberg Dos", ""], ["Dries", "Anton", ""], ["De Raedt", "Luc", ""]]}, {"id": "1807.00643", "submitter": "Ankit Anand", "authors": "Gagan Madan, Ankit Anand, Mausam and Parag Singla", "title": "Block-Value Symmetries in Probabilistic Graphical Models", "comments": "11 pages, 3 figures, Accepted in UAI 2018 and StaR AI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular way for lifted inference in probabilistic graphical models is to\nfirst merge symmetric states into a single cluster (orbit) and then use these\nfor downstream inference, via variations of orbital MCMC [Niepert, 2012]. These\norbits are represented compactly using permutations over variables, and\nvariable-value (VV) pairs, but they can miss several state symmetries in a\ndomain.\n  We define the notion of permutations over block-value (BV) pairs, where a\nblock is a set of variables. BV strictly generalizes VV symmetries, and can\ncompute many more symmetries for increasing block sizes. To operationalize use\nof BV permutations in lifted inference, we describe 1) an algorithm to compute\nBV permutations given a block partition of the variables, 2) BV-MCMC, an\nextension of orbital MCMC that can sample from BV orbits, and 3) a heuristic to\nsuggest good block partitions. Our experiments show that BV-MCMC can mix much\nfaster compared to vanilla MCMC and orbital MCMC.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:03:22 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 06:09:06 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Madan", "Gagan", ""], ["Anand", "Ankit", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "1807.00703", "submitter": "Fabio Ferreira", "authors": "Fabio Ferreira, Jonas Rothfuss, Eren Erdal Aksoy, You Zhou, Tamim\n  Asfour", "title": "Introducing the Simulated Flying Shapes and Simulated Planar Manipulator\n  Datasets", "comments": "technical documentation, 2 figures, links to repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We release two artificial datasets, Simulated Flying Shapes and Simulated\nPlanar Manipulator that allow to test the learning ability of video processing\nsystems. In particular, the dataset is meant as a tool which allows to easily\nassess the sanity of deep neural network models that aim to encode, reconstruct\nor predict video frame sequences. The datasets each consist of 90000 videos.\nThe Simulated Flying Shapes dataset comprises scenes showing two objects of\nequal shape (rectangle, triangle and circle) and size in which one object\napproaches its counterpart. The Simulated Planar Manipulator shows a 3-DOF\nplanar manipulator that executes a pick-and-place task in which it has to place\na size-varying circle on a squared platform. Different from other widely used\ndatasets such as moving MNIST [1], [2], the two presented datasets involve\ngoal-oriented tasks (e.g. the manipulator grasping an object and placing it on\na platform), rather than showing random movements. This makes our datasets more\nsuitable for testing prediction capabilities and the learning of sophisticated\nmotions by a machine learning model. This technical document aims at providing\nan introduction into the usage of both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 14:20:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ferreira", "Fabio", ""], ["Rothfuss", "Jonas", ""], ["Aksoy", "Eren Erdal", ""], ["Zhou", "You", ""], ["Asfour", "Tamim", ""]]}, {"id": "1807.00734", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau", "title": "The relativistic discriminator: a key element missing from standard GAN", "comments": "https://github.com/AlexiaJM/RelativisticGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard generative adversarial network (SGAN), the discriminator\nestimates the probability that the input data is real. The generator is trained\nto increase the probability that fake data is real. We argue that it should\nalso simultaneously decrease the probability that real data is real because 1)\nthis would account for a priori knowledge that half of the data in the\nmini-batch is fake, 2) this would be observed with divergence minimization, and\n3) in optimal settings, SGAN would be equivalent to integral probability metric\n(IPM) GANs.\n  We show that this property can be induced by using a relativistic\ndiscriminator which estimate the probability that the given real data is more\nrealistic than a randomly sampled fake data. We also present a variant in which\nthe discriminator estimate the probability that the given real data is more\nrealistic than fake data, on average. We generalize both approaches to\nnon-standard GAN loss functions and we refer to them respectively as\nRelativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that\nIPM-based GANs are a subset of RGANs which use the identity function.\n  Empirically, we observe that 1) RGANs and RaGANs are significantly more\nstable and generate higher quality data samples than their non-relativistic\ncounterparts, 2) Standard RaGAN with gradient penalty generate data of better\nquality than WGAN-GP while only requiring a single discriminator update per\ngenerator update (reducing the time taken for reaching the state-of-the-art by\n400%), and 3) RaGANs are able to generate plausible high resolutions images\n(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these\nimages are of significantly better quality than the ones generated by WGAN-GP\nand SGAN with spectral normalization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:11:23 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 15:07:07 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 17:11:59 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""]]}, {"id": "1807.00737", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Learning Goal-Oriented Visual Dialog via Tempered Policy Gradient", "comments": "Published in IEEE Spoken Language Technology (SLT 2018), Athens,\n  Greece", "journal-ref": null, "doi": "10.1109/SLT.2018.8639546", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning goal-oriented dialogues by means of deep reinforcement learning has\nrecently become a popular research topic. However, commonly used policy-based\ndialogue agents often end up focusing on simple utterances and suboptimal\npolicies. To mitigate this problem, we propose a class of novel\ntemperature-based extensions for policy gradient methods, which are referred to\nas Tempered Policy Gradients (TPGs). On a recent AI-testbed, i.e., the\nGuessWhat?! game, we achieve significant improvements with two innovations. The\nfirst one is an extension of the state-of-the-art solutions with Seq2Seq and\nMemory Network structures that leads to an improvement of 7%. The second one is\nthe application of our newly developed TPG methods, which improves the\nperformance additionally by around 5% and, even more importantly, helps produce\nmore convincing utterances.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:14:43 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 05:35:32 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 08:24:41 GMT"}, {"version": "v4", "created": "Wed, 20 Feb 2019 10:22:01 GMT"}, {"version": "v5", "created": "Sun, 24 May 2020 08:03:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1807.00743", "submitter": "Tanya Braun", "authors": "Tanya Braun and Ralf M\\\"oller", "title": "Fusing First-order Knowledge Compilation and the Lifted Junction Tree\n  Algorithm", "comments": "Accepted at the Eighth International Workshop on Statistical\n  Relational AI, a version is to appear in the Proceedings of the KI-18:\n  Advances in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard approaches for inference in probabilistic formalisms with\nfirst-order constructs include lifted variable elimination (LVE) for single\nqueries as well as first-order knowledge compilation (FOKC) based on weighted\nmodel counting. To handle multiple queries efficiently, the lifted junction\ntree algorithm (LJT) uses a first-order cluster representation of a model and\nLVE as a subroutine in its computations. For certain inputs, the\nimplementations of LVE and, as a result, LJT ground parts of a model where FOKC\nhas a lifted run. The purpose of this paper is to prepare LJT as a backbone for\nlifted inference and to use any exact inference algorithm as subroutine. Using\nFOKC in LJT allows us to compute answers faster than LJT, LVE, and FOKC for\ncertain inputs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:33:48 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Braun", "Tanya", ""], ["M\u00f6ller", "Ralf", ""]]}, {"id": "1807.00744", "submitter": "Marcel Gehrke", "authors": "Marcel Gehrke, Tanya Braun, and Ralf M\\\"oller", "title": "Preventing Unnecessary Groundings in the Lifted Dynamic Junction Tree\n  Algorithm", "comments": "Accepted at the Eighth International Workshop on Statistical\n  Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lifted dynamic junction tree algorithm (LDJT) efficiently answers\nfiltering and prediction queries for probabilistic relational temporal models\nby building and then reusing a first-order cluster representation of a\nknowledge base for multiple queries and time steps. Unfortunately, a non-ideal\nelimination order can lead to groundings even though a lifted run is possible\nfor a model. We extend LDJT (i) to identify unnecessary groundings while\nproceeding in time and (ii) to prevent groundings by delaying eliminations\nthrough changes in a temporal first-order cluster representation. The extended\nversion of LDJT answers multiple temporal queries orders of magnitude faster\nthan the original version.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:33:49 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Gehrke", "Marcel", ""], ["Braun", "Tanya", ""], ["M\u00f6ller", "Ralf", ""]]}, {"id": "1807.00751", "submitter": "Zhiming Zhou", "authors": "Zhiming Zhou, Yuxuan Song, Lantao Yu, Hongwei Wang, Jiadong Liang,\n  Weinan Zhang, Zhihua Zhang, Yong Yu", "title": "Understanding the Effectiveness of Lipschitz-Continuity in Generative\n  Adversarial Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the underlying factor that leads to failure and\nsuccess in the training of GANs. We study the property of the optimal\ndiscriminative function and show that in many GANs, the gradient from the\noptimal discriminative function is not reliable, which turns out to be the\nfundamental cause of failure in training of GANs. We further demonstrate that a\nwell-defined distance metric does not necessarily guarantee the convergence of\nGANs. Finally, we prove in this paper that Lipschitz-continuity condition is a\ngeneral solution to make the gradient of the optimal discriminative function\nreliable, and characterized the necessary condition where Lipschitz-continuity\nensures the convergence, which leads to a broad family of valid GAN objectives\nunder Lipschitz-continuity condition, where Wasserstein distance is one special\ncase. We experiment with several new objectives, which are sound according to\nour theorems, and we found that, compared with Wasserstein distance, the\noutputs of the discriminator with new objectives are more stable and the final\nqualities of generated samples are also consistently higher than those produced\nby Wasserstein distance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:41:34 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 03:52:20 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 09:27:16 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 07:04:43 GMT"}, {"version": "v5", "created": "Mon, 19 Nov 2018 16:55:18 GMT"}, {"version": "v6", "created": "Sun, 23 Dec 2018 15:09:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Zhou", "Zhiming", ""], ["Song", "Yuxuan", ""], ["Yu", "Lantao", ""], ["Wang", "Hongwei", ""], ["Liang", "Jiadong", ""], ["Zhang", "Weinan", ""], ["Zhang", "Zhihua", ""], ["Yu", "Yong", ""]]}, {"id": "1807.00755", "submitter": "Csaba Szepesvari", "authors": "Gell\\'ert Weisz and Andr\\'as Gy\\\"orgy and Csaba Szepesv\\'ari", "title": "LeapsAndBounds: A Method for Approximately Optimal Algorithm\n  Configuration", "comments": "to appear at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of configuring general-purpose solvers to run\nefficiently on problem instances drawn from an unknown distribution. The goal\nof the configurator is to find a configuration that runs fast on average on\nmost instances, and do so with the least amount of total work. It can run a\nchosen solver on a random instance until the solver finishes or a timeout is\nreached. We propose LeapsAndBounds, an algorithm that tests configurations on\nrandomly selected problem instances for longer and longer time. We prove that\nthe capped expected runtime of the configuration returned by LeapsAndBounds is\nclose to the optimal expected runtime, while our algorithm's running time is\nnear-optimal. Our results show that LeapsAndBounds is more efficient than the\nrecent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the\nonly other algorithm configuration method with non-trivial theoretical\nguarantees. Experimental results on configuring a public SAT solver on a new\nbenchmark dataset also stand witness to the superiority of our method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:44:36 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Weisz", "Gell\u00e9rt", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "1807.00771", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Path Finding for the Coalition of Co-operative Agents Acting in the\n  Environment with Destructible Obstacles", "comments": "10 pages, 7 figures, conference paper, ICR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of planning a set of paths for the coalition of robots (agents)\nwith different capabilities is considered in the paper. Some agents can modify\nthe environment by destructing the obstacles thus allowing the other ones to\nshorten their paths to the goal. As a result the mutual solution of lower cost,\ne.g. time to completion, may be acquired. We suggest an original procedure to\nidentify the obstacles for further removal that can be embedded into almost any\nheuristic search planner (we use Theta*) and evaluate it empirically. Results\nof the evaluation show that time-to-complete the mission can be decreased up to\n9-12 % by utilizing the proposed technique.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:15:35 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1807.00780", "submitter": "Pengqian Yu", "authors": "Xinhan Di, Pengqian Yu, Meng Tian", "title": "Ambient Hidden Space of Generative Adversarial Networks", "comments": "Accepted for publication in Uncertainty in Deep Learning Workshop at\n  Uncertainty in Artificial Intelligence (UAI) 2018", "journal-ref": "Uncertainty in Deep Learning Workshop at Uncertainty in Artificial\n  Intelligence (UAI) 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial models are powerful tools to model structure in\ncomplex distributions for a variety of tasks. Current techniques for learning\ngenerative models require an access to samples which have high quality, and\nadvanced generative models are applied to generate samples from noisy training\ndata through ambient modules. However, the modules are only practical for the\noutput space of the generator, and their application in the hidden space is not\nwell studied. In this paper, we extend the ambient module to the hidden space\nof the generator, and provide the uniqueness condition and the corresponding\nstrategy for the ambient hidden generator in the adversarial training process.\nWe report the practicality of the proposed method on the benchmark dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:51:27 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Di", "Xinhan", ""], ["Yu", "Pengqian", ""], ["Tian", "Meng", ""]]}, {"id": "1807.00818", "submitter": "Ilya Gusev", "authors": "Daniil Anastasyev, Ilya Gusev, Eugene Indenbom", "title": "Improving part-of-speech tagging via multi-task learning and\n  character-level word representations", "comments": null, "journal-ref": "Computational Linguistics and Intellectual Technologies, Papers\n  from the Annual International Conference \"Dialogue\" (2018) Issue 17, 14-27", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the ways to improve POS-tagging using various types\nof auxiliary losses and different word representations. As a baseline, we\nutilized a BiLSTM tagger, which is able to achieve state-of-the-art results on\nthe sequence labelling tasks. We developed a new method for character-level\nword representation using feedforward neural network. Such representation gave\nus better results in terms of speed and performance of the model. We also\napplied a novel technique of pretraining such word representations with\nexisting word vectors. Finally, we designed a new variant of auxiliary loss for\nsequence labelling tasks: an additional prediction of the neighbour labels.\nSuch loss forces a model to learn the dependencies in-side a sequence of labels\nand accelerates the process of training. We test these methods on English and\nRussian languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 13:04:52 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Anastasyev", "Daniil", ""], ["Gusev", "Ilya", ""], ["Indenbom", "Eugene", ""]]}, {"id": "1807.00847", "submitter": "Jiayi Liu", "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah", "title": "Make (Nearly) Every Neural Network Better: Generating Neural Network\n  Ensembles by Weight Parameter Resampling", "comments": "Accepted at UAI Workshop on Uncertainty in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become increasingly popular in computer\nvision, natural language processing, and other areas. However, training and\nfine-tuning a deep learning model is computationally intensive and\ntime-consuming. We propose a new method to improve the performance of nearly\nevery model including pre-trained models. The proposed method uses an ensemble\napproach where the networks in the ensemble are constructed by reassigning\nmodel parameter values based on the probabilistic distribution of these\nparameters, calculated towards the end of the training process. For pre-trained\nmodels, this approach results in an additional training step (usually less than\none epoch). We perform a variety of analysis using the MNIST dataset and\nvalidate the approach with a number of DNN models using pre-trained models on\nthe ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 18:12:32 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Liu", "Jiayi", ""], ["Tripathi", "Samarth", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1807.00886", "submitter": "Sai Vikneshwar Mani Jayaraman", "authors": "Aarthy Shivram Arun, Sai Vikneshwar Mani Jayaraman, Christopher R\\'e\n  and Atri Rudra", "title": "Hypertree Decompositions Revisited for PGMs", "comments": "Accepted for StarAI Proceedings. Camera Ready Version of\n  arXiv:1804.01640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the classical problem of exact inference on probabilistic\ngraphical models (PGMs). Our algorithm is based on recent \\emph{worst-case\noptimal database join} algorithms, which can be asymptotically faster than\ntraditional data processing methods. We present the first empirical evaluation\nof these algorithms via JoinInfer -- a new exact inference engine. We\nempirically explore the properties of the data for which our engine can be\nexpected to outperform traditional inference engines, refining current\ntheoretical notions. Further, JoinInfer outperforms existing state-of-the-art\ninference engines (ACE, IJGP and libDAI) on some standard benchmark datasets by\nup to a factor of 630x. Finally, we propose a promising data-driven heuristic\nthat extends JoinInfer to automatically tailor its parameters and/or switch to\nthe traditional inference algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 21:04:06 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Arun", "Aarthy Shivram", ""], ["Jayaraman", "Sai Vikneshwar Mani", ""], ["R\u00e9", "Christopher", ""], ["Rudra", "Atri", ""]]}, {"id": "1807.00900", "submitter": "Eneldo Loza Menc\\'ia", "authors": "Patryk Hopner, Eneldo Loza Menc\\'ia", "title": "Analysis and Optimization of Deep Counterfactual Value Networks", "comments": "Long version of publication appearing at KI 2018: The 41st German\n  Conference on Artificial Intelligence\n  (http://dx.doi.org/10.1007/978-3-030-00111-7_26). Corrected typo in title", "journal-ref": null, "doi": "10.1007/978-3-030-00111-7_26", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a strong poker-playing algorithm called DeepStack was published,\nwhich is able to find an approximate Nash equilibrium during gameplay by using\nheuristic values of future states predicted by deep neural networks. This paper\nanalyzes new ways of encoding the inputs and outputs of DeepStack's deep\ncounterfactual value networks based on traditional abstraction techniques, as\nwell as an unabstracted encoding, which was able to increase the network's\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 21:36:23 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 16:48:29 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Hopner", "Patryk", ""], ["Menc\u00eda", "Eneldo Loza", ""]]}, {"id": "1807.00911", "submitter": "Isay Katsman", "authors": "Isay Katsman, Rohun Tripathi, Andreas Veit, Serge Belongie", "title": "Semantic Segmentation with Scarce Data", "comments": "ICML 2018 Workshop, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is a challenging vision problem that usually\nnecessitates the collection of large amounts of finely annotated data, which is\noften quite expensive to obtain. Coarsely annotated data provides an\ninteresting alternative as it is usually substantially more cheap. In this\nwork, we present a method to leverage coarsely annotated data along with fine\nsupervision to produce better segmentation results than would be obtained when\ntraining using only the fine data. We validate our approach by simulating a\nscarce data setting with less than 200 low resolution images from the\nCityscapes dataset and show that our method substantially outperforms solely\ntraining on the fine annotation data by an average of 15.52% mIoU and\noutperforms the coarse mask by an average of 5.28% mIoU.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 22:06:11 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 03:23:04 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Katsman", "Isay", ""], ["Tripathi", "Rohun", ""], ["Veit", "Andreas", ""], ["Belongie", "Serge", ""]]}, {"id": "1807.00962", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James, Leon O. Chua", "title": "Neuro-memristive Circuits for Edge Computing: A review", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2899262", "report-no": null, "categories": "cs.ET cs.AI cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The volume, veracity, variability, and velocity of data produced from the\never-increasing network of sensors connected to Internet pose challenges for\npower management, scalability, and sustainability of cloud computing\ninfrastructure. Increasing the data processing capability of edge computing\ndevices at lower power requirements can reduce several overheads for cloud\ncomputing solutions. This paper provides the review of neuromorphic\nCMOS-memristive architectures that can be integrated into edge computing\ndevices. We discuss why the neuromorphic architectures are useful for edge\ndevices and show the advantages, drawbacks and open problems in the field of\nneuro-memristive circuits for edge computing.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 04:07:23 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 03:55:48 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""], ["Chua", "Leon O.", ""]]}, {"id": "1807.00973", "submitter": "Varun Embar", "authors": "Varun Embar and Dhanya Sridhar and Golnoosh Farnadi and Lise Getoor", "title": "Scalable Structure Learning for Probabilistic Soft Logic", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical relational frameworks such as Markov logic networks and\nprobabilistic soft logic (PSL) encode model structure with weighted first-order\nlogical clauses. Learning these clauses from data is referred to as structure\nlearning. Structure learning alleviates the manual cost of specifying models.\nHowever, this benefit comes with high computational costs; structure learning\ntypically requires an expensive search over the space of clauses which involves\nrepeated optimization of clause weights. In this paper, we propose the first\ntwo approaches to structure learning for PSL. We introduce a greedy\nsearch-based algorithm and a novel optimization method that trade-off\nscalability and approximations to the structure learning problem in varying\nways. The highly scalable optimization method combines data-driven generation\nof clauses with a piecewise pseudolikelihood (PPLL) objective that learns model\nstructure by optimizing clause weights only once. We compare both methods\nacross five real-world tasks, showing that PPLL achieves an order of magnitude\nruntime speedup and AUC gains up to 15% over greedy search.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 04:25:23 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Embar", "Varun", ""], ["Sridhar", "Dhanya", ""], ["Farnadi", "Golnoosh", ""], ["Getoor", "Lise", ""]]}, {"id": "1807.00975", "submitter": "Jie Liu", "authors": "Jie Liu, Cheng Sun, Xiang Xu, Baomin Xu, Shuangyuan Yu", "title": "A Spatial and Temporal Features Mixture Model with Body Parts for\n  Video-based Person Re-Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The video-based person re-identification is to recognize a person under\ndifferent cameras, which is a crucial task applied in visual surveillance\nsystem. Most previous methods mainly focused on the feature of full body in the\nframe. In this paper we propose a novel Spatial and Temporal Features Mixture\nModel (STFMM) based on convolutional neural network (CNN) and recurrent neural\nnetwork (RNN), in which the human body is split into $N$ parts in horizontal\ndirection so that we can obtain more specific features. The proposed method\nskillfully integrates features of each part to achieve more expressive\nrepresentation of each person. We first split the video sequence into $N$ part\nsequences which include the information of head, waist, legs and so on. Then\nthe features are extracted by STFMM whose $2N$ inputs are obtained from the\ndeveloped Siamese network, and these features are combined into a\ndiscriminative representation for one person. Experiments are conducted on the\niLIDS-VID and PRID-2011 datasets. The results demonstrate that our approach\noutperforms existing methods for video-based person re-identification. It\nachieves a rank-1 CMC accuracy of 74\\% on the iLIDS-VID dataset, exceeding the\nthe most recently developed method ASTPN by 12\\%. For the cross-data testing,\nour method achieves a rank-1 CMC accuracy of 48\\% exceeding the ASTPN method by\n18\\%, which shows that our model has significant stability.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 04:33:22 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Liu", "Jie", ""], ["Sun", "Cheng", ""], ["Xu", "Xiang", ""], ["Xu", "Baomin", ""], ["Yu", "Shuangyuan", ""]]}, {"id": "1807.01001", "submitter": "Patrick Wenzel", "authors": "Patrick Wenzel, Qadeer Khan, Daniel Cremers, Laura Leal-Taix\\'e", "title": "Modular Vehicle Control for Transferring Semantic Information Between\n  Weather Conditions Using GANs", "comments": "2nd Conference on Robot Learning (CoRL 2018), Z\\\"urich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though end-to-end supervised learning has shown promising results for\nsensorimotor control of self-driving cars, its performance is greatly affected\nby the weather conditions under which it was trained, showing poor\ngeneralization to unseen conditions. In this paper, we show how knowledge can\nbe transferred using semantic maps to new weather conditions without the need\nto obtain new ground truth data. To this end, we propose to divide the task of\nvehicle control into two independent modules: a control module which is only\ntrained on one weather condition for which labeled steering data is available,\nand a perception module which is used as an interface between new weather\nconditions and the fixed control module. To generate the semantic data needed\nto train the perception module, we propose to use a generative adversarial\nnetwork (GAN)-based model to retrieve the semantic information for the new\nconditions in an unsupervised manner. We introduce a master-servant\narchitecture, where the master model (semantic labels available) trains the\nservant model (semantic labels not available). We show that our proposed method\ntrained with ground truth data for a single weather condition is capable of\nachieving similar results on the task of steering angle prediction as an\nend-to-end model trained with ground truth data of 15 different weather\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 07:29:19 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 14:01:46 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Wenzel", "Patrick", ""], ["Khan", "Qadeer", ""], ["Cremers", "Daniel", ""], ["Leal-Taix\u00e9", "Laura", ""]]}, {"id": "1807.01035", "submitter": "Manfred Eppe", "authors": "Manfred Eppe and Matthias Kerzel and Erik Strahl and Stefan Wermter", "title": "Deep Neural Object Analysis by Interactive Auditory Exploration with a\n  Humanoid Robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for interactive auditory object analysis with a\nhumanoid robot. The robot elicits sensory information by physically shaking\nvisually indistinguishable plastic capsules. It gathers the resulting audio\nsignals from microphones that are embedded into the robotic ears. A neural\nnetwork architecture learns from these signals to analyze properties of the\ncontents of the containers. Specifically, we evaluate the material\nclassification and weight prediction accuracy and demonstrate that the\nframework is fairly robust to acoustic real-world noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 09:11:36 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 07:53:06 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Eppe", "Manfred", ""], ["Kerzel", "Matthias", ""], ["Strahl", "Erik", ""], ["Wermter", "Stefan", ""]]}, {"id": "1807.01068", "submitter": "Marco Reisert", "authors": "Marco Reisert, Volker A. Coenen, Christoph Kaller, Karl Egger, Henrik\n  Skibbe", "title": "HAMLET: Hierarchical Harmonic Filters for Learning Tracts from Diffusion\n  MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose HAMLET, a novel tract learning algorithm, which,\nafter training, maps raw diffusion weighted MRI directly onto an image which\nsimultaneously indicates tract direction and tract presence. The automatic\nlearning of fiber tracts based on diffusion MRI data is a rather new idea,\nwhich tries to overcome limitations of atlas-based techniques. HAMLET takes a\nsuch an approach. Unlike the current trend in machine learning, HAMLET has only\na small number of free parameters HAMLET is based on spherical tensor algebra\nwhich allows a translation and rotation covariant treatment of the problem.\nHAMLET is based on a repeated application of convolutions and non-linearities,\nwhich all respect the rotation covariance. The intrinsic treatment of such\nbasic image transformations in HAMLET allows the training and generalization of\nthe algorithm without any additional data augmentation. We demonstrate the\nperformance of our approach for twelve prominent bundles, and show that the\nobtained tract estimates are robust and reliable. It is also shown that the\nlearned models are portable from one sequence to another.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:25:05 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Reisert", "Marco", ""], ["Coenen", "Volker A.", ""], ["Kaller", "Christoph", ""], ["Egger", "Karl", ""], ["Skibbe", "Henrik", ""]]}, {"id": "1807.01079", "submitter": "Anna Latour", "authors": "Anna L.D. Latour, Behrouz Babaki, Siegfried Nijssen", "title": "Stochastic Constraint Optimization using Propagation on Ordered Binary\n  Decision Diagrams", "comments": "Eighth International Workshop on Statistical Relational AI, in\n  conjunction with the 2018 International Joint Conference on Artificial\n  Intelligence (IJCAI 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A number of problems in relational Artificial Intelligence can be viewed as\nStochastic Constraint Optimization Problems (SCOPs). These are constraint\noptimization problems that involve objectives or constraints with a stochastic\ncomponent. Building on the recently proposed language SC-ProbLog for modeling\nSCOPs, we propose a new method for solving these problems. Earlier methods used\nProbabilistic Logic Programming (PLP) techniques to create Ordered Binary\nDecision Diagrams (OBDDs), which were decomposed into smaller constraints in\norder to exploit existing constraint programming (CP) solvers. We argue that\nthis approach has as drawback that a decomposed representation of an OBDD does\nnot guarantee domain consistency during search, and hence limits the efficiency\nof the solver. For the specific case of monotonic distributions, we suggest an\nalternative method for using CP in SCOP, based on the development of a new\npropagator; we show that this propagator is linear in the size of the OBDD, and\nhas the potential to be more efficient than the decomposition method, as it\nmaintains domain consistency.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:58:38 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Latour", "Anna L. D.", ""], ["Babaki", "Behrouz", ""], ["Nijssen", "Siegfried", ""]]}, {"id": "1807.01081", "submitter": "Sergio Hernandez", "authors": "Sergio Hernandez Cerezo, Guillem Duran Ballester, Spiros Baxevanakis", "title": "Solving Atari Games Using Fractals And Entropy", "comments": "7 pages, 1 figure, submitted to NIPS-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel MCTS based approach that is derived from\nthe laws of the thermodynamics. The algorithm coined Fractal Monte Carlo (FMC),\nallows us to create an agent that takes intelligent actions in both continuous\nand discrete environments while providing control over every aspect of the\nagent behavior. Results show that FMC is several orders of magnitude more\nefficient than similar techniques, such as MCTS, in the Atari games tested.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:59:26 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Cerezo", "Sergio Hernandez", ""], ["Ballester", "Guillem Duran", ""], ["Baxevanakis", "Spiros", ""]]}, {"id": "1807.01183", "submitter": "V\\'ictor Guti\\'errez-Basulto", "authors": "V\\'ictor Guti\\'errez-Basulto, Jean Christoph Jung, Ondrej Kuzelka", "title": "Quantified Markov Logic Networks", "comments": "Paper accepted at the 16th International Conference on Principles of\n  Knowledge Representation and Reasoning (KR 2018). This work was also\n  presented in the Eighth International Workshop on Statistical Relational AI\n  (StarAI 2018) under the title \"Markov Logic Networks with Statistical\n  Quantifiers\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Logic Networks (MLNs) are well-suited for expressing statistics such\nas \"with high probability a smoker knows another smoker\" but not for expressing\nstatements such as \"there is a smoker who knows most other smokers\", which is\nnecessary for modeling, e.g. influencers in social networks. To overcome this\nshortcoming, we study quantified MLNs which generalize MLNs by introducing\nstatistical universal quantifiers, allowing to express also the latter type of\nstatistics in a principled way. Our main technical contribution is to show that\nthe standard reasoning tasks in quantified MLNs, maximum a posteriori and\nmarginal inference, can be reduced to their respective MLN counterparts in\npolynomial time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 13:39:19 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 16:47:24 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 14:18:47 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Jung", "Jean Christoph", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "1807.01194", "submitter": "Steve Dias Da Cruz", "authors": "Hans-Peter Beise, Steve Dias Da Cruz, Udo Schr\\\"oder", "title": "On decision regions of narrow deep neural networks", "comments": "This paper is accepted for publication in Neural Networks (Elsevier\n  Journal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that for neural network functions that have width less or equal to\nthe input dimension all connected components of decision regions are unbounded.\nThe result holds for continuous and strictly monotonic activation functions as\nwell as for the ReLU activation function. This complements recent results on\napproximation capabilities by [Hanin 2017 Approximating] and connectivity of\ndecision regions by [Nguyen 2018 Neural] for such narrow neural networks. Our\nresults are illustrated by means of numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 14:03:42 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 10:26:45 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 09:44:00 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 08:35:12 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Beise", "Hans-Peter", ""], ["Da Cruz", "Steve Dias", ""], ["Schr\u00f6der", "Udo", ""]]}, {"id": "1807.01227", "submitter": "Ariel Rosenfeld", "authors": "Akiva Kleinerman, Ariel Rosenfeld, Sarit Kraus", "title": "Providing Explanations for Recommendations in Reciprocal Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated platforms which support users in finding a mutually beneficial\nmatch, such as online dating and job recruitment sites, are becoming\nincreasingly popular. These platforms often include recommender systems that\nassist users in finding a suitable match. While recommender systems which\nprovide explanations for their recommendations have shown many benefits,\nexplanation methods have yet to be adapted and tested in recommending suitable\nmatches. In this paper, we introduce and extensively evaluate the use of\n\"reciprocal explanations\" -- explanations which provide reasoning as to why\nboth parties are expected to benefit from the match. Through an extensive\nempirical evaluation, in both simulated and real-world dating platforms with\n287 human participants, we find that when the acceptance of a recommendation\ninvolves a significant cost (e.g., monetary or emotional), reciprocal\nexplanations outperform standard explanation methods which consider the\nrecommendation receiver alone. However, contrary to what one may expect, when\nthe cost of accepting a recommendation is negligible, reciprocal explanations\nare shown to be less effective than the traditional explanation methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:10:01 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Kleinerman", "Akiva", ""], ["Rosenfeld", "Ariel", ""], ["Kraus", "Sarit", ""]]}, {"id": "1807.01251", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Yaoyu Zhang, Yanyang Xiao", "title": "Training behavior of deep neural network in frequency domain", "comments": "To appear in 2019 26th-International conference of neural information\n  processing (ICONIP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why deep neural networks (DNNs) capable of overfitting often generalize well\nin practice is a mystery [#zhang2016understanding]. To find a potential\nmechanism, we focus on the study of implicit biases underlying the training\nprocess of DNNs. In this work, for both real and synthetic datasets, we\nempirically find that a DNN with common settings first quickly captures the\ndominant low-frequency components, and then relatively slowly captures the\nhigh-frequency ones. We call this phenomenon Frequency Principle (F-Principle).\nThe F-Principle can be observed over DNNs of various structures, activation\nfunctions, and training algorithms in our experiments. We also illustrate how\nthe F-Principle help understand the effect of early-stopping as well as the\ngeneralization of DNNs. This F-Principle potentially provides insights into a\ngeneral principle underlying DNN optimization and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:50:41 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 17:53:43 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 05:54:32 GMT"}, {"version": "v4", "created": "Mon, 8 Apr 2019 21:46:34 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 07:26:27 GMT"}, {"version": "v6", "created": "Fri, 1 Nov 2019 02:21:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""], ["Xiao", "Yanyang", ""]]}, {"id": "1807.01268", "submitter": "Mauricio Gonzalez-Soto", "authors": "M. Gonzalez-Soto, L.E. Sucar, H.J. Escalante", "title": "Playing against Nature: causal discovery for decision making under\n  uncertainty", "comments": "Accepted as poster presentation at the CausalML Workshop at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decision problems under uncertainty where the options available\nto a decision maker and the resulting outcome are related through a causal\nmechanism which is unknown to the decision maker. We ask how a decision maker\ncan learn about this causal mechanism through sequential decision making as\nwell as using current causal knowledge inside each round in order to make\nbetter choices had she not considered causal knowledge and propose a decision\nmaking procedure in which an agent holds \\textit{beliefs} about her environment\nwhich are used to make a choice and are updated using the observed outcome. As\nproof of concept, we present an implementation of this causal decision making\nmodel and apply it in a simple scenario. We show that the model achieves a\nperformance similar to the classic Q-learning while it also acquires a causal\nmodel of the environment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:36:03 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Gonzalez-Soto", "M.", ""], ["Sucar", "L. E.", ""], ["Escalante", "H. J.", ""]]}, {"id": "1807.01270", "submitter": "Tao Ge", "authors": "Tao Ge, Furu Wei, Ming Zhou", "title": "Reaching Human-level Performance in Automatic Grammatical Error\n  Correction: An Empirical Study", "comments": "Substantial text overlap with \"Fluency Boost Learning and Inference\n  for Neural Grammatical Error Correction\" (accepted by ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence-to-sequence (seq2seq) approaches have proven to be successful\nin grammatical error correction (GEC). Based on the seq2seq framework, we\npropose a novel fluency boost learning and inference mechanism. Fluency\nboosting learning generates diverse error-corrected sentence pairs during\ntraining, enabling the error correction model to learn how to improve a\nsentence's fluency from more instances, while fluency boosting inference allows\nthe model to correct a sentence incrementally with multiple inference steps.\nCombining fluency boost learning and inference with convolutional seq2seq\nmodels, our approach achieves the state-of-the-art performance: 75.72 (F_{0.5})\non CoNLL-2014 10 annotation dataset and 62.42 (GLEU) on JFLEG test set\nrespectively, becoming the first GEC system that reaches human-level\nperformance (72.58 for CoNLL and 62.37 for JFLEG) on both of the benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:37:05 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 05:15:00 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 06:01:45 GMT"}, {"version": "v4", "created": "Tue, 10 Jul 2018 14:20:14 GMT"}, {"version": "v5", "created": "Wed, 11 Jul 2018 05:20:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ge", "Tao", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1807.01279", "submitter": "Edward Pyzer-Knapp", "authors": "Dipti Jasrasaria and Edward O. Pyzer-Knapp", "title": "Dynamic Control of Explore/Exploit Trade-Off In Bayesian Optimization", "comments": "Accepted for publication in the proceedings of 2018 Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization offers the possibility of optimizing black-box\noperations not accessible through traditional techniques. The success of\nBayesian optimization methods such as Expected Improvement (EI) are\nsignificantly affected by the degree of trade-off between exploration and\nexploitation. Too much exploration can lead to inefficient optimization\nprotocols, whilst too much exploitation leaves the protocol open to strong\ninitial biases, and a high chance of getting stuck in a local minimum.\nTypically, a constant margin is used to control this trade-off, which results\nin yet another hyper-parameter to be optimized. We propose contextual\nimprovement as a simple, yet effective heuristic to counter this - achieving a\none-shot optimization strategy. Our proposed heuristic can be swiftly\ncalculated and improves both the speed and robustness of discovery of optimal\nsolutions. We demonstrate its effectiveness on both synthetic and real world\nproblems and explore the unaccounted for uncertainty in the pre-determination\nof search hyperparameters controlling explore-exploit trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:56:05 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Jasrasaria", "Dipti", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "1807.01281", "submitter": "Wojciech Czarnecki", "authors": "Max Jaderberg, Wojciech M. Czarnecki, Iain Dunning, Luke Marris, Guy\n  Lever, Antonio Garcia Castaneda, Charles Beattie, Neil C. Rabinowitz, Ari S.\n  Morcos, Avraham Ruderman, Nicolas Sonnerat, Tim Green, Louise Deason, Joel Z.\n  Leibo, David Silver, Demis Hassabis, Koray Kavukcuoglu, Thore Graepel", "title": "Human-level performance in first-person multiplayer games with\n  population-based deep reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.1126/science.aau6249", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence through reinforcement learning\n(RL) has shown great success on increasingly complex single-agent environments\nand two-player turn-based games. However, the real-world contains multiple\nagents, each learning and acting independently to cooperate and compete with\nother agents, and environments reflecting this degree of complexity remain an\nopen challenge. In this work, we demonstrate for the first time that an agent\ncan achieve human-level in a popular 3D multiplayer first-person video game,\nQuake III Arena Capture the Flag, using only pixels and game points as input.\nThese results were achieved by a novel two-tier optimisation process in which a\npopulation of independent RL agents are trained concurrently from thousands of\nparallel matches with agents playing in teams together and against each other\non randomly generated environments. Each agent in the population learns its own\ninternal reward signal to complement the sparse delayed reward from winning,\nand selects actions using a novel temporally hierarchical representation that\nenables the agent to reason at multiple timescales. During game-play, these\nagents display human-like behaviours such as navigating, following, and\ndefending based on a rich learned representation that is shown to encode\nhigh-level game knowledge. In an extensive tournament-style evaluation the\ntrained agents exceeded the win-rate of strong human players both as teammates\nand opponents, and proved far stronger than existing state-of-the-art agents.\nThese results demonstrate a significant jump in the capabilities of artificial\nagents, bringing us closer to the goal of human-level intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 16:57:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Jaderberg", "Max", ""], ["Czarnecki", "Wojciech M.", ""], ["Dunning", "Iain", ""], ["Marris", "Luke", ""], ["Lever", "Guy", ""], ["Castaneda", "Antonio Garcia", ""], ["Beattie", "Charles", ""], ["Rabinowitz", "Neil C.", ""], ["Morcos", "Ari S.", ""], ["Ruderman", "Avraham", ""], ["Sonnerat", "Nicolas", ""], ["Green", "Tim", ""], ["Deason", "Louise", ""], ["Leibo", "Joel Z.", ""], ["Silver", "David", ""], ["Hassabis", "Demis", ""], ["Kavukcuoglu", "Koray", ""], ["Graepel", "Thore", ""]]}, {"id": "1807.01425", "submitter": "Artem Molchanov", "authors": "Artem Molchanov, Karol Hausman, Stan Birchfield, Gaurav Sukhatme", "title": "Region Growing Curriculum Generation for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a policy capable of moving an agent between any two states in the\nenvironment is important for many robotics problems involving navigation and\nmanipulation. Due to the sparsity of rewards in such tasks, applying\nreinforcement learning in these scenarios can be challenging. Common approaches\nfor tackling this problem include reward engineering with auxiliary rewards,\nrequiring domain-specific knowledge or changing the objective.\n  In this work, we introduce a method based on region-growing that allows\nlearning in an environment with any pair of initial and goal states. Our\nalgorithm first learns how to move between nearby states and then increases the\ndifficulty of the start-goal transitions as the agent's performance improves.\nThis approach creates an efficient curriculum for learning the objective\nbehavior of reaching any goal from any initial state. In addition, we describe\na method to adaptively adjust expansion of the growing region that allows\nautomatic adjustment of the key exploration hyperparameter to environments with\ndifferent requirements. We evaluate our approach on a set of simulated\nnavigation and manipulation tasks, where we demonstrate that our algorithm can\nefficiently learn a policy in the presence of sparse rewards.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 01:49:29 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Molchanov", "Artem", ""], ["Hausman", "Karol", ""], ["Birchfield", "Stan", ""], ["Sukhatme", "Gaurav", ""]]}, {"id": "1807.01442", "submitter": "Aditya Grover", "authors": "Manik Dhar, Aditya Grover, Stefano Ermon", "title": "Modeling Sparse Deviations for Compressed Sensing using Generative\n  Models", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing, a small number of linear measurements can be used to\nreconstruct an unknown signal. Existing approaches leverage assumptions on the\nstructure of these signals, such as sparsity or the availability of a\ngenerative model. A domain-specific generative model can provide a stronger\nprior and thus allow for recovery with far fewer measurements. However, unlike\nsparsity-based approaches, existing methods based on generative models\nguarantee exact recovery only over their support, which is typically only a\nsmall subset of the space on which the signals are defined. We propose\nSparse-Gen, a framework that allows for sparse deviations from the support set,\nthereby achieving the best of both worlds by using a domain specific prior and\nallowing reconstruction over the full space of signals. Theoretically, our\nframework provides a new class of signals that can be acquired using compressed\nsensing, reducing classic sparse vector recovery to a special case and avoiding\nthe restrictive support due to a generative model prior. Empirically, we\nobserve consistent improvements in reconstruction accuracy over competing\napproaches, especially in the more practical setting of transfer compressed\nsensing where a generative model for a data-rich, source domain aids sensing on\na data-scarce, target domain.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 03:57:21 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 21:30:28 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Dhar", "Manik", ""], ["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.01521", "submitter": "Adrien Laversanne-Finot", "authors": "Adrien Laversanne-Finot, Alexandre P\\'er\\'e and Pierre-Yves Oudeyer", "title": "Curiosity Driven Exploration of Learned Disentangled Goal Spaces", "comments": "The code used in the experiments is available at\n  https://github.com/flowersteam/Curiosity_Driven_Goal_Exploration", "journal-ref": "Proceedings of The 2nd Conference on Robot Learning, PMLR\n  87:487-504, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically motivated goal exploration processes enable agents to\nautonomously sample goals to explore efficiently complex environments with\nhigh-dimensional continuous actions. They have been applied successfully to\nreal world robots to discover repertoires of policies producing a wide\ndiversity of effects. Often these algorithms relied on engineered goal spaces\nbut it was recently shown that one can use deep representation learning\nalgorithms to learn an adequate goal space in simple environments. However, in\nthe case of more complex environments containing multiple objects or\ndistractors, an efficient exploration requires that the structure of the goal\nspace reflects the one of the environment. In this paper we show that using a\ndisentangled goal space leads to better exploration performances than an\nentangled goal space. We further show that when the representation is\ndisentangled, one can leverage it by sampling goals that maximize learning\nprogress in a modular manner. Finally, we show that the measure of learning\nprogress, used to drive curiosity-driven exploration, can be used\nsimultaneously to discover abstract independently controllable features of the\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 11:23:57 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 16:33:56 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 16:36:39 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Laversanne-Finot", "Adrien", ""], ["P\u00e9r\u00e9", "Alexandre", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1807.01554", "submitter": "Yutai Hou", "authors": "Yutai Hou, Yijia Liu, Wanxiang Che, Ting Liu", "title": "Sequence-to-Sequence Data Augmentation for Dialogue Language\n  Understanding", "comments": "Accepted By COLING2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of data augmentation for language\nunderstanding in task-oriented dialogue system. In contrast to previous work\nwhich augments an utterance without considering its relation with other\nutterances, we propose a sequence-to-sequence generation based data\naugmentation framework that leverages one utterance's same semantic\nalternatives in the training data. A novel diversity rank is incorporated into\nthe utterance representation to make the model produce diverse utterances and\nthese diversely augmented utterances help to improve the language understanding\nmodule. Experimental results on the Airline Travel Information System dataset\nand a newly created semantic frame annotation on Stanford Multi-turn,\nMultidomain Dialogue Dataset show that our framework achieves significant\nimprovements of 6.38 and 10.04 F-scores respectively when only a training set\nof hundreds utterances is represented. Case studies also confirm that our\nmethod generates diverse utterances.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 13:07:53 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Hou", "Yutai", ""], ["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "1807.01586", "submitter": "Marcel Gehrke", "authors": "Marcel Gehrke, Tanya Braun, and Ralf M\\\"oller", "title": "Answering Hindsight Queries with Lifted Dynamic Junction Trees", "comments": "Accepted at the Eighth International Workshop on Statistical\n  Relational AI. arXiv admin note: substantial text overlap with\n  arXiv:1807.00744", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lifted dynamic junction tree algorithm (LDJT) efficiently answers\nfiltering and prediction queries for probabilistic relational temporal models\nby building and then reusing a first-order cluster representation of a\nknowledge base for multiple queries and time steps. We extend LDJT to (i) solve\nthe smoothing inference problem to answer hindsight queries by introducing an\nefficient backward pass and (ii) discuss different options to instantiate a\nfirst-order cluster representation during a backward pass. Further, our\nrelational forward backward algorithm makes hindsight queries to the very\nbeginning feasible. LDJT answers multiple temporal queries faster than the\nstatic lifted junction tree algorithm on an unrolled model, which performs\nsmoothing during message passing.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 15:38:58 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Gehrke", "Marcel", ""], ["Braun", "Tanya", ""], ["M\u00f6ller", "Ralf", ""]]}, {"id": "1807.01603", "submitter": "Javier Ferrer", "authors": "Javier Ferrer and Enrique Alba", "title": "BIN-CT: Urban Waste Collection based in Predicting the Container Fill\n  Level", "comments": "11 pages, double column, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1016/j.biosystems.2019.04.006", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast demographic growth, together with the concentration of the\npopulation in cities and the increasing amount of daily waste, are factors that\npush to the limit the ability of waste assimilation by Nature. Therefore, we\nneed technological means to make an optimal management of the waste collection\nprocess, which represents 70% of the operational cost in waste treatment. In\nthis article, we present a free intelligent software system, based on\ncomputational learning algorithms, which plans the best routes for waste\ncollection supported by past (historical) and future (predictions) data.\n  The objective of the system is the cost reduction of the waste collection\nservice by means of the minimization in distance traveled by any truck to\ncollect a container, hence the fuel consumption. At the same time the quality\nof service to the citizen is increased avoiding the annoying overflows of\ncontainers thanks to the accurate fill level predictions performed by BIN-CT.\nIn this article we show the features of our software system, illustrating it\noperation with a real case study of a Spanish city. We conclude that the use of\nBIN-CT avoids unnecessary visits to containers, reduces the distance traveled\nto collect a container and therefore we obtain a reduction of total costs and\nharmful emissions thrown to the atmosphere.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 10:50:03 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 08:55:16 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Ferrer", "Javier", ""], ["Alba", "Enrique", ""]]}, {"id": "1807.01628", "submitter": "Rusheng Zhang", "authors": "Rusheng Zhang, Akihiro Ishikawa, Wenli Wang, Benjamin Striner, Ozan\n  Tonguz", "title": "Using Reinforcement Learning with Partial Vehicle Detection for\n  Intelligent Traffic Signal Control", "comments": "10 pages, 14 figures, submitted to IEEE ITS transaction, Special\n  Issue of Intelligent transportation systems empowered by AI technologies on\n  June 15, 2018 Accepted and will publish in 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Transportation Systems (ITS) have attracted the attention of\nresearchers and the general public alike as a means to alleviate traffic\ncongestion. Recently, the maturity of wireless technology has enabled a\ncost-efficient way to achieve ITS by detecting vehicles using Vehicle to\nInfrastructure (V2I) communications. Traditional ITS algorithms, in most cases,\nassume that every vehicle is observed, such as by a camera or a loop detector,\nbut a V2I implementation would detect only those vehicles with wireless\ncommunications capability. We examine a family of transportation systems, which\nwe will refer to as `Partially Detected Intelligent Transportation Systems'. An\nalgorithm that can act well under a small detection rate is highly desirable\ndue to gradual penetration rates of the underlying wireless technologies such\nas Dedicated Short Range Communications (DSRC) technology. Artificial\nIntelligence (AI) techniques for Reinforcement Learning (RL) are suitable tools\nfor finding such an algorithm due to utilizing varied inputs and not requiring\nexplicit analytic understanding or modeling of the underlying system dynamics.\nIn this paper, we report a RL algorithm for partially observable ITS based on\nDSRC. The performance of this system is studied under different car flows,\ndetection rates, and topologies of the road network. Our system is able to\nefficiently reduce the average waiting time of vehicles at an intersection,\neven with a low detection rate.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 15:12:02 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 18:22:13 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 00:02:04 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Rusheng", ""], ["Ishikawa", "Akihiro", ""], ["Wang", "Wenli", ""], ["Striner", "Benjamin", ""], ["Tonguz", "Ozan", ""]]}, {"id": "1807.01659", "submitter": "Guang-Yuan Hao", "authors": "Guang-Yuan Hao, Hong-Xing Yu, Wei-Shi Zheng", "title": "MIXGAN: Learning Concepts from Different Domains for Mixture Generation", "comments": "Accepted by IJCAI-ECAI 2018, the 27th International Joint Conference\n  on Artificial Intelligence and the 23rd European Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an interesting attempt on mixture generation:\nabsorbing different image concepts (e.g., content and style) from different\ndomains and thus generating a new domain with learned concepts. In particular,\nwe propose a mixture generative adversarial network (MIXGAN). MIXGAN learns\nconcepts of content and style from two domains respectively, and thus can join\nthem for mixture generation in a new domain, i.e., generating images with\ncontent from one domain and style from another. MIXGAN overcomes the limitation\nof current GAN-based models which either generate new images in the same domain\nas they observed in training stage, or require off-the-shelf content templates\nfor transferring or translation. Extensive experimental results demonstrate the\neffectiveness of MIXGAN as compared to related state-of-the-art GAN-based\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:20:47 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Hao", "Guang-Yuan", ""], ["Yu", "Hong-Xing", ""], ["Zheng", "Wei-Shi", ""]]}, {"id": "1807.01670", "submitter": "Karl Moritz Hermann", "authors": "Tiago Ramalho, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Frederic Besse, S. M. Ali\n  Eslami, G\\'abor Melis, Fabio Viola, Phil Blunsom, Karl Moritz Hermann", "title": "Encoding Spatial Relations from Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has made significant inroads into learning the\nsemantics of words through distributional approaches, however representations\nlearnt via these methods fail to capture certain kinds of information implicit\nin the real world. In particular, spatial relations are encoded in a way that\nis inconsistent with human spatial reasoning and lacking invariance to\nviewpoint changes. We present a system capable of capturing the semantics of\nspatial relations such as behind, left of, etc from natural language. Our key\ncontributions are a novel multi-modal objective based on generating images of\nscenes from their textual descriptions, and a new dataset on which to train it.\nWe demonstrate that internal representations are robust to meaning preserving\ntransformations of descriptions (paraphrase invariance), while viewpoint\ninvariance is an emergent property of the system.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:38:49 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 10:03:23 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ramalho", "Tiago", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Besse", "Frederic", ""], ["Eslami", "S. M. Ali", ""], ["Melis", "G\u00e1bor", ""], ["Viola", "Fabio", ""], ["Blunsom", "Phil", ""], ["Hermann", "Karl Moritz", ""]]}, {"id": "1807.01672", "submitter": "Torbjorn Dahl", "authors": "Alexandre Laterre and Yunguan Fu and Mohamed Khalil Jabri and\n  Alain-Sam Cohen and David Kas and Karl Hajjar and Torbjorn S. Dahl and Amine\n  Kerkeni and Karim Beguir", "title": "Ranked Reward: Enabling Self-Play Reinforcement Learning for\n  Combinatorial Optimization", "comments": null, "journal-ref": "Presented at the Thirty-second Conference on Neural Information\n  Processing Systems (NeurIPS 2018), Deep Reinforcement Learning Workshop,\n  Montreal, Canada, December 3-8, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial self-play in two-player games has delivered impressive results\nwhen used with reinforcement learning algorithms that combine deep neural\nnetworks and tree search. Algorithms like AlphaZero and Expert Iteration learn\ntabula-rasa, producing highly informative training data on the fly. However,\nthe self-play training strategy is not directly applicable to single-player\ngames. Recently, several practically important combinatorial optimisation\nproblems, such as the travelling salesman problem and the bin packing problem,\nhave been reformulated as reinforcement learning problems, increasing the\nimportance of enabling the benefits of self-play beyond two-player games. We\npresent the Ranked Reward (R2) algorithm which accomplishes this by ranking the\nrewards obtained by a single agent over multiple games to create a relative\nperformance metric. Results from applying the R2 algorithm to instances of a\ntwo-dimensional and three-dimensional bin packing problems show that it\noutperforms generic Monte Carlo tree search, heuristic algorithms and integer\nprogramming solvers. We also present an analysis of the ranked reward\nmechanism, in particular, the effects of problem instances with varying\ndifficulty and different ranking thresholds.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:40:53 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 17:17:07 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 23:32:05 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Laterre", "Alexandre", ""], ["Fu", "Yunguan", ""], ["Jabri", "Mohamed Khalil", ""], ["Cohen", "Alain-Sam", ""], ["Kas", "David", ""], ["Hajjar", "Karl", ""], ["Dahl", "Torbjorn S.", ""], ["Kerkeni", "Amine", ""], ["Beguir", "Karim", ""]]}, {"id": "1807.01675", "submitter": "Jacob Buckman", "authors": "Jacob Buckman, Danijar Hafner, George Tucker, Eugene Brevdo, Honglak\n  Lee", "title": "Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value\n  Expansion", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2019 (pp.\n  8224-8234)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating model-free and model-based approaches in reinforcement learning\nhas the potential to achieve the high performance of model-free algorithms with\nlow sample complexity. However, this is difficult because an imperfect dynamics\nmodel can degrade the performance of the learning algorithm, and in\nsufficiently complex environments, the dynamics model will almost always be\nimperfect. As a result, a key challenge is to combine model-based approaches\nwith model-free learning in such a way that errors in the model do not degrade\nperformance. We propose stochastic ensemble value expansion (STEVE), a novel\nmodel-based technique that addresses this issue. By dynamically interpolating\nbetween model rollouts of various horizon lengths for each individual example,\nSTEVE ensures that the model is only utilized when doing so does not introduce\nsignificant errors. Our approach outperforms model-free baselines on\nchallenging continuous control benchmarks with an order-of-magnitude increase\nin sample efficiency, and in contrast to previous model-based approaches,\nperformance does not degrade in complex environments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 16:51:56 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 16:39:35 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Buckman", "Jacob", ""], ["Hafner", "Danijar", ""], ["Tucker", "George", ""], ["Brevdo", "Eugene", ""], ["Lee", "Honglak", ""]]}, {"id": "1807.01697", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Thomas G. Dietterich", "title": "Benchmarking Neural Network Robustness to Common Corruptions and Surface\n  Variations", "comments": "Superseded by _Benchmarking Neural Network Robustness to Common\n  Corruptions and Perturbations_ arXiv:1903.12261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we establish rigorous benchmarks for image classifier\nrobustness. Our first benchmark, ImageNet-C, standardizes and expands the\ncorruption robustness topic, while showing which classifiers are preferable in\nsafety-critical applications. Unlike recent robustness research, this benchmark\nevaluates performance on commonplace corruptions not worst-case adversarial\ncorruptions. We find that there are negligible changes in relative corruption\nrobustness from AlexNet to ResNet classifiers, and we discover ways to enhance\ncorruption robustness. Then we propose a new dataset called Icons-50 which\nopens research on a new kind of robustness, surface variation robustness. With\nthis dataset we evaluate the frailty of classifiers on new styles of known\nobjects and unexpected instances of known classes. We also demonstrate two\nmethods that improve surface variation robustness. Together our benchmarks may\naid future work toward networks that learn fundamental class structure and also\nrobustly generalize.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 17:57:11 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 18:57:31 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 20:30:27 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 21:36:39 GMT"}, {"version": "v5", "created": "Sat, 27 Apr 2019 18:19:39 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Hendrycks", "Dan", ""], ["Dietterich", "Thomas G.", ""]]}, {"id": "1807.01736", "submitter": "Lucas Lehnert", "authors": "Lucas Lehnert, Michael L. Littman", "title": "Transfer with Model Features in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in Reinforcement Learning is which representation an agent can\nlearn to efficiently reuse knowledge between different tasks. Recently the\nSuccessor Representation was shown to have empirical benefits for transferring\nknowledge between tasks with shared transition dynamics. This paper presents\nModel Features: a feature representation that clusters behaviourally equivalent\nstates and that is equivalent to a Model-Reduction. Further, we present a\nSuccessor Feature model which shows that learning Successor Features is\nequivalent to learning a Model-Reduction. A novel optimization objective is\ndeveloped and we provide bounds showing that minimizing this objective results\nin an increasingly improved approximation of a Model-Reduction. Further, we\nprovide transfer experiments on randomly generated MDPs which vary in their\ntransition and reward functions but approximately preserve behavioural\nequivalence between states. These results demonstrate that Model Features are\nsuitable for transfer between tasks with varying transition and reward\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 18:41:27 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Lehnert", "Lucas", ""], ["Littman", "Michael L.", ""]]}, {"id": "1807.01739", "submitter": "Mihailo Jovanovic", "authors": "Armin Zare, Hesameddin Mohammadi, Neil K. Dhingra, Tryphon T.\n  Georgiou, Mihailo R. Jovanovi\\'c", "title": "Proximal algorithms for large-scale statistical modeling and\n  sensor/actuator selection", "comments": "To appear in IEEE Trans. Automat. Control", "journal-ref": null, "doi": "10.1109/TAC.2019.2948268", "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several problems in modeling and control of stochastically-driven dynamical\nsystems can be cast as regularized semi-definite programs. We examine two such\nrepresentative problems and show that they can be formulated in a similar\nmanner. The first, in statistical modeling, seeks to reconcile observed\nstatistics by suitably and minimally perturbing prior dynamics. The second\nseeks to optimally select a subset of available sensors and actuators for\ncontrol purposes. To address modeling and control of large-scale systems we\ndevelop a unified algorithmic framework using proximal methods. Our customized\nalgorithms exploit problem structure and allow handling statistical modeling,\nas well as sensor and actuator selection, for substantially larger scales than\nwhat is amenable to current general-purpose solvers. We establish linear\nconvergence of the proximal gradient algorithm, draw contrast between the\nproposed proximal algorithms and alternating direction method of multipliers,\nand provide examples that illustrate the merits and effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 18:47:03 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 17:38:06 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 07:45:19 GMT"}, {"version": "v4", "created": "Thu, 26 Dec 2019 18:04:42 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zare", "Armin", ""], ["Mohammadi", "Hesameddin", ""], ["Dhingra", "Neil K.", ""], ["Georgiou", "Tryphon T.", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1807.01747", "submitter": "Vasile Patrascu", "authors": "Vasile Patrascu", "title": "Shannon entropy for intuitionistic fuzzy information", "comments": "10 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.19707.41764", "report-no": "Technical Report, R.C.E.I.T-1.6.18", "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an extension of Shannon fuzzy entropy for intuitionistic\nfuzzy one. Firstly, we presented a new formula for calculating the distance and\nsimilarity of intuitionistic fuzzy information. Then, we constructed measures\nfor information features like score, certainty and uncertainty. Also, a new\nconcept was introduced, namely escort fuzzy information. Then, using the escort\nfuzzy information, Shannon's formula for intuitionistic fuzzy information was\nobtained. It should be underlined that Shannon's entropy for intuitionistic\nfuzzy information verifies the four defining conditions of intuitionistic fuzzy\nuncertainty. The measures of its two components were also identified: fuzziness\n(ambiguity) and incompleteness (ignorance).\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 06:06:00 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 13:10:13 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Patrascu", "Vasile", ""]]}, {"id": "1807.01763", "submitter": "Yue Liu", "authors": "Yue Liu, Tongtao Zhang, Zhicheng Liang, Heng Ji, Deborah L. McGuinness", "title": "Seq2RDF: An end-to-end application for deriving Triples from Natural\n  Language Text", "comments": "Proceedings of the 17th International Semantic Web Conference P&D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end approach that takes unstructured textual input and\ngenerates structured output compliant with a given vocabulary. Inspired by\nrecent successes in neural machine translation, we treat the triples within a\ngiven knowledge graph as an independent graph language and propose an\nencoder-decoder framework with an attention mechanism that leverages knowledge\ngraph embeddings. Our model learns the mapping from natural language text to\ntriple representation in the form of subject-predicate-object using the\nselected knowledge graph vocabulary. Experiments on three different data sets\nshow that we achieve competitive F1-Measures over the baselines using our\nsimple yet effective approach. A demo video is included.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 20:13:31 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 06:27:30 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 20:49:30 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Liu", "Yue", ""], ["Zhang", "Tongtao", ""], ["Liang", "Zhicheng", ""], ["Ji", "Heng", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1807.01798", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen, Evaggelia Tsiligianni, Robert Calderbank, Nikos\n  Deligiannis", "title": "Regularizing Autoencoder-Based Matrix Completion Models via Manifold\n  Learning", "comments": "5 pages, Eusipco 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are popular among neural-network-based matrix completion models\ndue to their ability to retrieve potential latent factors from the partially\nobserved matrices. Nevertheless, when training data is scarce their performance\nis significantly degraded due to overfitting. In this paper, we mit- igate\noverfitting with a data-dependent regularization technique that relies on the\nprinciples of multi-task learning. Specifically, we propose an\nautoencoder-based matrix completion model that performs prediction of the\nunknown matrix values as a main task, and manifold learning as an auxiliary\ntask. The latter acts as an inductive bias, leading to solutions that\ngeneralize better. The proposed model outperforms the existing\nautoencoder-based models designed for matrix completion, achieving high\nreconstruction accuracy in well-known datasets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 21:54:27 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Calderbank", "Robert", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1807.01801", "submitter": "Amar Viswanathan Kannan", "authors": "Amar Viswanathan, Geeth de Mel, James A.Hendler", "title": "Feature-based reformulation of entities in triple pattern queries", "comments": "ESWC 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graphs encode uniquely identifiable entities to other entities or\nliteral values by means of relationships, thus enabling semantically rich\nquerying over the stored data. Typically, the semantics of such queries are\noften crisp thereby resulting in crisp answers. Query log statistics show that\na majority of the queries issued to knowledge graphs are often entity centric\nqueries. When a user needs additional answers the state-of-the-art in assisting\nusers is to rewrite the original query resulting in a set of approximations.\nSeveral strategies have been proposed in past to address this. They typically\nmove up the taxonomy to relax a specific element to a more generic element.\nEntities don't have a taxonomy and they end up being generalized. To address\nthis issue, in this paper, we propose an entity centric reformulation strategy\nthat utilizes schema information and entity features present in the graph to\nsuggest rewrites. Once the features are identified, the entity in concern is\nreformulated as a set of features. Since entities can have a large number of\nfeatures, we introduce strategies that select the top-k most relevant and\n{informative ranked features and augment them to the original query to create a\nvalid reformulation. We then evaluate our approach by showing that our\nreformulation strategy produces results that are more informative when compared\nwith state-of-the-art\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 22:24:50 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Viswanathan", "Amar", ""], ["de Mel", "Geeth", ""], ["Hendler", "James A.", ""]]}, {"id": "1807.01830", "submitter": "Kristopher De Asis", "authors": "Kristopher De Asis, Richard S. Sutton", "title": "Per-decision Multi-step Temporal Difference Learning with Control\n  Variates", "comments": null, "journal-ref": "(2018). In Conference on Uncertainty in Artificial Intelligence.\n  http://auai.org/uai2018/proceedings/papers/282.pdf", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-step temporal difference (TD) learning is an important approach in\nreinforcement learning, as it unifies one-step TD learning with Monte Carlo\nmethods in a way where intermediate algorithms can outperform either extreme.\nThey address a bias-variance trade off between reliance on current estimates,\nwhich could be poor, and incorporating longer sampled reward sequences into the\nupdates. Especially in the off-policy setting, where the agent aims to learn\nabout a policy different from the one generating its behaviour, the variance in\nthe updates can cause learning to diverge as the number of sampled rewards used\nin the estimates increases. In this paper, we introduce per-decision control\nvariates for multi-step TD algorithms, and compare them to existing methods.\nOur results show that including the control variates can greatly improve\nperformance on both on and off-policy multi-step temporal difference learning\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 02:34:40 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["De Asis", "Kristopher", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1807.01909", "submitter": "Konstantin Yakovlev S", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Multi-robot Path Planning in Well-formed Infrastructures: Prioritized\n  Planning vs. Prioritized Wait Adjustment (Preliminary Results)", "comments": "Submitted to the Federated AI for Robotics Workshop (FAIR) 2018\n  (https://sites.google.com/site/federatedai4robotics2018/home) held at July 15\n  2018 as part of the Federated AI Meeting (joint IJCAI-ECAI/ICML/AAMAS\n  conferences)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of planning collision-free paths for a group of\nhomogeneous robots. We propose a novel approach for turning the paths that were\nplanned egocentrically by the robots, e.g. without taking other robots' moves\ninto account, into collision-free trajectories and evaluate it empirically.\nSuggested algorithm is much faster (up to one order of magnitude) than\nstate-of-the-art but this comes at the price of notable drop-down of the\nsolution cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 09:19:00 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1807.01953", "submitter": "Aswani Kumar Cherukuri Dr", "authors": "M S Ishwarya, Aswani Kumar Cherukuri", "title": "Lattice based Conceptual Spaces to Explore Cognitive Functionalities for\n  Prosthetic Arm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Upper limb Prosthetic can be viewed as an independent cognitive system in\norder to develop a conceptual space. In this paper, we provide a detailed\nanalogical reasoning of prosthetic arm to build the conceptual spaces with the\nhelp of the theory called geometric framework of conceptual spaces proposed by\nGardenfors. Terminologies of conceptual spaces such as concepts, similarities,\nproperties, quality dimensions and prototype are applied for a specific\nprosthetic system and conceptual space is built for prosthetic arm. Concept\nlattice traversals are used on the lattice represented conceptual spaces.\nCognitive functionalities such as generalization (Similarities) and\nspecialization (Differences) are achieved in the lattice represented conceptual\nspace. This might well prove to design intelligent prosthetics to assist\nchallenged humans. Geometric framework of conceptual spaces holds similar\nconcepts closer in geometric structures in a way similar to concept lattices.\nHence, we also propose to use concept lattice to represent concepts of\ngeometric framework of conceptual spaces. Also, we extend our discussion with\nour insights on conceptual spaces of bidirectional hand prosthetics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 11:58:16 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ishwarya", "M S", ""], ["Cherukuri", "Aswani Kumar", ""]]}, {"id": "1807.01960", "submitter": "Kyriakos Chatzidimitriou", "authors": "Georgios Papoudakis, Kyriakos C. Chatzidimitriou, Pericles A. Mitkas", "title": "Deep Reinforcement Learning for Doom using Unsupervised Auxiliary Tasks", "comments": "4 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in deep reinforcement learning have enabled the creation\nof agents for solving a large variety of games given a visual input. These\nmethods have been proven successful for 2D games, like the Atari games, or for\nsimple tasks, like navigating in mazes. It is still an open question, how to\naddress more complex environments, in which the reward is sparse and the state\nspace is huge. In this paper we propose a divide and conquer deep reinforcement\nlearning solution and we test our agent in the first person shooter (FPS) game\nof Doom. Our work is based on previous works in deep reinforcement learning and\nin Doom agents. We also present how our agent is able to perform better in\nunknown environments compared to a state of the art reinforcement learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:30:15 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Chatzidimitriou", "Kyriakos C.", ""], ["Mitkas", "Pericles A.", ""]]}, {"id": "1807.01970", "submitter": "Alexis Brenon", "authors": "Alexis Brenon and Fran\\c{c}ois Portet and Michel Vacher", "title": "Arcades: A deep model for adaptive decision making in voice controlled\n  smart-home", "comments": "27 pages, 15 figures, 5 tables, 4 algorithms. In Press, Accepted\n  Manuscript", "journal-ref": "Pervasive and Mobile Computing, Volume 49, September 2018, Pages\n  92-110", "doi": "10.1016/j.pmcj.2018.06.011", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a voice-controlled smart-home, a controller must respond not only to\nuser's requests but also according to the interaction context. This paper\ndescribes Arcades, a system which uses deep reinforcement learning to extract\ncontext from a graphical representation of home automation system and to update\ncontinuously its behavior to the user's one. This system is robust to changes\nin the environment (sensor breakdown or addition) through its graphical\nrepresentation (scale well) and the reinforcement mechanism (adapt well). The\nexperiments on realistic data demonstrate that this method promises to reach\nlong life context-aware control of smart-home.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:50:16 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Brenon", "Alexis", ""], ["Portet", "Fran\u00e7ois", ""], ["Vacher", "Michel", ""]]}, {"id": "1807.02037", "submitter": "Tung D. Le", "authors": "Tung D. Le, Haruki Imai, Yasushi Negishi and Kiyokuni Kawachiya", "title": "TFLMS: Large Model Support in TensorFlow by Graph Rewriting", "comments": "A new version of TFLMS was published at ISMM 2019\n  (https://dl.acm.org/citation.cfm?id=3329984)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While accelerators such as GPUs have limited memory, deep neural networks are\nbecoming larger and will not fit with the memory limitation of accelerators for\ntraining. We propose an approach to tackle this problem by rewriting the\ncomputational graph of a neural network, in which swap-out and swap-in\noperations are inserted to temporarily store intermediate results on CPU\nmemory. In particular, we first revise the concept of a computational graph by\ndefining a concrete semantics for variables in a graph. We then formally show\nhow to derive swap-out and swap-in operations from an existing graph and\npresent rules to optimize the graph. To realize our approach, we developed a\nmodule in TensorFlow, named TFLMS. TFLMS is published as a pull request in the\nTensorFlow repository for contributing to the TensorFlow community. With TFLMS,\nwe were able to train ResNet-50 and 3DUnet with 4.7x and 2x larger batch size,\nrespectively. In particular, we were able to train 3DUNet using images of size\nof $192^3$ for image segmentation, which, without TFLMS, had been done only by\ndividing the images to smaller images, which affects the accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:56:39 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:54:46 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Le", "Tung D.", ""], ["Imai", "Haruki", ""], ["Negishi", "Yasushi", ""], ["Kawachiya", "Kiyokuni", ""]]}, {"id": "1807.02072", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin", "title": "Representing scenarios for process evolution management", "comments": "12 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the following writing we discuss a conceptual framework for representing\nevents and scenarios from the perspective of a novel form of causal analysis.\nThis causal analysis is applied to the events and scenarios so as to determine\nmeasures that could be used to manage the development of the processes that\nthey are a part of in real time. An overall terminological framework and\nentity-relationship model are suggested along with a specification of the\nfunctional sets involved in both reasoning and analytics. The model is\nconsidered to be a specific case of the generic problem of finding sequential\nseries in disparate data. The specific inference and reasoning processes are\nidentified for future implementation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 16:10:23 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Kolonin", "Anton", ""]]}, {"id": "1807.02155", "submitter": "Konstantinos Michmizos", "authors": "Guangzhi Tang, Konstantinos P. Michmizos", "title": "Gridbot: An autonomous robot controlled by a Spiking Neural Network\n  mimicking the brain's navigational system", "comments": "8 pages, 3 Figures, International Conference on Neuromorphic Systems\n  (ICONS 2018)", "journal-ref": null, "doi": "10.1145/3229884.3229888", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is true that the \"best\" neural network is not necessarily the one with the\nmost \"brain-like\" behavior. Understanding biological intelligence, however, is\na fundamental goal for several distinct disciplines. Translating our\nunderstanding of intelligence to machines is a fundamental problem in robotics.\nPropelled by new advancements in Neuroscience, we developed a spiking neural\nnetwork (SNN) that draws from mounting experimental evidence that a number of\nindividual neurons is associated with spatial navigation. By following the\nbrain's structure, our model assumes no initial all-to-all connectivity, which\ncould inhibit its translation to a neuromorphic hardware, and learns an\nuncharted territory by mapping its identified components into a limited number\nof neural representations, through spike-timing dependent plasticity (STDP). In\nour ongoing effort to employ a bioinspired SNN-controlled robot to real-world\nspatial mapping applications, we demonstrate here how an SNN may robustly\ncontrol an autonomous robot in mapping and exploring an unknown environment,\nwhile compensating for its own intrinsic hardware imperfections, such as\npartial or total loss of visual input.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 19:09:45 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Tang", "Guangzhi", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1807.02189", "submitter": "David Paulius", "authors": "David Paulius, Ahmad Babaeian Jelodar and Yu Sun", "title": "Functional Object-Oriented Network: Construction & Expansion", "comments": "7 pages, 3 figures, presented at ICRA 2018", "journal-ref": "ICRA 2018 Submission -- 7 pages", "doi": "10.1109/ICRA.2018.8460200", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build upon the functional object-oriented network (FOON), a structured\nknowledge representation which is constructed from observations of human\nactivities and manipulations. A FOON can be used for representing object-motion\naffordances. Knowledge retrieval through graph search allows us to obtain novel\nmanipulation sequences using knowledge spanning across many video sources,\nhence the novelty in our approach. However, we are limited to the sources\ncollected. To further improve the performance of knowledge retrieval as a\nfollow up to our previous work, we discuss generalizing knowledge to be applied\nto objects which are similar to what we have in FOON without manually\nannotating new sources of knowledge. We discuss two means of generalization: 1)\nexpanding our network through the use of object similarity to create new\nfunctional units from those we already have, and 2) compressing the functional\nunits by object categories rather than specific objects. We discuss experiments\nwhich compare the performance of our knowledge retrieval algorithm with both\nexpansion and compression by categories.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 21:59:30 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 04:28:52 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Paulius", "David", ""], ["Jelodar", "Ahmad Babaeian", ""], ["Sun", "Yu", ""]]}, {"id": "1807.02192", "submitter": "David Paulius", "authors": "David Paulius and Yu Sun", "title": "A Survey of Knowledge Representation in Service Robotics", "comments": "Accepted for RAS Special Issue on Semantic Policy and Action\n  Representations for Autonomous Robots - 22 Pages", "journal-ref": null, "doi": "10.1016/j.robot.2019.03.005", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the realm of service robotics, researchers have placed a great amount\nof effort into learning, understanding, and representing motions as\nmanipulations for task execution by robots. The task of robot learning and\nproblem-solving is very broad, as it integrates a variety of tasks such as\nobject detection, activity recognition, task/motion planning, localization,\nknowledge representation and retrieval, and the intertwining of\nperception/vision and machine learning techniques. In this paper, we solely\nfocus on knowledge representations and notably how knowledge is typically\ngathered, represented, and reproduced to solve problems as done by researchers\nin the past decades. In accordance with the definition of knowledge\nrepresentations, we discuss the key distinction between such representations\nand useful learning models that have extensively been introduced and studied in\nrecent years, such as machine learning, deep learning, probabilistic modelling,\nand semantic graphical structures. Along with an overview of such tools, we\ndiscuss the problems which have existed in robot learning and how they have\nbeen built and used as solutions, technologies or developments (if any) which\nhave contributed to solving them. Finally, we discuss key principles that\nshould be considered when designing an effective knowledge representation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 22:18:08 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 20:24:53 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 00:39:17 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Paulius", "David", ""], ["Sun", "Yu", ""]]}, {"id": "1807.02254", "submitter": "Cheng-Wei Wu", "authors": "Cheng-Wei Wu, Jen-Yu Liu, Yi-Hsuan Yang, Jyh-Shing R. Jang", "title": "Singing Style Transfer Using Cycle-Consistent Boundary Equilibrium\n  Generative Adversarial Networks", "comments": "3 pages, 3 figures, demo website:\n  http://mirlab.org/users/haley.wu/cybegan", "journal-ref": "ICML Workshop 2018 (Joint Music Workshop)", "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we make a famous rap singer like Eminem sing whatever our favorite song?\nSinging style transfer attempts to make this possible, by replacing the vocal\nof a song from the source singer to the target singer. This paper presents a\nmethod that learns from unpaired data for singing style transfer using\ngenerative adversarial networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 04:32:18 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Wu", "Cheng-Wei", ""], ["Liu", "Jen-Yu", ""], ["Yang", "Yi-Hsuan", ""], ["Jang", "Jyh-Shing R.", ""]]}, {"id": "1807.02258", "submitter": "Aswani Kumar Cherukuri Dr", "authors": "Raghavendra K Chunduri, Aswani Kumar Cherukuri", "title": "Scalable Formal Concept Analysis algorithm for large datasets using\n  Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process of knowledge discovery and representation in large datasets\nusing formal concept analysis, complexity plays a major role in identifying all\nthe formal concepts and constructing the concept lattice(digraph of the\nconcepts). For identifying the formal concepts and constructing the digraph\nfrom the identified concepts in very large datasets, various distributed\nalgorithms are available in the literature. However, the existing distributed\nalgorithms are not very well suitable for concept generation because it is an\niterative process. The existing algorithms are implemented using distributed\nframeworks like MapReduce and Open MP, these frameworks are not appropriate for\niterative applications. Hence, in this paper we proposed efficient distributed\nalgorithms for both formal concept generation and concept lattice digraph\nconstruction in large formal contexts using Apache Spark. Various performance\nmetrics are considered for the evaluation of the proposed work, the results of\nthe evaluation proves that the proposed algorithms are efficient for concept\ngeneration and lattice graph construction in comparison with the existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 05:22:31 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Chunduri", "Raghavendra K", ""], ["Cherukuri", "Aswani Kumar", ""]]}, {"id": "1807.02262", "submitter": "Charini Nanayakkara", "authors": "Charini Nanayakkara, Peter Christen and Thilina Ranbaduge", "title": "Temporal graph-based clustering for historical record linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in the social sciences is increasingly based on large and complex\ndata collections, where individual data sets from different domains are linked\nand integrated to allow advanced analytics. A popular type of data used in such\na context are historical censuses, as well as birth, death, and marriage\ncertificates. Individually, such data sets however limit the types of studies\nthat can be conducted. Specifically, it is impossible to track individuals,\nfamilies, or households over time. Once such data sets are linked and family\ntrees spanning several decades are available it is possible to, for example,\ninvestigate how education, health, mobility, employment, and social status\ninfluence each other and the lives of people over two or even more generations.\nA major challenge is however the accurate linkage of historical data sets which\nis due to data quality and commonly also the lack of ground truth data being\navailable. Unsupervised techniques need to be employed, which can be based on\nsimilarity graphs generated by comparing individual records. In this paper we\npresent initial results from clustering birth records from Scotland where we\naim to identify all births of the same mother and group siblings into clusters.\nWe extend an existing clustering technique for record linkage by incorporating\ntemporal constraints that must hold between births by the same mother, and\npropose a novel greedy temporal clustering technique. Experimental results show\nimprovements over non-temporary approaches, however further work is needed to\nobtain links of high quality.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 05:51:48 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Nanayakkara", "Charini", ""], ["Christen", "Peter", ""], ["Ranbaduge", "Thilina", ""]]}, {"id": "1807.02297", "submitter": "Tanner Fiez", "authors": "Tanner Fiez, Shreyas Sekar, Liyuan Zheng, Lillian J. Ratliff", "title": "Combinatorial Bandits for Incentivizing Agents with Dynamic Preferences", "comments": "Published as a conference paper in Conference on Uncertainty in\n  Artificial Intelligence (UAI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of personalized incentives or recommendations to improve user\nengagement is gaining prominence as digital platform providers continually\nemerge. We propose a multi-armed bandit framework for matching incentives to\nusers, whose preferences are unknown a priori and evolving dynamically in time,\nin a resource constrained environment. We design an algorithm that combines\nideas from three distinct domains: (i) a greedy matching paradigm, (ii) the\nupper confidence bound algorithm (UCB) for bandits, and (iii) mixing times from\nthe theory of Markov chains. For this algorithm, we provide theoretical bounds\non the regret and demonstrate its performance via both synthetic and realistic\n(matching supply and demand in a bike-sharing platform) examples.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:03:39 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Fiez", "Tanner", ""], ["Sekar", "Shreyas", ""], ["Zheng", "Liyuan", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "1807.02303", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Freek Stulp,\n  Sylvain Calinon and Jean-Baptiste Mouret", "title": "A survey on policy search algorithms for learning robot controllers in a\n  handful of trials", "comments": "21 pages, 3 figures, 4 algorithms, accepted at IEEE Transactions on\n  Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most policy search algorithms require thousands of training episodes to find\nan effective policy, which is often infeasible with a physical robot. This\nsurvey article focuses on the extreme other end of the spectrum: how can a\nrobot adapt with only a handful of trials (a dozen) and a few minutes? By\nanalogy with the word \"big-data\", we refer to this challenge as \"micro-data\nreinforcement learning\". We show that a first strategy is to leverage prior\nknowledge on the policy structure (e.g., dynamic movement primitives), on the\npolicy parameters (e.g., demonstrations), or on the dynamics (e.g.,\nsimulators). A second strategy is to create data-driven surrogate models of the\nexpected reward (e.g., Bayesian optimization) or the dynamical model (e.g.,\nmodel-based policy search), so that the policy optimizer queries the model\ninstead of the real system. Overall, all successful micro-data algorithms\ncombine these two strategies by varying the kind of model and prior knowledge.\nThe current scientific challenges essentially revolve around scaling up to\ncomplex robots (e.g., humanoids), designing generic priors, and optimizing the\ncomputing time.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:14:27 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:17:41 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 13:44:20 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 22:22:44 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 10:24:27 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Vassiliades", "Vassilis", ""], ["Stulp", "Freek", ""], ["Calinon", "Sylvain", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1807.02314", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Lili Mou, Haotian Cui, Zhengdong Lu, Sen Song", "title": "JUMPER: Learning When to Make Classification Decisions in Reading", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In early years, text classification is typically accomplished by\nfeature-based machine learning models; recently, deep neural networks, as a\npowerful learning machine, make it possible to work with raw input as the text\nstands. However, exiting end-to-end neural networks lack explicit\ninterpretation of the prediction. In this paper, we propose a novel framework,\nJUMPER, inspired by the cognitive process of text reading, that models text\nclassification as a sequential decision process. Basically, JUMPER is a neural\nsystem that scans a piece of text sequentially and makes classification\ndecisions at the time it wishes. Both the classification result and when to\nmake the classification are part of the decision process, which is controlled\nby a policy network and trained with reinforcement learning. Experimental\nresults show that a properly trained JUMPER has the following properties: (1)\nIt can make decisions whenever the evidence is enough, therefore reducing total\ntext reading by 30-40% and often finding the key rationale of prediction. (2)\nIt achieves classification accuracy better than or comparable to\nstate-of-the-art models in several benchmark and industrial datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:49:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liu", "Xianggen", ""], ["Mou", "Lili", ""], ["Cui", "Haotian", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1807.02322", "submitter": "Chen Liang", "authors": "Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc Le, Ni Lao", "title": "Memory Augmented Policy Optimization for Program Synthesis and Semantic\n  Parsing", "comments": "17 Pages, 4 figures, 7 tables, accepted as a spotlight paper for\n  NeurIPS 2018, camera ready version, fixed a typo in table 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Memory Augmented Policy Optimization (MAPO), a simple and novel\nway to leverage a memory buffer of promising trajectories to reduce the\nvariance of policy gradient estimate. MAPO is applicable to deterministic\nenvironments with discrete actions, such as structured prediction and\ncombinatorial optimization tasks. We express the expected return objective as a\nweighted sum of two terms: an expectation over the high-reward trajectories\ninside the memory buffer, and a separate expectation over trajectories outside\nthe buffer. To make an efficient algorithm of MAPO, we propose: (1) memory\nweight clipping to accelerate and stabilize training; (2) systematic\nexploration to discover high-reward trajectories; (3) distributed sampling from\ninside and outside of the memory buffer to scale up training. MAPO improves the\nsample efficiency and robustness of policy gradient, especially on tasks with\nsparse rewards. We evaluate MAPO on weakly supervised program synthesis from\nnatural language (semantic parsing). On the WikiTableQuestions benchmark, we\nimprove the state-of-the-art by 2.6%, achieving an accuracy of 46.3%. On the\nWikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak\nsupervision, outperforming several strong baselines with full supervision. Our\nsource code is available at\nhttps://github.com/crazydonkey200/neural-symbolic-machines\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:15:05 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:53:35 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 07:51:12 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2018 17:58:45 GMT"}, {"version": "v5", "created": "Sun, 13 Jan 2019 02:03:10 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Liang", "Chen", ""], ["Norouzi", "Mohammad", ""], ["Berant", "Jonathan", ""], ["Le", "Quoc", ""], ["Lao", "Ni", ""]]}, {"id": "1807.02340", "submitter": "Wenyu Wang", "authors": "Wujie Zheng, Wenyu Wang, Dian Liu, Changrong Zhang, Qinsong Zeng,\n  Yuetang Deng, Wei Yang, Pinjia He, Tao Xie", "title": "Testing Untestable Neural Machine Translation: An Industrial Case", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has been widely adopted recently due to its\nadvantages compared with the traditional Statistical Machine Translation (SMT).\nHowever, an NMT system still often produces translation failures due to the\ncomplexity of natural language and sophistication in designing neural networks.\nWhile in-house black-box system testing based on reference translations (i.e.,\nexamples of valid translations) has been a common practice for NMT quality\nassurance, an increasingly critical industrial practice, named in-vivo testing,\nexposes unseen types or instances of translation failures when real users are\nusing a deployed industrial NMT system. To fill the gap of lacking test oracle\nfor in-vivo testing of an NMT system, in this paper, we propose a new approach\nfor automatically identifying translation failures, without requiring reference\ntranslations for a translation task; our approach can directly serve as a test\noracle for in-vivo testing. Our approach focuses on properties of natural\nlanguage translation that can be checked systematically and uses information\nfrom both the test inputs (i.e., the texts to be translated) and the test\noutputs (i.e., the translations under inspection) of the NMT system. Our\nevaluation conducted on real-world datasets shows that our approach can\neffectively detect targeted property violations as translation failures. Our\nexperiences on deploying our approach in both production and development\nenvironments of WeChat (a messenger app with over one billion monthly active\nusers) demonstrate high effectiveness of our approach along with high industry\nimpact.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 10:17:44 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:42:51 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Zheng", "Wujie", ""], ["Wang", "Wenyu", ""], ["Liu", "Dian", ""], ["Zhang", "Changrong", ""], ["Zeng", "Qinsong", ""], ["Deng", "Yuetang", ""], ["Yang", "Wei", ""], ["He", "Pinjia", ""], ["Xie", "Tao", ""]]}, {"id": "1807.02383", "submitter": "Sonit Singh", "authors": "Sonit Singh", "title": "Natural Language Processing for Information Extraction", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With rise of digital age, there is an explosion of information in the form of\nnews, articles, social media, and so on. Much of this data lies in unstructured\nform and manually managing and effectively making use of it is tedious, boring\nand labor intensive. This explosion of information and need for more\nsophisticated and efficient information handling tools gives rise to\nInformation Extraction(IE) and Information Retrieval(IR) technology.\nInformation Extraction systems takes natural language text as input and\nproduces structured information specified by certain criteria, that is relevant\nto a particular application. Various sub-tasks of IE such as Named Entity\nRecognition, Coreference Resolution, Named Entity Linking, Relation Extraction,\nKnowledge Base reasoning forms the building blocks of various high end Natural\nLanguage Processing (NLP) tasks such as Machine Translation, Question-Answering\nSystem, Natural Language Understanding, Text Summarization and Digital\nAssistants like Siri, Cortana and Google Now. This paper introduces Information\nExtraction technology, its various sub-tasks, highlights state-of-the-art\nresearch in various IE subtasks, current challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 12:44:31 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Singh", "Sonit", ""]]}, {"id": "1807.02406", "submitter": "Ramesh Ramasamy Pandi", "authors": "Song Guang Ho, Ramesh Ramasamy Pandi, Sarat Chandra Nagavarapu and\n  Justin Dauwels", "title": "Multi-atomic Annealing Heuristic for Static Dial-a-ride Problem", "comments": "To be presented at the IEEE International Conference on Service\n  Operations and Logistics, and Informatics (SOLI), Singapore, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dial-a-ride problem (DARP) deals with the transportation of users between\npickup and drop-off locations associated with specified time windows. This\npaper proposes a novel algorithm called multi-atomic annealing (MATA) to solve\nstatic dial-a-ride problem. Two new local search operators (burn and reform), a\nnew construction heuristic and two request sequencing mechanisms (Sorted List\nand Random List) are developed. Computational experiments conducted on various\nstandard DARP test instances prove that MATA is an expeditious meta-heuristic\nin contrast to other existing methods. In all experiments, MATA demonstrates\nthe capability to obtain high quality solutions, faster convergence, and\nquicker attainment of a first feasible solution. It is observed that MATA\nattains a first feasible solution 29.8 to 65.1% faster, and obtains a final\nsolution that is 3.9 to 5.2% better, when compared to other algorithms within\n60 sec.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 12:09:57 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ho", "Song Guang", ""], ["Pandi", "Ramesh Ramasamy", ""], ["Nagavarapu", "Sarat Chandra", ""], ["Dauwels", "Justin", ""]]}, {"id": "1807.02416", "submitter": "Songuel Tolan", "authors": "Enrique Fern\\'andez-Mac\\'ias and Emilia G\\'omez and Jos\\'e\n  Hern\\'andez-Orallo and Bao Sheng Loe and Bertin Martens and Fernando\n  Mart\\'inez-Plumed and Song\\\"ul Tolan", "title": "A multidisciplinary task-based perspective for evaluating the impact of\n  AI autonomy and generality on the future of work", "comments": "AEGAP2018 Workshop at ICML 2018, 7 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a multidisciplinary task approach for assessing the\nimpact of artificial intelligence on the future of work. We provide definitions\nof a task from two main perspectives: socio-economic and computational. We\npropose to explore ways in which we can integrate or map these perspectives,\nand link them with the skills or capabilities required by them, for humans and\nAI systems. Finally, we argue that in order to understand the dynamics of\ntasks, we have to explore the relevance of autonomy and generality of AI\nsystems for the automation or alteration of the workplace.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 13:52:23 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Fern\u00e1ndez-Mac\u00edas", "Enrique", ""], ["G\u00f3mez", "Emilia", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""], ["Loe", "Bao Sheng", ""], ["Martens", "Bertin", ""], ["Mart\u00ednez-Plumed", "Fernando", ""], ["Tolan", "Song\u00fcl", ""]]}, {"id": "1807.02490", "submitter": "Shabnam Ghaffarzadegan", "authors": "Shabnam Ghaffarzadegan", "title": "Deep Multiple Instance Feature Learning via Variational Autoencoder", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel weakly supervised deep learning framework that combines\nboth the discriminative and generative models to learn meaningful\nrepresentation in the multiple instance learning (MIL) setting. MIL is a weakly\nsupervised learning problem where labels are associated with groups of\ninstances (referred as bags) instead of individual instances. To address the\nessential challenge in MIL problems raised from the uncertainty of positive\ninstances label, we use a discriminative model regularized by variational\nautoencoders (VAEs) to maximize the differences between latent representations\nof all instances and negative instances. As a result, the hidden layer of the\nvariational autoencoder learns meaningful representation. This representation\ncan effectively be used for MIL problems as illustrated by better performance\non the standard benchmark datasets comparing to the state-of-the-art\napproaches. More importantly, unlike most related studies, the proposed\nframework can be easily scaled to large dataset problems, as illustrated by the\naudio event detection and segmentation task. Visualization also confirms the\neffectiveness of the latent representation in discriminating positive and\nnegative classes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 17:05:10 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ghaffarzadegan", "Shabnam", ""]]}, {"id": "1807.02572", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Vasanth Sarathy, Thomas Arnold, Matthias Scheutz,\n  Tom Williams", "title": "Quasi-Dilemmas for Artificial Moral Agents", "comments": "Accepted to the International Conference on Robot Ethics and\n  Standards (ICRES), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe moral quasi-dilemmas (MQDs): situations similar to\nmoral dilemmas, but in which an agent is unsure whether exploring the plan\nspace or the world may reveal a course of action that satisfies all moral\nrequirements. We argue that artificial moral agents (AMAs) should be built to\nhandle MQDs (in particular, by exploring the plan space rather than immediately\naccepting the inevitability of the moral dilemma), and that MQDs may be useful\nfor evaluating AMA architectures.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 21:34:48 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Sarathy", "Vasanth", ""], ["Arnold", "Thomas", ""], ["Scheutz", "Matthias", ""], ["Williams", "Tom", ""]]}, {"id": "1807.02637", "submitter": "Dejan Lavbi\\v{c}", "authors": "Dejan Lavbi\\v{c}, Tadej Matek and Alja\\v{z} Zrnec", "title": "Recommender system for learning SQL using hints", "comments": "18 pages, 8 figures, 2 tables", "journal-ref": "Interactive learning environments 25 (2017) 1048 - 1064", "doi": "10.1080/10494820.2016.1244084", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's software industry requires individuals who are proficient in as many\nprogramming languages as possible. Structured query language (SQL), as an\nadopted standard, is no exception, as it is the most widely used query language\nto retrieve and manipulate data. However, the process of learning SQL turns out\nto be challenging. The need for a computer-aided solution to help users learn\nSQL and improve their proficiency is vital. In this study, we present a new\napproach to help users conceptualize basic building blocks of the language\nfaster and more efficiently. The adaptive design of the proposed approach aids\nusers in learning SQL by supporting their own path to the solution and\nemploying successful previous attempts, while not enforcing the ideal solution\nprovided by the instructor. Furthermore, we perform an empirical evaluation\nwith 93 participants and demonstrate that the employment of hints is\nsuccessful, being especially beneficial for users with lower prior knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 09:13:34 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lavbi\u010d", "Dejan", ""], ["Matek", "Tadej", ""], ["Zrnec", "Alja\u017e", ""]]}, {"id": "1807.02648", "submitter": "Chairi Kiourt", "authors": "Chairi Kiourt, Dimitris Kalles and Panagiotis Kanellopoulos", "title": "How game complexity affects the playing behavior of synthetic agents", "comments": "15th European Conference on Multi-Agent Systems, Evry, France, 14-15\n  December 2017", "journal-ref": "Multi-Agent Systems and Agreement Technologies. EUMAS 2017, AT\n  2017. Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-01713-2_22", "report-no": null, "categories": "cs.AI cs.CC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent based simulation of social organizations, via the investigation of\nagents' training and learning tactics and strategies, has been inspired by the\nability of humans to learn from social environments which are rich in agents,\ninteractions and partial or hidden information. Such richness is a source of\ncomplexity that an effective learner has to be able to navigate. This paper\nfocuses on the investigation of the impact of the environmental complexity on\nthe game playing-and-learning behavior of synthetic agents. We demonstrate our\napproach using two independent turn-based zero-sum games as the basis of\nforming social events which are characterized both by competition and\ncooperation. The paper's key highlight is that as the complexity of a social\nenvironment changes, an effective player has to adapt its learning and playing\nprofile to maintain a given performance profile\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 11:57:21 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kiourt", "Chairi", ""], ["Kalles", "Dimitris", ""], ["Kanellopoulos", "Panagiotis", ""]]}, {"id": "1807.02799", "submitter": "Haseeb Shah", "authors": "Haseeb Shah, Khurram Javed and Faisal Shafait", "title": "Distillation Techniques for Pseudo-rehearsal Based Incremental Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from incrementally arriving data is essential for any\nlife-long learning system. However, standard deep neural networks forget the\nknowledge about the old tasks, a phenomenon called catastrophic forgetting,\nwhen trained on incrementally arriving data. We discuss the biases in current\nGenerative Adversarial Networks (GAN) based approaches that learn the\nclassifier by knowledge distillation from previously trained classifiers. These\nbiases cause the trained classifier to perform poorly. We propose an approach\nto remove these biases by distilling knowledge from the classifier of AC-GAN.\nExperiments on MNIST and CIFAR10 show that this method is comparable to current\nstate of the art rehearsal based approaches. The code for this paper is\navailable at https://bit.ly/incremental-learning\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 11:01:00 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 09:46:50 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 08:05:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Shah", "Haseeb", ""], ["Javed", "Khurram", ""], ["Shafait", "Faisal", ""]]}, {"id": "1807.02879", "submitter": "Laura Giordano", "authors": "Laura Giordano, Valentina Gliozzi", "title": "Reasoning about exceptions in ontologies: from the lexicographic closure\n  to the skeptical closure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about exceptions in ontologies is nowadays one of the challenges\nthe description logics community is facing. The paper describes a preferential\napproach for dealing with exceptions in Description Logics, based on the\nrational closure. The rational closure has the merit of providing a simple and\nefficient approach for reasoning with exceptions, but it does not allow\nindependent handling of the inheritance of different defeasible properties of\nconcepts. In this work we outline a possible solution to this problem by\nintroducing a variant of the lexicographical closure, that we call skeptical\nclosure, which requires to construct a single base. We develop a bi-preference\nsemantics semantics for defining a characterization of the skeptical closure.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 20:28:54 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Giordano", "Laura", ""], ["Gliozzi", "Valentina", ""]]}, {"id": "1807.02886", "submitter": "Hamed Hakkak", "authors": "Hamed Hakkak", "title": "Auto Deep Compression by Reinforcement Learning Based Actor-Critic\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based compression is an effective, facilitating, and expanded model of\nneural network models with limited computing and low power. However,\nconventional models of compression techniques utilize crafted features [2,3,12]\nand explore specialized areas for exploration and design of large spaces in\nterms of size, speed, and accuracy, which usually have returns Less and time is\nup. This paper will effectively analyze deep auto compression (ADC) and\nreinforcement learning strength in an effective sample and space design, and\nimprove the compression quality of the model. The results of compression of the\nadvanced model are obtained without any human effort and in a completely\nautomated way. With a 4- fold reduction in FLOP, the accuracy of 2.8% is higher\nthan the manual compression model for VGG-16 in ImageNet.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 21:34:30 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Hakkak", "Hamed", ""]]}, {"id": "1807.02963", "submitter": "Ryo Shirakawa", "authors": "Ryo Shirakawa, Yusei Yokoyama, Fumiya Okazaki, Ichigaku Takigawa", "title": "Jointly learning relevant subgraph patterns and nonlinear models of\n  their indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification and regression in which the inputs are graphs of arbitrary\nsize and shape have been paid attention in various fields such as computational\nchemistry and bioinformatics. Subgraph indicators are often used as the most\nfundamental features, but the number of possible subgraph patterns are\nintractably large due to the combinatorial explosion. We propose a novel\nefficient algorithm to jointly learn relevant subgraph patterns and nonlinear\nmodels of their indicators. Previous methods for such joint learning of\nsubgraph features and models are based on search for single best subgraph\nfeatures with specific pruning and boosting procedures of adding their\nindicators one by one, which result in linear models of subgraph indicators. In\ncontrast, the proposed approach is based on directly learning regression trees\nfor graph inputs using a newly derived bound of the total sum of squares for\ndata partitions by a given subgraph feature, and thus can learn nonlinear\nmodels through standard gradient boosting. An illustrative example we call the\nGraph-XOR problem to consider nonlinearity, numerical experiments with real\ndatasets, and scalability comparisons to naive approaches using explicit\npattern enumeration are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 06:56:22 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Shirakawa", "Ryo", ""], ["Yokoyama", "Yusei", ""], ["Okazaki", "Fumiya", ""], ["Takigawa", "Ichigaku", ""]]}, {"id": "1807.03021", "submitter": "Fangneng Zhan", "authors": "Fangneng Zhan, Shijian Lu, Chuhui Xue", "title": "Verisimilar Image Synthesis for Accurate Detection and Recognition of\n  Texts in Scenes", "comments": "14 pages, ECCV2018, datasets:\n  https://github.com/fnzhan/Verisimilar-Image-Synthesis-for-Accurate-Detection-and-Recognition-of-Texts-in-Scenes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirement of large amounts of annotated images has become one grand\nchallenge while training deep neural network models for various visual\ndetection and recognition tasks. This paper presents a novel image synthesis\ntechnique that aims to generate a large amount of annotated scene text images\nfor training accurate and robust scene text detection and recognition models.\nThe proposed technique consists of three innovative designs. First, it realizes\n\"semantic coherent\" synthesis by embedding texts at semantically sensible\nregions within the background image, where the semantic coherence is achieved\nby leveraging the semantic annotations of objects and image regions that have\nbeen created in the prior semantic segmentation research. Second, it exploits\nvisual saliency to determine the embedding locations within each semantic\nsensible region, which coincides with the fact that texts are often placed\naround homogeneous regions for better visibility in scenes. Third, it designs\nan adaptive text appearance model that determines the color and brightness of\nembedded texts by learning from the feature of real scene text images\nadaptively. The proposed technique has been evaluated over five public datasets\nand the experiments show its superior performance in training accurate and\nrobust scene text detection and recognition models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:58:06 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 07:55:02 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Zhan", "Fangneng", ""], ["Lu", "Shijian", ""], ["Xue", "Chuhui", ""]]}, {"id": "1807.03024", "submitter": "Joris Mooij", "authors": "Patrick Forr\\'e and Joris M. Mooij", "title": "Constraint-based Causal Discovery for Non-Linear Structural Causal\n  Models with Cycles and Latent Confounders", "comments": "Accepted for publication in Conference on Uncertainty in Artificial\n  Intelligence 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of causal discovery from data, making use of the\nrecently proposed causal modeling framework of modular structural causal models\n(mSCM) to handle cycles, latent confounders and non-linearities. We introduce\n{\\sigma}-connection graphs ({\\sigma}-CG), a new class of mixed graphs\n(containing undirected, bidirected and directed edges) with additional\nstructure, and extend the concept of {\\sigma}-separation, the appropriate\ngeneralization of the well-known notion of d-separation in this setting, to\napply to {\\sigma}-CGs. We prove the closedness of {\\sigma}-separation under\nmarginalisation and conditioning and exploit this to implement a test of\n{\\sigma}-separation on a {\\sigma}-CG. This then leads us to the first causal\ndiscovery algorithm that can handle non-linear functional relations, latent\nconfounders, cyclic causal relationships, and data from different (stochastic)\nperfect interventions. As a proof of concept, we show on synthetic data how\nwell the algorithm recovers features of the causal graph of modular structural\ncausal models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:17:48 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Forr\u00e9", "Patrick", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1807.03039", "submitter": "Prafulla Dhariwal", "authors": "Diederik P. Kingma, Prafulla Dhariwal", "title": "Glow: Generative Flow with Invertible 1x1 Convolutions", "comments": "15 pages; fixed typo in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models (Dinh et al., 2014) are conceptually attractive\ndue to tractability of the exact log-likelihood, tractability of exact\nlatent-variable inference, and parallelizability of both training and\nsynthesis. In this paper we propose Glow, a simple type of generative flow\nusing an invertible 1x1 convolution. Using our method we demonstrate a\nsignificant improvement in log-likelihood on standard benchmarks. Perhaps most\nstrikingly, we demonstrate that a generative model optimized towards the plain\nlog-likelihood objective is capable of efficient realistic-looking synthesis\nand manipulation of large images. The code for our model is available at\nhttps://github.com/openai/glow\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:57:26 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 05:12:03 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Dhariwal", "Prafulla", ""]]}, {"id": "1807.03052", "submitter": "Benjamin Roth", "authors": "Ivan Bilan and Benjamin Roth", "title": "Position-aware Self-attention with Relative Positional Encodings for\n  Slot Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes how to apply self-attention with relative positional\nencodings to the task of relation extraction. We propose to use the\nself-attention encoder layer together with an additional position-aware\nattention layer that takes into account positions of the query and the object\nin the sentence. The self-attention encoder also uses a custom implementation\nof relative positional encodings which allow each word in the sentence to take\ninto account its left and right context. The evaluation of the model is done on\nthe TACRED dataset. The proposed model relies only on attention (no recurrent\nor convolutional layers are used), while improving performance w.r.t. the\nprevious state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:34:13 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Bilan", "Ivan", ""], ["Roth", "Benjamin", ""]]}, {"id": "1807.03083", "submitter": "Patrick Rodler", "authors": "Patrick Rodler and Wolfgang Schmid", "title": "Evaluating Active Learning Heuristics for Sequential Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a malfunctioning system, sequential diagnosis aims at identifying the\nroot cause of the failure in terms of abnormally behaving system components. As\ninitial system observations usually do not suffice to deterministically pin\ndown just one explanation of the system's misbehavior, additional system\nmeasurements can help to differentiate between possible explanations. The goal\nis to restrict the space of explanations until there is only one (highly\nprobable) explanation left. To achieve this with a minimal-cost set of\nmeasurements, various (active learning) heuristics for selecting the best next\nmeasurement have been proposed.\n  We report preliminary results of extensive ongoing experiments with a set of\nselection heuristics on real-world diagnosis cases. In particular, we try to\nanswer questions such as \"Is some heuristic always superior to all others?\",\n\"On which factors does the (relative) performance of the particular heuristics\ndepend?\" or \"Under which circumstances should I use which heuristic?\"\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 12:56:03 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Rodler", "Patrick", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1807.03100", "submitter": "Oleksandr Polozov", "authors": "Chenglong Wang, Kedar Tatwawadi, Marc Brockschmidt, Po-Sen Huang, Yi\n  Mao, Oleksandr Polozov, Rishabh Singh", "title": "Robust Text-to-SQL Generation with Execution-Guided Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of neural semantic parsing, which translates natural\nlanguage questions into executable SQL queries. We introduce a new mechanism,\nexecution guidance, to leverage the semantics of SQL. It detects and excludes\nfaulty programs during the decoding procedure by conditioning on the execution\nof partially generated program. The mechanism can be used with any\nautoregressive generative model, which we demonstrate on four state-of-the-art\nrecurrent or template-based semantic parsing models. We demonstrate that\nexecution guidance universally improves model performance on various\ntext-to-SQL datasets with different scales and query complexity: WikiSQL, ATIS,\nand GeoQuery. As a result, we achieve new state-of-the-art execution accuracy\nof 83.8% on WikiSQL.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 13:20:28 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 21:55:52 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 00:29:17 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Wang", "Chenglong", ""], ["Tatwawadi", "Kedar", ""], ["Brockschmidt", "Marc", ""], ["Huang", "Po-Sen", ""], ["Mao", "Yi", ""], ["Polozov", "Oleksandr", ""], ["Singh", "Rishabh", ""]]}, {"id": "1807.03168", "submitter": "Maksym Zavershynskyi", "authors": "Maksym Zavershynskyi, Alex Skidanov, Illia Polosukhin", "title": "NAPS: Natural Program Synthesis Dataset", "comments": "4 pages, 5 tables in 2nd Workshop on Neural Abstract Machines &\n  Program Induction (NAMPI), @ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a program synthesis-oriented dataset consisting of human written\nproblem statements and solutions for these problems. The problem statements\nwere collected via crowdsourcing and the program solutions were extracted from\nhuman-written solutions in programming competitions, accompanied by\ninput/output examples. We propose using this dataset for the program synthesis\ntasks aimed for working with real user-generated data. As a baseline we present\nfew models, with the best model achieving 8.8% accuracy, showcasing both the\ncomplexity of the dataset and large room for future research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 02:59:34 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zavershynskyi", "Maksym", ""], ["Skidanov", "Alex", ""], ["Polosukhin", "Illia", ""]]}, {"id": "1807.03210", "submitter": "Michael Kamp", "authors": "Michael Kamp and Linara Adilova and Joachim Sicking and Fabian H\\\"uger\n  and Peter Schlicht and Tim Wirtz and Stefan Wrobel", "title": "Efficient Decentralized Deep Learning by Dynamic Model Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient protocol for decentralized training of deep neural\nnetworks from distributed data sources. The proposed protocol allows to handle\ndifferent phases of model training equally well and to quickly adapt to concept\ndrifts. This leads to a reduction of communication by an order of magnitude\ncompared to periodically communicating state-of-the-art approaches. Moreover,\nwe derive a communication bound that scales well with the hardness of the\nserialized learning problem. The reduction in communication comes at almost no\ncost, as the predictive performance remains virtually unchanged. Indeed, the\nproposed protocol retains loss bounds of periodically averaging schemes. An\nextensive empirical evaluation validates major improvement of the trade-off\nbetween model performance and communication which could be beneficial for\nnumerous decentralized learning applications, such as autonomous driving, or\nvoice recognition and image classification on mobile phones.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:01:51 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 18:45:10 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Sicking", "Joachim", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""], ["Wirtz", "Tim", ""], ["Wrobel", "Stefan", ""]]}, {"id": "1807.03215", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Ge Wang", "title": "Fuzzy Logic Interpretation of Quadratic Networks", "comments": "10 pages and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past several years, deep learning has achieved huge successes in various\napplications. However, such a data-driven approach is often criticized for lack\nof interpretability. Recently, we proposed artificial quadratic neural networks\nconsisting of second-order neurons in potentially many layers. In each\nsecond-order neuron, a quadratic function is used in the place of the inner\nproduct in a traditional neuron, and then undergoes a nonlinear activation.\nWith a single second-order neuron, any fuzzy logic operation, such as XOR, can\nbe implemented. In this sense, any deep network constructed with quadratic\nneurons can be interpreted as a deep fuzzy logic system. Since traditional\nneural networks and second-order counterparts can represent each other and\nfuzzy logic operations are naturally implemented in second-order neural\nnetworks, it is plausible to explain how a deep neural network works with a\nsecond-order network as the system model. In this paper, we generalize and\ncategorize fuzzy logic operations implementable with individual second-order\nneurons, and then perform statistical/information theoretic analyses of\nexemplary quadratic neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 12:45:25 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 19:57:58 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 00:21:40 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Fan", "Fenglei", ""], ["Wang", "Ge", ""]]}, {"id": "1807.03223", "submitter": "Yagiz Savas", "authors": "Yagiz Savas, Melkior Ornik, Murat Cubuktepe, Mustafa O. Karabag, Ufuk\n  Topcu", "title": "Entropy Maximization for Markov Decision Processes Under Temporal Logic\n  Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TAC.2019.2922583", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of synthesizing a policy that maximizes the entropy of a\nMarkov decision process (MDP) subject to a temporal logic constraint. Such a\npolicy minimizes the predictability of the paths it generates, or dually,\nmaximizes the exploration of different paths in an MDP while ensuring the\nsatisfaction of a temporal logic specification. We first show that the maximum\nentropy of an MDP can be finite, infinite or unbounded. We provide necessary\nand sufficient conditions under which the maximum entropy of an MDP is finite,\ninfinite or unbounded. We then present an algorithm which is based on a convex\noptimization problem to synthesize a policy that maximizes the entropy of an\nMDP. We also show that maximizing the entropy of an MDP is equivalent to\nmaximizing the entropy of the paths that reach a certain set of states in the\nMDP. Finally, we extend the algorithm to an MDP subject to a temporal logic\nspecification. In numerical examples, we demonstrate the proposed method on\ndifferent motion planning scenarios and illustrate the relation between the\nrestrictions imposed on the paths by a specification, the maximum entropy, and\nthe predictability of paths.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:19:15 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 17:36:35 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 17:24:10 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Savas", "Yagiz", ""], ["Ornik", "Melkior", ""], ["Cubuktepe", "Murat", ""], ["Karabag", "Mustafa O.", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1807.03224", "submitter": "Aditya Vempaty", "authors": "Ravi Kokku, Aditya Vempaty, Tamer Abuelsaad, Prasenjit Dey, Tammy\n  Humphrey, Akimi Gibson, Jennifer Kotler", "title": "Design and Evaluation of a Tutor Platform for Personalized Vocabulary\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our experiences in designing, implementing, and piloting\nan intelligent vocabulary learning tutor. The design builds on several\nintelligent tutoring design concepts, including graph-based knowledge\nrepresentation, learner modeling, and adaptive learning content and assessment\nexposition. Specifically, we design a novel phased learner model approach to\nenable systematic exposure to words during vocabulary instruction. We also\nbuilt an example application over the tutor platform that uses a learning\nactivity involving videos and an assessment activity involving word to\npicture/image association. More importantly, the tutor adapts to the\nsignificant variation in children's knowledge at the beginning of kindergarten,\nand evolves the application at the speed of each individual learner. A pilot\nstudy with 180 kindergarten learners allowed the tutor to collect various kinds\nof activity information suitable for insights and interventions both at an\nindividual- and class-level. The effort also demonstrates that we can do A/B\ntesting for a variety of hypotheses at scale with such a framework.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:19:22 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Kokku", "Ravi", ""], ["Vempaty", "Aditya", ""], ["Abuelsaad", "Tamer", ""], ["Dey", "Prasenjit", ""], ["Humphrey", "Tammy", ""], ["Gibson", "Akimi", ""], ["Kotler", "Jennifer", ""]]}, {"id": "1807.03341", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Jacob Steinhardt", "title": "Troubling Trends in Machine Learning Scholarship", "comments": "Presented at ICML 2018: The Debates", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collectively, machine learning (ML) researchers are engaged in the creation\nand dissemination of knowledge about data-driven algorithms. In a given paper,\nresearchers might aspire to any subset of the following goals, among others: to\ntheoretically characterize what is learnable, to obtain understanding through\nempirically rigorous experiments, or to build a working system that has high\npredictive accuracy. While determining which knowledge warrants inquiry may be\nsubjective, once the topic is fixed, papers are most valuable to the community\nwhen they act in service of the reader, creating foundational knowledge and\ncommunicating as clearly as possible.\n  Recent progress in machine learning comes despite frequent departures from\nthese ideals. In this paper, we focus on the following four patterns that\nappear to us to be trending in ML scholarship: (i) failure to distinguish\nbetween explanation and speculation; (ii) failure to identify the sources of\nempirical gains, e.g., emphasizing unnecessary modifications to neural\narchitectures when gains actually stem from hyper-parameter tuning; (iii)\nmathiness: the use of mathematics that obfuscates or impresses rather than\nclarifies, e.g., by confusing technical and non-technical concepts; and (iv)\nmisuse of language, e.g., by choosing terms of art with colloquial connotations\nor by overloading established technical terms.\n  While the causes behind these patterns are uncertain, possibilities include\nthe rapid expansion of the community, the consequent thinness of the reviewer\npool, and the often-misaligned incentives between scholarship and short-term\nmeasures of success (e.g., bibliometrics, attention, and entrepreneurial\nopportunity). While each pattern offers a corresponding remedy (don't do it),\nwe also discuss some speculative suggestions for how the community might combat\nthese trends.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 18:59:17 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 12:54:30 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1807.03361", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Marc Modat, Eli Gibson, Wenqi Li, Nooshin Ghavami, Ester\n  Bonmati, Guotai Wang, Steven Bandula, Caroline M. Moore, Mark Emberton,\n  S\\'ebastien Ourselin, J. Alison Noble, Dean C. Barratt, Tom Vercauteren", "title": "Weakly-Supervised Convolutional Neural Networks for Multimodal Image\n  Registration", "comments": "Accepted manuscript in Medical Image Analysis", "journal-ref": null, "doi": "10.1016/j.media.2018.07.002", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the fundamental challenges in supervised learning for multimodal image\nregistration is the lack of ground-truth for voxel-level spatial\ncorrespondence. This work describes a method to infer voxel-level\ntransformation from higher-level correspondence information contained in\nanatomical labels. We argue that such labels are more reliable and practical to\nobtain for reference sets of image pairs than voxel-level correspondence.\nTypical anatomical labels of interest may include solid organs, vessels, ducts,\nstructure boundaries and other subject-specific ad hoc landmarks. The proposed\nend-to-end convolutional neural network approach aims to predict displacement\nfields to align multiple labelled corresponding structures for individual image\npairs during the training, while only unlabelled image pairs are used as the\nnetwork input for inference. We highlight the versatility of the proposed\nstrategy, for training, utilising diverse types of anatomical labels, which\nneed not to be identifiable over all training image pairs. At inference, the\nresulting 3D deformable image registration algorithm runs in real-time and is\nfully-automated without requiring any anatomical labels or initialisation.\nSeveral network architecture variants are compared for registering T2-weighted\nmagnetic resonance images and 3D transrectal ultrasound images from prostate\ncancer patients. A median target registration error of 3.6 mm on landmark\ncentroids and a median Dice of 0.87 on prostate glands are achieved from\ncross-validation experiments, in which 108 pairs of multimodal images from 76\npatients were tested with high-quality anatomical labels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 19:53:16 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Hu", "Yipeng", ""], ["Modat", "Marc", ""], ["Gibson", "Eli", ""], ["Li", "Wenqi", ""], ["Ghavami", "Nooshin", ""], ["Bonmati", "Ester", ""], ["Wang", "Guotai", ""], ["Bandula", "Steven", ""], ["Moore", "Caroline M.", ""], ["Emberton", "Mark", ""], ["Ourselin", "S\u00e9bastien", ""], ["Noble", "J. Alison", ""], ["Barratt", "Dean C.", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1807.03367", "submitter": "Harm de Vries", "authors": "Harm de Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston,\n  Douwe Kiela", "title": "Talk the Walk: Navigating New York City through Grounded Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Talk The Walk\", the first large-scale dialogue dataset grounded\nin action and perception. The task involves two agents (a \"guide\" and a\n\"tourist\") that communicate via natural language in order to achieve a common\ngoal: having the tourist navigate to a given target location. The task and\ndataset, which are described in detail, are challenging and their full solution\nis an open problem that we pose to the community. We (i) focus on the task of\ntourist localization and develop the novel Masked Attention for Spatial\nConvolutions (MASC) mechanism that allows for grounding tourist utterances into\nthe guide's map, (ii) show it yields significant improvements for both emergent\nand natural language communication, and (iii) using this method, we establish\nnon-trivial baselines on the full task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:05:24 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 16:07:08 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 22:42:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["de Vries", "Harm", ""], ["Shuster", "Kurt", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Weston", "Jason", ""], ["Kiela", "Douwe", ""]]}, {"id": "1807.03395", "submitter": "Ao Liu", "authors": "Ao Liu, Qiong Wu, Zhenming Liu and Lirong Xia", "title": "Towards Non-Parametric Learning to Rank", "comments": "10 pages' main document and 10 pages' supplementary documents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a stylized, yet natural, learning-to-rank problem and\npoints out the critical incorrectness of a widely used nearest neighbor\nalgorithm. We consider a model with $n$ agents (users) $\\{x_i\\}_{i \\in [n]}$\nand $m$ alternatives (items) $\\{y_j\\}_{j \\in [m]}$, each of which is associated\nwith a latent feature vector. Agents rank items nondeterministically according\nto the Plackett-Luce model, where the higher the utility of an item to the\nagent, the more likely this item will be ranked high by the agent. Our goal is\nto find neighbors of an arbitrary agent or alternative in the latent space.\n  We first show that the Kendall-tau distance based kNN produces incorrect\nresults in our model. Next, we fix the problem by introducing a new algorithm\nwith features constructed from \"global information\" of the data matrix. Our\napproach is in sharp contrast to most existing feature engineering methods.\nFinally, we design another new algorithm identifying similar alternatives. The\nconstruction of alternative features can be done using \"local information,\"\nhighlighting the algorithmic difference between finding similar agents and\nsimilar alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:27:14 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Liu", "Ao", ""], ["Wu", "Qiong", ""], ["Liu", "Zhenming", ""], ["Xia", "Lirong", ""]]}, {"id": "1807.03399", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Albert M. Lai, Eric Fosler-Lussier", "title": "Jointly Embedding Entities and Text with Distant Supervision", "comments": "12 pages; Accepted to 3rd Workshop on Representation Learning for NLP\n  (Repl4NLP 2018). Code at https://github.com/OSU-slatelab/JET", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations for knowledge base entities and concepts is becoming\nincreasingly important for NLP applications. However, recent entity embedding\nmethods have relied on structured resources that are expensive to create for\nnew domains and corpora. We present a distantly-supervised method for jointly\nlearning embeddings of entities and text from an unnanotated corpus, using only\na list of mappings between entities and surface forms. We learn embeddings from\nopen-domain and biomedical corpora, and compare against prior methods that rely\non human-annotated text or large knowledge graph structure. Our embeddings\ncapture entity similarity and relatedness better than prior work, both in\nexisting biomedical datasets and a new Wikipedia-based dataset that we release\nto the community. Results on analogy completion and entity sense disambiguation\nindicate that entities and words capture complementary information that can be\neffectively combined for downstream use.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 21:40:53 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Lai", "Albert M.", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1807.03418", "submitter": "S\\\"oren Becker", "authors": "S\\\"oren Becker, Marcel Ackermann, Sebastian Lapuschkin, Klaus-Robert\n  M\\\"uller, Wojciech Samek", "title": "Interpreting and Explaining Deep Neural Networks for Classification of\n  Audio Signals", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of deep neural networks is a recently emerging area of\nmachine learning research targeting a better understanding of how models\nperform feature selection and derive their classification decisions. This paper\nexplores the interpretability of neural networks in the audio domain by using\nthe previously proposed technique of layer-wise relevance propagation (LRP). We\npresent a novel audio dataset of English spoken digits which we use for\nclassification tasks on spoken digits and speaker's gender. We use LRP to\nidentify relevant features for two neural network architectures that process\neither waveform or spectrogram representations of the data. Based on the\nrelevance scores obtained from LRP, hypotheses about the neural networks'\nfeature selection are derived and subsequently tested through systematic\nmanipulations of the input data. The results confirm that the networks are\nhighly reliant on features marked as relevant by LRP.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 23:11:17 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 11:16:44 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Becker", "S\u00f6ren", ""], ["Ackermann", "Marcel", ""], ["Lapuschkin", "Sebastian", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1807.03480", "submitter": "De-An Huang", "authors": "De-An Huang, Suraj Nair, Danfei Xu, Yuke Zhu, Animesh Garg, Li\n  Fei-Fei, Silvio Savarese, Juan Carlos Niebles", "title": "Neural Task Graphs: Generalizing to Unseen Tasks from a Single Video\n  Demonstration", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to generate a policy to complete an unseen task given just a\nsingle video demonstration of the task in a given domain. We hypothesize that\nto successfully generalize to unseen complex tasks from a single video\ndemonstration, it is necessary to explicitly incorporate the compositional\nstructure of the tasks into the model. To this end, we propose Neural Task\nGraph (NTG) Networks, which use conjugate task graph as the intermediate\nrepresentation to modularize both the video demonstration and the derived\npolicy. We empirically show NTG achieves inter-task generalization on two\ncomplex tasks: Block Stacking in BulletPhysics and Object Collection in\nAI2-THOR. NTG improves data efficiency with visual input as well as achieve\nstrong generalization without the need for dense hierarchical supervision. We\nfurther show that similar performance trends hold when applied to real-world\ndata. We show that NTG can effectively predict task structure on the JIGSAWS\nsurgical dataset and generalize to unseen tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 04:55:45 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 21:56:52 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Huang", "De-An", ""], ["Nair", "Suraj", ""], ["Xu", "Danfei", ""], ["Zhu", "Yuke", ""], ["Garg", "Animesh", ""], ["Fei-Fei", "Li", ""], ["Savarese", "Silvio", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1807.03487", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "Fine Tuning Method by using Knowledge Acquisition from Deep Belief\n  Network", "comments": "6 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1807.03486", "journal-ref": "Proc. of IEEE 9th International Workshop on Computational\n  Intelligence and Applications (IWCIA2016)", "doi": "10.1109/IWCIA.2016.7805759", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an adaptive structure learning method of Restricted Boltzmann\nMachine (RBM) which can generate/annihilate neurons by self-organizing learning\nmethod according to input patterns. Moreover, the adaptive Deep Belief Network\n(DBN) in the assemble process of pre-trained RBM layer was developed. The\nproposed method presents to score a great success to the training data set for\nbig data benchmark test such as CIFAR-10. However, the classification\ncapability of the test data set, which are included unknown patterns, is high,\nbut does not lead perfect correct solution. We investigated the wrong specified\ndata and then some characteristic patterns were found. In this paper, the\nknowledge related to the patterns is embedded into the classification algorithm\nof trained DBN. As a result, the classification capability can achieve a great\nsuccess (97.1\\% to unknown data set).\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:07:13 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:54:26 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1807.03490", "submitter": "Yu Shi", "authors": "Yu Shi and Qi Zhu and Fang Guo and Chao Zhang and Jiawei Han", "title": "Easing Embedding Learning by Comprehensive Transcription of\n  Heterogeneous Information Networks", "comments": "10 pages. In Proceedings of the 24th ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining, London, United Kingdom,\n  ACM, 2018", "journal-ref": null, "doi": "10.1145/3219819.3220006", "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information networks (HINs) are ubiquitous in real-world\napplications. In the meantime, network embedding has emerged as a convenient\ntool to mine and learn from networked data. As a result, it is of interest to\ndevelop HIN embedding methods. However, the heterogeneity in HINs introduces\nnot only rich information but also potentially incompatible semantics, which\nposes special challenges to embedding learning in HINs. With the intention to\npreserve the rich yet potentially incompatible information in HIN embedding, we\npropose to study the problem of comprehensive transcription of heterogeneous\ninformation networks. The comprehensive transcription of HINs also provides an\neasy-to-use approach to unleash the power of HINs, since it requires no\nadditional supervision, expertise, or feature engineering. To cope with the\nchallenges in the comprehensive transcription of HINs, we propose the HEER\nalgorithm, which embeds HINs via edge representations that are further coupled\nwith properly-learned heterogeneous metrics. To corroborate the efficacy of\nHEER, we conducted experiments on two large-scale real-words datasets with an\nedge reconstruction task and multiple case studies. Experiment results\ndemonstrate the effectiveness of the proposed HEER model and the utility of\nedge representations and heterogeneous metrics. The code and data are available\nat https://github.com/GentleZhu/HEER.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:21:22 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Shi", "Yu", ""], ["Zhu", "Qi", ""], ["Guo", "Fang", ""], ["Zhang", "Chao", ""], ["Han", "Jiawei", ""]]}, {"id": "1807.03527", "submitter": "Joris Mooij", "authors": "Thijs van Ommen, Joris M. Mooij", "title": "Algebraic Equivalence of Linear Structural Equation Models", "comments": "Published in (online) Proceedings of the 33rd Annual Conference on\n  Uncertainty in Artificial Intelligence (UAI-17)", "journal-ref": "Proceedings of the 33rd Annual Conference on Uncertainty in\n  Artificial Intelligence, 2017", "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their popularity, many questions about the algebraic constraints\nimposed by linear structural equation models remain open problems. For causal\ndiscovery, two of these problems are especially important: the enumeration of\nthe constraints imposed by a model, and deciding whether two graphs define the\nsame statistical model. We show how the half-trek criterion can be used to make\nprogress in both of these problems. We apply our theoretical results to a\nsmall-scale model selection problem, and find that taking the additional\nalgebraic constraints into account may lead to significant improvements in\nmodel selection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:38:37 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["van Ommen", "Thijs", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1807.03571", "submitter": "Min Wu", "authors": "Min Wu, Matthew Wicker, Wenjie Ruan, Xiaowei Huang, Marta Kwiatkowska", "title": "A Game-Based Approximate Verification of Deep Neural Networks with\n  Provable Guarantees", "comments": null, "journal-ref": "Theoretical Computer Science 807 (2020) 298-329", "doi": "10.1016/j.tcs.2019.05.046", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the improved accuracy of deep neural networks, the discovery of\nadversarial examples has raised serious safety concerns. In this paper, we\nstudy two variants of pointwise robustness, the maximum safe radius problem,\nwhich for a given input sample computes the minimum distance to an adversarial\nexample, and the feature robustness problem, which aims to quantify the\nrobustness of individual features to adversarial perturbations. We demonstrate\nthat, under the assumption of Lipschitz continuity, both problems can be\napproximated using finite optimisation by discretising the input space, and the\napproximation has provable guarantees, i.e., the error is bounded. We then show\nthat the resulting optimisation problems can be reduced to the solution of\ntwo-player turn-based games, where the first player selects features and the\nsecond perturbs the image within the feature. While the second player aims to\nminimise the distance to an adversarial example, depending on the optimisation\nobjective the first player can be cooperative or competitive. We employ an\nanytime approach to solve the games, in the sense of approximating the value of\na game by monotonically improving its upper and lower bounds. The Monte Carlo\ntree search algorithm is applied to compute upper bounds for both games, and\nthe Admissible A* and the Alpha-Beta Pruning algorithms are, respectively, used\nto compute lower bounds for the maximum safety radius and feature robustness\ngames. When working on the upper bound of the maximum safe radius problem, our\ntool demonstrates competitive performance against existing adversarial example\ncrafting algorithms. Furthermore, we show how our framework can be deployed to\nevaluate pointwise robustness of neural networks in safety-critical\napplications such as traffic sign recognition in self-driving cars.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 11:28:46 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 22:21:11 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Min", ""], ["Wicker", "Matthew", ""], ["Ruan", "Wenjie", ""], ["Huang", "Xiaowei", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1807.03586", "submitter": "Yifan Gao", "authors": "Yifan Gao, Lidong Bing, Wang Chen, Michael R. Lyu, Irwin King", "title": "Difficulty Controllable Generation of Reading Comprehension Questions", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the difficulty levels of questions in reading comprehension\ndatasets such as SQuAD, and propose a new question generation setting, named\nDifficulty-controllable Question Generation (DQG). Taking as input a sentence\nin the reading comprehension paragraph and some of its text fragments (i.e.,\nanswers) that we want to ask questions about, a DQG method needs to generate\nquestions each of which has a given text fragment as its answer, and meanwhile\nthe generation is under the control of specified difficulty labels---the output\nquestions should satisfy the specified difficulty as much as possible. To solve\nthis task, we propose an end-to-end framework to generate questions of\ndesignated difficulty levels by exploring a few important intuitions. For\nevaluation, we prepared the first dataset of reading comprehension questions\nwith difficulty labels. The results show that the question generated by our\nframework not only have better quality under the metrics like BLEU, but also\ncomply with the specified difficulty labels.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 12:10:16 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 12:06:29 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 07:01:52 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2019 06:34:25 GMT"}, {"version": "v5", "created": "Thu, 30 May 2019 09:41:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gao", "Yifan", ""], ["Bing", "Lidong", ""], ["Chen", "Wang", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1807.03633", "submitter": "Tong Wang", "authors": "Tong Wang, Veerajalandhar Allareddy, Sankeerth Rampa and\n  Veerasathpurush Allareddy", "title": "Interpretable Patient Mortality Prediction with Multi-value Rule Sets", "comments": "arXiv admin note: text overlap with arXiv:1710.05257", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Multi-vAlue Rule Set (MRS) model for in-hospital predicting\npatient mortality. Compared to rule sets built from single-valued rules, MRS\nadopts a more generalized form of association rules that allows multiple values\nin a condition. Rules of this form are more concise than classical\nsingle-valued rules in capturing and describing patterns in data. Our\nformulation also pursues a higher efficiency of feature utilization, which\nreduces possible cost in data collection and storage. We propose a Bayesian\nframework for formulating a MRS model and propose an efficient inference method\nfor learning a maximum \\emph{a posteriori}, incorporating theoretically\ngrounded bounds to iteratively reduce the search space and improve the search\nefficiency. Experiments show that our model was able to achieve better\nperformance than baseline method including the current system used by the\nhospital.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 22:47:19 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 14:57:51 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Wang", "Tong", ""], ["Allareddy", "Veerajalandhar", ""], ["Rampa", "Sankeerth", ""], ["Allareddy", "Veerasathpurush", ""]]}, {"id": "1807.03653", "submitter": "Pablo Martinez Olmos", "authors": "Alfredo Nazabal, Pablo M. Olmos, Zoubin Ghahramani, Isabel Valera", "title": "Handling Incomplete Heterogeneous Data using VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs), as well as other generative models, have\nbeen shown to be efficient and accurate for capturing the latent structure of\nvast amounts of complex high-dimensional data. However, existing VAEs can still\nnot directly handle data that are heterogenous (mixed continuous and discrete)\nor incomplete (with missing data at random), which is indeed common in\nreal-world applications. In this paper, we propose a general framework to\ndesign VAEs suitable for fitting incomplete heterogenous data. The proposed\nHI-VAE includes likelihood models for real-valued, positive real valued,\ninterval, categorical, ordinal and count data, and allows accurate estimation\n(and potentially imputation) of missing data. Furthermore, HI-VAE presents\ncompetitive predictive performance in supervised tasks, outperforming\nsupervised models when trained on incomplete data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 14:00:23 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 12:06:18 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 14:58:48 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 13:56:07 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Nazabal", "Alfredo", ""], ["Olmos", "Pablo M.", ""], ["Ghahramani", "Zoubin", ""], ["Valera", "Isabel", ""]]}, {"id": "1807.03710", "submitter": "Timothy Wong", "authors": "Timothy Wong, Zhiyuan Luo", "title": "Recurrent Auto-Encoder Model for Large-Scale Industrial Sensor Signal\n  Analysis", "comments": "Accepted paper at the 19th International Conference on Engineering\n  Applications of Neural Networks (EANN 2018)", "journal-ref": "E. Pimenidis and C. Jayne (Eds.): EANN 2018, CCIS 893", "doi": "10.1007/978-3-319-98204-5_17", "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent auto-encoder model summarises sequential data through an encoder\nstructure into a fixed-length vector and then reconstructs the original\nsequence through the decoder structure. The summarised vector can be used to\nrepresent time series features. In this paper, we propose relaxing the\ndimensionality of the decoder output so that it performs partial\nreconstruction. The fixed-length vector therefore represents features in the\nselected dimensions only. In addition, we propose using rolling fixed window\napproach to generate training samples from unbounded time series data. The\nchange of time series features over time can be summarised as a smooth\ntrajectory path. The fixed-length vectors are further analysed using additional\nvisualisation and unsupervised clustering techniques. The proposed method can\nbe applied in large-scale industrial processes for sensors signal analysis\npurpose, where clusters of the vector representations can reflect the operating\nstates of the industrial system.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:26:33 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Wong", "Timothy", ""], ["Luo", "Zhiyuan", ""]]}, {"id": "1807.03760", "submitter": "Yen-Chia Hsu", "authors": "Yen-Chia Hsu", "title": "SimArch: A Multi-agent System For Human Path Simulation In Architecture\n  Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human moving path is an important feature in architecture design. By studying\nthe path, architects know where to arrange the basic elements (e.g. structures,\nglasses, furniture, etc.) in the space. This paper presents SimArch, a\nmulti-agent system for human moving path simulation. It involves a behavior\nmodel built by using a Markov Decision Process. The model simulates human\nmental states, target range detection, and collision prediction when agents are\non the floor, in a particular small gallery, looking at an exhibit, or leaving\nthe floor. It also models different kinds of human characteristics by assigning\ndifferent transition probabilities. A modified weighted A* search algorithm\nquickly plans the sub-optimal path of the agents. In an experiment, SimArch\ntakes a series of preprocessed floorplans as inputs, simulates the moving path,\nand outputs a density map for evaluation. The density map provides the\nprediction that how likely a person will occur in a location. A following\ndiscussion illustrates how architects can use the density map to improve their\nfloorplan design.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:04:49 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Hsu", "Yen-Chia", ""]]}, {"id": "1807.03765", "submitter": "Chi Jin", "authors": "Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, Michael I. Jordan", "title": "Is Q-learning Provably Efficient?", "comments": "Best paper in ICML 2018 workshop \"Exploration in RL\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) algorithms, such as Q-learning,\ndirectly parameterize and update value functions or policies without explicitly\nmodeling the environment. They are typically simpler, more flexible to use, and\nthus more prevalent in modern deep RL than model-based approaches. However,\nempirical work has suggested that model-free algorithms may require more\nsamples to learn [Deisenroth and Rasmussen 2011, Schulman et al. 2015]. The\ntheoretical question of \"whether model-free algorithms can be made sample\nefficient\" is one of the most fundamental questions in RL, and remains unsolved\neven in the basic scenario with finitely many states and actions.\n  We prove that, in an episodic MDP setting, Q-learning with UCB exploration\nachieves regret $\\tilde{O}(\\sqrt{H^3 SAT})$, where $S$ and $A$ are the numbers\nof states and actions, $H$ is the number of steps per episode, and $T$ is the\ntotal number of steps. This sample efficiency matches the optimal regret that\ncan be achieved by any model-based approach, up to a single $\\sqrt{H}$ factor.\nTo the best of our knowledge, this is the first analysis in the model-free\nsetting that establishes $\\sqrt{T}$ regret without requiring access to a\n\"simulator.\"\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:21:35 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Jin", "Chi", ""], ["Allen-Zhu", "Zeyuan", ""], ["Bubeck", "Sebastien", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1807.03769", "submitter": "Vassilis Kekatos", "authors": "Aditie Garg, Mana Jalali, Vassilis Kekatos, Nikolaos Gatsis", "title": "Kernel-Based Learning for Smart Inverter Control", "comments": "Submitted to the 2018 IEEE Global Signal and Information Processing\n  Conf., Symposium on Smart Energy Infrastructures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution grids are currently challenged by frequent voltage excursions\ninduced by intermittent solar generation. Smart inverters have been advocated\nas a fast-responding means to regulate voltage and minimize ohmic losses. Since\noptimal inverter coordination may be computationally challenging and preset\nlocal control rules are subpar, the approach of customized control rules\ndesigned in a quasi-static fashion features as a golden middle. Departing from\naffine control rules, this work puts forth non-linear inverter control\npolicies. Drawing analogies to multi-task learning, reactive control is posed\nas a kernel-based regression task. Leveraging a linearized grid model and given\nanticipated data scenarios, inverter rules are jointly designed at the feeder\nlevel to minimize a convex combination of voltage deviations and ohmic losses\nvia a linearly-constrained quadratic program. Numerical tests using real-world\ndata on a benchmark feeder demonstrate that nonlinear control rules driven also\nby a few non-local readings can attain near-optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 17:46:02 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Garg", "Aditie", ""], ["Jalali", "Mana", ""], ["Kekatos", "Vassilis", ""], ["Gatsis", "Nikolaos", ""]]}, {"id": "1807.03858", "submitter": "Yuping Luo", "authors": "Yuping Luo, Huazhe Xu, Yuanzhi Li, Yuandong Tian, Trevor Darrell,\n  Tengyu Ma", "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with\n  Theoretical Guarantees", "comments": "Added important notes that the conditions of Theorem 3.1 cannot\n  simultaneously hold for most models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) is considered to be a promising\napproach to reduce the sample complexity that hinders model-free RL. However,\nthe theoretical understanding of such methods has been rather limited. This\npaper introduces a novel algorithmic framework for designing and analyzing\nmodel-based RL algorithms with theoretical guarantees. We design a\nmeta-algorithm with a theoretical guarantee of monotone improvement to a local\nmaximum of the expected reward. The meta-algorithm iteratively builds a lower\nbound of the expected reward based on the estimated dynamical model and sample\ntrajectories, and then maximizes the lower bound jointly over the policy and\nthe model. The framework extends the optimism-in-face-of-uncertainty principle\nto non-linear dynamical models in a way that requires \\textit{no explicit}\nuncertainty quantification. Instantiating our framework with simplification\ngives a variant of model-based RL algorithms Stochastic Lower Bounds\nOptimization (SLBO). Experiments demonstrate that SLBO achieves\nstate-of-the-art performance when only one million or fewer samples are\npermitted on a range of continuous control benchmark tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 20:53:04 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 18:00:46 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 21:09:58 GMT"}, {"version": "v4", "created": "Mon, 21 Jan 2019 20:04:56 GMT"}, {"version": "v5", "created": "Mon, 15 Feb 2021 17:29:47 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Luo", "Yuping", ""], ["Xu", "Huazhe", ""], ["Li", "Yuanzhi", ""], ["Tian", "Yuandong", ""], ["Darrell", "Trevor", ""], ["Ma", "Tengyu", ""]]}, {"id": "1807.03909", "submitter": "Md Kamruzzaman Sarker", "authors": "Md. Kamruzzaman Sarker, Kazi Md. Rokibul Alam, Md. Arifuzzaman", "title": "Emotion Recognition from Speech based on Relevant Feature and Majority\n  Voting", "comments": null, "journal-ref": "International Conference on Informatics, Electronics & Vision\n  (ICIEV) (2014) 1-5", "doi": "10.1109/ICIEV.2014.6850685", "report-no": null, "categories": "cs.SD cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to detect emotion from human speech employing\nmajority voting technique over several machine learning techniques. The\ncontribution of this work is in two folds: firstly it selects those features of\nspeech which is most promising for classification and secondly it uses the\nmajority voting technique that selects the exact class of emotion. Here,\nmajority voting technique has been applied over Neural Network (NN), Decision\nTree (DT), Support Vector Machine (SVM) and K-Nearest Neighbor (KNN). Input\nvector of NN, DT, SVM and KNN consists of various acoustic and prosodic\nfeatures like Pitch, Mel-Frequency Cepstral coefficients etc. From speech\nsignal many feature have been extracted and only promising features have been\nselected. To consider a feature as promising, Fast Correlation based feature\nselection (FCBF) and Fisher score algorithms have been used and only those\nfeatures are selected which are highly ranked by both of them. The proposed\napproach has been tested on Berlin dataset of emotional speech [3] and\nElectromagnetic Articulography (EMA) dataset [4]. The experimental result shows\nthat majority voting technique attains better accuracy over individual machine\nlearning techniques. The employment of the proposed approach can effectively\nrecognize the emotion of human beings in case of social robot, intelligent chat\nclient, call-center of a company etc.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 00:25:13 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Sarker", "Md. Kamruzzaman", ""], ["Alam", "Kazi Md. Rokibul", ""], ["Arifuzzaman", "Md.", ""]]}, {"id": "1807.03952", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "Shortening Time Required for Adaptive Structural Learning Method of Deep\n  Belief Network with Multi-Modal Data Arrangement", "comments": "6 pages, 5 figures, Proc. of IEEE 10th International Workshop on\n  Computational Intelligence and Applications (IWCIA2017)", "journal-ref": null, "doi": "10.1109/IWCIA.2017.8203568", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Learning has been applied in the techniques of artificial\nintelligence. Especially, Deep Learning performed good results in the field of\nimage recognition. Most new Deep Learning architectures are naturally developed\nin image recognition. For this reason, not only the numerical data and text\ndata but also the time-series data are transformed to the image data format.\nMulti-modal data consists of two or more kinds of data such as picture and\ntext. The arrangement in a general method is formed in the squared array with\nno specific aim. In this paper, the data arrangement are modified according to\nthe similarity of input-output pattern in Adaptive Structural Learning method\nof Deep Belief Network. The similarity of output signals of hidden neurons is\nmade by the order rearrangement of hidden neurons. The experimental results for\nthe data rearrangement in squared array showed the shortening time required for\nDBN learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:30:20 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1807.03954", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "Knowledge Extracted from Recurrent Deep Belief Network for Real Time\n  Deterministic Control", "comments": "6 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1807.03953", "journal-ref": "Proc. of 2017 IEEE International Conference on Systems, Man, and\n  Cybernetics (IEEE SMC2017)", "doi": "10.1109/SMC.2017.8122711", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the market on deep learning including not only software but also\nhardware is developing rapidly. Big data is collected through IoT devices and\nthe industry world will analyze them to improve their manufacturing process.\nDeep Learning has the hierarchical network architecture to represent the\ncomplicated features of input patterns. Although deep learning can show the\nhigh capability of classification, prediction, and so on, the implementation on\nGPU devices are required. We may meet the trade-off between the higher\nprecision by deep learning and the higher cost with GPU devices. We can success\nthe knowledge extraction from the trained deep learning with high\nclassification capability. The knowledge that can realize faster inference of\npre-trained deep network is extracted as IF-THEN rules from the network signal\nflow given input data. Some experiment results with benchmark tests for time\nseries data sets showed the effectiveness of our proposed method related to the\ncomputational speed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 05:37:02 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1807.03975", "submitter": "Pierre Schaus", "authors": "Aur\\'elie Massart, Valentin Rombouts, Pierre Schaus", "title": "Testing Global Constraints", "comments": "CP2018 Doctoral Program http://cp2018.a4cp.org/doctoral.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every Constraint Programming (CP) solver exposes a library of constraints for\nsolving combinatorial problems. In order to be useful, CP solvers need to be\nbug-free. Therefore the testing of the solver is crucial to make developers and\nusers confident. We present a Java library allowing any JVM based solver to\ntest that the implementations of the individual constraints are correct. The\nlibrary can be used in a test suite executed in a continuous integration tool\nor it can also be used to discover minimalist instances violating some\nproperties (arc-consistency, etc) in order to help the developer to identify\nthe origin of the problem using standard debuggers.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 07:45:46 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Massart", "Aur\u00e9lie", ""], ["Rombouts", "Valentin", ""], ["Schaus", "Pierre", ""]]}, {"id": "1807.04001", "submitter": "Ismail Elezi", "authors": "Benjamin Bruno Meier, Ismail Elezi, Mohammadreza Amirian, Oliver Durr\n  and Thilo Stadelmann", "title": "Learning Neural Models for End-to-End Clustering", "comments": "Accepted for publication on ANNPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel end-to-end neural network architecture that, once trained,\ndirectly outputs a probabilistic clustering of a batch of input examples in one\npass. It estimates a distribution over the number of clusters $k$, and for each\n$1 \\leq k \\leq k_\\mathrm{max}$, a distribution over the individual cluster\nassignment for each data point. The network is trained in advance in a\nsupervised fashion on separate data to learn grouping by any perceptual\nsimilarity criterion based on pairwise labels (same/different group). It can\nthen be applied to different data containing different groups. We demonstrate\npromising performance on high-dimensional data like images (COIL-100) and\nspeech (TIMIT). We call this ``learning to cluster'' and show its conceptual\ndifference to deep metric learning, semi-supervise clustering and other related\napproaches while having the advantage of performing learnable clustering fully\nend-to-end.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 08:45:45 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Meier", "Benjamin Bruno", ""], ["Elezi", "Ismail", ""], ["Amirian", "Mohammadreza", ""], ["Durr", "Oliver", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1807.04170", "submitter": "Stephane Perrin", "authors": "St\\'ephane Perrin (LISTIC), Eric Benoit (LISTIC), Didier Coquin\n  (LISTIC)", "title": "Decision method choice in a human posture recognition context", "comments": null, "journal-ref": "Human-Computer Systems Interaction. Backgrounds and Applications\n  4, 4, 2018", "doi": "10.1007/978-3-319-62120-3_11", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human posture recognition provides a dynamic field that has produced many\nmethods. Using fuzzy subsets based data fusion methods to aggregate the results\ngiven by different types of recognition processes is a convenient way to\nimprove recognition methods. Nevertheless, choosing a defuzzification method to\nimple-ment the decision is a crucial point of this approach. The goal of this\npaper is to present an approach where the choice of the defuzzification method\nis driven by the constraints of the final data user, which are expressed as\nlimitations on indica-tors like confidence or accuracy. A practical\nexperimentation illustrating this ap-proach is presented: from a depth camera\nsensor, human posture is interpreted and the defuzzification method is selected\nin accordance with the constraints of the final information consumer. The paper\nillustrates the interest of the approach in a context of postures based human\nrobot communication.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:45:07 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Perrin", "St\u00e9phane", "", "LISTIC"], ["Benoit", "Eric", "", "LISTIC"], ["Coquin", "Didier", "", "LISTIC"]]}, {"id": "1807.04178", "submitter": "Luca Vigan\\`o", "authors": "Luca Vigan\\`o and Daniele Magazzeni", "title": "Explainable Security", "comments": "1 figure, IJCAI/ECAI 2018 Workshop on Explainable Artificial\n  Intelligence (XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Defense Advanced Research Projects Agency (DARPA) recently launched the\nExplainable Artificial Intelligence (XAI) program that aims to create a suite\nof new AI techniques that enable end users to understand, appropriately trust,\nand effectively manage the emerging generation of AI systems.\n  In this paper, inspired by DARPA's XAI program, we propose a new paradigm in\nsecurity research: Explainable Security (XSec). We discuss the ``Six Ws'' of\nXSec (Who? What? Where? When? Why? and How?) and argue that XSec has unique and\ncomplex characteristics: XSec involves several different stakeholders (i.e.,\nthe system's developers, analysts, users and attackers) and is multi-faceted by\nnature (as it requires reasoning about system model, threat model and\nproperties of security, privacy and trust as well as about concrete attacks,\nvulnerabilities and countermeasures). We define a roadmap for XSec that\nidentifies several possible research directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 14:54:39 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Vigan\u00f2", "Luca", ""], ["Magazzeni", "Daniele", ""]]}, {"id": "1807.04320", "submitter": "Louis Kim", "authors": "Rebecca L. Russell, Louis Kim, Lei H. Hamilton, Tomo Lazovich, Jacob\n  A. Harer, Onur Ozdemir, Paul M. Ellingwood, Marc W. McConley", "title": "Automated Vulnerability Detection in Source Code Using Deep\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing numbers of software vulnerabilities are discovered every year\nwhether they are reported publicly or discovered internally in proprietary\ncode. These vulnerabilities can pose serious risk of exploit and result in\nsystem compromise, information leaks, or denial of service. We leveraged the\nwealth of C and C++ open-source code available to develop a large-scale\nfunction-level vulnerability detection system using machine learning. To\nsupplement existing labeled vulnerability datasets, we compiled a vast dataset\nof millions of open-source functions and labeled it with carefully-selected\nfindings from three different static analyzers that indicate potential\nexploits. The labeled dataset is available at: https://osf.io/d45bw/. Using\nthese datasets, we developed a fast and scalable vulnerability detection tool\nbased on deep feature representation learning that directly interprets lexed\nsource code. We evaluated our tool on code from both real software packages and\nthe NIST SATE IV benchmark dataset. Our results demonstrate that deep feature\nrepresentation learning on source code is a promising approach for automated\nsoftware vulnerability detection.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 19:29:14 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 00:27:12 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Russell", "Rebecca L.", ""], ["Kim", "Louis", ""], ["Hamilton", "Lei H.", ""], ["Lazovich", "Tomo", ""], ["Harer", "Jacob A.", ""], ["Ozdemir", "Onur", ""], ["Ellingwood", "Paul M.", ""], ["McConley", "Marc W.", ""]]}, {"id": "1807.04375", "submitter": "Michael Green", "authors": "Michael Cerny Green, Ahmed Khalifa, Gabriella A.B. Barros, Tiago\n  Machado, Andy Nealen and Julian Togelius", "title": "AtDelfi: Automatically Designing Legible, Full Instructions For Games", "comments": "10 pages, 11 figures, published at Foundations of Digital Games\n  Conference 2018", "journal-ref": "Foundations of Digital Games (FDG) 2018", "doi": "10.1145/3235765.3235790", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a fully automatic method for generating video game\ntutorials. The AtDELFI system (AuTomatically DEsigning Legible, Full\nInstructions for games) was created to investigate procedural generation of\ninstructions that teach players how to play video games. We present a\nrepresentation of game rules and mechanics using a graph system as well as a\ntutorial generation method that uses said graph representation. We demonstrate\nthe concept by testing it on games within the General Video Game Artificial\nIntelligence (GVG-AI) framework; the paper discusses tutorials generated for\neight different games. Our findings suggest that a graph representation scheme\nworks well for simple arcade style games such as Space Invaders and Pacman, but\nit appears that tutorials for more complex games might require higher-level\nunderstanding of the game than just single mechanics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 23:02:43 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 21:54:25 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Barros", "Gabriella A. B.", ""], ["Machado", "Tiago", ""], ["Nealen", "Andy", ""], ["Togelius", "Julian", ""]]}, {"id": "1807.04457", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Thong Le, Pin-Yu Chen, Jinfeng Yi, Huan Zhang, Cho-Jui\n  Hsieh", "title": "Query-Efficient Hard-label Black-box Attack:An Optimization-based\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of attacking a machine learning model in the hard-label\nblack-box setting, where no model information is revealed except that the\nattacker can make queries to probe the corresponding hard-label decisions. This\nis a very challenging problem since the direct extension of state-of-the-art\nwhite-box attacks (e.g., CW or PGD) to the hard-label black-box setting will\nrequire minimizing a non-continuous step function, which is combinatorial and\ncannot be solved by a gradient-based optimizer. The only current approach is\nbased on random walk on the boundary, which requires lots of queries and lacks\nconvergence guarantees. We propose a novel way to formulate the hard-label\nblack-box attack as a real-valued optimization problem which is usually\ncontinuous and can be solved by any zeroth order optimization algorithm. For\nexample, using the Randomized Gradient-Free method, we are able to bound the\nnumber of iterations needed for our algorithm to achieve stationary points. We\ndemonstrate that our proposed method outperforms the previous random walk\napproach to attacking convolutional neural networks on MNIST, CIFAR, and\nImageNet datasets. More interestingly, we show that the proposed algorithm can\nalso be used to attack other discrete and non-continuous machine learning\nmodels, such as Gradient Boosting Decision Trees (GBDT).\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:04:27 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Cheng", "Minhao", ""], ["Le", "Thong", ""], ["Chen", "Pin-Yu", ""], ["Yi", "Jinfeng", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1807.04458", "submitter": "Mikael Zayenz Lagerkvist", "authors": "Magnus Gedda, Mikael Z. Lagerkvist, Martin Butler", "title": "Monte Carlo Methods for the Game Kingdomino", "comments": "To be published in IEEE Conference on Computational Intelligence and\n  Games 2018 (IEEE CIG 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kingdomino is introduced as an interesting game for studying game playing:\nthe game is multiplayer (4 independent players per game); it has a limited game\ndepth (13 moves per player); and it has limited but not insignificant\ninteraction among players.\n  Several strategies based on locally greedy players, Monte Carlo Evaluation\n(MCE), and Monte Carlo Tree Search (MCTS) are presented with variants. We\nexamine a variation of UCT called progressive win bias and a playout policy\n(Player-greedy) focused on selecting good moves for the player. A thorough\nevaluation is done showing how the strategies perform and how to choose\nparameters given specific time constraints. The evaluation shows that\nsurprisingly MCE is stronger than MCTS for a game like Kingdomino.\n  All experiments use a cloud-native design, with a game server in a Docker\ncontainer, and agents communicating using a REST-style JSON protocol. This\nenables a multi-language approach to separating the game state, the strategy\nimplementations, and the coordination layer.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:07:21 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 05:23:13 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Gedda", "Magnus", ""], ["Lagerkvist", "Mikael Z.", ""], ["Butler", "Martin", ""]]}, {"id": "1807.04551", "submitter": "Marco Saerens Marco", "authors": "Bertrand Lebichot, Guillaume Guex, Ilkka Kivim\\\"aki and Marco Saerens", "title": "A Constrained Randomized Shortest-Paths Framework for Optimal\n  Exploration", "comments": "Draft manuscript submitted for publication and subject to changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work extends the randomized shortest-paths framework (RSP),\ninterpolating between shortest-path and random-walk routing in a network, in\nthree directions. First, it shows how to deal with equality constraints on a\nsubset of transition probabilities and develops a generic algorithm for solving\nthis constrained RSP problem using Lagrangian duality. Second, it derives a\nsurprisingly simple iterative procedure to compute the optimal, randomized,\nrouting policy generalizing the previously developed \"soft\" Bellman-Ford\nalgorithm. The resulting algorithm allows balancing exploitation and\nexploration in an optimal way by interpolating between a pure random behavior\nand the deterministic, optimal, policy (least-cost paths) while satisfying the\nconstraints. Finally, the two algorithms are applied to Markov decision\nproblems by considering the process as a constrained RSP on a bipartite\nstate-action graph. In this context, the derived \"soft\" value iteration\nalgorithm appears to be closely related to dynamic policy programming as well\nas Kullback-Leibler and path integral control, and similar to a recently\nintroduced reinforcement learning exploration strategy. This shows that this\nstrategy is optimal in the RSP sense - it minimizes expected path cost subject\nto relative entropy constraint. Simulation results on illustrative examples\nshow that the model behaves as expected.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 11:42:04 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Lebichot", "Bertrand", ""], ["Guex", "Guillaume", ""], ["Kivim\u00e4ki", "Ilkka", ""], ["Saerens", "Marco", ""]]}, {"id": "1807.04561", "submitter": "Fabio Patrizi", "authors": "Giuseppe De Giacomo, Brian Logan, Paolo Felli, Fabio Patrizi,\n  Sebastian Sardina", "title": "Situation Calculus for Synthesis of Manufacturing Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturing is transitioning from a mass production model to a\nmanufacturing as a service model in which manufacturing facilities 'bid' to\nproduce products. To decide whether to bid for a complex, previously unseen\nproduct, a manufacturing facility must be able to synthesize, 'on the fly', a\nprocess plan controller that delegates abstract manufacturing tasks in the\nsupplied process recipe to the appropriate manufacturing resources, e.g., CNC\nmachines, robots etc. Previous work in applying AI behaviour composition to\nsynthesize process plan controllers has considered only finite state ad-hoc\nrepresentations. Here, we study the problem in the relational setting of the\nSituation Calculus. By taking advantage of recent work on abstraction in the\nSituation Calculus, process recipes and available resources are represented by\nConGolog programs over, respectively, an abstract and a concrete action theory.\nThis allows us to capture the problem in a formal, general framework, and show\ndecidability for the case of bounded action theories. We also provide\ntechniques for actually synthesizing the controller.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 12:05:41 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["De Giacomo", "Giuseppe", ""], ["Logan", "Brian", ""], ["Felli", "Paolo", ""], ["Patrizi", "Fabio", ""], ["Sardina", "Sebastian", ""]]}, {"id": "1807.04587", "submitter": "Sergey Bartunov", "authors": "Sergey Bartunov, Adam Santoro, Blake A. Richards, Luke Marris,\n  Geoffrey E. Hinton, Timothy Lillicrap", "title": "Assessing the Scalability of Biologically-Motivated Deep Learning\n  Algorithms and Architectures", "comments": "NIPS 2018. Version 2 contains more experimental data including best\n  hyperparameters found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation of error algorithm (BP) is impossible to implement in a\nreal brain. The recent success of deep networks in machine learning and AI,\nhowever, has inspired proposals for understanding how the brain might learn\nacross multiple layers, and hence how it might approximate BP. As of yet, none\nof these proposals have been rigorously evaluated on tasks where BP-guided deep\nlearning has proved critical, or in architectures more structured than simple\nfully-connected networks. Here we present results on scaling up biologically\nmotivated models of deep learning on datasets which need deep networks with\nappropriate architectures to achieve good performance. We present results on\nthe MNIST, CIFAR-10, and ImageNet datasets and explore variants of\ntarget-propagation (TP) and feedback alignment (FA) algorithms, and explore\nperformance in both fully- and locally-connected architectures. We also\nintroduce weight-transport-free variants of difference target propagation (DTP)\nmodified to remove backpropagation from the penultimate layer. Many of these\nalgorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP\nand FA variants perform significantly worse than BP, especially for networks\ncomposed of locally connected units, opening questions about whether new\narchitectures and algorithms are required to scale these approaches. Our\nresults and implementation details help establish baselines for biologically\nmotivated deep learning schemes going forward.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 12:53:50 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 14:26:44 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Bartunov", "Sergey", ""], ["Santoro", "Adam", ""], ["Richards", "Blake A.", ""], ["Marris", "Luke", ""], ["Hinton", "Geoffrey E.", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1807.04640", "submitter": "Michael Chang", "authors": "Michael B. Chang, Abhishek Gupta, Sergey Levine, Thomas L. Griffiths", "title": "Automatically Composing Representation Transformations as a Means for\n  Generalization", "comments": "Accepted to the International Conference on Learning Representations\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generally intelligent learner should generalize to more complex tasks than\nit has previously encountered, but the two common paradigms in machine learning\n-- either training a separate learner per task or training a single learner for\nall tasks -- both have difficulty with such generalization because they do not\nleverage the compositional structure of the task distribution. This paper\nintroduces the compositional problem graph as a broadly applicable formalism to\nrelate tasks of different complexity in terms of problems with shared\nsubproblems. We propose the compositional generalization problem for measuring\nhow readily old knowledge can be reused and hence built upon. As a first step\nfor tackling compositional generalization, we introduce the compositional\nrecursive learner, a domain-general framework for learning algorithmic\nprocedures for composing representation transformations, producing a learner\nthat reasons about what computation to execute by making analogies to\npreviously seen problems. We show on a symbolic and a high-dimensional domain\nthat our compositional approach can generalize to more complex problems than\nthe learner has previously encountered, whereas baselines that are not\nexplicitly compositional do not.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 14:33:49 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 06:41:28 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Chang", "Michael B.", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1807.04723", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Chinnadhurai Sankar, Michael Pieper, Joelle\n  Pineau, Yoshua Bengio", "title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning\n  Approach", "comments": "26 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 16:59:28 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sankar", "Chinnadhurai", ""], ["Pieper", "Michael", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1807.04837", "submitter": "Nicola Gigante", "authors": "Nicola Gigante, Angelo Montanari, Marta Cialdea Mayer, Andrea\n  Orlandini, Mark Reynolds", "title": "A game-theoretic approach to timeline-based planning with uncertainty", "comments": "Published in Proceedings of TIME 2018\n  (https://time2018.ipipan.waw.pl)", "journal-ref": null, "doi": "10.4230/LIPIcs.TIME.2018.13", "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In timeline-based planning, domains are described as sets of independent, but\ninteracting, components, whose behaviour over time (the set of timelines) is\ngoverned by a set of temporal constraints. A distinguishing feature of\ntimeline-based planning systems is the ability to integrate planning with\nexecution by synthesising control strategies for flexible plans. However,\nflexible plans can only represent temporal uncertainty, while more complex\nforms of nondeterminism are needed to deal with a wider range of realistic\nproblems. In this paper, we propose a novel game-theoretic approach to\ntimeline-based planning problems, generalising the state of the art while\nuniformly handling temporal uncertainty and nondeterminism. We define a general\nconcept of timeline-based game and we show that the notion of winning strategy\nfor these games is strictly more general than that of control strategy for\ndynamically controllable flexible plans. Moreover, we show that the problem of\nestablishing the existence of such winning strategies is decidable using a\ndoubly exponential amount of space.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 21:38:06 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 14:04:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Gigante", "Nicola", ""], ["Montanari", "Angelo", ""], ["Mayer", "Marta Cialdea", ""], ["Orlandini", "Andrea", ""], ["Reynolds", "Mark", ""]]}, {"id": "1807.04861", "submitter": "Vitaliy Batusov", "authors": "Vitaliy Batusov, Giuseppe De Giacomo, Mikhail Soutchanski", "title": "Hybrid Temporal Situation Calculus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to model continuous change in Reiter's temporal situation\ncalculus action theories has attracted a lot of interest. In this paper, we\npropose a new development of his approach, which is directly inspired by hybrid\nsystems in control theory. Specifically, while keeping the foundations of\nReiter's axiomatization, we propose an elegant extension of his approach by\nadding a time argument to all fluents that represent continuous change.\nThereby, we insure that change can happen not only because of actions, but also\ndue to the passage of time. We present a systematic methodology to derive, from\nsimple premises, a new group of axioms which specify how continuous fluents\nchange over time within a situation. We study regression for our new temporal\nbasic action theories and demonstrate what reasoning problems can be solved.\nFinally, we formally show that our temporal basic action theories indeed\ncapture hybrid automata.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:20:11 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Batusov", "Vitaliy", ""], ["De Giacomo", "Giuseppe", ""], ["Soutchanski", "Mikhail", ""]]}, {"id": "1807.04905", "submitter": "Eunsol Choi", "authors": "Eunsol Choi, Omer Levy, Yejin Choi, Luke Zettlemoyer", "title": "Ultra-Fine Entity Typing", "comments": "ACL 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new entity typing task: given a sentence with an entity\nmention, the goal is to predict a set of free-form phrases (e.g. skyscraper,\nsongwriter, or criminal) that describe appropriate types for the target entity.\nThis formulation allows us to use a new type of distant supervision at large\nscale: head words, which indicate the type of the noun phrases they appear in.\nWe show that these ultra-fine types can be crowd-sourced, and introduce new\nevaluation sets that are much more diverse and fine-grained than existing\nbenchmarks. We present a model that can predict open types, and is trained\nusing a multitask objective that pools our new head-word supervision with prior\nsupervision from entity linking. Experimental results demonstrate that our\nmodel is effective in predicting entity types at varying granularity; it\nachieves state of the art performance on an existing fine-grained entity typing\nbenchmark, and sets baselines for our newly-introduced datasets. Our data and\nmodel can be downloaded from: http://nlp.cs.washington.edu/entity_type\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 04:19:03 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Choi", "Eunsol", ""], ["Levy", "Omer", ""], ["Choi", "Yejin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1807.04920", "submitter": "Stefan Kiefer", "authors": "Nikhil Balaji, Stefan Kiefer, Petr Novotn\\'y, Guillermo A. P\\'erez,\n  and Mahsa Shirmohammadi", "title": "On the Complexity of Value Iteration", "comments": "Full version of an ICALP'19 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a fundamental algorithm for solving Markov Decision\nProcesses (MDPs). It computes the maximal $n$-step payoff by iterating $n$\ntimes a recurrence equation which is naturally associated to the MDP. At the\nsame time, value iteration provides a policy for the MDP that is optimal on a\ngiven finite horizon $n$. In this paper, we settle the computational complexity\nof value iteration. We show that, given a horizon $n$ in binary and an MDP,\ncomputing an optimal policy is EXP-complete, thus resolving an open problem\nthat goes back to the seminal 1987 paper on the complexity of MDPs by\nPapadimitriou and Tsitsiklis. As a stepping stone, we show that it is\nEXP-complete to compute the $n$-fold iteration (with $n$ in binary) of a\nfunction given by a straight-line program over the integers with $\\max$ and $+$\nas operators.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 05:28:11 GMT"}, {"version": "v2", "created": "Sat, 17 Nov 2018 13:32:27 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 11:03:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Balaji", "Nikhil", ""], ["Kiefer", "Stefan", ""], ["Novotn\u00fd", "Petr", ""], ["P\u00e9rez", "Guillermo A.", ""], ["Shirmohammadi", "Mahsa", ""]]}, {"id": "1807.04950", "submitter": "Ismail Elezi", "authors": "Thilo Stadelmann, Mohammadreza Amirian and Ismail Arabaci, Marek\n  Arnold, Gilbert Fran\\c{c}ois Duivesteijn, Ismail Elezi, Melanie Geiger and\n  Stefan L\\\"orwald and Benjamin Bruno Meier, Katharina Rombach and Lukas\n  Tuggener", "title": "Deep Learning in the Wild", "comments": "Invited paper on ANNPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with neural networks is applied by an increasing number of\npeople outside of classic research environments, due to the vast success of the\nmethodology on a wide range of machine perception tasks. While this interest is\nfueled by beautiful success stories, practical work in deep learning on novel\ntasks without existing baselines remains challenging. This paper explores the\nspecific challenges arising in the realm of real world tasks, based on case\nstudies from research \\& development in conjunction with industry, and extracts\nlessons learned from them. It thus fills a gap between the publication of\nlatest algorithmic and methodical developments, and the usually omitted\nnitty-gritty of how to make them work. Specifically, we give insight into deep\nlearning projects on face matching, print media monitoring, industrial quality\ncontrol, music scanning, strategy game playing, and automated machine learning,\nthereby providing best practices for deep learning in practice.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 07:22:45 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Stadelmann", "Thilo", ""], ["Amirian", "Mohammadreza", ""], ["Arabaci", "Ismail", ""], ["Arnold", "Marek", ""], ["Duivesteijn", "Gilbert Fran\u00e7ois", ""], ["Elezi", "Ismail", ""], ["Geiger", "Melanie", ""], ["L\u00f6rwald", "Stefan", ""], ["Meier", "Benjamin Bruno", ""], ["Rombach", "Katharina", ""], ["Tuggener", "Lukas", ""]]}, {"id": "1807.05037", "submitter": "Chris Cundy", "authors": "Chris Cundy, Daniel Filan", "title": "Exploring Hierarchy-Aware Inverse Reinforcement Learning", "comments": "Presented at the first Workshop on Goal Specifications for\n  Reinforcement Learning, ICML 2018, Stockholm, Sweden", "journal-ref": "1st Workshop on Goal Specifications for Reinforcement Learning,\n  ICML 2018, Stockholm, Sweden, 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new generative model for human planning under the Bayesian\nInverse Reinforcement Learning (BIRL) framework which takes into account the\nfact that humans often plan using hierarchical strategies. We describe the\nBayesian Inverse Hierarchical RL (BIHRL) algorithm for inferring the values of\nhierarchical planners, and use an illustrative toy model to show that BIHRL\nretains accuracy where standard BIRL fails. Furthermore, BIHRL is able to\naccurately predict the goals of `Wikispeedia' game players, with inclusion of\nhierarchical structure in the model resulting in a large boost in accuracy. We\nshow that BIHRL is able to significantly outperform BIRL even when we only have\na weak prior on the hierarchical structure of the plans available to the agent,\nand discuss the significant challenges that remain for scaling up this\nframework to more realistic settings.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 12:33:07 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Cundy", "Chris", ""], ["Filan", "Daniel", ""]]}, {"id": "1807.05054", "submitter": "Jeffrey Cheng", "authors": "Jeffrey Cheng", "title": "AI Reasoning Systems: PAC and Applied Methods", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and logic are distinct and remarkable approaches to prediction.\nMachine learning has experienced a surge in popularity because it is robust to\nnoise and achieves high performance; however, ML experiences many issues with\nknowledge transfer and extrapolation. In contrast, logic is easily intepreted,\nand logical rules are easy to chain and transfer between systems; however,\ninductive logic is brittle to noise. We then explore the premise of combining\nlearning with inductive logic into AI Reasoning Systems. Specifically, we\nsummarize findings from PAC learning (conceptual graphs, robust logics,\nknowledge infusion) and deep learning (DSRL, $\\partial$ILP, DeepLogic) by\nreproducing proofs of tractability, presenting algorithms in pseudocode,\nhighlighting results, and synthesizing between fields. We conclude with\nsuggestions for integrated models by combining the modules listed above and\nwith a list of unsolved (likely intractable) problems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 20:23:38 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Cheng", "Jeffrey", ""]]}, {"id": "1807.05076", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai and Adam Trischler", "title": "Metalearning with Hebbian Fast Weights", "comments": "8 pages, 3 figures, 4 tables. arXiv admin note: text overlap with\n  arXiv:1712.09926", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We unify recent neural approaches to one-shot learning with older ideas of\nassociative memory in a model for metalearning. Our model learns jointly to\nrepresent data and to bind class labels to representations in a single shot. It\nbuilds representations via slow weights, learned across tasks through SGD,\nwhile fast weights constructed by a Hebbian learning rule implement one-shot\nbinding for each new task. On the Omniglot, Mini-ImageNet, and Penn Treebank\none-shot learning benchmarks, our model achieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 14:40:06 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Trischler", "Adam", ""]]}, {"id": "1807.05154", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao", "title": "Deep Enhanced Representation for Implicit Discourse Relation Recognition", "comments": "13(10) pages, accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task as the relation\nprediction without explicit connectives in discourse parsing needs\nunderstanding of text spans and cannot be easily derived from surface features\nfrom the input sentence pairs. Thus, properly representing the text is very\ncrucial to this task. In this paper, we propose a model augmented with\ndifferent grained text representations, including character, subword, word,\nsentence, and sentence pair levels. The proposed deeper model is evaluated on\nthe benchmark treebank and achieves state-of-the-art accuracy with greater than\n48% in 11-way and $F_1$ score greater than 50% in 4-way classifications for the\nfirst time according to our best knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:57:39 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.05196", "submitter": "Lars Kunze", "authors": "Lars Kunze, Nick Hawes, Tom Duckett, Marc Hanheide, Tom\\'a\\v{s}\n  Krajn\\'ik", "title": "Artificial Intelligence for Long-Term Robot Autonomy: A Survey", "comments": "Accepted for publication in the IEEE Robotics and Automation Letters\n  (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems will play an essential role in many applications across\ndiverse domains including space, marine, air, field, road, and service\nrobotics. They will assist us in our daily routines and perform dangerous,\ndirty and dull tasks. However, enabling robotic systems to perform autonomously\nin complex, real-world scenarios over extended time periods (i.e. weeks,\nmonths, or years) poses many challenges. Some of these have been investigated\nby sub-disciplines of Artificial Intelligence (AI) including navigation &\nmapping, perception, knowledge representation & reasoning, planning,\ninteraction, and learning. The different sub-disciplines have developed\ntechniques that, when re-integrated within an autonomous system, can enable\nrobots to operate effectively in complex, long-term scenarios. In this paper,\nwe survey and discuss AI techniques as 'enablers' for long-term robot autonomy,\ncurrent progress in integrating these techniques within long-running robotic\nsystems, and the future challenges and opportunities for AI in long-term\nautonomy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:32:32 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Kunze", "Lars", ""], ["Hawes", "Nick", ""], ["Duckett", "Tom", ""], ["Hanheide", "Marc", ""], ["Krajn\u00edk", "Tom\u00e1\u0161", ""]]}, {"id": "1807.05464", "submitter": "Andreas Bueff Mr.", "authors": "Andreas Bueff, Stefanie Speichert, Vaishak Belle", "title": "Tractable Querying and Learning in Hybrid Domains via Sum-Product\n  Networks", "comments": "Accepted at the 2018 KR Workshop on Hybrid Reasoning and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic representations, such as Bayesian and Markov networks, are\nfundamental to much of statistical machine learning. Thus, learning\nprobabilistic representations directly from data is a deep challenge, the main\ncomputational bottleneck being inference that is intractable. Tractable\nlearning is a powerful new paradigm that attempts to learn distributions that\nsupport efficient probabilistic querying. By leveraging local structure,\nrepresentations such as sum-product networks (SPNs) can capture high tree-width\nmodels with many hidden layers, essentially a deep architecture, while still\nadmitting a range of probabilistic queries to be computable in time polynomial\nin the network size. The leaf nodes in SPNs, from which more intricate mixtures\nare formed, are tractable univariate distributions, and so the literature has\nfocused on Bernoulli and Gaussian random variables. This is clearly a\nrestriction for handling mixed discrete-continuous data, especially if the\ncontinuous features are generated from non-parametric and non-Gaussian\ndistribution families. In this work, we present a framework that systematically\nintegrates SPN structure learning with weighted model integration, a recently\nintroduced computational abstraction for performing inference in hybrid\ndomains, by means of piecewise polynomial approximations of density functions\nof arbitrary shape. Our framework is instantiated by exploiting the notion of\npropositional abstractions, thus minimally interfering with the SPN structure\nlearning module, and supports a powerful query interface for conditioning on\ninterval constraints. Our empirical results show that our approach is\neffective, and allows a study of the trade off between the granularity of the\nlearned model and its predictive power.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 23:25:16 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 16:30:13 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:13:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Bueff", "Andreas", ""], ["Speichert", "Stefanie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1807.05517", "submitter": "Michele Lombardi", "authors": "Michele Lombardi and Michela Milano", "title": "Boosting Combinatorial Problem Modeling with Machine Learning", "comments": "Originally submitted to IJCAI2018", "journal-ref": null, "doi": "10.24963/ijcai.2018/177", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, the area of Machine Learning (ML) has witnessed\ntremendous advancements, becoming a pervasive technology in a wide range of\napplications. One area that can significantly benefit from the use of ML is\nCombinatorial Optimization. The three pillars of constraint satisfaction and\noptimization problem solving, i.e., modeling, search, and optimization, can\nexploit ML techniques to boost their accuracy, efficiency and effectiveness. In\nthis survey we focus on the modeling component, whose effectiveness is crucial\nfor solving the problem. The modeling activity has been traditionally shaped by\noptimization and domain experts, interacting to provide realistic results.\nMachine Learning techniques can tremendously ease the process, and exploit the\navailable data to either create models or refine expert-designed ones. In this\nsurvey we cover approaches that have been recently proposed to enhance the\nmodeling process by learning either single constraints, objective functions, or\nthe whole model. We highlight common themes to multiple approaches and draw\nconnections with related fields of research.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 09:12:08 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "1807.05527", "submitter": "Stefanie Speichert", "authors": "Stefanie Speichert, Vaishak Belle", "title": "Learning Probabilistic Logic Programs in Continuous Domains", "comments": "Accepted at the 2018 KR Workshop on Hybrid Reasoning and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of statistical relational learning aims at unifying logic and\nprobability to reason and learn from data. Perhaps the most successful paradigm\nin the field is probabilistic logic programming: the enabling of stochastic\nprimitives in logic programming, which is now increasingly seen to provide a\ndeclarative background to complex machine learning applications. While many\nsystems offer inference capabilities, the more significant challenge is that of\nlearning meaningful and interpretable symbolic representations from data. In\nthat regard, inductive logic programming and related techniques have paved much\nof the way for the last few decades.\n  Unfortunately, a major limitation of this exciting landscape is that much of\nthe work is limited to finite-domain discrete probability distributions.\nRecently, a handful of systems have been extended to represent and perform\ninference with continuous distributions. The problem, of course, is that\nclassical solutions for inference are either restricted to well-known\nparametric families (e.g., Gaussians) or resort to sampling strategies that\nprovide correct answers only in the limit. When it comes to learning, moreover,\ninducing representations remains entirely open, other than \"data-fitting\"\nsolutions that force-fit points to aforementioned parametric families.\n  In this paper, we take the first steps towards inducing probabilistic logic\nprograms for continuous and mixed discrete-continuous data, without being\npigeon-holed to a fixed set of distribution families. Our key insight is to\nleverage techniques from piecewise polynomial function approximation theory,\nyielding a principled way to learn and compositionally construct density\nfunctions. We test the framework and discuss the learned representations.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 11:00:00 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 12:45:38 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Speichert", "Stefanie", ""], ["Belle", "Vaishak", ""]]}, {"id": "1807.05579", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Tru H. Cao", "title": "Ontology-Based Query Expansion with Latently Related Named Entities for\n  Semantic Text Search", "comments": "12 pages - accepted by Advances in Intelligent Information and\n  Database Systems, Book of series SCI, Springer-Verlag (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional information retrieval systems represent documents and queries by\nkeyword sets. However, the content of a document or a query is mainly defined\nby both keywords and named entities occurring in it. Named entities have\nontological features, namely, their aliases, classes, and identifiers, which\nare hidden from their textual appearance. Besides, the meaning of a query may\nimply latent named entities that are related to the apparent ones in the query.\nWe propose an ontology-based generalized vector space model to semantic text\nsearch. It exploits ontological features of named entities and their latently\nrelated ones to reveal the semantics of documents and queries. We also propose\na framework to combine different ontologies to take their complementary\nadvantages for semantic annotation and searching. Experiments on a benchmark\ndataset show better search quality of our model to other ones.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 17:20:54 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""]]}, {"id": "1807.05609", "submitter": "Bart Jacobs", "authors": "Bart Jacobs", "title": "The Mathematics of Changing one's Mind, via Jeffrey's or via Pearl's\n  update rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence in probabilistic reasoning may be 'hard' or 'soft', that is, it may\nbe of yes/no form, or it may involve a strength of belief, in the unit interval\n[0, 1]. Reasoning with soft, [0, 1]-valued evidence is important in many\nsituations but may lead to different, confusing interpretations. This paper\nintends to bring more mathematical and conceptual clarity to the field by\nshifting the existing focus from specification of soft evidence to accomodation\nof soft evidence. There are two main approaches, known as Jeffrey's rule and\nPearl's method; they give different outcomes on soft evidence. This paper\nargues that they can be understood as correction and as improvement. It\ndescribes these two approaches as different ways of updating with soft\nevidence, highlighting their differences, similarities and applications. This\naccount is based on a novel channel-based approach to Bayesian probability.\nProper understanding of these two update mechanisms is highly relevant for\ninference, decision tools and probabilistic programming languages.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 20:29:15 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 19:26:13 GMT"}, {"version": "v3", "created": "Sat, 29 Jun 2019 09:28:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Jacobs", "Bart", ""]]}, {"id": "1807.05691", "submitter": "Evan Patterson", "authors": "Evan Patterson, Ioana Baldini, Aleksandra Mojsilovic, Kush R. Varshney", "title": "Teaching machines to understand data science code by semantic enrichment\n  of dataflow graphs", "comments": "33 pages. Significantly expanded from previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Your computer is continuously executing programs, but does it really\nunderstand them? Not in any meaningful sense. That burden falls upon human\nknowledge workers, who are increasingly asked to write and understand code.\nThey deserve to have intelligent tools that reveal the connections between code\nand its subject matter. Towards this prospect, we develop an AI system that\nforms semantic representations of computer programs, using techniques from\nknowledge representation and program analysis. To create the representations,\nwe introduce an algorithm for enriching dataflow graphs with semantic\ninformation. The semantic enrichment algorithm is undergirded by a new ontology\nlanguage for modeling computer programs and a new ontology about data science,\nwritten in this language. Throughout the paper, we focus on code written by\ndata scientists and we locate our work within a larger movement towards\ncollaborative, open, and reproducible science.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 06:21:54 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 06:19:21 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Patterson", "Evan", ""], ["Baldini", "Ioana", ""], ["Mojsilovic", "Aleksandra", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1807.05720", "submitter": "Araz Taeihagh", "authors": "Araz Taeihagh, Hazel Si Min Lim", "title": "Governing autonomous vehicles: emerging responses for safety, liability,\n  privacy, cybersecurity, and industry risks", "comments": "Transport Reviews, 2018", "journal-ref": null, "doi": "10.1080/01441647.2018.1494640", "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of autonomous vehicles (AVs) are widely acknowledged, but there\nare concerns about the extent of these benefits and AV risks and unintended\nconsequences. In this article, we first examine AVs and different categories of\nthe technological risks associated with them. We then explore strategies that\ncan be adopted to address these risks, and explore emerging responses by\ngovernments for addressing AV risks. Our analyses reveal that, thus far,\ngovernments have in most instances avoided stringent measures in order to\npromote AV developments and the majority of responses are non-binding and focus\non creating councils or working groups to better explore AV implications. The\nUS has been active in introducing legislations to address issues related to\nprivacy and cybersecurity. The UK and Germany, in particular, have enacted laws\nto address liability issues, other countries mostly acknowledge these issues,\nbut have yet to implement specific strategies. To address privacy and\ncybersecurity risks strategies ranging from introduction or amendment of non-AV\nspecific legislation to creating working groups have been adopted. Much less\nattention has been paid to issues such as environmental and employment risks,\nalthough a few governments have begun programmes to retrain workers who might\nbe negatively affected.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 08:18:57 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Taeihagh", "Araz", ""], ["Lim", "Hazel Si Min", ""]]}, {"id": "1807.05853", "submitter": "Mohamed Reda Bouadjenek", "authors": "Mohamed Reda Bouadjenek, Esther Pacitti, Maximilien Servajean, Florent\n  Masseglia, Amr El Abbadi", "title": "A Distributed Collaborative Filtering Algorithm Using Multiple Data\n  Sources", "comments": "The Tenth International Conference on Advances in Databases,\n  Knowledge, and Data Applications, DBKDA 2018 May 20, 2018 to May 24, 2018 -\n  Nice, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) is one of the most commonly used recommendation\nmethods. CF consists in predicting whether, or how much, a user will like (or\ndislike) an item by leveraging the knowledge of the user's preferences as well\nas that of other users. In practice, users interact and express their opinion\non only a small subset of items, which makes the corresponding user-item rating\nmatrix very sparse. Such data sparsity yields two main problems for recommender\nsystems: (1) the lack of data to effectively model users' preferences, and (2)\nthe lack of data to effectively model item characteristics. However, there are\noften many other data sources that are available to a recommender system\nprovider, which can describe user interests and item characteristics (e.g.,\nusers' social network, tags associated to items, etc.). These valuable data\nsources may supply useful information to enhance a recommendation system in\nmodeling users' preferences and item characteristics more accurately and thus,\nhopefully, to make recommenders more precise. For various reasons, these data\nsources may be managed by clusters of different data centers, thus requiring\nthe development of distributed solutions. In this paper, we propose a new\ndistributed collaborative filtering algorithm, which exploits and combines\nmultiple and diverse data sources to improve recommendation quality. Our\nexperimental evaluation using real datasets shows the effectiveness of our\nalgorithm compared to state-of-the-art recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:35:58 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bouadjenek", "Mohamed Reda", ""], ["Pacitti", "Esther", ""], ["Servajean", "Maximilien", ""], ["Masseglia", "Florent", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1807.05906", "submitter": "Nalin Chhibber", "authors": "Nalin Chhibber, Rohail Syed, Mengqiu Teng, Joslin Goh, Kevyn\n  Collins-Thompson, Edith Law", "title": "Human Perception of Surprise: A User Study", "comments": "4 pages. Presented at Computational Surprise Workshop, SIGIR 2018\n  (Michigan)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how to engage users is a critical question in many\napplications. Previous research has shown that unexpected or astonishing events\ncan attract user attention, leading to positive outcomes such as engagement and\nlearning. In this work, we investigate the similarity and differences in how\npeople and algorithms rank the surprisingness of facts. Our crowdsourcing\nstudy, involving 106 participants, shows that computational models of surprise\ncan be used to artificially induce surprise in humans.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:02:38 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chhibber", "Nalin", ""], ["Syed", "Rohail", ""], ["Teng", "Mengqiu", ""], ["Goh", "Joslin", ""], ["Collins-Thompson", "Kevyn", ""], ["Law", "Edith", ""]]}, {"id": "1807.05924", "submitter": "Navneet Paul", "authors": "Arun Kumar, Navneet Paul and S N Omkar", "title": "Bipedal Walking Robot using Deep Deterministic Policy Gradient", "comments": "Research manuscript submitted to IEEE Symposium Series on\n  Computational Intelligence(SSCI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms have found several applications in the field of\nrobotics and control systems. The control systems community has started to show\ninterest towards several machine learning algorithms from the sub-domains such\nas supervised learning, imitation learning and reinforcement learning to\nachieve autonomous control and intelligent decision making. Amongst many\ncomplex control problems, stable bipedal walking has been the most challenging\nproblem. In this paper, we present an architecture to design and simulate a\nplanar bipedal walking robot(BWR) using a realistic robotics simulator, Gazebo.\nThe robot demonstrates successful walking behaviour by learning through several\nof its trial and errors, without any prior knowledge of itself or the world\ndynamics. The autonomous walking of the BWR is achieved using reinforcement\nlearning algorithm called Deep Deterministic Policy Gradient(DDPG). DDPG is one\nof the algorithms for learning controls in continuous action spaces. After\ntraining the model in simulation, it was observed that, with a proper shaped\nreward function, the robot achieved faster walking or even rendered a running\ngait with an average speed of 0.83 m/s. The gait pattern of the bipedal walker\nwas compared with the actual human walking pattern. The results show that the\nbipedal walking pattern had similar characteristics to that of a human walking\npattern. The video presenting our experiment is available at\nhttps://goo.gl/NHXKqR.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:34:52 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 15:44:28 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kumar", "Arun", ""], ["Paul", "Navneet", ""], ["Omkar", "S N", ""]]}, {"id": "1807.05976", "submitter": "Zhenyue Qin", "authors": "Zhenyue Qin, Robert McKay, Tom Gedeon", "title": "Why don't the modules dominate - Investigating the Structure of a\n  Well-Known Modularity-Inducing Problem Domain", "comments": null, "journal-ref": null, "doi": "10.1145/3205651.3205737", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wagner's modularity inducing problem domain is a key contribution to the\nstudy of the evolution of modularity, including both evolutionary theory and\nevolutionary computation. We study its behavior under classical genetic\nalgorithms. Unlike what we seem to observe in nature, the emergence of\nmodularity is highly conditional and dependent, for example, on the eagerness\nof search. In nature, modular solutions generally dominate populations, whereas\nin this domain, modularity, when it emerges, is a relatively rare variant.\nEmergence of modularity depends heavily on random fluctuations in the fitness\nfunction, with a randomly varied but unchanging fitness function, modularity\nevolved far more rarely. Interestingly, high-fitness non-modular solutions\ncould frequently be converted into even-higher-fitness modular solutions by\nmanually removing all inter-module edges. Despite careful exploration, we do\nnot yet have a full explanation of why the genetic algorithm was unable to find\nthese better solutions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 13:36:59 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 06:30:46 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Qin", "Zhenyue", ""], ["McKay", "Robert", ""], ["Gedeon", "Tom", ""]]}, {"id": "1807.06046", "submitter": "Yuri Chervonyi", "authors": "Yuri Chervonyi, Dragos Harabor, Brian Zhang, Josh Sacks", "title": "Zap: Making Predictions Based on Online User Behavior", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Zap, a generic machine learning pipeline for making\npredictions based on online user behavior. Zap combines well known techniques\nfor processing sequential data with more obscure techniques such as Bloom\nfilters, bucketing, and model calibration into an end-to-end solution. The\npipeline creates website- and task-specific models without knowing anything\nabout the structure of the website. It is designed to minimize the amount of\nwebsite-specific code, which is realized by factoring all website-specific\nlogic into example generators. New example generators can typically be written\nup in a few lines of code.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:18:02 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chervonyi", "Yuri", ""], ["Harabor", "Dragos", ""], ["Zhang", "Brian", ""], ["Sacks", "Josh", ""]]}, {"id": "1807.06072", "submitter": "Jungwook Lee", "authors": "Jungwook Lee, Sean Walsh, Ali Harakeh, and Steven L. Waslander", "title": "Leveraging Pre-Trained 3D Object Detection Models For Fast Ground Truth\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training 3D object detectors for autonomous driving has been limited to small\ndatasets due to the effort required to generate annotations. Reducing both task\ncomplexity and the amount of task switching done by annotators is key to\nreducing the effort and time required to generate 3D bounding box annotations.\nThis paper introduces a novel ground truth generation method that combines\nhuman supervision with pretrained neural networks to generate per-instance 3D\npoint cloud segmentation, 3D bounding boxes, and class annotations. The\nannotators provide object anchor clicks which behave as a seed to generate\ninstance segmentation results in 3D. The points belonging to each instance are\nthen used to regress object centroids, bounding box dimensions, and object\norientation. Our proposed annotation scheme requires 30x lower human annotation\ntime. We use the KITTI 3D object detection dataset to evaluate the efficiency\nand the quality of our annotation scheme. We also test the the proposed scheme\non previously unseen data from the Autonomoose self-driving vehicle to\ndemonstrate generalization capabilities of the network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 19:33:09 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Lee", "Jungwook", ""], ["Walsh", "Sean", ""], ["Harakeh", "Ali", ""], ["Waslander", "Steven L.", ""]]}, {"id": "1807.06078", "submitter": "Diego Sempreboni", "authors": "Luca Vigan\\'o and Diego Sempreboni", "title": "Gnirut: The Trouble With Being Born Human In An Autonomous World", "comments": "5 pages, 0 figures, Accepted at the \"Re-Coding Black Mirror\" workshop\n  of the International World Wide Web Conferences (WWW)", "journal-ref": null, "doi": "10.1145/3184558.3191612", "report-no": null, "categories": "cs.CY cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What if we delegated so much to autonomous AI and intelligent machines that\nThey passed a law that forbids humans to carry out a number of professions? We\nconceive the plot of a new episode of Black Mirror to reflect on what might\nawait us and how we can deal with such a future.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 19:33:16 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Vigan\u00f3", "Luca", ""], ["Sempreboni", "Diego", ""]]}, {"id": "1807.06096", "submitter": "Nils Jansen", "authors": "Nils Jansen, Bettina K\\\"onighofer, Sebastian Junges, Alexandru C.\n  Serban, Roderick Bloem", "title": "Safe Reinforcement Learning via Probabilistic Shields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the efficient construction of a safety shield for decision\nmaking in scenarios that incorporate uncertainty. Markov decision processes\n(MDPs) are prominent models to capture such planning problems. Reinforcement\nlearning (RL) is a machine learning technique to determine near-optimal\npolicies in MDPs that may be unknown prior to exploring the model. However,\nduring exploration, RL is prone to induce behavior that is undesirable or not\nallowed in safety- or mission-critical contexts. We introduce the concept of a\nprobabilistic shield that enables decision-making to adhere to safety\nconstraints with high probability. In a separation of concerns, we employ\nformal verification to efficiently compute the probabilities of critical\ndecisions within a safety-relevant fragment of the MDP. We use these results to\nrealize a shield that is applied to an RL algorithm which then optimizes the\nactual performance objective. We discuss tradeoffs between sufficient progress\nin exploration of the environment and ensuring safety. In our experiments, we\ndemonstrate on the arcade game PAC-MAN and on a case study involving service\nrobots that the learning efficiency increases as the learning needs orders of\nmagnitude fewer episodes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:29:04 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:12:41 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Jansen", "Nils", ""], ["K\u00f6nighofer", "Bettina", ""], ["Junges", "Sebastian", ""], ["Serban", "Alexandru C.", ""], ["Bloem", "Roderick", ""]]}, {"id": "1807.06103", "submitter": "Hadi Hosseini", "authors": "Angelina Brilliantova, Anton Pletenev, Liliya Doronina, Hadi Hosseini", "title": "An agent-based model of an endangered population of the Arctic fox from\n  Mednyi Island", "comments": "The AI for Wildlife Conservation (AIWC) Workshop at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence techniques such as agent-based modeling and\nprobabilistic reasoning have shown promise in modeling complex biological\nsystems and testing ecological hypotheses through simulation. We develop an\nagent-based model of Arctic foxes from Medniy Island while utilizing\nProbabilistic Graphical Models to capture the conditional dependencies between\nthe random variables. Such models provide valuable insights in analyzing\nfactors behind catastrophic degradation of this population and in revealing\nevolutionary mechanisms of its persistence in high-density environment. Using\nempirical data from studies in Medniy Island, we create a realistic model of\nArctic foxes as agents, and study their survival and population dynamics under\na variety of conditions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 20:49:12 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Brilliantova", "Angelina", ""], ["Pletenev", "Anton", ""], ["Doronina", "Liliya", ""], ["Hosseini", "Hadi", ""]]}, {"id": "1807.06107", "submitter": "Amita Misra", "authors": "Mansurul Bhuiyan, Amita Misra, Saurabh Tripathy, Jalal Mahmud, Rama\n  Akkiraju", "title": "Don't get Lost in Negation: An Effective Negation Handled Dialogue Acts\n  Prediction Algorithm for Twitter Customer Service Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last several years, Twitter is being adopted by the companies as an\nalternative platform to interact with the customers to address their concerns.\nWith the abundance of such unconventional conversation resources, push for\ndeveloping effective virtual agents is more than ever. To address this\nchallenge, a better understanding of such customer service conversations is\nrequired. Lately, there have been several works proposing a novel taxonomy for\nfine-grained dialogue acts as well as develop algorithms for automatic\ndetection of these acts. The outcomes of these works are providing stepping\nstones for the ultimate goal of building efficient and effective virtual\nagents. But none of these works consider handling the notion of negation into\nthe proposed algorithms. In this work, we developed an SVM-based dialogue acts\nprediction algorithm for Twitter customer service conversations where negation\nhandling is an integral part of the end-to-end solution. For negation handling,\nwe propose several efficient heuristics as well as adopt recent state-of- art\nthird party machine learning based solutions. Empirically we show model's\nperformance gain while handling negation compared to when we don't. Our\nexperiments show that for the informal text such as tweets, the heuristic-based\napproach is more effective.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 21:01:52 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bhuiyan", "Mansurul", ""], ["Misra", "Amita", ""], ["Tripathy", "Saurabh", ""], ["Mahmud", "Jalal", ""], ["Akkiraju", "Rama", ""]]}, {"id": "1807.06142", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Andreas Wichert", "title": "Introducing Quantum-Like Influence Diagrams for Violations of the Sure\n  Thing Principle", "comments": null, "journal-ref": "Quantum Interactions, 2018", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is the focus of this work to extend and study the previously proposed\nquantum-like Bayesian networks to deal with decision-making scenarios by\nincorporating the notion of maximum expected utility in influence diagrams. The\ngeneral idea is to take advantage of the quantum interference terms produced in\nthe quantum-like Bayesian Network to influence the probabilities used to\ncompute the expected utility of some action. This way, we are not proposing a\nnew type of expected utility hypothesis. On the contrary, we are keeping it\nunder its classical definition. We are only incorporating it as an extension of\na probabilistic graphical model in a compact graphical representation called an\ninfluence diagram in which the utility function depends on the probabilistic\ninfluences of the quantum-like Bayesian network.\n  Our findings suggest that the proposed quantum-like influence digram can\nindeed take advantage of the quantum interference effects of quantum-like\nBayesian Networks to maximise the utility of a cooperative behaviour in\ndetriment of a fully rational defect behaviour under the prisoner's dilemma\ngame.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:39:16 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 17:39:56 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Moreira", "Catarina", ""], ["Wichert", "Andreas", ""]]}, {"id": "1807.06149", "submitter": "Tom Hanika", "authors": "Daniel Borchmann, Tom Hanika, Sergei Obiedkov", "title": "Probably approximately correct learning of Horn envelopes from queries", "comments": "21 pages, 1 figure", "journal-ref": "Discrete Applied Mathematics Volume 273 (2020), Pages 30-42", "doi": "10.1016/j.dam.2019.02.036", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for learning the Horn envelope of an arbitrary domain\nusing an expert, or an oracle, capable of answering certain types of queries\nabout this domain. Attribute exploration from formal concept analysis is a\nprocedure that solves this problem, but the number of queries it may ask is\nexponential in the size of the resulting Horn formula in the worst case. We\nrecall a well-known polynomial-time algorithm for learning Horn formulas with\nmembership and equivalence queries and modify it to obtain a polynomial-time\nprobably approximately correct algorithm for learning the Horn envelope of an\narbitrary domain.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 23:24:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Borchmann", "Daniel", ""], ["Hanika", "Tom", ""], ["Obiedkov", "Sergei", ""]]}, {"id": "1807.06158", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Generative Adversarial Imitation from Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation from observation (IfO) is the problem of learning directly from\nstate-only demonstrations without having access to the demonstrator's actions.\nThe lack of action information both distinguishes IfO from most of the\nliterature in imitation learning, and also sets it apart as a method that may\nenable agents to learn from a large set of previously inapplicable resources\nsuch as internet videos. In this paper, we propose both a general framework for\nIfO approaches and also a new IfO approach based on generative adversarial\nnetworks called generative adversarial imitation from observation (GAIfO). We\nconduct experiments in two different settings: (1) when demonstrations consist\nof low-dimensional, manually-defined state features, and (2) when\ndemonstrations consist of high-dimensional, raw visual data. We demonstrate\nthat our approach performs comparably to classical imitation learning\napproaches (which have access to the demonstrator's actions) and significantly\noutperforms existing imitation from observation methods in high-dimensional\nsimulation environments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:25:15 GMT"}, {"version": "v2", "created": "Sun, 18 Nov 2018 18:12:35 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 05:08:02 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 04:56:56 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1807.06161", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shruti Joshi", "title": "Explanations for Temporal Recommendations", "comments": "Accepted at the XAI Workshop in IJCAI/ECAI 2018", "journal-ref": "Homanga Bharadhwaj and Shruti Joshi. \"Explanations for Temporal\n  Recommendations\" IJCAI-18 Workshop on Explainable AI (XAI). 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are an integral part of Artificial Intelligence (AI)\nand have become increasingly important in the growing age of commercialization\nin AI. Deep learning (DL) techniques for recommendation systems (RS) provide\npowerful latent-feature models for effective recommendation but suffer from the\nmajor drawback of being non-interpretable. In this paper we describe a\nframework for explainable temporal recommendations in a DL model. We consider\nan LSTM based Recurrent Neural Network (RNN) architecture for recommendation\nand a neighbourhood-based scheme for generating explanations in the model. We\ndemonstrate the effectiveness of our approach through experiments on the\nNetflix dataset by jointly optimizing for both prediction accuracy and\nexplainability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:38:40 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Joshi", "Shruti", ""]]}, {"id": "1807.06228", "submitter": "Yao Ming", "authors": "Yao Ming and Huamin Qu and Enrico Bertini", "title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules", "comments": "Accepted by IEEE Conference of Visual Analytics Science and\n  Technology 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing adoption of machine learning techniques, there is a surge of\nresearch interest towards making machine learning systems more transparent and\ninterpretable. Various visualizations have been developed to help model\ndevelopers understand, diagnose, and refine machine learning models. However, a\nlarge number of potential but neglected users are the domain experts with\nlittle knowledge of machine learning but are expected to work with machine\nlearning systems. In this paper, we present an interactive visualization\ntechnique to help users with little expertise in machine learning to\nunderstand, explore and validate predictive models. By viewing the model as a\nblack box, we extract a standardized rule-based knowledge representation from\nits input-output behavior. We design RuleMatrix, a matrix-based visualization\nof rules to help users navigate and verify the rules and the black-box model.\nWe evaluate the effectiveness of RuleMatrix via two use cases and a usability\nstudy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 05:29:10 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ming", "Yao", ""], ["Qu", "Huamin", ""], ["Bertini", "Enrico", ""]]}, {"id": "1807.06286", "submitter": "Tobias Joppen", "authors": "Tobias Joppen, Christian Wirth, and Johannes F\\\"urnkranz", "title": "Preference-Based Monte Carlo Tree Search", "comments": "To be published", "journal-ref": "Proceedings of the 41st German Conference on Artificial\n  Intelligence (KI-18), 2018", "doi": "10.1007/978-3-030-00111-7_28", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo tree search (MCTS) is a popular choice for solving sequential\nanytime problems. However, it depends on a numeric feedback signal, which can\nbe difficult to define. Real-time MCTS is a variant which may only rarely\nencounter states with an explicit, extrinsic reward. To deal with such cases,\nthe experimenter has to supply an additional numeric feedback signal in the\nform of a heuristic, which intrinsically guides the agent. Recent work has\nshown evidence that in different areas the underlying structure is ordinal and\nnot numerical. Hence erroneous and biased heuristics are inevitable, especially\nin such domains. In this paper, we propose a MCTS variant which only depends on\nqualitative feedback, and therefore opens up new applications for MCTS. We also\nfind indications that translating absolute into ordinal feedback may be\nbeneficial. Using a puzzle domain, we show that our preference-based MCTS\nvariant, wich only receives qualitative feedback, is able to reach a\nperformance level comparable to a regular MCTS baseline, which obtains\nquantitative feedback.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 09:04:35 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Joppen", "Tobias", ""], ["Wirth", "Christian", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1807.06333", "submitter": "Fabio Patrizi", "authors": "Giuseppe De Giacomo and Luca Iocchi and Marco Favorito and Fabio\n  Patrizi", "title": "Foundations for Restraining Bolts: Reinforcement Learning with LTLf/LDLf\n  restraining specifications", "comments": null, "journal-ref": "ICAPS 2019: 128-136", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate on the concept of \"restraining bolt\", envisioned\nin Science Fiction. Specifically we introduce a novel problem in AI. We have\ntwo distinct sets of features extracted from the world, one by the agent and\none by the authority imposing restraining specifications (the \"restraining\nbolt\"). The two sets are apparently unrelated since of interest to independent\nparties, however they both account for (aspects of) the same world. We consider\nthe case in which the agent is a reinforcement learning agent on the first set\nof features, while the restraining bolt is specified logically using linear\ntime logic on finite traces LTLf/LDLf over the second set of features. We show\nformally, and illustrate with examples, that, under general circumstances, the\nagent can learn while shaping its goals to suitably conform (as much as\npossible) to the restraining bolt specifications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 10:51:04 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 11:19:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["De Giacomo", "Giuseppe", ""], ["Iocchi", "Luca", ""], ["Favorito", "Marco", ""], ["Patrizi", "Fabio", ""]]}, {"id": "1807.06391", "submitter": "Matthias Dorfer", "authors": "Matthias Dorfer and Florian Henkel and Gerhard Widmer", "title": "Learning to Listen, Read, and Follow: Score Following as a Reinforcement\n  Learning Game", "comments": "Published in the Proceedings of the 19th International Society for\n  Music Information Retrieval Conference, Paris, France, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score following is the process of tracking a musical performance (audio) with\nrespect to a known symbolic representation (a score). We start this paper by\nformulating score following as a multimodal Markov Decision Process, the\nmathematical foundation for sequential decision making. Given this formal\ndefinition, we address the score following task with state-of-the-art deep\nreinforcement learning (RL) algorithms such as synchronous advantage actor\ncritic (A2C). In particular, we design multimodal RL agents that simultaneously\nlearn to listen to music, read the scores from images of sheet music, and\nfollow the audio along in the sheet, in an end-to-end fashion. All this\nbehavior is learned entirely from scratch, based on a weak and potentially\ndelayed reward signal that indicates to the agent how close it is to the\ncorrect position in the score. Besides discussing the theoretical advantages of\nthis learning paradigm, we show in experiments that it is in fact superior\ncompared to previously proposed methods for score following in raw sheet music\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 12:49:18 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Dorfer", "Matthias", ""], ["Henkel", "Florian", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1807.06397", "submitter": "Ronald de Haan", "authors": "Ronald de Haan", "title": "Expressing Linear Orders Requires Exponential-Size DNNFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any DNNF circuit that expresses the set of linear orders over a\nset of $n$ candidates must be of size $2^{\\Omega(n)}$. Moreover, we show that\nthere exist DNNF circuits of size $2^{O(n)}$ expressing linear orders over $n$\ncandidates.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 13:02:55 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 15:45:40 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 12:15:48 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["de Haan", "Ronald", ""]]}, {"id": "1807.06414", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin", "title": "Combining a Context Aware Neural Network with a Denoising Autoencoder\n  for Measuring String Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between strings is central for many established and\nfast growing research areas including information retrieval, biology, and\nnatural language processing. The traditional approach for string similarity\nmeasurements is to define a metric over a word space that quantifies and sums\nup the differences between characters in two strings. The state-of-the-art in\nthe area has, surprisingly, not evolved much during the last few decades. The\nmajority of the metrics are based on a simple comparison between character and\ncharacter distributions without consideration for the context of the words.\nThis paper proposes a string metric that encompasses similarities between\nstrings based on (1) the character similarities between the words including.\nNon-Standard and standard spellings of the same words, and (2) the context of\nthe words. Our proposal is a neural network composed of a denoising autoencoder\nand what we call a context encoder specifically designed to find similarities\nbetween the words based on their context. The experimental results show that\nthe resulting metrics succeeds in 85.4\\% of the cases in finding the correct\nversion of a non-standard spelling among the closest words, compared to 63.2\\%\nwith the established Normalised-Levenshtein distance. Besides, we show that\nwords used in similar context are with our approach calculated to be similar\nthan words with different contexts, which is a desirable property missing in\nestablished string metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:29:23 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""]]}, {"id": "1807.06419", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "On Ternary Coding and Three-Valued Logic", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically, ternary coding is more efficient than binary coding. It is\nlittle used in computation because technology for binary processing is already\nestablished and the implementation of ternary coding is more complicated, but\nremains relevant in algorithms that use decision trees and in communications.\nIn this paper we present a new comparison of binary and ternary coding and\ntheir relative efficiencies are computed both for number representation and\ndecision trees. The implications of our inability to use optimal representation\nthrough mathematics or logic are examined. Apart from considerations of\nrepresentation efficiency, ternary coding appears preferable to binary coding\nin classification of many real-world problems of artificial intelligence (AI)\nand medicine. We examine the problem of identifying appropriate three classes\nfor domain-specific applications.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 17:23:54 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1807.06538", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno and Michiaki Iwazume", "title": "Cavity Filling: Pseudo-Feature Generation for Multi-Class Imbalanced\n  Data Problems in Deep Learning", "comments": "The slides are available at https://goo.gl/SPsSDh in English and at\n  https://goo.gl/RFHYAa in Japanese. 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we generate pseudo-features based on the multivariate probability\ndistributions obtained from the feature maps in layers of trained deep neural\nnetworks. Further, we augment the minor-class data based on these generated\npseudo-features to overcome the imbalanced data problems. The proposed method,\ni.e., cavity filling, improves the deep learning capabilities in several\nproblems because all the real-world data are observed to be imbalanced.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:34:47 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 02:37:09 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 01:22:27 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 02:45:11 GMT"}, {"version": "v5", "created": "Tue, 1 Oct 2019 08:50:34 GMT"}, {"version": "v6", "created": "Sun, 13 Oct 2019 14:47:42 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Konno", "Tomohiko", ""], ["Iwazume", "Michiaki", ""]]}, {"id": "1807.06540", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno and Michiaki Iwazume", "title": "Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try\n  After Deep Learning", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We found an easy and quick post-learning method named \"Icing on the Cake\" to\nenhance a classification performance in deep learning. The method is that we\ntrain only the final classifier again after an ordinary training is done.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 16:35:51 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Konno", "Tomohiko", ""], ["Iwazume", "Michiaki", ""]]}, {"id": "1807.06613", "submitter": "Maximilian H\\\"uttenrauch", "authors": "Maximilian H\\\"uttenrauch, Adrian \\v{S}o\\v{s}i\\'c, Gerhard Neumann", "title": "Deep Reinforcement Learning for Swarm Systems", "comments": "31 pages, 12 figures, version 3 (published in JMLR Volume 20)", "journal-ref": "Journal of Machine Learning Research 20(54):1-31, 2019", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep reinforcement learning (RL) methods have been applied\nsuccessfully to multi-agent scenarios. Typically, these methods rely on a\nconcatenation of agent states to represent the information content required for\ndecentralized decision making. However, concatenation scales poorly to swarm\nsystems with a large number of homogeneous agents as it does not exploit the\nfundamental properties inherent to these systems: (i) the agents in the swarm\nare interchangeable and (ii) the exact number of agents in the swarm is\nirrelevant. Therefore, we propose a new state representation for deep\nmulti-agent RL based on mean embeddings of distributions. We treat the agents\nas samples of a distribution and use the empirical mean embedding as input for\na decentralized policy. We define different feature spaces of the mean\nembedding using histograms, radial basis functions and a neural network learned\nend-to-end. We evaluate the representation on two well known problems from the\nswarm literature (rendezvous and pursuit evasion), in a globally and locally\nobservable setup. For the local setup we furthermore introduce simple\ncommunication protocols. Of all approaches, the mean embedding representation\nusing neural network features enables the richest information exchange between\nneighboring agents facilitating the development of more complex collective\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 18:27:03 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 13:57:21 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 10:27:01 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["H\u00fcttenrauch", "Maximilian", ""], ["\u0160o\u0161i\u0107", "Adrian", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1807.06666", "submitter": "Dong Hao", "authors": "Dong Hao, Kai Li, Tao Zhou", "title": "Payoff Control in the Iterated Prisoner's Dilemma", "comments": null, "journal-ref": "Proceedings of the Twenty-Seventh International Joint Conference\n  on Artificial Intelligence. Main track. Pages 296-302. 2018", "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeated game has long been the touchstone model for agents' long-run\nrelationships. Previous results suggest that it is particularly difficult for a\nrepeated game player to exert an autocratic control on the payoffs since they\nare jointly determined by all participants. This work discovers that the scale\nof a player's capability to unilaterally influence the payoffs may have been\nmuch underestimated. Under the conventional iterated prisoner's dilemma, we\ndevelop a general framework for controlling the feasible region where the\nplayers' payoff pairs lie. A control strategy player is able to confine the\npayoff pairs in her objective region, as long as this region has feasible\nlinear boundaries. With this framework, many well-known existing strategies can\nbe categorized and various new strategies with nice properties can be further\nidentified. We show that the control strategies perform well either in a\ntournament or against a human-like opponent.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:44:51 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Hao", "Dong", ""], ["Li", "Kai", ""], ["Zhou", "Tao", ""]]}, {"id": "1807.06685", "submitter": "Till Mossakowski", "authors": "Till Mossakowski, Fabian Neuhaus", "title": "Modular Semantics and Characteristics for Bipolar Weighted Argumentation\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the semantics of weighted argumentation graphs that are\nbipolar, i.e. contain both attacks and supports for arguments. It builds on\nprevious work by Amgoud, Ben-Naim et. al. We study the various characteristics\nof acceptability semantics that have been introduced in these works, and\nintroduce the notion of a modular acceptability semantics. A semantics is\nmodular if it cleanly separates aggregation of attacking and supporting\narguments (for a given argument $a$) from the computation of their influence on\n$a$'s initial weight.\n  We show that the various semantics for bipolar argumentation graphs from the\nliterature may be analysed as a composition of an aggregation function with an\ninfluence function. Based on this modular framework, we prove general\nconvergence and divergence theorems. We demonstrate that all well-behaved\nmodular acceptability semantics converge for all acyclic graphs and that no\nsum-based semantics can converge for all graphs. In particular, we show\ndivergence of Euler-based semantics (Amgoud et al.) for certain cyclic graphs.\nFurther, we provide the first semantics for bipolar weighted graphs that\nconverges for all graphs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 21:54:49 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 19:33:13 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Mossakowski", "Till", ""], ["Neuhaus", "Fabian", ""]]}, {"id": "1807.06696", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu, Wee Sun Lee", "title": "Integrating Algorithmic Planning and Deep Learning for Partially\n  Observable Navigation", "comments": "MLPC workshop, ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to take a novel approach to robot system design where each\nbuilding block of a larger system is represented as a differentiable program,\ni.e. a deep neural network. This representation allows for integrating\nalgorithmic planning and deep learning in a principled manner, and thus combine\nthe benefits of model-free and model-based methods. We apply the proposed\napproach to a challenging partially observable robot navigation task. The robot\nmust navigate to a goal in a previously unseen 3-D environment without knowing\nits initial location, and instead relying on a 2-D floor map and visual\nobservations from an onboard camera. We introduce the Navigation Networks\n(NavNets) that encode state estimation, planning and acting in a single,\nend-to-end trainable recurrent neural network. In preliminary simulation\nexperiments we successfully trained navigation networks to solve the\nchallenging partially observable navigation task.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 22:51:14 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1807.06734", "submitter": "Michael Green", "authors": "Michael Cerny Green, Ahmed Khalifa, Gabriella A.B. Barros, Andy\n  Nealen, Julian Togelius", "title": "Generating Levels That Teach Mechanics", "comments": "8 pages, 7 figures, PCG Workshop at FDG 2018, 9th International\n  Workshop on Procedural Content Generation (PCG2018)", "journal-ref": null, "doi": "10.1145/3235765.3235820", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic generation of game tutorials is a challenging AI problem. While\nit is possible to generate annotations and instructions that explain to the\nplayer how the game is played, this paper focuses on generating a gameplay\nexperience that introduces the player to a game mechanic. It evolves small\nlevels for the Mario AI Framework that can only be beaten by an agent that\nknows how to perform specific actions in the game. It uses variations of a\nperfect A* agent that are limited in various ways, such as not being able to\njump high or see enemies, to test how failing to do certain actions can stop\nthe player from beating the level.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:47:47 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 21:52:23 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 15:30:52 GMT"}, {"version": "v4", "created": "Mon, 1 Oct 2018 16:15:18 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Barros", "Gabriella A. B.", ""], ["Nealen", "Andy", ""], ["Togelius", "Julian", ""]]}, {"id": "1807.06756", "submitter": "Zhen Li", "authors": "Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, and Zhaoxuan\n  Chen", "title": "SySeVR: A Framework for Using Deep Learning to Detect Software\n  Vulnerabilities", "comments": "To be published in IEEE TDSC", "journal-ref": null, "doi": "10.1109/TDSC.2021.3051525", "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of software vulnerabilities (or vulnerabilities for short) is\nan important problem that has yet to be tackled, as manifested by the many\nvulnerabilities reported on a daily basis. This calls for machine learning\nmethods for vulnerability detection. Deep learning is attractive for this\npurpose because it alleviates the requirement to manually define features.\nDespite the tremendous success of deep learning in other application domains,\nits applicability to vulnerability detection is not systematically understood.\nIn order to fill this void, we propose the first systematic framework for using\ndeep learning to detect vulnerabilities in C/C++ programs with source code. The\nframework, dubbed Syntax-based, Semantics-based, and Vector Representations\n(SySeVR), focuses on obtaining program representations that can accommodate\nsyntax and semantic information pertinent to vulnerabilities. Our experiments\nwith 4 software products demonstrate the usefulness of the framework: we detect\n15 vulnerabilities that are not reported in the National Vulnerability\nDatabase. Among these 15 vulnerabilities, 7 are unknown and have been reported\nto the vendors, and the other 8 have been \"silently\" patched by the vendors\nwhen releasing newer versions of the pertinent software products.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:26:39 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 01:41:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 00:04:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Zhen", ""], ["Zou", "Deqing", ""], ["Xu", "Shouhuai", ""], ["Jin", "Hai", ""], ["Zhu", "Yawei", ""], ["Chen", "Zhaoxuan", ""]]}, {"id": "1807.06757", "submitter": "Vladlen Koltun", "authors": "Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey\n  Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik,\n  Roozbeh Mottaghi, Manolis Savva, and Amir R. Zamir", "title": "On Evaluation of Embodied Navigation Agents", "comments": "Report of a working group on empirical methodology in navigation\n  research. Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Skillful mobile operation in three-dimensional environments is a primary\ntopic of study in Artificial Intelligence. The past two years have seen a surge\nof creative work on navigation. This creative output has produced a plethora of\nsometimes incompatible task definitions and evaluation protocols. To coordinate\nongoing and future research in this area, we have convened a working group to\nstudy empirical methodology in navigation research. The present document\nsummarizes the consensus recommendations of this working group. We discuss\ndifferent problem statements and the role of generalization, present evaluation\nmeasures, and provide standard scenarios that can be used for benchmarking.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:28:02 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Anderson", "Peter", ""], ["Chang", "Angel", ""], ["Chaplot", "Devendra Singh", ""], ["Dosovitskiy", "Alexey", ""], ["Gupta", "Saurabh", ""], ["Koltun", "Vladlen", ""], ["Kosecka", "Jana", ""], ["Malik", "Jitendra", ""], ["Mottaghi", "Roozbeh", ""], ["Savva", "Manolis", ""], ["Zamir", "Amir R.", ""]]}, {"id": "1807.06763", "submitter": "Matthew Schlegel", "authors": "Matthew Schlegel, Andrew Jacobsen, Zaheer Abbas, Andrew Patterson,\n  Adam White, and Martha White", "title": "General Value Function Networks", "comments": "Published in the Journal of Artificial Intelligence Research", "journal-ref": "Journal of Artificial Intelligence Research, 70, 497-543 (2021)", "doi": "10.1613/jair.1.12105", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State construction is important for learning in partially observable\nenvironments. A general purpose strategy for state construction is to learn the\nstate update using a Recurrent Neural Network (RNN), which updates the internal\nstate using the current internal state and the most recent observation. This\ninternal state provides a summary of the observed sequence, to facilitate\naccurate predictions and decision-making. At the same time, specifying and\ntraining RNNs is notoriously tricky, particularly as the common strategy to\napproximate gradients back in time, called truncated Back-prop Through Time\n(BPTT), can be sensitive to the truncation window. Further,\ndomain-expertise--which can usually help constrain the function class and so\nimprove trainability--can be difficult to incorporate into complex recurrent\nunits used within RNNs. In this work, we explore how to use multi-step\npredictions to constrain the RNN and incorporate prior knowledge. In\nparticular, we revisit the idea of using predictions to construct state and\nask: does constraining (parts of) the state to consist of predictions about the\nfuture improve RNN trainability? We formulate a novel RNN architecture, called\na General Value Function Network (GVFN), where each internal state component\ncorresponds to a prediction about the future represented as a value function.\nWe first provide an objective for optimizing GVFNs, and derive several\nalgorithms to optimize this objective. We then show that GVFNs are more robust\nto the truncation level, in many cases only requiring one-step gradient\nupdates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 03:51:08 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 03:49:01 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 02:54:31 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 18:50:25 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Schlegel", "Matthew", ""], ["Jacobsen", "Andrew", ""], ["Abbas", "Zaheer", ""], ["Patterson", "Andrew", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1807.06777", "submitter": "Sasha Rubin", "authors": "Benjamin Aminof, Giuseppe De Giacomo, Aniello Murano, Sasha Rubin", "title": "Planning and Synthesis Under Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Reasoning about Action and Planning, one synthesizes the agent plan by\ntaking advantage of the assumption on how the environment works (that is, one\nexploits the environment's effects, its fairness, its trajectory constraints).\nIn this paper we study this form of synthesis in detail. We consider\nassumptions as constraints on the possible strategies that the environment can\nhave in order to respond to the agent's actions. Such constraints may be given\nin the form of a planning domain (or action theory), as linear-time formulas\nover infinite or finite runs, or as a combination of the two. We argue though\nthat not all assumption specifications are meaningful: they need to be\nconsistent, which means that there must exist an environment strategy\nfulfilling the assumption in spite of the agent actions. For such assumptions,\nwe study how to do synthesis/planning for agent goals, ranging from a classical\nreachability to goal on traces specified in \\LTL and \\LTLf/\\LDLf,\ncharacterizing the problem both mathematically and algorithmically.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 05:23:43 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 22:42:13 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Aminof", "Benjamin", ""], ["De Giacomo", "Giuseppe", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""]]}, {"id": "1807.06813", "submitter": "Pier Luca Lanzi", "authors": "Stefano Di Palma and Pier Luca Lanzi", "title": "Traditional Wisdom and Monte Carlo Tree Search Face-to-Face in the Card\n  Game Scopone", "comments": "Preprint. Accepted for publication in the IEEE Transaction on Games", "journal-ref": "IEEE Transactions on Games 2018", "doi": "10.1109/TG.2018.2834618", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the design of a competitive artificial intelligence for Scopone, a\npopular Italian card game. We compare rule-based players using the most\nestablished strategies (one for beginners and two for advanced players) against\nplayers using Monte Carlo Tree Search (MCTS) and Information Set Monte Carlo\nTree Search (ISMCTS) with different reward functions and simulation strategies.\nMCTS requires complete information about the game state and thus implements a\ncheating player while ISMCTS can deal with incomplete information and thus\nimplements a fair player. Our results show that, as expected, the cheating MCTS\noutperforms all the other strategies; ISMCTS is stronger than all the\nrule-based players implementing well-known and most advanced strategies and it\nalso turns out to be a challenging opponent for human players.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 08:18:22 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Di Palma", "Stefano", ""], ["Lanzi", "Pier Luca", ""]]}, {"id": "1807.06822", "submitter": "Dong Hao", "authors": "Bin Li, Dong Hao, Dengji Zhao, Tao Zhou", "title": "Customer Sharing in Economic Networks with Costs", "comments": "Proceedings of the Twenty-Seventh International Joint Conference on\n  Artificial Intelligence. Main track. Pages 368-374. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA cs.SI econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an economic market, sellers, infomediaries and customers constitute an\neconomic network. Each seller has her own customer group and the seller's\nprivate customers are unobservable to other sellers. Therefore, a seller can\nonly sell commodities among her own customers unless other sellers or\ninfomediaries share her sale information to their customer groups. However, a\nseller is not incentivized to share others' sale information by default, which\nleads to inefficient resource allocation and limited revenue for the sale. To\ntackle this problem, we develop a novel mechanism called customer sharing\nmechanism (CSM) which incentivizes all sellers to share each other's sale\ninformation to their private customer groups. Furthermore, CSM also\nincentivizes all customers to truthfully participate in the sale. In the end,\nCSM not only allocates the commodities efficiently but also optimizes the\nseller's revenue.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 08:55:27 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Li", "Bin", ""], ["Hao", "Dong", ""], ["Zhao", "Dengji", ""], ["Zhou", "Tao", ""]]}, {"id": "1807.06874", "submitter": "Robin Lamarche-Perrin", "authors": "Robin Lamarche-Perrin", "title": "An Information-theoretic Framework for the Lossy Compression of Link\n  Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph compression is a data analysis technique that consists in the\nreplacement of parts of a graph by more general structural patterns in order to\nreduce its description length. It notably provides interesting exploration\ntools for the study of real, large-scale, and complex graphs which cannot be\ngrasped at first glance. This article proposes a framework for the compression\nof temporal graphs, that is for the compression of graphs that evolve with\ntime. This framework first builds on a simple and limited scheme, exploiting\nstructural equivalence for the lossless compression of static graphs, then\ngeneralises it to the lossy compression of link streams, a recent formalism for\nthe study of temporal graphs. Such generalisation relies on the natural\nextension of (bidimensional) relational data by the addition of a third\ntemporal dimension. Moreover, we introduce an information-theoretic measure to\nquantify and to control the information that is lost during compression, as\nwell as an algebraic characterisation of the space of possible compression\npatterns to enhance the expressiveness of the initial compression scheme. These\ncontributions lead to the definition of a combinatorial optimisation problem,\nthat is the Lossy Multistream Compression Problem, for which we provide an\nexact algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 11:48:37 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Lamarche-Perrin", "Robin", ""]]}, {"id": "1807.06906", "submitter": "Arber Zela", "authors": "Arber Zela, Aaron Klein, Stefan Falkner and Frank Hutter", "title": "Towards Automated Deep Learning: Efficient Joint Neural Architecture and\n  Hyperparameter Search", "comments": "11 pages, 3 figures, 3 tables, ICML 2018 AutoML Workshop", "journal-ref": "ICML 2018 AutoML Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing work on neural architecture search (NAS) tunes hyperparameters\nin a separate post-processing step, we demonstrate that architectural choices\nand other hyperparameter settings interact in a way that can render this\nseparation suboptimal. Likewise, we demonstrate that the common practice of\nusing very few epochs during the main NAS and much larger numbers of epochs\nduring a post-processing step is inefficient due to little correlation in the\nrelative rankings for these two training regimes. To combat both of these\nproblems, we propose to use a recent combination of Bayesian optimization and\nHyperband for efficient joint neural architecture and hyperparameter search.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:11:08 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Zela", "Arber", ""], ["Klein", "Aaron", ""], ["Falkner", "Stefan", ""], ["Hutter", "Frank", ""]]}, {"id": "1807.06918", "submitter": "Joeran Beel", "authors": "Joeran Beel and Barry Smyth and Andrew Collins", "title": "RARD II: The 94 Million Related-Article Recommendation Dataset", "comments": null, "journal-ref": "1st Workshop on Algorithm Selection and Meta-Learning in\n  Information Retrieval (AMIR). 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is to introduce and describe a new\nrecommender-systems dataset (RARD II). It is based on data from Mr. DLib, a\nrecommender-system as-a-service in the digital library and\nreference-management-software domain. As such, RARD II complements datasets\nfrom other domains such as books, movies, and music. The dataset encompasses\n94m recommendations, delivered in the two years from September 2016 to\nSeptember 2018. The dataset covers an item-space of 24m unique items. RARD II\nprovides a range of rich recommendation data, beyond conventional ratings. For\nexample, in addition to the usual (implicit) ratings matrices, RARD II includes\nthe original recommendation logs, which provide a unique insight into many\naspects of the algorithms that generated the recommendations. The logs enable\nresearchers to conduct various analyses about a real-world recommender system.\nThis includes the evaluation of meta-learning approaches for predicting\nalgorithm performance. In this paper, we summarise the key features of this\ndataset release, describe how it was generated and discuss some of its unique\nfeatures. Compared to its predecessor RARD, RARD II contains 64% more\nrecommendations, 187% more features (algorithms, parameters, and statistics),\n50% more clicks, 140% more documents, and one additional service partner\n(JabRef).\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:27:33 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 08:46:06 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:47:36 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Beel", "Joeran", ""], ["Smyth", "Barry", ""], ["Collins", "Andrew", ""]]}, {"id": "1807.06919", "submitter": "Cinjon Resnick", "authors": "Cinjon Resnick, Roberta Raileanu, Sanyam Kapoor, Alexander\n  Peysakhovich, Kyunghyun Cho, Joan Bruna", "title": "Backplay: \"Man muss immer umkehren\"", "comments": "AAAI-19 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) requires a large number of trials to\nlearn a good policy, especially in environments with sparse rewards. We explore\na method to improve the sample efficiency when we have access to\ndemonstrations. Our approach, Backplay, uses a single demonstration to\nconstruct a curriculum for a given task. Rather than starting each training\nepisode in the environment's fixed initial state, we start the agent near the\nend of the demonstration and move the starting point backwards during the\ncourse of training until we reach the initial state. Our contributions are that\nwe analytically characterize the types of environments where Backplay can\nimprove training speed, demonstrate the effectiveness of Backplay both in large\ngrid worlds and a complex four player zero-sum game (Pommerman), and show that\nBackplay compares favorably to other competitive methods known to improve\nsample efficiency. This includes reward shaping, behavioral cloning, and\nreverse curriculum generation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:28:59 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 21:09:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 20:13:45 GMT"}, {"version": "v4", "created": "Mon, 31 Dec 2018 15:16:18 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Resnick", "Cinjon", ""], ["Raileanu", "Roberta", ""], ["Kapoor", "Sanyam", ""], ["Peysakhovich", "Alexander", ""], ["Cho", "Kyunghyun", ""], ["Bruna", "Joan", ""]]}, {"id": "1807.06957", "submitter": "Peyman Tavallali", "authors": "Peyman Tavallali, Gary B. Doran Jr., Lukas Mandrake", "title": "Discrete linear-complexity reinforcement learning in continuous action\n  spaces for Q-learning algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we sketch an algorithm that extends the Q-learning\nalgorithms to the continuous action space domain. Our method is based on the\ndiscretization of the action space. Despite the commonly used discretization\nmethods, our method does not increase the discretized problem dimensionality\nexponentially. We will show that our proposed method is linear in complexity\nwhen the discretization is employed. The variant of the Q-learning algorithm\npresented in this work, labeled as Finite Step Q-Learning (FSQ), can be\ndeployed to both shallow and deep neural network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 22:57:11 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 20:14:30 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Tavallali", "Peyman", ""], ["Doran", "Gary B.", "Jr."], ["Mandrake", "Lukas", ""]]}, {"id": "1807.06978", "submitter": "Sixun Ouyang", "authors": "Sixun Ouyang and Aonghus Lawlor and Felipe Costa and Peter Dolog", "title": "Improving Explainable Recommendations with Synthetic Reviews", "comments": "Recsys DLRS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task for a recommender system to provide interpretable\nexplanations for the user. This is important for the credibility of the system.\nCurrent interpretable recommender systems tend to focus on certain features\nknown to be important to the user and offer their explanations in a structured\nform. It is well known that user generated reviews and feedback from reviewers\nhave strong leverage over the users' decisions. On the other hand, recent text\ngeneration works have been shown to generate text of similar quality to human\nwritten text, and we aim to show that generated text can be successfully used\nto explain recommendations.\n  In this paper, we propose a framework consisting of popular review-oriented\ngeneration models aiming to create personalised explanations for\nrecommendations. The interpretations are generated at both character and word\nlevels. We build a dataset containing reviewers' feedback from the Amazon books\nreview dataset. Our cross-domain experiments are designed to bridge from\nnatural language processing to the recommender system domain. Besides language\nmodel evaluation methods, we employ DeepCoNN, a novel review-oriented\nrecommender system using a deep neural network, to evaluate the recommendation\nperformance of generated reviews by root mean square error (RMSE). We\ndemonstrate that the synthetic personalised reviews have better recommendation\nperformance than human written reviews. To our knowledge, this presents the\nfirst machine-generated natural language explanations for rating prediction.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:42:35 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Ouyang", "Sixun", ""], ["Lawlor", "Aonghus", ""], ["Costa", "Felipe", ""], ["Dolog", "Peter", ""]]}, {"id": "1807.06981", "submitter": "Robin Vogel", "authors": "Robin Vogel, Aur\\'elien Bellet, St\\'ephan Cl\\'emen\\c{c}on", "title": "A Probabilistic Theory of Supervised Similarity Learning for Pointwise\n  ROC Curve Optimization", "comments": "8 pages main paper, 22 pages with appendices, proceedings of ICML\n  2018", "journal-ref": "PMLR 80 (2018) 5062-5071", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of many machine learning techniques depends on the choice of\nan appropriate similarity or distance measure on the input space. Similarity\nlearning (or metric learning) aims at building such a measure from training\ndata so that observations with the same (resp. different) label are as close\n(resp. far) as possible. In this paper, similarity learning is investigated\nfrom the perspective of pairwise bipartite ranking, where the goal is to rank\nthe elements of a database by decreasing order of the probability that they\nshare the same label with some query data point, based on the similarity\nscores. A natural performance criterion in this setting is pointwise ROC\noptimization: maximize the true positive rate under a fixed false positive\nrate. We study this novel perspective on similarity learning through a rigorous\nprobabilistic framework. The empirical version of the problem gives rise to a\nconstrained optimization formulation involving U-statistics, for which we\nderive universal learning rates as well as faster rates under a noise\nassumption on the data distribution. We also address the large-scale setting by\nanalyzing the effect of sampling-based approximations. Our theoretical results\nare supported by illustrative numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:47:54 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Vogel", "Robin", ""], ["Bellet", "Aur\u00e9lien", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "1807.06996", "submitter": "Choiru Za'in", "authors": "Mahardhika Pratama, Choiru Za'in, Eric Pardede", "title": "Evolving Large-Scale Data Stream Analytics based on Scalable PANFIS", "comments": "20 pages, 5 figures", "journal-ref": "Knowledge-based System, 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many distributed machine learning frameworks have recently been built to\nspeed up the large-scale data learning process. However, most distributed\nmachine learning used in these frameworks still uses an offline algorithm model\nwhich cannot cope with the data stream problems. In fact, large-scale data are\nmostly generated by the non-stationary data stream where its pattern evolves\nover time. To address this problem, we propose a novel Evolving Large-scale\nData Stream Analytics framework based on a Scalable Parsimonious Network based\non Fuzzy Inference System (Scalable PANFIS), where the PANFIS evolving\nalgorithm is distributed over the worker nodes in the cloud to learn\nlarge-scale data stream. Scalable PANFIS framework incorporates the active\nlearning (AL) strategy and two model fusion methods. The AL accelerates the\ndistributed learning process to generate an initial evolving large-scale data\nstream model (initial model), whereas the two model fusion methods aggregate an\ninitial model to generate the final model. The final model represents the\nupdate of current large-scale data knowledge which can be used to infer future\ndata. Extensive experiments on this framework are validated by measuring the\naccuracy and running time of four combinations of Scalable PANFIS and other\nSpark-based built in algorithms. The results indicate that Scalable PANFIS with\nAL improves the training time to be almost two times faster than Scalable\nPANFIS without AL. The results also show both rule merging and the voting\nmechanisms yield similar accuracy in general among Scalable PANFIS algorithms\nand they are generally better than Spark-based algorithms. In terms of running\ntime, the Scalable PANFIS training time outperforms all Spark-based algorithms\nwhen classifying numerous benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 15:36:06 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Za'in", "Choiru", ""], ["Pardede", "Eric", ""]]}, {"id": "1807.07024", "submitter": "Brennan Klein", "authors": "Stefano Balietti, Brennan Klein, Christoph Riedl", "title": "Optimal design of experiments to identify latent behavioral types", "comments": null, "journal-ref": "published in Experimental Economics (2020)", "doi": "10.1007/s10683-020-09680-w", "report-no": null, "categories": "stat.AP cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimal experiments that maximize the information gained from\ncollected data are critical to efficiently identify behavioral models. We\nextend a seminal method for designing Bayesian optimal experiments by\nintroducing two computational improvements that make the procedure tractable:\n(1) a search algorithm from artificial intelligence that efficiently explores\nthe space of possible design parameters, and (2) a sampling procedure which\nevaluates each design parameter combination more efficiently. We apply our\nprocedure to a game of imperfect information to evaluate and quantify the\ncomputational improvements. We then collect data across five different\nexperimental designs to compare the ability of the optimal experimental design\nto discriminate among competing behavioral models against the experimental\ndesigns chosen by a \"wisdom of experts\" prediction experiment. We find that\ndata from the experiment suggested by the optimal design approach requires\nsignificantly less data to distinguish behavioral models (i.e., test\nhypotheses) than data from the experiment suggested by experts. Substantively,\nwe find that reinforcement learning best explains human decision-making in the\nimperfect information game and that behavior is not adequately described by the\nBayesian Nash equilibrium. Our procedure is general and computationally\nefficient and can be applied to dynamically optimize online experiments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 09:14:37 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 23:59:53 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 21:31:32 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Balietti", "Stefano", ""], ["Klein", "Brennan", ""], ["Riedl", "Christoph", ""]]}, {"id": "1807.07049", "submitter": "Lerrel Pinto Mr", "authors": "Abhinav Gupta, Adithyavairavan Murali, Dhiraj Gandhi, Lerrel Pinto", "title": "Robot Learning in Homes: Improving Generalization and Reducing Dataset\n  Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches to solving robotic tasks have gained a lot of traction\nin recent years. However, most existing policies are trained on large-scale\ndatasets collected in curated lab settings. If we aim to deploy these models in\nunstructured visual environments like people's homes, they will be unable to\ncope with the mismatch in data distribution. In such light, we present the\nfirst systematic effort in collecting a large dataset for robotic grasping in\nhomes. First, to scale and parallelize data collection, we built a low cost\nmobile manipulator assembled for under 3K USD. Second, data collected using low\ncost robots suffer from noisy labels due to imperfect execution and calibration\nerrors. To handle this, we develop a framework which factors out the noise as a\nlatent variable. Our model is trained on 28K grasps collected in several houses\nunder an array of different environmental conditions. We evaluate our models by\nphysically executing grasps on a collection of novel objects in multiple unseen\nhomes. The models trained with our home dataset showed a marked improvement of\n43.7% over a baseline model trained with data collected in lab. Our\narchitecture which explicitly models the latent noise in the dataset also\nperformed 10% better than one that did not factor out the noise. We hope this\neffort inspires the robotics community to look outside the lab and embrace\nlearning based approaches to handle inaccurate cheap robots.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 17:25:28 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Gupta", "Abhinav", ""], ["Murali", "Adithyavairavan", ""], ["Gandhi", "Dhiraj", ""], ["Pinto", "Lerrel", ""]]}, {"id": "1807.07134", "submitter": "Sophia Sanborn", "authors": "Sophia Sanborn, David D. Bourgin, Michael Chang, Thomas L. Griffiths", "title": "Representational efficiency outweighs action efficiency in human program\n  induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of hierarchically structured representations for tractable\nplanning has long been acknowledged. However, the questions of how people\ndiscover such abstractions and how to define a set of optimal abstractions\nremain open. This problem has been explored in cognitive science in the problem\nsolving literature and in computer science in hierarchical reinforcement\nlearning. Here, we emphasize an algorithmic perspective on learning\nhierarchical representations in which the objective is to efficiently encode\nthe structure of the problem, or, equivalently, to learn an algorithm with\nminimal length. We introduce a novel problem-solving paradigm that links\nproblem solving and program induction under the Markov Decision Process (MDP)\nframework. Using this task, we target the question of whether humans discover\nhierarchical solutions by maximizing efficiency in number of actions they\ngenerate or by minimizing the complexity of the resulting representation and\nfind evidence for the primacy of representational efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 20:20:40 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Sanborn", "Sophia", ""], ["Bourgin", "David D.", ""], ["Chang", "Michael", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1807.07147", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov and Ivan P. Yamshchikov", "title": "Guess who? Multilingual approach for the automated generation of\n  author-stylized poetry", "comments": null, "journal-ref": null, "doi": "10.1109/SLT.2018.8639573", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of stylized text generation in a\nmultilingual setup. A version of a language model based on a long short-term\nmemory (LSTM) artificial neural network with extended phonetic and semantic\nembeddings is used for stylized poetry generation. The quality of the resulting\npoems generated by the network is estimated through bilingual evaluation\nunderstudy (BLEU), a survey and a new cross-entropy based metric that is\nsuggested for the problems of such type. The experiments show that the proposed\nmodel consistently outperforms random sample and vanilla-LSTM baselines, humans\nalso tend to associate machine generated texts with the target author.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 15:13:20 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 21:08:53 GMT"}, {"version": "v3", "created": "Mon, 17 Sep 2018 16:27:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1807.07186", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Katharina Kann and Hinrich Sch\\\"utze", "title": "Evaluating Word Embeddings in Multi-label Classification Using\n  Fine-grained Name Typing", "comments": "6 pages, The 3rd Workshop on Representation Learning for NLP\n  (RepL4NLP @ ACL2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models typically associate each word with a single real-valued\nvector, representing its different properties. Evaluation methods, therefore,\nneed to analyze the accuracy and completeness of these properties in\nembeddings. This requires fine-grained analysis of embedding subspaces.\nMulti-label classification is an appropriate way to do so. We propose a new\nevaluation method for word embeddings based on multi-label classification given\na word embedding. The task we use is fine-grained name typing: given a large\ncorpus, find all types that a name can refer to based on the name embedding.\nGiven the scale of entities in knowledge bases, we can build datasets for this\ntask that are complementary to the current embedding evaluation datasets in:\nthey are very large, contain fine-grained classes, and allow the direct\nevaluation of embeddings without confounding factors like sentence context\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 23:38:08 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Kann", "Katharina", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.07255", "submitter": "Wei Wu", "authors": "Can Xu, Wei Wu, Yu Wu", "title": "Towards Explainable and Controllable Open Domain Dialogue Generation\n  with Dialogue Acts", "comments": "The paper is also available on OpenReview of ICLR 2018\n  (https://openreview.net/forum?id=Bym0cU1CZ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study open domain dialogue generation with dialogue acts designed to\nexplain how people engage in social chat. To imitate human behavior, we propose\nmanaging the flow of human-machine interactions with the dialogue acts as\npolicies. The policies and response generation are jointly learned from\nhuman-human conversations, and the former is further optimized with a\nreinforcement learning approach. With the dialogue acts, we achieve significant\nimprovement over state-of-the-art methods on response quality for given\ncontexts and dialogue length in both machine-machine simulation and\nhuman-machine conversation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 06:41:05 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 01:45:32 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Xu", "Can", ""], ["Wu", "Wei", ""], ["Wu", "Yu", ""]]}, {"id": "1807.07281", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Jitong Chen", "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "comments": "Published at ICLR 2019. (v3: add important details & discussion in\n  Appendix A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new solution for parallel wave generation by\nWaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we\ndistill a Gaussian inverse autoregressive flow from the autoregressive WaveNet\nby minimizing a regularized KL divergence between their highly-peaked output\ndistributions. Our method computes the KL divergence in closed-form, which\nsimplifies the training algorithm and provides very efficient distillation. In\naddition, we introduce the first text-to-wave neural architecture for speech\nsynthesis, which is fully convolutional and enables fast end-to-end training\nfrom scratch. It significantly outperforms the previous pipeline that connects\na text-to-spectrogram model to a separately trained WaveNet (Ping et al.,\n2018). We also successfully distill a parallel waveform synthesizer conditioned\non the hidden representation in this end-to-end model.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:15:41 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 07:34:16 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 00:22:40 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Chen", "Jitong", ""]]}, {"id": "1807.07389", "submitter": "Felix Diaz Hermida", "authors": "F. D\\'iaz-Hermida, Juan. C. Vidal", "title": "Fuzzy quantification for linguistic data analysis and data mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy quantification is a subtopic of fuzzy logic which deals with the\nmodelling of the quantified expressions we can find in natural language. Fuzzy\nquantifiers have been successfully applied in several fields like fuzzy,\ncontrol, fuzzy databases, information retrieval, natural language generation,\netc. Their ability to model and evaluate linguistic expressions in a\nmathematical way, makes fuzzy quantifiers very powerful for data analytics and\ndata mining applications. In this paper we will give a general overview of the\nmain applications of fuzzy quantifiers in this field as well as some ideas to\nuse them in new application contexts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 13:22:01 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["D\u00edaz-Hermida", "F.", ""], ["Vidal", "Juan. C.", ""]]}, {"id": "1807.07404", "submitter": "Michaela Regneri", "authors": "Michaela Regneri, Malte Hoffmann, Jurij Kost, Niklas Pietsch, Timo\n  Schulz, and Sabine Stamm", "title": "Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine\n  Learning", "comments": "7 pages, presented as poster at IJCAI-ECAI Workshop on Explainable AI", "journal-ref": "Proceedings of the 2nd Workshop on Explainable Artificial\n  Intelligence (XAI 2018)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive geometric models deliver excellent results for many Machine\nLearning use cases. Despite their undoubted performance, neural predictive\nalgorithms can show unexpected degrees of instability and variance,\nparticularly when applied to large datasets. We present an approach to measure\nchanges in geometric models with respect to both output consistency and\ntopological stability. Considering the example of a recommender system using\nword2vec, we analyze the influence of single data points, approximation methods\nand parameter settings. Our findings can help to stabilize models where needed\nand to detect differences in informational value of data points on a large\nscale.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 14:02:14 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Regneri", "Michaela", ""], ["Hoffmann", "Malte", ""], ["Kost", "Jurij", ""], ["Pietsch", "Niklas", ""], ["Schulz", "Timo", ""], ["Stamm", "Sabine", ""]]}, {"id": "1807.07490", "submitter": "William Drozd", "authors": "William Drozd and Michael D. Wagner", "title": "FuzzerGym: A Competitive Framework for Fuzzing and Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzing is a commonly used technique designed to test software by\nautomatically crafting program inputs. Currently, the most successful fuzzing\nalgorithms emphasize simple, low-overhead strategies with the ability to\nefficiently monitor program state during execution. Through compile-time\ninstrumentation, these approaches have access to numerous aspects of program\nstate including coverage, data flow, and heterogeneous fault detection and\nclassification. However, existing approaches utilize blind random mutation\nstrategies when generating test inputs. We present a different approach that\nuses this state information to optimize mutation operators using reinforcement\nlearning (RL). By integrating OpenAI Gym with libFuzzer we are able to\nsimultaneously leverage advancements in reinforcement learning as well as\nfuzzing to achieve deeper coverage across several varied benchmarks. Our\ntechnique connects the rich, efficient program monitors provided by LLVM\nSantizers with a deep neural net to learn mutation selection strategies\ndirectly from the input data. The cross-language, asynchronous architecture we\ndeveloped enables us to apply any OpenAI Gym compatible deep reinforcement\nlearning algorithm to any fuzzing problem with minimal slowdown.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 15:22:35 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Drozd", "William", ""], ["Wagner", "Michael D.", ""]]}, {"id": "1807.07530", "submitter": "Thommen George Karimpanal", "authors": "Thommen George Karimpanal, Roland Bouffanais", "title": "Self-Organizing Maps as a Storage and Transfer Mechanism in\n  Reinforcement Learning", "comments": "7 pages, 7 figures, presented at ALA Workshop, FAIM, Stockholm, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of reusing information from previously learned tasks (source tasks)\nfor the learning of new tasks (target tasks) has the potential to significantly\nimprove the sample efficiency reinforcement learning agents. In this work, we\ndescribe an approach to concisely store and represent learned task knowledge,\nand reuse it by allowing it to guide the exploration of an agent while it\nlearns new tasks. In order to do so, we use a measure of similarity that is\ndefined directly in the space of parameterized representations of the value\nfunctions. This similarity measure is also used as a basis for a variant of the\ngrowing self-organizing map algorithm, which is simultaneously used to enable\nthe storage of previously acquired task knowledge in an adaptive and scalable\nmanner.We empirically validate our approach in a simulated navigation\nenvironment and discuss possible extensions to this approach along with\npotential applications where it could be particularly useful.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 16:49:51 GMT"}], "update_date": "2018-07-21", "authors_parsed": [["Karimpanal", "Thommen George", ""], ["Bouffanais", "Roland", ""]]}, {"id": "1807.07545", "submitter": "Jo\\~ao Loula", "authors": "Jo\\~ao Loula, Marco Baroni, Brenden M. Lake", "title": "Rearranging the Familiar: Testing Compositional Generalization in\n  Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic compositionality is the ability to recombine meaningful units with\nregular and predictable outcomes, and it's seen as key to humans' capacity for\ngeneralization in language. Recent work has studied systematic compositionality\nin modern seq2seq models using generalization to novel navigation instructions\nin a grounded environment as a probing tool, requiring models to quickly\nbootstrap the meaning of new words. We extend this framework here to settings\nwhere the model needs only to recombine well-trained functional words (such as\n\"around\" and \"right\") in novel contexts. Our findings confirm and strengthen\nthe earlier ones: seq2seq models can be impressively good at generalizing to\nnovel combinations of previously-seen input, but only when they receive\nextensive training on the specific pattern to be generalized (e.g.,\ngeneralizing from many examples of \"X around right\" to \"jump around right\"),\nwhile failing when generalization requires novel application of compositional\nrules (e.g., inferring the meaning of \"around right\" from those of \"right\" and\n\"around\").\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:23:13 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Loula", "Jo\u00e3o", ""], ["Baroni", "Marco", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1807.07560", "submitter": "Samaneh Azadi", "authors": "Samaneh Azadi, Deepak Pathak, Sayna Ebrahimi, Trevor Darrell", "title": "Compositional GAN: Learning Image-Conditional Binary Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can produce images of remarkable\ncomplexity and realism but are generally structured to sample from a single\nlatent source ignoring the explicit spatial interaction between multiple\nentities that could be present in a scene. Capturing such complex interactions\nbetween different objects in the world, including their relative scaling,\nspatial layout, occlusion, or viewpoint transformation is a challenging\nproblem. In this work, we propose a novel self-consistent\nComposition-by-Decomposition (CoDe) network to compose a pair of objects. Given\nobject images from two distinct distributions, our model can generate a\nrealistic composite image from their joint distribution following the texture\nand shape of the input objects. We evaluate our approach through qualitative\nexperiments and user evaluations. Our results indicate that the learned model\ncaptures potential interactions between the two object domains, and generates\nrealistic composed scenes at test time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 17:57:16 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 09:12:37 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 17:04:47 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Azadi", "Samaneh", ""], ["Pathak", "Deepak", ""], ["Ebrahimi", "Sayna", ""], ["Darrell", "Trevor", ""]]}, {"id": "1807.07665", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Junhyuk Oh, Honglak Lee", "title": "Hierarchical Reinforcement Learning for Zero-shot Generalization with\n  Subtask Dependencies", "comments": "In NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new RL problem where the agent is required to generalize to a\npreviously-unseen environment characterized by a subtask graph which describes\na set of subtasks and their dependencies. Unlike existing hierarchical\nmultitask RL approaches that explicitly describe what the agent should do at a\nhigh level, our problem only describes properties of subtasks and relationships\namong them, which requires the agent to perform complex reasoning to find the\noptimal subtask to execute. To solve this problem, we propose a neural subtask\ngraph solver (NSGS) which encodes the subtask graph using a recursive neural\nnetwork embedding. To overcome the difficulty of training, we propose a novel\nnon-parametric gradient-based policy, graph reward propagation, to pre-train\nour NSGS agent and further finetune it through actor-critic method. The\nexperimental results on two 2D visual domains show that our agent can perform\ncomplex reasoning to find a near-optimal way of executing the subtask graph and\ngeneralize well to the unseen subtask graphs. In addition, we compare our agent\nwith a Monte-Carlo tree search (MCTS) method showing that our method is much\nmore efficient than MCTS, and the performance of NSGS can be further improved\nby combining it with MCTS.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 23:51:55 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 05:00:38 GMT"}, {"version": "v3", "created": "Sat, 1 Dec 2018 20:52:03 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 22:10:33 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Sohn", "Sungryull", ""], ["Oh", "Junhyuk", ""], ["Lee", "Honglak", ""]]}, {"id": "1807.07789", "submitter": "Aur\\'elien Bellet", "authors": "Kuan Liu and Aur\\'elien Bellet", "title": "Escaping the Curse of Dimensionality in Similarity Learning: Efficient\n  Frank-Wolfe Algorithm and Generalization Bounds", "comments": "Long version of arXiv:1411.2374 (AISTATS 2015), to appear in\n  Neurocomputing. Matlab code: https://github.com/bellet/HDSL", "journal-ref": null, "doi": "10.1016/j.neucom.2018.12.060", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity and metric learning provides a principled approach to construct a\ntask-specific similarity from weakly supervised data. However, these methods\nare subject to the curse of dimensionality: as the number of features grows\nlarge, poor generalization is to be expected and training becomes intractable\ndue to high computational and memory costs. In this paper, we propose a\nsimilarity learning method that can efficiently deal with high-dimensional\nsparse data. This is achieved through a parameterization of similarity\nfunctions by convex combinations of sparse rank-one matrices, together with the\nuse of a greedy approximate Frank-Wolfe algorithm which provides an efficient\nway to control the number of active features. We show that the convergence rate\nof the algorithm, as well as its time and memory complexity, are independent of\nthe data dimension. We further provide a theoretical justification of our\nmodeling choices through an analysis of the generalization error, which depends\nlogarithmically on the sparsity of the solution rather than on the number of\nfeatures. Our experiments on datasets with up to one million features\ndemonstrate the ability of our approach to generalize well despite the high\ndimensionality as well as its superiority compared to several competing\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 11:18:00 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 09:35:34 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 21:46:38 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 17:02:07 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Liu", "Kuan", ""], ["Bellet", "Aur\u00e9lien", ""]]}, {"id": "1807.07896", "submitter": "Gabriele Carcassi", "authors": "Gabriele Carcassi, Christine A. Aidala", "title": "Towards a general mathematical theory of experimental science", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We lay the groundwork for a formal framework that studies scientific theories\nand can serve as a unified foundation for the different theories within\nphysics. We define a scientific theory as a set of verifiable statements,\nassertions that can be shown to be true with an experimental test in finite\ntime. By studying the algebra of such objects, we show that verifiability\nalready provides severe constraints. In particular, it requires that a set of\nphysically distinguishable cases is naturally equipped with the mathematical\nstructures (i.e. second-countable Kolmogorov topologies and $\\sigma$-algebras)\nthat form the foundation of manifold theory, differential geometry, measure\ntheory, probability theory and all the major branches of mathematics currently\nused in physics. This gives a clear physical meaning to those mathematical\nstructures and provides a strong justification for their use in science. Most\nimportantly it provides a formal framework to incorporate additional\nassumptions and constrain the search space for new physical theories.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 14:05:43 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 15:32:58 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Carcassi", "Gabriele", ""], ["Aidala", "Christine A.", ""]]}, {"id": "1807.07957", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi and Souma Chowdhury", "title": "Decentralized Task Allocation in Multi-Robot Systems via Bipartite Graph\n  Matching Augmented with Fuzzy Clustering", "comments": "The ASME 2018 International Design Engineering Technical Conferences\n  & Computers and Information in Engineering Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic systems, working together as a team, are becoming valuable players in\ndifferent real-world applications, from disaster response to warehouse\nfulfillment services. Centralized solutions for coordinating multi-robot teams\noften suffer from poor scalability and vulnerability to communication\ndisruptions. This paper develops a decentralized multi-agent task allocation\n(Dec-MATA) algorithm for multi-robot applications. The task planning problem is\nposed as a maximum-weighted matching of a bipartite graph, the solution of\nwhich using the blossom algorithm allows each robot to autonomously identify\nthe optimal sequence of tasks it should undertake. The graph weights are\ndetermined based on a soft clustering process, which also plays a problem\ndecomposition role seeking to reduce the complexity of the individual-agents'\ntask assignment problems. To evaluate the new Dec-MATA algorithm, a series of\ncase studies (of varying complexity) are performed, with tasks being\ndistributed randomly over an observable 2D environment. A centralized approach,\nbased on a state-of-the-art MILP formulation of the multi-Traveling Salesman\nproblem is used for comparative analysis. While getting within 7-28% of the\noptimal cost obtained by the centralized algorithm, the Dec-MATA algorithm is\nfound to be 1-3 orders of magnitude faster and minimally sensitive to\ntask-to-robot ratios, unlike the centralized algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 17:59:58 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Ghassemi", "Payam", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1807.07964", "submitter": "Minjeong Kim", "authors": "Minjeong Kim, David Keetae Park, Hyungjong Noh, Yeonsoo Lee and Jaegul\n  Choo", "title": "Question-Aware Sentence Gating Networks for Question and Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine comprehension question answering, which finds an answer to the\nquestion given a passage, involves high-level reasoning processes of\nunderstanding and tracking the relevant contents across various semantic units\nsuch as words, phrases, and sentences in a document. This paper proposes the\nnovel question-aware sentence gating networks that directly incorporate the\nsentence-level information into word-level encoding processes. To this end, our\nmodel first learns question-aware sentence representations and then dynamically\ncombines them with word-level representations, resulting in semantically\nmeaningful word representations for QA tasks. Experimental results demonstrate\nthat our approach consistently improves the accuracy over existing baseline\napproaches on various QA datasets and bears the wide applicability to other\nneural network-based QA models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 07:35:43 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kim", "Minjeong", ""], ["Park", "David Keetae", ""], ["Noh", "Hyungjong", ""], ["Lee", "Yeonsoo", ""], ["Choo", "Jaegul", ""]]}, {"id": "1807.07984", "submitter": "John Boaz Lee", "authors": "John Boaz Lee, Ryan A. Rossi, Sungchul Kim, Nesreen K. Ahmed, Eunyee\n  Koh", "title": "Attention Models in Graphs: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data arise naturally in many different application domains.\nBy representing data as graphs, we can capture entities (i.e., nodes) as well\nas their relationships (i.e., edges) with each other. Many useful insights can\nbe derived from graph-structured data as demonstrated by an ever-growing body\nof work focused on graph mining. However, in the real-world, graphs can be both\nlarge - with many complex patterns - and noisy which can pose a problem for\neffective graph mining. An effective way to deal with this issue is to\nincorporate \"attention\" into graph mining solutions. An attention mechanism\nallows a method to focus on task-relevant parts of the graph, helping it to\nmake better decisions. In this work, we conduct a comprehensive and focused\nsurvey of the literature on the emerging field of graph attention models. We\nintroduce three intuitive taxonomies to group existing work. These are based on\nproblem setting (type of input and output), the type of attention mechanism\nused, and the task (e.g., graph classification, link prediction, etc.). We\nmotivate our taxonomies through detailed examples and use each to survey\ncompeting approaches from a unique standpoint. Finally, we highlight several\nchallenges in the area and discuss promising directions for future work.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:11:07 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Lee", "John Boaz", ""], ["Rossi", "Ryan A.", ""], ["Kim", "Sungchul", ""], ["Ahmed", "Nesreen K.", ""], ["Koh", "Eunyee", ""]]}, {"id": "1807.07991", "submitter": "Oshani Seneviratne", "authors": "Oshani Seneviratne, Sabbir M. Rashid, Shruthi Chari, James P.\n  McCusker, Kristin P. Bennett, James A. Hendler, and Deborah L. McGuinness", "title": "Knowledge Integration for Disease Characterization: A Breast Cancer\n  Example", "comments": "International Semantic Web Conference (Resource Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advancements in cancer research, the information that is\nuseful for characterizing disease, staging tumors, and creating treatment and\nsurvivorship plans has been changing at a pace that creates challenges when\nphysicians try to remain current. One example involves increasing usage of\nbiomarkers when characterizing the pathologic prognostic stage of a breast\ntumor. We present our semantic technology approach to support cancer\ncharacterization and demonstrate it in our end-to-end prototype system that\ncollects the newest breast cancer staging criteria from authoritative oncology\nmanuals to construct an ontology for breast cancer. Using a tool we developed\nthat utilizes this ontology, physician-facing applications can be used to\nquickly stage a new patient to support identifying risks, treatment options,\nand monitoring plans based on authoritative and best practice guidelines.\nPhysicians can also re-stage existing patients or patient populations, allowing\nthem to find patients whose stage has changed in a given patient cohort. As new\nguidelines emerge, using our proposed mechanism, which is grounded by semantic\ntechnologies for ingesting new data from staging manuals, we have created an\nenriched cancer staging ontology that integrates relevant data from several\nsources with very little human intervention.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 18:26:29 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Seneviratne", "Oshani", ""], ["Rashid", "Sabbir M.", ""], ["Chari", "Shruthi", ""], ["McCusker", "James P.", ""], ["Bennett", "Kristin P.", ""], ["Hendler", "James A.", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1807.08048", "submitter": "Haoyang Fan", "authors": "Haoyang Fan, Fan Zhu, Changchun Liu, Liangliang Zhang, Li Zhuang, Dong\n  Li, Weicheng Zhu, Jiangtao Hu, Hongye Li, Qi Kong", "title": "Baidu Apollo EM Motion Planner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we introduce a real-time motion planning system based on\nthe Baidu Apollo (open source) autonomous driving platform. The developed\nsystem aims to address the industrial level-4 motion planning problem while\nconsidering safety, comfort and scalability. The system covers multilane and\nsingle-lane autonomous driving in a hierarchical manner: (1) The top layer of\nthe system is a multilane strategy that handles lane-change scenarios by\ncomparing lane-level trajectories computed in parallel. (2) Inside the\nlane-level trajectory generator, it iteratively solves path and speed\noptimization based on a Frenet frame. (3) For path and speed optimization, a\ncombination of dynamic programming and spline-based quadratic programming is\nproposed to construct a scalable and easy-to-tune framework to handle traffic\nrules, obstacle decisions and smoothness simultaneously. The planner is\nscalable to both highway and lower-speed city driving scenarios. We also\ndemonstrate the algorithm through scenario illustrations and on-road test\nresults.\n  The system described in this manuscript has been deployed to dozens of Baidu\nApollo autonomous driving vehicles since Apollo v1.5 was announced in September\n2017. As of May 16th, 2018, the system has been tested under 3,380 hours and\napproximately 68,000 kilometers (42,253 miles) of closed-loop autonomous\ndriving under various urban scenarios.\n  The algorithm described in this manuscript is available at\nhttps://github.com/ApolloAuto/apollo/tree/master/modules/planning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 22:34:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Fan", "Haoyang", ""], ["Zhu", "Fan", ""], ["Liu", "Changchun", ""], ["Zhang", "Liangliang", ""], ["Zhuang", "Li", ""], ["Li", "Dong", ""], ["Zhu", "Weicheng", ""], ["Hu", "Jiangtao", ""], ["Li", "Hongye", ""], ["Kong", "Qi", ""]]}, {"id": "1807.08058", "submitter": "Markus N Rabe", "authors": "Gil Lederman and Markus N. Rabe and Edward A. Lee and Sanjit A. Seshia", "title": "Learning Heuristics for Quantified Boolean Formulas through Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how to learn efficient heuristics for automated reasoning\nalgorithms for quantified Boolean formulas through deep reinforcement learning.\nWe focus on a backtracking search algorithm, which can already solve formulas\nof impressive size - up to hundreds of thousands of variables. The main\nchallenge is to find a representation of these formulas that lends itself to\nmaking predictions in a scalable way. For a family of challenging problems, we\nlearned a heuristic that solves significantly more formulas compared to the\nexisting handwritten heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 23:59:36 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:23:14 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 19:38:45 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Lederman", "Gil", ""], ["Rabe", "Markus N.", ""], ["Lee", "Edward A.", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1807.08060", "submitter": "Arushi Jain", "authors": "Arushi Jain, Khimya Khetarpal, Doina Precup", "title": "Safe Option-Critic: Learning Safety in the Option-Critic Architecture", "comments": "To appear at The Knowledge Engineering Review (KER), 2021. Previous\n  draft appeared in Adaptive Learning Agents (ALA) 2018 workshop held at ICML,\n  AAMAS in Stockholm. Corrected typos, added references and added extra figures", "journal-ref": "The Knowledge Engineering Review 36 (2021) e4", "doi": "10.1017/S0269888921000035", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing hierarchical reinforcement learning algorithms that exhibit safe\nbehaviour is not only vital for practical applications but also, facilitates a\nbetter understanding of an agent's decisions. We tackle this problem in the\noptions framework, a particular way to specify temporally abstract actions\nwhich allow an agent to use sub-policies with start and end conditions. We\nconsider a behaviour as safe that avoids regions of state-space with high\nuncertainty in the outcomes of actions. We propose an optimization objective\nthat learns safe options by encouraging the agent to visit states with higher\nbehavioural consistency. The proposed objective results in a trade-off between\nmaximizing the standard expected return and minimizing the effect of model\nuncertainty in the return. We propose a policy gradient algorithm to optimize\nthe constrained objective function. We examine the quantitative and qualitative\nbehaviour of the proposed approach in a tabular grid-world, continuous-state\npuddle-world, and three games from the Arcade Learning Environment: Ms.Pacman,\nAmidar, and Q*Bert. Our approach achieves a reduction in the variance of\nreturn, boosts performance in environments with intrinsic variability in the\nreward structure, and compares favorably both with primitive actions as well as\nwith risk-neutral options.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 00:39:23 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 11:07:34 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Jain", "Arushi", ""], ["Khetarpal", "Khimya", ""], ["Precup", "Doina", ""]]}, {"id": "1807.08133", "submitter": "John Kelleher", "authors": "John D. Kelleher and Simon Dobnik", "title": "What is not where: the challenge of integrating spatial representations\n  into deep learning architectures", "comments": "15 pages, 10 figures, Appears in CLASP Papers in Computational\n  Linguistics Vol 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017), pp. 41-52", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines to what degree current deep learning architectures for\nimage caption generation capture spatial language. On the basis of the\nevaluation of examples of generated captions from the literature we argue that\nsystems capture what objects are in the image data but not where these objects\nare located: the captions generated by these systems are the output of a\nlanguage model conditioned on the output of an object detector that cannot\ncapture fine-grained location information. Although language models provide\nuseful knowledge for image captions, we argue that deep learning image\ncaptioning architectures should also model geometric relations between objects.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:55:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kelleher", "John D.", ""], ["Dobnik", "Simon", ""]]}, {"id": "1807.08169", "submitter": "Jibon Naher", "authors": "Matiur Rahman Minar, Jibon Naher", "title": "Recent Advances in Deep Learning: An Overview", "comments": "31 pages including bibliography", "journal-ref": null, "doi": "10.13140/RG.2.2.24831.10403", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is one of the newest trends in Machine Learning and Artificial\nIntelligence research. It is also one of the most popular scientific research\ntrends now-a-days. Deep learning methods have brought revolutionary advances in\ncomputer vision and machine learning. Every now and then, new and new deep\nlearning techniques are being born, outperforming state-of-the-art machine\nlearning and even existing deep learning techniques. In recent years, the world\nhas seen many major breakthroughs in this field. Since deep learning is\nevolving at a huge speed, its kind of hard to keep track of the regular\nadvances especially for new researchers. In this paper, we are going to briefly\ndiscuss about recent advances in Deep Learning for past few years.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 15:40:10 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Minar", "Matiur Rahman", ""], ["Naher", "Jibon", ""]]}, {"id": "1807.08173", "submitter": "Alberto Rossi", "authors": "Alberto Rossi, Gianni Barlacchi, Monica Bianchini, Bruno Lepri", "title": "Modeling Taxi Drivers' Behaviour for the Next Destination Prediction", "comments": "preprint version of a paper submitted to IEEE Transactions on\n  Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to model taxi drivers' behaviour and geographical\ninformation for an interesting and challenging task: the next destination\nprediction in a taxi journey. Predicting the next location is a well studied\nproblem in human mobility, which finds several applications in real-world\nscenarios, from optimizing the efficiency of electronic dispatching systems to\npredicting and reducing the traffic jam. This task is normally modeled as a\nmulticlass classification problem, where the goal is to select, among a set of\nalready known locations, the next taxi destination. We present a Recurrent\nNeural Network (RNN) approach that models the taxi drivers' behaviour and\nencodes the semantics of visited locations by using geographical information\nfrom Location-Based Social Networks (LBSNs). In particular, RNNs are trained to\npredict the exact coordinates of the next destination, overcoming the problem\nof producing, in output, a limited set of locations, seen during the training\nphase. The proposed approach was tested on the ECML/PKDD Discovery Challenge\n2015 dataset - based on the city of Porto -, obtaining better results with\nrespect to the competition winner, whilst using less information, and on\nManhattan and San Francisco datasets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 16:31:03 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 10:34:48 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Rossi", "Alberto", ""], ["Barlacchi", "Gianni", ""], ["Bianchini", "Monica", ""], ["Lepri", "Bruno", ""]]}, {"id": "1807.08195", "submitter": "Tshilidzi Marwala", "authors": "Bo Xing and Tshilidzi Marwala", "title": "Creativity and Artificial Intelligence: A Digital Art Perspective", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the application of artificial intelligence to the\ncreation of digital art. AI is a computational paradigm that codifies\nintelligence into machines. There are generally three types of artificial\nintelligence and these are machine learning, evolutionary programming and soft\ncomputing. Machine learning is the statistical approach to building intelligent\nsystems. Evolutionary programming is the use of natural evolutionary systems to\ndesign intelligent machines. Some of the evolutionary programming systems\ninclude genetic algorithm which is inspired by the principles of evolution and\nswarm optimization which is inspired by the swarming of birds, fish, ants etc.\nSoft computing includes techniques such as agent based modelling and fuzzy\nlogic. Opportunities on the applications of these to digital art are explored.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 19:37:25 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Xing", "Bo", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "1807.08204", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "Towards Neural Theorem Proving at Scale", "comments": "Federated Artificial Intelligence Meeting (FAIM) Workshop on Neural\n  Abstract Machines & Program Induction v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models combining representation learning and reasoning in an\nend-to-end trainable manner are receiving increasing interest. However, their\nuse is severely limited by their computational complexity, which renders them\nunusable on real world datasets. We focus on the Neural Theorem Prover (NTP)\nmodel proposed by Rockt{\\\"{a}}schel and Riedel (2017), a continuous relaxation\nof the Prolog backward chaining algorithm where unification between terms is\nreplaced by the similarity between their embedding representations. For\nanswering a given query, this model needs to consider all possible proof paths,\nand then aggregate results - this quickly becomes infeasible even for small\nKnowledge Bases (KBs). We observe that we can accurately approximate the\ninference process in this model by considering only proof paths associated with\nthe highest proof scores. This enables inference and learning on previously\nimpracticable KBs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 20:48:53 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Minervini", "Pasquale", ""], ["Bosnjak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1807.08217", "submitter": "Keerthana P G", "authors": "Basel Alghanem, Keerthana P G", "title": "Asynchronous Advantage Actor-Critic Agent for Starcraft II", "comments": "arXiv admin note: text overlap with arXiv:1708.04782 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning, and especially the Asynchronous Advantage\nActor-Critic algorithm, has been successfully used to achieve super-human\nperformance in a variety of video games. Starcraft II is a new challenge for\nthe reinforcement learning community with the release of pysc2 learning\nenvironment proposed by Google Deepmind and Blizzard Entertainment. Despite\nbeing a target for several AI developers, few have achieved human level\nperformance. In this project we explain the complexities of this environment\nand discuss the results from our experiments on the environment. We have\ncompared various architectures and have proved that transfer learning can be an\neffective paradigm in reinforcement learning research for complex scenarios\nrequiring skill transfer.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 01:07:43 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Alghanem", "Basel", ""], ["G", "Keerthana P", ""]]}, {"id": "1807.08229", "submitter": "Nisar Ahmed", "authors": "Luke Burks, Ian Loefgren, Nisar Ahmed", "title": "Optimal Continuous State POMDP Planning with Semantic Observations: A\n  Variational Approach", "comments": "Final version accepted to IEEE Transactions on Robotics (in press as\n  of August 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops novel strategies for optimal planning with semantic\nobservations using continuous state partially observable markov decision\nprocesses (CPOMDPs). Two major innovations are presented in relation to\nGaussian mixture (GM) CPOMDP policy approximation methods. While existing\nmethods have many desirable theoretical properties, they are unable to\nefficiently represent and reason over hybrid continuous-discrete probabilistic\nmodels. The first major innovation is the derivation of closed-form variational\nBayes GM approximations of Point-Based Value Iteration Bellman policy backups,\nusing softmax models of continuous-discrete semantic observation probabilities.\nA key benefit of this approach is that dynamic decision-making tasks can be\nperformed with complex non-Gaussian uncertainties, while also exploiting\ncontinuous dynamic state space models (thus avoiding cumbersome and costly\ndiscretization). The second major innovation is a new clustering-based\ntechnique for mixture condensation that scales well to very large GM policy\nfunctions and belief functions. Simulation results for a target search and\ninterception task with semantic observations show that the GM policies\nresulting from these innovations are more effective than those produced by\nother state of the art policy approximations, but require significantly less\nmodeling overhead and online runtime cost. Additional results show the\nrobustness of this approach to model errors and scaling to higher dimensions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 03:19:41 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 22:03:41 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Burks", "Luke", ""], ["Loefgren", "Ian", ""], ["Ahmed", "Nisar", ""]]}, {"id": "1807.08237", "submitter": "Xingjun Ma", "authors": "Yisen Wang, Bo Dai, Lingkai Kong, Sarah Monazam Erfani, James Bailey,\n  Hongyuan Zha", "title": "Learning Deep Hidden Nonlinear Dynamics from Aggregate Data", "comments": "In Proceedings of the Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning nonlinear dynamics from diffusion data is a challenging problem\nsince the individuals observed may be different at different time points,\ngenerally following an aggregate behaviour. Existing work cannot handle the\ntasks well since they model such dynamics either directly on observations or\nenforce the availability of complete longitudinal individual-level\ntrajectories. However, in most of the practical applications, these\nrequirements are unrealistic: the evolving dynamics may be too complex to be\nmodeled directly on observations, and individual-level trajectories may not be\navailable due to technical limitations, experimental costs and/or privacy\nissues. To address these challenges, we formulate a model of diffusion dynamics\nas the {\\em hidden stochastic process} via the introduction of hidden variables\nfor flexibility, and learn the hidden dynamics directly on {\\em aggregate\nobservations} without any requirement for individual-level trajectories. We\npropose a dynamic generative model with Wasserstein distance for LEarninG dEep\nhidden Nonlinear Dynamics (LEGEND) and prove its theoretical guarantees as\nwell. Experiments on a range of synthetic and real-world datasets illustrate\nthat LEGEND has very strong performance compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 05:59:41 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 12:07:43 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Wang", "Yisen", ""], ["Dai", "Bo", ""], ["Kong", "Lingkai", ""], ["Erfani", "Sarah Monazam", ""], ["Bailey", "James", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1807.08265", "submitter": "Mark Scanlon", "authors": "Quan Le, Ois\\'in Boydell, Brian Mac Namee, Mark Scanlon", "title": "Deep learning at the shallow end: Malware classification for non-domain\n  experts", "comments": null, "journal-ref": "Digital Investigation, Volume 26, Supplement, 2018, Pages\n  S118-S126, ISSN 1742-2876", "doi": "10.1016/j.diin.2018.04.024", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current malware detection and classification approaches generally rely on\ntime consuming and knowledge intensive processes to extract patterns\n(signatures) and behaviors from malware, which are then used for\nidentification. Moreover, these signatures are often limited to local,\ncontiguous sequences within the data whilst ignoring their context in relation\nto each other and throughout the malware file as a whole. We present a Deep\nLearning based malware classification approach that requires no expert domain\nknowledge and is based on a purely data driven approach for complex pattern and\nfeature identification.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 10:07:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Le", "Quan", ""], ["Boydell", "Ois\u00edn", ""], ["Mac Namee", "Brian", ""], ["Scanlon", "Mark", ""]]}, {"id": "1807.08312", "submitter": "Mahdi Hajibabaei", "authors": "Mahdi Hajibabaei, Dengxin Dai", "title": "Unified Hypersphere Embedding for Speaker Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental improvements in accuracy of Convolutional Neural Networks are\nusually achieved through use of deeper and more complex models trained on\nlarger datasets. However, enlarging dataset and models increases the\ncomputation and storage costs and cannot be done indefinitely. In this work, we\nseek to improve the identification and verification accuracy of a\ntext-independent speaker recognition system without use of extra data or deeper\nand more complex models by augmenting the training and testing data, finding\nthe optimal dimensionality of embedding space and use of more discriminative\nloss functions. Results of experiments on VoxCeleb dataset suggest that: (i)\nSimple repetition and random time-reversion of utterances can reduce prediction\nerrors by up to 18%. (ii) Lower dimensional embeddings are more suitable for\nverification. (iii) Use of proposed logistic margin loss function leads to\nunified embeddings with state-of-the-art identification and competitive\nverification accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 16:26:31 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Hajibabaei", "Mahdi", ""], ["Dai", "Dengxin", ""]]}, {"id": "1807.08325", "submitter": "Ahmed Qureshi", "authors": "Zaid Tahir, Ahmed H. Qureshi, Yasar Ayaz and Raheel Nawaz", "title": "Potentially Guided Bidirectionalized RRT* for Fast Optimal Path Planning\n  in Cluttered Environments", "comments": null, "journal-ref": "Volume 108, Pages 13-27, 2018, Elsevier, Robotics and Autonomous\n  Systems", "doi": "10.1016/j.robot.2018.06.013", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly-exploring Random Tree star (RRT*) has recently gained immense\npopularity in the motion planning community as it provides a probabilistically\ncomplete and asymptotically optimal solution without requiring the complete\ninformation of the obstacle space. In spite of all of its advantages, RRT*\nconverges to an optimal solution very slowly. Hence to improve the convergence\nrate, its bidirectional variants were introduced, the Bi-directional RRT*\n(B-RRT*) and Intelligent Bi-directional RRT* (IB-RRT*). However, as both\nvariants perform pure exploration, they tend to suffer in highly cluttered\nenvironments. In order to overcome these limitations, we introduce a new\nconcept of potentially guided bidirectional trees in our proposed Potentially\nGuided Intelligent Bi-directional RRT* (PIB-RRT*) and Potentially Guided\nBi-directional RRT* (PB-RRT*). The proposed algorithms greatly improve the\nconvergence rate and have a more efficient memory utilization. Theoretical and\nexperimental evaluation of the proposed algorithms have been made and compared\nto the latest state of the art motion planning algorithms under different\nchallenging environmental conditions and have proven their remarkable\nimprovement in efficiency and convergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 17:27:56 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Tahir", "Zaid", ""], ["Qureshi", "Ahmed H.", ""], ["Ayaz", "Yasar", ""], ["Nawaz", "Raheel", ""]]}, {"id": "1807.08360", "submitter": "Lijun Yu", "authors": "Lijun Yu, Dawei Zhang, Xiangqun Chen, Xing Xie", "title": "MOBA-Slice: A Time Slice Based Evaluation Framework of Relative\n  Advantage between Teams in MOBA Games", "comments": "Computer Games Workshop at IJCAI 2018, Stockholm, Friday 13 July,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiplayer Online Battle Arena (MOBA) is currently one of the most popular\ngenres of digital games around the world. The domain of knowledge contained in\nthese complicated games is large. It is hard for humans and algorithms to\nevaluate the real-time game situation or predict the game result. In this\npaper, we introduce MOBA-Slice, a time slice based evaluation framework of\nrelative advantage between teams in MOBA games. MOBA-Slice is a quantitative\nevaluation method based on learning, similar to the value network of AlphaGo.\nIt establishes a foundation for further MOBA related research including AI\ndevelopment. In MOBA-Slice, with an analysis of the deciding factors of MOBA\ngame results, we design a neural network model to fit our discounted evaluation\nfunction. Then we apply MOBA-Slice to Defense of the Ancients 2 (DotA2), a\ntypical and popular MOBA game. Experiments on a large number of match replays\nshow that our model works well on arbitrary matches. MOBA-Slice not only has an\naccuracy 3.7% higher than DotA Plus Assistant at result prediction, but also\nsupports the prediction of the remaining time of the game, and then realizes\nthe evaluation of relative advantage between teams.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:20:43 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Yu", "Lijun", ""], ["Zhang", "Dawei", ""], ["Chen", "Xiangqun", ""], ["Xie", "Xing", ""]]}, {"id": "1807.08364", "submitter": "Kunal Menda", "authors": "Kunal Menda, Katherine Driggs-Campbell, Mykel J. Kochenderfer", "title": "EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning", "comments": "Accepted to the 2019 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While imitation learning is often used in robotics, the approach frequently\nsuffers from data mismatch and compounding errors. DAgger is an iterative\nalgorithm that addresses these issues by aggregating training data from both\nthe expert and novice policies, but does not consider the impact of safety. We\npresent a probabilistic extension to DAgger, which attempts to quantify the\nconfidence of the novice policy as a proxy for safety. Our method,\nEnsembleDAgger, approximates a Gaussian Process using an ensemble of neural\nnetworks. Using the variance as a measure of confidence, we compute a decision\nrule that captures how much we doubt the novice, thus determining when it is\nsafe to allow the novice to act. With this approach, we aim to maximize the\nnovice's share of actions, while constraining the probability of failure. We\ndemonstrate improved safety and learning performance compared to other DAgger\nvariants and classic imitation learning on an inverted pendulum and in the\nMuJoCo HalfCheetah environment.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 20:52:56 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 20:47:20 GMT"}, {"version": "v3", "created": "Fri, 19 Jul 2019 18:03:57 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Menda", "Kunal", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1807.08372", "submitter": "Jiaoyan Chen", "authors": "Jiaoyan Chen, Freddy Lecue, Jeff Z. Pan, Ian Horrocks, Huajun Chen", "title": "Knowledge-based Transfer Learning Explanation", "comments": "Accepted by International Conference on Principles of Knowledge\n  Representation and Reasoning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning explanation can significantly boost machine learning's\napplication in decision making, but the usability of current methods is limited\nin human-centric explanation, especially for transfer learning, an important\nmachine learning branch that aims at utilizing knowledge from one learning\ndomain (i.e., a pair of dataset and prediction task) to enhance prediction\nmodel training in another learning domain. In this paper, we propose an\nontology-based approach for human-centric explanation of transfer learning.\nThree kinds of knowledge-based explanatory evidence, with different\ngranularities, including general factors, particular narrators and core\ncontexts are first proposed and then inferred with both local ontologies and\nexternal knowledge bases. The evaluation with US flight data and DBpedia has\npresented their confidence and availability in explaining the transferability\nof feature representation in flight departure delay forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 21:32:12 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Chen", "Jiaoyan", ""], ["Lecue", "Freddy", ""], ["Pan", "Jeff Z.", ""], ["Horrocks", "Ian", ""], ["Chen", "Huajun", ""]]}, {"id": "1807.08405", "submitter": "Trent Houliston", "authors": "Trent Houliston and Stephan K. Chalup", "title": "Visual Mesh: Real-time Object Detection Using Constant Sample Density", "comments": "12 pages, 6 figures, RoboCup International Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an enhancement of convolutional neural networks for\nobject detection in resource-constrained robotics through a geometric input\ntransformation called Visual Mesh. It uses object geometry to create a graph in\nvision space, reducing computational complexity by normalizing the pixel and\nfeature density of objects. The experiments compare the Visual Mesh with\nseveral other fast convolutional neural networks. The results demonstrate\nexecution times sixteen times quicker than the fastest competitor tested, while\nachieving outstanding accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 02:21:31 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Houliston", "Trent", ""], ["Chalup", "Stephan K.", ""]]}, {"id": "1807.08430", "submitter": "Kang Dang Mr", "authors": "Kang Dang, Chunluan Zhou, Zhigang Tu, Michael Hoy, Justin Dauwels,\n  Junsong Yuan", "title": "Actor-Action Semantic Segmentation with Region Masks", "comments": "Accepted by BMVC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the actor-action semantic segmentation problem, which\nrequires joint labeling of both actor and action categories in video frames.\nOne major challenge for this task is that when an actor performs an action,\ndifferent body parts of the actor provide different types of cues for the\naction category and may receive inconsistent action labeling when they are\nlabeled independently. To address this issue, we propose an end-to-end\nregion-based actor-action segmentation approach which relies on region masks\nfrom an instance segmentation algorithm. Our main novelty is to avoid labeling\npixels in a region mask independently - instead we assign a single action label\nto these pixels to achieve consistent action labeling. When a pixel belongs to\nmultiple region masks, max pooling is applied to resolve labeling conflicts.\nOur approach uses a two-stream network as the front-end (which learns features\ncapturing both appearance and motion information), and uses two region-based\nsegmentation networks as the back-end (which takes the fused features from the\ntwo-stream network as the input and predicts actor-action labeling).\nExperiments on the A2D dataset demonstrate that both the region-based\nsegmentation strategy and the fused features from the two-stream network\ncontribute to the performance improvements. The proposed approach outperforms\nthe state-of-the-art results by more than 8% in mean class accuracy, and more\nthan 5% in mean class IOU, which validates its effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 05:11:23 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Dang", "Kang", ""], ["Zhou", "Chunluan", ""], ["Tu", "Zhigang", ""], ["Hoy", "Michael", ""], ["Dauwels", "Justin", ""], ["Yuan", "Junsong", ""]]}, {"id": "1807.08447", "submitter": "Rakshit Trivedi", "authors": "Rakshit Trivedi and Bunyamin Sisman and Jun Ma and Christos Faloutsos\n  and Hongyuan Zha and Xin Luna Dong", "title": "LinkNBed: Multi-Graph Representation Learning with Entity Linkage", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs have emerged as an important model for studying complex\nmulti-relational data. This has given rise to the construction of numerous\nlarge scale but incomplete knowledge graphs encoding information extracted from\nvarious resources. An effective and scalable approach to jointly learn over\nmultiple graphs and eventually construct a unified graph is a crucial next step\nfor the success of knowledge-based inference for many downstream applications.\nTo this end, we propose LinkNBed, a deep relational learning framework that\nlearns entity and relationship representations across multiple graphs. We\nidentify entity linkage across graphs as a vital component to achieve our goal.\nWe design a novel objective that leverage entity linkage and build an efficient\nmulti-task training procedure. Experiments on link prediction and entity\nlinkage demonstrate substantial improvements over the state-of-the-art\nrelational learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:47:57 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Trivedi", "Rakshit", ""], ["Sisman", "Bunyamin", ""], ["Ma", "Jun", ""], ["Faloutsos", "Christos", ""], ["Zha", "Hongyuan", ""], ["Dong", "Xin Luna", ""]]}, {"id": "1807.08452", "submitter": "Somnuk Phon-Amnuaisuk", "authors": "Somnuk Phon-Amnuaisuk", "title": "Learning to Play Pong using Policy Gradient Learning", "comments": "19 pages, 9 figures. Expanded from a conference paper titled 'What\n  does a policy network learn after mastering a Pong game?\" by the same author.\n  MIWAI 2017 pp. 213-222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activities in reinforcement learning (RL) revolve around learning the Markov\ndecision process (MDP) model, in particular, the following parameters: state\nvalues, V; state-action values, Q; and policy, pi. These parameters are\ncommonly implemented as an array. Scaling up the problem means scaling up the\nsize of the array and this will quickly lead to a computational bottleneck. To\nget around this, the RL problem is commonly formulated to learn a specific task\nusing hand-crafted input features to curb the size of the array. In this\nreport, we discuss an alternative end-to-end Deep Reinforcement Learning (DRL)\napproach where the DRL attempts to learn general task representations which in\nour context refers to learning to play the Pong game from a sequence of screen\nsnapshots without game-specific hand-crafted features. We apply artificial\nneural networks (ANN) to approximate a policy of the RL model. The policy\nnetwork, via Policy Gradients (PG) method, learns to play the Pong game from a\nsequence of frames without any extra semantics apart from the pixel information\nand the score. In contrast to the traditional tabular RL approach where the\ncontents in the array have clear interpretations such as V or Q, the\ninterpretation of knowledge content from the weights of the policy network is\nmore illusive. In this work, we experiment with various Deep ANN architectures\ni.e., Feed forward ANN (FFNN), Convolution ANN (CNN) and Asynchronous Advantage\nActor-Critic (A3C). We also examine the activation of hidden nodes and the\nweights between the input and the hidden layers, before and after the DRL has\nsuccessfully learnt to play the Pong game. Insights into the internal learning\nmechanisms and future research directions are then discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 06:55:23 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Phon-Amnuaisuk", "Somnuk", ""]]}, {"id": "1807.08484", "submitter": "Wang Ruijie", "authors": "Ruijie Wang, Yuchen Yan, Jialu Wang, Yuting Jia, Ye Zhang, Weinan\n  Zhang, Xinbing Wang", "title": "AceKG: A Large-scale Knowledge Graph for Academic Data Mining", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing knowledge graphs (KGs) in academic domains suffer from problems\nof insufficient multi-relational information, name ambiguity and improper data\nformat for large-scale machine processing. In this paper, we present AceKG, a\nnew large-scale KG in academic domain. AceKG not only provides clean academic\ninformation, but also offers a large-scale benchmark dataset for researchers to\nconduct challenging data mining projects including link prediction, community\ndetection and scholar classification. Specifically, AceKG describes 3.13\nbillion triples of academic facts based on a consistent ontology, including\nnecessary properties of papers, authors, fields of study, venues and\ninstitutes, as well as the relations among them. To enrich the proposed\nknowledge graph, we also perform entity alignment with existing databases and\nrule-based inference. Based on AceKG, we conduct experiments of three typical\nacademic data mining tasks and evaluate several state-of- the-art knowledge\nembedding and network representation learning approaches on the benchmark\ndatasets built from AceKG. Finally, we discuss several promising research\ndirections that benefit from AceKG.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:57:44 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 07:46:48 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wang", "Ruijie", ""], ["Yan", "Yuchen", ""], ["Wang", "Jialu", ""], ["Jia", "Yuting", ""], ["Zhang", "Ye", ""], ["Zhang", "Weinan", ""], ["Wang", "Xinbing", ""]]}, {"id": "1807.08595", "submitter": "Zhaohong Deng", "authors": "Te Zhang, Zhaohong Deng, Dongrui Wu, and Shitong Wang", "title": "Multi-View Fuzzy Logic System with the Cooperation between Visible and\n  Hidden Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view datasets are frequently encountered in learning tasks, such as web\ndata mining and multimedia information analysis. Given a multi-view dataset,\ntraditional learning algorithms usually decompose it into several single-view\ndatasets, from each of which a single-view model is learned. In contrast, a\nmulti-view learning algorithm can achieve better performance by cooperative\nlearning on the multi-view data. However, existing multi-view approaches mainly\nfocus on the views that are visible and ignore the hidden information behind\nthe visible views, which usually contains some intrinsic information of the\nmulti-view data, or vice versa. To address this problem, this paper proposes a\nmulti-view fuzzy logic system, which utilizes both the hidden information\nshared by the multiple visible views and the information of each visible view.\nExtensive experiments were conducted to validate its effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:25:37 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Zhang", "Te", ""], ["Deng", "Zhaohong", ""], ["Wu", "Dongrui", ""], ["Wang", "Shitong", ""]]}, {"id": "1807.08709", "submitter": "Emanuel Sallinger", "authors": "Luigi Bellomarini, Georg Gottlob, Emanuel Sallinger", "title": "The Vadalog System: Datalog-based Reasoning for Knowledge Graphs", "comments": "Extended version of VLDB paper\n  <https://doi.org/10.14778/3213880.3213888>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, there has been a resurgence of Datalog-based systems in\nthe database community as well as in industry. In this context, it has been\nrecognized that to handle the complex knowl\\-edge-based scenarios encountered\ntoday, such as reasoning over large knowledge graphs, Datalog has to be\nextended with features such as existential quantification. Yet, Datalog-based\nreasoning in the presence of existential quantification is in general\nundecidable. Many efforts have been made to define decidable fragments. Warded\nDatalog+/- is a very promising one, as it captures PTIME complexity while\nallowing ontological reasoning. Yet so far, no implementation of Warded\nDatalog+/- was available. In this paper we present the Vadalog system, a\nDatalog-based system for performing complex logic reasoning tasks, such as\nthose required in advanced knowledge graphs. The Vadalog system is Oxford's\ncontribution to the VADA research programme, a joint effort of the universities\nof Oxford, Manchester and Edinburgh and around 20 industrial partners. As the\nmain contribution of this paper, we illustrate the first implementation of\nWarded Datalog+/-, a high-performance Datalog+/- system utilizing an aggressive\ntermination control strategy. We also provide a comprehensive experimental\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:38:05 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bellomarini", "Luigi", ""], ["Gottlob", "Georg", ""], ["Sallinger", "Emanuel", ""]]}, {"id": "1807.08712", "submitter": "Emanuel Sallinger", "authors": "Luigi Bellomarini, Ruslan R. Fayzrakhmanov, Georg Gottlob, Andrey\n  Kravchenko, Eleonora Laurenza, Yavor Nenov, Stephane Reissfelder, Emanuel\n  Sallinger, Evgeny Sherkhonov, Lianlong Wu", "title": "Data Science with Vadalog: Bridging Machine Learning and Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent successful examples of large technology companies, many\nmodern enterprises seek to build knowledge graphs to provide a unified view of\ncorporate knowledge and to draw deep insights using machine learning and\nlogical reasoning. There is currently a perceived disconnect between the\ntraditional approaches for data science, typically based on machine learning\nand statistical modelling, and systems for reasoning with domain knowledge. In\nthis paper we present a state-of-the-art Knowledge Graph Management System,\nVadalog, which delivers highly expressive and efficient logical reasoning and\nprovides seamless integration with modern data science toolkits, such as the\nJupyter platform. We demonstrate how to use Vadalog to perform traditional data\nwrangling tasks, as well as complex logical and probabilistic reasoning. We\nargue that this is a significant step forward towards combining machine\nlearning and reasoning in data science.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 16:40:37 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bellomarini", "Luigi", ""], ["Fayzrakhmanov", "Ruslan R.", ""], ["Gottlob", "Georg", ""], ["Kravchenko", "Andrey", ""], ["Laurenza", "Eleonora", ""], ["Nenov", "Yavor", ""], ["Reissfelder", "Stephane", ""], ["Sallinger", "Emanuel", ""], ["Sherkhonov", "Evgeny", ""], ["Wu", "Lianlong", ""]]}, {"id": "1807.08856", "submitter": "Dylan Shell", "authors": "Fatemeh Zahra Saberifar, Shervin Ghasemlou, Dylan A. Shell, and Jason\n  M. O'Kane", "title": "Toward a language-theoretic foundation for planning and filtering", "comments": "Accepted to appear in IJRR Special Issue on WAFR'16. Keywords:\n  planning; combinatorial filter; design automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address problems underlying the algorithmic question of automating the\nco-design of robot hardware in tandem with its apposite software. Specifically,\nwe consider the impact that degradations of a robot's sensor and actuation\nsuites may have on the ability of that robot to complete its tasks. We\nintroduce a new formal structure that generalizes and consolidates a variety of\nwell-known structures including many forms of plans, planning problems, and\nfilters, into a single data structure called a procrustean graph, and give\nthese graph structures semantics in terms of ideas based in formal language\ntheory. We describe a collection of operations on procrustean graphs (both\nsemantics-preserving and semantics-mutating), and show how a family of\nquestions about the destructiveness of a change to the robot hardware can be\nanswered by applying these operations. We also highlight the connections\nbetween this new approach and existing threads of research, including\ncombinatorial filtering, Erdmann's strategy complexes, and hybrid automata.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 23:12:16 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Saberifar", "Fatemeh Zahra", ""], ["Ghasemlou", "Shervin", ""], ["Shell", "Dylan A.", ""], ["O'Kane", "Jason M.", ""]]}, {"id": "1807.08894", "submitter": "Lin Shao", "authors": "Lin Shao, Ye Tian, Jeannette Bohg", "title": "ClusterNet: 3D Instance Segmentation in RGB-D Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for instance-level segmentation that uses RGB-D data as\ninput and provides detailed information about the location, geometry and number\nof individual objects in the scene. This level of understanding is fundamental\nfor autonomous robots. It enables safe and robust decision-making under the\nlarge uncertainty of the real-world. In our model, we propose to use the first\nand second order moments of the object occupancy function to represent an\nobject instance. We train an hourglass Deep Neural Network (DNN) where each\npixel in the output votes for the 3D position of the corresponding object\ncenter and for the object's size and pose. The final instance segmentation is\nachieved through clustering in the space of moments. The object-centric\ntraining loss is defined on the output of the clustering. Our method\noutperforms the state-of-the-art instance segmentation method on our\nsynthesized dataset. We show that our method generalizes well on real-world\ndata achieving visually better segmentation results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 03:42:53 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 05:23:11 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Shao", "Lin", ""], ["Tian", "Ye", ""], ["Bohg", "Jeannette", ""]]}, {"id": "1807.08919", "submitter": "Maxwell Nye", "authors": "Luke B. Hewitt, Maxwell I. Nye, Andreea Gane, Tommi Jaakkola, Joshua\n  B. Tenenbaum", "title": "The Variational Homoencoder: Learning to learn high capacity generative\n  models from few examples", "comments": "UAI 2018 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Bayesian methods can unify many related tasks (e.g. k-shot\nclassification, conditional and unconditional generation) as inference within a\nsingle generative model. However, when this generative model is expressed as a\npowerful neural network such as a PixelCNN, we show that existing learning\ntechniques typically fail to effectively use latent variables. To address this,\nwe develop a modification of the Variational Autoencoder in which encoded\nobservations are decoded to new elements from the same class. This technique,\nwhich we call a Variational Homoencoder (VHE), produces a hierarchical latent\nvariable model which better utilises latent variables. We use the VHE framework\nto learn a hierarchical PixelCNN on the Omniglot dataset, which outperforms all\nexisting models on test set likelihood and achieves strong performance on\none-shot generation and classification tasks. We additionally validate the VHE\non natural images from the YouTube Faces database. Finally, we develop\nextensions of the model that apply to richer dataset structures such as\nfactorial and hierarchical categories.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 06:05:43 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Hewitt", "Luke B.", ""], ["Nye", "Maxwell I.", ""], ["Gane", "Andreea", ""], ["Jaakkola", "Tommi", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1807.08920", "submitter": "Yang Hu Dr.", "authors": "Yang Hu, Guihua Wen, Mingnan Luo, Dan Dai, Jiajiong Ma, Zhiwen Yu", "title": "Competitive Inner-Imaging Squeeze and Excitation for Residual Network", "comments": "Code is available at\n  https://github.com/scut-aitcm/Competitive-Inner-Imaging-SENet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks, which use a residual unit to supplement the identity\nmappings, enable very deep convolutional architecture to operate well, however,\nthe residual architecture has been proved to be diverse and redundant, which\nmay leads to low-efficient modeling. In this work, we propose a competitive\nsqueeze-excitation (SE) mechanism for the residual network. Re-scaling the\nvalue for each channel in this structure will be determined by the residual and\nidentity mappings jointly, and this design enables us to expand the meaning of\nchannel relationship modeling in residual blocks. Modeling of the competition\nbetween residual and identity mappings cause the identity flow to control the\ncomplement of the residual feature maps for itself. Furthermore, we design a\nnovel inner-imaging competitive SE block to shrink the consumption and re-image\nthe global features of intermediate network structure, by using the\ninner-imaging mechanism, we can model the channel-wise relations with\nconvolution in spatial. We carry out experiments on the CIFAR, SVHN, and\nImageNet datasets, and the proposed method can challenge state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 06:13:25 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 14:55:37 GMT"}, {"version": "v3", "created": "Sat, 10 Nov 2018 16:52:45 GMT"}, {"version": "v4", "created": "Sun, 23 Dec 2018 02:56:45 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Hu", "Yang", ""], ["Wen", "Guihua", ""], ["Luo", "Mingnan", ""], ["Dai", "Dan", ""], ["Ma", "Jiajiong", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1807.08934", "submitter": "Vinod Kumar Chauhan", "authors": "Vinod Kumar Chauhan, Anuj Sharma, Kalpana Dahiya", "title": "SAAGs: Biased Stochastic Variance Reduction Methods for Large-scale\n  Learning", "comments": "Final journal version. Appl Intell (2019)", "journal-ref": null, "doi": "10.1007/s10489-019-01450-3", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic approximation is one of the effective approach to deal with the\nlarge-scale machine learning problems and the recent research has focused on\nreduction of variance, caused by the noisy approximations of the gradients. In\nthis paper, we have proposed novel variants of SAAG-I and II (Stochastic\nAverage Adjusted Gradient) (Chauhan et al. 2017), called SAAG-III and IV,\nrespectively. Unlike SAAG-I, starting point is set to average of previous epoch\nin SAAG-III, and unlike SAAG-II, the snap point and starting point are set to\naverage and last iterate of previous epoch in SAAG-IV, respectively. To\ndetermine the step size, we have used Stochastic Backtracking-Armijo line\nSearch (SBAS) which performs line search only on selected mini-batch of data\npoints. Since backtracking line search is not suitable for large-scale problems\nand the constants used to find the step size, like Lipschitz constant, are not\nalways available so SBAS could be very effective in such cases. We have\nextended SAAGs (I, II, III and IV) to solve non-smooth problems and designed\ntwo update rules for smooth and non-smooth problems. Moreover, our theoretical\nresults have proved linear convergence of SAAG-IV for all the four combinations\nof smoothness and strong-convexity, in expectation. Finally, our experimental\nstudies have proved the efficacy of proposed methods against the state-of-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 07:36:21 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 10:04:22 GMT"}, {"version": "v3", "created": "Sat, 6 Apr 2019 05:04:23 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Chauhan", "Vinod Kumar", ""], ["Sharma", "Anuj", ""], ["Dahiya", "Kalpana", ""]]}, {"id": "1807.08941", "submitter": "Joost Broekens", "authors": "Joost Broekens", "title": "A Temporal Difference Reinforcement Learning Theory of Emotion: unifying\n  emotion, cognition and adaptive behavior", "comments": "pre-print, don't cite verbatim", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions are intimately tied to motivation and the adaptation of behavior,\nand many animal species show evidence of emotions in their behavior. Therefore,\nemotions must be related to powerful mechanisms that aid survival, and,\nemotions must be evolutionary continuous phenomena. How and why did emotions\nevolve in nature, how do events get emotionally appraised, how do emotions\nrelate to cognitive complexity, and, how do they impact behavior and learning?\nIn this article I propose that all emotions are manifestations of reward\nprocessing, in particular Temporal Difference (TD) error assessment.\nReinforcement Learning (RL) is a powerful computational model for the learning\nof goal oriented tasks by exploration and feedback. Evidence indicates that\nRL-like processes exist in many animal species. Key in the processing of\nfeedback in RL is the notion of TD error, the assessment of how much better or\nworse a situation just became, compared to what was previously expected (or,\nthe estimated gain or loss of utility - or well-being - resulting from new\nevidence). I propose a TDRL Theory of Emotion and discuss its ramifications for\nour understanding of emotions in humans, animals and machines, and present\npsychological, neurobiological and computational evidence in its support.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 07:50:14 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Broekens", "Joost", ""]]}, {"id": "1807.08970", "submitter": "Vedran Dunjko", "authors": "Vedran Dunjko, Yimin Ge, J. Ignacio Cirac", "title": "Computational speedups using small quantum devices", "comments": "5+12 pages", "journal-ref": "Phys. Rev. Lett. 121, 250501 (2018)", "doi": "10.1103/PhysRevLett.121.250501", "report-no": null, "categories": "quant-ph cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have a small quantum computer with only M qubits. Can such a\ndevice genuinely speed up certain algorithms, even when the problem size is\nmuch larger than M? Here we answer this question to the affirmative. We present\na hybrid quantum-classical algorithm to solve 3SAT problems involving n>>M\nvariables that significantly speeds up its fully classical counterpart. This\nquestion may be relevant in view of the current quest to build small quantum\ncomputers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 09:01:50 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 07:00:34 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Dunjko", "Vedran", ""], ["Ge", "Yimin", ""], ["Cirac", "J. Ignacio", ""]]}, {"id": "1807.09161", "submitter": "Renato Luiz de Freitas Cunha", "authors": "Renato L. de F. Cunha, Eduardo R. Rodrigues, Matheus Palhares Viana,\n  Dario Augusto Borges Oliveira", "title": "An argument in favor of strong scaling for deep neural networks with\n  small datasets", "comments": "8 pages, 5 figures, Presented at HPML 2018 -\n  http://hpml2018.github.io/", "journal-ref": null, "doi": "10.1109/CAHPC.2018.8645881", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the popularization of deep learning frameworks and\nlarge datasets, researchers have started parallelizing their models in order to\ntrain faster. This is crucially important, because they typically explore many\nhyperparameters in order to find the best ones for their applications. This\nprocess is time consuming and, consequently, speeding up training improves\nproductivity. One approach to parallelize deep learning models followed by many\nresearchers is based on weak scaling. The minibatches increase in size as new\nGPUs are added to the system. In addition, new learning rates schedules have\nbeen proposed to fix optimization issues that occur with large minibatch sizes.\nIn this paper, however, we show that the recommendations provided by recent\nwork do not apply to models that lack large datasets. In fact, we argument in\nfavor of using strong scaling for achieving reliable performance in such cases.\nWe evaluated our approach with up to 32 GPUs and show that weak scaling not\nonly does not have the same accuracy as the sequential model, it also fails to\nconverge most of time. Meanwhile, strong scaling has good scalability while\nhaving exactly the same accuracy of a sequential implementation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 14:48:19 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 12:23:39 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 22:59:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cunha", "Renato L. de F.", ""], ["Rodrigues", "Eduardo R.", ""], ["Viana", "Matheus Palhares", ""], ["Oliveira", "Dario Augusto Borges", ""]]}, {"id": "1807.09205", "submitter": "Okan A\\c{s}{\\i}k", "authors": "Okan A\\c{s}{\\i}k, Binnur G\\\"orer and H. Levent Ak{\\i}n", "title": "End-to-End Deep Imitation Learning: Robot Soccer Case Study", "comments": "RoboCup 2018 Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In imitation learning, behavior learning is generally done using the features\nextracted from the demonstration data. Recent deep learning algorithms enable\nthe development of machine learning methods that can get high dimensional data\nas an input. In this work, we use imitation learning to teach the robot to\ndribble the ball to the goal. We use B-Human robot software to collect\ndemonstration data and a deep convolutional network to represent the policies.\nWe use top and bottom camera images of the robot as input and speed commands as\noutputs. The CNN policy learns the mapping between the series of images and\nspeed commands. In 3D realistic robotics simulator experiments, we show that\nthe robot is able to learn to search the ball and dribble the ball, but it\nstruggles to align to the goal. The best-proposed policy model learns to score\n4 goals out of 20 test episodes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 15:51:41 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["A\u015f\u0131k", "Okan", ""], ["G\u00f6rer", "Binnur", ""], ["Ak\u0131n", "H. Levent", ""]]}, {"id": "1807.09232", "submitter": "Maria Camila Alvarez Trivino", "authors": "Maria Camila Alvarez Trivino (1), Jeremie Despraz (2), Jesus Alfonso\n  Lopez Sotelo (1), Carlos Andres Pena (2) ((1) Universidad Autonoma de\n  Occidente, (2) School of Business and Engineering Vaud (HEIG-VD))", "title": "Deep Learning on Retina Images as Screening Tool for Diagnostic Decision\n  Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we developed a deep learning system applied to human retina\nimages for medical diagnostic decision support. The retina images were provided\nby EyePACS. These images were used in the framework of a Kaggle contest, whose\npurpose to identify diabetic retinopathy signs through an automatic detection\nsystem. Using as inspiration one of the solutions proposed in the contest, we\nimplemented a model that successfully detects diabetic retinopathy from retina\nimages. After a carefully designed preprocessing, the images were used as input\nto a deep convolutional neural network (CNN). The CNN performed a feature\nextraction process followed by a classification stage, which allowed the system\nto differentiate between healthy and ill patients using five categories. Our\nmodel was able to identify diabetic retinopathy in the patients with an\nagreement rate of 76.73% with respect to the medical expert's labels for the\ntest data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 16:59:06 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Trivino", "Maria Camila Alvarez", ""], ["Despraz", "Jeremie", ""], ["Sotelo", "Jesus Alfonso Lopez", ""], ["Pena", "Carlos Andres", ""]]}, {"id": "1807.09244", "submitter": "Jiajun Wu", "authors": "David Zheng, Vinson Luo, Jiajun Wu, Joshua B. Tenenbaum", "title": "Unsupervised Learning of Latent Physical Properties Using\n  Perception-Prediction Networks", "comments": "UAI 2018 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for the completely unsupervised learning of latent\nobject properties from their interactions: the perception-prediction network\n(PPN). Consisting of a perception module that extracts representations of\nlatent object properties and a prediction module that uses those extracted\nproperties to simulate system dynamics, the PPN can be trained in an end-to-end\nfashion purely from samples of object dynamics. The representations of latent\nobject properties learned by PPNs not only are sufficient to accurately\nsimulate the dynamics of systems comprised of previously unseen objects, but\nalso can be translated directly into human-interpretable properties (e.g.,\nmass, coefficient of restitution) in an entirely unsupervised manner.\nCrucially, PPNs also generalize to novel scenarios: their gradient-based\ntraining can be applied to many dynamical systems and their graph-based\nstructure functions over systems comprised of different numbers of objects. Our\nresults demonstrate the efficacy of graph-based neural architectures in\nobject-centric inference and prediction tasks, and our model has the potential\nto discover relevant object properties in systems that are not yet well\nunderstood.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:28:27 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 19:03:07 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zheng", "David", ""], ["Luo", "Vinson", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1807.09245", "submitter": "Jiajun Wu", "authors": "Tianfan Xue, Jiajun Wu, Katherine L. Bouman, William T. Freeman", "title": "Visual Dynamics: Stochastic Future Generation via Layered Cross\n  Convolutional Networks", "comments": "Journal preprint of arXiv:1607.02586 (IEEE TPAMI, 2019). The first\n  two authors contributed equally to this work. Project page:\n  http://visualdynamics.csail.mit.edu", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI), vol. 41, no. 9, pp. 2236-2250, 2019", "doi": "10.1109/TPAMI.2018.2854726", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of synthesizing a number of likely future frames from a\nsingle input image. In contrast to traditional methods that have tackled this\nproblem in a deterministic or non-parametric way, we propose to model future\nframes in a probabilistic manner. Our probabilistic model makes it possible for\nus to sample and synthesize many possible future frames from a single input\nimage. To synthesize realistic movement of objects, we propose a novel network\nstructure, namely a Cross Convolutional Network; this network encodes image and\nmotion information as feature maps and convolutional kernels, respectively. In\nexperiments, our model performs well on synthetic data, such as 2D shapes and\nanimated game sprites, and on real-world video frames. We present analyses of\nthe learned network representations, showing it is implicitly learning a\ncompact encoding of object appearance and motion. We also demonstrate a few of\nits applications, including visual analogy-making and video extrapolation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 17:28:31 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 19:17:56 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 23:11:54 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Xue", "Tianfan", ""], ["Wu", "Jiajun", ""], ["Bouman", "Katherine L.", ""], ["Freeman", "William T.", ""]]}, {"id": "1807.09295", "submitter": "Rishi Sharma", "authors": "Rishi Sharma, Shane Barratt, Stefano Ermon, Vijay Pande", "title": "Improved Training with Curriculum GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Curriculum GANs, a curriculum learning strategy\nfor training Generative Adversarial Networks that increases the strength of the\ndiscriminator over the course of training, thereby making the learning task\nprogressively more difficult for the generator. We demonstrate that this\nstrategy is key to obtaining state-of-the-art results in image generation. We\nalso show evidence that this strategy may be broadly applicable to improving\nGAN training in other data modalities.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 18:27:20 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Sharma", "Rishi", ""], ["Barratt", "Shane", ""], ["Ermon", "Stefano", ""], ["Pande", "Vijay", ""]]}, {"id": "1807.09341", "submitter": "Thanard Kurutach", "authors": "Thanard Kurutach, Aviv Tamar, Ge Yang, Stuart Russell, Pieter Abbeel", "title": "Learning Plannable Representations with Causal InfoGAN", "comments": "ICML / IJCAI / AAMAS 2018 Workshop on Planning and Learning (PAL-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep generative models have been shown to 'imagine'\nconvincing high-dimensional observations such as images, audio, and even video,\nlearning directly from raw data. In this work, we ask how to imagine\ngoal-directed visual plans -- a plausible sequence of observations that\ntransition a dynamical system from its current configuration to a desired goal\nstate, which can later be used as a reference trajectory for control. We focus\non systems with high-dimensional observations, such as images, and propose an\napproach that naturally combines representation learning and planning. Our\nframework learns a generative model of sequential observations, where the\ngenerative process is induced by a transition in a low-dimensional planning\nmodel, and an additional noise. By maximizing the mutual information between\nthe generated observations and the transition in the planning model, we obtain\na low-dimensional representation that best explains the causal nature of the\ndata. We structure the planning model to be compatible with efficient planning\nalgorithms, and we propose several such models based on either discrete or\ncontinuous states. Finally, to generate a visual plan, we project the current\nand goal observations onto their respective states in the planning model, plan\na trajectory, and then use the generative model to transform the trajectory to\na sequence of observations. We demonstrate our method on imagining plausible\nvisual plans of rope manipulation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 20:46:05 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kurutach", "Thanard", ""], ["Tamar", "Aviv", ""], ["Yang", "Ge", ""], ["Russell", "Stuart", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1807.09358", "submitter": "Lifeng Zhou", "authors": "Lifeng Zhou and Pratap Tokekar", "title": "An Approximation Algorithm for Risk-averse Submodular Optimization", "comments": "Whole version for WAFR, 2018 final submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of incorporating risk while making combinatorial\ndecisions under uncertainty. We formulate a discrete submodular maximization\nproblem for selecting a set using Conditional-Value-at-Risk (CVaR), a risk\nmetric commonly used in financial analysis. While CVaR has recently been used\nin optimization of linear cost functions in robotics, we take the first stages\ntowards extending this to discrete submodular optimization and provide several\npositive results. Specifically, we propose the Sequential Greedy Algorithm that\nprovides an approximation guarantee on finding the maxima of the CVaR cost\nfunction under a matroidal constraint. The approximation guarantee shows that\nthe solution produced by our algorithm is within a constant factor of the\noptimal and an additive term that depends on the optimal. Our analysis uses the\ncurvature of the submodular set function, and proves that the algorithm runs in\npolynomial time. This formulates a number of combinatorial optimization\nproblems that appear in robotics. We use two such problems, vehicle assignment\nunder uncertainty for mobility-on-demand and sensor selection with failures for\nenvironmental monitoring, as case studies to demonstrate the efficacy of our\nformulation.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 21:10:50 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 18:40:59 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhou", "Lifeng", ""], ["Tokekar", "Pratap", ""]]}, {"id": "1807.09388", "submitter": "Kai Xu", "authors": "Kai Xu, Zhikang Zhang, Fengbo Ren", "title": "LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network\n  for Flexible Compressive Sensing Reconstruction", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the single-image compressive sensing (CS) and\nreconstruction problem. We propose a scalable Laplacian pyramid reconstructive\nadversarial network (LAPRAN) that enables high-fidelity, flexible and fast CS\nimages reconstruction. LAPRAN progressively reconstructs an image following the\nconcept of Laplacian pyramid through multiple stages of reconstructive\nadversarial networks (RANs). At each pyramid level, CS measurements are fused\nwith a contextual latent vector to generate a high-frequency image residual.\nConsequently, LAPRAN can produce hierarchies of reconstructed images and each\nwith an incremental resolution and improved quality. The scalable pyramid\nstructure of LAPRAN enables high-fidelity CS reconstruction with a flexible\nresolution that is adaptive to a wide range of compression ratios (CRs), which\nis infeasible with existing methods. Experimental results on multiple public\ndatasets show that LAPRAN offers an average 7.47dB and 5.98dB PSNR, and an\naverage 57.93% and 33.20% SSIM improvement compared to model-based and\ndata-driven baselines, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 23:28:17 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 18:45:27 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 18:36:57 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Xu", "Kai", ""], ["Zhang", "Zhikang", ""], ["Ren", "Fengbo", ""]]}, {"id": "1807.09427", "submitter": "Sanyam Kapoor", "authors": "Sanyam Kapoor", "title": "Multi-Agent Reinforcement Learning: A Report on Challenges and\n  Approaches", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) is a learning paradigm concerned with learning to\ncontrol a system so as to maximize an objective over the long term. This\napproach to learning has received immense interest in recent times and success\nmanifests itself in the form of human-level performance on games like\n\\textit{Go}. While RL is emerging as a practical component in real-life\nsystems, most successes have been in Single Agent domains. This report will\ninstead specifically focus on challenges that are unique to Multi-Agent Systems\ninteracting in mixed cooperative and competitive environments. The report\nconcludes with advances in the paradigm of training Multi-Agent Systems called\n\\textit{Decentralized Actor, Centralized Critic}, based on an extension of MDPs\ncalled \\textit{Decentralized Partially Observable MDP}s, which has seen a\nrenewed interest lately.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 03:56:04 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Kapoor", "Sanyam", ""]]}, {"id": "1807.09510", "submitter": "Luca Carcano", "authors": "Luca Carcano, Emanuele Plebani, Danilo Pietro Pau, Marco Piastra", "title": "Pre-trainable Reservoir Computing with Recursive Neural Gas", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESN) are a class of Recurrent Neural Networks (RNN) that\nhas gained substantial popularity due to their effectiveness, ease of use and\npotential for compact hardware implementation. An ESN contains the three\nnetwork layers input, reservoir and readout where the reservoir is the truly\nrecurrent network. The input and reservoir layers of an ESN are initialized at\nrandom and never trained afterwards and the training of the ESN is applied to\nthe readout layer only. The alternative of Recursive Neural Gas (RNG) is one of\nthe many proposals of fully-trainable reservoirs that can be found in the\nliterature. Although some improvements in performance have been reported with\nRNG, to the best of authors' knowledge, no experimental comparative results are\nknown with benchmarks for which ESN is known to yield excellent results. This\nwork describes an accurate model of RNG together with some extensions to the\nmodels presented in the literature and shows comparative results on three\nwell-known and accepted datasets. The experimental results obtained show that,\nunder specific circumstances, RNG-based reservoirs can achieve better\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 10:05:46 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Carcano", "Luca", ""], ["Plebani", "Emanuele", ""], ["Pau", "Danilo Pietro", ""], ["Piastra", "Marco", ""]]}, {"id": "1807.09511", "submitter": "Xiaoran Xu", "authors": "Xiaoran Xu, Songpeng Zu, Yuan Zhang, Hanning Zhou, and Wei Feng", "title": "Backprop-Q: Generalized Backpropagation for Stochastic Computation\n  Graphs", "comments": "NeurIPS 2018 Deep Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, it is appealing to learn a model carrying out\nstochastic operations internally, known as stochastic computation graphs\n(SCGs), rather than learning a deterministic mapping. However, standard\nbackpropagation is not applicable to SCGs. We attempt to address this issue\nfrom the angle of cost propagation, with local surrogate costs, called\nQ-functions, constructed and learned for each stochastic node in an SCG. Then,\nthe SCG can be trained based on these surrogate costs using standard\nbackpropagation. We propose the entire framework as a solution to generalize\nbackpropagation for SCGs, which resembles an actor-critic architecture but\nbased on a graph. For broad applicability, we study a variety of SCG structures\nfrom one cost to multiple costs. We utilize recent advances in reinforcement\nlearning (RL) and variational Bayes (VB), such as off-policy critic learning\nand unbiased-and-low-variance gradient estimation, and review them in the\ncontext of SCGs. The generalized backpropagation extends transported learning\nsignals beyond gradients between stochastic nodes while preserving the benefit\nof backpropagating gradients through deterministic nodes. Experimental\nsuggestions and concerns are listed to help design and test any specific model\nusing this framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 10:06:24 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 08:43:31 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Xu", "Xiaoran", ""], ["Zu", "Songpeng", ""], ["Zhang", "Yuan", ""], ["Zhou", "Hanning", ""], ["Feng", "Wei", ""]]}, {"id": "1807.09530", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Chenyang Zhou, J. Marius Z\\\"ollner", "title": "Decentralized Cooperative Planning for Automated Vehicles with\n  Hierarchical Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": "10.1109/IVS.2018.8500712", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's automated vehicles lack the ability to cooperate implicitly with\nothers. This work presents a Monte Carlo Tree Search (MCTS) based approach for\ndecentralized cooperative planning using macro-actions for automated vehicles\nin heterogeneous environments. Based on cooperative modeling of other agents\nand Decoupled-UCT (a variant of MCTS), the algorithm evaluates the\nstate-action-values of each agent in a cooperative and decentralized manner,\nexplicitly modeling the interdependence of actions between traffic\nparticipants. Macro-actions allow for temporal extension over multiple time\nsteps and increase the effective search depth requiring fewer iterations to\nplan over longer horizons. Without predefined policies for macro-actions, the\nalgorithm simultaneously learns policies over and within macro-actions. The\nproposed method is evaluated under several conflict scenarios, showing that the\nalgorithm can achieve effective cooperative planning with learned macro-actions\nin heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 11:20:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kurzer", "Karl", ""], ["Zhou", "Chenyang", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1807.09623", "submitter": "Alon Talmor", "authors": "Alon Talmor and Jonathan Berant", "title": "Repartitioning of the ComplexWebQuestions Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Talmor and Berant (2018) introduced ComplexWebQuestions - a dataset\nfocused on answering complex questions by decomposing them into a sequence of\nsimpler questions and extracting the answer from retrieved web snippets. In\ntheir work the authors used a pre-trained reading comprehension (RC) model\n(Salant and Berant, 2018) to extract the answer from the web snippets. In this\nshort note we show that training a RC model directly on the training data of\nComplexWebQuestions reveals a leakage from the training set to the test set\nthat allows to obtain unreasonably high performance. As a solution, we\nconstruct a new partitioning of ComplexWebQuestions that does not suffer from\nthis leakage and publicly release it. We also perform an empirical evaluation\non these two datasets and show that training a RC model on the training data\nsubstantially improves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:15:40 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "1807.09639", "submitter": "Yingting Wu", "authors": "Yingting Wu and Hai Zhao", "title": "Finding Better Subword Segmentation for Neural Machine Translation", "comments": "12 pages, accepted by CCL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For different language pairs, word-level neural machine translation (NMT)\nmodels with a fixed-size vocabulary suffer from the same problem of\nrepresenting out-of-vocabulary (OOV) words. The common practice usually\nreplaces all these rare or unknown words with a <UNK> token, which limits the\ntranslation performance to some extent. Most of recent work handled such a\nproblem by splitting words into characters or other specially extracted subword\nunits to enable open-vocabulary translation. Byte pair encoding (BPE) is one of\nthe successful attempts that has been shown extremely competitive by providing\neffective subword segmentation for NMT systems. In this paper, we extend the\nBPE style segmentation to a general unsupervised framework with three\nstatistical measures: frequency (FRQ), accessor variety (AV) and description\nlength gain (DLG). We test our approach on two translation tasks: German to\nEnglish and Chinese to English. The experimental results show that AV and DLG\nenhanced systems outperform the FRQ baseline in the frequency weighted schemes\nat different significant levels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:43:46 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Wu", "Yingting", ""], ["Zhao", "Hai", ""]]}, {"id": "1807.09647", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue", "title": "Variational Bayesian Reinforcement Learning with Regret Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation trade-off in reinforcement learning\nand we show that an agent imbued with an epistemic-risk-seeking utility\nfunction is able to explore efficiently, as measured by regret. The parameter\nthat controls how risk-seeking the agent is can be optimized to minimize\nregret, or annealed according to a schedule. We call the resulting algorithm\nK-learning and we show that the K-values that the agent maintains are\noptimistic for the expected optimal Q-values at each state-action pair. The\nutility function approach induces a natural Boltzmann exploration policy for\nwhich the 'temperature' parameter is equal to the risk-seeking parameter. This\npolicy achieves a Bayesian regret bound of $\\tilde O(L^{3/2} \\sqrt{SAT})$,\nwhere L is the time horizon, S is the number of states, A is the number of\nactions, and T is the total number of elapsed time-steps. K-learning can be\ninterpreted as mirror descent in the policy space, and it is similar to other\nwell-known methods in the literature, including Q-learning, soft-Q-learning,\nand maximum entropy policy gradient. K-learning is simple to implement, as it\nonly requires adding a bonus to the reward at each state-action and then\nsolving a Bellman equation. We conclude with a numerical example demonstrating\nthat K-learning is competitive with other state-of-the-art algorithms in\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 14:56:09 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 10:52:26 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["O'Donoghue", "Brendan", ""]]}, {"id": "1807.09659", "submitter": "Qianli Liao", "authors": "Qianli Liao, Brando Miranda, Andrzej Banburski, Jack Hidary, Tomaso\n  Poggio", "title": "A Surprising Linear Relationship Predicts Test Performance in Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given two networks with the same training loss on a dataset, when would they\nhave drastically different test losses and errors? Better understanding of this\nquestion of generalization may improve practical applications of deep networks.\nIn this paper we show that with cross-entropy loss it is surprisingly simple to\ninduce significantly different generalization performances for two networks\nthat have the same architecture, the same meta parameters and the same training\nerror: one can either pretrain the networks with different levels of\n\"corrupted\" data or simply initialize the networks with weights of different\nGaussian standard deviations. A corollary of recent theoretical results on\noverfitting shows that these effects are due to an intrinsic problem of\nmeasuring test performance with a cross-entropy/exponential-type loss, which\ncan be decomposed into two components both minimized by SGD -- one of which is\nnot related to expected classification performance. However, if we factor out\nthis component of the loss, a linear relationship emerges between training and\ntest losses. Under this transformation, classical generalization bounds are\nsurprisingly tight: the empirical/training loss is very close to the\nexpected/test loss. Furthermore, the empirical relation between classification\nerror and normalized cross-entropy loss seem to be approximately monotonic\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:20:02 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Banburski", "Andrzej", ""], ["Hidary", "Jack", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1807.09664", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Doina Precup", "title": "Attend Before you Act: Leveraging human visual attention for continual\n  learning", "comments": "Lifelong Learning: A Reinforcement Learning Approach (LLARLA)\n  Workshop, ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans perform a task, such as playing a game, they selectively pay\nattention to certain parts of the visual input, gathering relevant information\nand sequentially combining it to build a representation from the sensory data.\nIn this work, we explore leveraging where humans look in an image as an\nimplicit indication of what is salient for decision making. We build on top of\nthe UNREAL architecture in DeepMind Lab's 3D navigation maze environment. We\ntrain the agent both with original images and foveated images, which were\ngenerated by overlaying the original images with saliency maps generated using\na real-time spectral residual technique. We investigate the effectiveness of\nthis approach in transfer learning by measuring performance in the context of\nnoise in the environment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 15:23:44 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Precup", "Doina", ""]]}, {"id": "1807.09754", "submitter": "Sarathkrishna Swaminathan", "authors": "Stephen Boyer, Thomas Griffin, Sarath Swaminathan, Kenneth L.\n  Clarkson, Dmitry Zubarev", "title": "Data Infrastructure and Approaches for Ontology-Based Drug Repurposing", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report development of a data infrastructure for drug repurposing that\ntakes advantage of two currently available chemical ontologies. The data\ninfrastructure includes a database of compound- target associations augmented\nwith molecular ontological labels. It also contains two computational tools for\nprediction of new associations. We describe two drug-repurposing systems: one,\nNascent Ontological Information Retrieval for Drug Repurposing (NOIR-DR), based\non an information retrieval strategy, and another, based on non-negative matrix\nfactorization together with compound similarity, that was inspired by\nrecommender systems. We report the performance of both tools on a\ndrug-repurposing task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:17:05 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Boyer", "Stephen", ""], ["Griffin", "Thomas", ""], ["Swaminathan", "Sarath", ""], ["Clarkson", "Kenneth L.", ""], ["Zubarev", "Dmitry", ""]]}, {"id": "1807.09825", "submitter": "Nikhil Churamani", "authors": "Nikhil Churamani and Alexander Sutherland and Pablo Barros", "title": "An Affective Robot Companion for Assisting the Elderly in a Cognitive\n  Game Scenario", "comments": "Proceedings of the Workshop on Intelligent Assistive Computing, IEEE\n  World Congress on Computational Intelligence (WCCI) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being able to recognize emotions in human users is considered a highly\ndesirable trait in Human-Robot Interaction (HRI) scenarios. However, most\ncontemporary approaches rarely attempt to apply recognized emotional features\nin an active manner to modulate robot decision-making and dialogue for the\nbenefit of the user. In this position paper, we propose a method of\nincorporating recognized emotions into a Reinforcement Learning (RL) based\ndialogue management module that adapts its dialogue responses in order to\nattempt to make cognitive training tasks, like the 2048 Puzzle Game, more\nenjoyable for the users.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 02:27:19 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Churamani", "Nikhil", ""], ["Sutherland", "Alexander", ""], ["Barros", "Pablo", ""]]}, {"id": "1807.09836", "submitter": "G Gordon Worley IIi", "authors": "G Gordon Worley III", "title": "Robustness to fundamental uncertainty in AGI alignment", "comments": null, "journal-ref": "Journal of Consciousness Studies, Volume 27, Numbers 1-2, 2020,\n  pp. 225-241(17)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AGI alignment problem has a bimodal distribution of outcomes with most\noutcomes clustering around the poles of total success and existential,\ncatastrophic failure. Consequently, attempts to solve AGI alignment should, all\nelse equal, prefer false negatives (ignoring research programs that would have\nbeen successful) to false positives (pursuing research programs that will\nunexpectedly fail). Thus, we propose adopting a policy of responding to points\nof philosophical and practical uncertainty associated with the alignment\nproblem by limiting and choosing necessary assumptions to reduce the risk of\nfalse positives. Herein we explore in detail two relevant points of uncertainty\nthat AGI alignment research hinges on---meta-ethical uncertainty and\nuncertainty about mental phenomena---and show how to reduce false positives in\nresponse to them.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 20:11:47 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 10:03:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Worley", "G Gordon", "III"]]}, {"id": "1807.09844", "submitter": "John Kelleher", "authors": "Simon Dobnik and John D. Kelleher", "title": "Modular Mechanistic Networks: On Bridging Mechanistic and\n  Phenomenological Models with Deep Neural Networks in Natural Language\n  Processing", "comments": "18 pages, 1 figure, Appears in CLASP Papers in Computational\n  Linguistics Vol. 1: Proceedings of the Conference on Logic and Machine\n  Learning in Natural Language (LaML 2017)", "journal-ref": "CLASP Papers in Computational Linguistics Vol. 1: Proceedings of\n  the Conference on Logic and Machine Learning in Natural Language (LaML 2017).\n  ISSN: 2002-9764. URI: http://hdl.handle.net/2077/54911", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) can be done using either top-down (theory\ndriven) and bottom-up (data driven) approaches, which we call mechanistic and\nphenomenological respectively. The approaches are frequently considered to\nstand in opposition to each other. Examining some recent approaches in deep\nlearning we argue that deep neural networks incorporate both perspectives and,\nfurthermore, that leveraging this aspect of deep learning may help in solving\ncomplex problems within language technology, such as modelling language and\nperception in the domain of spatial cognition.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:37:15 GMT"}, {"version": "v2", "created": "Sat, 23 Mar 2019 15:45:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Dobnik", "Simon", ""], ["Kelleher", "John D.", ""]]}, {"id": "1807.09886", "submitter": "Pegah Karimi", "authors": "Pegah Karimi, Kazjon Grace, Mary Lou Maher, Nicholas Davis", "title": "Evaluating Creativity in Computational Co-Creative Systems", "comments": "9 pages, 2 Figures, 1 Table, Accepted in ICCC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a framework for evaluating creativity in co-creative\nsystems: those that involve computer programs collaborating with human users on\ncreative tasks. We situate co-creative systems within a broader context of\ncomputational creativity and explain the unique qualities of these systems. We\npresent four main questions that can guide evaluation in co-creative systems:\nWho is evaluating the creativity, what is being evaluated, when does evaluation\noccur and how the evaluation is performed. These questions provide a framework\nfor comparing how existing co-creative systems evaluate creativity, and we\napply them to examples of co-creative systems in art, humor, games and\nrobotics. We conclude that existing co-creative systems tend to focus on\nevaluating the user experience. Adopting evaluation methods from autonomous\ncreative systems may lead to co-creative systems that are self-aware and\nintentional.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 22:38:16 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Karimi", "Pegah", ""], ["Grace", "Kazjon", ""], ["Maher", "Mary Lou", ""], ["Davis", "Nicholas", ""]]}, {"id": "1807.09936", "submitter": "Jiaming Song", "authors": "Jiaming Song, Hongyu Ren, Dorsa Sadigh, Stefano Ermon", "title": "Multi-Agent Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms can be used to learn a policy from expert\ndemonstrations without access to a reward signal. However, most existing\napproaches are not applicable in multi-agent settings due to the existence of\nmultiple (Nash) equilibria and non-stationary environments. We propose a new\nframework for multi-agent imitation learning for general Markov games, where we\nbuild upon a generalized notion of inverse reinforcement learning. We further\nintroduce a practical multi-agent actor-critic algorithm with good empirical\nperformance. Our method can be used to imitate complex behaviors in\nhigh-dimensional environments with multiple cooperative or competing agents.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:21:49 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Song", "Jiaming", ""], ["Ren", "Hongyu", ""], ["Sadigh", "Dorsa", ""], ["Ermon", "Stefano", ""]]}, {"id": "1807.09942", "submitter": "Jake Chandler", "authors": "Richard Booth, Jake Chandler", "title": "On Strengthening the Logic of Iterated Belief Revision: Proper Ordinal\n  Interval Operators", "comments": "Extended version of a paper accepted to KR 2018. 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Darwiche and Pearl's seminal 1997 article outlined a number of baseline\nprinciples for a logic of iterated belief revision. These principles, the DP\npostulates, have been supplemented in a number of alternative ways. Most of the\nsuggestions made have resulted in a form of `reductionism' that identifies\nbelief states with orderings of worlds. However, this position has recently\nbeen criticised as being unacceptably strong. Other proposals, such as the\npopular principle (P), aka `Independence', characteristic of `admissible'\nrevision operators, remain commendably more modest. In this paper, we\nsupplement both the DP postulates and (P) with a number of novel conditions.\nWhile the DP postulates constrain the relation between a prior and a posterior\nconditional belief set, our new principles notably govern the relation between\ntwo posterior conditional belief sets obtained from a common prior by different\nrevisions. We show that operators from the resulting family, which subsumes\nboth lexicographic and restrained revision, can be represented as relating\nbelief states that are associated with a `proper ordinal interval' (POI)\nassignment, a structure more fine-grained than a simple ordering of worlds. We\nclose the paper by noting that these operators satisfy iterated versions of a\nlarge number of AGM era postulates, including Superexpansion, that are not\nsound for admissible operators in general.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 03:38:43 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Booth", "Richard", ""], ["Chandler", "Jake", ""]]}, {"id": "1807.09962", "submitter": "Beomjoon Kim", "authors": "Beomjoon Kim and Zi Wang and Leslie Pack Kaelbling and Tomas\n  Lozano-Perez", "title": "Learning to guide task and motion planning using score-space\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a learning algorithm that speeds up the search in\ntask and motion planning problems. Our algorithm proposes solutions to three\ndifferent challenges that arise in learning to improve planning efficiency:\nwhat to predict, how to represent a planning problem instance, and how to\ntransfer knowledge from one problem instance to another. We propose a method\nthat predicts constraints on the search space based on a generic representation\nof a planning problem instance, called score-space, where we represent a\nproblem instance in terms of the performance of a set of solutions attempted so\nfar. Using this representation, we transfer knowledge, in the form of\nconstraints, from previous problems based on the similarity in score space. We\ndesign a sequential algorithm that efficiently predicts these constraints, and\nevaluate it in three different challenging task and motion planning problems.\nResults indicate that our approach performs orders of magnitudes faster than an\nunguided planner\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 05:35:18 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kim", "Beomjoon", ""], ["Wang", "Zi", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1807.09991", "submitter": "German I. Parisi", "authors": "Francisco Cruz and German I. Parisi and Stefan Wermter", "title": "Multi-modal Feedback for Affordance-driven Interactive Reinforcement\n  Learning", "comments": "Accepted at IEEE IJCNN 2018, Rio de Janeiro, Brazil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive reinforcement learning (IRL) extends traditional reinforcement\nlearning (RL) by allowing an agent to interact with parent-like trainers during\na task. In this paper, we present an IRL approach using dynamic audio-visual\ninput in terms of vocal commands and hand gestures as feedback. Our\narchitecture integrates multi-modal information to provide robust commands from\nmultiple sensory cues along with a confidence value indicating the\ntrustworthiness of the feedback. The integration process also considers the\ncase in which the two modalities convey incongruent information. Additionally,\nwe modulate the influence of sensory-driven feedback in the IRL task using\ngoal-oriented knowledge in terms of contextual affordances. We implement a\nneural network architecture to predict the effect of performed actions with\ndifferent objects to avoid failed-states, i.e., states from which it is not\npossible to accomplish the task. In our experimental setup, we explore the\ninterplay of multimodal feedback and task-specific affordances in a robot\ncleaning scenario. We compare the learning performance of the agent under four\ndifferent conditions: traditional RL, multi-modal IRL, and each of these two\nsetups with the use of contextual affordances. Our experiments show that the\nbest performance is obtained by using audio-visual feedback with\naffordancemodulated IRL. The obtained results demonstrate the importance of\nmulti-modal sensory processing integrated with goal-oriented knowledge in IRL\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 07:48:33 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Cruz", "Francisco", ""], ["Parisi", "German I.", ""], ["Wermter", "Stefan", ""]]}, {"id": "1807.10029", "submitter": "Jiaolong Yang", "authors": "Dongqing Zhang, Jiaolong Yang, Dongqiangzi Ye and Gang Hua", "title": "LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep\n  Neural Networks", "comments": "ECCV'18 (European Conference on Computer Vision); Main paper + suppl.\n  material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although weight and activation quantization is an effective approach for Deep\nNeural Network (DNN) compression and has a lot of potentials to increase\ninference speed leveraging bit-operations, there is still a noticeable gap in\nterms of prediction accuracy between the quantized model and the full-precision\nmodel. To address this gap, we propose to jointly train a quantized,\nbit-operation-compatible DNN and its associated quantizers, as opposed to using\nfixed, handcrafted quantization schemes such as uniform or logarithmic\nquantization. Our method for learning the quantizers applies to both network\nweights and activations with arbitrary-bit precision, and our quantizers are\neasy to train. The comprehensive experiments on CIFAR-10 and ImageNet datasets\nshow that our method works consistently well for various network structures\nsuch as AlexNet, VGG-Net, GoogLeNet, ResNet, and DenseNet, surpassing previous\nquantization methods in terms of accuracy by an appreciable margin. Code\navailable at https://github.com/Microsoft/LQ-Nets\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 09:26:39 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Zhang", "Dongqing", ""], ["Yang", "Jiaolong", ""], ["Ye", "Dongqiangzi", ""], ["Hua", "Gang", ""]]}, {"id": "1807.10096", "submitter": "Georgios Leontidis", "authors": "Fabio De Sousa Ribeiro, Francesco Caliva, Dionysios Chionis,\n  Abdelhamid Dokhane, Antonios Mylonakis, Christophe Demaziere, Georgios\n  Leontidis and Stefanos Kollias", "title": "Towards a Deep Unified Framework for Nuclear Reactor Perturbation\n  Analysis", "comments": "8 pages, 8 figures, 5 tables; typos corrected, added references,\n  minor alterations, results unchanged", "journal-ref": null, "doi": "10.1109/SSCI.2018.8628637", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we take the first steps towards a novel unified framework for\nthe analysis of perturbations in both the Time and Frequency domains. The\nidentification of type and source of such perturbations is fundamental for\nmonitoring reactor cores and guarantee safety while running at nominal\nconditions. A 3D Convolutional Neural Network (3D-CNN) was employed to analyse\nperturbations happening in the frequency domain, such as an absorber of\nvariable strength or propagating perturbation. Recurrent neural networks (RNN),\nspecifically Long Short-Term Memory (LSTM) networks were used to study signal\nsequences related to perturbations induced in the time domain, including the\nvibrations of fuel assemblies and the fluctuations of thermal-hydraulic\nparameters at the inlet of the reactor coolant loops. 512 dimensional\nrepresentations were extracted from the 3D-CNN and LSTM architectures, and used\nas input to a fused multi-sigmoid classification layer to recognise the\nperturbation type. If the perturbation is in the frequency domain, a separate\nfully-connected layer utilises said representations to regress the coordinates\nof its source. The results showed that the perturbation type can be recognised\nwith high accuracy in all cases, and frequency domain scenario sources can be\nlocalised with high precision.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 12:34:25 GMT"}, {"version": "v2", "created": "Sat, 8 Sep 2018 21:06:57 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ribeiro", "Fabio De Sousa", ""], ["Caliva", "Francesco", ""], ["Chionis", "Dionysios", ""], ["Dokhane", "Abdelhamid", ""], ["Mylonakis", "Antonios", ""], ["Demaziere", "Christophe", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1807.10104", "submitter": "Jonathan Mamou", "authors": "Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Ido Dagan, Yoav\n  Goldberg, Alon Eirew, Yael Green, Shira Guskin, Peter Izsak, Daniel Korat", "title": "Term Set Expansion based on Multi-Context Term Embeddings: an End-to-end\n  Workflow", "comments": "COLING 2018 System Demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present SetExpander, a corpus-based system for expanding a seed set of\nterms into a more complete set of terms that belong to the same semantic class.\nSetExpander implements an iterative end-to end workflow for term set expansion.\nIt enables users to easily select a seed set of terms, expand it, view the\nexpanded set, validate it, re-expand the validated set and store it, thus\nsimplifying the extraction of domain-specific fine-grained semantic classes.\nSetExpander has been used for solving real-life use cases including integration\nin an automated recruitment system and an issues and defects resolution system.\nA video demo of SetExpander is available at\nhttps://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images\nwere blurred for privacy reasons).\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:11:51 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Mamou", "Jonathan", ""], ["Pereg", "Oren", ""], ["Wasserblat", "Moshe", ""], ["Dagan", "Ido", ""], ["Goldberg", "Yoav", ""], ["Eirew", "Alon", ""], ["Green", "Yael", ""], ["Guskin", "Shira", ""], ["Izsak", "Peter", ""], ["Korat", "Daniel", ""]]}, {"id": "1807.10110", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Ville Hautam\\\"aki", "title": "ToriLLE: Learning Environment for Hand-to-Hand Combat", "comments": "https://github.com/Miffyli/ToriLLE . Accepted to IEEE Conference on\n  Games 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Toribash Learning Environment (ToriLLE), a learning environment\nfor machine learning agents based on the video game Toribash. Toribash is a\nMuJoCo-like environment of two humanoid character fighting each other\nhand-to-hand, controlled by changing actuation modes of the joints. Competitive\nnature of Toribash as well its focused domain provide a platform for evaluating\nself-play methods, and evaluating machine learning agents against human\nplayers. In this paper we describe the environment with ToriLLE's capabilities\nand limitations, and experimentally show its applicability as a learning\nenvironment. The source code of the environment and conducted experiments can\nbe found at https://github.com/Miffyli/ToriLLE.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:27:35 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 14:12:22 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 10:29:48 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1807.10117", "submitter": "Guoqiang Zhang", "authors": "G. Zhang and H. Li", "title": "Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, self-normalizing neural networks (SNNs) have been proposed with the\nintention to avoid batch or weight normalization. The key step in SNNs is to\nproperly scale the exponential linear unit (referred to as SELU) to inherently\nincorporate normalization based on central limit theory. SELU is a\nmonotonically increasing function, where it has an approximately constant\nnegative output for large negative input. In this work, we propose a new\nactivation function to break the monotonicity property of SELU while still\npreserving the self-normalizing property. Differently from SELU, the new\nfunction introduces a bump-shaped function in the region of negative input by\nregularizing a linear function with a scaled exponential function, which is\nreferred to as a scaled exponentially-regularized linear unit (SERLU). The\nbump-shaped function has approximately zero response to large negative input\nwhile being able to push the output of SERLU towards zero mean statistically.\nTo effectively combat over-fitting, we develop a so-called shift-dropout for\nSERLU, which includes standard dropout as a special case. Experimental results\non MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide\nconsistently promising results in comparison to other 5 activation functions\nincluding ELU, SELU, Swish, Leakly ReLU and ReLU.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:33:49 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 09:16:41 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Zhang", "G.", ""], ["Li", "H.", ""]]}, {"id": "1807.10119", "submitter": "Yuzhe Ma", "authors": "Yuzhe Ma, Ran Chen, Wei Li, Fanhua Shang, Wenjian Yu, Minsik Cho, Bei\n  Yu", "title": "A Unified Approximation Framework for Compressing and Accelerating Deep\n  Neural Networks", "comments": "8 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved significant success in a variety of\nreal world applications, i.e., image classification. However, tons of\nparameters in the networks restrict the efficiency of neural networks due to\nthe large model size and the intensive computation. To address this issue,\nvarious approximation techniques have been investigated, which seek for a light\nweighted network with little performance degradation in exchange of smaller\nmodel size or faster inference. Both low-rankness and sparsity are appealing\nproperties for the network approximation. In this paper we propose a unified\nframework to compress the convolutional neural networks (CNNs) by combining\nthese two properties, while taking the nonlinear activation into consideration.\nEach layer in the network is approximated by the sum of a structured sparse\ncomponent and a low-rank component, which is formulated as an optimization\nproblem. Then, an extended version of alternating direction method of\nmultipliers (ADMM) with guaranteed convergence is presented to solve the\nrelaxed optimization problem. Experiments are carried out on VGG-16, AlexNet\nand GoogLeNet with large image classification datasets. The results outperform\nprevious work in terms of accuracy degradation, compression rate and speedup\nratio. The proposed method is able to remarkably compress the model (with up to\n4.9x reduction of parameters) at a cost of little loss or without loss on\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 13:36:19 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 05:37:24 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 03:06:00 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ma", "Yuzhe", ""], ["Chen", "Ran", ""], ["Li", "Wei", ""], ["Shang", "Fanhua", ""], ["Yu", "Wenjian", ""], ["Cho", "Minsik", ""], ["Yu", "Bei", ""]]}, {"id": "1807.10251", "submitter": "Hongyu Guo", "authors": "Hongyu Guo, Yongyi Mao, Ali Al-Bashabsheh and Richong Zhang", "title": "Aggregated Learning: A Deep Learning Framework Based on\n  Information-Bottleneck Vector Quantization", "comments": "with Supplementary Materials, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the notion of information bottleneck (IB), we formulate a\nquantization problem called \"IB quantization\". We show that IB quantization is\nequivalent to learning based on the IB principle. Under this equivalence, the\nstandard neural network models can be viewed as scalar (single sample) IB\nquantizers. It is known, from conventional rate-distortion theory, that scalar\nquantizers are inferior to vector (multi-sample) quantizers. Such a deficiency\nthen inspires us to develop a novel learning framework, AgrLearn, that\ncorresponds to vector IB quantizers for learning with neural networks. Unlike\nstandard networks, AgrLearn simultaneously optimizes against multiple data\nsamples. We experimentally verify that AgrLearn can result in significant\nimprovements when applied to several current deep learning architectures for\nimage recognition and text classification. We also empirically show that\nAgrLearn can reduce up to 80% of the training samples needed for ResNet\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:22:29 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 20:55:00 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 04:29:27 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Guo", "Hongyu", ""], ["Mao", "Yongyi", ""], ["Al-Bashabsheh", "Ali", ""], ["Zhang", "Richong", ""]]}, {"id": "1807.10268", "submitter": "Andrzej Kucik", "authors": "Andrzej Stanis{\\l}aw Kucik, Konstantin Korovin", "title": "Premise selection with neural networks and distributed representation of\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the problem of selecting relevant premises for a proof of a given\nstatement. When stated as a binary classification task for pairs (conjecture,\naxiom), it can be efficiently solved using artificial neural networks. The key\ndifference between our advance to solve this problem and previous approaches is\nthe use of just functional signatures of premises. To further improve the\nperformance of the model, we use dimensionality reduction technique, to replace\nlong and sparse signature vectors with their compact and dense embedded\nversions. These are obtained by firstly defining the concept of a context for\neach functor symbol, and then training a simple neural network to predict the\ndistribution of other functor symbols in the context of this functor. After\ntraining the network, the output of its hidden layer is used to construct a\nlower dimensional embedding of a functional signature (for each premise) with a\ndistributed representation of features. This allows us to use 512-dimensional\nembeddings for conjecture-axiom pairs, containing enough information about the\noriginal statements to reach the accuracy of 76.45% in premise selection task,\nonly with simple two-layer densely connected neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:54:58 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Kucik", "Andrzej Stanis\u0142aw", ""], ["Korovin", "Konstantin", ""]]}, {"id": "1807.10299", "submitter": "Joshua Achiam", "authors": "Joshua Achiam, Harrison Edwards, Dario Amodei, Pieter Abbeel", "title": "Variational Option Discovery Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore methods for option discovery based on variational inference and\nmake two algorithmic contributions. First: we highlight a tight connection\nbetween variational option discovery methods and variational autoencoders, and\nintroduce Variational Autoencoding Learning of Options by Reinforcement\n(VALOR), a new method derived from the connection. In VALOR, the policy encodes\ncontexts from a noise distribution into trajectories, and the decoder recovers\nthe contexts from the complete trajectories. Second: we propose a curriculum\nlearning approach where the number of contexts seen by the agent increases\nwhenever the agent's performance is strong enough (as measured by the decoder)\non the current set of contexts. We show that this simple trick stabilizes\ntraining for VALOR and prior variational option discovery methods, allowing a\nsingle agent to learn many more modes of behavior than it could with a fixed\ncontext distribution. Finally, we investigate other topics related to\nvariational option discovery, including fundamental limitations of the general\napproach and the applicability of learned options to downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 18:05:45 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Achiam", "Joshua", ""], ["Edwards", "Harrison", ""], ["Amodei", "Dario", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1807.10303", "submitter": "Joris Gu\\'erin", "authors": "Joris Gu\\'erin, Olivier Gibaru, Eric Nyiri, St\\'ephane Thiery and\n  Byron Boots", "title": "Semantically Meaningful View Selection", "comments": "6 pages double columns, 5 figures, 3 tables, Accepted for\n  presentation at IROS 2018, Madrid, Spain (46% acceptance)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An understanding of the nature of objects could help robots to solve both\nhigh-level abstract tasks and improve performance at lower-level concrete\ntasks. Although deep learning has facilitated progress in image understanding,\na robot's performance in problems like object recognition often depends on the\nangle from which the object is observed. Traditionally, robot sorting tasks\nrely on a fixed top-down view of an object. By changing its viewing angle, a\nrobot can select a more semantically informative view leading to better\nperformance for object recognition. In this paper, we introduce the problem of\nsemantic view selection, which seeks to find good camera poses to gain semantic\nknowledge about an observed object. We propose a conceptual formulation of the\nproblem, together with a solvable relaxation based on clustering. We then\npresent a new image dataset consisting of around 10k images representing\nvarious views of 144 objects under different poses. Finally we use this dataset\nto propose a first solution to the problem by training a neural network to\npredict a \"semantic score\" from a top view image and camera pose. The views\npredicted to have higher scores are then shown to provide better clustering\nresults than fixed top-down views.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 18:17:19 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Gu\u00e9rin", "Joris", ""], ["Gibaru", "Olivier", ""], ["Nyiri", "Eric", ""], ["Thiery", "St\u00e9phane", ""], ["Boots", "Byron", ""]]}, {"id": "1807.10399", "submitter": "Murat Kocaoglu", "authors": "Murat Kocaoglu, Sanjay Shakkottai, Alexandros G. Dimakis, Constantine\n  Caramanis, Sriram Vishwanath", "title": "Applications of Common Entropy for Causal Inference", "comments": "In Proceedings of NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of discovering the simplest latent variable that can\nmake two observed discrete variables conditionally independent. The minimum\nentropy required for such a latent is known as common entropy in information\ntheory. We extend this notion to Renyi common entropy by minimizing the Renyi\nentropy of the latent variable. To efficiently compute common entropy, we\npropose an iterative algorithm that can be used to discover the trade-off\nbetween the entropy of the latent variable and the conditional mutual\ninformation of the observed variables. We show two applications of common\nentropy in causal inference: First, under the assumption that there are no\nlow-entropy mediators, it can be used to distinguish causation from spurious\ncorrelation among almost all joint distributions on simple causal graphs with\ntwo observed variables. Second, common entropy can be used to improve\nconstraint-based methods such as PC or FCI algorithms in the small-sample\nregime, where these methods are known to struggle. We propose a modification to\nthese constraint-based methods to assess if a separating set found by these\nalgorithms is valid using common entropy. We finally evaluate our algorithms on\nsynthetic and real data to establish their performance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 23:30:09 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 21:20:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kocaoglu", "Murat", ""], ["Shakkottai", "Sanjay", ""], ["Dimakis", "Alexandros G.", ""], ["Caramanis", "Constantine", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1807.10413", "submitter": "Ulrich Viereck", "authors": "Ulrich Viereck, Xingchao Peng, Kate Saenko, Robert Platt", "title": "Adapting control policies from simulation to reality using a pairwise\n  loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach to domain transfer based on a pairwise loss\nfunction that helps transfer control policies learned in simulation onto a real\nrobot. We explore the idea in the context of a 'category level' manipulation\ntask where a control policy is learned that enables a robot to perform a mating\ntask involving novel objects. We explore the case where depth images are used\nas the main form of sensor input. Our experimental results demonstrate that\nproposed method consistently outperforms baseline methods that train only in\nsimulation or that combine real and simulated data in a naive way.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 01:54:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 19:42:23 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Viereck", "Ulrich", ""], ["Peng", "Xingchao", ""], ["Saenko", "Kate", ""], ["Platt", "Robert", ""]]}, {"id": "1807.10454", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Cho-Jui Hsieh", "title": "Rob-GAN: Generator, Discriminator, and Adversarial Attacker", "comments": "CVPR'19 camera ready, project url:\n  https://github.com/xuanqing94/RobGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two important concepts in adversarial deep learning---adversarial\ntraining and generative adversarial network (GAN). Adversarial training is the\ntechnique used to improve the robustness of discriminator by combining\nadversarial attacker and discriminator in the training phase. GAN is commonly\nused for image generation by jointly optimizing discriminator and generator. We\nshow these two concepts are indeed closely related and can be used to\nstrengthen each other---adding a generator to the adversarial training\nprocedure can improve the robustness of discriminators, and adding an\nadversarial attack to GAN training can improve the convergence speed and lead\nto better generators. Combining these two insights, we develop a framework\ncalled Rob-GAN to jointly optimize generator and discriminator in the presence\nof adversarial attacks---the generator generates fake images to fool\ndiscriminator; the adversarial attacker perturbs real images to fool the\ndiscriminator, and the discriminator wants to minimize loss under fake and\nadversarial images. Through this end-to-end training procedure, we are able to\nsimultaneously improve the convergence speed of GAN training, the quality of\nsynthetic images, and the robustness of discriminator under strong adversarial\nattacks. Experimental results demonstrate that the obtained classifier is more\nrobust than the state-of-the-art adversarial training approach, and the\ngenerator outperforms SN-GAN on ImageNet-143.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 06:50:43 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 16:57:47 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2019 21:12:02 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Liu", "Xuanqing", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1807.10511", "submitter": "Asan Agibetov", "authors": "Asan Agibetov and Matthias Samwald", "title": "Global and local evaluation of link prediction tasks with neural\n  embeddings", "comments": "Accepted to 4th Semantic Deep Learning (SemDeep-4) Workshop at the\n  ISWC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus our attention on the link prediction problem for knowledge graphs,\nwhich is treated herein as a binary classification task on neural embeddings of\nthe entities. By comparing, combining and extending different methodologies for\nlink prediction on graph-based data coming from different domains, we formalize\na unified methodology for the quality evaluation benchmark of neural embeddings\nfor knowledge graphs. This benchmark is then used to empirically investigate\nthe potential of training neural embeddings globally for the entire graph, as\nopposed to the usual way of training embeddings locally for a specific\nrelation. This new way of testing the quality of the embeddings evaluates the\nperformance of binary classifiers for scalable link prediction with limited\ndata. Our evaluation pipeline is made open source, and with this we aim to draw\nmore attention of the community towards an important issue of transparency and\nreproducibility of the neural embeddings evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 09:45:04 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "1807.10580", "submitter": "Zhijie Fang", "authors": "Zhijie Fang and Antonio M. L\\'opez", "title": "Is the Pedestrian going to Cross? Answering by 2D Pose Estimation", "comments": "This is a paper presented in IEEE Intelligent Vehicles Symposium\n  (IEEE IV 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our recent work suggests that, thanks to nowadays powerful CNNs, image-based\n2D pose estimation is a promising cue for determining pedestrian intentions\nsuch as crossing the road in the path of the ego-vehicle, stopping before\nentering the road, and starting to walk or bending towards the road. This\nstatement is based on the results obtained on non-naturalistic sequences\n(Daimler dataset), i.e. in sequences choreographed specifically for performing\nthe study. Fortunately, a new publicly available dataset (JAAD) has appeared\nrecently to allow developing methods for detecting pedestrian intentions in\nnaturalistic driving conditions; more specifically, for addressing the relevant\nquestion is the pedestrian going to cross? Accordingly, in this paper we use\nJAAD to assess the usefulness of 2D pose estimation for answering such a\nquestion. We combine CNN-based pedestrian detection, tracking and pose\nestimation to predict the crossing action from monocular images. Overall, the\nproposed pipeline provides new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 17:57:54 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Fang", "Zhijie", ""], ["L\u00f3pez", "Antonio M.", ""]]}, {"id": "1807.10587", "submitter": "Gabriel Kreiman", "authors": "Mengmi Zhang, Jiashi Feng, Keng Teck Ma, Joo Hwee Lim, Qi Zhao,\n  Gabriel Kreiman", "title": "Finding any Waldo: zero-shot invariant and efficient visual search", "comments": "Number of figures: 6 Number of supplementary figures: 14", "journal-ref": null, "doi": "10.1038/s41467-018-06217-x", "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for a target object in a cluttered scene constitutes a fundamental\nchallenge in daily vision. Visual search must be selective enough to\ndiscriminate the target from distractors, invariant to changes in the\nappearance of the target, efficient to avoid exhaustive exploration of the\nimage, and must generalize to locate novel target objects with zero-shot\ntraining. Previous work has focused on searching for perfect matches of a\ntarget after extensive category-specific training. Here we show for the first\ntime that humans can efficiently and invariantly search for natural objects in\ncomplex scenes. To gain insight into the mechanisms that guide visual search,\nwe propose a biologically inspired computational model that can locate targets\nwithout exhaustive sampling and generalize to novel objects. The model provides\nan approximation to the mechanisms integrating bottom-up and top-down signals\nduring search in natural scenes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:17:34 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Zhang", "Mengmi", ""], ["Feng", "Jiashi", ""], ["Ma", "Keng Teck", ""], ["Lim", "Joo Hwee", ""], ["Zhao", "Qi", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1807.10615", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Sameep Mehta, Shravika Mittal, Ashima Suvarna", "title": "Judging a Book by its Description : Analyzing Gender Stereotypes in the\n  Man Bookers Prize Winning Fiction", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.04117", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of gender stereotypes in many aspects of society is a well-known\nphenomenon. In this paper, we focus on studying and quantifying such\nstereotypes and bias in the Man Bookers Prize winning fiction. We consider 275\nbooks shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias\nis analyzed by semantic modeling of book descriptions on Goodreads. This\nreveals the pervasiveness of gender bias and stereotype in the books on\ndifferent features like occupation, introductions and actions associated to the\ncharacters in the book.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 08:36:02 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Madaan", "Nishtha", ""], ["Mehta", "Sameep", ""], ["Mittal", "Shravika", ""], ["Suvarna", "Ashima", ""]]}, {"id": "1807.10643", "submitter": "Lucas Lamata", "authors": "Yongcheng Ding, Lucas Lamata, Mikel Sanz, Xi Chen, and Enrique Solano", "title": "Experimental Implementation of a Quantum Autoencoder via Quantum Adders", "comments": null, "journal-ref": "Advanced Quantum Technologies 1800065, 2019", "doi": "10.1002/qute.201800065", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum autoencoders allow for reducing the amount of resources in a quantum\ncomputation by mapping the original Hilbert space onto a reduced space with the\nrelevant information. Recently, it was proposed to employ approximate quantum\nadders to implement quantum autoencoders in quantum technologies. Here, we\ncarry out the experimental implementation of this proposal in the Rigetti cloud\nquantum computer employing up to three qubits. The experimental fidelities are\nin good agreement with the theoretical prediction, thus proving the feasibility\nto realize quantum autoencoders via quantum adders in state-of-the-art\nsuperconducting quantum technologies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 14:13:30 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 09:09:16 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Ding", "Yongcheng", ""], ["Lamata", "Lucas", ""], ["Sanz", "Mikel", ""], ["Chen", "Xi", ""], ["Solano", "Enrique", ""]]}, {"id": "1807.10680", "submitter": "Klaus Broelemann", "authors": "Klaus Broelemann, Gjergji Kasneci", "title": "Combining Restricted Boltzmann Machines with Neural Networks for Latent\n  Truth Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent truth discovery, LTD for short, refers to the problem of aggregating\nltiple claims from various sources in order to estimate the plausibility of\natements about entities. In the absence of a ground truth, this problem is\nhighly challenging, when some sources provide conflicting claims and others no\nclaims at all. In this work we provide an unsupervised stochastic inference\nprocedure on top of a model that combines restricted Boltzmann machines with\nfeed-forward neural networks to accurately infer the reliability of sources as\nwell as the plausibility of statements about entities. In comparison to prior\nwork our approach stands out (1) by allowing the incorporation of arbitrary\nfeatures about sources and claims, (2) by generalizing from reliability per\nsource towards a reliability function, and thus (3) enabling the estimation of\nsource reliability even for sources that have provided no or very few claims,\n(4) by building on efficient and scalable stochastic inference algorithms, and\n(5) by outperforming the state-of-the-art by a considerable margin.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:19:31 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "1807.10756", "submitter": "Woochan Hwang", "authors": "Sejin Park, Woochan Hwang, Kyu Hwan Jung, Joon Beom Seo, Namkug Kim", "title": "False Positive Reduction by Actively Mining Negative Samples for\n  Pulmonary Nodule Detection in Chest Radiographs", "comments": "Presented at the 2nd SIIM C-MIMI(SIIM Conference on Machine\n  Intelligence in Medical Imaging)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating large quantities of quality labeled data in medical imaging is\nvery time consuming and expensive. The performance of supervised algorithms for\nvarious tasks on imaging has improved drastically over the years, however the\navailability of data to train these algorithms have become one of the main\nbottlenecks for implementation. To address this, we propose a semi-supervised\nlearning method where pseudo-negative labels from unlabeled data are used to\nfurther refine the performance of a pulmonary nodule detection network in chest\nradiographs. After training with the proposed network, the false positive rate\nwas reduced to 0.1266 from 0.4864 while maintaining sensitivity at 0.89.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 23:29:39 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Park", "Sejin", ""], ["Hwang", "Woochan", ""], ["Jung", "Kyu Hwan", ""], ["Seo", "Joon Beom", ""], ["Kim", "Namkug", ""]]}, {"id": "1807.10760", "submitter": "Jinming Duan", "authors": "Jinming Duan, Jo Schlemper, Wenjia Bai, Timothy J W Dawes, Ghalib\n  Bello, Georgia Doumou, Antonio De Marvao, Declan P O'Regan, Daniel Rueckert", "title": "Deep nested level sets: Fully automated segmentation of cardiac MR\n  images in patients with pulmonary hypertension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel and accurate optimisation method for\nsegmentation of cardiac MR (CMR) images in patients with pulmonary hypertension\n(PH). The proposed method explicitly takes into account the image features\nlearned from a deep neural network. To this end, we estimate simultaneous\nprobability maps over region and edge locations in CMR images using a fully\nconvolutional network. Due to the distinct morphology of the heart in patients\nwith PH, these probability maps can then be incorporated in a single nested\nlevel set optimisation framework to achieve multi-region segmentation with high\nefficiency. The proposed method uses an automatic way for level set\ninitialisation and thus the whole optimisation is fully automated. We\ndemonstrate that the proposed deep nested level set (DNLS) method outperforms\nexisting state-of-the-art methods for CMR segmentation in PH patients.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 22:38:12 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Duan", "Jinming", ""], ["Schlemper", "Jo", ""], ["Bai", "Wenjia", ""], ["Dawes", "Timothy J W", ""], ["Bello", "Ghalib", ""], ["Doumou", "Georgia", ""], ["De Marvao", "Antonio", ""], ["O'Regan", "Declan P", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1807.10847", "submitter": "Bryan Head", "authors": "Bryan Head and Uri Wilensky", "title": "Agent cognition through micro-simulations: Adaptive and tunable\n  intelligence with NetLogo LevelSpace", "comments": "Model source code available here:\n  https://github.com/qiemem/Wolf-Sheep-Predation-Micro-Sims, In: Unifying\n  Themes in Complex Systems IX. ICCS 2018. Springer Proceedings in Complexity.\n  Springer, Cham", "journal-ref": null, "doi": "10.1007/978-3-319-96661-8_7", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a method of endowing agents in an agent-based model (ABM) with\nsophisticated cognitive capabilities and a naturally tunable level of\nintelligence. Often, ABMs use random behavior or greedy algorithms for\nmaximizing objectives (such as a predator always chasing after the closest\nprey). However, random behavior is too simplistic in many circumstances and\ngreedy algorithms, as well as classic AI planning techniques, can be brittle in\nthe context of the unpredictable and emergent situations in which agents may\nfind themselves. Our method, called agent-centric Monte Carlo cognition\n(ACMCC), centers around using a separate agent-based model to represent the\nagents' cognition. This model is then used by the agents in the primary model\nto predict the outcomes of their actions, and thus guide their behavior. To\nthat end, we have implemented our method in the NetLogo agent-based modeling\nplatform, using the recently released LevelSpace extension, which we developed\nto allow NetLogo models to interact with other NetLogo models. As an\nillustrative example, we extend the Wolf Sheep Predation model (included with\nNetLogo) by using ACMCC to guide animal behavior, and analyze the impact on\nagent performance and model dynamics. We find that ACMCC provides a reliable\nand understandable method of controlling agent intelligence, and has a large\nimpact on agent performance and model dynamics even at low settings.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 22:33:40 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Head", "Bryan", ""], ["Wilensky", "Uri", ""]]}, {"id": "1807.10857", "submitter": "Shubham Toshniwal", "authors": "Shubham Toshniwal, Anjuli Kannan, Chung-Cheng Chiu, Yonghui Wu, Tara N\n  Sainath, Karen Livescu", "title": "A Comparison of Techniques for Language Model Integration in\n  Encoder-Decoder Speech Recognition", "comments": "Accepted in SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based recurrent neural encoder-decoder models present an elegant\nsolution to the automatic speech recognition problem. This approach folds the\nacoustic model, pronunciation model, and language model into a single network\nand requires only a parallel corpus of speech and text for training. However,\nunlike in conventional approaches that combine separate acoustic and language\nmodels, it is not clear how to use additional (unpaired) text. While there has\nbeen previous work on methods addressing this problem, a thorough comparison\namong methods is still lacking. In this paper, we compare a suite of past\nmethods and some of our own proposed methods for using unpaired text data to\nimprove encoder-decoder models. For evaluation, we use the medium-sized\nSwitchboard data set and the large-scale Google voice search and dictation data\nsets. Our results confirm the benefits of using unpaired text across a range of\nmethods and data sets. Surprisingly, for first-pass decoding, the rather simple\napproach of shallow fusion performs best across data sets. However, for Google\ndata sets we find that cold fusion has a lower oracle error rate and\noutperforms other approaches after second-pass rescoring on the Google voice\nsearch data set.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 23:33:33 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 23:21:14 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Toshniwal", "Shubham", ""], ["Kannan", "Anjuli", ""], ["Chiu", "Chung-Cheng", ""], ["Wu", "Yonghui", ""], ["Sainath", "Tara N", ""], ["Livescu", "Karen", ""]]}, {"id": "1807.10934", "submitter": "Leye Wang", "authors": "Di Chai, Leye Wang, Qiang Yang", "title": "Bike Flow Prediction with Multi-Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fundamental issue in managing bike sharing systems is the bike flow\nprediction. Due to the hardness of predicting the flow for a single station,\nrecent research works often predict the bike flow at cluster-level. While such\nstudies gain satisfactory prediction accuracy, they cannot directly guide some\nfine-grained bike sharing system management issues at station-level. In this\npaper, we revisit the problem of the station-level bike flow prediction, aiming\nto boost the prediction accuracy leveraging the breakthroughs of deep learning\ntechniques. We propose a new multi-graph convolutional neural network model to\npredict the bike flow at station-level, where the key novelty is viewing the\nbike sharing system from the graph perspective. More specifically, we construct\nmultiple inter-station graphs for a bike sharing system. In each graph, nodes\nare stations, and edges are a certain type of relations between stations. Then,\nmultiple graphs are constructed to reflect heterogeneous relationships (e.g.,\ndistance, ride record correlation). Afterward, we fuse the multiple graphs and\nthen apply the convolutional layers on the fused graph to predict station-level\nfuture bike flow. In addition to the estimated bike flow value, our model also\ngives the prediction confidence interval so as to help the bike sharing system\nmanagers make decisions. Using New York City and Chicago bike sharing data for\nexperiments, our model can outperform state-of-the-art station-level prediction\nmodels by reducing 25.1% and 17.0% of prediction error in New York City and\nChicago, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 13:35:37 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Yang", "Qiang", ""]]}, {"id": "1807.10935", "submitter": "Xiaoyu Ge", "authors": "Xiaoyu Ge and Jochen Renz and Hua Hua", "title": "Towards Explainable Inference about Object Motion using Qualitative\n  Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability of making explainable inferences regarding physical processes\nhas long been desired. One fundamental physical process is object motion.\nInferring what causes the motion of a group of objects can even be a\nchallenging task for experts, e.g., in forensics science. Most of the work in\nthe literature relies on physics simulation to draw such infer- ences. The\nsimulation requires a precise model of the under- lying domain to work well and\nis essentially a black-box from which one can hardly obtain any useful\nexplanation. By contrast, qualitative reasoning methods have the advan- tage in\nmaking transparent inferences with ambiguous infor- mation, which makes it\nsuitable for this task. However, there has been no suitable qualitative theory\nproposed for object motion in three-dimensional space. In this paper, we take\nthis challenge and develop a qualitative theory for the motion of rigid\nobjects. Based on this theory, we develop a reasoning method to solve a very\ninteresting problem: Assuming there are several objects that were initially at\nrest and now have started to move. We want to infer what action causes the\nmovement of these objects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 13:35:39 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ge", "Xiaoyu", ""], ["Renz", "Jochen", ""], ["Hua", "Hua", ""]]}, {"id": "1807.10965", "submitter": "Tim Finin", "authors": "Jennifer Sleeman, Tim Finin, Milton Halem", "title": "Ontology-Grounded Topic Modeling for Climate Science Research", "comments": "To appear in Proc. of Semantic Web for Social Good Workshop of the\n  Int. Semantic Web Conf., Oct 2018 and published as part of the book \"Emerging\n  Topics in Semantic Technologies. ISWC 2018 Satellite Events\", E. Demidova,\n  A.J. Zaveri, E. Simperl (Eds.), ISBN: 978-3-89838-736-1, 2018, AKA Verlag\n  Berlin, (edited authors)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scientific disciplines where research findings have a strong impact on\nsociety, reducing the amount of time it takes to understand, synthesize and\nexploit the research is invaluable. Topic modeling is an effective technique\nfor summarizing a collection of documents to find the main themes among them\nand to classify other documents that have a similar mixture of co-occurring\nwords. We show how grounding a topic model with an ontology, extracted from a\nglossary of important domain phrases, improves the topics generated and makes\nthem easier to understand. We apply and evaluate this method to the climate\nscience domain. The result improves the topics generated and supports faster\nresearch understanding, discovery of social networks among researchers, and\nautomatic ontology generation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 18:26:28 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 01:08:37 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sleeman", "Jennifer", ""], ["Finin", "Tim", ""], ["Halem", "Milton", ""]]}, {"id": "1807.11024", "submitter": "Vuong M. Ngo", "authors": "L.H. Nguyen, N.T.H. Pham, V.M. Ngo", "title": "Opinion Spam Recognition Method for Online Reviews using Ontological\n  Features", "comments": "15 pages, In Journal of Science, Special Issue: Natural Science and\n  Technology, Ho Chi Minh City University of Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there are a lot of people using social media opinions to make their\ndecision on buying products or services. Opinion spam detection is a hard\nproblem because fake reviews can be made by organizations as well as\nindividuals for different purposes. They write fake reviews to mislead readers\nor automated detection system by promoting or demoting target products to\npromote them or to damage their reputations. In this paper, we pro-pose a new\napproach using knowledge-based Ontology to detect opinion spam with high\naccuracy (higher than 75%). Keywords: Opinion spam, Fake review, E-commercial,\nOntology.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:05:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Nguyen", "L. H.", ""], ["Pham", "N. T. H.", ""], ["Ngo", "V. M.", ""]]}, {"id": "1807.11061", "submitter": "Fan Xiao", "authors": "Chu-Min Li, Fan Xiao, Mao Luo, Felip Many\\`a, Zhipeng L\\\"u, Yu Li", "title": "Clause Vivification by Unit Propagation in CDCL SAT Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Original and learnt clauses in Conflict-Driven Clause Learning (CDCL) SAT\nsolvers often contain redundant literals. This may have a negative impact on\nperformance because redundant literals may deteriorate both the effectiveness\nof Boolean constraint propagation and the quality of subsequent learnt clauses.\nTo overcome this drawback, we propose a clause vivification approach that\neliminates redundant literals by applying unit propagation. The proposed clause\nvivification is activated before the SAT solver triggers some selected\nrestarts, and only affects a subset of original and learnt clauses, which are\nconsidered to be more relevant according to metrics like the literal block\ndistance (LBD). Moreover, we conducted an empirical investigation with\ninstances coming from the hard combinatorial and application categories of\nrecent SAT competitions. The results show that a remarkable number of\nadditional instances are solved when the proposed approach is incorporated into\nfive of the best performing CDCL SAT solvers (Glucose, TC_Glucose, COMiniSatPS,\nMapleCOMSPS and MapleCOMSPS_LRB). More importantly, the empirical investigation\nincludes an in-depth analysis of the effectiveness of clause vivification. It\nis worth mentioning that one of the SAT solvers described here was ranked first\nin the main track of SAT Competition 2017 thanks to the incorporation of the\nproposed clause vivification. That solver was further improved in this paper\nand won the bronze medal in the main track of SAT Competition 2018.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 14:05:55 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Li", "Chu-Min", ""], ["Xiao", "Fan", ""], ["Luo", "Mao", ""], ["Many\u00e0", "Felip", ""], ["L\u00fc", "Zhipeng", ""], ["Li", "Yu", ""]]}, {"id": "1807.11079", "submitter": "Wayne Wu", "authors": "Wayne Wu, Yunxuan Zhang, Cheng Li, Chen Qian, Chen Change Loy", "title": "ReenactGAN: Learning to Reenact Faces via Boundary Transfer", "comments": "Accepted to ECCV 2018. Project page:\n  https://wywu.github.io/projects/ReenactGAN/ReenactGAN.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel learning-based framework for face reenactment. The\nproposed method, known as ReenactGAN, is capable of transferring facial\nmovements and expressions from monocular video input of an arbitrary person to\na target person. Instead of performing a direct transfer in the pixel space,\nwhich could result in structural artifacts, we first map the source face onto a\nboundary latent space. A transformer is subsequently used to adapt the boundary\nof source face to the boundary of target face. Finally, a target-specific\ndecoder is used to generate the reenacted target face. Thanks to the effective\nand reliable boundary-based transfer, our method can perform photo-realistic\nface reenactment. In addition, ReenactGAN is appealing in that the whole\nreenactment process is purely feed-forward, and thus the reenactment process\ncan run in real-time (30 FPS on one GTX 1080 GPU). Dataset and model will be\npublicly available at\nhttps://wywu.github.io/projects/ReenactGAN/ReenactGAN.html\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 16:35:15 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Wu", "Wayne", ""], ["Zhang", "Yunxuan", ""], ["Li", "Cheng", ""], ["Qian", "Chen", ""], ["Loy", "Chen Change", ""]]}, {"id": "1807.11112", "submitter": "Huy Tu", "authors": "Huy Tu and Vivek Nair", "title": "Is One Hyperparameter Optimizer Enough?", "comments": "7 pages, 2 columns, accepted for SWAN18", "journal-ref": null, "doi": "10.1145/3278142.3278145", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter tuning is the black art of automatically finding a good\ncombination of control parameters for a data miner. While widely applied in\nempirical Software Engineering, there has not been much discussion on which\nhyperparameter tuner is best for software analytics. To address this gap in the\nliterature, this paper applied a range of hyperparameter optimizers (grid\nsearch, random search, differential evolution, and Bayesian optimization) to\ndefect prediction problem. Surprisingly, no hyperparameter optimizer was\nobserved to be `best' and, for one of the two evaluation measures studied here\n(F-measure), hyperparameter optimization, in 50\\% cases, was no better than\nusing default configurations.\n  We conclude that hyperparameter optimization is more nuanced than previously\nbelieved. While such optimization can certainly lead to large improvements in\nthe performance of classifiers used in software analytics, it remains to be\nseen which specific optimizers should be applied to a new dataset.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 21:26:12 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 17:33:25 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 21:56:46 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2018 19:30:21 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Tu", "Huy", ""], ["Nair", "Vivek", ""]]}, {"id": "1807.11113", "submitter": "Nanqing Dong", "authors": "Nanqing Dong, Michael Kampffmeyer, Xiaodan Liang, Zeya Wang, Wei Dai,\n  Eric P. Xing", "title": "Reinforced Auto-Zoom Net: Towards Accurate and Fast Breast Cancer\n  Segmentation in Whole-slide Images", "comments": "Accepted by MICCAI 2018 Workshop on Deep Learning in Medical Image\n  Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have led to significant breakthroughs in the\ndomain of medical image analysis. However, the task of breast cancer\nsegmentation in whole-slide images (WSIs) is still underexplored. WSIs are\nlarge histopathological images with extremely high resolution. Constrained by\nthe hardware and field of view, using high-magnification patches can slow down\nthe inference process and using low-magnification patches can cause the loss of\ninformation. In this paper, we aim to achieve two seemingly conflicting goals\nfor breast cancer segmentation: accurate and fast prediction. We propose a\nsimple yet efficient framework Reinforced Auto-Zoom Net (RAZN) to tackle this\ntask. Motivated by the zoom-in operation of a pathologist using a digital\nmicroscope, RAZN learns a policy network to decide whether zooming is required\nin a given region of interest. Because the zoom-in action is selective, RAZN is\nrobust to unbalanced and noisy ground truth labels and can efficiently reduce\noverfitting. We evaluate our method on a public breast cancer dataset. RAZN\noutperforms both single-scale and multi-scale baseline approaches, achieving\nbetter accuracy at low inference cost.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 21:45:35 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Dong", "Nanqing", ""], ["Kampffmeyer", "Michael", ""], ["Liang", "Xiaodan", ""], ["Wang", "Zeya", ""], ["Dai", "Wei", ""], ["Xing", "Eric P.", ""]]}, {"id": "1807.11121", "submitter": "Jacob Beck", "authors": "Jacob Beck and Zoe Papakipos", "title": "Neural Mesh: Introducing a Notion of Space and Conservation of Energy to\n  Neural Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are based on a simplified model of the brain. In this\nproject, we wanted to relax the simplifying assumptions of a traditional neural\nnetwork by making a model that more closely emulates the low level interactions\nof neurons. Like in an RNN, our model has a state that persists between time\nsteps, so that the energies of neurons persist. However, unlike an RNN, our\nstate consists of a 2 dimensional matrix, rather than a 1 dimensional vector,\nthereby introducing a concept of distance to other neurons within the state. In\nour model, neurons can only fire to adjacent neurons, as in the brain. Like in\nthe brain, we only allow neurons to fire in a time step if they contain enough\nenergy, or excitement. We also enforce a notion of conservation of energy, so\nthat a neuron cannot excite its neighbors more than the excitement it already\ncontained at that time step. Taken together, these two features allow signals\nin the form of activations to flow around in our network over time, making our\nneural mesh more closely model signals traveling through the brain the brain.\nAlthough our main goal is to design an architecture to more closely emulate the\nbrain in the hope of having a correct internal representation of information by\nthe time we know how to properly train a general intelligence, we did benchmark\nour neural mash on a specific task. We found that by increasing the runtime of\nthe mesh, we were able to increase its accuracy without increasing the number\nof parameters.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 23:14:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Beck", "Jacob", ""], ["Papakipos", "Zoe", ""]]}, {"id": "1807.11125", "submitter": "Xiujun Li", "authors": "Xiujun Li and Yu Wang and Siqi Sun and Sarah Panda and Jingjing Liu\n  and Jianfeng Gao", "title": "Microsoft Dialogue Challenge: Building End-to-End Task-Completion\n  Dialogue Systems", "comments": "SLT 2018 Special Session: http://www.slt2018.org/news/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This proposal introduces a Dialogue Challenge for building end-to-end\ntask-completion dialogue systems, with the goal of encouraging the dialogue\nresearch community to collaborate and benchmark on standard datasets and\nunified experimental environment. In this special session, we will release\nhuman-annotated conversational data in three domains (movie-ticket booking,\nrestaurant reservation, and taxi booking), as well as an experiment platform\nwith built-in simulators in each domain, for training and evaluation purposes.\nThe final submitted systems will be evaluated both in simulated setting and by\nhuman judges.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 23:51:08 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 23:47:59 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Xiujun", ""], ["Wang", "Yu", ""], ["Sun", "Siqi", ""], ["Panda", "Sarah", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1807.11139", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling", "title": "Causal Modeling with Probabilistic Simulation Models", "comments": "PLP 2018 (The 5th Workshop on Probabilistic Logic Programming)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent authors have proposed analyzing conditional reasoning through a notion\nof intervention on a simulation program, and have found a sound and complete\naxiomatization of the logic of conditionals in this setting. Here we extend\nthis setting to the case of probabilistic simulation models. We give a natural\ndefinition of probability on formulas of the conditional language, allowing for\nthe expression of counterfactuals, and prove foundational results about this\ndefinition. We also find an axiomatization for reasoning about linear\ninequalities involving probabilities in this setting. We prove soundness,\ncompleteness, and NP-completeness of the satisfiability problem for this logic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 01:38:58 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ibeling", "Duligur", ""]]}, {"id": "1807.11150", "submitter": "Tingguang Li", "authors": "Tingguang Li, Jin Pan, Delong Zhu, Max Q.-H. Meng", "title": "Learning to Interrupt: A Hierarchical Deep Reinforcement Learning\n  Framework for Efficient Exploration", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve scenario intelligence, humans must transfer knowledge to robots by\ndeveloping goal-oriented algorithms, which are sometimes insensitive to\ndynamically changing environments. While deep reinforcement learning achieves\nsignificant success recently, it is still extremely difficult to be deployed in\nreal robots directly. In this paper, we propose a hybrid structure named\nOption-Interruption in which human knowledge is embedded into a hierarchical\nreinforcement learning framework. Our architecture has two key components:\noptions, represented by existing human-designed methods, can significantly\nspeed up the training process and interruption mechanism, based on learnable\ntermination functions, enables our system to quickly respond to the external\nenvironment. To implement this architecture, we derive a set of update rules\nbased on policy gradient methods and present a complete training process. In\nthe experiment part, our method is evaluated in Four-room navigation and\nexploration task, which shows the efficiency and flexibility of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 02:39:10 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Li", "Tingguang", ""], ["Pan", "Jin", ""], ["Zhu", "Delong", ""], ["Meng", "Max Q. -H.", ""]]}, {"id": "1807.11161", "submitter": "Hao Min Liu", "authors": "Hao-Min Liu, Yi-Hsuan Yang", "title": "Lead Sheet Generation and Arrangement by Conditional Generative\n  Adversarial Network", "comments": "7 pages, 7 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on automatic music generation has seen great progress due to the\ndevelopment of deep neural networks. However, the generation of\nmulti-instrument music of arbitrary genres still remains a challenge. Existing\nresearch either works on lead sheets or multi-track piano-rolls found in MIDIs,\nbut both musical notations have their limits. In this work, we propose a new\ntask called lead sheet arrangement to avoid such limits. A new recurrent\nconvolutional generative model for the task is proposed, along with three new\nsymbolic-domain harmonic features to facilitate learning from unpaired lead\nsheets and MIDIs. Our model can generate lead sheets and their arrangements of\neight-bar long. Audio samples of the generated result can be found at\nhttps://drive.google.com/open?id=1c0FfODTpudmLvuKBbc23VBCgQizY6-Rk\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 03:48:04 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Hao-Min", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1807.11174", "submitter": "Xin Ye", "authors": "Xin Ye, Zhe Lin, Haoxiang Li, Shibin Zheng, Yezhou Yang", "title": "Active Object Perceiver: Recognition-guided Policy Learning for Object\n  Searching on Mobile Robots", "comments": "2018 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a navigation policy for a robot to actively\nsearch for an object of interest in an indoor environment solely from its\nvisual inputs. While scene-driven visual navigation has been widely studied,\nprior efforts on learning navigation policies for robots to find objects are\nlimited. The problem is often more challenging than target scene finding as the\ntarget objects can be very small in the view and can be in an arbitrary pose.\nWe approach the problem from an active perceiver perspective, and propose a\nnovel framework that integrates a deep neural network based object recognition\nmodule and a deep reinforcement learning based action prediction mechanism. To\nvalidate our method, we conduct experiments on both a simulation dataset\n(AI2-THOR) and a real-world environment with a physical robot. We further\npropose a new decaying reward function to learn the control policy specific to\nthe object searching task. Experimental results validate the efficacy of our\nmethod, which outperforms competing methods in both average trajectory length\nand success rate.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 05:09:27 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ye", "Xin", ""], ["Lin", "Zhe", ""], ["Li", "Haoxiang", ""], ["Zheng", "Shibin", ""], ["Yang", "Yezhou", ""]]}, {"id": "1807.11215", "submitter": "Corentin Kervadec", "authors": "Corentin Kervadec, Valentin Vielzeuf, St\\'ephane Pateux, Alexis\n  Lechervy, Fr\\'ed\\'eric Jurie", "title": "CAKE: Compact and Accurate K-dimensional representation of Emotion", "comments": null, "journal-ref": "Image Analysis for Human Facial and Activity Recognition (BMVC\n  Workshop), Sep 2018, Newcastle, United Kingdom.\n  http://juz-dev.myweb.port.ac.uk/BMVCWorkshop/index.html", "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous models describing the human emotional states have been built by the\npsychology community. Alongside, Deep Neural Networks (DNN) are reaching\nexcellent performances and are becoming interesting features extraction tools\nin many computer vision tasks.Inspired by works from the psychology community,\nwe first study the link between the compact two-dimensional representation of\nthe emotion known as arousal-valence, and discrete emotion classes (e.g. anger,\nhappiness, sadness, etc.) used in the computer vision community. It enables to\nassess the benefits -- in terms of discrete emotion inference -- of adding an\nextra dimension to arousal-valence (usually named dominance). Building on these\nobservations, we propose CAKE, a 3-dimensional representation of emotion\nlearned in a multi-domain fashion, achieving accurate emotion recognition on\nseveral public datasets. Moreover, we visualize how emotions boundaries are\norganized inside DNN representations and show that DNNs are implicitly learning\narousal-valence-like descriptions of emotions. Finally, we use the CAKE\nrepresentation to compare the quality of the annotations of different public\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:03:09 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 08:07:32 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Kervadec", "Corentin", ""], ["Vielzeuf", "Valentin", ""], ["Pateux", "St\u00e9phane", ""], ["Lechervy", "Alexis", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1807.11227", "submitter": "Tao Li", "authors": "Tao Li, Lei Lin, Minsoo Choi, Kaiming Fu, Siyuan Gong, Jian Wang", "title": "YouTube AV 50K: An Annotated Corpus for Comments in Autonomous Vehicles", "comments": "in Proceedings of the Thirteenth International Joint Symposium on\n  Artificial Intelligence and Natural Language Processing (iSAI-NLP 2018)", "journal-ref": null, "doi": "10.1109/iSAI-NLP.2018.8692799", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With one billion monthly viewers, and millions of users discussing and\nsharing opinions, comments below YouTube videos are rich sources of data for\nopinion mining and sentiment analysis. We introduce the YouTube AV 50K dataset,\na freely-available collections of more than 50,000 YouTube comments and\nmetadata below autonomous vehicle (AV)-related videos. We describe its creation\nprocess, its content and data format, and discuss its possible usages.\nEspecially, we do a case study of the first self-driving car fatality to\nevaluate the dataset, and show how we can use this dataset to better understand\npublic attitudes toward self-driving cars and public reactions to the accident.\nFuture developments of the dataset are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:28:44 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 05:12:09 GMT"}, {"version": "v3", "created": "Mon, 1 Oct 2018 03:07:22 GMT"}, {"version": "v4", "created": "Mon, 15 Oct 2018 06:56:48 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Li", "Tao", ""], ["Lin", "Lei", ""], ["Choi", "Minsoo", ""], ["Fu", "Kaiming", ""], ["Gong", "Siyuan", ""], ["Wang", "Jian", ""]]}, {"id": "1807.11236", "submitter": "Liu Yongcheng", "authors": "Yongcheng Liu, Bin Fan, Lingfeng Wang, Jun Bai, Shiming Xiang,\n  Chunhong Pan", "title": "Semantic Labeling in Very High Resolution Images via a Self-Cascaded\n  Convolutional Neural Network", "comments": "accepted by ISPRS Journal of Photogrammetry and Remote Senseing 2017", "journal-ref": null, "doi": "10.1016/j.isprsjprs.2017.12.007", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic labeling for very high resolution (VHR) images in urban areas, is of\nsignificant importance in a wide range of remote sensing applications. However,\nmany confusing manmade objects and intricate fine-structured objects make it\nvery difficult to obtain both coherent and accurate labeling results. For this\nchallenging task, we propose a novel deep model with convolutional neural\nnetworks (CNNs), i.e., an end-to-end self-cascaded network (ScasNet).\nSpecifically, for confusing manmade objects, ScasNet improves the labeling\ncoherence with sequential global-to-local contexts aggregation. Technically,\nmulti-scale contexts are captured on the output of a CNN encoder, and then they\nare successively aggregated in a self-cascaded manner. Meanwhile, for\nfine-structured objects, ScasNet boosts the labeling accuracy with a\ncoarse-to-fine refinement strategy. It progressively refines the target objects\nusing the low-level features learned by CNN's shallow layers. In addition, to\ncorrect the latent fitting residual caused by multi-feature fusion inside\nScasNet, a dedicated residual correction scheme is proposed. It greatly\nimproves the effectiveness of ScasNet. Extensive experimental results on three\npublic datasets, including two challenging benchmarks, show that ScasNet\nachieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 08:49:25 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Yongcheng", ""], ["Fan", "Bin", ""], ["Wang", "Lingfeng", ""], ["Bai", "Jun", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1807.11272", "submitter": "Katar\\'ina T\\'othov\\'a", "authors": "Katar\\'ina T\\'othov\\'a, Sarah Parisot, Matthew C. H. Lee, Esther\n  Puyol-Ant\\'on, Lisa M. Koch, Andrew P. King, Ender Konukoglu, and Marc\n  Pollefeys", "title": "Uncertainty Quantification in CNN-Based Surface Prediction Using Shape\n  Priors", "comments": "Accepted to ShapeMI MICCAI 2018: Workshop on Shape in Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Surface reconstruction is a vital tool in a wide range of areas of medical\nimage analysis and clinical research. Despite the fact that many methods have\nproposed solutions to the reconstruction problem, most, due to their\ndeterministic nature, do not directly address the issue of quantifying\nuncertainty associated with their predictions. We remedy this by proposing a\nnovel probabilistic deep learning approach capable of simultaneous surface\nreconstruction and associated uncertainty prediction. The method incorporates\nprior shape information in the form of a principal component analysis (PCA)\nmodel. Experiments using the UK Biobank data show that our probabilistic\napproach outperforms an analogous deterministic PCA-based method in the task of\n2D organ delineation and quantifies uncertainty by formulating distributions\nover predicted surface vertex positions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 10:24:26 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["T\u00f3thov\u00e1", "Katar\u00edna", ""], ["Parisot", "Sarah", ""], ["Lee", "Matthew C. H.", ""], ["Puyol-Ant\u00f3n", "Esther", ""], ["Koch", "Lisa M.", ""], ["King", "Andrew P.", ""], ["Konukoglu", "Ender", ""], ["Pollefeys", "Marc", ""]]}, {"id": "1807.11284", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu, Marc Ferras Font", "title": "Unsupervised Domain Adaptation by Adversarial Learning for Robust Speech\n  Recognition", "comments": "5 pages, 2 figures, the 13th ITG conference on Speech Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we investigate the use of adversarial learning for\nunsupervised adaptation to unseen recording conditions, more specifically,\nsingle microphone far-field speech. We adapt neural networks based acoustic\nmodels trained with close-talk clean speech to the new recording conditions\nusing untranscribed adaptation data. Our experimental results on Italian\nSPEECON data set show that our proposed method achieves 19.8% relative word\nerror rate (WER) reduction compared to the unadapted models. Furthermore, this\nadaptation method is beneficial even when performed on data from another\nlanguage (i.e. French) giving 12.6% relative WER reduction.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 11:00:59 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""], ["Font", "Marc Ferras", ""]]}, {"id": "1807.11367", "submitter": "Warut Suksompong", "authors": "Hoon Oh, Ariel D. Procaccia, Warut Suksompong", "title": "Fairly Allocating Many Goods with Few Queries", "comments": "A preliminary version appears in the 33rd AAAI Conference on\n  Artificial Intelligence (AAAI), 2019", "journal-ref": "SIAM Journal on Discrete Mathematics, 35(2): 788-813 (2021)", "doi": "10.1137/20M1313349", "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the query complexity of the fair allocation of indivisible\ngoods. For two agents with arbitrary monotonic utilities, we design an\nalgorithm that computes an allocation satisfying envy-freeness up to one good\n(EF1), a relaxation of envy-freeness, using a logarithmic number of queries. We\nshow that the logarithmic query complexity bound also holds for three agents\nwith additive utilities, and that a polylogarithmic bound holds for three\nagents with monotonic utilities. These results suggest that it is possible to\nfairly allocate goods in practice even when the number of goods is extremely\nlarge. By contrast, we prove that computing an allocation satisfying\nenvy-freeness and another of its relaxations, envy-freeness up to any good\n(EFX), requires a linear number of queries even when there are only two agents\nwith identical additive utilities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 14:27:52 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 06:21:06 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Oh", "Hoon", ""], ["Procaccia", "Ariel D.", ""], ["Suksompong", "Warut", ""]]}, {"id": "1807.11429", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Brian Mac Namee", "title": "Kalman Filter-based Heuristic Ensemble (KFHE): A new perspective on\n  multi-class ensemble classification using Kalman filters", "comments": null, "journal-ref": "Volume 485, June 2019, Pages 456-485", "doi": "10.1016/j.ins.2019.02.017", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new perspective on multi-class ensemble\nclassification that considers training an ensemble as a state estimation\nproblem. The new perspective considers the final ensemble classifier model as a\nstatic state, which can be estimated using a Kalman filter that combines noisy\nestimates made by individual classifier models. A new algorithm based on this\nperspective, the Kalman Filter-based Heuristic Ensemble (KFHE), is also\npresented in this paper which shows the practical applicability of the new\nperspective. Experiments performed on 30 datasets compare KFHE with\nstate-of-the-art multi-class ensemble classification algorithms and show the\npotential and effectiveness of the new perspective and algorithm. Existing\nensemble approaches trade off classification accuracy against robustness to\nclass label noise, but KFHE is shown to be significantly better or at least as\ngood as the state-of-the-art algorithms for datasets both with and without\nclass label noise.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 16:38:51 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 21:02:48 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 21:22:03 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1807.11456", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora, Alessandro Saffiotti", "title": "Norms, Institutions, and Robots", "comments": "12 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactions within human societies are usually regulated by social norms. If\nrobots are to be accepted into human society, it is essential that they are\naware of and capable of reasoning about social norms. In this paper, we focus\non how to represent social norms in societies with humans and robots, and how\nartificial agents such as robots can reason about social norms in order to plan\nappropriate behavior. We use the notion of institution as a way to formally\ndefine and encapsulate norms, and we provide a formal framework for\ninstitutions. Our framework borrows ideas from the field of multi-agent systems\nto define abstract normative models, and ideas from the field of robotics to\ndefine physical executions as state-space trajectories. By bridging the two in\na common model, our framework allows us to use the same abstract institution\nacross physical domains and agent types. We then make our framework\ncomputational via a reduction to CSP and show experiments where this reduction\nis used for norm verification, planning, and plan execution in a domain\nincluding a mixture of humans and robots.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 17:27:06 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:43:40 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1807.11545", "submitter": "Hazrat Ali", "authors": "Kashif Sultan, Hazrat Ali and Zhongshan Zhang", "title": "Call Detail Records Driven Anomaly Detection and Traffic Prediction in\n  Mobile Cellular Networks", "comments": "IEEE Access Journal paper", "journal-ref": "10.1109/ACCESS.2018.2859756", "doi": "10.1109/ACCESS.2018.2859756", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile networks possess information about the users as well as the network.\nSuch information is useful for making the network end-to-end visible and\nintelligent. Big data analytics can efficiently analyze user and network\ninformation, unearth meaningful insights with the help of machine learning\ntools. Utilizing big data analytics and machine learning, this work contributes\nin three ways. First, we utilize the call detail records (CDR) data to detect\nanomalies in the network. For authentication and verification of anomalies, we\nuse k-means clustering, an unsupervised machine learning algorithm. Through\neffective detection of anomalies, we can proceed to suitable design for\nresource distribution as well as fault detection and avoidance. Second, we\nprepare anomaly-free data by removing anomalous activities and train a neural\nnetwork model. By passing anomaly and anomaly-free data through this model, we\nobserve the effect of anomalous activities in training of the model and also\nobserve mean square error of anomaly and anomaly free data. Lastly, we use an\nautoregressive integrated moving average (ARIMA) model to predict future\ntraffic for a user. Through simple visualization, we show that anomaly free\ndata better generalizes the learning models and performs better on prediction\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 19:37:56 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Sultan", "Kashif", ""], ["Ali", "Hazrat", ""], ["Zhang", "Zhongshan", ""]]}, {"id": "1807.11567", "submitter": "Seonghan Ryu", "authors": "Seonghan Ryu, Seokhwan Kim, Junhwi Choi, Hwanjo Yu, Gary Geunbae Lee", "title": "Neural Sentence Embedding using Only In-domain Sentences for\n  Out-of-domain Sentence Detection in Dialog Systems", "comments": "Published in Pattern Recognition Letters, 88:26-32, 2017", "journal-ref": null, "doi": "10.1016/j.patrec.2017.01.008", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure satisfactory user experience, dialog systems must be able to\ndetermine whether an input sentence is in-domain (ID) or out-of-domain (OOD).\nWe assume that only ID sentences are available as training data because\ncollecting enough OOD sentences in an unbiased way is a laborious and\ntime-consuming job. This paper proposes a novel neural sentence embedding\nmethod that represents sentences in a low-dimensional continuous vector space\nthat emphasizes aspects that distinguish ID cases from OOD cases. We first used\na large set of unlabeled text to pre-train word representations that are used\nto initialize neural sentence embedding. Then we used domain-category analysis\nas an auxiliary task to train neural sentence embedding for OOD sentence\ndetection. After the sentence representations were learned, we used them to\ntrain an autoencoder aimed at OOD sentence detection. We evaluated our method\nby experimentally comparing it to the state-of-the-art methods in an\neight-domain dialog system; our proposed method achieved the highest accuracy\nin all tests.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:31:15 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Ryu", "Seonghan", ""], ["Kim", "Seokhwan", ""], ["Choi", "Junhwi", ""], ["Yu", "Hwanjo", ""], ["Lee", "Gary Geunbae", ""]]}, {"id": "1807.11583", "submitter": "Thomas Cherico Wanger Dr.", "authors": "Thomas Cherico Wanger, Peter Frohn", "title": "Testing the Efficient Network TRaining (ENTR) Hypothesis: initially\n  reducing training image size makes Convolutional Neural Network training for\n  image recognition tasks more efficient", "comments": "12 pages, 5 figures, 1 table +++ Keywords: Image recognition,\n  Efficient Network Training hypothesis, image size increase, network\n  efficiency, ResNet models, Google Colaboratory, free cloud GPU, material\n  science, geoscience, environmental science, convolutional neural networks,\n  regularization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) for image recognition tasks are seeing\nrapid advances in the available architectures and how networks are trained\nbased on large computational infrastructure and standard datasets with millions\nof images. In contrast, performance and time constraints for example, of small\ndevices and free cloud GPUs necessitate efficient network training (i.e.,\nhighest accuracy in the shortest inference time possible), often on small\ndatasets. Here, we hypothesize that initially decreasing image size during\ntraining makes the training process more efficient, because pre-shaping weights\nwith small images and later utilizing these weights with larger images reduces\ninitial network parameters and total inference time. We test this Efficient\nNetwork TRaining (ENTR) Hypothesis by training pre-trained Residual Network\n(ResNet) models (ResNet18, 34, & 50) on three small datasets (steel\nmicrostructures, bee images, and geographic aerial images) with a free cloud\nGPU. Based on three training regimes of i) not, ii) gradually or iii) in one\nstep increasing image size over the training process, we show that initially\nreducing image size increases training efficiency consistently across datasets\nand networks. We interpret these results mechanistically in the framework of\nregularization theory. Support for the ENTR hypothesis is an important\ncontribution, because network efficiency improvements for image recognition\ntasks are needed for practical applications. In the future, it will be exciting\nto see how the ENTR hypothesis holds for large standard datasets like ImageNet\nor CIFAR, to better understand the underlying mechanisms, and how these results\ncompare to other fields such as structural learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 21:10:25 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Wanger", "Thomas Cherico", ""], ["Frohn", "Peter", ""]]}, {"id": "1807.11615", "submitter": "Diego Calvanese", "authors": "Diego Calvanese, Marlon Dumas, Fabrizio Maria Maggi, Marco Montali", "title": "Semantic DMN: Formalizing and Reasoning About Decisions in the Presence\n  of Background Knowledge", "comments": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Decision Model and Notation (DMN) is a recent OMG standard for the\nelicitation and representation of decision models, and for managing their\ninterconnection with business processes. DMN builds on the notion of decision\ntables, and their combination into more complex decision requirements graphs\n(DRGs), which bridge between business process models and decision logic models.\nDRGs may rely on additional, external business knowledge models, whose\nfunctioning is not part of the standard. In this work, we consider one of the\nmost important types of business knowledge, namely background knowledge that\nconceptually accounts for the structural aspects of the domain of interest, and\npropose decision knowledge bases (DKBs), which semantically combine DRGs\nmodeled in DMN, and domain knowledge captured by means of first-order logic\nwith datatypes. We provide a logic-based semantics for such an integration, and\nformalize different DMN reasoning tasks for DKBs. We then consider background\nknowledge formulated as a description logic ontology with datatypes, and show\nhow the main verification tasks for DMN in this enriched setting can be\nformalized as standard DL reasoning services, and actually carried out in\nExpTime. We discuss the effectiveness of our framework on a case study in\nmaritime security.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 00:27:08 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 18:39:08 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 22:34:40 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Calvanese", "Diego", ""], ["Dumas", "Marlon", ""], ["Maggi", "Fabrizio Maria", ""], ["Montali", "Marco", ""]]}, {"id": "1807.11622", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado, Marc G. Bellemare, Michael Bowling", "title": "Count-Based Exploration with the Successor Representation", "comments": "This paper appears in the Proceedings of the 34th AAAI Conference on\n  Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a simple approach for exploration in reinforcement\nlearning (RL) that allows us to develop theoretically justified algorithms in\nthe tabular case but that is also extendable to settings where function\napproximation is required. Our approach is based on the successor\nrepresentation (SR), which was originally introduced as a representation\ndefining state generalization by the similarity of successor states. Here we\nshow that the norm of the SR, while it is being learned, can be used as a\nreward bonus to incentivize exploration. In order to better understand this\ntransient behavior of the norm of the SR we introduce the substochastic\nsuccessor representation (SSR) and we show that it implicitly counts the number\nof times each state (or feature) has been observed. We use this result to\nintroduce an algorithm that performs as well as some theoretically\nsample-efficient approaches. Finally, we extend these ideas to a deep RL\nalgorithm and show that it achieves state-of-the-art performance in Atari 2600\ngames when in a low sample-complexity regime.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 01:25:44 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 02:56:53 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 16:24:45 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 16:48:02 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bellemare", "Marc G.", ""], ["Bowling", "Michael", ""]]}, {"id": "1807.11761", "submitter": "Michael Cochez", "authors": "Michael Cochez and Martina Garofalo and J\\'er\\^ome Len{\\ss}en and\n  Maria Angela Pellegrino", "title": "A First Experiment on Including Text Literals in KGloVe", "comments": "Presented at the 4th Workshop on Semantic Deep Learning (SemDeep-4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding models produce embedding vectors for entities and relations\nin Knowledge Graphs, often without taking literal properties into account. We\nshow an initial idea based on the combination of global graph structure with\nadditional information provided by textual information in properties. Our\ninitial experiment shows that this approach might be useful, but does not\nclearly outperform earlier approaches when evaluated on machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 11:18:18 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Cochez", "Michael", ""], ["Garofalo", "Martina", ""], ["Len\u00dfen", "J\u00e9r\u00f4me", ""], ["Pellegrino", "Maria Angela", ""]]}, {"id": "1807.11805", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris and Francesc X. Prenafeta-Bold\\'u", "title": "Disaster Monitoring using Unmanned Aerial Vehicles and Deep Learning", "comments": "Disaster Management for Resilience and Public Safety Workshop, Proc.\n  of EnviroInfo 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring of disasters is crucial for mitigating their effects on the\nenvironment and human population, and can be facilitated by the use of unmanned\naerial vehicles (UAV), equipped with camera sensors that produce aerial photos\nof the areas of interest. A modern technique for recognition of events based on\naerial photos is deep learning. In this paper, we present the state of the art\nwork related to the use of deep learning techniques for disaster\nidentification. We demonstrate the potential of this technique in identifying\ndisasters with high accuracy, by means of a relatively simple deep learning\nmodel. Based on a dataset of 544 images (containing disaster images such as\nfires, earthquakes, collapsed buildings, tsunami and flooding, as well as\nnon-disaster scenes), our results show an accuracy of 91% achieved, indicating\nthat deep learning, combined with UAV equipped with camera sensors, have the\npotential to predict disasters with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 13:24:31 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 09:29:37 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Prenafeta-Bold\u00fa", "Francesc X.", ""]]}, {"id": "1807.11838", "submitter": "Jonathan Connell", "authors": "Jonathan Connell", "title": "Extensible Grounding of Speech for Robot Instruction", "comments": null, "journal-ref": null, "doi": null, "report-no": "draft of chapter for \"Robots That Talk and Listen\", J. Markowitz\n  (ed.), De Grutyer 2014", "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language is a convenient interface for commanding a mobile robot. Yet\nfor this to work a number of base terms must be grounded in perceptual and\nmotor skills. We detail the language processing used on our robot ELI and\nexplain how this grounding is performed, how it interacts with user gestures,\nand how it handles phenomena such as anaphora. More importantly, however, there\nare certain concepts which the robot cannot be preprogrammed with, such as the\nnames of various objects in a household or the nature of specific tasks it may\nbe requested to perform. In these cases it is vital that there exist a method\nfor extending the grounding, essentially \"learning by being told\". We describe\nhow this was successfully implemented for learning new nouns and verbs in a\ntabletop setting. Creating this language learning kernel may be the last\nexplicit programming the robot ever needs - the core mechanism could eventually\nbe used for imparting a vast amount of knowledge, much as a child learns from\nits parents and teachers.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:31:17 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Connell", "Jonathan", ""]]}, {"id": "1807.11914", "submitter": "Alberto Marchesi", "authors": "Giuseppe De Nittis, Alberto Marchesi, Nicola Gatti", "title": "Computing the Strategy to Commit to in Polymatrix Games (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leadership games provide a powerful paradigm to model many real-world\nsettings. Most literature focuses on games with a single follower who acts\noptimistically, breaking ties in favour of the leader. Unfortunately, for\nreal-world applications, this is unlikely. In this paper, we look for\nefficiently solvable games with multiple followers who play either\noptimistically or pessimistically, i.e., breaking ties in favour or against the\nleader. We study the computational complexity of finding or approximating an\noptimistic or pessimistic leader-follower equilibrium in specific classes of\nsuccinct games---polymatrix like---which are equivalent to 2-player Bayesian\ngames with uncertainty over the follower, with interdependent or independent\ntypes. Furthermore, we provide an exact algorithm to find a pessimistic\nequilibrium for those game classes. Finally, we show that in general polymatrix\ngames the computation is harder even when players are forced to play pure\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 16:50:19 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["De Nittis", "Giuseppe", ""], ["Marchesi", "Alberto", ""], ["Gatti", "Nicola", ""]]}, {"id": "1807.11919", "submitter": "Sylvain Bouveret", "authors": "Aur\\'elie Beynier and Sylvain Bouveret and Michel Lema\\^itre and\n  Nicolas Maudet and Simon Rey", "title": "Efficiency, Sequenceability and Deal-Optimality in Fair Division of\n  Indivisible Goods", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.01734", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is as\nfollows: at each stage, a designated agent picks one object among those that\nremain. Another intuitive way to obtain an allocation is to give objects to\nagents in the first place, and to let agents exchange them as long as such\n\"deals\" are beneficial. This paper investigates these notions, when agents have\nadditive preferences over objects, and unveils surprising connections between\nthem, and with other efficiency and fairness notions. In particular, we show\nthat an allocation is sequenceable iff it is optimal for a certain type of\ndeals, namely cycle deals involving a single object. Furthermore, any\nPareto-optimal allocation is sequenceable, but not the converse. Regarding\nfairness, we show that an allocation can be envy-free and non-sequenceable, but\nthat every competitive equilibrium with equal incomes is sequenceable. To\ncomplete the picture, we show how some domain restrictions may affect the\nrelations between these notions. Finally, we experimentally explore the links\nbetween the scales of efficiency and fairness.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 12:13:31 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Beynier", "Aur\u00e9lie", ""], ["Bouveret", "Sylvain", ""], ["Lema\u00eetre", "Michel", ""], ["Maudet", "Nicolas", ""], ["Rey", "Simon", ""]]}, {"id": "1807.11926", "submitter": "Mengmi Zhang", "authors": "Mengmi Zhang, Gabriel Kreiman", "title": "What am I Searching for: Zero-shot Target Identity Inference in Visual\n  Search", "comments": "Accepted for presentation at EPIC@CVPR2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we infer intentions from a person's actions? As an example problem, here\nwe consider how to decipher what a person is searching for by decoding their\neye movement behavior. We conducted two psychophysics experiments where we\nmonitored eye movements while subjects searched for a target object. We defined\nthe fixations falling on non-target objects as \"error fixations\". Using those\nerror fixations, we developed a model (InferNet) to infer what the target was.\nInferNet uses a pre-trained convolutional neural network to extract features\nfrom the error fixations and computes a similarity map between the error\nfixations and all locations across the search image. The model consolidates the\nsimilarity maps across layers and integrates these maps across all error\nfixations. InferNet successfully identifies the subject's goal and outperforms\ncompetitive null models, even without any object-specific training on the\ninference task.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 17:15:11 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 01:17:22 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Zhang", "Mengmi", ""], ["Kreiman", "Gabriel", ""]]}]