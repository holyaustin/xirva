[{"id": "1707.00081", "submitter": "Alexander Wong", "authors": "A. H. Karimi, M. J. Shafiee, A. Ghodsi, and A. Wong", "title": "Synthesizing Deep Neural Network Architectures using Biological Synaptic\n  Strength Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we perform an exploratory study on synthesizing deep neural\nnetworks using biological synaptic strength distributions, and the potential\ninfluence of different distributions on modelling performance particularly for\nthe scenario associated with small data sets. Surprisingly, a CNN with\nconvolutional layer synaptic strengths drawn from biologically-inspired\ndistributions such as log-normal or correlated center-surround distributions\nperformed relatively well suggesting a possibility for designing deep neural\nnetwork architectures that do not require many data samples to learn, and can\nsidestep current training procedures while maintaining or boosting modelling\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 01:30:21 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Karimi", "A. H.", ""], ["Shafiee", "M. J.", ""], ["Ghodsi", "A.", ""], ["Wong", "A.", ""]]}, {"id": "1707.00112", "submitter": "Rachit Agarwal", "authors": "Garvita Bajaj, Rachit Agarwal, Pushpendra Singh, Nikolaos Georgantas,\n  Valerie Issarny", "title": "A study of existing Ontologies in the IoT-domain", "comments": "Submitted to Elsevier JWS SI on Web semantics for the Internet/Web of\n  Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several domains have adopted the increasing use of IoT-based devices to\ncollect sensor data for generating abstractions and perceptions of the real\nworld. This sensor data is multi-modal and heterogeneous in nature. This\nheterogeneity induces interoperability issues while developing cross-domain\napplications, thereby restricting the possibility of reusing sensor data to\ndevelop new applications. As a solution to this, semantic approaches have been\nproposed in the literature to tackle problems related to interoperability of\nsensor data. Several ontologies have been proposed to handle different aspects\nof IoT-based sensor data collection, ranging from discovering the IoT sensors\nfor data collection to applying reasoning on the collected sensor data for\ndrawing inferences. In this paper, we survey these existing semantic ontologies\nto provide an overview of the recent developments in this field. We highlight\nthe fundamental ontological concepts (e.g., sensor-capabilities and\ncontext-awareness) required for an IoT-based application, and survey the\nexisting ontologies which include these concepts. Based on our study, we also\nidentify the shortcomings of currently available ontologies, which serves as a\nstepping stone to state the need for a common unified ontology for the IoT\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 08:31:28 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Bajaj", "Garvita", ""], ["Agarwal", "Rachit", ""], ["Singh", "Pushpendra", ""], ["Georgantas", "Nikolaos", ""], ["Issarny", "Valerie", ""]]}, {"id": "1707.00130", "submitter": "Pei-Hao Su", "authors": "Pei-Hao Su, Pawel Budzianowski, Stefan Ultes, Milica Gasic, and Steve\n  Young", "title": "Sample-efficient Actor-Critic Reinforcement Learning with Supervised\n  Data for Dialogue Management", "comments": "Accepted as a long paper in SigDial 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) methods have significant potential for\ndialogue policy optimisation. However, they suffer from a poor performance in\nthe early stages of learning. This is especially problematic for on-line\nlearning with real users. Two approaches are introduced to tackle this problem.\nFirstly, to speed up the learning process, two sample-efficient neural networks\nalgorithms: trust region actor-critic with experience replay (TRACER) and\nepisodic natural actor-critic with experience replay (eNACER) are presented.\nFor TRACER, the trust region helps to control the learning step size and avoid\ncatastrophic model changes. For eNACER, the natural gradient identifies the\nsteepest ascent direction in policy space to speed up the convergence. Both\nmodels employ off-policy learning with experience replay to improve\nsample-efficiency. Secondly, to mitigate the cold start issue, a corpus of\ndemonstration data is utilised to pre-train the models prior to on-line\nreinforcement learning. Combining these two approaches, we demonstrate a\npractical approach to learn deep RL-based dialogue policies and demonstrate\ntheir effectiveness in a task-oriented information seeking domain.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 09:56:31 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 08:55:16 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Su", "Pei-Hao", ""], ["Budzianowski", "Pawel", ""], ["Ultes", "Stefan", ""], ["Gasic", "Milica", ""], ["Young", "Steve", ""]]}, {"id": "1707.00183", "submitter": "Tambet Matiisen", "authors": "Tambet Matiisen, Avital Oliver, Taco Cohen, John Schulman", "title": "Teacher-Student Curriculum Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Teacher-Student Curriculum Learning (TSCL), a framework for\nautomatic curriculum learning, where the Student tries to learn a complex task\nand the Teacher automatically chooses subtasks from a given set for the Student\nto train on. We describe a family of Teacher algorithms that rely on the\nintuition that the Student should practice more those tasks on which it makes\nthe fastest progress, i.e. where the slope of the learning curve is highest. In\naddition, the Teacher algorithms address the problem of forgetting by also\nchoosing tasks where the Student's performance is getting worse. We demonstrate\nthat TSCL matches or surpasses the results of carefully hand-crafted curricula\nin two tasks: addition of decimal numbers with LSTM and navigation in\nMinecraft. Using our automatically generated curriculum enabled to solve a\nMinecraft maze that could not be solved at all when training directly on\nsolving the maze, and the learning was an order of magnitude faster than\nuniform sampling of subtasks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 18:13:17 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 20:57:09 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Matiisen", "Tambet", ""], ["Oliver", "Avital", ""], ["Cohen", "Taco", ""], ["Schulman", "John", ""]]}, {"id": "1707.00228", "submitter": "Pavel Surynek", "authors": "Pavel Surynek, Ariel Felner, Roni Stern, Eli Boyarski", "title": "Modifying Optimal SAT-based Approach to Multi-agent Path-finding Problem\n  to Suboptimal Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent path finding (MAPF) the task is to find non-conflicting paths\nfor multiple agents. In this paper we focus on finding suboptimal solutions for\nMAPF for the sum-of-costs variant. Recently, a SAT-based approached was\ndeveloped to solve this problem and proved beneficial in many cases when\ncompared to other search-based solvers. In this paper, we present SAT-based\nunbounded- and bounded-suboptimal algorithms and compare them to relevant\nalgorithms. Experimental results show that in many case the SAT-based solver\nsignificantly outperforms the search-based solvers.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 03:08:26 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Surynek", "Pavel", ""], ["Felner", "Ariel", ""], ["Stern", "Roni", ""], ["Boyarski", "Eli", ""]]}, {"id": "1707.00355", "submitter": "Carleton Coffrin", "authors": "Carleton Coffrin and Harsha Nagarajan and Russell Bent", "title": "Evaluating Ising Processing Units with Integer Programming", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19212-9_11", "report-no": "LA-UR-19-22000", "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of novel computational devices, such as adiabatic\nquantum computers, CMOS annealers, and optical parametric oscillators, present\nnew opportunities for hybrid-optimization algorithms that are hardware\naccelerated by these devices. In this work, we propose the idea of an Ising\nprocessing unit as a computational abstraction for reasoning about these\nemerging devices. The challenges involved in using and benchmarking these\ndevices are presented and commercial mixed integer programming solvers are\nproposed as a valuable tool for the validation of these disparate hardware\nplatforms. The proposed validation methodology is demonstrated on a D-Wave 2X\nadiabatic quantum computer, one example of an Ising processing unit. The\ncomputational results demonstrate that the D-Wave hardware consistently\nproduces high-quality solutions and suggests that as IPU technology matures it\ncould become a valuable co-processor in hybrid-optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 21:07:45 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 00:37:37 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Coffrin", "Carleton", ""], ["Nagarajan", "Harsha", ""], ["Bent", "Russell", ""]]}, {"id": "1707.00524", "submitter": "Hayan Yin", "authors": "Haiyan Yin, Jianda Chen, Sinno Jialin Pan", "title": "Hashing over Predicted Future Frames for Informed Exploration of Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep reinforcement learning (RL) tasks, an efficient exploration mechanism\nshould be able to encourage an agent to take actions that lead to less frequent\nstates which may yield higher accumulative future return. However, both knowing\nabout the future and evaluating the frequentness of states are non-trivial\ntasks, especially for deep RL domains, where a state is represented by\nhigh-dimensional image frames. In this paper, we propose a novel informed\nexploration framework for deep RL, where we build the capability for an RL\nagent to predict over the future transitions and evaluate the frequentness for\nthe predicted future frames in a meaningful manner. To this end, we train a\ndeep prediction model to predict future frames given a state-action pair, and a\nconvolutional autoencoder model to hash over the seen frames. In addition, to\nutilize the counts derived from the seen frames to evaluate the frequentness\nfor the predicted frames, we tackle the challenge of matching the predicted\nfuture frames and their corresponding seen frames at the latent feature level.\nIn this way, we derive a reliable metric for evaluating the novelty of the\nfuture direction pointed by each action, and hence inform the agent to explore\nthe least frequent one.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 13:07:40 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 12:09:47 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Yin", "Haiyan", ""], ["Chen", "Jianda", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "1707.00561", "submitter": "Varun Ojha", "authors": "Varun Kumar Ojha, Paramartha Dutta, Atal Chaudhuri", "title": "Identifying hazardousness of sewer pipeline gas mixture using\n  classification methods: a comparative study", "comments": null, "journal-ref": "Neural Comput & Applic (2017) 28: 1343", "doi": "10.1007/s00521-016-2443-0", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulated a real-world problem related to sewer pipeline\ngas detection using the classification-based approaches. The primary goal of\nthis work was to identify the hazardousness of sewer pipeline to offer safe and\nnon-hazardous access to sewer pipeline workers so that the human fatalities,\nwhich occurs due to the toxic exposure of sewer gas components, can be avoided.\nThe dataset acquired through laboratory tests, experiments, and various\nliterature sources was organized to design a predictive model that was able to\nidentify/classify hazardous and non-hazardous situation of sewer pipeline. To\ndesign such prediction model, several classification algorithms were used and\ntheir performances were evaluated and compared, both empirically and\nstatistically, over the collected dataset. In addition, the performances of\nseveral ensemble methods were analyzed to understand the extent of improvement\noffered by these methods. The result of this comprehensive study showed that\nthe instance-based learning algorithm performed better than many other\nalgorithms such as multilayer perceptron, radial basis function network,\nsupport vector machine, reduced pruning tree. Similarly, it was observed that\nmulti-scheme ensemble approach enhanced the performance of base predictors.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:57:46 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Ojha", "Varun Kumar", ""], ["Dutta", "Paramartha", ""], ["Chaudhuri", "Atal", ""]]}, {"id": "1707.00614", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "A Roadmap for the Development of the \"SP Machine\" for Artificial\n  Intelligence", "comments": "Accepted for publication in the journal \"Complexity\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a roadmap for the development of the \"SP Machine\", based\non the \"SP Theory of Intelligence\" and its realisation in the \"SP Computer\nModel\". The SP Machine will be developed initially as a software virtual\nmachine with high levels of parallel processing, hosted on a high-performance\ncomputer. The system should help users visualise knowledge structures and\nprocessing. Research is needed into how the system may discover low-level\nfeatures in speech and in images. Strengths of the SP System in the processing\nof natural language may be augmented, in conjunction with the further\ndevelopment of the SP System's strengths in unsupervised learning. Strengths of\nthe SP System in pattern recognition may be developed for computer vision. Work\nis needed on the representation of numbers and the performance of arithmetic\nprocesses. A computer model is needed of \"SP-Neural\", the version of the SP\nTheory expressed in terms of neurons and their inter-connections. The SP\nMachine has potential in many areas of application, several of which may be\nrealised on short-to-medium timescales.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 11:01:16 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 09:19:39 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 22:25:47 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1707.00617", "submitter": "Arvind Raghunathan", "authors": "Srikumar Ramalingam, Arvind U. Raghunathan, Daniel Nikovski", "title": "Submodular Function Maximization for Group Elevator Scheduling", "comments": "10 pages; 2017 International Conference on Automated Planning and\n  Scheduling (ICAPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for group elevator scheduling by formulating it\nas the maximization of submodular function under a matroid constraint. In\nparticular, we propose to model the total waiting time of passengers using a\nquadratic Boolean function. The unary and pairwise terms in the function denote\nthe waiting time for single and pairwise allocation of passengers to elevators,\nrespectively. We show that this objective function is submodular. The matroid\nconstraints ensure that every passenger is allocated to exactly one elevator.\nWe use a greedy algorithm to maximize the submodular objective function, and\nderive provable guarantees on the optimality of the solution. We tested our\nalgorithm using Elevate 8, a commercial-grade elevator simulator that allows\nsimulation with a wide range of elevator settings. We achieve significant\nimprovement over the existing algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 01:56:25 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Ramalingam", "Srikumar", ""], ["Raghunathan", "Arvind U.", ""], ["Nikovski", "Daniel", ""]]}, {"id": "1707.00627", "submitter": "Kenneth Young", "authors": "Kenny Young and Ryan B. Hayward", "title": "A Reverse Hex Solver", "comments": "Presented at Computers and Games 2016 Leiden, International\n  Conference on Computers and Games. Springer International Publishing, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Solrex,an automated solver for the game of Reverse Hex.Reverse\nHex, also known as Rex, or Misere Hex, is the variant of the game of Hex in\nwhich the player who joins her two sides loses the game. Solrex performs a\nmini-max search of the state space using Scalable Parallel Depth First Proof\nNumber Search, enhanced by the pruning of inferior moves and the early\ndetection of certain winning strategies. Solrex is implemented on the same code\nbase as the Hex program Solver, and can solve arbitrary positions on board\nsizes up to 6x6, with the hardest position taking less than four hours on four\nthreads.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:51:08 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Young", "Kenny", ""], ["Hayward", "Ryan B.", ""]]}, {"id": "1707.00703", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "Automated Problem Identification: Regression vs Classification via\n  Evolutionary Deep Networks", "comments": "9 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regression or classification? This is perhaps the most basic question faced\nwhen tackling a new supervised learning problem. We present an Evolutionary\nDeep Learning (EDL) algorithm that automatically solves this by identifying the\nquestion type with high accuracy, along with a proposed deep architecture.\nTypically, a significant amount of human insight and preparation is required\nprior to executing machine learning algorithms. For example, when creating deep\nneural networks, the number of parameters must be selected in advance and\nfurthermore, a lot of these choices are made based upon pre-existing knowledge\nof the data such as the use of a categorical cross entropy loss function.\nHumans are able to study a dataset and decide whether it represents a\nclassification or a regression problem, and consequently make decisions which\nwill be applied to the execution of the neural network. We propose the\nAutomated Problem Identification (API) algorithm, which uses an evolutionary\nalgorithm interface to TensorFlow to manipulate a deep neural network to decide\nif a dataset represents a classification or a regression problem. We test API\non 16 different classification, regression and sentiment analysis datasets with\nup to 10,000 features and up to 17,000 unique target values. API achieves an\naverage accuracy of $96.3\\%$ in identifying the problem type without hardcoding\nany insights about the general characteristics of regression or classification\nproblems. For example, API successfully identifies classification problems even\nwith 1000 target values. Furthermore, the algorithm recommends which loss\nfunction to use and also recommends a neural network architecture. Our work is\ntherefore a step towards fully automated machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 18:00:08 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1707.00724", "submitter": "Daniel Brown", "authors": "Daniel S. Brown and Scott Niekum", "title": "Efficient Probabilistic Performance Bounds for Inverse Reinforcement\n  Learning", "comments": "In proceedings AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of reinforcement learning there has been recent progress towards\nsafety and high-confidence bounds on policy performance. However, to our\nknowledge, no practical methods exist for determining high-confidence policy\nperformance bounds in the inverse reinforcement learning setting---where the\ntrue reward function is unknown and only samples of expert behavior are given.\nWe propose a sampling method based on Bayesian inverse reinforcement learning\nthat uses demonstrations to determine practical high-confidence upper bounds on\nthe $\\alpha$-worst-case difference in expected return between any evaluation\npolicy and the optimal policy under the expert's unknown reward function. We\nevaluate our proposed bound on both a standard grid navigation task and a\nsimulated driving task and achieve tighter and more accurate bounds than a\nfeature count-based baseline. We also give examples of how our proposed bound\ncan be utilized to perform risk-aware policy selection and risk-aware policy\nimprovement. Because our proposed bound requires several orders of magnitude\nfewer demonstrations than existing high-confidence bounds, it is the first\npractical method that allows agents that learn from demonstration to express\nconfidence in the quality of their learned policy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 18:40:13 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 19:00:28 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 23:28:40 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 21:27:17 GMT"}, {"version": "v5", "created": "Sat, 23 Jun 2018 02:11:52 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Brown", "Daniel S.", ""], ["Niekum", "Scott", ""]]}, {"id": "1707.00790", "submitter": "Hamid Mirzaei Buini", "authors": "Hamid Mirzaei, Mona Fathollahi, Tony Givargis", "title": "OPEB: Open Physical Environment Benchmark for Artificial Intelligence", "comments": "Accepted in 3rd IEEE International Forum on Research and Technologies\n  for Society and Industry 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence methods to solve continuous- control tasks have made\nsignificant progress in recent years. However, these algorithms have important\nlimitations and still need significant improvement to be used in industry and\nreal- world applications. This means that this area is still in an active\nresearch phase. To involve a large number of research groups, standard\nbenchmarks are needed to evaluate and compare proposed algorithms. In this\npaper, we propose a physical environment benchmark framework to facilitate\ncollaborative research in this area by enabling different research groups to\nintegrate their designed benchmarks in a unified cloud-based repository and\nalso share their actual implemented benchmarks via the cloud. We demonstrate\nthe proposed framework using an actual implementation of the classical\nmountain-car example and present the results obtained using a Reinforcement\nLearning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 00:42:57 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Mirzaei", "Hamid", ""], ["Fathollahi", "Mona", ""], ["Givargis", "Tony", ""]]}, {"id": "1707.00791", "submitter": "Clifford Champion", "authors": "Clifford Champion and Charles Elkan", "title": "Visualizing the Consequences of Evidence in Bayesian Networks", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenge of viewing and navigating Bayesian\nnetworks as their structural size and complexity grow. Starting with a review\nof the state of the art of visualizing Bayesian networks, an area which has\nlargely been passed over, we improve upon existing visualizations in three\nways. First, we apply a disciplined approach to the graphic design of the basic\nelements of the Bayesian network. Second, we propose a technique for direct,\nvisual comparison of posterior distributions resulting from alternative\nevidence sets. Third, we leverage a central mathematical tool in information\ntheory, to assist the user in finding variables of interest in the network, and\nto reduce visual complexity where unimportant. We present our methods applied\nto two modestly large Bayesian networks constructed from real-world data sets.\nResults suggest the new techniques can be a useful tool for discovering\ninformation flow phenomena, and also for qualitative comparisons of different\nevidence configurations, especially in large probabilistic networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 00:43:16 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Champion", "Clifford", ""], ["Elkan", "Charles", ""]]}, {"id": "1707.00819", "submitter": "Sebastian Weichwald", "authors": "Paul K. Rubenstein, Sebastian Weichwald, Stephan Bongers, Joris M.\n  Mooij, Dominik Janzing, Moritz Grosse-Wentrup, Bernhard Sch\\\"olkopf", "title": "Causal Consistency of Structural Equation Models", "comments": "equal contribution between Rubenstein and Weichwald; accepted\n  manuscript", "journal-ref": "Proceedings of the Annual Conference on Uncertainty in Artificial\n  Intelligence, UAI 2017 ( http://auai.org/uai2017/proceedings/papers/11.pdf )", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems can be modelled at various levels of detail. Ideally, causal\nmodels of the same system should be consistent with one another in the sense\nthat they agree in their predictions of the effects of interventions. We\nformalise this notion of consistency in the case of Structural Equation Models\n(SEMs) by introducing exact transformations between SEMs. This provides a\ngeneral language to consider, for instance, the different levels of description\nin the following three scenarios: (a) models with large numbers of variables\nversus models in which the `irrelevant' or unobservable variables have been\nmarginalised out; (b) micro-level models versus macro-level models in which the\nmacro-variables are aggregate features of the micro-variables; (c) dynamical\ntime series models versus models of their stationary behaviour. Our analysis\nstresses the importance of well specified interventions in the causal modelling\nprocess and sheds light on the interpretation of cyclic SEMs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 06:05:31 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Rubenstein", "Paul K.", ""], ["Weichwald", "Sebastian", ""], ["Bongers", "Stephan", ""], ["Mooij", "Joris M.", ""], ["Janzing", "Dominik", ""], ["Grosse-Wentrup", "Moritz", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1707.00836", "submitter": "Kyungmin Kim", "authors": "Kyung-Min Kim, Min-Oh Heo, Seong-Ho Choi, and Byoung-Tak Zhang", "title": "DeepStory: Video Story QA by Deep Embedded Memory Networks", "comments": "7 pages, accepted for IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) on video contents is a significant challenge for\nachieving human-level intelligence as it involves both vision and language in\nreal-world settings. Here we demonstrate the possibility of an AI agent\nperforming video story QA by learning from a large amount of cartoon videos. We\ndevelop a video-story learning model, i.e. Deep Embedded Memory Networks\n(DEMN), to reconstruct stories from a joint scene-dialogue video stream using a\nlatent embedding space of observed data. The video stories are stored in a\nlong-term memory component. For a given question, an LSTM-based attention model\nuses the long-term memory to recall the best question-story-answer triplet by\nfocusing on specific words containing key information. We trained the DEMN on a\nnovel QA dataset of children's cartoon video series, Pororo. The dataset\ncontains 16,066 scene-dialogue pairs of 20.5-hour videos, 27,328 fine-grained\nsentences for scene description, and 8,913 story-related QA pairs. Our\nexperimental results show that the DEMN outperforms other QA models. This is\nmainly due to 1) the reconstruction of video stories in a scene-dialogue\ncombined form that utilize the latent embedding and 2) attention. DEMN also\nachieved state-of-the-art results on the MovieQA benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 07:42:05 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Kim", "Kyung-Min", ""], ["Heo", "Min-Oh", ""], ["Choi", "Seong-Ho", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1707.00860", "submitter": "Sakyasingha Dasgupta", "authors": "Subhajit Chaudhury, Sakyasingha Dasgupta, Asim Munawar, Md. A. Salam\n  Khan, Ryuki Tachibana", "title": "Conditional generation of multi-modal data using constrained embedding\n  space mapping", "comments": "7 pages, 4 figures, ICML 2017 Workshop on Implicit Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a conditional generative model that maps low-dimensional\nembeddings of multiple modalities of data to a common latent space hence\nextracting semantic relationships between them. The embedding specific to a\nmodality is first extracted and subsequently a constrained optimization\nprocedure is performed to project the two embedding spaces to a common\nmanifold. The individual embeddings are generated back from this common latent\nspace. However, in order to enable independent conditional inference for\nseparately extracting the corresponding embeddings from the common latent space\nrepresentation, we deploy a proxy variable trick - wherein, the single shared\nlatent space is replaced by the respective separate latent spaces of each\nmodality. We design an objective function, such that, during training we can\nforce these separate spaces to lie close to each other, by minimizing the\ndistance between their probability distribution functions. Experimental results\ndemonstrate that the learned joint model can generalize to learning concepts of\ndouble MNIST digits with additional attributes of colors,from both textual and\nspeech input.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 09:00:38 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 00:51:04 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Dasgupta", "Sakyasingha", ""], ["Munawar", "Asim", ""], ["Khan", "Md. A. Salam", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "1707.00936", "submitter": "Amiram Moshaiov", "authors": "Eliran Farhi and Amiram Moshaiov", "title": "Window-of-interest based Multi-objective Evolutionary Search for\n  Satisficing Concepts", "comments": "To be published in the proceedings of the IEEE SMC 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The set-based concept approach has been suggested as a means to\nsimultaneously explore different design concepts, which are meaningful sub-sets\nof the entire set of solutions. Previous efforts concerning the suggested\napproach focused on either revealing the global front (s-Pareto front), of all\nthe concepts, or on finding the concepts' fronts, within a relaxation zone. In\ncontrast, here the aim is to reveal which of the concepts have at least one\nsolution with a performance vector within a pre-defined window-of-interest\n(WOI). This paper provides the rational for this new concept-based exploration\nproblem, and suggests a WOI-based rather than Pareto-based multi-objective\nevolutionary algorithm. The proposed algorithm, which simultaneously explores\ndifferent concepts, is tested using a recently suggested concept-based\nbenchmarking approach. The numerical study of this paper shows that the\nalgorithm can cope with various numerical difficulties in a simultaneous way,\nwhich outperforms a sequential exploration approach.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 12:14:18 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Farhi", "Eliran", ""], ["Moshaiov", "Amiram", ""]]}, {"id": "1707.01067", "submitter": "Yuandong Tian", "authors": "Yuandong Tian, Qucheng Gong, Wenling Shang, Yuxin Wu and C. Lawrence\n  Zitnick", "title": "ELF: An Extensive, Lightweight and Flexible Research Platform for\n  Real-time Strategy Games", "comments": "NIPS 2017 oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose ELF, an Extensive, Lightweight and Flexible\nplatform for fundamental reinforcement learning research. Using ELF, we\nimplement a highly customizable real-time strategy (RTS) engine with three game\nenvironments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a\nminiature version of StarCraft, captures key game dynamics and runs at 40K\nframe-per-second (FPS) per core on a Macbook Pro notebook. When coupled with\nmodern reinforcement learning methods, the system can train a full-game bot\nagainst built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition,\nour platform is flexible in terms of environment-agent communication\ntopologies, choices of RL methods, changes in game parameters, and can host\nexisting C/C++-based game environments like Arcade Learning Environment. Using\nELF, we thoroughly explore training parameters and show that a network with\nLeaky ReLU and Batch Normalization coupled with long-horizon training and\nprogressive curriculum beats the rule-based built-in AI more than $70\\%$ of the\ntime in the full game of Mini-RTS. Strong performance is also achieved on the\nother two games. In game replays, we show our agents learn interesting\nstrategies. ELF, along with its RL platform, is open-sourced at\nhttps://github.com/facebookresearch/ELF.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 16:48:56 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 06:21:02 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Tian", "Yuandong", ""], ["Gong", "Qucheng", ""], ["Shang", "Wenling", ""], ["Wu", "Yuxin", ""], ["Zitnick", "C. Lawrence", ""]]}, {"id": "1707.01068", "submitter": "Alexander Peysakhovich", "authors": "Adam Lerer and Alexander Peysakhovich", "title": "Maintaining cooperation in complex social dilemmas using deep\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social dilemmas are situations where individuals face a temptation to\nincrease their payoffs at a cost to total welfare. Building artificially\nintelligent agents that achieve good outcomes in these situations is important\nbecause many real world interactions include a tension between selfish\ninterests and the welfare of others. We show how to modify modern reinforcement\nlearning methods to construct agents that act in ways that are simple to\nunderstand, nice (begin by cooperating), provokable (try to avoid being\nexploited), and forgiving (try to return to mutual cooperation). We show both\ntheoretically and experimentally that such agents can maintain cooperation in\nMarkov social dilemmas. Our construction does not require training methods\nbeyond a modification of self-play, thus if an environment is such that good\nstrategies can be constructed in the zero-sum case (eg. Atari) then we can\nconstruct agents that solve social dilemmas in this environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 17:02:05 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 22:40:15 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 15:23:38 GMT"}, {"version": "v4", "created": "Fri, 2 Mar 2018 14:39:55 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lerer", "Adam", ""], ["Peysakhovich", "Alexander", ""]]}, {"id": "1707.01154", "submitter": "Himabindu Lakkaraju", "authors": "Himabindu Lakkaraju, Ece Kamar, Rich Caruana, Jure Leskovec", "title": "Interpretable & Explorable Approximations of Black Box Models", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Black Box Explanations through Transparent Approximations (BETA),\na novel model agnostic framework for explaining the behavior of any black-box\nclassifier by simultaneously optimizing for fidelity to the original model and\ninterpretability of the explanation. To this end, we develop a novel objective\nfunction which allows us to learn (with optimality guarantees), a small number\nof compact decision sets each of which explains the behavior of the black box\nmodel in unambiguous, well-defined regions of feature space. Furthermore, our\nframework also is capable of accepting user input when generating these\napproximations, thus allowing users to interactively explore how the black-box\nmodel behaves in different subspaces that are of interest to the user. To the\nbest of our knowledge, this is the first approach which can produce global\nexplanations of the behavior of any given black box model through joint\noptimization of unambiguity, fidelity, and interpretability, while also\nallowing users to explore model behavior based on their preferences.\nExperimental evaluation with real-world datasets and user studies demonstrates\nthat our approach can generate highly compact, easy-to-understand, yet accurate\napproximations of various kinds of predictive models compared to\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 21:10:40 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Kamar", "Ece", ""], ["Caruana", "Rich", ""], ["Leskovec", "Jure", ""]]}, {"id": "1707.01164", "submitter": "Jianbo Chen", "authors": "Jianbo Chen, Mitchell Stern, Martin J. Wainwright, Michael I. Jordan", "title": "Kernel Feature Selection via Conditional Covariance Minimization", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for feature selection that employs kernel-based measures\nof independence to find a subset of covariates that is maximally predictive of\nthe response. Building on past work in kernel dimension reduction, we show how\nto perform feature selection via a constrained optimization problem involving\nthe trace of the conditional covariance operator. We prove various consistency\nresults for this procedure, and also demonstrate that our method compares\nfavorably with other state-of-the-art algorithms on a variety of synthetic and\nreal data sets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 22:00:58 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 19:34:49 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chen", "Jianbo", ""], ["Stern", "Mitchell", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1707.01166", "submitter": "Jun Qi", "authors": "Jun Qi, Xu Liu, Javier Tejedor and Shunsuke Kamijo", "title": "Unsupervised Submodular Rank Aggregation on Score-based Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised rank aggregation on score-based permutations, which is widely\nused in many applications, has not been deeply explored yet. This work studies\nthe use of submodular optimization for rank aggregation on score-based\npermutations in an unsupervised way. Specifically, we propose an unsupervised\napproach based on the Lovasz Bregman divergence for setting up linear\nstructured convex and nested structured concave objective functions. In\naddition, stochastic optimization methods are applied in the training process\nand efficient algorithms for inference can be guaranteed. The experimental\nresults from Information Retrieval, Combining Distributed Neural Networks,\nInfluencers in Social Networks, and Distributed Automatic Speech Recognition\ntasks demonstrate the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 22:21:38 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 03:49:19 GMT"}, {"version": "v3", "created": "Wed, 6 Sep 2017 20:57:59 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Qi", "Jun", ""], ["Liu", "Xu", ""], ["Tejedor", "Javier", ""], ["Kamijo", "Shunsuke", ""]]}, {"id": "1707.01184", "submitter": "Souvick Ghosh", "authors": "Souvick Ghosh, Satanu Ghosh, and Dipankar Das", "title": "Sentiment Identification in Code-Mixed Social Media Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is the Natural Language Processing (NLP) task dealing with\nthe detection and classification of sentiments in texts. While some tasks deal\nwith identifying the presence of sentiment in the text (Subjectivity analysis),\nother tasks aim at determining the polarity of the text categorizing them as\npositive, negative and neutral. Whenever there is a presence of sentiment in\nthe text, it has a source (people, group of people or any entity) and the\nsentiment is directed towards some entity, object, event or person. Sentiment\nanalysis tasks aim to determine the subject, the target and the polarity or\nvalence of the sentiment. In our work, we try to automatically extract\nsentiment (positive or negative) from Facebook posts using a machine learning\napproach.While some works have been done in code-mixed social media data and in\nsentiment analysis separately, our work is the first attempt (as of now) which\naims at performing sentiment analysis of code-mixed social media text. We have\nused extensive pre-processing to remove noise from raw text. Multilayer\nPerceptron model has been used to determine the polarity of the sentiment. We\nhave also developed the corpus for this task by manually labeling Facebook\nposts with their associated sentiments.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 23:29:44 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Ghosh", "Souvick", ""], ["Ghosh", "Satanu", ""], ["Das", "Dipankar", ""]]}, {"id": "1707.01195", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "The impossibility of \"fairness\": a generalized impossibility result for\n  decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various measures can be used to estimate bias or unfairness in a predictor.\nPrevious work has already established that some of these measures are\nincompatible with each other. Here we show that, when groups differ in\nprevalence of the predicted event, several intuitive, reasonable measures of\nfairness (probability of positive prediction given occurrence or\nnon-occurrence; probability of occurrence given prediction or non-prediction;\nand ratio of predictions over occurrences for each group) are all mutually\nexclusive: if one of them is equal among groups, the other two must differ. The\nonly exceptions are for perfect, or trivial (always-positive or\nalways-negative) predictors. As a consequence, any non-perfect, non-trivial\npredictor must necessarily be \"unfair\" under two out of three reasonable sets\nof criteria. This result readily generalizes to a wide range of well-known\nstatistical quantities (sensitivity, specificity, false positive rate,\nprecision, etc.), all of which can be divided into three mutually exclusive\ngroups. Importantly, The results applies to all predictors, whether algorithmic\nor human. We conclude with possible ways to handle this effect when assessing\nand designing prediction methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 02:02:42 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 16:31:06 GMT"}, {"version": "v3", "created": "Mon, 11 Sep 2017 21:18:54 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Miconi", "Thomas", ""]]}, {"id": "1707.01250", "submitter": "Shlomo Berkovsky", "authors": "Amit Tiroshi, Tsvi Kuflik, Shlomo Berkovsky, Mohamed Ali Kaafar", "title": "Graph Based Recommendations: From Data Representation to Feature\n  Extraction and Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling users for the purpose of identifying their preferences and then\npersonalizing services on the basis of these models is a complex task,\nprimarily due to the need to take into consideration various explicit and\nimplicit signals, missing or uncertain information, contextual aspects, and\nmore. In this study, a novel generic approach for uncovering latent preference\npatterns from user data is proposed and evaluated. The approach relies on\nrepresenting the data using graphs, and then systematically extracting\ngraph-based features and using them to enrich the original user models. The\nextracted features encapsulate complex relationships between users, items, and\nmetadata. The enhanced user models can then serve as an input to any\nrecommendation algorithm. The proposed approach is domain-independent\n(demonstrated on data from movies, music, and business recommender systems),\nand is evaluated using several state-of-the-art machine learning methods, on\ndifferent recommendation tasks, and using different evaluation metrics. The\nresults show a unanimous improvement in the recommendation accuracy across\ntasks and domains. In addition, the evaluation provides a deeper analysis\nregarding the performance of the approach in special scenarios, including high\nsparsity and variability of ratings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 08:08:21 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Tiroshi", "Amit", ""], ["Kuflik", "Tsvi", ""], ["Berkovsky", "Shlomo", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1707.01283", "submitter": "Ruichu Cai", "authors": "Ruichu Cai, Zhenjie Zhang, Zhifeng Hao", "title": "SADA: A General Framework to Support Robust Causation Discovery with\n  Theoretical Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causation discovery without manipulation is considered a crucial problem to a\nvariety of applications. The state-of-the-art solutions are applicable only\nwhen large numbers of samples are available or the problem domain is\nsufficiently small. Motivated by the observations of the local sparsity\nproperties on causal structures, we propose a general Split-and-Merge\nframework, named SADA, to enhance the scalability of a wide class of causation\ndiscovery algorithms. In SADA, the variables are partitioned into subsets, by\nfinding causal cut on the sparse causal structure over the variables. By\nrunning mainstream causation discovery algorithms as basic causal solvers on\nthe subproblems, complete causal structure can be reconstructed by combining\nthe partial results. SADA benefits from the recursive division technique, since\neach small subproblem generates more accurate result under the same number of\nsamples. We theoretically prove that SADA always reduces the scales of problems\nwithout sacrifice on accuracy, under the condition of local causal sparsity and\nreliable conditional independence tests. We also present sufficient condition\nto accuracy enhancement by SADA, even when the conditional independence tests\nare vulnerable. Extensive experiments on both simulated and real-world datasets\nverify the improvements on scalability and accuracy by applying SADA together\nwith existing causation discovery algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 09:37:00 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Cai", "Ruichu", ""], ["Zhang", "Zhenjie", ""], ["Hao", "Zhifeng", ""]]}, {"id": "1707.01310", "submitter": "Haifeng Zhang", "authors": "Haifeng Zhang, Jun Wang, Zhiming Zhou, Weinan Zhang, Ying Wen, Yong\n  Yu, Wenxin Li", "title": "Learning to Design Games: Strategic Environments in Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In typical reinforcement learning (RL), the environment is assumed given and\nthe goal of the learning is to identify an optimal policy for the agent taking\nactions through its interactions with the environment. In this paper, we extend\nthis setting by considering the environment is not given, but controllable and\nlearnable through its interaction with the agent at the same time. This\nextension is motivated by environment design scenarios in the real-world,\nincluding game design, shopping space design and traffic signal design.\nTheoretically, we find a dual Markov decision process (MDP) w.r.t. the\nenvironment to that w.r.t. the agent, and derive a policy gradient solution to\noptimizing the parametrized environment. Furthermore, discontinuous\nenvironments are addressed by a proposed general generative framework. Our\nexperiments on a Maze game design task show the effectiveness of the proposed\nalgorithms in generating diverse and challenging Mazes against various agent\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 10:45:43 GMT"}, {"version": "v2", "created": "Tue, 19 Sep 2017 15:58:40 GMT"}, {"version": "v3", "created": "Thu, 12 Oct 2017 08:41:39 GMT"}, {"version": "v4", "created": "Wed, 23 May 2018 08:56:12 GMT"}, {"version": "v5", "created": "Wed, 23 Oct 2019 18:03:48 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Zhang", "Haifeng", ""], ["Wang", "Jun", ""], ["Zhou", "Zhiming", ""], ["Zhang", "Weinan", ""], ["Wen", "Ying", ""], ["Yu", "Yong", ""], ["Li", "Wenxin", ""]]}, {"id": "1707.01357", "submitter": "Stefan Lattner", "authors": "Stefan Lattner and Maarten Grachten", "title": "Improving Content-Invariance in Gated Autoencoders for 2D and 3D Object\n  Rotation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-invariance in mapping codes learned by GAEs is a useful feature for\nvarious relation learning tasks. In this paper we show that the\ncontent-invariance of mapping codes for images of 2D and 3D rotated objects can\nbe substantially improved by extending the standard GAE loss (symmetric\nreconstruction error) with a regularization term that penalizes the symmetric\ncross-reconstruction error. This error term involves reconstruction of pairs\nwith mapping codes obtained from other pairs exhibiting similar\ntransformations. Although this would principally require knowledge of the\ntransformations exhibited by training pairs, our experiments show that a\nbootstrapping approach can sidestep this issue, and that the regularization\nterm can effectively be used in an unsupervised setting.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 12:28:43 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Lattner", "Stefan", ""], ["Grachten", "Maarten", ""]]}, {"id": "1707.01415", "submitter": "Paul Rozdeba", "authors": "Henry Abarbanel, Paul Rozdeba, Sasha Shirman", "title": "Machine Learning, Deepest Learning: Statistical Data Assimilation\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a strong equivalence between machine learning, artificial\nintelligence methods and the formulation of statistical data assimilation as\nused widely in physical and biological sciences. The correspondence is that\nlayer number in the artificial network setting is the analog of time in the\ndata assimilation setting. Within the discussion of this equivalence we show\nthat adding more layers (making the network deeper) is analogous to adding\ntemporal resolution in a data assimilation framework.\n  How one can find a candidate for the global minimum of the cost functions in\nthe machine learning context using a method from data assimilation is\ndiscussed. Calculations on simple models from each side of the equivalence are\nreported.\n  Also discussed is a framework in which the time or layer label is taken to be\ncontinuous, providing a differential equation, the Euler-Lagrange equation,\nwhich shows that the problem being solved is a two point boundary value problem\nfamiliar in the discussion of variational methods. The use of continuous layers\nis denoted \"deepest learning\". These problems respect a symplectic symmetry in\ncontinuous time/layer phase space. Both Lagrangian versions and Hamiltonian\nversions of these problems are presented. Their well-studied implementation in\na discrete time/layer, while respected the symplectic structure, is addressed.\nThe Hamiltonian version provides a direct rationale for back propagation as a\nsolution method for the canonical momentum.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 14:23:00 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Abarbanel", "Henry", ""], ["Rozdeba", "Paul", ""], ["Shirman", "Sasha", ""]]}, {"id": "1707.01423", "submitter": "Mario Alviano", "authors": "Mario Alviano", "title": "Model enumeration in propositional circumscription via unsatisfiable\n  core analysis", "comments": "15 pages, 2 algorithms, 2 tables, 2 figures, ICLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical problems are characterized by a preference relation over\nadmissible solutions, where preferred solutions are minimal in some sense. For\nexample, a preferred diagnosis usually comprises a minimal set of reasons that\nis sufficient to cause the observed anomaly. Alternatively, a minimal\ncorrection subset comprises a minimal set of reasons whose deletion is\nsufficient to eliminate the observed anomaly. Circumscription formalizes such\npreference relations by associating propositional theories with minimal models.\nThe resulting enumeration problem is addressed here by means of a new algorithm\ntaking advantage of unsatisfiable core analysis. Empirical evidence of the\nefficiency of the algorithm is given by comparing the performance of the\nresulting solver, CIRCUMSCRIPTINO, with HCLASP, CAMUS MCS, LBX and MCSLS on the\nenumeration of minimal models for problems originating from practical\napplications.\n  This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 14:39:00 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Alviano", "Mario", ""]]}, {"id": "1707.01450", "submitter": "Romain Laroche", "authors": "Romain Laroche", "title": "The Complex Negotiation Dialogue Game", "comments": "Position paper for Sigdial/Semdial 2017 special session on\n  negotiation dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This position paper formalises an abstract model for complex negotiation\ndialogue. This model is to be used for the benchmark of optimisation algorithms\nranging from Reinforcement Learning to Stochastic Games, through Transfer\nLearning, One-Shot Learning or others.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 16:11:31 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Laroche", "Romain", ""]]}, {"id": "1707.01489", "submitter": "Filippo Vella", "authors": "Agnese Augello, Emanuele Cipolla, Ignazio Infantino, Adriano Manfre,\n  Giovanni Pilato and Filippo Vella", "title": "Creative Robot Dance with Variational Encoder", "comments": "This paper is an extended version of a paper published on the eighth\n  International Conference on Computational Creativity (ICCC), held in Atlanta,\n  GA, June 20th-June 22nd, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What we appreciate in dance is the ability of people to sponta- neously\nimprovise new movements and choreographies, sur- rendering to the music rhythm,\nbeing inspired by the cur- rent perceptions and sensations and by previous\nexperiences, deeply stored in their memory. Like other human abilities, this,\nof course, is challenging to reproduce in an artificial entity such as a robot.\nRecent generations of anthropomor- phic robots, the so-called humanoids,\nhowever, exhibit more and more sophisticated skills and raised the interest in\nrobotic communities to design and experiment systems devoted to automatic dance\ngeneration. In this work, we highlight the importance to model a computational\ncreativity behavior in dancing robots to avoid a mere execution of\npreprogrammed dances. In particular, we exploit a deep learning approach that\nallows a robot to generate in real time new dancing move- ments according to to\nthe listened music.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:42:42 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Augello", "Agnese", ""], ["Cipolla", "Emanuele", ""], ["Infantino", "Ignazio", ""], ["Manfre", "Adriano", ""], ["Pilato", "Giovanni", ""], ["Vella", "Filippo", ""]]}, {"id": "1707.01495", "submitter": "Marcin Andrychowicz", "authors": "Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel\n  Fong, Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, Wojciech Zaremba", "title": "Hindsight Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with sparse rewards is one of the biggest challenges in Reinforcement\nLearning (RL). We present a novel technique called Hindsight Experience Replay\nwhich allows sample-efficient learning from rewards which are sparse and binary\nand therefore avoid the need for complicated reward engineering. It can be\ncombined with an arbitrary off-policy RL algorithm and may be seen as a form of\nimplicit curriculum.\n  We demonstrate our approach on the task of manipulating objects with a\nrobotic arm. In particular, we run experiments on three different tasks:\npushing, sliding, and pick-and-place, in each case using only binary rewards\nindicating whether or not the task is completed. Our ablation studies show that\nHindsight Experience Replay is a crucial ingredient which makes training\npossible in these challenging environments. We show that our policies trained\non a physics simulation can be deployed on a physical robot and successfully\ncomplete the task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:55:53 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 18:35:33 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 10:04:20 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Andrychowicz", "Marcin", ""], ["Wolski", "Filip", ""], ["Ray", "Alex", ""], ["Schneider", "Jonas", ""], ["Fong", "Rachel", ""], ["Welinder", "Peter", ""], ["McGrew", "Bob", ""], ["Tobin", "Josh", ""], ["Abbeel", "Pieter", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1707.01550", "submitter": "Anthony Di Franco", "authors": "Anthony Di Franco", "title": "Information-gain computation", "comments": "Accepted, PLP 2017 (http://www.stoics.org.uk/plp/plp2017/) Revised\n  version of project for Phys 256B @ Davis\n  (http://csc.ucdavis.edu/~chaos/courses/ncaso/) Reduces to practice ideas\n  previously presented in arXiv:1505.00002 and at\n  https://www.meetup.com/SF-Types-Theorems-and-Programming-Languages/events/232908199/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite large incentives, ecorrectness in software remains an elusive goal.\nDeclarative programming techniques, where algorithms are derived from a\nspecification of the desired behavior, offer hope to address this problem,\nsince there is a combinatorial reduction in complexity in programming in terms\nof specifications instead of algorithms, and arbitrary desired properties can\nbe expressed and enforced in specifications directly. However, limitations on\nperformance have prevented programming with declarative specifications from\nbecoming a mainstream technique for general-purpose programming. To address the\nperformance bottleneck in deriving an algorithm from a specification, I propose\ninformation-gain computation, a framework where an adaptive evaluation strategy\nis used to efficiently perform a search which derives algorithms that provide\ninformation about a query most directly. Within this framework, opportunities\nto compress the search space present themselves, which suggest that\ninformation-theoretic bounds on the performance of such a system might be\narticulated and a system designed to achieve them. In a preliminary empirical\nstudy of adaptive evaluation for a simple test program, the evaluation strategy\nadapts successfully to evaluate a query efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 19:26:14 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 00:52:56 GMT"}, {"version": "v3", "created": "Mon, 14 Aug 2017 01:16:23 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Di Franco", "Anthony", ""]]}, {"id": "1707.01555", "submitter": "Hongyu Guo", "authors": "Hongyu Guo", "title": "A Deep Network with Visual Text Composition Behavior", "comments": "accepted to ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While natural languages are compositional, how state-of-the-art neural models\nachieve compositionality is still unclear. We propose a deep network, which not\nonly achieves competitive accuracy for text classification, but also exhibits\ncompositional behavior. That is, while creating hierarchical representations of\na piece of text, such as a sentence, the lower layers of the network distribute\ntheir layer-specific attention weights to individual words. In contrast, the\nhigher layers compose meaningful phrases and clauses, whose lengths increase as\nthe networks get deeper until fully composing the sentence.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 19:37:23 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Guo", "Hongyu", ""]]}, {"id": "1707.01606", "submitter": "Ekraam Sabir", "authors": "Ayush Jaiswal, Ekraam Sabir, Wael AbdAlmageed, Premkumar Natarajan", "title": "Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images\n  And Text", "comments": "*Ayush Jaiswal and Ekraam Sabir contributed equally to the work in\n  this paper", "journal-ref": "In Proceedings of the 2017 ACM on Multimedia Conference, pp.\n  1465-1471. ACM, 2017", "doi": "10.1145/3123266.3123385", "report-no": null, "categories": "cs.MM cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world multimedia data is often composed of multiple modalities such as\nan image or a video with associated text (e.g. captions, user comments, etc.)\nand metadata. Such multimodal data packages are prone to manipulations, where a\nsubset of these modalities can be altered to misrepresent or repurpose data\npackages, with possible malicious intent. It is, therefore, important to\ndevelop methods to assess or verify the integrity of these multimedia packages.\nUsing computer vision and natural language processing methods to directly\ncompare the image (or video) and the associated caption to verify the integrity\nof a media package is only possible for a limited set of objects and scenes. In\nthis paper, we present a novel deep learning-based approach for assessing the\nsemantic integrity of multimedia packages containing images and captions, using\na reference set of multimedia packages. We construct a joint embedding of\nimages and captions with deep multimodal representation learning on the\nreference dataset in a framework that also provides image-caption consistency\nscores (ICCSs). The integrity of query media packages is assessed as the\ninlierness of the query ICCSs with respect to the reference dataset. We present\nthe MultimodAl Information Manipulation dataset (MAIM), a new dataset of media\npackages from Flickr, which we make available to the research community. We use\nboth the newly created dataset as well as Flickr30K and MS COCO datasets to\nquantitatively evaluate our proposed approach. The reference dataset does not\ncontain unmanipulated versions of tampered query packages. Our method is able\nto achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO,\nrespectively, for detecting semantically incoherent media packages.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 01:25:17 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 00:47:21 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 18:02:08 GMT"}, {"version": "v4", "created": "Fri, 29 Jun 2018 00:34:27 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Sabir", "Ekraam", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1707.01625", "submitter": "Weiran Shen", "authors": "Mengjing Chen, Weiran Shen, Pingzhong Tang, Song Zuo", "title": "Optimal Vehicle Dispatching Schemes via Dynamic Pricing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, ride-sharing has emerged as an effective way to\nrelieve traffic congestion. A key problem for these platforms is to come up\nwith a revenue-optimal (or GMV-optimal) pricing scheme and an induced vehicle\ndispatching policy that incorporate geographic and temporal information. In\nthis paper, we aim to tackle this problem via an economic approach.\n  Modeled naively, the underlying optimization problem may be non-convex and\nthus hard to compute. To this end, we use a so-called \"ironing\" technique to\nconvert the problem into an equivalent convex optimization one via a clean\nMarkov decision process (MDP) formulation, where the states are the driver\ndistributions and the decision variables are the prices for each pair of\nlocations. Our main finding is an efficient algorithm that computes the exact\nrevenue-optimal (or GMV-optimal) randomized pricing schemes. We characterize\nthe optimal solution of the MDP by a primal-dual analysis of a corresponding\nconvex program. We also conduct empirical evaluations of our solution through\nreal data of a major ride-sharing platform and show its advantages over fixed\npricing schemes as well as several prevalent surge-based pricing schemes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 03:46:09 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 05:33:08 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chen", "Mengjing", ""], ["Shen", "Weiran", ""], ["Tang", "Pingzhong", ""], ["Zuo", "Song", ""]]}, {"id": "1707.01647", "submitter": "Alex Kim", "authors": "HyoungSeok Kim, JiHoon Kang, WooMyoung Park, SukHyun Ko, YoonHo Cho,\n  DaeSung Yu, YoungSook Song, JungWon Choi", "title": "Convergence Analysis of Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The regret bound of an optimization algorithms is one of the basic criteria\nfor evaluating the performance of the given algorithm. By inspecting the\ndifferences between the regret bounds of traditional algorithms and adaptive\none, we provide a guide for choosing an optimizer with respect to the given\ndata set and the loss function. For analysis, we assume that the loss function\nis convex and its gradient is Lipschitz continuous.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 06:10:53 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Kim", "HyoungSeok", ""], ["Kang", "JiHoon", ""], ["Park", "WooMyoung", ""], ["Ko", "SukHyun", ""], ["Cho", "YoonHo", ""], ["Yu", "DaeSung", ""], ["Song", "YoungSook", ""], ["Choi", "JungWon", ""]]}, {"id": "1707.01700", "submitter": "Joris Gu\\'erin", "authors": "Joris Gu\\'erin, Olivier Gibaru, St\\'ephane Thiery and Eric Nyiri", "title": "CNN features are also great at unsupervised classification", "comments": "10 pages, 2 figures, 4 tables. Proceedings of AIFU 2018, Melbourne,\n  Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at providing insight on the transferability of deep CNN\nfeatures to unsupervised problems. We study the impact of different pretrained\nCNN feature extractors on the problem of image set clustering for object\nclassification as well as fine-grained classification. We propose a rather\nstraightforward pipeline combining deep-feature extraction using a CNN\npretrained on ImageNet and a classic clustering algorithm to classify sets of\nimages. This approach is compared to state-of-the-art algorithms in\nimage-clustering and provides better results. These results strengthen the\nbelief that supervised training of deep CNN on large datasets, with a large\nvariability of classes, extracts better features than most carefully designed\nengineering approaches, even for unsupervised tasks. We also validate our\napproach on a robotic application, consisting in sorting and storing objects\nsmartly based on clustering.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 09:24:35 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 11:11:15 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Gu\u00e9rin", "Joris", ""], ["Gibaru", "Olivier", ""], ["Thiery", "St\u00e9phane", ""], ["Nyiri", "Eric", ""]]}, {"id": "1707.01727", "submitter": "Mehrdad J. Bani", "authors": "Shoele Jamali and Mehrdad J. Bani", "title": "Application of Fuzzy Assessing for Reliability Decision Making", "comments": "Submitted to Proceedings of the World Congress on Engineering and\n  Computer Science 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new fuzzy assessing procedure with application in\nmanagement decision making. The proposed fuzzy approach build the membership\nfunctions for system characteristics of a standby repairable system. This\nmethod is used to extract a family of conventional crisp intervals from the\nfuzzy repairable system for the desired system characteristics. This can be\ndetermined with a set of nonlinear parametric programing using the membership\nfunctions. When system characteristics are governed by the membership\nfunctions, more information is provided for use by management, and because the\nredundant system is extended to the fuzzy environment, general repairable\nsystems are represented more accurately and the analytic results are more\nuseful for designers and practitioners. Also beside standby, active redundancy\nsystems are used in many cases so this article has many practical instances.\nDifferent from other studies, our model provides, a good estimated value based\non uncertain environments, a comparison discussion of using fuzzy theory and\nconventional method and also a comparison between parallel (active redundancy)\nand series system in fuzzy world when we have standby redundancy. When the\nmembership function intervals cannot be inverted explicitly, system management\nor designers can specify the system characteristics of interest, perform\nnumerical calculations, examine the corresponding {\\alpha}-cuts, and use this\ninformation to develop or improve system processes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 10:47:08 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Jamali", "Shoele", ""], ["Bani", "Mehrdad J.", ""]]}, {"id": "1707.01736", "submitter": "Emiel van Miltenburg", "authors": "Emiel van Miltenburg, Desmond Elliott, Piek Vossen", "title": "Cross-linguistic differences and similarities in image descriptions", "comments": "Accepted for INLG 2017, Santiago de Compostela, Spain, 4-7 September,\n  2017. Camera-ready version. See the ACL anthology for full bibliographic\n  information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic image description systems are commonly trained and evaluated on\nlarge image description datasets. Recently, researchers have started to collect\nsuch datasets for languages other than English. An unexplored question is how\ndifferent these datasets are from English and, if there are any differences,\nwhat causes them to differ. This paper provides a cross-linguistic comparison\nof Dutch, English, and German image descriptions. We find that these\ndescriptions are similar in many respects, but the familiarity of crowd workers\nwith the subjects of the images has a noticeable influence on description\nspecificity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 11:53:41 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 10:18:44 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["van Miltenburg", "Emiel", ""], ["Elliott", "Desmond", ""], ["Vossen", "Piek", ""]]}, {"id": "1707.01865", "submitter": "Claudia Schulz", "authors": "Elias Marcopoulos, Christian Reotutar and Yuanlin Zhang", "title": "An Online Development Environment for Answer Set Programming", "comments": "Proceedings of the 2nd International Workshop on User-Oriented Logic\n  Paradigms(IULP 2017), Editors: Claudia Schulz and Stefan Ellmauthaler", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in logic programming (e.g., the development of the Answer Set\nProgramming paradigm) has made it possible to teach it to general undergraduate\nand even high school students. Given the limited exposure of these students to\ncomputer science, the complexity of downloading, installing and using tools for\nwriting logic programs could be a major barrier for logic programming to reach\na much wider audience. We developed an online answer set programming\nenvironment with a self contained file system and a simple interface, allowing\nusers to write logic programs and perform several tasks over the programs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 10:01:24 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Marcopoulos", "Elias", ""], ["Reotutar", "Christian", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "1707.01891", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mohammad Norouzi, Kelvin Xu, Dale Schuurmans", "title": "Trust-PCL: An Off-Policy Trust Region Method for Continuous Control", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust region methods, such as TRPO, are often used to stabilize policy\noptimization algorithms in reinforcement learning (RL). While current trust\nregion strategies are effective for continuous control, they typically require\na prohibitively large amount of on-policy interaction with the environment. To\naddress this problem, we propose an off-policy trust region method, Trust-PCL.\nThe algorithm is the result of observing that the optimal policy and state\nvalues of a maximum reward objective with a relative-entropy regularizer\nsatisfy a set of multi-step pathwise consistencies along any path. Thus,\nTrust-PCL is able to maintain optimization stability while exploiting\noff-policy data to improve sample efficiency. When evaluated on a number of\ncontinuous control tasks, Trust-PCL improves the solution quality and sample\nefficiency of TRPO.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 17:50:19 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 16:16:27 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 21:28:57 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Nachum", "Ofir", ""], ["Norouzi", "Mohammad", ""], ["Xu", "Kelvin", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1707.01959", "submitter": "Jianmin Ji", "authors": "Jianmin Ji, Fangfang Liu, Jia-Huai You", "title": "Well-Founded Operators for Normal Hybrid MKNF Knowledge Bases", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1,\n  2017. Total 20 pages, Main part 16 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid MKNF knowledge bases have been considered one of the dominant\napproaches to combining open world ontology languages with closed world\nrule-based languages. Currently, the only known inference methods are based on\nthe approach of guess-and-verify, while most modern SAT/ASP solvers are built\nunder the DPLL architecture. The central impediment here is that it is not\nclear what constitutes a constraint propagator, a key component employed in any\nDPLL-based solver. In this paper, we address this problem by formulating the\nnotion of unfounded sets for nondisjunctive hybrid MKNF knowledge bases, based\non which we propose and study two new well-founded operators. We show that by\nemploying a well-founded operator as a constraint propagator, a sound and\ncomplete DPLL search engine can be readily defined. We compare our approach\nwith the operator based on the alternating fixpoint construction by Knorr et al\n[2011] and show that, when applied to arbitrary partial partitions, the new\nwell-founded operators not only propagate more truth values but also circumvent\nthe non-converging behavior of the latter. In addition, we study the\npossibility of simplifying a given hybrid MKNF knowledge base by employing a\nwell-founded operator, and show that, out of the two operators proposed in this\npaper, the weaker one can be applied for this purpose and the stronger one\ncannot. These observations are useful in implementing a grounder for hybrid\nMKNF knowledge bases, which can be applied before the computation of MKNF\nmodels.\n  The paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 20:38:35 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 22:50:14 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Ji", "Jianmin", ""], ["Liu", "Fangfang", ""], ["You", "Jia-Huai", ""]]}, {"id": "1707.01961", "submitter": "Fenglong Ma", "authors": "Fenglong Ma, Radha Chitta, Saurabh Kataria, Jing Zhou, Palghat Ramesh,\n  Tong Sun, Jing Gao", "title": "Long-Term Memory Networks for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering is an important and difficult task in the natural language\nprocessing domain, because many basic natural language processing tasks can be\ncast into a question answering task. Several deep neural network architectures\nhave been developed recently, which employ memory and inference components to\nmemorize and reason over text information, and generate answers to questions.\nHowever, a major drawback of many such models is that they are capable of only\ngenerating single-word answers. In addition, they require large amount of\ntraining data to generate accurate answers. In this paper, we introduce the\nLong-Term Memory Network (LTMN), which incorporates both an external memory\nmodule and a Long Short-Term Memory (LSTM) module to comprehend the input data\nand generate multi-word answers. The LTMN model can be trained end-to-end using\nback-propagation and requires minimal supervision. We test our model on two\nsynthetic data sets (based on Facebook's bAbI data set) and the real-world\nStanford question answering data set, and show that it can achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 20:48:42 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Ma", "Fenglong", ""], ["Chitta", "Radha", ""], ["Kataria", "Saurabh", ""], ["Zhou", "Jing", ""], ["Ramesh", "Palghat", ""], ["Sun", "Tong", ""], ["Gao", "Jing", ""]]}, {"id": "1707.02033", "submitter": "Xiaohui Bei", "authors": "Xiaohui Bei, Youming Qiao, Shengyu Zhang", "title": "Networked Fairness in Cake Cutting", "comments": "A preliminary version of this paper appears at IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graphical framework for fair division in cake cutting, where\ncomparisons between agents are limited by an underlying network structure. We\ngeneralize the classical fairness notions of envy-freeness and proportionality\nto this graphical setting. Given a simple undirected graph G, an allocation is\nenvy-free on G if no agent envies any of her neighbor's share, and is\nproportional on G if every agent values her own share no less than the average\namong her neighbors, with respect to her own measure. These generalizations\nopen new research directions in developing simple and efficient algorithms that\ncan produce fair allocations under specific graph structures.\n  On the algorithmic frontier, we first propose a moving-knife algorithm that\noutputs an envy-free allocation on trees. The algorithm is significantly\nsimpler than the discrete and bounded envy-free algorithm recently designed by\nAziz and Mackenzie for complete graphs. Next, we give a discrete and bounded\nalgorithm for computing a proportional allocation on descendant graphs, a class\nof graphs by taking a rooted tree and connecting all its ancestor-descendant\npairs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 04:31:33 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Bei", "Xiaohui", ""], ["Qiao", "Youming", ""], ["Zhang", "Shengyu", ""]]}, {"id": "1707.02174", "submitter": "Nicola Gatti", "authors": "Nicola Basilico, Stefano Coniglio, Nicola Gatti", "title": "Methods for finding leader--follower equilibria with multiple followers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of leader--follower (or Stackelberg) equilibrium plays a central\nrole in a number of real--world applications of game theory. While the case\nwith a single follower has been thoroughly investigated, results with multiple\nfollowers are only sporadic and the problem of designing and evaluating\ncomputationally tractable equilibrium-finding algorithms is still largely open.\nIn this work, we focus on the fundamental case where multiple followers play a\nNash equilibrium once the leader has committed to a strategy---as we\nillustrate, the corresponding equilibrium finding problem can be easily shown\nto be $\\mathcal{FNP}$--hard and not in Poly--$\\mathcal{APX}$ unless\n$\\mathcal{P} = \\mathcal{NP}$ and therefore it is one among the hardest problems\nto solve and approximate. We propose nonconvex mathematical programming\nformulations and global optimization methods to find both exact and approximate\nequilibria, as well as a heuristic black box algorithm. All the methods and\nformulations that we introduce are thoroughly evaluated computationally.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 13:50:06 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Basilico", "Nicola", ""], ["Coniglio", "Stefano", ""], ["Gatti", "Nicola", ""]]}, {"id": "1707.02275", "submitter": "Antonio Valerio Miceli Barone", "authors": "Antonio Valerio Miceli Barone and Rico Sennrich", "title": "A parallel corpus of Python functions and documentation strings for\n  automated code documentation and code generation", "comments": "5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated documentation of programming source code and automated code\ngeneration from natural language are challenging tasks of both practical and\nscientific interest. Progress in these areas has been limited by the low\navailability of parallel corpora of code and natural language descriptions,\nwhich tend to be small and constrained to specific domains.\n  In this work we introduce a large and diverse parallel corpus of a hundred\nthousands Python functions with their documentation strings (\"docstrings\")\ngenerated by scraping open source repositories on GitHub. We describe baseline\nresults for the code documentation and code generation tasks obtained by neural\nmachine translation. We also experiment with data augmentation techniques to\nfurther increase the amount of training data.\n  We release our datasets and processing scripts in order to stimulate research\nin these areas.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 17:15:27 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Barone", "Antonio Valerio Miceli", ""], ["Sennrich", "Rico", ""]]}, {"id": "1707.02286", "submitter": "Nicolas Heess", "authors": "Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel,\n  Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang, S. M. Ali Eslami, Martin\n  Riedmiller, David Silver", "title": "Emergence of Locomotion Behaviours in Rich Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reinforcement learning paradigm allows, in principle, for complex\nbehaviours to be learned directly from simple reward signals. In practice,\nhowever, it is common to carefully hand-design the reward function to encourage\na particular solution, or to derive it from demonstration data. In this paper\nexplore how a rich environment can help to promote the learning of complex\nbehavior. Specifically, we train agents in diverse environmental contexts, and\nfind that this encourages the emergence of robust behaviours that perform well\nacross a suite of tasks. We demonstrate this principle for locomotion --\nbehaviours that are known for their sensitivity to the choice of reward. We\ntrain several simulated bodies on a diverse set of challenging terrains and\nobstacles, using a simple reward function based on forward progress. Using a\nnovel scalable variant of policy gradient reinforcement learning, our agents\nlearn to run, jump, crouch and turn as required by the environment without\nexplicit reward-based guidance. A visual depiction of highlights of the learned\nbehavior can be viewed following https://youtu.be/hx_bgoTF7bs .\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 17:56:57 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 18:52:12 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Heess", "Nicolas", ""], ["TB", "Dhruva", ""], ["Sriram", "Srinivasan", ""], ["Lemmon", "Jay", ""], ["Merel", "Josh", ""], ["Wayne", "Greg", ""], ["Tassa", "Yuval", ""], ["Erez", "Tom", ""], ["Wang", "Ziyu", ""], ["Eslami", "S. M. Ali", ""], ["Riedmiller", "Martin", ""], ["Silver", "David", ""]]}, {"id": "1707.02292", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Kai-Uwe K\\\"uhnberger", "title": "Measuring Relations Between Concepts In Conceptual Spaces", "comments": "Accepted at SGAI 2017 (http://www.bcs-sgai.org/ai2017/). The final\n  publication is available at Springer via\n  https://doi.org/10.1007/978-3-319-71078-5_7. arXiv admin note: substantial\n  text overlap with arXiv:1707.05165, arXiv:1706.06366", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The highly influential framework of conceptual spaces provides a geometric\nway of representing knowledge. Instances are represented by points in a\nhigh-dimensional space and concepts are represented by regions in this space.\nOur recent mathematical formalization of this framework is capable of\nrepresenting correlations between different domains in a geometric way. In this\npaper, we extend our formalization by providing quantitative mathematical\ndefinitions for the notions of concept size, subsethood, implication,\nsimilarity, and betweenness. This considerably increases the representational\npower of our formalization by introducing measurable ways of describing\nrelations between concepts.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 09:01:00 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 13:57:33 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["K\u00fchnberger", "Kai-Uwe", ""]]}, {"id": "1707.02353", "submitter": "Alex Zhavoronkov", "authors": "Konstantin Chekanov, Polina Mamoshina, Roman V. Yampolskiy, Radu\n  Timofte, Morten Scheibye-Knudsen, Alex Zhavoronkov", "title": "Evaluating race and sex diversity in the world's largest companies using\n  deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity is one of the fundamental properties for the survival of species,\npopulations, and organizations. Recent advances in deep learning allow for the\nrapid and automatic assessment of organizational diversity and possible\ndiscrimination by race, sex, age and other parameters. Automating the process\nof assessing the organizational diversity using the deep neural networks and\neliminating the human factor may provide a set of real-time unbiased reports to\nall stakeholders. In this pilot study we applied the deep-learned predictors of\nrace and sex to the executive management and board member profiles of the 500\nlargest companies from the 2016 Forbes Global 2000 list and compared the\npredicted ratios to the ratios within each company's country of origin and\nranked them by the sex-, age- and race- diversity index (DI). While the study\nhas many limitations and no claims are being made concerning the individual\ncompanies, it demonstrates a method for the rapid and impartial assessment of\norganizational diversity using deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 12:32:19 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Chekanov", "Konstantin", ""], ["Mamoshina", "Polina", ""], ["Yampolskiy", "Roman V.", ""], ["Timofte", "Radu", ""], ["Scheibye-Knudsen", "Morten", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "1707.02363", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Gokhan Tur, Dilek Hakkani-Tur, Larry Heck", "title": "Towards Zero-Shot Frame Semantic Parsing for Domain Scaling", "comments": "4 pages + 1 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art slot filling models for goal-oriented human/machine\nconversational language understanding systems rely on deep learning methods.\nWhile multi-task training of such models alleviates the need for large\nin-domain annotated datasets, bootstrapping a semantic parsing model for a new\ndomain using only the semantic frame, such as the back-end API or knowledge\ngraph schema, is still one of the holy grail tasks of language understanding\nfor dialogue systems. This paper proposes a deep learning based approach that\ncan utilize only the slot description in context without the need for any\nlabeled or unlabeled in-domain examples, to quickly bootstrap a new domain. The\nmain idea of this paper is to leverage the encoding of the slot names and\ndescriptions within a multi-task deep learned slot filling model, to implicitly\nalign slots across domains. The proposed approach is promising for solving the\ndomain scaling problem and eliminating the need for any manually annotated data\nor explicit schema alignment. Furthermore, our experiments on multiple domains\nshow that this approach results in significantly better slot-filling\nperformance when compared to using only in-domain data, especially in the low\ndata regime.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 21:21:33 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Bapna", "Ankur", ""], ["Tur", "Gokhan", ""], ["Hakkani-Tur", "Dilek", ""], ["Heck", "Larry", ""]]}, {"id": "1707.02385", "submitter": "Ivan Brugere", "authors": "Ivan Brugere, Chris Kanich, Tanya Y. Berger-Wolf", "title": "Evaluating Social Networks Using Task-Focused Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are representations of complex underlying social processes. However,\nthe same given network may be more suitable to model one behavior of\nindividuals than another. In many cases, aggregate population models may be\nmore effective than modeling on the network. We present a general framework for\nevaluating the suitability of given networks for a set of predictive tasks of\ninterest, compared against alternative, networks inferred from data. We present\nseveral interpretable network models and measures for our comparison. We apply\nthis general framework to the case study on collective classification of music\npreferences in a newly available dataset of the Last.fm social network.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 03:09:46 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Brugere", "Ivan", ""], ["Kanich", "Chris", ""], ["Berger-Wolf", "Tanya Y.", ""]]}, {"id": "1707.02459", "submitter": "Jian Ni", "authors": "Jian Ni and Radu Florian", "title": "Improving Multilingual Named Entity Recognition with Wikipedia Entity\n  Type Mapping", "comments": "11 pages, Conference on Empirical Methods in Natural Language\n  Processing (EMNLP), 2016", "journal-ref": null, "doi": "10.18653/v1/D16-1135", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art named entity recognition (NER) systems are statistical\nmachine learning models that have strong generalization capability (i.e., can\nrecognize unseen entities that do not appear in training data) based on lexical\nand contextual information. However, such a model could still make mistakes if\nits features favor a wrong entity type. In this paper, we utilize Wikipedia as\nan open knowledge base to improve multilingual NER systems. Central to our\napproach is the construction of high-accuracy, high-coverage multilingual\nWikipedia entity type mappings. These mappings are built from weakly annotated\ndata and can be extended to new languages with no human annotation or\nlanguage-dependent knowledge involved. Based on these mappings, we develop\nseveral approaches to improve an NER system. We evaluate the performance of the\napproaches via experiments on NER systems trained for 6 languages. Experimental\nresults show that the proposed approaches are effective in improving the\naccuracy of such systems on unseen entities, especially when a system is\napplied to a new domain or it is trained with little training data (up to 18.3\nF1 score improvement).\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 16:17:04 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "1707.02515", "submitter": "Liting Sun", "authors": "Liting Sun, Cheng Peng, Wei Zhan, Masayoshi Tomizuka", "title": "A Fast Integrated Planning and Control Framework for Autonomous Driving\n  via Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For safe and efficient planning and control in autonomous driving, we need a\ndriving policy which can achieve desirable driving quality in long-term horizon\nwith guaranteed safety and feasibility. Optimization-based approaches, such as\nModel Predictive Control (MPC), can provide such optimal policies, but their\ncomputational complexity is generally unacceptable for real-time\nimplementation. To address this problem, we propose a fast integrated planning\nand control framework that combines learning- and optimization-based approaches\nin a two-layer hierarchical structure. The first layer, defined as the \"policy\nlayer\", is established by a neural network which learns the long-term optimal\ndriving policy generated by MPC. The second layer, called the \"execution\nlayer\", is a short-term optimization-based controller that tracks the reference\ntrajecotries given by the \"policy layer\" with guaranteed short-term safety and\nfeasibility. Moreover, with efficient and highly-representative features, a\nsmall-size neural network is sufficient in the \"policy layer\" to handle many\ncomplicated driving scenarios. This renders online imitation learning with\nDataset Aggregation (DAgger) so that the performance of the \"policy layer\" can\nbe improved rapidly and continuously online. Several exampled driving scenarios\nare demonstrated to verify the effectiveness and efficiency of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 02:00:21 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Sun", "Liting", ""], ["Peng", "Cheng", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1707.02657", "submitter": "Edilson Anselmo Corr\\^ea J\\'unior", "authors": "Edilson A. Corr\\^ea Jr, Vanessa Q. Marinho, Leandro B. dos Santos,\n  Thales F. C. Bertaglia, Marcos V. Treviso, Henrico B. Brum", "title": "PELESent: Cross-domain polarity classification using distant supervision", "comments": "Accepted for publication in BRACIS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous amount of texts published daily by Internet users has fostered\nthe development of methods to analyze this content in several natural language\nprocessing areas, such as sentiment analysis. The main goal of this task is to\nclassify the polarity of a message. Even though many approaches have been\nproposed for sentiment analysis, some of the most successful ones rely on the\navailability of large annotated corpus, which is an expensive and\ntime-consuming process. In recent years, distant supervision has been used to\nobtain larger datasets. So, inspired by these techniques, in this paper we\nextend such approaches to incorporate popular graphic symbols used in\nelectronic messages, the emojis, in order to create a large sentiment corpus\nfor Portuguese. Trained on almost one million tweets, several models were\ntested in both same domain and cross-domain corpora. Our methods obtained very\ncompetitive results in five annotated corpora from mixed domains (Twitter and\nproduct reviews), which proves the domain-independent property of such\napproach. In addition, our results suggest that the combination of emoticons\nand emojis is able to properly capture the sentiment of a message.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 23:13:58 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Corr\u00eaa", "Edilson A.", "Jr"], ["Marinho", "Vanessa Q.", ""], ["Santos", "Leandro B. dos", ""], ["Bertaglia", "Thales F. C.", ""], ["Treviso", "Marcos V.", ""], ["Brum", "Henrico B.", ""]]}, {"id": "1707.02729", "submitter": "Peter Sch\\\"uller", "authors": "Peter Sch\\\"uller and Mishal Benz", "title": "Best-Effort Inductive Logic Programming via Fine-grained Cost-based\n  Hypothesis Generation", "comments": "Submitted to Machine Learning special issue on Inductive Logic\n  Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Inspire system which participated in the first competition on\nInductive Logic Programming (ILP). Inspire is based on Answer Set Programming\n(ASP). The distinguishing feature of Inspire is an ASP encoding for hypothesis\nspace generation: given a set of facts representing the mode bias, and a set of\ncost configuration parameters, each answer set of this encoding represents a\nsingle rule that is considered for finding a hypothesis that entails the given\nexamples. Compared with state-of-the-art methods that use the length of the\nrule body as a metric for rule complexity, our approach permits a much more\nfine-grained specification of the shape of hypothesis candidate rules. The\nInspire system iteratively increases the rule cost limit and thereby increases\nthe search space until it finds a suitable hypothesis. The system searches for\na hypothesis that entails a single example at a time, utilizing an ASP encoding\nderived from the encoding used in XHAIL. We perform experiments with the\ndevelopment and test set of the ILP competition. For comparison we also adapted\nthe ILASP system to process competition instances. Experimental results show\nthat the cost parameters for the hypothesis search space are an important\nfactor for finding hypotheses to competition instances within tight resource\nbounds.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 07:50:04 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 23:08:07 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sch\u00fcller", "Peter", ""], ["Benz", "Mishal", ""]]}, {"id": "1707.02774", "submitter": "Slava Mikhaylov", "authors": "Alexander Baturo, Niheer Dasandi, Slava J. Mikhaylov", "title": "Understanding State Preferences With Text As Data: Introducing the UN\n  General Debate Corpus", "comments": null, "journal-ref": "Research & Politics, Volume 4, Issue 2, 2017", "doi": "10.1177/2053168017712821", "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year at the United Nations, member states deliver statements during the\nGeneral Debate discussing major issues in world politics. These speeches\nprovide invaluable information on governments' perspectives and preferences on\na wide range of issues, but have largely been overlooked in the study of\ninternational politics. This paper introduces a new dataset consisting of over\n7,701 English-language country statements from 1970-2016. We demonstrate how\nthe UN General Debate Corpus (UNGDC) can be used to derive country positions on\ndifferent policy dimensions using text analytic methods. The paper provides\napplications of these estimates, demonstrating the contribution the UNGDC can\nmake to the study of international politics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 09:40:12 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Baturo", "Alexander", ""], ["Dasandi", "Niheer", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1707.02812", "submitter": "Suranjana Samanta", "authors": "Suranjana Samanta, Sameep Mehta", "title": "Towards Crafting Text Adversarial Samples", "comments": "11 pages, 5 figues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial samples are strategically modified samples, which are crafted\nwith the purpose of fooling a classifier at hand. An attacker introduces\nspecially crafted adversarial samples to a deployed classifier, which are being\nmis-classified by the classifier. However, the samples are perceived to be\ndrawn from entirely different classes and thus it becomes hard to detect the\nadversarial samples. Most of the prior works have been focused on synthesizing\nadversarial samples in the image domain. In this paper, we propose a new method\nof crafting adversarial text samples by modification of the original samples.\nModifications of the original text samples are done by deleting or replacing\nthe important or salient words in the text or by introducing new words in the\ntext sample. Our algorithm works best for the datasets which have\nsub-categories within each of the classes of examples. While crafting\nadversarial samples, one of the key constraint is to generate meaningful\nsentences which can at pass off as legitimate from language (English)\nviewpoint. Experimental results on IMDB movie review dataset for sentiment\nanalysis and Twitter dataset for gender detection show the efficiency of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 11:58:08 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Samanta", "Suranjana", ""], ["Mehta", "Sameep", ""]]}, {"id": "1707.02919", "submitter": "Mehdi Allahyari", "authors": "Mehdi Allahyari, Seyedamin Pouriyeh, Mehdi Assefi, Saied Safaei,\n  Elizabeth D. Trippe, Juan B. Gutierrez, Krys Kochut", "title": "A Brief Survey of Text Mining: Classification, Clustering and Extraction\n  Techniques", "comments": "some of References format have updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of text that is generated every day is increasing dramatically.\nThis tremendous volume of mostly unstructured text cannot be simply processed\nand perceived by computers. Therefore, efficient and effective techniques and\nalgorithms are required to discover useful patterns. Text mining is the task of\nextracting meaningful information from text, which has gained significant\nattentions in recent years. In this paper, we describe several of the most\nfundamental text mining tasks and techniques including text pre-processing,\nclassification and clustering. Additionally, we briefly explain text mining in\nbiomedical and health care domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 16:02:44 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 16:32:25 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Allahyari", "Mehdi", ""], ["Pouriyeh", "Seyedamin", ""], ["Assefi", "Mehdi", ""], ["Safaei", "Saied", ""], ["Trippe", "Elizabeth D.", ""], ["Gutierrez", "Juan B.", ""], ["Kochut", "Krys", ""]]}, {"id": "1707.02920", "submitter": "Rouhollah Rahmatizadeh", "authors": "Rouhollah Rahmatizadeh, Pooya Abolghasemi, Ladislau B\\\"ol\\\"oni, Sergey\n  Levine", "title": "Vision-Based Multi-Task Manipulation for Inexpensive Robots Using\n  End-To-End Learning from Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for multi-task learning from demonstration that trains\nthe controller of a low-cost robotic arm to accomplish several complex picking\nand placing tasks, as well as non-prehensile manipulation. The controller is a\nrecurrent neural network using raw images as input and generating robot arm\ntrajectories, with the parameters shared across the tasks. The controller also\ncombines VAE-GAN-based reconstruction with autoregressive multimodal action\nprediction. Our results demonstrate that it is possible to learn complex\nmanipulation tasks, such as picking up a towel, wiping an object, and\ndepositing the towel to its previous position, entirely from raw images with\ndirect behavior cloning. We show that weight sharing and reconstruction-based\nregularization substantially improve generalization and robustness, and\ntraining on multiple tasks simultaneously increases the success rate on all\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 16:05:53 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 16:19:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Rahmatizadeh", "Rouhollah", ""], ["Abolghasemi", "Pooya", ""], ["B\u00f6l\u00f6ni", "Ladislau", ""], ["Levine", "Sergey", ""]]}, {"id": "1707.02968", "submitter": "Chen Sun", "authors": "Chen Sun and Abhinav Shrivastava and Saurabh Singh and Abhinav Gupta", "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "comments": "ICCV 2017 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in vision can be attributed to: (a) models with\nhigh capacity; (b) increased computational power; and (c) availability of\nlarge-scale labeled data. Since 2012, there have been significant advances in\nrepresentation capabilities of the models and computational capabilities of\nGPUs. But the size of the biggest dataset has surprisingly remained constant.\nWhat will happen if we increase the dataset size by 10x or 100x? This paper\ntakes a step towards clearing the clouds of mystery surrounding the\nrelationship between `enormous data' and visual deep learning. By exploiting\nthe JFT-300M dataset which has more than 375M noisy labels for 300M images, we\ninvestigate how the performance of current vision tasks would change if this\ndata was used for representation learning. Our paper delivers some surprising\n(and some expected) findings. First, we find that the performance on vision\ntasks increases logarithmically based on volume of training data size. Second,\nwe show that representation learning (or pre-training) still holds a lot of\npromise. One can improve performance on many vision tasks by just training a\nbetter base model. Finally, as expected, we present new state-of-the-art\nresults for different vision tasks including image classification, object\ndetection, semantic segmentation and human pose estimation. Our sincere hope is\nthat this inspires vision community to not undervalue the data and develop\ncollective efforts in building larger datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 17:54:31 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 01:33:22 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Sun", "Chen", ""], ["Shrivastava", "Abhinav", ""], ["Singh", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1707.03017", "submitter": "Ethan Perez", "authors": "Ethan Perez, Harm de Vries, Florian Strub, Vincent Dumoulin, Aaron\n  Courville", "title": "Learning Visual Reasoning Without Strong Priors", "comments": "Full AAAI 2018 paper is at arXiv:1709.07871. Presented at ICML 2017's\n  Machine Learning in Speech and Language Processing Workshop. Code is at\n  http://github.com/ethanjperez/film", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving artificial visual reasoning - the ability to answer image-related\nquestions which require a multi-step, high-level process - is an important step\ntowards artificial general intelligence. This multi-modal task requires\nlearning a question-dependent, structured reasoning process over images from\nlanguage. Standard deep learning approaches tend to exploit biases in the data\nrather than learn this underlying structure, while leading methods learn to\nvisually reason successfully but are hand-crafted for reasoning. We show that a\ngeneral-purpose, Conditional Batch Normalization approach achieves\nstate-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4%\nerror rate. We outperform the next best end-to-end method (4.5%) and even\nmethods that use extra supervision (3.1%). We probe our model to shed light on\nhow it reasons, showing it has learned a question-dependent, multi-step\nprocess. Previous work has operated under the assumption that visual reasoning\ncalls for a specialized architecture, but we show that a general architecture\nwith proper conditioning can learn to visually reason effectively.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 18:49:28 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 15:02:50 GMT"}, {"version": "v3", "created": "Sun, 20 Aug 2017 14:56:51 GMT"}, {"version": "v4", "created": "Wed, 4 Oct 2017 20:01:27 GMT"}, {"version": "v5", "created": "Mon, 18 Dec 2017 21:37:16 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Perez", "Ethan", ""], ["de Vries", "Harm", ""], ["Strub", "Florian", ""], ["Dumoulin", "Vincent", ""], ["Courville", "Aaron", ""]]}, {"id": "1707.03034", "submitter": "Mohak Bhardwaj", "authors": "Mohak Bhardwaj, Sanjiban Choudhury, Sebastian Scherer", "title": "Learning Heuristic Search via Imitation", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic motion planning problems are typically solved by constructing a\nsearch tree of valid maneuvers from a start to a goal configuration. Limited\nonboard computation and real-time planning constraints impose a limit on how\nlarge this search tree can grow. Heuristics play a crucial role in such\nsituations by guiding the search towards potentially good directions and\nconsequently minimizing search effort. Moreover, it must infer such directions\nin an efficient manner using only the information uncovered by the search up\nuntil that time. However, state of the art methods do not address the problem\nof computing a heuristic that explicitly minimizes search effort. In this\npaper, we do so by training a heuristic policy that maps the partial\ninformation from the search to decide which node of the search tree to expand.\nUnfortunately, naively training such policies leads to slow convergence and\npoor local minima. We present SaIL, an efficient algorithm that trains\nheuristic policies by imitating \"clairvoyant oracles\" - oracles that have full\ninformation about the world and demonstrate decisions that minimize search\neffort. We leverage the fact that such oracles can be efficiently computed\nusing dynamic programming and derive performance guarantees for the learnt\nheuristic. We validate the approach on a spectrum of environments which show\nthat SaIL consistently outperforms state of the art algorithms. Our approach\npaves the way forward for learning heuristics that demonstrate an anytime\nnature - finding feasible solutions quickly and incrementally refining it over\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 19:36:14 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Bhardwaj", "Mohak", ""], ["Choudhury", "Sanjiban", ""], ["Scherer", "Sebastian", ""]]}, {"id": "1707.03069", "submitter": "Arthur Van Camp", "authors": "Arthur Van Camp, Gert de Cooman, Enrique Miranda", "title": "Lexicographic choice functions", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a generalisation of the coherent choice functions considered\nby Seidenfeld et al. (2010), by sticking to the convexity axiom but imposing no\nArchimedeanity condition. We define our choice functions on vector spaces of\noptions, which allows us to incorporate as special cases both Seidenfeld et\nal.'s (2010) choice functions on horse lotteries and sets of desirable gambles\n(Quaeghebeur, 2014), and to investigate their connections. We show that choice\nfunctions based on sets of desirable options (gambles) satisfy Seidenfeld's\nconvexity axiom only for very particular types of sets of desirable options,\nwhich are in a one-to-one relationship with the lexicographic probabilities. We\ncall them lexicographic choice functions. Finally, we prove that these choice\nfunctions can be used to determine the most conservative convex choice function\nassociated with a given binary relation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 21:39:03 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Van Camp", "Arthur", ""], ["de Cooman", "Gert", ""], ["Miranda", "Enrique", ""]]}, {"id": "1707.03098", "submitter": "Ole-Christoffer Granmo", "authors": "Sondre Glimsdal and Ole-Christoffer Granmo", "title": "An Optimal Bayesian Network Based Solution Scheme for the Constrained\n  Stochastic On-line Equi-Partitioning Problem", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of intriguing decision scenarios revolve around partitioning a\ncollection of objects to optimize some application specific objective function.\nThis problem is generally referred to as the Object Partitioning Problem (OPP)\nand is known to be NP-hard. We here consider a particularly challenging version\nof OPP, namely, the Stochastic On-line Equi-Partitioning Problem (SO-EPP). In\nSO-EPP, the target partitioning is unknown and has to be inferred purely from\nobserving an on-line sequence of object pairs. The paired objects belong to the\nsame partition with probability $p$ and to different partitions with\nprobability $1-p$, with $p$ also being unknown. As an additional complication,\nthe partitions are required to be of equal cardinality. Previously, only\nsub-optimal solution strategies have been proposed for SO- EPP. In this paper,\nwe propose the first optimal solution strategy. In brief, the scheme that we\npropose, BN-EPP, is founded on a Bayesian network representation of SO-EPP\nproblems. Based on probabilistic reasoning, we are not only able to infer the\nunderlying object partitioning with optimal accuracy. We are also able to\nsimultaneously infer $p$, allowing us to accelerate learning as object pairs\narrive. Furthermore, our scheme is the first to support arbitrary constraints\non the partitioning (Constrained SO-EPP). Being optimal, BN-EPP provides\nsuperior performance compared to existing solution schemes. We additionally\nintroduce Walk-BN-EPP, a novel WalkSAT inspired algorithm for solving large\nscale BN-EPP problems. Finally, we provide a BN-EPP based solution to the\nproblem of order picking, a representative real-life application of BN-EPP.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 01:48:47 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Glimsdal", "Sondre", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1707.03141", "submitter": "Nikhil Mishra", "authors": "Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel", "title": "A Simple Neural Attentive Meta-Learner", "comments": "iclr 2018 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks excel in regimes with large amounts of data, but tend to\nstruggle when data is scarce or when they need to adapt quickly to changes in\nthe task. In response, recent work in meta-learning proposes training a\nmeta-learner on a distribution of similar tasks, in the hopes of generalization\nto novel but related tasks by learning a high-level strategy that captures the\nessence of the problem it is asked to solve. However, many recent meta-learning\napproaches are extensively hand-designed, either using architectures\nspecialized to a particular application, or hard-coding algorithmic components\nthat constrain how the meta-learner solves the task. We propose a class of\nsimple and generic meta-learner architectures that use a novel combination of\ntemporal convolutions and soft attention; the former to aggregate information\nfrom past experience and the latter to pinpoint specific pieces of information.\nIn the most extensive set of meta-learning experiments to date, we evaluate the\nresulting Simple Neural AttentIve Learner (or SNAIL) on several\nheavily-benchmarked tasks. On all tasks, in both supervised and reinforcement\nlearning, SNAIL attains state-of-the-art performance by significant margins.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 06:21:31 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 16:08:03 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 04:55:20 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Mishra", "Nikhil", ""], ["Rohaninejad", "Mostafa", ""], ["Chen", "Xi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1707.03167", "submitter": "Nick Schneider", "authors": "Nick Schneider, Florian Piewak, Christoph Stiller, Uwe Franke", "title": "RegNet: Multimodal Sensor Registration Using Deep Neural Networks", "comments": "published in IEEE Intelligent Vehicles Symposium, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present RegNet, the first deep convolutional neural network\n(CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between\nmultimodal sensors, exemplified using a scanning LiDAR and a monocular camera.\nCompared to existing approaches, RegNet casts all three conventional\ncalibration steps (feature extraction, feature matching and global regression)\ninto a single real-time capable CNN. Our method does not require any human\ninteraction and bridges the gap between classical offline and target-less\nonline calibration approaches as it provides both a stable initial estimation\nas well as a continuous online correction of the extrinsic parameters. During\ntraining we randomly decalibrate our system in order to train RegNet to infer\nthe correspondence between projected depth measurements and RGB image and\nfinally regress the extrinsic calibration. Additionally, with an iterative\nexecution of multiple CNNs, that are trained on different magnitudes of\ndecalibration, our approach compares favorably to state-of-the-art methods in\nterms of a mean calibration error of 0.28 degrees for the rotational and 6 cm\nfor the translation components even for large decalibrations up to 1.5 m and 20\ndegrees.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 08:21:58 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Schneider", "Nick", ""], ["Piewak", "Florian", ""], ["Stiller", "Christoph", ""], ["Franke", "Uwe", ""]]}, {"id": "1707.03184", "submitter": "Atul Kumar", "authors": "Atul Kumar, Sameep Mehta", "title": "A Survey on Resilient Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based system are increasingly being used for sensitive tasks\nsuch as security surveillance, guiding autonomous vehicle, taking investment\ndecisions, detecting and blocking network intrusion and malware etc. However,\nrecent research has shown that machine learning models are venerable to attacks\nby adversaries at all phases of machine learning (eg, training data collection,\ntraining, operation). All model classes of machine learning systems can be\nmisled by providing carefully crafted inputs making them wrongly classify\ninputs. Maliciously created input samples can affect the learning process of a\nML system by either slowing down the learning process, or affecting the\nperformance of the learned mode, or causing the system make error(s) only in\nattacker's planned scenario. Because of these developments, understanding\nsecurity of machine learning algorithms and systems is emerging as an important\nresearch area among computer security and machine learning researchers and\npractitioners. We present a survey of this emerging area in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 09:15:46 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Kumar", "Atul", ""], ["Mehta", "Sameep", ""]]}, {"id": "1707.03191", "submitter": "Sergio Consoli", "authors": "Sergio Consoli, Jacek Kustra, Pieter Vos, Monique Hendriks, Dimitrios\n  Mavroeidis", "title": "Towards an automated method based on Iterated Local Search optimization\n  for tuning the parameters of Support Vector Machines", "comments": "3 pages, Benelearn 2017 conference, Eindhoven", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide preliminary details and formulation of an optimization strategy\nunder current development that is able to automatically tune the parameters of\na Support Vector Machine over new datasets. The optimization strategy is a\nheuristic based on Iterated Local Search, a modification of classic hill\nclimbing which iterates calls to a local search routine.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 09:29:58 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Consoli", "Sergio", ""], ["Kustra", "Jacek", ""], ["Vos", "Pieter", ""], ["Hendriks", "Monique", ""], ["Mavroeidis", "Dimitrios", ""]]}, {"id": "1707.03232", "submitter": "Douglas Summers Stay", "authors": "Douglas Summers-Stay", "title": "Deductive and Analogical Reasoning on a Semantically Embedded Knowledge\n  Graph", "comments": "AGI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing knowledge as high-dimensional vectors in a continuous semantic\nvector space can help overcome the brittleness and incompleteness of\ntraditional knowledge bases. We present a method for performing deductive\nreasoning directly in such a vector space, combining analogy, association, and\ndeduction in a straightforward way at each step in a chain of reasoning,\ndrawing on knowledge from diverse sources and ontologies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 11:49:52 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Summers-Stay", "Douglas", ""]]}, {"id": "1707.03300", "submitter": "Serkan Cabi", "authors": "Serkan Cabi, Sergio G\\'omez Colmenarejo, Matthew W. Hoffman, Misha\n  Denil, Ziyu Wang, Nando de Freitas", "title": "The Intentional Unintentional Agent: Learning to Solve Many Continuous\n  Control Tasks Simultaneously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Intentional Unintentional (IU) agent. This agent\nendows the deep deterministic policy gradients (DDPG) agent for continuous\ncontrol with the ability to solve several tasks simultaneously. Learning to\nsolve many tasks simultaneously has been a long-standing, core goal of\nartificial intelligence, inspired by infant development and motivated by the\ndesire to build flexible robot manipulators capable of many diverse behaviours.\nWe show that the IU agent not only learns to solve many tasks simultaneously\nbut it also learns faster than agents that target a single task at-a-time. In\nsome cases, where the single task DDPG method completely fails, the IU agent\nsuccessfully solves the task. To demonstrate this, we build a playroom\nenvironment using the MuJoCo physics engine, and introduce a grounded formal\nlanguage to automatically generate tasks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 14:30:06 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Cabi", "Serkan", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Hoffman", "Matthew W.", ""], ["Denil", "Misha", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""]]}, {"id": "1707.03311", "submitter": "Gil Shabat", "authors": "Yariv Aizenbud, Amir Averbuch, Gil Shabat and Guy Ziv", "title": "Similarity Search Over Graphs Using Localized Spectral Analysis", "comments": "Published in SampTA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a new similarity detection algorithm. Given an input set\nof multi-dimensional data points, where each data point is assumed to be\nmulti-dimensional, and an additional reference data point for similarity\nfinding, the algorithm uses kernel method that embeds the data points into a\nlow dimensional manifold. Unlike other kernel methods, which consider the\nentire data for the embedding, our method selects a specific set of kernel\neigenvectors. The eigenvectors are chosen to separate between the data points\nand the reference data point so that similar data points can be easily\nidentified as being distinct from most of the members in the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 15:03:57 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Aizenbud", "Yariv", ""], ["Averbuch", "Amir", ""], ["Shabat", "Gil", ""], ["Ziv", "Guy", ""]]}, {"id": "1707.03333", "submitter": "Joseph Osborn", "authors": "Joseph C Osborn, Adam Summerville and Michael Mateas", "title": "Automated Game Design Learning", "comments": "8 pages, 2 figures. Accepted for CIG 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While general game playing is an active field of research, the learning of\ngame design has tended to be either a secondary goal of such research or it has\nbeen solely the domain of humans. We propose a field of research, Automated\nGame Design Learning (AGDL), with the direct purpose of learning game designs\ndirectly through interaction with games in the mode that most people experience\ngames: via play. We detail existing work that touches the edges of this field,\ndescribe current successful projects in AGDL and the theoretical foundations\nthat enable them, point to promising applications enabled by AGDL, and discuss\nnext steps for this exciting area of study. The key moves of AGDL are to use\ngame programs as the ultimate source of truth about their own design, and to\nmake these design properties available to other systems and avenues of inquiry.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 15:43:45 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Osborn", "Joseph C", ""], ["Summerville", "Adam", ""], ["Mateas", "Michael", ""]]}, {"id": "1707.03336", "submitter": "Joseph Osborn", "authors": "Adam Summerville, Joseph Osborn, Michael Mateas", "title": "CHARDA: Causal Hybrid Automata Recovery via Dynamic Analysis", "comments": "7 pages, 2 figures. Accepted for IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate a new technique for learning hybrid automata\nautomatically by observing the runtime behavior of a dynamical system. Working\nfrom a sequence of continuous state values and predicates about the\nenvironment, CHARDA recovers the distinct dynamic modes, learns a model for\neach mode from a given set of templates, and postulates causal guard conditions\nwhich trigger transitions between modes. Our main contribution is the use of\ninformation-theoretic measures (1)~as a cost function for data segmentation and\nmodel selection to penalize over-fitting and (2)~to determine the likely causes\nof each transition. CHARDA is easily extended with different classes of model\ntemplates, fitting methods, or predicates. In our experiments on a complex\nvideogame character, CHARDA successfully discovers a reasonable\nover-approximation of the character's true behaviors. Our results also compare\nfavorably against recent work in automatically learning probabilistic timed\nautomata in an aircraft domain: CHARDA exactly learns the modes of these\nsimpler automata.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 15:50:09 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Summerville", "Adam", ""], ["Osborn", "Joseph", ""], ["Mateas", "Michael", ""]]}, {"id": "1707.03374", "submitter": "Abhishek Gupta", "authors": "YuXuan Liu, Abhishek Gupta, Pieter Abbeel, Sergey Levine", "title": "Imitation from Observation: Learning to Imitate Behaviors from Raw Video\n  via Context Translation", "comments": "Accepted at ICRA 2018, Brisbane. YuXuan Liu and Abhishek Gupta had\n  equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is an effective approach for autonomous systems to acquire\ncontrol policies when an explicit reward function is unavailable, using\nsupervision provided as demonstrations from an expert, typically a human\noperator. However, standard imitation learning methods assume that the agent\nreceives examples of observation-action tuples that could be provided, for\ninstance, to a supervised learning algorithm. This stands in contrast to how\nhumans and animals imitate: we observe another person performing some behavior\nand then figure out which actions will realize that behavior, compensating for\nchanges in viewpoint, surroundings, object positions and types, and other\nfactors. We term this kind of imitation learning \"imitation-from-observation,\"\nand propose an imitation learning method based on video prediction with context\ntranslation and deep reinforcement learning. This lifts the assumption in\nimitation learning that the demonstration should consist of observations in the\nsame environment configuration, and enables a variety of interesting\napplications, including learning robotic skills that involve tool use simply by\nobserving videos of human tool use. Our experimental results show the\neffectiveness of our approach in learning a wide range of real-world robotic\ntasks modeled after common household chores from videos of a human\ndemonstrator, including sweeping, ladling almonds, pushing objects as well as a\nnumber of tasks in simulation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 17:23:53 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 21:00:13 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Liu", "YuXuan", ""], ["Gupta", "Abhishek", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1707.03377", "submitter": "Qunzhi Zhang", "authors": "Qunzhi Zhang and Didier Sornette", "title": "Learning like humans with Deep Symbolic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Deep Symbolic Network (DSN) model, which aims at becoming\nthe white-box version of Deep Neural Networks (DNN). The DSN model provides a\nsimple, universal yet powerful structure, similar to DNN, to represent any\nknowledge of the world, which is transparent to humans. The conjecture behind\nthe DSN model is that any type of real world objects sharing enough common\nfeatures are mapped into human brains as a symbol. Those symbols are connected\nby links, representing the composition, correlation, causality, or other\nrelationships between them, forming a deep, hierarchical symbolic network\nstructure. Powered by such a structure, the DSN model is expected to learn like\nhumans, because of its unique characteristics. First, it is universal, using\nthe same structure to store any knowledge. Second, it can learn symbols from\nthe world and construct the deep symbolic networks automatically, by utilizing\nthe fact that real world objects have been naturally separated by\nsingularities. Third, it is symbolic, with the capacity of performing causal\ndeduction and generalization. Fourth, the symbols and the links between them\nare transparent to us, and thus we will know what it has learned or not - which\nis the key for the security of an AI system. Fifth, its transparency enables it\nto learn with relatively small data. Sixth, its knowledge can be accumulated.\nLast but not least, it is more friendly to unsupervised learning than DNN. We\npresent the details of the model, the algorithm powering its automatic learning\nability, and describe its usefulness in different use cases. The purpose of\nthis paper is to generate broad interest to develop it within an open source\nproject centered on the Deep Symbolic Network (DSN) model towards the\ndevelopment of general AI.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 17:29:51 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 12:00:38 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Zhang", "Qunzhi", ""], ["Sornette", "Didier", ""]]}, {"id": "1707.03471", "submitter": "Suju Rajan", "authors": "Abraham Bagherjeiran, Nemanja Djuric, Mihajlo Grbovic, Kuang-Chih Lee,\n  Kun Liu, Vladan Radosavljevic and Suju Rajan", "title": "Proceedings of the 2017 AdKDD & TargetAd Workshop", "comments": "Workshop Proceedings with links to the accepted papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the 2017 AdKDD and TargetAd Workshop held in conjunction with\nthe 23rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining Halifax,\nNova Scotia, Canada.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 21:43:14 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Bagherjeiran", "Abraham", ""], ["Djuric", "Nemanja", ""], ["Grbovic", "Mihajlo", ""], ["Lee", "Kuang-Chih", ""], ["Liu", "Kun", ""], ["Radosavljevic", "Vladan", ""], ["Rajan", "Suju", ""]]}, {"id": "1707.03490", "submitter": "Slava Mikhaylov", "authors": "Stefano Gurciullo and Slava Mikhaylov", "title": "Detecting Policy Preferences and Dynamics in the UN General Debate with\n  Neural Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreign policy analysis has been struggling to find ways to measure policy\npreferences and paradigm shifts in international political systems. This paper\npresents a novel, potential solution to this challenge, through the application\nof a neural word embedding (Word2vec) model on a dataset featuring speeches by\nheads of state or government in the United Nations General Debate. The paper\nprovides three key contributions based on the output of the Word2vec model.\nFirst, it presents a set of policy attention indices, synthesizing the semantic\nproximity of political speeches to specific policy themes. Second, it\nintroduces country-specific semantic centrality indices, based on topological\nanalyses of countries' semantic positions with respect to each other. Third, it\ntests the hypothesis that there exists a statistical relation between the\nsemantic content of political speeches and UN voting behavior, falsifying it\nand suggesting that political speeches contain information of different nature\nthen the one behind voting outcomes. The paper concludes with a discussion of\nthe practical use of its results and consequences for foreign policy analysis,\npublic accountability, and transparency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:16:20 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Gurciullo", "Stefano", ""], ["Mikhaylov", "Slava", ""]]}, {"id": "1707.03497", "submitter": "Junhyuk Oh", "authors": "Junhyuk Oh, Satinder Singh, Honglak Lee", "title": "Value Prediction Network", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep reinforcement learning (RL) architecture,\ncalled Value Prediction Network (VPN), which integrates model-free and\nmodel-based RL methods into a single neural network. In contrast to typical\nmodel-based RL methods, VPN learns a dynamics model whose abstract states are\ntrained to make option-conditional predictions of future values (discounted sum\nof rewards) rather than of future observations. Our experimental results show\nthat VPN has several advantages over both model-free and model-based baselines\nin a stochastic environment where careful planning is required but building an\naccurate observation-prediction model is difficult. Furthermore, VPN\noutperforms Deep Q-Network (DQN) on several Atari games even with\nshort-lookahead planning, demonstrating its potential as a new way of learning\na good state representation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:32:36 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 23:55:47 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""], ["Lee", "Honglak", ""]]}, {"id": "1707.03501", "submitter": "Jiajun Lu", "authors": "Jiajun Lu, Hussein Sibai, Evan Fabry, David Forsyth", "title": "NO Need to Worry about Adversarial Examples in Object Detection in\n  Autonomous Vehicles", "comments": "Accepted to CVPR 2017, Spotlight Oral Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that most machine learning algorithms are susceptible to\nadversarial perturbations. Slightly perturbing an image in a carefully chosen\ndirection in the image space may cause a trained neural network model to\nmisclassify it. Recently, it was shown that physical adversarial examples\nexist: printing perturbed images then taking pictures of them would still\nresult in misclassification. This raises security and safety concerns.\n  However, these experiments ignore a crucial property of physical objects: the\ncamera can view objects from different distances and at different angles. In\nthis paper, we show experiments that suggest that current constructions of\nphysical adversarial examples do not disrupt object detection from a moving\nplatform. Instead, a trained neural network classifies most of the pictures\ntaken from different distances and angles of a perturbed image correctly. We\nbelieve this is because the adversarial property of the perturbation is\nsensitive to the scale at which the perturbed picture is viewed, so (for\nexample) an autonomous car will misclassify a stop sign only from a small range\nof distances.\n  Our work raises an important question: can one construct examples that are\nadversarial for many or most viewing conditions? If so, the construction should\noffer very significant insights into the internal representation of patterns by\ndeep networks. If not, there is a good prospect that adversarial examples can\nbe reduced to a curiosity with little practical impact.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 00:09:50 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Lu", "Jiajun", ""], ["Sibai", "Hussein", ""], ["Fabry", "Evan", ""], ["Forsyth", "David", ""]]}, {"id": "1707.03502", "submitter": "Jindong Wang", "authors": "Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng and Lisha Hu", "title": "Deep Learning for Sensor-based Activity Recognition: A Survey", "comments": "10 pages, 2 figures, and 5 tables; submitted to Pattern Recognition\n  Letters (second revision)", "journal-ref": null, "doi": "10.1016/j.patrec.2018.02.010", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor-based activity recognition seeks the profound high-level knowledge\nabout human activities from multitudes of low-level sensor readings.\nConventional pattern recognition approaches have made tremendous progress in\nthe past years. However, those methods often heavily rely on heuristic\nhand-crafted feature extraction, which could hinder their generalization\nperformance. Additionally, existing methods are undermined for unsupervised and\nincremental learning tasks. Recently, the recent advancement of deep learning\nmakes it possible to perform automatic high-level feature extraction thus\nachieves promising performance in many areas. Since then, deep learning based\nmethods have been widely adopted for the sensor-based activity recognition\ntasks. This paper surveys the recent advance of deep learning based\nsensor-based activity recognition. We summarize existing literature from three\naspects: sensor modality, deep model, and application. We also present detailed\ninsights on existing work and propose grand challenges for future research.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 00:21:04 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 03:11:15 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Hao", "Shuji", ""], ["Peng", "Xiaohui", ""], ["Hu", "Lisha", ""]]}, {"id": "1707.03602", "submitter": "Serkan Ayvaz", "authors": "Serkan Ayvaz, Mehmet Aydar", "title": "Using RDF Summary Graph For Keyword-based Semantic Searches", "comments": "5th International Conference on Advanced Technology & Sciences\n  (ICAT'17). Istanbul, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web began to emerge as its standards and technologies developed\nrapidly in the recent years. The continuing development of Semantic Web\ntechnologies has facilitated publishing explicit semantics with data on the Web\nin RDF data model. This study proposes a semantic search framework to support\nefficient keyword-based semantic search on RDF data utilizing near neighbor\nexplorations. The framework augments the search results with the resources in\nclose proximity by utilizing the entity type semantics. Along with the search\nresults, the system generates a relevance confidence score measuring the\ninferred semantic relatedness of returned entities based on the degree of\nsimilarity. Furthermore, the evaluations assessing the effectiveness of the\nframework and the accuracy of the results are presented.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 08:54:48 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Ayvaz", "Serkan", ""], ["Aydar", "Mehmet", ""]]}, {"id": "1707.03739", "submitter": "Guangming Lang", "authors": "Guangming Lang", "title": "Conflict Analysis for Pythagorean Fuzzy Information Systems with Group\n  Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pythagorean fuzzy sets provide stronger ability than intuitionistic fuzzy\nsets to model uncertainty information and knowledge, but little effort has been\npaid to conflict analysis of Pythagorean fuzzy information systems. In this\npaper, we present three types of positive, central, and negative alliances with\ndifferent thresholds, and employ examples to illustrate how to construct the\npositive, central, and negative alliances. Then we study conflict analysis of\nPythagorean fuzzy information systems based on Bayesian minimum risk theory.\nFinally, we investigate group conflict analysis of Pythagorean fuzzy\ninformation systems based on Bayesian minimum risk theory.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 14:35:32 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Lang", "Guangming", ""]]}, {"id": "1707.03743", "submitter": "Niels Justesen", "authors": "Niels Justesen and Sebastian Risi", "title": "Learning Macromanagement in StarCraft from Replays using Deep Learning", "comments": "8 pages, to appear in the proceedings of the IEEE Conference on\n  Computational Intelligence and Games (CIG 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-time strategy game StarCraft has proven to be a challenging\nenvironment for artificial intelligence techniques, and as a result, current\nstate-of-the-art solutions consist of numerous hand-crafted modules. In this\npaper, we show how macromanagement decisions in StarCraft can be learned\ndirectly from game replays using deep learning. Neural networks are trained on\n789,571 state-action pairs extracted from 2,005 replays of highly skilled\nplayers, achieving top-1 and top-3 error rates of 54.6% and 22.9% in predicting\nthe next build action. By integrating the trained network into UAlbertaBot, an\nopen source StarCraft bot, the system can significantly outperform the game's\nbuilt-in Terran bot, and play competitively against UAlbertaBot with a fixed\nrush strategy. To our knowledge, this is the first time macromanagement tasks\nare learned directly from replays in StarCraft. While the best hand-crafted\nstrategies are still the state-of-the-art, the deep network approach is able to\nexpress a wide range of different strategies and thus improving the network's\nperformance further with deep reinforcement learning is an immediately\npromising avenue for future research. Ultimately this approach could lead to\nstrong StarCraft bots that are less reliant on hard-coded strategies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 14:40:00 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Justesen", "Niels", ""], ["Risi", "Sebastian", ""]]}, {"id": "1707.03744", "submitter": "Christian Oesch", "authors": "Christian Oesch", "title": "P-Tree Programming", "comments": "Submitted to IEEE SSCI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for automatic program synthesis. P-Tree Programming\nrepresents the program search space through a single probabilistic prototype\ntree. From this prototype tree we form program instances which we evaluate on a\ngiven problem. The error values from the evaluations are propagated through the\nprototype tree. We use them to update the probability distributions that\ndetermine the symbol choices of further instances. The iterative method is\napplied to several symbolic regression benchmarks from the literature. It\noutperforms standard Genetic Programming to a large extend. Furthermore, it\nrelies on a concise set of parameters which are held constant for all problems.\nThe algorithm can be employed for most of the typical computational\nintelligence tasks such as classification, automatic program induction, and\nsymbolic regression.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 14:40:06 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Oesch", "Christian", ""]]}, {"id": "1707.03804", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "Source-Target Inference Models for Spatial Instruction Understanding", "comments": "Accepted to AAAI 2018 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that can execute natural language instructions for situated robotic\ntasks such as assembly and navigation have several useful applications in\nhomes, offices, and remote scenarios. We study the semantics of\nspatially-referred configuration and arrangement instructions, based on the\nchallenging Bisk-2016 blank-labeled block dataset. This task involves finding a\nsource block and moving it to the target position (mentioned via a reference\nblock and offset), where the blocks have no names or colors and are just\nreferred to via spatial location features. We present novel models for the\nsubtasks of source block classification and target position regression, based\non joint-loss language and spatial-world representation learning, as well as\nCNN-based and dual attention models to compute the alignment between the world\nblocks and the instruction phrases. For target position prediction, we compare\ntwo inference approaches: annealed sampling via policy gradient versus\nexpectation inference via supervised regression. Our models achieve the new\nstate-of-the-art on this task, with an improvement of 47% on source block\naccuracy and 22% on target position distance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 17:15:57 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 16:57:02 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "1707.03865", "submitter": "Joseph Osborn", "authors": "Adam Summerville, Joseph C. Osborn, Christoffer Holmg{\\aa}rd, Daniel\n  W. Zhang", "title": "Mechanics Automatically Recognized via Interactive Observation: Jumping", "comments": "10 pages, 12 figures. Accepted at Foundations of Digital Games 2017", "journal-ref": null, "doi": "10.1145/3102071.3102104", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jumping has been an important mechanic since its introduction in Donkey Kong.\nIt has taken a variety of forms and shown up in numerous games, with each jump\nhaving a different feel. In this paper, we use a modified Nintendo\nEntertainment System (NES) emulator to semi-automatically run experiments on a\nlarge subset (30%) of NES platform games. We use these experiments to build\nmodels of jumps from different developers, series, and games across the history\nof the console. We then examine these models to gain insights into different\nforms of jumping and their associated feel.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 18:49:15 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Summerville", "Adam", ""], ["Osborn", "Joseph C.", ""], ["Holmg\u00e5rd", "Christoffer", ""], ["Zhang", "Daniel W.", ""]]}, {"id": "1707.03872", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Independence, Conditionality and Structure of Dempster-Shafer Belief\n  Functions", "comments": "1994 internal report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several approaches of structuring (factorization, decomposition) of\nDempster-Shafer joint belief functions from literature are reviewed with\nspecial emphasis on their capability to capture independence from the point of\nview of the claim that belief functions generalize bayes notion of probability.\n  It is demonstrated that Zhu and Lee's {Zhu:93} logical networks and Smets'\n{Smets:93} directed acyclic graphs are unable to capture statistical\ndependence/independence of bayesian networks {Pearl:88}. On the other hand,\nthough Shenoy and Shafer's hypergraphs can explicitly represent bayesian\nnetwork factorization of bayesian belief functions, they disclaim any need for\nrepresentation of independence of variables in belief functions.\n  Cano et al. {Cano:93} reject the hypergraph representation of Shenoy and\nShafer just on grounds of missing representation of variable independence, but\nin their frameworks some belief functions factorizable in Shenoy/Shafer\nframework cannot be factored.\n  The approach in {Klopotek:93f} on the other hand combines the merits of both\nCano et al. and of Shenoy/Shafer approach in that for Shenoy/Shafer approach no\nsimpler factorization than that in {Klopotek:93f} approach exists and on the\nother hand all independences among variables captured in Cano et al. framework\nand many more are captured in {Klopotek:93f} approach.%\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 19:06:35 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1707.03881", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Identification and Interpretation of Belief Structure in Dempster-Shafer\n  Theory", "comments": "An internal report 1994", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical Theory of Evidence called also Dempster-Shafer Theory (DST) is\nknown as a foundation for reasoning when knowledge is expressed at various\nlevels of detail. Though much research effort has been committed to this theory\nsince its foundation, many questions remain open. One of the most important\nopen questions seems to be the relationship between frequencies and the\nMathematical Theory of Evidence. The theory is blamed to leave frequencies\noutside (or aside of) its framework. The seriousness of this accusation is\nobvious: (1) no experiment may be run to compare the performance of DST-based\nmodels of real world processes against real world data, (2) data may not serve\nas foundation for construction of an appropriate belief model.\n  In this paper we develop a frequentist interpretation of the DST bringing to\nfall the above argument against DST. An immediate consequence of it is the\npossibility to develop algorithms acquiring automatically DST belief models\nfrom data. We propose three such algorithms for various classes of belief model\nstructures: for tree structured belief networks, for poly-tree belief networks\nand for general type belief networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 19:24:26 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1707.03886", "submitter": "Amit Dhurandhar", "authors": "Amit Dhurandhar, Vijay Iyengar, Ronny Luss and Karthikeyan Shanmugam", "title": "A Formal Framework to Characterize Interpretability of Procedures", "comments": "presented at 2017 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2017), Sydney, NSW, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 19:42:08 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Dhurandhar", "Amit", ""], ["Iyengar", "Vijay", ""], ["Luss", "Ronny", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "1707.03902", "submitter": "Samuel James Alvernaz", "authors": "Samuel Alvernaz, Julian Togelius", "title": "Autoencoder-augmented Neuroevolution for Visual Doom Playing", "comments": "IEEE conference on Computational Intelligence and Games 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution has proven effective at many reinforcement learning tasks, but\ndoes not seem to scale well to high-dimensional controller representations,\nwhich are needed for tasks where the input is raw pixel data. We propose a\nnovel method where we train an autoencoder to create a comparatively\nlow-dimensional representation of the environment observation, and then use\nCMA-ES to train neural network controllers acting on this input data. As the\nbehavior of the agent changes the nature of the input data, the autoencoder\ntraining progresses throughout evolution. We test this method in the VizDoom\nenvironment built on the classic FPS Doom, where it performs well on a\nhealth-pack gathering task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 20:46:21 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Alvernaz", "Samuel", ""], ["Togelius", "Julian", ""]]}, {"id": "1707.03908", "submitter": "Joseph Osborn", "authors": "Joseph C. Osborn and Adam Summerville and Michael Mateas", "title": "Automatic Mapping of NES Games with Mappy", "comments": "9 pages, 7 figures. Appearing at Procedural Content Generation\n  Workshop 2017", "journal-ref": null, "doi": "10.1145/3102071.3110576", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game maps are useful for human players, general-game-playing agents, and\ndata-driven procedural content generation. These maps are generally made by\nhand-assembling manually-created screenshots of game levels. Besides being\ntedious and error-prone, this approach requires additional effort for each new\ngame and level to be mapped. The results can still be hard for humans or\ncomputational systems to make use of, privileging visual appearance over\nsemantic information. We describe a software system, Mappy, that produces a\ngood approximation of a linked map of rooms given a Nintendo Entertainment\nSystem game program and a sequence of button inputs exploring its world. In\naddition to visual maps, Mappy outputs grids of tiles (and how they change over\ntime), positions of non-tile objects, clusters of similar rooms that might in\nfact be the same room, and a set of links between these rooms. We believe this\nis a necessary step towards developing larger corpora of high-quality\nsemantically-annotated maps for PCG via machine learning and other\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 21:02:19 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Osborn", "Joseph C.", ""], ["Summerville", "Adam", ""], ["Mateas", "Michael", ""]]}, {"id": "1707.03938", "submitter": "Michael Janner", "authors": "Michael Janner, Karthik Narasimhan, Regina Barzilay", "title": "Representation Learning for Grounded Spatial Reasoning", "comments": "Accepted to TACL 2017, code:\n  https://github.com/jannerm/spatial-reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interpretation of spatial references is highly contextual, requiring\njoint inference over both language and the environment. We consider the task of\nspatial reasoning in a simulated environment, where an agent can act and\nreceive rewards. The proposed model learns a representation of the world\nsteered by instruction text. This design allows for precise alignment of local\nneighborhoods with corresponding verbalizations, while also handling global\nreferences in the instructions. We train our model with reinforcement learning\nusing a variant of generalized value iteration. The model outperforms\nstate-of-the-art approaches on several metrics, yielding a 45% reduction in\ngoal localization error.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 00:17:45 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 02:20:54 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Janner", "Michael", ""], ["Narasimhan", "Karthik", ""], ["Barzilay", "Regina", ""]]}, {"id": "1707.03979", "submitter": "Marc Pickett", "authors": "Marc Pickett, Ayush Sekhari, James Davidson", "title": "A Brief Study of In-Domain Transfer and Learning from Fewer Samples\n  using A Few Simple Priors", "comments": "Accepted for ICML 2017 Workshop on Picky Learners", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain knowledge can often be encoded in the structure of a network, such as\nconvolutional layers for vision, which has been shown to increase\ngeneralization and decrease sample complexity, or the number of samples\nrequired for successful learning. In this study, we ask whether sample\ncomplexity can be reduced for systems where the structure of the domain is\nunknown beforehand, and the structure and parameters must both be learned from\nthe data. We show that sample complexity reduction through learning structure\nis possible for at least two simple cases. In studying these cases, we also\ngain insight into how this might be done for more complex domains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 04:56:24 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Pickett", "Marc", ""], ["Sekhari", "Ayush", ""], ["Davidson", "James", ""]]}, {"id": "1707.03981", "submitter": "Gautam Malu", "authors": "Gautam Malu, Raju S. Bapi, Bipin Indurkhya", "title": "Learning Photography Aesthetics with Deep CNNs", "comments": "Accepted in The 28th Modern Artificial Intelligence and Cognitive\n  Science Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic photo aesthetic assessment is a challenging artificial intelligence\ntask. Existing computational approaches have focused on modeling a single\naesthetic score or a class (good or bad), however these do not provide any\ndetails on why the photograph is good or bad, or which attributes contribute to\nthe quality of the photograph. To obtain both accuracy and human interpretation\nof the score, we advocate learning the aesthetic attributes along with the\nprediction of the overall score. For this purpose, we propose a novel multitask\ndeep convolution neural network, which jointly learns eight aesthetic\nattributes along with the overall aesthetic score. We report near human\nperformance in the prediction of the overall aesthetic score. To understand the\ninternal representation of these attributes in the learned model, we also\ndevelop the visualization technique using back propagation of gradients. These\nvisualizations highlight the important image regions for the corresponding\nattributes, thus providing insights about model's representation of these\nattributes. We showcase the diversity and complexity associated with different\nattributes through a qualitative analysis of the activation maps.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 05:16:03 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Malu", "Gautam", ""], ["Bapi", "Raju S.", ""], ["Indurkhya", "Bipin", ""]]}, {"id": "1707.04016", "submitter": "Jerry Swan", "authors": "Zoltan A. Kocsis and Jerry Swan", "title": "Dependency Injection for Programming by Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Programming by Optimization tools perform automatic software configuration\naccording to the specification supplied by a software developer. Developers\nspecify design spaces for program components, and the onerous task of\ndetermining which configuration best suits a given use case is determined using\nautomated analysis tools and optimization heuristics. However, in current\napproaches to Programming by Optimization, design space specification and\nexploration relies on external configuration algorithms, executable wrappers\nand fragile, preprocessed programming language extensions.\n  Here we show that the architectural pattern of Dependency Injection provides\na superior alternative to the traditional Programming by Optimization pipeline.\nWe demonstrate that configuration tools based on Dependency Injection fit\nnaturally into the software development process, while requiring less overhead\nthan current wrapper-based mechanisms. Furthermore, the structural\ncorrespondence between Dependency Injection and context-free grammars yields a\nnew class of evolutionary metaheuristics for automated algorithm configuration.\nWe found that the new heuristics significantly outperform existing\nconfiguration algorithms on many problems of interest (in one case by two\norders of magnitude). We anticipate that these developments will make\nProgramming by Optimization immediately applicable to a large number of\nenterprise software projects.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 08:02:23 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Kocsis", "Zoltan A.", ""], ["Swan", "Jerry", ""]]}, {"id": "1707.04027", "submitter": "Peter Sch\\\"uller", "authors": "Bernardo Cuteri, Carmine Dodaro, Francesco Ricca, Peter Sch\\\"uller", "title": "Constraints, Lazy Constraints, or Propagators in ASP Solving: An\n  Empirical Analysis", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1,\n  2017. 16 pages", "journal-ref": "Theory and Practice of Logic Programming 17 (5-6), pages 780-799,\n  2017", "doi": "10.1017/S1471068417000254", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-established declarative paradigm. One\nof the successes of ASP is the availability of efficient systems.\nState-of-the-art systems are based on the ground+solve approach. In some\napplications this approach is infeasible because the grounding of one or few\nconstraints is expensive. In this paper, we systematically compare alternative\nstrategies to avoid the instantiation of problematic constraints, that are\nbased on custom extensions of the solver. Results on real and synthetic\nbenchmarks highlight some strengths and weaknesses of the different strategies.\n(Under consideration for acceptance in TPLP, ICLP 2017 Special Issue.)\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 08:41:30 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Cuteri", "Bernardo", ""], ["Dodaro", "Carmine", ""], ["Ricca", "Francesco", ""], ["Sch\u00fcller", "Peter", ""]]}, {"id": "1707.04035", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Steven Van Vaerenbergh, Simone Totaro, Aurelio\n  Uncini", "title": "Kafnets: kernel-based non-parametric activation functions for neural\n  networks", "comments": "Preprint submitted to Neural Networks (Elsevier)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are generally built by interleaving (adaptable) linear layers\nwith (fixed) nonlinear activation functions. To increase their flexibility,\nseveral authors have proposed methods for adapting the activation functions\nthemselves, endowing them with varying degrees of flexibility. None of these\napproaches, however, have gained wide acceptance in practice, and research in\nthis topic remains open. In this paper, we introduce a novel family of flexible\nactivation functions that are based on an inexpensive kernel expansion at every\nneuron. Leveraging over several properties of kernel-based models, we propose\nmultiple variations for designing and initializing these kernel activation\nfunctions (KAFs), including a multidimensional scheme allowing to nonlinearly\ncombine information from different paths in the network. The resulting KAFs can\napproximate any mapping defined over a subset of the real line, either convex\nor nonconvex. Furthermore, they are smooth over their entire domain, linear in\ntheir parameters, and they can be regularized using any known scheme, including\nthe use of $\\ell_1$ penalties to enforce sparseness. To the best of our\nknowledge, no other known model satisfies all these properties simultaneously.\nIn addition, we provide a relatively complete overview on alternative\ntechniques for adapting the activation functions, which is currently lacking in\nthe literature. A large set of experiments validates our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 09:22:01 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 11:33:32 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Scardapane", "Simone", ""], ["Van Vaerenbergh", "Steven", ""], ["Totaro", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1707.04046", "submitter": "Ben Usman", "authors": "Ben Usman, Kate Saenko, Brian Kulis", "title": "Stable Distribution Alignment Using the Dual of the Adversarial Distance", "comments": "ICLR 2018 Conference Invite to Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods that align distributions by minimizing an adversarial distance\nbetween them have recently achieved impressive results. However, these\napproaches are difficult to optimize with gradient descent and they often do\nnot converge well without careful hyperparameter tuning and proper\ninitialization. We investigate whether turning the adversarial min-max problem\ninto an optimization problem by replacing the maximization part with its dual\nimproves the quality of the resulting alignment and explore its connections to\nMaximum Mean Discrepancy. Our empirical results suggest that using the dual\nformulation for the restricted family of linear discriminators results in a\nmore stable convergence to a desirable solution when compared with the\nperformance of a primal min-max GAN-like objective and an MMD objective under\nthe same restrictions. We test our hypothesis on the problem of aligning two\nsynthetic point clouds on a plane and on a real-image domain adaptation problem\non digits. In both cases, the dual formulation yields an iterative procedure\nthat gives more stable and monotonic improvement over time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 09:50:14 GMT"}, {"version": "v2", "created": "Sat, 28 Oct 2017 02:28:56 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 19:32:26 GMT"}, {"version": "v4", "created": "Tue, 30 Jan 2018 20:49:21 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Usman", "Ben", ""], ["Saenko", "Kate", ""], ["Kulis", "Brian", ""]]}, {"id": "1707.04053", "submitter": "Torsten Schaub", "authors": "Tomi Janhunen and Roland Kaminski and Max Ostrowski and Torsten Schaub\n  and Sebastian Schellhorn and Philipp Wanko", "title": "Clingo goes Linear Constraints over Reals and Integers", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1, 2017\n  16 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent series 5 of the ASP system clingo provides generic means to\nenhance basic Answer Set Programming (ASP) with theory reasoning capabilities.\nWe instantiate this framework with different forms of linear constraints,\ndiscuss the respective implementations, and present techniques of how to use\nthese constraints in a reactive context. More precisely, we introduce\nextensions to clingo with difference and linear constraints over integers and\nreals, respectively, and realize them in complementary ways. Finally, we\nempirically evaluate the resulting clingo derivatives clingo[dl] and clingo[lp]\non common fragments and contrast them to related ASP systems.\n  This paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 10:18:12 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Janhunen", "Tomi", ""], ["Kaminski", "Roland", ""], ["Ostrowski", "Max", ""], ["Schaub", "Torsten", ""], ["Schellhorn", "Sebastian", ""], ["Wanko", "Philipp", ""]]}, {"id": "1707.04092", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Xunyu Lin, Victor Campos, Xavier Giro-i-Nieto, Jordi Torres and\n  Cristian Canton Ferrer", "title": "Disentangling Motion, Foreground and Background Features in Videos", "comments": "Poster presented at the CVPR 2017 Workshop Brave New Ideas for Motion\n  Representations in Videos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an unsupervised framework to extract semantically rich\nfeatures for video representation. Inspired by how the human visual system\ngroups objects based on motion cues, we propose a deep convolutional neural\nnetwork that disentangles motion, foreground and background information. The\nproposed architecture consists of a 3D convolutional feature encoder for blocks\nof 16 frames, which is trained for reconstruction tasks over the first and last\nframes of the sequence. A preliminary supervised experiment was conducted to\nverify the feasibility of proposed method by training the model with a fraction\nof videos from the UCF-101 dataset taking as ground truth the bounding boxes\naround the activity regions. Qualitative results indicate that the network can\nsuccessfully segment foreground and background in videos as well as update the\nforeground appearance based on disentangled motion features. The benefits of\nthese learned features are shown in a discriminative classification task, where\ninitializing the network with the proposed pretraining method outperforms both\nrandom initialization and autoencoder pretraining. Our model and source code\nare publicly available at https://imatge-upc.github.io/unsupervised-2017-cvprw/ .\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 12:40:28 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 13:50:01 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Lin", "Xunyu", ""], ["Campos", "Victor", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""], ["Ferrer", "Cristian Canton", ""]]}, {"id": "1707.04106", "submitter": "Pavel Naumov", "authors": "Kaya Deuser and Pavel Naumov", "title": "Armstrong's Axioms and Navigation Strategies", "comments": null, "journal-ref": "Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18), 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates navigability with imperfect information. It shows that\nthe properties of navigability with perfect recall are exactly those captured\nby Armstrong's axioms from the database theory. If the assumption of perfect\nrecall is omitted, then Armstrong's transitivity axiom is not valid, but it can\nbe replaced by two new weaker principles. The main technical results are\nsoundness and completeness theorems for the logical systems describing\nproperties of navigability with and without perfect recall.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 13:17:06 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 19:21:09 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Deuser", "Kaya", ""], ["Naumov", "Pavel", ""]]}, {"id": "1707.04242", "submitter": "Christophe Van Gysel", "authors": "Tom Kenter, Alexey Borisov, Christophe Van Gysel, Mostafa Dehghani,\n  Maarten de Rijke, Bhaskar Mitra", "title": "Neural Networks for Information Retrieval", "comments": "Overview of full-day tutorial at SIGIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays a role in many aspects of modern IR systems, and deep\nlearning is applied in all of them. The fast pace of modern-day research has\ngiven rise to many different approaches for many different IR problems. The\namount of information available can be overwhelming both for junior students\nand for experienced researchers looking for new research topics and directions.\nAdditionally, it is interesting to see what key insights into IR problems the\nnew technologies are able to give us. The aim of this full-day tutorial is to\ngive a clear overview of current tried-and-trusted neural methods in IR and how\nthey benefit IR research. It covers key architectures, as well as the most\npromising future directions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 17:46:59 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Kenter", "Tom", ""], ["Borisov", "Alexey", ""], ["Van Gysel", "Christophe", ""], ["Dehghani", "Mostafa", ""], ["de Rijke", "Maarten", ""], ["Mitra", "Bhaskar", ""]]}, {"id": "1707.04244", "submitter": "Preeti Bhargava", "authors": "Preeti Bhargava and Nemanja Spasojevic and Guoning Hu", "title": "Lithium NLP: A System for Rich Information Extraction from Noisy User\n  Generated Text on Social Media", "comments": "9 pages, 6 figures, 2 tables, EMNLP 2017 Workshop on Noisy User\n  Generated Text WNUT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the Lithium Natural Language Processing (NLP)\nsystem - a resource-constrained, high- throughput and language-agnostic system\nfor information extraction from noisy user generated text on social media.\nLithium NLP extracts a rich set of information including entities, topics,\nhashtags and sentiment from text. We discuss several real world applications of\nthe system currently incorporated in Lithium products. We also compare our\nsystem with existing commercial and academic NLP systems in terms of\nperformance, information extracted and languages supported. We show that\nLithium NLP is at par with and in some cases, outperforms state- of-the-art\ncommercial NLP systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 17:52:51 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Bhargava", "Preeti", ""], ["Spasojevic", "Nemanja", ""], ["Hu", "Guoning", ""]]}, {"id": "1707.04245", "submitter": "Chris Fawcett", "authors": "Chris Fawcett, Lars Kotthoff, Holger H. Hoos", "title": "Hot-Rodding the Browser Engine: Automatic Configuration of JavaScript\n  Compilers", "comments": "11 pages, long version of a poster presented at CGO 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern software systems in many application areas offer to the user a\nmultitude of parameters, switches and other customisation hooks. Humans tend to\nhave difficulties determining the best configurations for particular\napplications. Modern optimising compilers are an example of such software\nsystems; their many parameters need to be tuned for optimal performance, but\nare often left at the default values for convenience. In this work, we\nautomatically determine compiler parameter settings that result in optimised\nperformance for particular applications. Specifically, we apply a\nstate-of-the-art automated parameter configuration procedure based on\ncutting-edge machine learning and optimisation techniques to two prominent\nJavaScript compilers and demonstrate that significant performance improvements,\nmore than 35% in some cases, can be achieved over the default parameter\nsettings on a diverse set of benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:31:23 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Fawcett", "Chris", ""], ["Kotthoff", "Lars", ""], ["Hoos", "Holger H.", ""]]}, {"id": "1707.04277", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "On (Anti)Conditional Independence in Dempster-Shafer Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper verifies a result of {Shenoy:94} concerning graphoidal structure\nof Shenoy's notion of independence for Dempster-Shafer theory of belief\nfunctions. Shenoy proved that his notion of independence has graphoidal\nproperties for positive normal valuations.\n  The requirement of strict positive normal valuations as prerequisite for\napplication of graphoidal properties excludes a wide class of DS belief\nfunctions. It excludes especially so-called probabilistic belief functions. It\nis demonstrated that the requirement of positiveness of valuation may be\nweakened in that it may be required that commonality function is non-zero for\nsingleton sets instead, and the graphoidal properties for independence of\nbelief function variables are then preserved. This means especially that\nprobabilistic belief functions with all singleton sets as focal points possess\ngraphoidal properties for independence.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 18:33:34 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1707.04291", "submitter": "An Yan", "authors": "An Yan, Michael J. Lee, Andrew J. Ko", "title": "Predicting Abandonment in Online Coding Tutorials", "comments": "Accepted to IEEE Symposium on Visual Languages and Human-Centric\n  Computing (VL/HCC), 2017", "journal-ref": null, "doi": "10.1109/VLHCC.2017.8103467", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learners regularly abandon online coding tutorials when they get bored or\nfrustrated, but there are few techniques for anticipating this abandonment to\nintervene. In this paper, we examine the feasibility of predicting abandonment\nwith machine-learned classifiers. Using interaction logs from an online\nprogramming game, we extracted a collection of features that are potentially\nrelated to learner abandonment and engagement, then developed classifiers for\neach level. Across the first five levels of the game, our classifiers\nsuccessfully predicted 61% to 76% of learners who did not complete the next\nlevel, achieving an average AUC of 0.68. In these classifiers, features\nnegatively associated with abandonment included account activation and\nhelp-seeking behaviors, whereas features positively associated with abandonment\nincluded features indicating difficulty and disengagement. These findings\nhighlight the feasibility of providing timely intervention to learners likely\nto quit.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 19:55:00 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Yan", "An", ""], ["Lee", "Michael J.", ""], ["Ko", "Andrew J.", ""]]}, {"id": "1707.04298", "submitter": "Pavel Naumov", "authors": "Pavel Naumov and Jia Tao", "title": "Strategic Coalitions with Perfect Recall", "comments": null, "journal-ref": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18), New Orleans, Lousiana, USA (2018)", "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a bimodal logic that describes an interplay between\ndistributed knowledge modality and coalition know-how modality. Unlike other\nsimilar systems, the one proposed here assumes perfect recall by all agents.\nPerfect recall is captured in the system by a single axiom. The main technical\nresults are the soundness and the completeness theorems for the proposed\nlogical system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:18:29 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 20:11:10 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Naumov", "Pavel", ""], ["Tao", "Jia", ""]]}, {"id": "1707.04314", "submitter": "Tom Rainforth", "authors": "Tom Rainforth, Tuan Anh Le, Jan-Willem van de Meent, Michael A.\n  Osborne, Frank Wood", "title": "Bayesian Optimization for Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.PL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first general purpose framework for marginal maximum a\nposteriori estimation of probabilistic program variables. By using a series of\ncode transformations, the evidence of any probabilistic program, and therefore\nof any graphical model, can be optimized with respect to an arbitrary subset of\nits sampled variables. To carry out this optimization, we develop the first\nBayesian optimization package to directly exploit the source code of its\ntarget, leading to innovations in problem-independent hyperpriors, unbounded\noptimization, and implicit constraint satisfaction; delivering significant\nperformance improvements over prominent existing packages. We present\napplications of our method to a number of tasks including engineering design\nand parameter optimization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 20:49:29 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Rainforth", "Tom", ""], ["Le", "Tuan Anh", ""], ["van de Meent", "Jan-Willem", ""], ["Osborne", "Michael A.", ""], ["Wood", "Frank", ""]]}, {"id": "1707.04327", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Human-Level Intelligence or Animal-Like Abilities?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision systems of the eagle and the snake outperform everything that we\ncan make in the laboratory, but snakes and eagles cannot build an eyeglass or a\ntelescope or a microscope. (Judea Pearl)\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 21:17:14 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1707.04347", "submitter": "Lin Chen", "authors": "Lin Chen, Moran Feldman, Amin Karbasi", "title": "Weakly Submodular Maximization Beyond Cardinality Constraints: Does\n  Randomization Help Greedy?", "comments": "Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are a broad class of set functions, which naturally\narise in diverse areas. Many algorithms have been suggested for the\nmaximization of these functions. Unfortunately, once the function deviates from\nsubmodularity, the known algorithms may perform arbitrarily poorly. Amending\nthis issue, by obtaining approximation results for set functions generalizing\nsubmodular functions, has been the focus of recent works.\n  One such class, known as weakly submodular functions, has received a lot of\nattention. A key result proved by Das and Kempe (2011) showed that the\napproximation ratio of the greedy algorithm for weakly submodular maximization\nsubject to a cardinality constraint degrades smoothly with the distance from\nsubmodularity. However, no results have been obtained for maximization subject\nto constraints beyond cardinality. In particular, it is not known whether the\ngreedy algorithm achieves any non-trivial approximation ratio for such\nconstraints.\n  In this paper, we prove that a randomized version of the greedy algorithm\n(previously used by Buchbinder et al. (2014) for a different problem) achieves\nan approximation ratio of $(1 + 1/\\gamma)^{-2}$ for the maximization of a\nweakly submodular function subject to a general matroid constraint, where\n$\\gamma$ is a parameter measuring the distance of the function from\nsubmodularity. Moreover, we also experimentally compare the performance of this\nversion of the greedy algorithm on real world problems against natural\nbenchmarks, and show that the algorithm we study performs well also in\npractice. To the best of our knowledge, this is the first algorithm with a\nnon-trivial approximation guarantee for maximizing a weakly submodular function\nsubject to a constraint other than the simple cardinality constraint. In\nparticular, it is the first algorithm with such a guarantee for the important\nand broad class of matroid constraints.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 22:48:43 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Chen", "Lin", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "1707.04352", "submitter": "Vasant Honavar", "authors": "Gregory D. Hager, Randal Bryant, Eric Horvitz, Maja Mataric, and\n  Vasant Honavar", "title": "Advances in Artificial Intelligence Require Progress Across all of\n  Computer Science", "comments": "7 pages, Computing Community Consortium White Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Artificial Intelligence require progress across all of computer\nscience.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 23:11:18 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Hager", "Gregory D.", ""], ["Bryant", "Randal", ""], ["Horvitz", "Eric", ""], ["Mataric", "Maja", ""], ["Honavar", "Vasant", ""]]}, {"id": "1707.04373", "submitter": "Yi Liu", "authors": "Yi Liu and Liang He and Yao Tian and Zhuzi Chen and Jia Liu and\n  Michael T. Johnson", "title": "Comparison of Multiple Features and Modeling Methods for Text-dependent\n  Speaker Verification", "comments": "The 2017 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-dependent speaker verification is becoming popular in the speaker\nrecognition society. However, the conventional i-vector framework which has\nbeen successful for speaker identification and other similar tasks works\nrelatively poorly in this task. Researchers have proposed several new methods\nto improve performance, but it is still unclear that which model is the best\nchoice, especially when the pass-phrases are prompted during enrollment and\ntest. In this paper, we introduce four modeling methods and compare their\nperformance on the newly published RedDots dataset. To further explore the\ninfluence of different frame alignments, Viterbi and forward-backward\nalgorithms are both used in the HMM-based models. Several bottleneck features\nare also investigated. Our experiments show that, by explicitly modeling the\nlexical content, the HMM-based modeling achieves good results in the\nfixed-phrase condition. In the prompted-phrase condition, GMM-HMM and\ni-vector/HMM are not as successful. In both conditions, the forward-backward\nalgorithm brings more benefits to the i-vector/HMM system. Additionally, we\nalso find that even though bottleneck features perform well for\ntext-independent speaker verification, they do not outperform MFCCs on the most\nchallenging Imposter-Correct trials on RedDots.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 02:44:07 GMT"}, {"version": "v2", "created": "Sat, 9 Sep 2017 07:59:07 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Liu", "Yi", ""], ["He", "Liang", ""], ["Tian", "Yao", ""], ["Chen", "Zhuzi", ""], ["Liu", "Jia", ""], ["Johnson", "Michael T.", ""]]}, {"id": "1707.04402", "submitter": "Gregory Palmer", "authors": "Gregory Palmer, Karl Tuyls, Daan Bloembergen, Rahul Savani", "title": "Lenient Multi-Agent Deep Reinforcement Learning", "comments": "9 pages, 6 figures, AAMAS2018 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the success of single agent deep reinforcement learning (DRL) in\nrecent years can be attributed to the use of experience replay memories (ERM),\nwhich allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\nstored state transitions. However, care is required when using ERMs for\nmulti-agent deep reinforcement learning (MA-DRL), as stored transitions can\nbecome outdated because agents update their policies in parallel [11]. In this\nwork we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\ndecaying temperature values that control the amount of leniency applied towards\nnegative policy updates that are sampled from the ERM. This introduces optimism\nin the value-function update, and has been shown to facilitate cooperation in\ntabular fully-cooperative multi-agent reinforcement learning problems. We\nevaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\n(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\nthat uses average reward learning near terminal states. Evaluations take place\nin extended variations of the Coordinated Multi-Agent Object Transportation\nProblem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\nrewards. We find that LDQN agents are more likely to converge to the optimal\npolicy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\nagents.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 07:33:20 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 09:36:29 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Palmer", "Gregory", ""], ["Tuyls", "Karl", ""], ["Bloembergen", "Daan", ""], ["Savani", "Rahul", ""]]}, {"id": "1707.04489", "submitter": "Tomoki Nishi", "authors": "Tomoki Nishi and Prashant Doshi and Danil Prokhorov", "title": "Freeway Merging in Congested Traffic based on Multipolicy Decision\n  Making with Passive Actor Critic", "comments": "6 pages, 5 figures. ICML Workshop on Machine Learning for Autonomous\n  Vehicles", "journal-ref": null, "doi": "10.1109/TIV.2019.2904417", "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freeway merging in congested traffic is a significant challenge toward fully\nautomated driving. Merging vehicles need to decide not only how to merge into a\nspot, but also where to merge. We present a method for the freeway merging\nbased on multi-policy decision making with a reinforcement learning method\ncalled {\\em passive actor-critic} (pAC), which learns with less knowledge of\nthe system and without active exploration. The method selects a merging spot\ncandidate by using the state value learned with pAC. We evaluate our method\nusing real traffic data. Our experiments show that pAC achieves 92\\% success\nrate to merge into a freeway, which is comparable to human decision making.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 12:47:37 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Nishi", "Tomoki", ""], ["Doshi", "Prashant", ""], ["Prokhorov", "Danil", ""]]}, {"id": "1707.04506", "submitter": "Hossein Sangrody", "authors": "Ahmad Shokrollahi, Hossein Sangrody, Mahdi Motalleb, Mandana\n  Rezaeiahari, Elham Foruzan, Fattah Hassanzadeh", "title": "Reliability Assessment of Distribution System Using Fuzzy Logic for\n  Modelling of Transformer and Line Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability assessment of distribution system, based on historical data and\nprobabilistic methods, leads to an unreliable estimation of reliability indices\nsince the data for the distribution components are usually inaccurate or\nunavailable. Fuzzy logic is an efficient method to deal with the uncertainty in\nreliability inputs. In this paper, the ENS index along with other commonly used\nindices in reliability assessment are evaluated for the distribution system\nusing fuzzy logic. Accordingly, the influential variables on the failure rate\nand outage duration time of the distribution components, which are natural or\nhuman-made, are explained using proposed fuzzy membership functions. The\nreliability indices are calculated and compared for different cases of the\nsystem operations by simulation on the IEEE RBTS Bus 2. The results of\nsimulation show how utilities can significantly improve the reliability of\ntheir distribution system by considering the risk of the influential variables.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 18:39:37 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Shokrollahi", "Ahmad", ""], ["Sangrody", "Hossein", ""], ["Motalleb", "Mahdi", ""], ["Rezaeiahari", "Mandana", ""], ["Foruzan", "Elham", ""], ["Hassanzadeh", "Fattah", ""]]}, {"id": "1707.04584", "submitter": "Mieczys{\\l}aw K{\\l}opotek", "authors": "Mieczys{\\l}aw A. K{\\l}opotek", "title": "Fast Restricted Causal Inference", "comments": "1995 internal report. arXiv admin note: substantial text overlap with\n  arXiv:1705.10308, arXiv:1706.10117; text overlap with arXiv:1707.03881", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden variables are well known sources of disturbance when recovering belief\nnetworks from data based only on measurable variables. Hence models assuming\nexistence of hidden variables are under development.\n  This paper presents a new algorithm \"accelerating\" the known CI algorithm of\nSpirtes, Glymour and Scheines {Spirtes:93}. We prove that this algorithm does\nnot produces (conditional) independencies not present in the data if\nstatistical independence test is reliable.\n  This result is to be considered as non-trivial since e.g. the same claim\nfails to be true for FCI algorithm, another \"accelerator\" of CI, developed in\n{Spirtes:93}.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 18:11:40 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["K\u0142opotek", "Mieczys\u0142aw A.", ""]]}, {"id": "1707.04588", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen and Fran\\c{c}ois Pachet", "title": "GLSR-VAE: Geodesic Latent Space Regularization for Variational\n  AutoEncoder Architectures", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VAEs (Variational AutoEncoders) have proved to be powerful in the context of\ndensity modeling and have been used in a variety of contexts for creative\npurposes. In many settings, the data we model possesses continuous attributes\nthat we would like to take into account at generation time. We propose in this\npaper GLSR-VAE, a Geodesic Latent Space Regularization for the Variational\nAutoEncoder architecture and its generalizations which allows a fine control on\nthe embedding of the data into the latent space. When augmenting the VAE loss\nwith this regularization, changes in the learned latent space reflects changes\nof the attributes of the data. This deeper understanding of the VAE latent\nspace structure offers the possibility to modulate the attributes of the\ngenerated data in a continuous way. We demonstrate its efficiency on a\nmonophonic music generation task where we manage to generate variations of\ndiscrete sequences in an intended and playful way.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 12:28:25 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""], ["Pachet", "Fran\u00e7ois", ""]]}, {"id": "1707.04679", "submitter": "Abhisek Kundu", "authors": "Abhisek Kundu, Kunal Banerjee, Naveen Mellempudi, Dheevatsa Mudigere,\n  Dipankar Das, Bharat Kaul, Pradeep Dubey", "title": "Ternary Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sub-8-bit representation of DNNs incur some discernible loss of accuracy\ndespite rigorous (re)training at low-precision. Such loss of accuracy\nessentially makes them equivalent to a much shallower counterpart, diminishing\nthe power of being deep networks. To address this problem of accuracy drop we\nintroduce the notion of \\textit{residual networks} where we add more\nlow-precision edges to sensitive branches of the sub-8-bit network to\ncompensate for the lost accuracy. Further, we present a perturbation theory to\nidentify such sensitive edges. Aided by such an elegant trade-off between\naccuracy and compute, the 8-2 model (8-bit activations, ternary weights),\nenhanced by ternary residual edges, turns out to be sophisticated enough to\nachieve very high accuracy ($\\sim 1\\%$ drop from our FP-32 baseline), despite\n$\\sim 1.6\\times$ reduction in model size, $\\sim 26\\times$ reduction in number\nof multiplications, and potentially $\\sim 2\\times$ power-performance gain\ncomparing to 8-8 representation, on the state-of-the-art deep network\nResNet-101 pre-trained on ImageNet dataset. Moreover, depending on the varying\naccuracy requirements in a dynamic environment, the deployed low-precision\nmodel can be upgraded/downgraded on-the-fly by partially enabling/disabling\nresidual connections. For example, disabling the least important residual\nconnections in the above enhanced network, the accuracy drop is $\\sim 2\\%$\n(from FP32), despite $\\sim 1.9\\times$ reduction in model size, $\\sim 32\\times$\nreduction in number of multiplications, and potentially $\\sim 2.3\\times$\npower-performance gain comparing to 8-8 representation. Finally, all the\nternary connections are sparse in nature, and the ternary residual conversion\ncan be done in a resource-constraint setting with no low-precision\n(re)training.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 02:36:28 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 05:32:41 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Kundu", "Abhisek", ""], ["Banerjee", "Kunal", ""], ["Mellempudi", "Naveen", ""], ["Mudigere", "Dheevatsa", ""], ["Das", "Dipankar", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1707.04775", "submitter": "Tathagata Chakraborti", "authors": "Tathagata Chakraborti, Subbarao Kambhampati, Matthias Scheutz, Yu\n  Zhang", "title": "AI Challenges in Human-Robot Cognitive Teaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many anticipated roles for robots in the future is that of being a\nhuman teammate. Aside from all the technological hurdles that have to be\novercome with respect to hardware and control to make robots fit to work with\nhumans, the added complication here is that humans have many conscious and\nsubconscious expectations of their teammates - indeed, we argue that teaming is\nmostly a cognitive rather than physical coordination activity. This introduces\nnew challenges for the AI and robotics community and requires fundamental\nchanges to the traditional approach to the design of autonomy. With this in\nmind, we propose an update to the classical view of the intelligent agent\narchitecture, highlighting the requirements for mental modeling of the human in\nthe deliberative process of the autonomous agent. In this article, we outline\nbriefly the recent efforts of ours, and others in the community, towards\ndeveloping cognitive teammates along these guidelines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 18:42:16 GMT"}, {"version": "v2", "created": "Sun, 13 Aug 2017 00:14:32 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Chakraborti", "Tathagata", ""], ["Kambhampati", "Subbarao", ""], ["Scheutz", "Matthias", ""], ["Zhang", "Yu", ""]]}, {"id": "1707.04780", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H.\n  Nguyen, Madeleine Gibescu, Antonio Liotta", "title": "Scalable Training of Artificial Neural Networks with Adaptive Sparse\n  Connectivity inspired by Network Science", "comments": "18 pages", "journal-ref": "Nature Communications, 2018", "doi": "10.1038/s41467-018-04316-3", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the success of deep learning in various domains, artificial neural\nnetworks are currently among the most used artificial intelligence methods.\nTaking inspiration from the network properties of biological neural networks\n(e.g. sparsity, scale-freeness), we argue that (contrary to general practice)\nartificial neural networks, too, should not have fully-connected layers. Here\nwe propose sparse evolutionary training of artificial neural networks, an\nalgorithm which evolves an initial sparse topology (Erd\\H{o}s-R\\'enyi random\ngraph) of two consecutive layers of neurons into a scale-free topology, during\nlearning. Our method replaces artificial neural networks fully-connected layers\nwith sparse ones before training, reducing quadratically the number of\nparameters, with no decrease in accuracy. We demonstrate our claims on\nrestricted Boltzmann machines, multi-layer perceptrons, and convolutional\nneural networks for unsupervised and supervised learning on 15 datasets. Our\napproach has the potential to enable artificial neural networks to scale up\nbeyond what is currently possible.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 19:46:25 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 12:55:55 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Mocanu", "Elena", ""], ["Stone", "Peter", ""], ["Nguyen", "Phuong H.", ""], ["Gibescu", "Madeleine", ""], ["Liotta", "Antonio", ""]]}, {"id": "1707.04822", "submitter": "Adams Wei Yu", "authors": "Adams Wei Yu, Lei Huang, Qihang Lin, Ruslan Salakhutdinov, Jaime\n  Carbonell", "title": "Block-Normalized Gradient Method: An Empirical Study for Training Deep\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generic and simple strategy for utilizing\nstochastic gradient information in optimization. The technique essentially\ncontains two consecutive steps in each iteration: 1) computing and normalizing\neach block (layer) of the mini-batch stochastic gradient; 2) selecting\nappropriate step size to update the decision variable (parameter) towards the\nnegative of the block-normalized gradient. We conduct extensive empirical\nstudies on various non-convex neural network optimization problems, including\nmulti-layer perceptron, convolution neural networks and recurrent neural\nnetworks. The results indicate the block-normalized gradient can help\naccelerate the training of neural networks. In particular, we observe that the\nnormalized gradient methods having constant step size with occasionally decay,\nsuch as SGD with momentum, have better performance in the deep convolution\nneural networks, while those with adaptive step sizes, such as Adam, perform\nbetter in recurrent neural networks. Besides, we also observe this line of\nmethods can lead to solutions with better generalization properties, which is\nconfirmed by the performance improvement over strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 04:47:22 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 09:45:02 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yu", "Adams Wei", ""], ["Huang", "Lei", ""], ["Lin", "Qihang", ""], ["Salakhutdinov", "Ruslan", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1707.04828", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Sheng-Chi Yang, Pi-Hsia Hung, Su-Wei\n  Lin, Nan Shuo, Naoyuki Kubota, Chun-Hsun Chou, Ping-Chiang Chou, and\n  Chia-Hsiu Kao", "title": "FML-based Dynamic Assessment Agent for Human-Machine Cooperative System\n  on Game of Go", "comments": "26 pages, 14 figures", "journal-ref": null, "doi": "10.1142/S0218488517500295", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate the application of Fuzzy Markup Language (FML)\nto construct an FML-based Dynamic Assessment Agent (FDAA), and we present an\nFML-based Human-Machine Cooperative System (FHMCS) for the game of Go. The\nproposed FDAA comprises an intelligent decision-making and learning mechanism,\nan intelligent game bot, a proximal development agent, and an intelligent\nagent. The intelligent game bot is based on the open-source code of Facebook\nDarkforest, and it features a representational state transfer application\nprogramming interface mechanism. The proximal development agent contains a\ndynamic assessment mechanism, a GoSocket mechanism, and an FML engine with a\nfuzzy knowledge base and rule base. The intelligent agent contains a GoSocket\nengine and a summarization agent that is based on the estimated win rate,\nreal-time simulation number, and matching degree of predicted moves.\nAdditionally, the FML for player performance evaluation and linguistic\ndescriptions for game results commentary are presented. We experimentally\nverify and validate the performance of the FDAA and variants of the FHMCS by\ntesting five games in 2016 and 60 games of Google Master Go, a new version of\nthe AlphaGo program, in January 2017. The experimental results demonstrate that\nthe proposed FDAA can work effectively for Go applications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 06:20:19 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Yang", "Sheng-Chi", ""], ["Hung", "Pi-Hsia", ""], ["Lin", "Su-Wei", ""], ["Shuo", "Nan", ""], ["Kubota", "Naoyuki", ""], ["Chou", "Chun-Hsun", ""], ["Chou", "Ping-Chiang", ""], ["Kao", "Chia-Hsiu", ""]]}, {"id": "1707.04873", "submitter": "Han Cai", "authors": "Han Cai, Tianyao Chen, Weinan Zhang, Yong Yu, Jun Wang", "title": "Efficient Architecture Search by Network Transformation", "comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18). We change the title from \"Reinforcement Learning for Architecture\n  Search by Network Transformation\" to \"Efficient Architecture Search by\n  Network Transformation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Techniques for automatically designing deep neural network architectures such\nas reinforcement learning based approaches have recently shown promising\nresults. However, their success is based on vast computational resources (e.g.\nhundreds of GPUs), making them difficult to be widely used. A noticeable\nlimitation is that they still design and train each network from scratch during\nthe exploration of the architecture space, which is highly inefficient. In this\npaper, we propose a new framework toward efficient architecture search by\nexploring the architecture space based on the current network and reusing its\nweights. We employ a reinforcement learning agent as the meta-controller, whose\naction is to grow the network depth or layer width with function-preserving\ntransformations. As such, the previously validated networks can be reused for\nfurther exploration, thus saves a large amount of computational cost. We apply\nour method to explore the architecture space of the plain convolutional neural\nnetworks (no skip-connections, branching etc.) on image benchmark datasets\n(CIFAR-10, SVHN) with restricted computational resources (5 GPUs). Our method\ncan design highly competitive networks that outperform existing networks using\nthe same design scheme. On CIFAR-10, our model without skip-connections\nachieves 4.23\\% test error rate, exceeding a vast majority of modern\narchitectures and approaching DenseNet. Furthermore, by applying our method to\nexplore the DenseNet architecture space, we are able to achieve more accurate\nnetworks with fewer parameters.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 12:39:02 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 08:38:04 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Cai", "Han", ""], ["Chen", "Tianyao", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1707.04903", "submitter": "Antoine Cornu\\'ejols", "authors": "Antoine Cornu\\'ejols, Andr\\'ee Tiberghien and G\\'erard Collet", "title": "Tunnel Effects in Cognition: A new Mechanism for Scientific Discovery\n  and Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is quite exceptional, if it ever happens, that a new conceptual domain be\nbuilt from scratch. Usually, it is developed and mastered in interaction, both\npositive and negative, with other more operational existing domains. Few\nreasoning mechanisms have been proposed to account for the interplay of\ndifferent conceptual domains and the transfer of information from one to\nanother. Analogical reasoning is one, blending is another. This paper presents\na new mechanism, called 'tunnel effect', that may explain, in part, how\nscientists and students reason while constructing a new conceptual domain. One\nexperimental study with high school students and analyses from the history of\nscience, particularly about the birth of classical thermodynamics, provide\nevidence and illustrate this mechanism. The knowledge organization, processes\nand conditions for its appearance are detailed and put into the perspective of\na computational model. Specifically, we put forward the hypothesis that two\nlevels of knowledge, notional and conceptual, cooperate in the scientific\ndiscovery process when a new conceptual domain is being built. The type of\nconceptual learning that can be associated with tunnel effect is discussed and\na thorough comparison is made with analogical reasoning in order to underline\nthe main features of the new proposed mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 16:05:21 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Cornu\u00e9jols", "Antoine", ""], ["Tiberghien", "Andr\u00e9e", ""], ["Collet", "G\u00e9rard", ""]]}, {"id": "1707.04943", "submitter": "Michael Mayo Dr", "authors": "Michael Mayo and Eibe Frank", "title": "Improving Naive Bayes for Regression with Optimised Artificial Surrogate\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we evolve better training data for machine learning algorithms? To\ninvestigate this question we use population-based optimisation algorithms to\ngenerate artificial surrogate training data for naive Bayes for regression. We\ndemonstrate that the generalisation performance of naive Bayes for regression\nmodels is enhanced by training them on the artificial data as opposed to the\nreal data. These results are important for two reasons. Firstly, naive Bayes\nmodels are simple and interpretable but frequently underperform compared to\nmore complex \"black box\" models, and therefore new methods of enhancing\naccuracy are called for. Secondly, the idea of using the real training data\nindirectly in the construction of the artificial training data, as opposed to\ndirectly for model training, is a novel twist on the usual machine learning\nparadigm.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 20:53:06 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 19:43:09 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 21:04:24 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Mayo", "Michael", ""], ["Frank", "Eibe", ""]]}, {"id": "1707.04957", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Elmer Salazar, Kyle Marple, Gopal Gupta, Lakshman Tamil,\n  Sandeep Das, Alpesh Amin", "title": "Improving Adherence to Heart Failure Management Guidelines via Abductive\n  Reasoning", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1, 2017\n  15 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Management of chronic diseases such as heart failure (HF) is a major public\nhealth problem. A standard approach to managing chronic diseases by medical\ncommunity is to have a committee of experts develop guidelines that all\nphysicians should follow. Due to their complexity, these guidelines are\ndifficult to implement and are adopted slowly by the medical community at\nlarge. We have developed a physician advisory system that codes the entire set\nof clinical practice guidelines for managing HF using answer set\nprogramming(ASP). In this paper we show how abductive reasoning can be deployed\nto find missing symptoms and conditions that the patient must exhibit in order\nfor a treatment prescribed by a physician to work effectively. Thus, if a\nphysician does not make an appropriate recommendation or makes a non-adherent\nrecommendation, our system will advise the physician about symptoms and\nconditions that must be in effect for that recommendation to apply. It is under\nconsideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 22:55:53 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Chen", "Zhuo", ""], ["Salazar", "Elmer", ""], ["Marple", "Kyle", ""], ["Gupta", "Gopal", ""], ["Tamil", "Lakshman", ""], ["Das", "Sandeep", ""], ["Amin", "Alpesh", ""]]}, {"id": "1707.04987", "submitter": "Uma Roy", "authors": "Uma Roy, Ashwath Thirmulai, Joe Zurier", "title": "Online Multi-Armed Bandit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel variant of the multi-armed bandit problem, in which\nbandits are streamed one at a time to the player, and at each point, the player\ncan either choose to pull the current bandit or move on to the next bandit.\nOnce a player has moved on from a bandit, they may never visit it again, which\nis a crucial difference between our problem and classic multi-armed bandit\nproblems. In this online context, we study Bernoulli bandits (bandits with\npayout Ber($p_i$) for some underlying mean $p_i$) with underlying means drawn\ni.i.d. from various distributions, including the uniform distribution, and in\ngeneral, all distributions that have a CDF satisfying certain differentiability\nconditions near zero. In all cases, we suggest several strategies and\ninvestigate their expected performance. Furthermore, we bound the performance\nof any optimal strategy and show that the strategies we have suggested are\nindeed optimal up to a constant factor. We also investigate the case where the\ndistribution from which the underlying means are drawn is not known ahead of\ntime. We again, are able to suggest algorithms that are optimal up to a\nconstant factor for this case, given certain mild conditions on the universe of\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 02:55:00 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Roy", "Uma", ""], ["Thirmulai", "Ashwath", ""], ["Zurier", "Joe", ""]]}, {"id": "1707.05001", "submitter": "Zhaoyi Pei Mr", "authors": "Zhaoyi Pei, Songhao Piao, Mohammed Ei Souidi", "title": "Coalition formation for Multi-agent Pursuit based on Neural Network and\n  AGRMF Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach for coalition formation of multi-agent pursuit based on neural\nnetwork and AGRMF model is proposed.This paper constructs a novel neural work\ncalled AGRMF-ANN which consists of feature extraction part and group generation\npart. On one hand,The convolutional layers of feature extraction part can\nabstract the features of agent group role membership function(AGRMF) for all of\nthe groups,on the other hand,those features will be fed to the group generation\npart based on self-organizing map(SOM) layer which is used to group the\npursuers with similar features in the same group. Besides, we also come up the\ngroup attractiveness function(GAF) to evaluate the quality of groups and the\npursuers contribution in order to adjust the main ability indicators of AGRMF\nand other weight of all neural network. The simulation experiment showed that\nthis proposal can improve the effectiveness of coalition formation for\nmulti-agent pursuit and ability to adopt pursuit-evasion problem with the scale\nof pursuer team growing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 04:41:25 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Pei", "Zhaoyi", ""], ["Piao", "Songhao", ""], ["Souidi", "Mohammed Ei", ""]]}, {"id": "1707.05005", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan,\n  Lihui Chen, Yang Liu and Shantanu Jaiswal", "title": "graph2vec: Learning Distributed Representations of Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CR cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on representation learning for graph structured data\npredominantly focus on learning distributed representations of graph\nsubstructures such as nodes and subgraphs. However, many graph analytics tasks\nsuch as graph classification and clustering require representing entire graphs\nas fixed length feature vectors. While the aforementioned approaches are\nnaturally unequipped to learn such representations, graph kernels remain as the\nmost effective way of obtaining them. However, these graph kernels use\nhandcrafted features (e.g., shortest paths, graphlets, etc.) and hence are\nhampered by problems such as poor generalization. To address this limitation,\nin this work, we propose a neural embedding framework named graph2vec to learn\ndata-driven distributed representations of arbitrary sized graphs. graph2vec's\nembeddings are learnt in an unsupervised manner and are task agnostic. Hence,\nthey could be used for any downstream task such as graph classification,\nclustering and even seeding supervised representation learning approaches. Our\nexperiments on several benchmark and large real-world datasets show that\ngraph2vec achieves significant improvements in classification and clustering\naccuracies over substructure representation learning approaches and are\ncompetitive with state-of-the-art graph kernels.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 05:09:03 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Chandramohan", "Mahinthan", ""], ["Venkatesan", "Rajasekar", ""], ["Chen", "Lihui", ""], ["Liu", "Yang", ""], ["Jaiswal", "Shantanu", ""]]}, {"id": "1707.05101", "submitter": "Alexey Drutsa", "authors": "Alexey Drutsa", "title": "On consistency of optimal pricing algorithms in repeated posted-price\n  auctions with strategic buyer", "comments": "25 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study revenue optimization learning algorithms for repeated posted-price\nauctions where a seller interacts with a single strategic buyer that holds a\nfixed private valuation for a good and seeks to maximize his cumulative\ndiscounted surplus. For this setting, first, we propose a novel algorithm that\nnever decreases offered prices and has a tight strategic regret bound in\n$\\Theta(\\log\\log T)$ under some mild assumptions on the buyer surplus\ndiscounting. This result closes the open research question on the existence of\na no-regret horizon-independent weakly consistent pricing. The proposed\nalgorithm is inspired by our observation that a double decrease of offered\nprices in a weakly consistent algorithm is enough to cause a linear regret.\nThis motivates us to construct a novel transformation that maps a\nright-consistent algorithm to a weakly consistent one that never decreases\noffered prices.\n  Second, we outperform the previously known strategic regret upper bound of\nthe algorithm PRRFES, where the improvement is achieved by means of a finer\nconstant factor $C$ of the principal term $C\\log\\log T$ in this upper bound.\nFinally, we generalize results on strategic regret previously known for\ngeometric discounting of the buyer's surplus to discounting of other types,\nnamely: the optimality of the pricing PRRFES to the case of geometrically\nconcave decreasing discounting; and linear lower bound on the strategic regret\nof a wide range of horizon-independent weakly consistent algorithms to the case\nof arbitrary discounts.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 11:29:14 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 01:15:57 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Drutsa", "Alexey", ""]]}, {"id": "1707.05115", "submitter": "Anssi Yli-Jyr\\\"a", "authors": "Anssi Yli-Jyr\\\"a", "title": "The Power of Constraint Grammars Revisited", "comments": "9 pages, 4 figures", "journal-ref": "Proceedings of the NoDaLiDa 2017 Workshop on Constraint Grammar -\n  Methods, Tools and Applications, 22 May 2017, Gothenburg, Sweden. Pages 23-31", "doi": null, "report-no": null, "categories": "cs.FL cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential Constraint Grammar (SCG) (Karlsson, 1990) and its extensions have\nlacked clear connections to formal language theory. The purpose of this article\nis to lay a foundation for these connections by simplifying the definition of\nstrings processed by the grammar and by showing that Nonmonotonic SCG is\nundecidable and that derivations similar to the Generative Phonology exist. The\ncurrent investigations propose resource bounds that restrict the generative\npower of SCG to a subset of context sensitive languages and present a strong\nfinite-state condition for grammars as wholes. We show that a grammar is\nequivalent to a finite-state transducer if it is implemented with a Turing\nmachine that runs in o(n log n) time. This condition opens new finite-state\nhypotheses and avenues for deeper analysis of SCG instances in the way inspired\nby Finite-State Phonology.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 12:20:15 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Yli-Jyr\u00e4", "Anssi", ""]]}, {"id": "1707.05152", "submitter": "Ricardo Gon\\c{c}alves", "authors": "Ricardo Gon\\c{c}alves (1), Matthias Knorr (1), Jo\\~ao Leite (1),\n  Stefan Woltran (2) ((1) NOVA LINCS, Universidade Nova de Lisboa, Portugal,\n  (2) TU Wien, Austria)", "title": "When You Must Forget: beyond strong persistence when forgetting in\n  answer set programming", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1,\n  2017, 15 pages, LaTeX (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": "10.1017/S1471068417000382", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the myriad of desirable properties discussed in the context of\nforgetting in Answer Set Programming (ASP), strong persistence naturally\ncaptures its essence. Recently, it has been shown that it is not always\npossible to forget a set of atoms from a program while obeying this property,\nand a precise criterion regarding what can be forgotten has been presented,\naccompanied by a class of forgetting operators that return the correct result\nwhen forgetting is possible.\n  However, it is an open question what to do when we have to forget a set of\natoms, but cannot without violating this property. In this paper, we address\nthis issue and investigate three natural alternatives to forget when forgetting\nwithout violating strong persistence is not possible, which turn out to\ncorrespond to the different possible relaxations of the characterization of\nstrong persistence. Additionally, we discuss their preferable usage, shed light\non the relation between forgetting and notions of relativized equivalence\nestablished earlier in the context of ASP, and present a detailed study on\ntheir computational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 13:41:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Gon\u00e7alves", "Ricardo", ""], ["Knorr", "Matthias", ""], ["Leite", "Jo\u00e3o", ""], ["Woltran", "Stefan", ""]]}, {"id": "1707.05165", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Kai-Uwe K\\\"uhnberger", "title": "A Comprehensive Implementation of Conceptual Spaces", "comments": "Accepted at AIC 2017 (http://www.di.unito.it/~lieto/AIC2017/), final\n  paper available at http://ceur-ws.org/Vol-2090/. arXiv admin note:\n  substantial text overlap with arXiv:1707.02292, arXiv:1801.03929,\n  arXiv:1706.06366", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The highly influential framework of conceptual spaces provides a geometric\nway of representing knowledge. Instances are represented by points and concepts\nare represented by regions in a (potentially) high-dimensional space. Based on\nour recent formalization, we present a comprehensive implementation of the\nconceptual spaces framework that is not only capable of representing concepts\nwith inter-domain correlations, but that also offers a variety of operations on\nthese concepts.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 09:22:23 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 13:27:45 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 06:28:22 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bechberger", "Lucas", ""], ["K\u00fchnberger", "Kai-Uwe", ""]]}, {"id": "1707.05173", "submitter": "Owain Evans", "authors": "William Saunders, Girish Sastry, Andreas Stuhlmueller, Owain Evans", "title": "Trial without Error: Towards Safe Reinforcement Learning via Human\n  Intervention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems are increasingly applied to complex tasks that involve interaction\nwith humans. During training, such systems are potentially dangerous, as they\nhaven't yet learned to avoid actions that could cause serious harm. How can an\nAI system explore and learn without making a single mistake that harms humans\nor otherwise causes serious damage? For model-free reinforcement learning,\nhaving a human \"in the loop\" and ready to intervene is currently the only way\nto prevent all catastrophes. We formalize human intervention for RL and show\nhow to reduce the human labor required by training a supervised learner to\nimitate the human's intervention decisions. We evaluate this scheme on Atari\ngames, with a Deep RL agent being overseen by a human for four hours. When the\nclass of catastrophes is simple, we are able to prevent all catastrophes\nwithout affecting the agent's learning (whereas an RL baseline fails due to\ncatastrophic forgetting). However, this scheme is less successful when\ncatastrophes are more complex: it reduces but does not eliminate catastrophes\nand the supervised learner fails on adversarial examples found by the agent.\nExtrapolating to more challenging environments, we show that our implementation\nwould not scale (due to the infeasible amount of human labor required). We\noutline extensions of the scheme that are necessary if we are to train\nmodel-free agents without a single catastrophe.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:13:40 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Saunders", "William", ""], ["Sastry", "Girish", ""], ["Stuhlmueller", "Andreas", ""], ["Evans", "Owain", ""]]}, {"id": "1707.05176", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "Latent Relational Metric Learning via Memory-based Attention for\n  Collaborative Ranking", "comments": "WWW 2018", "journal-ref": null, "doi": "10.1145/3178876.3186154", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new neural architecture for collaborative ranking with\nimplicit feedback. Our model, LRML (\\textit{Latent Relational Metric Learning})\nis a novel metric learning approach for recommendation. More specifically,\ninstead of simple push-pull mechanisms between user and item pairs, we propose\nto learn latent relations that describe each user item interaction. This helps\nto alleviate the potential geometric inflexibility of existing metric learing\napproaches. This enables not only better performance but also a greater extent\nof modeling capability, allowing our model to scale to a larger number of\ninteractions. In order to do so, we employ a augmented memory module and learn\nto attend over these memory blocks to construct latent relations. The\nmemory-based attention module is controlled by the user-item interaction,\nmaking the learned relation vector specific to each user-item pair. Hence, this\ncan be interpreted as learning an exclusive and optimal relational translation\nfor each user-item interaction. The proposed architecture demonstrates the\nstate-of-the-art performance across multiple recommendation benchmarks. LRML\noutperforms other metric learning models by $6\\%-7.5\\%$ in terms of Hits@10 and\nnDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover,\nqualitative studies also demonstrate evidence that our proposed model is able\nto infer and encode explicit sentiment, temporal and attribute information\ndespite being only trained on implicit feedback. As such, this ascertains the\nability of LRML to uncover hidden relational structure within implicit\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:19:49 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 13:42:09 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 07:34:50 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1707.05224", "submitter": "Kumar Sankar Ray", "authors": "Kumar S. Ray, Anit Chakraborty, Sayandip Dutta", "title": "Detection, Recognition and Tracking of Moving Objects from Real-time\n  Video via Visual Vocabulary Model and Species Inspired PSO", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the basic problem of recognizing moving objects in\nvideo images using Visual Vocabulary model and Bag of Words and track our\nobject of interest in the subsequent video frames using species inspired PSO.\nInitially, the shadow free images are obtained by background modelling followed\nby foreground modeling to extract the blobs of our object of interest.\nSubsequently, we train a cubic SVM with human body datasets in accordance with\nour domain of interest for recognition and tracking. During training, using the\nprinciple of Bag of Words we extract necessary features of certain domains and\nobjects for classification. Subsequently, matching these feature sets with\nthose of the extracted object blobs that are obtained by subtracting the shadow\nfree background from the foreground, we detect successfully our object of\ninterest from the test domain. The performance of the classification by cubic\nSVM is satisfactorily represented by confusion matrix and ROC curve reflecting\nthe accuracy of each module. After classification, our object of interest is\ntracked in the test domain using species inspired PSO. By combining the\nadaptive learning tools with the efficient classification of description, we\nachieve optimum accuracy in recognition of the moving objects. We evaluate our\nalgorithm benchmark datasets: iLIDS, VIVID, Walking2, Woman. Comparative\nanalysis of our algorithm against the existing state-of-the-art trackers shows\nvery satisfactory and competitive results.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jun 2017 11:09:10 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Ray", "Kumar S.", ""], ["Chakraborty", "Anit", ""], ["Dutta", "Sayandip", ""]]}, {"id": "1707.05228", "submitter": "Kumar Sankar Ray", "authors": "Rajesh Misra, Kumar S. Ray", "title": "Object Tracking based on Quantum Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Computer Vision domain, moving Object Tracking considered as one of the\ntoughest problem.As there so many factors associated like illumination of\nlight, noise, occlusion, sudden start and stop of moving object, shading which\nmakes tracking even harder problem not only for dynamic background but also for\nstatic background.In this paper we present a new object tracking algorithm\nbased on Dominant points on tracked object using Quantum particle swarm\noptimization (QPSO) which is a new different version of PSO based on Quantum\ntheory. The novelty in our approach is that it can be successfully applicable\nin variable background as well as static background and application of quantum\nPSO makes the algorithm runs lot faster where other basic PSO algorithm failed\nto do so due to heavy computation.In our approach firstly dominants points of\ntracked objects detected, then a group of particles form a swarm are\ninitialized randomly over the image search space and then start searching the\ncurvature connected between two consecutive dominant points until they satisfy\nfitness criteria. Obviously it is a Multi-Swarm approach as there are multiple\ndominant points, as they moves, the curvature moves and the curvature movement\nis tracked by the swarm throughout the video and eventually when the swarm\nreaches optimal solution , a bounding box drawn based on particles final\nposition.Experimental results demonstrate this proposed QPSO based method work\nefficiently and effectively in visual object tracking in both dynamic and\nstatic environments and run time shows that it runs closely 90% faster than\nbasic PSO.in our approach we also apply parallelism using MatLab Parfor command\nto show how very less number of iteration and swarm size will enable us to\nsuccessfully track object.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 10:29:45 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Misra", "Rajesh", ""], ["Ray", "Kumar S.", ""]]}, {"id": "1707.05300", "submitter": "Carlos Florensa", "authors": "Carlos Florensa, David Held, Markus Wulfmeier, Michael Zhang, Pieter\n  Abbeel", "title": "Reverse Curriculum Generation for Reinforcement Learning", "comments": "Published at the 1st Conference on Robot Learning (CoRL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many relevant tasks require an agent to reach a certain state, or to\nmanipulate objects into a desired configuration. For example, we might want a\nrobot to align and assemble a gear onto an axle or insert and turn a key in a\nlock. These goal-oriented tasks present a considerable challenge for\nreinforcement learning, since their natural reward function is sparse and\nprohibitive amounts of exploration are required to reach the goal and receive\nsome learning signal. Past approaches tackle these problems by exploiting\nexpert demonstrations or by manually designing a task-specific reward shaping\nfunction to guide the learning agent. Instead, we propose a method to learn\nthese tasks without requiring any prior knowledge other than obtaining a single\nstate in which the task is achieved. The robot is trained in reverse, gradually\nlearning to reach the goal from a set of start states increasingly far from the\ngoal. Our method automatically generates a curriculum of start states that\nadapts to the agent's performance, leading to efficient training on\ngoal-oriented tasks. We demonstrate our approach on difficult simulated\nnavigation and fine-grained manipulation problems, not solvable by\nstate-of-the-art reinforcement learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 17:53:54 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 02:46:26 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 10:10:17 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Florensa", "Carlos", ""], ["Held", "David", ""], ["Wulfmeier", "Markus", ""], ["Zhang", "Michael", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1707.05308", "submitter": "Amit Sheth", "authors": "Amit Sheth, Sujan Perera, Sanjaya Wijeratne, Krishnaprasad\n  Thirunarayan", "title": "Knowledge will Propel Machine Understanding of Content: Extrapolating\n  from Current Examples", "comments": "Pre-print of the paper accepted at 2017 IEEE/WIC/ACM International\n  Conference on Web Intelligence (WI). arXiv admin note: substantial text\n  overlap with arXiv:1610.07708", "journal-ref": null, "doi": "10.1145/3106426.3109448", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has been a big success story during the AI resurgence. One\nparticular stand out success relates to learning from a massive amount of data.\nIn spite of early assertions of the unreasonable effectiveness of data, there\nis increasing recognition for utilizing knowledge whenever it is available or\ncan be created purposefully. In this paper, we discuss the indispensable role\nof knowledge for deeper understanding of content where (i) large amounts of\ntraining data are unavailable, (ii) the objects to be recognized are complex,\n(e.g., implicit entities and highly subjective content), and (iii) applications\nneed to use complementary or related data in multiple modalities/media. What\nbrings us to the cusp of rapid progress is our ability to (a) create relevant\nand reliable knowledge and (b) carefully exploit knowledge to enhance ML/NLP\ntechniques. Using diverse examples, we seek to foretell unprecedented progress\nin our ability for deeper understanding and exploitation of multimodal data and\ncontinued incorporation of knowledge in learning techniques.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 19:01:15 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Sheth", "Amit", ""], ["Perera", "Sujan", ""], ["Wijeratne", "Sanjaya", ""], ["Thirunarayan", "Krishnaprasad", ""]]}, {"id": "1707.05340", "submitter": "Meng Wang", "authors": "Meng Wang, Jiaheng Zhang, Jun Liu, Wei Hu, Sen Wang, Xue Li, Wenqiang\n  Liu", "title": "PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge\n  Graphs via Entity Linking", "comments": "9 pages,5 figures,accepted by ISWC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records contain multi-format electronic medical data that\nconsist of an abundance of medical knowledge. Facing with patient's symptoms,\nexperienced caregivers make right medical decisions based on their professional\nknowledge that accurately grasps relationships between symptoms, diagnosis and\ncorresponding treatments. In this paper, we aim to capture these relationships\nby constructing a large and high-quality heterogenous graph linking patients,\ndiseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework\nto extract important medical entities from MIMIC-III (Medical Information Mart\nfor Intensive Care III) and automatically link them with the existing\nbiomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD\ngraph presented in this paper is accessible on the Web via the SPARQL endpoint,\nand provides a pathway for medical discovery and applications, such as\neffective treatment recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 18:04:27 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 14:36:18 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Wang", "Meng", ""], ["Zhang", "Jiaheng", ""], ["Liu", "Jun", ""], ["Hu", "Wei", ""], ["Wang", "Sen", ""], ["Li", "Xue", ""], ["Liu", "Wenqiang", ""]]}, {"id": "1707.05373", "submitter": "Moustapha Cisse", "authors": "Moustapha Cisse, Yossi Adi, Natalia Neverova and Joseph Keshet", "title": "Houdini: Fooling Deep Structured Prediction Models", "comments": "12 pages, 8 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating adversarial examples is a critical step for evaluating and\nimproving the robustness of learning machines. So far, most existing methods\nonly work for classification and are not designed to alter the true performance\nmeasure of the problem at hand. We introduce a novel flexible approach named\nHoudini for generating adversarial examples specifically tailored for the final\nperformance measure of the task considered, be it combinatorial and\nnon-decomposable. We successfully apply Houdini to a range of applications such\nas speech recognition, pose estimation and semantic segmentation. In all cases,\nthe attacks based on Houdini achieve higher success rate than those based on\nthe traditional surrogates used to train the models while using a less\nperceptible adversarial perturbation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 19:11:08 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Cisse", "Moustapha", ""], ["Adi", "Yossi", ""], ["Neverova", "Natalia", ""], ["Keshet", "Joseph", ""]]}, {"id": "1707.05390", "submitter": "William Cohen", "authors": "William W. Cohen, Fan Yang, Kathryn Rivard Mazaitis", "title": "TensorLog: Deep Learning Meets Probabilistic DBs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of a probabilistic first-order logic called\nTensorLog, in which classes of logical queries are compiled into differentiable\nfunctions in a neural-network infrastructure such as Tensorflow or Theano. This\nleads to a close integration of probabilistic logical reasoning with\ndeep-learning infrastructure: in particular, it enables high-performance deep\nlearning frameworks to be used for tuning the parameters of a probabilistic\nlogic. Experimental results show that TensorLog scales to problems involving\nhundreds of thousands of knowledge-base triples and tens of thousands of\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 20:37:08 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Cohen", "William W.", ""], ["Yang", "Fan", ""], ["Mazaitis", "Kathryn Rivard", ""]]}, {"id": "1707.05493", "submitter": "Pradipta Ghosh", "authors": "Pradipta Ghosh, Jason A. Tran and Bhaskar Krishnamachari", "title": "ARREST: A RSSI Based Approach for Mobile Sensing and Tracking of a\n  Moving Object", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Autonomous Rssi based RElative poSitioning and Tracking (ARREST),\na new robotic sensing system for tracking and following a moving, RF-emitting\nobject, which we refer to as the Leader, solely based on signal strength\ninformation. This kind of system can expand the horizon of autonomous mobile\ntracking and distributed robotics into many scenarios with limited visibility\nsuch as nighttime, dense forests, and cluttered environments. Our proposed\ntracking agent, which we refer to as the TrackBot, uses a single rotating,\noff-the-shelf, directional antenna, novel angle and relative speed estimation\nalgorithms, and Kalman filtering to continually estimate the relative position\nof the Leader with decimeter level accuracy (which is comparable to a\nstate-of-the-art multiple access point based RF-localization system) and the\nrelative speed of the Leader with accuracy on the order of 1 m/s. The TrackBot\nfeeds the relative position and speed estimates into a Linear Quadratic\nGaussian (LQG) controller to generate a set of control outputs to control the\norientation and the movement of the TrackBot. We perform an extensive set of\nreal world experiments with a full-fledged prototype to demonstrate that the\nTrackBot is able to stay within 5m of the Leader with: (1) more than $99\\%$\nprobability in line of sight scenarios, and (2) more than $70\\%$ probability in\nno line of sight scenarios, when it moves 1.8X faster than the Leader. For\nground truth estimation in real world experiments, we also developed an\nintegrated TDoA based distance and angle estimation system with centimeter\nlevel localization accuracy in line of sight scenarios. While providing a first\nproof of concept, our work opens the door to future research aimed at further\nimprovements of autonomous RF-based tracking.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 06:37:43 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 23:58:34 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Ghosh", "Pradipta", ""], ["Tran", "Jason A.", ""], ["Krishnamachari", "Bhaskar", ""]]}, {"id": "1707.05499", "submitter": "Anirban Laha", "authors": "Disha Shrivastava, Saneem Ahmed CG, Anirban Laha, Karthik\n  Sankaranarayanan", "title": "A Machine Learning Approach for Evaluating Creative Artifacts", "comments": "Accepted at SIGKDD Workshop on Machine Learning for Creativity\n  (ML4Creativity), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work has been done in understanding human creativity and defining\nmeasures to evaluate creativity. This is necessary mainly for the reason of\nhaving an objective and automatic way of quantifying creative artifacts. In\nthis work, we propose a regression-based learning framework which takes into\naccount quantitatively the essential criteria for creativity like novelty,\ninfluence, value and unexpectedness. As it is often the case with most creative\ndomains, there is no clear ground truth available for creativity. Our proposed\nlearning framework is applicable to all creative domains; yet we evaluate it on\na dataset of movies created from IMDb and Rotten Tomatoes due to availability\nof audience and critic scores, which can be used as proxy ground truth labels\nfor creativity. We report promising results and observations from our\nexperiments in the following ways : 1) Correlation of creative criteria with\ncritic scores, 2) Improvement in movie rating prediction with inclusion of\nvarious creative criteria, and 3) Identification of creative movies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 06:59:45 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Shrivastava", "Disha", ""], ["CG", "Saneem Ahmed", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1707.05654", "submitter": "Zeno Toffano", "authors": "Zeno Toffano (L2S), Fran\\c{c}ois Dubois (LM-Orsay)", "title": "Eigenlogic: Interpretable Quantum Observables with applications to Fuzzy\n  Behavior of Vehicular Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a formulation of propositional logic, named Eigenlogic,\nusing quantum observables as propositions. The eigenvalues of these operators\nare the truth-values and the associated eigenvectors the interpretations of the\npropositional system. Fuzzy logic arises naturally when considering vectors\noutside the eigensystem, the fuzzy membership function is obtained by the Born\nrule of the logical observable.This approach is then applied in the context of\nquantum robots using simple behavioral agents represented by Braitenberg\nvehicles. Processing with non-classical logic such as multivalued logic, fuzzy\nlogic and the quantum Eigenlogic permits to enlarge the behavior possibilities\nand the associated decisions of these simple agents.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 09:39:05 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Toffano", "Zeno", "", "L2S"], ["Dubois", "Fran\u00e7ois", "", "LM-Orsay"]]}, {"id": "1707.05720", "submitter": "Mohit Shridhar", "authors": "Mohit Shridhar, David Hsu", "title": "Grounding Spatio-Semantic Referring Expressions for Human-Robot\n  Interaction", "comments": "8 pages, 4 figures, Accepted at RSS 2017 Workshop on Spatial-Semantic\n  Representations in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human language is one of the most natural interfaces for humans to\ninteract with robots. This paper presents a robot system that retrieves\neveryday objects with unconstrained natural language descriptions. A core issue\nfor the system is semantic and spatial grounding, which is to infer objects and\ntheir spatial relationships from images and natural language expressions. We\nintroduce a two-stage neural-network grounding pipeline that maps natural\nlanguage referring expressions directly to objects in the images. The first\nstage uses visual descriptions in the referring expressions to generate a\ncandidate set of relevant objects. The second stage examines all pairwise\nrelationships between the candidates and predicts the most likely referred\nobject according to the spatial descriptions in the referring expressions. A\nkey feature of our system is that by leveraging a large dataset of images\nlabeled with text descriptions, it allows unrestricted object types and natural\nlanguage referring expressions. Preliminary results indicate that our system\noutperforms a near state-of-the-art object comprehension system on standard\nbenchmark datasets. We also present a robot system that follows voice commands\nto pick and place previously unseen objects.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 16:02:05 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Shridhar", "Mohit", ""], ["Hsu", "David", ""]]}, {"id": "1707.05729", "submitter": "Ruben Martinez-Cantin", "authors": "Ruben Martinez-Cantin, Michael McCourt, Kevin Tee", "title": "Robust Bayesian Optimization with Student-t Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has recently attracted the attention of the automatic\nmachine learning community for its excellent results in hyperparameter tuning.\nBO is characterized by the sample efficiency with which it can optimize\nexpensive black-box functions. The efficiency is achieved in a similar fashion\nto the learning to learn methods: surrogate models (typically in the form of\nGaussian processes) learn the target function and perform intelligent sampling.\nThis surrogate model can be applied even in the presence of noise; however, as\nwith most regression methods, it is very sensitive to outlier data. This can\nresult in erroneous predictions and, in the case of BO, biased and inefficient\nexploration. In this work, we present a GP model that is robust to outliers\nwhich uses a Student-t likelihood to segregate outliers and robustly conduct\nBayesian optimization. We present numerical results evaluating the proposed\nmethod in both artificial functions and real problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 16:22:07 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Martinez-Cantin", "Ruben", ""], ["McCourt", "Michael", ""], ["Tee", "Kevin", ""]]}, {"id": "1707.05733", "submitter": "Oier Mees", "authors": "Oier Mees, Andreas Eitel, Wolfram Burgard", "title": "Choosing Smartly: Adaptive Multimodal Fusion for Object Detection in\n  Changing Environments", "comments": "Published at the 2016 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems. Added a new baseline with respect to the IROS\n  version. Project page with code, pretrained models and our InOutDoorPeople\n  RGB-D dataset at http://adaptivefusion.cs.uni-freiburg.de/", "journal-ref": null, "doi": "10.1109/IROS.2016.7759048", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is an essential task for autonomous robots operating in\ndynamic and changing environments. A robot should be able to detect objects in\nthe presence of sensor noise that can be induced by changing lighting\nconditions for cameras and false depth readings for range sensors, especially\nRGB-D cameras. To tackle these challenges, we propose a novel adaptive fusion\napproach for object detection that learns weighting the predictions of\ndifferent sensor modalities in an online manner. Our approach is based on a\nmixture of convolutional neural network (CNN) experts and incorporates multiple\nmodalities including appearance, depth and motion. We test our method in\nextensive robot experiments, in which we detect people in a combined indoor and\noutdoor scenario from RGB-D data, and we demonstrate that our method can adapt\nto harsh lighting changes and severe camera motion blur. Furthermore, we\npresent a new RGB-D dataset for people detection in mixed in- and outdoor\nenvironments, recorded with a mobile robot. Code, pretrained models and dataset\nare available at http://adaptivefusion.cs.uni-freiburg.de\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 16:36:56 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 12:43:54 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Mees", "Oier", ""], ["Eitel", "Andreas", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1707.05858", "submitter": "Marco Gavanelli", "authors": "Marco Gavanelli, Maddalena Nonato, Andrea Peano and Davide Bertozzi", "title": "Logic Programming approaches for routing fault-free and\n  maximally-parallel Wavelength Routed Optical Networks on Chip (Application\n  paper)", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1,\n  2017. 16 pages, LaTeX, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One promising trend in digital system integration consists of boosting\non-chip communication performance by means of silicon photonics, thus\nmaterializing the so-called Optical Networks-on-Chip (ONoCs). Among them,\nwavelength routing can be used to route a signal to destination by univocally\nassociating a routing path to the wavelength of the optical carrier. Such\nwavelengths should be chosen so to minimize interferences among optical\nchannels and to avoid routing faults. As a result, physical parameter selection\nof such networks requires the solution of complex constrained optimization\nproblems. In previous work, published in the proceedings of the International\nConference on Computer-Aided Design, we proposed and solved the problem of\ncomputing the maximum parallelism obtainable in the communication between any\ntwo endpoints while avoiding misrouting of optical signals. The underlying\ntechnology, only quickly mentioned in that paper, is Answer Set Programming\n(ASP). In this work, we detail the ASP approach we used to solve such problem.\n  Another important design issue is to select the wavelengths of optical\ncarriers such that they are spread across the available spectrum, in order to\nreduce the likelihood that, due to imperfections in the manufacturing process,\nunintended routing faults arise. We show how to address such problem in\nConstraint Logic Programming on Finite Domains (CLP(FD)).\n  This paper is under consideration for possible publication on Theory and\nPractice of Logic Programming.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 21:12:26 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Gavanelli", "Marco", ""], ["Nonato", "Maddalena", ""], ["Peano", "Andrea", ""], ["Bertozzi", "Davide", ""]]}, {"id": "1707.05878", "submitter": "Elena Mocanu", "authors": "Elena Mocanu, Decebal Constantin Mocanu, Phuong H. Nguyen, Antonio\n  Liotta, Michael E. Webber, Madeleine Gibescu, J.G. Slootweg", "title": "On-line Building Energy Optimization using Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unprecedented high volumes of data are becoming available with the growth of\nthe advanced metering infrastructure. These are expected to benefit planning\nand operation of the future power system, and to help the customers transition\nfrom a passive to an active role. In this paper, we explore for the first time\nin the smart grid context the benefits of using Deep Reinforcement Learning, a\nhybrid type of methods that combines Reinforcement Learning with Deep Learning,\nto perform on-line optimization of schedules for building energy management\nsystems. The learning procedure was explored using two methods, Deep Q-learning\nand Deep Policy Gradient, both of them being extended to perform multiple\nactions simultaneously. The proposed approach was validated on the large-scale\nPecan Street Inc. database. This highly-dimensional database includes\ninformation about photovoltaic power generation, electric vehicles as well as\nbuildings appliances. Moreover, these on-line energy scheduling strategies\ncould be used to provide real-time feedback to consumers to encourage more\nefficient use of electricity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 22:00:53 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Mocanu", "Elena", ""], ["Mocanu", "Decebal Constantin", ""], ["Nguyen", "Phuong H.", ""], ["Liotta", "Antonio", ""], ["Webber", "Michael E.", ""], ["Gibescu", "Madeleine", ""], ["Slootweg", "J. G.", ""]]}, {"id": "1707.05904", "submitter": "Esra Erdem", "authors": "Ibrahim Faruk Yalciner, Ahmed Nouman, Volkan Patoglu, and Esra Erdem", "title": "Hybrid Conditional Planning using Answer Set Programming", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1,\n  2017; 28 pages, 3 figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parallel offline algorithm for computing hybrid conditional\nplans, called HCP-ASP, oriented towards robotics applications. HCP-ASP relies\non modeling actuation actions and sensing actions in an expressive nonmonotonic\nlanguage of answer set programming (ASP), and computation of the branches of a\nconditional plan in parallel using an ASP solver. In particular, thanks to\nexternal atoms, continuous feasibility checks (like collision checks) are\nembedded into formal representations of actuation actions and sensing actions\nin ASP; and thus each branch of a hybrid conditional plan describes a feasible\nexecution of actions to reach their goals. Utilizing nonmonotonic constructs\nand nondeterministic choices, partial knowledge about states and\nnondeterministic effects of sensing actions can be explicitly formalized in\nASP; and thus each branch of a conditional plan can be computed by an ASP\nsolver without necessitating a conformant planner and an ordering of sensing\nactions in advance. We apply our method in a service robotics domain and report\nexperimental evaluations. Furthermore, we present performance comparisons with\nother compilation based conditional planners on standardized benchmark domains.\nThis paper is under consideration for acceptance in TPLP.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 00:29:16 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Yalciner", "Ibrahim Faruk", ""], ["Nouman", "Ahmed", ""], ["Patoglu", "Volkan", ""], ["Erdem", "Esra", ""]]}, {"id": "1707.06170", "submitter": "Razvan Pascanu", "authors": "Razvan Pascanu, Yujia Li, Oriol Vinyals, Nicolas Heess, Lars Buesing,\n  Sebastien Racani\\`ere, David Reichert, Th\\'eophane Weber, Daan Wierstra,\n  Peter Battaglia", "title": "Learning model-based planning from scratch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom holds that model-based planning is a powerful approach to\nsequential decision-making. It is often very challenging in practice, however,\nbecause while a model can be used to evaluate a plan, it does not prescribe how\nto construct a plan. Here we introduce the \"Imagination-based Planner\", the\nfirst model-based, sequential decision-making agent that can learn to\nconstruct, evaluate, and execute plans. Before any action, it can perform a\nvariable number of imagination steps, which involve proposing an imagined\naction and evaluating it with its model-based imagination. All imagined actions\nand outcomes are aggregated, iteratively, into a \"plan context\" which\nconditions future real and imagined actions. The agent can even decide how to\nimagine: testing out alternative imagined actions, chaining sequences of\nactions together, or building a more complex \"imagination tree\" by navigating\nflexibly among the previously imagined states using a learned policy. And our\nagent can learn to plan economically, jointly optimizing for external rewards\nand computational costs associated with using its imagination. We show that our\narchitecture can learn to solve a challenging continuous control problem, and\nalso learn elaborate planning strategies in a discrete maze-solving task. Our\nwork opens a new direction toward learning the components of a model-based\nplanning system and how to use them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 15:52:35 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Pascanu", "Razvan", ""], ["Li", "Yujia", ""], ["Vinyals", "Oriol", ""], ["Heess", "Nicolas", ""], ["Buesing", "Lars", ""], ["Racani\u00e8re", "Sebastien", ""], ["Reichert", "David", ""], ["Weber", "Th\u00e9ophane", ""], ["Wierstra", "Daan", ""], ["Battaglia", "Peter", ""]]}, {"id": "1707.06175", "submitter": "Taylor Mordan", "authors": "Taylor Mordan, Nicolas Thome, Matthieu Cord and Gilles Henaff", "title": "Deformable Part-based Fully Convolutional Network for Object Detection", "comments": "Accepted to BMVC 2017 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing region-based object detectors are limited to regions with fixed box\ngeometry to represent objects, even if those are highly non-rectangular. In\nthis paper we introduce DP-FCN, a deep model for object detection which\nexplicitly adapts to shapes of objects with deformable parts. Without\nadditional annotations, it learns to focus on discriminative elements and to\nalign them, and simultaneously brings more invariance for classification and\ngeometric information to refine localization. DP-FCN is composed of three main\nmodules: a Fully Convolutional Network to efficiently maintain spatial\nresolution, a deformable part-based RoI pooling layer to optimize positions of\nparts and build invariance, and a deformation-aware localization module\nexplicitly exploiting displacements of parts to improve accuracy of bounding\nbox regression. We experimentally validate our model and show significant\ngains. DP-FCN achieves state-of-the-art performances of 83.1% and 80.9% on\nPASCAL VOC 2007 and 2012 with VOC data only.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 16:03:05 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Mordan", "Taylor", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""], ["Henaff", "Gilles", ""]]}, {"id": "1707.06194", "submitter": "Cassio P. de Campos", "authors": "Cassio P. de Campos, Mauro Scanagatta, Giorgio Corani, Marco Zaffalon", "title": "Entropy-based Pruning for Learning Bayesian Networks using BIC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decomposable score-based structure learning of Bayesian networks,\nexisting approaches first compute a collection of candidate parent sets for\neach variable and then optimize over this collection by choosing one parent set\nfor each variable without creating directed cycles while maximizing the total\nscore. We target the task of constructing the collection of candidate parent\nsets when the score of choice is the Bayesian Information Criterion (BIC). We\nprovide new non-trivial results that can be used to prune the search space of\ncandidate parent sets of each node. We analyze how these new results relate to\nprevious ideas in the literature both theoretically and empirically. We show in\nexperiments with UCI data sets that gains can be significant. Since the new\npruning rules are easy to implement and have low computational costs, they can\nbe promptly integrated into all state-of-the-art methods for structure learning\nof Bayesian networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:03:14 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["de Campos", "Cassio P.", ""], ["Scanagatta", "Mauro", ""], ["Corani", "Giorgio", ""], ["Zaffalon", "Marco", ""]]}, {"id": "1707.06203", "submitter": "Th\\'eophane  Weber", "authors": "Th\\'eophane Weber, S\\'ebastien Racani\\`ere, David P. Reichert, Lars\n  Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom\\`enech Badia,\n  Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia,\n  Demis Hassabis, David Silver, Daan Wierstra", "title": "Imagination-Augmented Agents for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Imagination-Augmented Agents (I2As), a novel architecture for\ndeep reinforcement learning combining model-free and model-based aspects. In\ncontrast to most existing model-based reinforcement learning and planning\nmethods, which prescribe how a model should be used to arrive at a policy, I2As\nlearn to interpret predictions from a learned environment model to construct\nimplicit plans in arbitrary ways, by using the predictions as additional\ncontext in deep policy networks. I2As show improved data efficiency,\nperformance, and robustness to model misspecification compared to several\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:12:56 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 17:26:18 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Weber", "Th\u00e9ophane", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Reichert", "David P.", ""], ["Buesing", "Lars", ""], ["Guez", "Arthur", ""], ["Rezende", "Danilo Jimenez", ""], ["Badia", "Adria Puigdom\u00e8nech", ""], ["Vinyals", "Oriol", ""], ["Heess", "Nicolas", ""], ["Li", "Yujia", ""], ["Pascanu", "Razvan", ""], ["Battaglia", "Peter", ""], ["Hassabis", "Demis", ""], ["Silver", "David", ""], ["Wierstra", "Daan", ""]]}, {"id": "1707.06209", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Nelson F. Liu, Matt Gardner", "title": "Crowdsourcing Multiple Choice Science Questions", "comments": "accepted for the Workshop on Noisy User-generated Text (W-NUT) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for obtaining high-quality, domain-targeted\nmultiple choice questions from crowd workers. Generating these questions can be\ndifficult without trading away originality, relevance or diversity in the\nanswer options. Our method addresses these problems by leveraging a large\ncorpus of domain-specific text and a small set of existing questions. It\nproduces model suggestions for document selection and answer distractor choice\nwhich aid the human question generation process. With this method we have\nassembled SciQ, a dataset of 13.7K multiple choice science exam questions\n(Dataset available at http://allenai.org/data.html). We demonstrate that the\nmethod produces in-domain questions by providing an analysis of this new\ndataset and by showing that humans cannot distinguish the crowdsourced\nquestions from original questions. When using SciQ as additional training data\nto existing questions, we observe accuracy improvements on real science exams.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:28:46 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Welbl", "Johannes", ""], ["Liu", "Nelson F.", ""], ["Gardner", "Matt", ""]]}, {"id": "1707.06217", "submitter": "Ashwin Pananjady", "authors": "Ashwin Pananjady, Cheng Mao, Vidya Muthukumar, Martin J. Wainwright,\n  Thomas A. Courtade", "title": "Worst-case vs Average-case Design for Estimation from Fixed Pairwise\n  Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparison data arises in many domains, including tournament\nrankings, web search, and preference elicitation. Given noisy comparisons of a\nfixed subset of pairs of items, we study the problem of estimating the\nunderlying comparison probabilities under the assumption of strong stochastic\ntransitivity (SST). We also consider the noisy sorting subclass of the SST\nmodel. We show that when the assignment of items to the topology is arbitrary,\nthese permutation-based models, unlike their parametric counterparts, do not\nadmit consistent estimation for most comparison topologies used in practice. We\nthen demonstrate that consistent estimation is possible when the assignment of\nitems to the topology is randomized, thus establishing a dichotomy between\nworst-case and average-case designs. We propose two estimators in the\naverage-case setting and analyze their risk, showing that it depends on the\ncomparison topology only through the degree sequence of the topology. The rates\nachieved by these estimators are shown to be optimal for a large class of\ngraphs. Our results are corroborated by simulations on multiple comparison\ntopologies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 17:47:05 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Pananjady", "Ashwin", ""], ["Mao", "Cheng", ""], ["Muthukumar", "Vidya", ""], ["Wainwright", "Martin J.", ""], ["Courtade", "Thomas A.", ""]]}, {"id": "1707.06226", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh, Alexander Richard Fabbri, Smaranda Muresan", "title": "The Role of Conversation Context for Sarcasm Detection in Online\n  Interactions", "comments": "SIGDial 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models for sarcasm detection have often relied on the content\nof utterances in isolation. However, speaker's sarcastic intent is not always\nobvious without additional context. Focusing on social media discussions, we\ninvestigate two issues: (1) does modeling of conversation context help in\nsarcasm detection and (2) can we understand what part of conversation context\ntriggered the sarcastic reply. To address the first issue, we investigate\nseveral types of Long Short-Term Memory (LSTM) networks that can model both the\nconversation context and the sarcastic response. We show that the conditional\nLSTM network (Rocktaschel et al., 2015) and LSTM networks with sentence level\nattention on context and response outperform the LSTM model that reads only the\nresponse. To address the second issue, we present a qualitative analysis of\nattention weights produced by the LSTM models with attention and discuss the\nresults compared with human performance on the task.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 01:21:26 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Fabbri", "Alexander Richard", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1707.06325", "submitter": "Joohyung Lee", "authors": "Joohyung Lee, Samidh Talsania, Yi Wang", "title": "Computing LPMLN Using ASP and MLN Solvers", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1, 2017\n  16 pages, LaTeX, 3 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LPMLN is a recent addition to probabilistic logic programming languages. Its\nmain idea is to overcome the rigid nature of the stable model semantics by\nassigning a weight to each rule in a way similar to Markov Logic is defined. We\npresent two implementations of LPMLN, $\\text{LPMLN2ASP}$ and\n$\\text{LPMLN2MLN}$. System $\\text{LPMLN2ASP}$ translates LPMLN programs into\nthe input language of answer set solver $\\text{CLINGO}$, and using weak\nconstraints and stable model enumeration, it can compute most probable stable\nmodels as well as exact conditional and marginal probabilities. System\n$\\text{LPMLN2MLN}$ translates LPMLN programs into the input language of Markov\nLogic solvers, such as $\\text{ALCHEMY}$, $\\text{TUFFY}$, and $\\text{ROCKIT}$,\nand allows for performing approximate probabilistic inference on LPMLN\nprograms. We also demonstrate the usefulness of the LPMLN systems for computing\nother languages, such as ProbLog and Pearl's Causal Models, that are shown to\nbe translatable into LPMLN. (Under consideration for acceptance in TPLP)\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 23:38:47 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 20:04:27 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 23:10:25 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Lee", "Joohyung", ""], ["Talsania", "Samidh", ""], ["Wang", "Yi", ""]]}, {"id": "1707.06334", "submitter": "David Fridovich-Keil", "authors": "Roel Dobbe, David Fridovich-Keil, Claire Tomlin", "title": "Fully Decentralized Policies for Multi-Agent Systems: An Information\n  Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.IT math.IT math.OC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning cooperative policies for multi-agent systems is often challenged by\npartial observability and a lack of coordination. In some settings, the\nstructure of a problem allows a distributed solution with limited\ncommunication. Here, we consider a scenario where no communication is\navailable, and instead we learn local policies for all agents that collectively\nmimic the solution to a centralized multi-agent static optimization problem.\nOur main contribution is an information theoretic framework based on rate\ndistortion theory which facilitates analysis of how well the resulting fully\ndecentralized policies are able to reconstruct the optimal solution. Moreover,\nthis framework provides a natural extension that addresses which nodes an agent\nshould communicate with to improve the performance of its individual policy.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 01:37:14 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 23:27:28 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Dobbe", "Roel", ""], ["Fridovich-Keil", "David", ""], ["Tomlin", "Claire", ""]]}, {"id": "1707.06354", "submitter": "Jaime Fisac", "authors": "Jaime F. Fisac, Monica A. Gates, Jessica B. Hamrick, Chang Liu, Dylan\n  Hadfield-Menell, Malayandi Palaniappan, Dhruv Malik, S. Shankar Sastry,\n  Thomas L. Griffiths, and Anca D. Dragan", "title": "Pragmatic-Pedagogic Value Alignment", "comments": "Published at the International Symposium on Robotics Research (ISRR\n  2017)", "journal-ref": "International Symposium on Robotics Research, 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As intelligent systems gain autonomy and capability, it becomes vital to\nensure that their objectives match those of their human users; this is known as\nthe value-alignment problem. In robotics, value alignment is key to the design\nof collaborative robots that can integrate into human workflows, successfully\ninferring and adapting to their users' objectives as they go. We argue that a\nmeaningful solution to value alignment must combine multi-agent decision theory\nwith rich mathematical models of human cognition, enabling robots to tap into\npeople's natural collaborative capabilities. We present a solution to the\ncooperative inverse reinforcement learning (CIRL) dynamic game based on\nwell-established cognitive models of decision making and theory of mind. The\nsolution captures a key reciprocity relation: the human will not plan her\nactions in isolation, but rather reason pedagogically about how the robot might\nlearn from them; the robot, in turn, can anticipate this and interpret the\nhuman's actions pragmatically. To our knowledge, this work constitutes the\nfirst formal analysis of value alignment grounded in empirically validated\ncognitive models.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 03:07:19 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 20:44:09 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Fisac", "Jaime F.", ""], ["Gates", "Monica A.", ""], ["Hamrick", "Jessica B.", ""], ["Liu", "Chang", ""], ["Hadfield-Menell", "Dylan", ""], ["Palaniappan", "Malayandi", ""], ["Malik", "Dhruv", ""], ["Sastry", "S. Shankar", ""], ["Griffiths", "Thomas L.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "1707.06355", "submitter": "Yunan Ye", "authors": "Yunan Ye, Zhou Zhao, Yimeng Li, Long Chen, Jun Xiao and Yueting Zhuang", "title": "Video Question Answering via Attribute-Augmented Attention Network\n  Learning", "comments": "Accepted for SIGIR 2017", "journal-ref": null, "doi": "10.1145/3077136.3080655", "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video Question Answering is a challenging problem in visual information\nretrieval, which provides the answer to the referenced video content according\nto the question. However, the existing visual question answering approaches\nmainly tackle the problem of static image question, which may be ineffectively\nfor video question answering due to the insufficiency of modeling the temporal\ndynamics of video contents. In this paper, we study the problem of video\nquestion answering by modeling its temporal dynamics with frame-level attention\nmechanism. We propose the attribute-augmented attention network learning\nframework that enables the joint frame-level attribute detection and unified\nvideo representation learning for video question answering. We then incorporate\nthe multi-step reasoning process for our proposed attention network to further\nimprove the performance. We construct a large-scale video question answering\ndataset. We conduct the experiments on both multiple-choice and open-ended\nvideo question answering tasks to show the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 03:12:29 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Ye", "Yunan", ""], ["Zhao", "Zhou", ""], ["Li", "Yimeng", ""], ["Chen", "Long", ""], ["Xiao", "Jun", ""], ["Zhuang", "Yueting", ""]]}, {"id": "1707.06387", "submitter": "Joohyung Lee", "authors": "Joohyung Lee, Nikhil Loney, Yunsong Meng", "title": "Representing Hybrid Automata by Action Language Modulo Theories", "comments": "Paper presented at the 33nd International Conference on Logic\n  Programming (ICLP 2017), Melbourne, Australia, August 28 to September 1, 2017\n  16 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both hybrid automata and action languages are formalisms for describing the\nevolution of dynamic systems. This paper establishes a formal relationship\nbetween them. We show how to succinctly represent hybrid automata in an action\nlanguage which in turn is defined as a high-level notation for answer set\nprogramming modulo theories (ASPMT) --- an extension of answer set programs to\nthe first-order level similar to the way satisfiability modulo theories (SMT)\nextends propositional satisfiability (SAT). We first show how to represent\nlinear hybrid automata with convex invariants by an action language modulo\ntheories. A further translation into SMT allows for computing them using SMT\nsolvers that support arithmetic over reals. Next, we extend the representation\nto the general class of non-linear hybrid automata allowing even non-convex\ninvariants. We represent them by an action language modulo ODE (Ordinary\nDifferential Equations), which can be compiled into satisfiability modulo ODE.\nWe developed a prototype system cplus2aspmt based on these translations, which\nallows for a succinct representation of hybrid transition systems that can be\ncomputed effectively by the state-of-the-art SMT solver dReal.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 06:37:40 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 20:06:36 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Lee", "Joohyung", ""], ["Loney", "Nikhil", ""], ["Meng", "Yunsong", ""]]}, {"id": "1707.06446", "submitter": "Max Schr\\\"oder", "authors": "Max Schr\\\"oder, Stefan L\\\"udtke, Sebastian Bader, Frank Kr\\\"uger,\n  Thomas Kirste", "title": "Sequential Lifted Bayesian Filtering in Multiset Rewriting Systems", "comments": "7 pages, 3 figures, accepted at UAI-17 Statistical Relational AI\n  (StarAI) workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bayesian Filtering for plan and activity recognition is challenging for\nscenarios that contain many observation equivalent entities (i.e. entities that\nproduce the same observations). This is due to the combinatorial explosion in\nthe number of hypotheses that need to be tracked. However, this class of\nproblems exhibits a certain symmetry that can be exploited for state space\nrepresentation and inference. We analyze current state of the art methods and\nfind that none of them completely fits the requirements arising in this problem\nclass. We sketch a novel inference algorithm that provides a solution by\nincorporating concepts from Lifted Inference algorithms, Probabilistic Multiset\nRewriting Systems, and Computational State Space Models. Two experiments\nconfirm that this novel algorithm has the potential to perform efficient\nprobabilistic inference on this problem class.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 11:14:20 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 15:31:56 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Schr\u00f6der", "Max", ""], ["L\u00fcdtke", "Stefan", ""], ["Bader", "Sebastian", ""], ["Kr\u00fcger", "Frank", ""], ["Kirste", "Thomas", ""]]}, {"id": "1707.06541", "submitter": "Jian Wu", "authors": "Jian Wu and Peter I. Frazier", "title": "Discretization-free Knowledge Gradient Methods for Bayesian Optimization", "comments": "This paper, which combines and extends two conference papers\n  (arXiv:1703.04389, arXiv:1606.04414), has been withdrawn by the authors\n  because it was submitted prematurely before proper attribution could be\n  provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies Bayesian ranking and selection (R&S) problems with\ncorrelated prior beliefs and continuous domains, i.e. Bayesian optimization\n(BO). Knowledge gradient methods [Frazier et al., 2008, 2009] have been widely\nstudied for discrete R&S problems, which sample the one-step Bayes-optimal\npoint. When used over continuous domains, previous work on the knowledge\ngradient [Scott et al., 2011, Wu and Frazier, 2016, Wu et al., 2017] often rely\non a discretized finite approximation. However, the discretization introduces\nerror and scales poorly as the dimension of domain grows. In this paper, we\ndevelop a fast discretization-free knowledge gradient method for Bayesian\noptimization. Our method is not restricted to the fully sequential setting, but\nuseful in all settings where knowledge gradient can be used over continuous\ndomains. We show how our method can be generalized to handle (i) batch of\npoints suggestion (parallel knowledge gradient); (ii) the setting where\nderivative information is available in the optimization process\n(derivative-enabled knowledge gradient). In numerical experiments, we\ndemonstrate that the discretization-free knowledge gradient method finds global\noptima significantly faster than previous Bayesian optimization algorithms on\nboth synthetic test functions and real-world applications, especially when\nfunction evaluations are noisy; and derivative-enabled knowledge gradient can\nfurther improve the performances, even outperforming the gradient-based\noptimizer such as BFGS when derivative information is available.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 14:28:05 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 18:31:35 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Wu", "Jian", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1707.06543", "submitter": "Boyi Li", "authors": "Boyi Li and Xiulian Peng and Zhangyang Wang and Jizheng Xu and Dan\n  Feng", "title": "An All-in-One Network for Dehazing and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an image dehazing model built with a convolutional neural\nnetwork (CNN), called All-in-One Dehazing Network (AOD-Net). It is designed\nbased on a re-formulated atmospheric scattering model. Instead of estimating\nthe transmission matrix and the atmospheric light separately as most previous\nmodels did, AOD-Net directly generates the clean image through a light-weight\nCNN. Such a novel end-to-end design makes it easy to embed AOD-Net into other\ndeep models, e.g., Faster R-CNN, for improving high-level task performance on\nhazy images. Experimental results on both synthesized and natural hazy image\ndatasets demonstrate our superior performance than the state-of-the-art in\nterms of PSNR, SSIM and the subjective visual quality. Furthermore, when\nconcatenating AOD-Net with Faster R-CNN and training the joint pipeline from\nend to end, we witness a large improvement of the object detection performance\non hazy images.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 14:30:35 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Li", "Boyi", ""], ["Peng", "Xiulian", ""], ["Wang", "Zhangyang", ""], ["Xu", "Jizheng", ""], ["Feng", "Dan", ""]]}, {"id": "1707.06607", "submitter": "Anton Andreychuk", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Applying MAPP Algorithm for Cooperative Path Finding in Urban\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper considers the problem of planning a set of non-conflict\ntrajectories for the coalition of intelligent agents (mobile robots). Two\ndivergent approaches, e.g. centralized and decentralized, are surveyed and\nanalyzed. Decentralized planner - MAPP is described and applied to the task of\nfinding trajectories for dozens UAVs performing nap-of-the-earth flight in\nurban environments. Results of the experimental studies provide an opportunity\nto claim that MAPP is a highly efficient planner for solving considered types\nof tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:57:49 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1707.06633", "submitter": "Martin V\\\"olker", "authors": "Felix Burget, Lukas Dominique Josef Fiederer, Daniel Kuhner, Martin\n  V\\\"olker, Johannes Aldinger, Robin Tibor Schirrmeister, Chau Do, Joschka\n  Boedecker, Bernhard Nebel, Tonio Ball, Wolfram Burgard", "title": "Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users\n  with Limited Communication Skills", "comments": "* FB, LDJF, DK, MV and JA contributed equally to the work. Accepted\n  as a conference paper at the European Conference on Mobile Robotics 2017\n  (ECMR 2017), 6 pages, 3 figures", "journal-ref": "2017 European Conference on Mobile Robots (ECMR)", "doi": "10.1109/ECMR.2017.8098658", "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As autonomous service robots become more affordable and thus available also\nfor the general public, there is a growing need for user friendly interfaces to\ncontrol the robotic system. Currently available control modalities typically\nexpect users to be able to express their desire through either touch, speech or\ngesture commands. While this requirement is fulfilled for the majority of\nusers, paralyzed users may not be able to use such systems. In this paper, we\npresent a novel framework, that allows these users to interact with a robotic\nservice assistant in a closed-loop fashion, using only thoughts. The\nbrain-computer interface (BCI) system is composed of several interacting\ncomponents, i.e., non-invasive neuronal signal recording and decoding,\nhigh-level task planning, motion and manipulation planning as well as\nenvironment perception. In various experiments, we demonstrate its\napplicability and robustness in real world scenarios, considering\nfetch-and-carry tasks and tasks involving human-robot interaction. As our\nresults demonstrate, our system is capable of adapting to frequent changes in\nthe environment and reliably completing given tasks within a reasonable amount\nof time. Combined with high-level planning and autonomous robotic systems,\ninteresting new perspectives open up for non-invasive BCI-based human-robot\ninteractions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 17:51:12 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 06:30:43 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 08:25:20 GMT"}, {"version": "v4", "created": "Tue, 12 Jun 2018 14:52:41 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Burget", "Felix", ""], ["Fiederer", "Lukas Dominique Josef", ""], ["Kuhner", "Daniel", ""], ["V\u00f6lker", "Martin", ""], ["Aldinger", "Johannes", ""], ["Schirrmeister", "Robin Tibor", ""], ["Do", "Chau", ""], ["Boedecker", "Joschka", ""], ["Nebel", "Bernhard", ""], ["Ball", "Tonio", ""], ["Burgard", "Wolfram", ""]]}, {"id": "1707.06658", "submitter": "Anirban Santara", "authors": "Anirban Santara, Abhishek Naik, Balaraman Ravindran, Dipankar Das,\n  Dheevatsa Mudigere, Sasikanth Avancha, Bharat Kaul", "title": "RAIL: Risk-Averse Imitation Learning", "comments": "Accepted for presentation in Deep Reinforcement Learning Symposium at\n  NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning algorithms learn viable policies by imitating an expert's\nbehavior when reward signals are not available. Generative Adversarial\nImitation Learning (GAIL) is a state-of-the-art algorithm for learning policies\nwhen the expert's behavior is available as a fixed set of trajectories. We\nevaluate in terms of the expert's cost function and observe that the\ndistribution of trajectory-costs is often more heavy-tailed for GAIL-agents\nthan the expert at a number of benchmark continuous-control tasks. Thus,\nhigh-cost trajectories, corresponding to tail-end events of catastrophic\nfailure, are more likely to be encountered by the GAIL-agents than the expert.\nThis makes the reliability of GAIL-agents questionable when it comes to\ndeployment in risk-sensitive applications like robotic surgery and autonomous\ndriving. In this work, we aim to minimize the occurrence of tail-end events by\nminimizing tail risk within the GAIL framework. We quantify tail risk by the\nConditional-Value-at-Risk (CVaR) of trajectories and develop the Risk-Averse\nImitation Learning (RAIL) algorithm. We observe that the policies learned with\nRAIL show lower tail-end risk than those of vanilla GAIL. Thus the proposed\nRAIL algorithm appears as a potent alternative to GAIL for improved reliability\nin risk-sensitive applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 18:01:45 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 05:40:58 GMT"}, {"version": "v3", "created": "Wed, 4 Oct 2017 09:34:42 GMT"}, {"version": "v4", "created": "Wed, 29 Nov 2017 12:44:19 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Santara", "Anirban", ""], ["Naik", "Abhishek", ""], ["Ravindran", "Balaraman", ""], ["Das", "Dipankar", ""], ["Mudigere", "Dheevatsa", ""], ["Avancha", "Sasikanth", ""], ["Kaul", "Bharat", ""]]}, {"id": "1707.06690", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong and Thien Hoang and William Yang Wang", "title": "DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning", "comments": "EMNLP 17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning to reason in large scale knowledge graphs\n(KGs). More specifically, we describe a novel reinforcement learning framework\nfor learning multi-hop relational paths: we use a policy-based agent with\ncontinuous states based on knowledge graph embeddings, which reasons in a KG\nvector space by sampling the most promising relation to extend its path. In\ncontrast to prior work, our approach includes a reward function that takes the\naccuracy, diversity, and efficiency into consideration. Experimentally, we show\nthat our proposed method outperforms a path-ranking based algorithm and\nknowledge graph embedding methods on Freebase and Never-Ending Language\nLearning datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 19:39:23 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 23:11:17 GMT"}, {"version": "v3", "created": "Sat, 7 Jul 2018 06:42:02 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Xiong", "Wenhan", ""], ["Hoang", "Thien", ""], ["Wang", "William Yang", ""]]}, {"id": "1707.06742", "submitter": "Patrice Simard", "authors": "Patrice Y. Simard, Saleema Amershi, David M. Chickering, Alicia\n  Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh,\n  Johan Verwey, Mo Wang, and John Wernsing", "title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems", "comments": "Also available at: http://aka.ms/machineteachingpaper", "journal-ref": null, "doi": null, "report-no": "MSR-TR-2017-26", "categories": "cs.LG cs.AI cs.HC cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current processes for building machine learning systems require\npractitioners with deep knowledge of machine learning. This significantly\nlimits the number of machine learning systems that can be created and has led\nto a mismatch between the demand for machine learning systems and the ability\nfor organizations to build them. We believe that in order to meet this growing\ndemand for machine learning systems we must significantly increase the number\nof individuals that can teach machines. We postulate that we can achieve this\ngoal by making the process of teaching machines easy, fast and above all,\nuniversally accessible.\n  While machine learning focuses on creating new algorithms and improving the\naccuracy of \"learners\", the machine teaching discipline focuses on the efficacy\nof the \"teachers\". Machine teaching as a discipline is a paradigm shift that\nfollows and extends principles of software engineering and programming\nlanguages. We put a strong emphasis on the teacher and the teacher's\ninteraction with data, as well as crucial components such as techniques and\ndesign principles of interaction and visualization.\n  In this paper, we present our position regarding the discipline of machine\nteaching and articulate fundamental machine teaching principles. We also\ndescribe how, by decoupling knowledge about machine learning algorithms from\nthe process of teaching, we can accelerate innovation and empower millions of\nnew uses for machine learning models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 02:37:04 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 05:45:05 GMT"}, {"version": "v3", "created": "Fri, 11 Aug 2017 00:16:49 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Simard", "Patrice Y.", ""], ["Amershi", "Saleema", ""], ["Chickering", "David M.", ""], ["Pelton", "Alicia Edelman", ""], ["Ghorashi", "Soroush", ""], ["Meek", "Christopher", ""], ["Ramos", "Gonzalo", ""], ["Suh", "Jina", ""], ["Verwey", "Johan", ""], ["Wang", "Mo", ""], ["Wernsing", "John", ""]]}, {"id": "1707.06756", "submitter": "Clayton Morrison", "authors": "Colin Reimer Dawson, Chaofan Huang, Clayton T. Morrison", "title": "An Infinite Hidden Markov Model With Similarity-Biased Transitions", "comments": "16 pages, 4 figures, accepted to ICML 2017, includes supplemental\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a generalization of the Hierarchical Dirichlet Process Hidden\nMarkov Model (HDP-HMM) which is able to encode prior information that state\ntransitions are more likely between \"nearby\" states. This is accomplished by\ndefining a similarity function on the state space and scaling transition\nprobabilities by pair-wise similarities, thereby inducing correlations among\nthe transition distributions. We present an augmented data representation of\nthe model as a Markov Jump Process in which: (1) some jump attempts fail, and\n(2) the probability of success is proportional to the similarity between the\nsource and destination states. This augmentation restores conditional conjugacy\nand admits a simple Gibbs sampler. We evaluate the model and inference method\non a speaker diarization task and a \"harmonic parsing\" task using four-part\nchorale data, as well as on several synthetic datasets, achieving favorable\ncomparisons to existing models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 04:39:10 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Dawson", "Colin Reimer", ""], ["Huang", "Chaofan", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1707.06766", "submitter": "Irene Teinemaa", "authors": "Irene Teinemaa, Marlon Dumas, Marcello La Rosa, and Fabrizio Maria\n  Maggi", "title": "Outcome-Oriented Predictive Process Monitoring: Review and Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring refers to the act of making\npredictions about the future state of ongoing cases of a business process,\nbased on their incomplete execution traces and logs of historical (completed)\ntraces. Motivated by the increasingly pervasive availability of fine-grained\nevent data about business process executions, the problem of predictive process\nmonitoring has received substantial attention in the past years. In particular,\na considerable number of methods have been put forward to address the problem\nof outcome-oriented predictive process monitoring, which refers to classifying\neach ongoing case of a process according to a given set of possible categorical\noutcomes - e.g., Will the customer complain or not? Will an order be delivered,\ncanceled or withdrawn? Unfortunately, different authors have used different\ndatasets, experimental settings, evaluation measures and baselines to assess\ntheir proposals, resulting in poor comparability and an unclear picture of the\nrelative merits and applicability of different methods. To address this gap,\nthis article presents a systematic review and taxonomy of outcome-oriented\npredictive process monitoring methods, and a comparative experimental\nevaluation of eleven representative methods using a benchmark covering 24\npredictive process monitoring tasks based on nine real-life event logs.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 06:25:31 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 00:22:49 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 19:56:16 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 15:10:07 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio Maria", ""]]}, {"id": "1707.06813", "submitter": "Giovanni Amendola", "authors": "Giovanni Amendola, Carmine Dodaro, Wolfgang Faber, Nicola Leone,\n  Francesco Ricca", "title": "On the Computation of Paracoherent Answer Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-established formalism for nonmonotonic\nreasoning. An ASP program can have no answer set due to cyclic default\nnegation. In this case, it is not possible to draw any conclusion, even if this\nis not intended. Recently, several paracoherent semantics have been proposed\nthat address this issue, and several potential applications for these semantics\nhave been identified. However, paracoherent semantics have essentially been\ninapplicable in practice, due to the lack of efficient algorithms and\nimplementations. In this paper, this lack is addressed, and several different\nalgorithms to compute semi-stable and semi-equilibrium models are proposed and\nimplemented into an answer set solving framework. An empirical performance\ncomparison among the new algorithms on benchmarks from ASP competitions is\ngiven as well.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 09:45:06 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Amendola", "Giovanni", ""], ["Dodaro", "Carmine", ""], ["Faber", "Wolfgang", ""], ["Leone", "Nicola", ""], ["Ricca", "Francesco", ""]]}, {"id": "1707.06887", "submitter": "Marc G. Bellemare", "authors": "Marc G. Bellemare, Will Dabney, R\\'emi Munos", "title": "A Distributional Perspective on Reinforcement Learning", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we argue for the fundamental importance of the value\ndistribution: the distribution of the random return received by a reinforcement\nlearning agent. This is in contrast to the common approach to reinforcement\nlearning which models the expectation of this return, or value. Although there\nis an established body of literature studying the value distribution, thus far\nit has always been used for a specific purpose such as implementing risk-aware\nbehaviour. We begin with theoretical results in both the policy evaluation and\ncontrol settings, exposing a significant distributional instability in the\nlatter. We then use the distributional perspective to design a new algorithm\nwhich applies Bellman's equation to the learning of approximate value\ndistributions. We evaluate our algorithm using the suite of games from the\nArcade Learning Environment. We obtain both state-of-the-art results and\nanecdotal evidence demonstrating the importance of the value distribution in\napproximate reinforcement learning. Finally, we combine theoretical and\nempirical evidence to highlight the ways in which the value distribution\nimpacts learning in the approximate setting.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 13:21:54 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Bellemare", "Marc G.", ""], ["Dabney", "Will", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "1707.06895", "submitter": "Pawel Gomoluch", "authors": "Pawel Gomoluch, Dalal Alrajeh, Alessandra Russo, Antonio Bucchiarone", "title": "Towards learning domain-independent planning heuristics", "comments": "Accepted for the IJCAI-17 Workshop on Architectures for Generality\n  and Autonomy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated planning remains one of the most general paradigms in Artificial\nIntelligence, providing means of solving problems coming from a wide variety of\ndomains. One of the key factors restricting the applicability of planning is\nits computational complexity resulting from exponentially large search spaces.\nHeuristic approaches are necessary to solve all but the simplest problems. In\nthis work, we explore the possibility of obtaining domain-independent heuristic\nfunctions using machine learning. This is a part of a wider research program\nwhose objective is to improve practical applicability of planning in systems\nfor which the planning domains evolve at run time. The challenge is therefore\nthe learning of (corrections of) domain-independent heuristics that can be\nreused across different planning domains.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 13:39:24 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Gomoluch", "Pawel", ""], ["Alrajeh", "Dalal", ""], ["Russo", "Alessandra", ""], ["Bucchiarone", "Antonio", ""]]}, {"id": "1707.06959", "submitter": "Davide Fusc\\`a", "authors": "Francesco Calimeri, Davide Fusc\\`a, Stefano Germano, Simona Perri and\n  Jessica Zangari", "title": "A Framework for Easing the Development of Applications Embedding Answer\n  Set Programming", "comments": null, "journal-ref": null, "doi": "10.1145/2967973.2968594", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer Set Programming (ASP) is a well-established declarative problem\nsolving paradigm which became widely used in AI and recognized as a powerful\ntool for knowledge representation and reasoning (KRR), especially for its high\nexpressiveness and the ability to deal also with incomplete knowledge.\n  Recently, thanks to the availability of a number of robust and efficient\nimplementations, ASP has been increasingly employed in a number of different\ndomains, and used for the development of industrial-level and enterprise\napplications. This made clear the need for proper development tools and\ninteroperability mechanisms for easing interaction and integration with\nexternal systems in the widest range of real-world scenarios, including mobile\napplications and educational contexts.\n  In this work we present a framework for integrating the KRR capabilities of\nASP into generic applications. We show the use of the framework by illustrating\nproper specializations for some relevant ASP systems over different platforms,\nincluding the mobile setting; furthermore, the potential of the framework for\neducational purposes is illustrated by means of the development of several\nASP-based applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 16:15:31 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Calimeri", "Francesco", ""], ["Fusc\u00e0", "Davide", ""], ["Germano", "Stefano", ""], ["Perri", "Simona", ""], ["Zangari", "Jessica", ""]]}, {"id": "1707.06992", "submitter": "Hossein Hosseini", "authors": "S. Hossein Hosseini and Afshin Ebrahimi", "title": "Ideological Sublations: Resolution of Dialectic in Population-based\n  Optimization", "comments": "An antenna selection model for massive MIMO was considered at the\n  current version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A population-based optimization algorithm was designed, inspired by two main\nthinking modes in philosophy, both based on dialectic concept and\nthesis-antithesis paradigm. They impose two different kinds of dialectics.\nIdealistic and materialistic antitheses are formulated as optimization models.\nBased on the models, the population is coordinated for dialectical\ninteractions. At the population-based context, the formulated optimization\nmodels are reduced to a simple detection problem for each thinker (particle).\nAccording to the assigned thinking mode to each thinker and her/his\nmeasurements of corresponding dialectic with other candidate particles, they\ndeterministically decide to interact with a thinker in maximum dialectic with\ntheir theses. The position of a thinker at maximum dialectic is known as an\navailable antithesis among the existing solutions. The dialectical interactions\nat each ideological community are distinguished by meaningful distributions of\nstep-sizes for each thinking mode. In fact, the thinking modes are regarded as\nexploration and exploitation elements of the proposed algorithm. The result is\na delicate balance without any requirement for adjustment of step-size\ncoefficients. Main parameter of the proposed algorithm is the number of\nparticles appointed to each thinking modes, or equivalently for each kind of\nmotions. An additional integer parameter is defined to boost the stability of\nthe final algorithm in some particular problems. The proposed algorithm is\nevaluated by a testbed of 12 single-objective continuous benchmark functions.\nMoreover, its performance and speed were highlighted in sparse reconstruction\nand antenna selection problems, at the context of compressed sensing and\nmassive MIMO, respectively. The results indicate fast and efficient performance\nin comparison with well-known evolutionary algorithms and dedicated\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 17:53:04 GMT"}, {"version": "v2", "created": "Sun, 3 Sep 2017 13:33:09 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Hosseini", "S. Hossein", ""], ["Ebrahimi", "Afshin", ""]]}, {"id": "1707.07048", "submitter": "Zhehuai Chen", "authors": "Zhehuai Chen, Jasha Droppo, Jinyu Li, Wayne Xiong", "title": "Progressive Joint Modeling in Unsupervised Single-channel Overlapped\n  Speech Recognition", "comments": "submitted to TASLP, 07/20/2017; accepted by TASLP, 10/13/2017", "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  26 (2018) 184-196", "doi": "10.1109/TASLP.2017.2765834", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised single-channel overlapped speech recognition is one of the\nhardest problems in automatic speech recognition (ASR). Permutation invariant\ntraining (PIT) is a state of the art model-based approach, which applies a\nsingle neural network to solve this single-input, multiple-output modeling\nproblem. We propose to advance the current state of the art by imposing a\nmodular structure on the neural network, applying a progressive pretraining\nregimen, and improving the objective function with transfer learning and a\ndiscriminative training criterion. The modular structure splits the problem\ninto three sub-tasks: frame-wise interpreting, utterance-level speaker tracing,\nand speech recognition. The pretraining regimen uses these modules to solve\nprogressively harder tasks. Transfer learning leverages parallel clean speech\nto improve the training targets for the network. Our discriminative training\nformulation is a modification of standard formulations, that also penalizes\ncompeting outputs of the system. Experiments are conducted on the artificial\noverlapped Switchboard and hub5e-swb dataset. The proposed framework achieves\nover 30% relative improvement of WER over both a strong jointly trained system,\nPIT for ASR, and a separately optimized system, PIT for speech separation with\nclean speech ASR model. The improvement comes from better model generalization,\ntraining efficiency and the sequence level linguistic knowledge integration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 21:21:09 GMT"}, {"version": "v2", "created": "Fri, 20 Oct 2017 03:06:23 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Chen", "Zhehuai", ""], ["Droppo", "Jasha", ""], ["Li", "Jinyu", ""], ["Xiong", "Wayne", ""]]}, {"id": "1707.07298", "submitter": "Youssef Hamadi", "authors": "Youssef Hamadi, Souhila Kaci", "title": "Preference Reasoning in Matching Procedures: Application to the\n  Admission Post-Baccalaureat Platform", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because preferences naturally arise and play an important role in many\nreal-life decisions, they are at the backbone of various fields. In particular\npreferences are increasingly used in almost all matching procedures-based\napplications. In this work we highlight the benefit of using AI insights on\npreferences in a large scale application, namely the French Admission\nPost-Baccalaureat Platform (APB). Each year APB allocates hundreds of thousands\nfirst year applicants to universities. This is done automatically by matching\napplicants preferences to university seats. In practice, APB can be unable to\ndistinguish between applicants which leads to the introduction of random\nselection. This has created frustration in the French public since randomness,\neven used as a last mean does not fare well with the republican egalitarian\nprinciple. In this work, we provide a solution to this problem. We take\nadvantage of recent AI Preferences Theory results to show how to enhance APB in\norder to improve expressiveness of applicants preferences and reduce their\nexposure to random decisions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 14:01:08 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 03:48:50 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 09:36:34 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Hamadi", "Youssef", ""], ["Kaci", "Souhila", ""]]}, {"id": "1707.07341", "submitter": "Michael Hughes", "authors": "Michael C. Hughes and Leah Weiner and Gabriel Hope and Thomas H. McCoy\n  Jr. and Roy H. Perlis and Erik B. Sudderth and Finale Doshi-Velez", "title": "Prediction-Constrained Training for Semi-Supervised Mixture and Topic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervisory signals have the potential to make low-dimensional data\nrepresentations, like those learned by mixture and topic models, more\ninterpretable and useful. We propose a framework for training latent variable\nmodels that explicitly balances two goals: recovery of faithful generative\nexplanations of high-dimensional data, and accurate prediction of associated\nsemantic labels. Existing approaches fail to achieve these goals due to an\nincomplete treatment of a fundamental asymmetry: the intended application is\nalways predicting labels from data, not data from labels. Our\nprediction-constrained objective for training generative models coherently\nintegrates loss-based supervisory signals while enabling effective\nsemi-supervised learning from partially labeled data. We derive learning\nalgorithms for semi-supervised mixture and topic models using stochastic\ngradient descent with automatic differentiation. We demonstrate improved\nprediction quality compared to several previous supervised topic models,\nachieving predictions competitive with high-dimensional logistic regression on\ntext sentiment analysis and electronic health records tasks while\nsimultaneously learning interpretable topics.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 20:19:06 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Hughes", "Michael C.", ""], ["Weiner", "Leah", ""], ["Hope", "Gabriel", ""], ["McCoy", "Thomas H.", "Jr."], ["Perlis", "Roy H.", ""], ["Sudderth", "Erik B.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1707.07402", "submitter": "Khanh Nguyen", "authors": "Khanh Nguyen, Hal Daum\\'e III and Jordan Boyd-Graber", "title": "Reinforcement Learning for Bandit Neural Machine Translation with\n  Simulated Human Feedback", "comments": "11 pages, 5 figures, In Proceedings of Empirical Methods in Natural\n  Language Processing (EMNLP) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation is a natural candidate problem for reinforcement learning\nfrom human feedback: users provide quick, dirty ratings on candidate\ntranslations to guide a system to improve. Yet, current neural machine\ntranslation training focuses on expensive human-generated reference\ntranslations. We describe a reinforcement learning algorithm that improves\nneural machine translation systems from simulated human feedback. Our algorithm\ncombines the advantage actor-critic algorithm (Mnih et al., 2016) with the\nattention-based neural encoder-decoder architecture (Luong et al., 2015). This\nalgorithm (a) is well-designed for problems with a large action space and\ndelayed rewards, (b) effectively optimizes traditional corpus-level machine\ntranslation metrics, and (c) is robust to skewed, high-variance, granular\nfeedback modeled after actual human behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 04:35:19 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 17:19:01 GMT"}, {"version": "v3", "created": "Fri, 13 Oct 2017 06:10:55 GMT"}, {"version": "v4", "created": "Sat, 11 Nov 2017 05:01:23 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Nguyen", "Khanh", ""], ["Daum\u00e9", "Hal", "III"], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1707.07530", "submitter": "Hamid Eghbal-Zadeh", "authors": "Hamid Eghbal-zadeh, Gerhard Widmer", "title": "Likelihood Estimation for Generative Adversarial Networks", "comments": "ICML 2017 Workshop on Implicit Models", "journal-ref": null, "doi": null, "report-no": "1707.07530", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple method for assessing the quality of generated images in\nGenerative Adversarial Networks (GANs). The method can be applied in any kind\nof GAN without interfering with the learning procedure or affecting the\nlearning objective. The central idea is to define a likelihood function that\ncorrelates with the quality of the generated images. In particular, we derive a\nGaussian likelihood function from the distribution of the embeddings (hidden\nactivations) of the real images in the discriminator, and based on this, define\ntwo simple measures of how likely it is that the embeddings of generated images\nare from the distribution of the embeddings of the real images. This yields a\nsimple measure of fitness for generated images, for all varieties of GANs.\nEmpirical results on CIFAR-10 demonstrate a strong correlation between the\nproposed measures and the perceived quality of the generated images.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 12:58:46 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1707.07554", "submitter": "Victor Prokhorov", "authors": "Victor Prokhorov, Mohammad Taher Pilehvar, Dimitri Kartsaklis, Pietro\n  Li\\'o and Nigel Collier", "title": "Learning Rare Word Representations using Semantic Bridging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology that adapts graph embedding techniques (DeepWalk\n(Perozzi et al., 2014) and node2vec (Grover and Leskovec, 2016)) as well as\ncross-lingual vector space mapping approaches (Least Squares and Canonical\nCorrelation Analysis) in order to merge the corpus and ontological sources of\nlexical knowledge. We also perform comparative analysis of the used algorithms\nin order to identify the best combination for the proposed system. We then\napply this to the task of enhancing the coverage of an existing word\nembedding's vocabulary with rare and unseen words. We show that our technique\ncan provide considerable extra coverage (over 99%), leading to consistent\nperformance gain (around 10% absolute gain is achieved with w2v-gn-500K cf.\\S\n3.3) on the Rare Word Similarity dataset.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 13:38:00 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Prokhorov", "Victor", ""], ["Pilehvar", "Mohammad Taher", ""], ["Kartsaklis", "Dimitri", ""], ["Li\u00f3", "Pietro", ""], ["Collier", "Nigel", ""]]}, {"id": "1707.07596", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Thomas Demeester, Tim Rockt\\\"aschel, Sebastian\n  Riedel", "title": "Adversarial Sets for Regularising Neural Link Predictors", "comments": "Proceedings of the 33rd Conference on Uncertainty in Artificial\n  Intelligence (UAI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial training, a set of models learn together by pursuing competing\ngoals, usually defined on single data instances. However, in relational\nlearning and other non-i.i.d domains, goals can also be defined over sets of\ninstances. For example, a link predictor for the is-a relation needs to be\nconsistent with the transitivity property: if is-a(x_1, x_2) and is-a(x_2, x_3)\nhold, is-a(x_1, x_3) needs to hold as well. Here we use such assumptions for\nderiving an inconsistency loss, measuring the degree to which the model\nviolates the assumptions on an adversarially-generated set of examples. The\ntraining objective is defined as a minimax problem, where an adversary finds\nthe most offending adversarial examples by maximising the inconsistency loss,\nand the model is trained by jointly minimising a supervised loss and the\ninconsistency loss on the adversarial examples. This yields the first method\nthat can use function-free Horn clauses (as in Datalog) to regularise any\nneural link predictor, with complexity independent of the domain size. We show\nthat for several link prediction models, the optimisation problem faced by the\nadversary has efficient closed-form solutions. Experiments on link prediction\nbenchmarks indicate that given suitable prior knowledge, our method can\nsignificantly improve neural link predictors on all relevant metrics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 15:00:55 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Minervini", "Pasquale", ""], ["Demeester", "Thomas", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1707.07605", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Hosein Azarbonyad, Jaap Kamps, Maarten de Rijke", "title": "Share your Model instead of your Data: Privacy Preserving Mimic Learning\n  for Ranking", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval\n  (Neu-IR'17)}{}{August 7--11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become a primary tool for solving problems in many\nfields. They are also used for addressing information retrieval problems and\nshow strong performance in several tasks. Training these models requires large,\nrepresentative datasets and for most IR tasks, such data contains sensitive\ninformation from users. Privacy and confidentiality concerns prevent many data\nowners from sharing the data, thus today the research community can only\nbenefit from research on large-scale datasets in a limited manner. In this\npaper, we discuss privacy preserving mimic learning, i.e., using predictions\nfrom a privacy preserving trained model instead of labels from the original\nsensitive training data as a supervision signal. We present the results of\npreliminary experiments in which we apply the idea of mimic learning and\nprivacy preserving mimic learning for the task of document re-ranking as one of\nthe core IR tasks. This research is a step toward laying the ground for\nenabling researchers from data-rich environments to share knowledge learned\nfrom actual users' data, which should facilitate research collaborations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 15:23:41 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Azarbonyad", "Hosein", ""], ["Kamps", "Jaap", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1707.07662", "submitter": "James McMahon", "authors": "James McMahon and Harun Yetkin and Artur Wolek and Zachary Waters and\n  Dan Stilwell", "title": "Towards Real-Time Search Planning in Subsea Environments", "comments": "8 pages, 5 figures. Submitted to 2017 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenge of computing search paths in real-time for subsea\napplications where the goal is to locate an unknown number of targets on the\nseafloor. Our approach maximizes a formal definition of search effectiveness\ngiven finite search effort. We account for false positive measurements and\nvariation in the performance of the search sensor due to geographic variation\nof the seafloor. We compare near-optimal search paths that can be computed in\nreal-time with optimal search paths for which real-time computation is\ninfeasible. We show how sonar data acquired for locating targets at a specific\nlocation can also be used to characterize the performance of the search sonar\nat that location. Our approach is illustrated with numerical experiments where\nsearch paths are planned using sonar data previously acquired from Boston\nHarbor.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 17:46:10 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["McMahon", "James", ""], ["Yetkin", "Harun", ""], ["Wolek", "Artur", ""], ["Waters", "Zachary", ""], ["Stilwell", "Dan", ""]]}, {"id": "1707.07673", "submitter": "Spiros Denaxas", "authors": "Vaclav Papez, Spiros Denaxas and Harry Hemingway", "title": "Evaluation of Semantic Web Technologies for Storing Computable\n  Definitions of Electronic Health Records Phenotyping Algorithms", "comments": "Accepted American Medical Informatics Association Annual Symposium\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records are electronic data generated during or as a\nbyproduct of routine patient care. Structured, semi-structured and unstructured\nEHR offer researchers unprecedented phenotypic breadth and depth and have the\npotential to accelerate the development of precision medicine approaches at\nscale. A main EHR use-case is defining phenotyping algorithms that identify\ndisease status, onset and severity. Phenotyping algorithms utilize diagnoses,\nprescriptions, laboratory tests, symptoms and other elements in order to\nidentify patients with or without a specific trait. No common standardized,\nstructured, computable format exists for storing phenotyping algorithms. The\nmajority of algorithms are stored as human-readable descriptive text documents\nmaking their translation to code challenging due to their inherent complexity\nand hinders their sharing and re-use across the community. In this paper, we\nevaluate the two key Semantic Web Technologies, the Web Ontology Language and\nthe Resource Description Framework, for enabling computable representations of\nEHR-driven phenotyping algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 07:16:06 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Papez", "Vaclav", ""], ["Denaxas", "Spiros", ""], ["Hemingway", "Harry", ""]]}, {"id": "1707.07763", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi, Angelika Kimmig, Guy Van den Broeck, David Poole", "title": "Domain Recursion for Lifted Inference with Existential Quantifiers", "comments": "7 pages, 1 figure, Accepted at Statistical Relational AI (StarAI)\n  Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent work, we proved that the domain recursion inference rule makes\ndomain-lifted inference possible on several relational probability models\n(RPMs) for which the best known time complexity used to be exponential. We also\nidentified two classes of RPMs for which inference becomes domain lifted when\nusing domain recursion. These two classes subsume the largest lifted classes\nthat were previously known. In this paper, we show that domain recursion can\nalso be applied to models with existential quantifiers. Currently, all lifted\ninference algorithms assume that existential quantifiers have been removed in\npre-processing by Skolemization. We show that besides introducing potentially\ninconvenient negative weights, Skolemization may increase the time complexity\nof inference. We give two example models where domain recursion can replace\nSkolemization, avoids the need for dealing with negative numbers, and reduces\nthe time complexity of inference. These two examples may be interesting from\nthree theoretical aspects: 1- they provide a better and deeper understanding of\ndomain recursion and, in general, (lifted) inference, 2- they may serve as\nevidence that there are larger classes of models for which domain recursion can\nsatisfyingly replace Skolemization, and 3- they may serve as evidence that\nbetter Skolemization techniques exist.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 22:29:24 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 23:42:22 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Kimmig", "Angelika", ""], ["Broeck", "Guy Van den", ""], ["Poole", "David", ""]]}, {"id": "1707.07794", "submitter": "Parisa Kordjamshidi", "authors": "Parisa Kordjamshidi, Sameer Singh, Daniel Khashabi, Christos\n  Christodoulopoulos, Mark Summons, Saurabh Sinha, Dan Roth", "title": "Relational Learning and Feature Extraction by Querying over\n  Heterogeneous Information Networks", "comments": "Seventh International Workshop on Statistical Relational AI, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world systems need to operate on heterogeneous information networks\nthat consist of numerous interacting components of different types. Examples\ninclude systems that perform data analysis on biological information networks;\nsocial networks; and information extraction systems processing unstructured\ndata to convert raw text to knowledge graphs. Many previous works describe\nspecialized approaches to perform specific types of analysis, mining and\nlearning on such networks. In this work, we propose a unified framework\nconsisting of a data model -a graph with a first order schema along with a\ndeclarative language for constructing, querying and manipulating such networks\nin ways that facilitate relational and structured machine learning. In\nparticular, we provide an initial prototype for a relational and graph\ntraversal query language where queries are directly used as relational features\nfor structured machine learning models. Feature extraction is performed by\nmaking declarative graph traversal queries. Learning and inference models can\ndirectly operate on this relational representation and augment it with new data\nand knowledge that, in turn, is integrated seamlessly into the relational\nstructure to support new predictions. We demonstrate this system's capabilities\nby showcasing tasks in natural language processing and computational biology\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 02:32:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Kordjamshidi", "Parisa", ""], ["Singh", "Sameer", ""], ["Khashabi", "Daniel", ""], ["Christodoulopoulos", "Christos", ""], ["Summons", "Mark", ""], ["Sinha", "Saurabh", ""], ["Roth", "Dan", ""]]}, {"id": "1707.07907", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Ingmar Posner, Pieter Abbeel", "title": "Mutual Alignment Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training robots for operation in the real world is a complex, time consuming\nand potentially expensive task. Despite significant success of reinforcement\nlearning in games and simulations, research in real robot applications has not\nbeen able to match similar progress. While sample complexity can be reduced by\ntraining policies in simulation, such policies can perform sub-optimally on the\nreal platform given imperfect calibration of model dynamics. We present an\napproach -- supplemental to fine tuning on the real robot -- to further benefit\nfrom parallel access to a simulator during training and reduce sample\nrequirements on the real robot. The developed approach harnesses auxiliary\nrewards to guide the exploration for the real world agent based on the\nproficiency of the agent in simulation and vice versa. In this context, we\ndemonstrate empirically that the reciprocal alignment for both agents provides\nfurther benefit as the agent in simulation can adjust to optimize its behaviour\nfor states commonly visited by the real-world agent.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 10:43:35 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 08:51:42 GMT"}, {"version": "v3", "created": "Tue, 26 Sep 2017 18:26:06 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Posner", "Ingmar", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1707.07930", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke and Evangelos Kanoulas", "title": "Structural Regularities in Text-based Entity Vector Spaces", "comments": "ICTIR2017. Proceedings of the 3rd ACM International Conference on the\n  Theory of Information Retrieval. 2017", "journal-ref": null, "doi": "10.1145/3121050.3121066", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity retrieval is the task of finding entities such as people or products\nin response to a query, based solely on the textual documents they are\nassociated with. Recent semantic entity retrieval algorithms represent queries\nand experts in finite-dimensional vector spaces, where both are constructed\nfrom text sequences.\n  We investigate entity vector spaces and the degree to which they capture\nstructural regularities. Such vector spaces are constructed in an unsupervised\nmanner without explicit information about structural aspects. For concreteness,\nwe address these questions for a specific type of entity: experts in the\ncontext of expert finding. We discover how clusterings of experts correspond to\ncommittees in organizations, the ability of expert representations to encode\nthe co-author graph, and the degree to which they encode academic rank. We\ncompare latent, continuous representations created using methods based on\ndistributional semantics (LSI), topic models (LDA) and neural networks\n(word2vec, doc2vec, SERT). Vector spaces created using neural methods, such as\ndoc2vec and SERT, systematically perform better at clustering than LSI, LDA and\nword2vec. When it comes to encoding entity relations, SERT performs best.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 11:54:19 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1707.07999", "submitter": "Kuang Zhou", "authors": "Kuang Zhou (1), Arnaud Martin (2), Quan Pan (1) ((1) NPU (2) DRUID)", "title": "Evidence combination for a large number of sources", "comments": "2017 20th International Conference on Information Fusion (FUSION),\n  Jul 2017, Xi'an, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of belief functions is an effective tool to deal with the multiple\nuncertain information. In recent years, many evidence combination rules have\nbeen proposed in this framework, such as the conjunctive rule, the cautious\nrule, the PCR (Proportional Conflict Redistribution) rules and so on. These\nrules can be adopted for different types of sources. However, most of these\nrules are not applicable when the number of sources is large. This is due to\neither the complexity or the existence of an absorbing element (such as the\ntotal conflict mass function for the conjunctive-based rules when applied on\nunreliable evidence). In this paper, based on the assumption that the majority\nof sources are reliable, a combination rule for a large number of sources,\nnamed LNS (stands for Large Number of Sources), is proposed on the basis of a\nsimple idea: the more common ideas one source shares with others, the\nmorereliable the source is. This rule is adaptable for aggregating a large\nnumber of sources among which some are unreliable. It will keep the spirit of\nthe conjunctive rule to reinforce the belief on the focal elements with which\nthe sources are in agreement. The mass on the empty set will be kept as an\nindicator of the conflict. Moreover, it can be used to elicit the major opinion\namong the experts. The experimental results on synthetic mass functionsverify\nthat the rule can be effectively used to combine a large number of mass\nfunctions and to elicit the major opinion.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 13:52:40 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Zhou", "Kuang", "", "NPU"], ["Martin", "Arnaud", "", "DRUID"], ["Pan", "Quan", "", "NPU"]]}, {"id": "1707.08000", "submitter": "Gilles Falquet", "authors": "Sahar Aljalbout (1), Gilles Falquet (1) ((1) CUI)", "title": "Un mod\\`ele pour la repr\\'esentation des connaissances temporelles dans\n  les documents historiques", "comments": "in French, IC\\_2017 - 28\\`emes Journ\\'ees francophones d'Ing\\'enierie\n  des Connaissances, Jul 2017, Caen, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing and publishing the data of the historical sciences in the semantic\nweb is an interesting challenge in which the representation of temporal aspects\nplays a key role. We propose in this paper a model of temporal knowledge\nrepresentation adapted to work on historical documents. This model is based on\nthe notion of fluent that is represented in RDF graphs. We show how this model\nallows to represent the knowledge necessary to the historians and how it can be\nused to reason on this knowledge using the SWRL and SPARQL languages. This\nmodel is being used in a project to digitize, study and publish the manuscripts\nof linguist Ferdinand de Saussure.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 13:54:45 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Aljalbout", "Sahar", "", "CUI"], ["Falquet", "Gilles", "", "CUI"]]}, {"id": "1707.08029", "submitter": "Dietmar Jannach", "authors": "Dietmar Jannach and Gediminas Adomavicius", "title": "Price and Profit Awareness in Recommender Systems", "comments": "Presented at the 2017 Workshop on Value-Aware and Multi-Stakeholder\n  Recommendation (VAMS) collocated with ACM RecSys 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic research in the field of recommender systems mainly focuses on the\nproblem of maximizing the users' utility by trying to identify the most\nrelevant items for each user. However, such items are not necessarily the ones\nthat maximize the utility of the service provider (e.g., an online retailer) in\nterms of the business value, such as profit. One approach to increasing the\nproviders' utility is to incorporate purchase-oriented information, e.g., the\nprice, sales probabilities, and the resulting profit, into the recommendation\nalgorithms. In this paper we specifically focus on price- and profit-aware\nrecommender systems. We provide a brief overview of the relevant literature and\nuse numerical simulations to illustrate the potential business benefit of such\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 15:07:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Jannach", "Dietmar", ""], ["Adomavicius", "Gediminas", ""]]}, {"id": "1707.08114", "submitter": "Yu Zhang", "authors": "Yu Zhang and Qiang Yang", "title": "A Survey on Multi-Task Learning", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Task Learning (MTL) is a learning paradigm in machine learning and its\naim is to leverage useful information contained in multiple related tasks to\nhelp improve the generalization performance of all the tasks. In this paper, we\ngive a survey for MTL from the perspective of algorithmic modeling,\napplications and theoretical analyses. For algorithmic modeling, we give a\ndefinition of MTL and then classify different MTL algorithms into five\ncategories, including feature learning approach, low-rank approach, task\nclustering approach, task relation learning approach and decomposition approach\nas well as discussing the characteristics of each approach. In order to improve\nthe performance of learning tasks further, MTL can be combined with other\nlearning paradigms including semi-supervised learning, active learning,\nunsupervised learning, reinforcement learning, multi-view learning and\ngraphical models. When the number of tasks is large or the data dimensionality\nis high, we review online, parallel and distributed MTL models as well as\ndimensionality reduction and feature hashing to reveal their computational and\nstorage advantages. Many real-world applications use MTL to boost their\nperformance and we review representative works in this paper. Finally, we\npresent theoretical analyses and discuss several future directions for MTL.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 04:43:47 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 03:17:17 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 14:32:58 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1707.08151", "submitter": "Francisco Henrique Otte Vieira de Faria", "authors": "Francisco H. O. V. de Faria, Arthur C. Gusm\\~ao, Fabio G. Cozman,\n  Denis D. Mau\\'a", "title": "Speeding-up ProbLog's Parameter Learning", "comments": "StarAI - International Workshop on Statistical Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProbLog is a state-of-art combination of logic programming and probabilities;\nin particular ProbLog offers parameter learning through a variant of the EM\nalgorithm. However, the resulting learning algorithm is rather slow, even when\nthe data are complete. In this short paper we offer some insights that lead to\norders of magnitude improvements in ProbLog's parameter learning speed with\ncomplete data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 18:47:18 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 20:49:52 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["de Faria", "Francisco H. O. V.", ""], ["Gusm\u00e3o", "Arthur C.", ""], ["Cozman", "Fabio G.", ""], ["Mau\u00e1", "Denis D.", ""]]}, {"id": "1707.08167", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi, Rachid Guerraoui, Sebastien Rouault", "title": "On The Robustness of a Neural Network", "comments": "36th IEEE International Symposium on Reliable Distributed Systems 26\n  - 29 September 2017. Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of neural networks based machine learning and their\nusage in mission critical applications, voices are rising against the\n\\textit{black box} aspect of neural networks as it becomes crucial to\nunderstand their limits and capabilities. With the rise of neuromorphic\nhardware, it is even more critical to understand how a neural network, as a\ndistributed system, tolerates the failures of its computing nodes, neurons, and\nits communication channels, synapses. Experimentally assessing the robustness\nof neural networks involves the quixotic venture of testing all the possible\nfailures, on all the possible inputs, which ultimately hits a combinatorial\nexplosion for the first, and the impossibility to gather all the possible\ninputs for the second.\n  In this paper, we prove an upper bound on the expected error of the output\nwhen a subset of neurons crashes. This bound involves dependencies on the\nnetwork parameters that can be seen as being too pessimistic in the average\ncase. It involves a polynomial dependency on the Lipschitz coefficient of the\nneurons activation function, and an exponential dependency on the depth of the\nlayer where a failure occurs. We back up our theoretical results with\nexperiments illustrating the extent to which our prediction matches the\ndependencies between the network parameters and robustness. Our results show\nthat the robustness of neural networks to the average crash can be estimated\nwithout the need to neither test the network on all failure configurations, nor\naccess the training set used to train the network, both of which are\npractically impossible requirements.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 19:22:55 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 16:18:24 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Rouault", "Sebastien", ""]]}, {"id": "1707.08212", "submitter": "Ilker Yildirim", "authors": "Ilker Yildirim, Tobias Gerstenberg, Basil Saeed, Marc Toussaint, Josh\n  Tenenbaum", "title": "Physical problem solving: Joint planning with symbolic, geometric, and\n  dynamic constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new task that investigates how people interact\nwith and make judgments about towers of blocks. In Experiment~1, participants\nin the lab solved a series of problems in which they had to re-configure three\nblocks from an initial to a final configuration. We recorded whether they used\none hand or two hands to do so. In Experiment~2, we asked participants online\nto judge whether they think the person in the lab used one or two hands. The\nresults revealed a close correspondence between participants' actions in the\nlab, and the mental simulations of participants online. To explain\nparticipants' actions and mental simulations, we develop a model that plans\nover a symbolic representation of the situation, executes the plan using a\ngeometric solver, and checks the plan's feasibility by taking into account the\nphysical constraints of the scene. Our model explains participants' actions and\njudgments to a high degree of quantitative accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 20:44:18 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Yildirim", "Ilker", ""], ["Gerstenberg", "Tobias", ""], ["Saeed", "Basil", ""], ["Toussaint", "Marc", ""], ["Tenenbaum", "Josh", ""]]}, {"id": "1707.08234", "submitter": "Jeremy Morton", "authors": "Jeremy Morton, Tim A. Wheeler, Mykel J. Kochenderfer", "title": "Closed-Loop Policies for Operational Tests of Safety-Critical Systems", "comments": "12 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturers of safety-critical systems must make the case that their\nproduct is sufficiently safe for public deployment. Much of this case often\nrelies upon critical event outcomes from real-world testing, requiring\nmanufacturers to be strategic about how they allocate testing resources in\norder to maximize their chances of demonstrating system safety. This work\nframes the partially observable and belief-dependent problem of test scheduling\nas a Markov decision process, which can be solved efficiently to yield\nclosed-loop manufacturer testing policies. By solving for policies over a wide\nrange of problem formulations, we are able to provide high-level guidance for\nmanufacturers and regulators on issues relating to the testing of\nsafety-critical systems. This guidance spans an array of topics, including\ncircumstances under which manufacturers should continue testing despite\nobserved incidents, when manufacturers should test aggressively, and when\nregulators should increase or reduce the real-world testing requirements for an\nautonomous vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 21:48:58 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 18:20:38 GMT"}, {"version": "v3", "created": "Sat, 19 May 2018 20:34:54 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Morton", "Jeremy", ""], ["Wheeler", "Tim A.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1707.08250", "submitter": "EPTCS", "authors": "J\\'er\\^ome Lang (CNRS)", "title": "Proceedings Sixteenth Conference on Theoretical Aspects of Rationality\n  and Knowledge", "comments": null, "journal-ref": "EPTCS 251, 2017", "doi": "10.4204/EPTCS.251", "report-no": null, "categories": "cs.GT cs.AI cs.CR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume consists of papers presented at the Sixteenth Conference on\nTheoretical Aspects of Rationality and Knowledge (TARK) held at the University\nof Liverpool, UK, from July 24 to 26, 2017.\n  TARK conferences bring together researchers from a wide variety of fields,\nincluding Computer Science (especially, Artificial Intelligence, Cryptography,\nDistributed Computing), Economics (especially, Decision Theory, Game Theory,\nSocial Choice Theory), Linguistics, Philosophy (especially, Philosophical\nLogic), and Cognitive Psychology, in order to further understand the issues\ninvolving reasoning about rationality and knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 23:32:51 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Lang", "J\u00e9r\u00f4me", "", "CNRS"]]}, {"id": "1707.08255", "submitter": "Pavel Naumov", "authors": "Kaya Deuser and Pavel Naumov", "title": "Navigability with Imperfect Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article studies navigability of an autonomous agent in a maze where some\nrooms may be indistinguishable. In a previous work the authors have shown that\nthe properties of navigability in such a setting depend on whether an agent has\nperfect recall. Navigability by an agent with perfect recall is a transitive\nrelation and without is not transitive.\n  This article introduces a notion of restricted navigability and shows that a\ncertain form of transitivity holds for restricted navigability, even for an\nagent without perfect recall. The main technical result is a sound and complete\nlogical system describing the properties of restricted navigability.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 00:17:00 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Deuser", "Kaya", ""], ["Naumov", "Pavel", ""]]}, {"id": "1707.08309", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee", "title": "Probabilistic Graphical Models for Credibility Analysis in Evolving\n  Online Communities", "comments": "PhD thesis, Mar 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major hurdles preventing the full exploitation of information from\nonline communities is the widespread concern regarding the quality and\ncredibility of user-contributed content. Prior works in this domain operate on\na static snapshot of the community, making strong assumptions about the\nstructure of the data (e.g., relational tables), or consider only shallow\nfeatures for text classification.\n  To address the above limitations, we propose probabilistic graphical models\nthat can leverage the joint interplay between multiple factors in online\ncommunities --- like user interactions, community dynamics, and textual content\n--- to automatically assess the credibility of user-contributed online content,\nand the expertise of users and their evolution with user-interpretable\nexplanation. To this end, we devise new models based on Conditional Random\nFields for different settings like incorporating partial expert knowledge for\nsemi-supervised learning, and handling discrete labels as well as numeric\nratings for fine-grained analysis. This enables applications such as extracting\nreliable side-effects of drugs from user-contributed posts in healthforums, and\nidentifying credible content in news communities.\n  Online communities are dynamic, as users join and leave, adapt to evolving\ntrends, and mature over time. To capture this dynamics, we propose generative\nmodels based on Hidden Markov Model, Latent Dirichlet Allocation, and Brownian\nMotion to trace the continuous evolution of user expertise and their language\nmodel over time. This allows us to identify expert users and credible content\njointly over time, improving state-of-the-art recommender systems by explicitly\nconsidering the maturity of users. This also enables applications such as\nidentifying helpful product reviews, and detecting fake and anomalous reviews\nwith limited information.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 07:41:27 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Mukherjee", "Subhabrata", ""]]}, {"id": "1707.08316", "submitter": "Raksha Kumaraswamy", "authors": "Lei Le, Raksha Kumaraswamy, Martha White", "title": "Learning Sparse Representations in Reinforcement Learning with Sparse\n  Coding", "comments": "6(+1) pages, 2 figures, International Joint Conference on Artificial\n  Intelligence 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of representation learning approaches have been investigated for\nreinforcement learning; much less attention, however, has been given to\ninvestigating the utility of sparse coding. Outside of reinforcement learning,\nsparse coding representations have been widely used, with non-convex objectives\nthat result in discriminative representations. In this work, we develop a\nsupervised sparse coding objective for policy evaluation. Despite the\nnon-convexity of this objective, we prove that all local minima are global\nminima, making the approach amenable to simple optimization strategies. We\nempirically show that it is key to use a supervised objective, rather than the\nmore straightforward unsupervised sparse coding approach. We compare the\nlearned representations to a canonical fixed sparse representation, called\ntile-coding, demonstrating that the sparse coding representation outperforms a\nwide variety of tilecoding representations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 08:23:04 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Le", "Lei", ""], ["Kumaraswamy", "Raksha", ""], ["White", "Martha", ""]]}, {"id": "1707.08342", "submitter": "Yann Dauxais", "authors": "Thomas Guyet (1), Andr\\'e Happe, Yann Dauxais (2) ((1) LACODAM, (2)\n  UR1)", "title": "Declarative Sequential Pattern Mining of Care Pathways", "comments": null, "journal-ref": "Conference on Artificial Intelligence in Medicine in Europe, Jun\n  2017, Vienna, Austria. 24, pp.1161 - 266, 2017", "doi": "10.1002/pds.3879", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential pattern mining algorithms are widely used to explore care pathways\ndatabase, but they generate a deluge of patterns, mostly redundant or useless.\nClinicians need tools to express complex mining queries in order to generate\nless but more significant patterns. These algorithms are not versatile enough\nto answer complex clinician queries. This article proposes to apply a\ndeclarative pattern mining approach based on Answer Set Programming paradigm.\nIt is exemplified by a pharmaco-epidemiological study investigating the\npossible association between hospitalization for seizure and antiepileptic drug\nswitch from a french medico-administrative database.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 09:49:21 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Guyet", "Thomas", ""], ["Happe", "Andr\u00e9", ""], ["Dauxais", "Yann", ""]]}, {"id": "1707.08418", "submitter": "Salma Ben", "authors": "Salma Ben Dhaou (LARODEC, DRUID), Kuang Zhou (NPU), Mouloud Kharoune\n  (DRUID), Arnaud Martin (DRUID), Boutheina Ben Yaghlane (LARODEC)", "title": "The Advantage of Evidential Attributes in Social Networks", "comments": "20th International Conference on Information Fusion, Jul 2017, Xi'an,\n  China", "journal-ref": "20th International Conference on Information Fusion, Jul 2017,\n  Xi'an, China. 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there are many approaches designed for the task of detecting\ncommunities in social networks. Among them, some methods only consider the\ntopological graph structure, while others take use of both the graph structure\nand the node attributes. In real-world networks, there are many uncertain and\nnoisy attributes in the graph. In this paper, we will present how we detect\ncommunities in graphs with uncertain attributes in the first step. The\nnumerical, probabilistic as well as evidential attributes are generated\naccording to the graph structure. In the second step, some noise will be added\nto the attributes. We perform experiments on graphs with different types of\nattributes and compare the detection results in terms of the Normalized Mutual\nInformation (NMI) values. The experimental results show that the clustering\nwith evidential attributes gives better results comparing to those with\nprobabilistic and numerical attributes. This illustrates the advantages of\nevidential attributes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 13:04:42 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 14:20:34 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Dhaou", "Salma Ben", "", "LARODEC, DRUID"], ["Zhou", "Kuang", "", "NPU"], ["Kharoune", "Mouloud", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"], ["Yaghlane", "Boutheina Ben", "", "LARODEC"]]}, {"id": "1707.08454", "submitter": "Thomas Lef\\`evre", "authors": "Vincent Laugier (1,2), Eric Stindel (3), Alcibiade Lichterowicz (1),\n  S\\'everine Ansart (3) and Thomas Lef\\`evre (4,5) ((1) Tekliko SARL - 362,\n  chemin de la Bosque Antonelle, France, (2) Tekliko Pte Ltd - 100, Singapore,\n  (3) Laboratory of Medical Information Processing (LaTIM - INSERM UMR 1101),\n  France, (4) Department of forensic medicine, H\\^opital Jean Verdier APHP,\n  France, (5) IRIS - Institut de Recherches Interdisciplinaires sur les enjeux\n  Sociaux, INSERM, CNRS, EHESS, Universit\\'e Paris 13, France)", "title": "Making the best of data derived from a daily practice in clinical legal\n  medicine for research and practice - the example of Spe3dLab", "comments": "15 pages, 3 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forensic science suffers from a lack of studies with high-quality design,\nsuch as randomized controlled trials (RCT). Evidence in forensic science may be\nof insufficient quality, which is a major concern. Results from RCT are\ncriticized for providing artificial results that are not useful in real life\nand unfit for individualized prescription. Various sources of collected data\n(e.g. data collected in routine practice) could be exploited for distinct\ngoals. Obstacles remain before such data can be practically accessed and used,\nincluding technical issues. We present an easy-to-use software dedicated to\ninnovative data analyses for practitioners and researchers. We provide 2\nexamples in forensics. Spe3dLab has been developed by 3 French teams: a\nbioinformatics laboratory (LaTIM), a private partner (Tekliko) and a department\nof forensic medicine (Jean Verdier Hospital). It was designed to be open\nsource, relying on documented and maintained libraries, query-oriented and\ncapable of handling the entire data process from capture to export of best\npredictive models for their integration in information systems. Spe3dLab was\nused for 2 specific forensics applications: i) the search for multiple causal\nfactors and ii) the best predictive model of the functional impairment (total\nincapacity to work, TIW) of assault survivors. 2,892 patients were included\nover a 6-month period. Time to evaluation was the only direct cause identified\nfor TIW, and victim category was an indirect cause. The specificity and\nsensitivity of the predictive model were 99.9% and 90%, respectively. Spe3dLab\nis a quick and efficient tool for accessing observational, routinely collected\ndata and performing innovative analyses. Analyses can be exported for\nvalidation and routine use by practitioners, e.g., for computer-aided\nevaluation of complex problems. It can provide a fully integrated solution for\nindividualized medicine.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:27:46 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Laugier", "Vincent", ""], ["Stindel", "Eric", ""], ["Lichterowicz", "Alcibiade", ""], ["Ansart", "S\u00e9verine", ""], ["Lef\u00e8vre", "Thomas", ""]]}, {"id": "1707.08468", "submitter": "Rafael Pe\\~naloza", "authors": "Alessandro Artale, Enrico Franconi, Rafael Pe\\~naloza and Francesco\n  Sportelli", "title": "A Decidable Very Expressive Description Logic for Databases (Extended\n  Version)", "comments": "20 pages. Extended version of paper appearing in the International\n  Semantic Web Conference (ISWC 2017). arXiv admin note: text overlap with\n  arXiv:1604.00799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce $\\mathcal{DLR}^+$, an extension of the n-ary propositionally\nclosed description logic $\\mathcal{DLR}$ to deal with attribute-labelled tuples\n(generalising the positional notation), projections of relations, and global\nand local objectification of relations, able to express inclusion, functional,\nkey, and external uniqueness dependencies. The logic is equipped with both TBox\nand ABox axioms. We show how a simple syntactic restriction on the appearance\nof projections sharing common attributes in a $\\mathcal{DLR}^+$ knowledge base\nmakes reasoning in the language decidable with the same computational\ncomplexity as $\\mathcal{DLR}$. The obtained $\\mathcal{DLR}^\\pm$ n-ary\ndescription logic is able to encode more thoroughly conceptual data models such\nas EER, UML, and ORM.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 12:46:24 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Artale", "Alessandro", ""], ["Franconi", "Enrico", ""], ["Pe\u00f1aloza", "Rafael", ""], ["Sportelli", "Francesco", ""]]}, {"id": "1707.08470", "submitter": "Amit Sheth", "authors": "Sujan Perera, Pablo N. Mendes, Adarsh Alex, Amit Sheth, Krishnaprasad\n  Thirunarayan", "title": "Implicit Entity Linking in Tweets", "comments": "This paper was accepted at the Extended Semantic Web Conference 2016\n  as a full research track paper", "journal-ref": null, "doi": "10.1007/978-3-319-34129-3_8", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, Twitter has become one of the largest communication platforms\nproviding key data to various applications such as brand monitoring, trend\ndetection, among others. Entity linking is one of the major tasks in natural\nlanguage understanding from tweets and it associates entity mentions in text to\ncorresponding entries in knowledge bases in order to provide unambiguous\ninterpretation and additional con- text. State-of-the-art techniques have\nfocused on linking explicitly mentioned entities in tweets with reasonable\nsuccess. However, we argue that in addition to explicit mentions i.e. The movie\nGravity was more ex- pensive than the mars orbiter mission entities (movie\nGravity) can also be mentioned implicitly i.e. This new space movie is crazy.\nyou must watch it!. This paper introduces the problem of implicit entity\nlinking in tweets. We propose an approach that models the entities by\nexploiting their factual and contextual knowledge. We demonstrate how to use\nthese models to perform implicit entity linking on a ground truth dataset with\n397 tweets from two domains, namely, Movie and Book. Specifically, we show: 1)\nthe importance of linking implicit entities and its value addition to the\nstandard entity linking task, and 2) the importance of exploiting contextual\nknowledge associated with an entity for linking their implicit mentions. We\nalso make the ground truth dataset publicly available to foster the research in\nthis new research area.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 14:36:58 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Perera", "Sujan", ""], ["Mendes", "Pablo N.", ""], ["Alex", "Adarsh", ""], ["Sheth", "Amit", ""], ["Thirunarayan", "Krishnaprasad", ""]]}, {"id": "1707.08475", "submitter": "Irina Higgins", "authors": "Irina Higgins, Arka Pal, Andrei A. Rusu, Loic Matthey, Christopher P\n  Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, Alexander\n  Lerchner", "title": "DARLA: Improving Zero-Shot Transfer in Reinforcement Learning", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is an important open problem in deep reinforcement learning\n(RL). In many scenarios of interest data is hard to obtain, so agents may learn\na source policy in a setting where data is readily available, with the hope\nthat it generalises well to the target domain. We propose a new multi-stage RL\nagent, DARLA (DisentAngled Representation Learning Agent), which learns to see\nbefore learning to act. DARLA's vision is based on learning a disentangled\nrepresentation of the observed environment. Once DARLA can see, it is able to\nacquire source policies that are robust to many domain shifts - even with no\naccess to the target domain. DARLA significantly outperforms conventional\nbaselines in zero-shot domain adaptation scenarios, an effect that holds across\na variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms\n(DQN, A3C and EC).\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 14:50:51 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 16:51:02 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Higgins", "Irina", ""], ["Pal", "Arka", ""], ["Rusu", "Andrei A.", ""], ["Matthey", "Loic", ""], ["Burgess", "Christopher P", ""], ["Pritzel", "Alexander", ""], ["Botvinick", "Matthew", ""], ["Blundell", "Charles", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1707.08476", "submitter": "Roman Yampolskiy", "authors": "James Babcock, Janos Kramar, Roman V. Yampolskiy", "title": "Guidelines for Artificial Intelligence Containment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With almost daily improvements in capabilities of artificial intelligence it\nis more important than ever to develop safety software for use by the AI\nresearch community. Building on our previous work on AI Containment Problem we\npropose a number of guidelines which should help AI safety researchers to\ndevelop reliable sandboxing software for intelligent programs of all levels.\nSuch safety container software will make it possible to study and analyze\nintelligent artificial agent while maintaining certain level of safety against\ninformation leakage, social engineering attacks and cyberattacks from within\nthe container.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 18:33:18 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Babcock", "James", ""], ["Kramar", "Janos", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1707.08559", "submitter": "Cheng-Yang Fu", "authors": "Cheng-Yang Fu, Joon Lee, Mohit Bansal, Alexander C. Berg", "title": "Video Highlight Prediction Using Audience Chat Reactions", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sports channel video portals offer an exciting domain for research on\nmultimodal, multilingual analysis. We present methods addressing the problem of\nautomatic video highlight prediction based on joint visual features and textual\nanalysis of the real-world audience discourse with complex slang, in both\nEnglish and traditional Chinese. We present a novel dataset based on League of\nLegends championships recorded from North American and Taiwanese Twitch.tv\nchannels (will be released for further research), and demonstrate strong\nresults on these using multimodal, character-level CNN-RNN model architectures.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 17:44:38 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Fu", "Cheng-Yang", ""], ["Lee", "Joon", ""], ["Bansal", "Mohit", ""], ["Berg", "Alexander C.", ""]]}, {"id": "1707.08616", "submitter": "Mark Riedl", "authors": "Brent Harrison, Upol Ehsan, Mark O. Riedl", "title": "Guiding Reinforcement Learning Exploration Using Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a technique to use natural language to help\nreinforcement learning generalize to unseen environments. This technique uses\nneural machine translation, specifically the use of encoder-decoder networks,\nto learn associations between natural language behavior descriptions and\nstate-action information. We then use this learned model to guide agent\nexploration using a modified version of policy shaping to make it more\neffective at learning in unseen environments. We evaluate this technique using\nthe popular arcade game, Frogger, under ideal and non-ideal conditions. This\nevaluation shows that our modified policy shaping algorithm improves over a\nQ-learning agent as well as a baseline version of policy shaping.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 19:23:54 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 02:06:26 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Harrison", "Brent", ""], ["Ehsan", "Upol", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1707.08626", "submitter": "Can Pu", "authors": "Can Pu, Nanbo Li, Robert B Fisher", "title": "Robust Rigid Point Registration based on Convolution of Adaptive\n  Gaussian Mixture Models", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching 3D rigid point clouds in complex environments robustly and\naccurately is still a core technique used in many applications. This paper\nproposes a new architecture combining error estimation from sample covariances\nand dual global probability alignment based on the convolution of adaptive\nGaussian Mixture Models (GMM) from point clouds. Firstly, a novel adaptive GMM\nis defined using probability distributions from the corresponding points. Then\nrigid point cloud alignment is performed by maximizing the global probability\nfrom the convolution of dual adaptive GMMs in the whole 2D or 3D space, which\ncan be efficiently optimized and has a large zone of accurate convergence.\nThousands of trials have been conducted on 200 models from public 2D and 3D\ndatasets to demonstrate superior robustness and accuracy in complex\nenvironments with unpredictable noise, outliers, occlusion, initial rotation,\nshape and missing points.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 20:06:38 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Pu", "Can", ""], ["Li", "Nanbo", ""], ["Fisher", "Robert B", ""]]}, {"id": "1707.08668", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Edward C. Williams, Dilip Arumugam, Mina Rhee,\n  Nakul Gopalan, Lawson L. S. Wong, and Stefanie Tellex", "title": "A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting\n  Action-Oriented and Goal-Oriented Instructions", "comments": "Accepted at the 1st Workshop on Language Grounding for Robotics at\n  ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots operating alongside humans in diverse, stochastic environments must be\nable to accurately interpret natural language commands. These instructions\noften fall into one of two categories: those that specify a goal condition or\ntarget state, and those that specify explicit actions, or how to perform a\ngiven task. Recent approaches have used reward functions as a semantic\nrepresentation of goal-based commands, which allows for the use of a\nstate-of-the-art planner to find a policy for the given task. However, these\nreward functions cannot be directly used to represent action-oriented commands.\nWe introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding\nNetwork (DRAGGN), for task grounding and execution that handles natural\nlanguage from either category as input, and generalizes to unseen environments.\nOur robot-simulation results demonstrate that a system successfully\ninterpreting both goal-oriented and action-oriented task specifications brings\nus closer to robust natural language understanding for human-robot interaction.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 23:57:29 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Williams", "Edward C.", ""], ["Arumugam", "Dilip", ""], ["Rhee", "Mina", ""], ["Gopalan", "Nakul", ""], ["Wong", "Lawson L. S.", ""], ["Tellex", "Stefanie", ""]]}, {"id": "1707.08704", "submitter": "Rodrigo de Salvo Braz", "authors": "Gabriel Azevedo Ferreira, Quentin Bertrand, Charles Maussion, Rodrigo\n  de Salvo Braz", "title": "Anytime Exact Belief Propagation", "comments": "Submission to StaRAI-17 workshop at UAI-17 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical Relational Models and, more recently, Probabilistic Programming,\nhave been making strides towards an integration of logic and probabilistic\nreasoning. A natural expectation for this project is that a probabilistic logic\nreasoning algorithm reduces to a logic reasoning algorithm when provided a\nmodel that only involves 0-1 probabilities, exhibiting all the advantages of\nlogic reasoning such as short-circuiting, intelligibility, and the ability to\nprovide proof trees for a query answer. In fact, we can take this further and\nrequire that these characteristics be present even for probabilistic models\nwith probabilities \\emph{near} 0 and 1, with graceful degradation as the model\nbecomes more uncertain. We also seek inference that has amortized constant time\ncomplexity on a model's size (even if still exponential in the induced width of\na more directly relevant portion of it) so that it can be applied to huge\nknowledge bases of which only a relatively small portion is relevant to typical\nqueries. We believe that, among the probabilistic reasoning algorithms, Belief\nPropagation is the most similar to logic reasoning: messages are propagated\namong neighboring variables, and the paths of message-passing are similar to\nproof trees. However, Belief Propagation is either only applicable to tree\nmodels, or approximate (and without guarantees) for precision and convergence.\nIn this paper we present work in progress on an Anytime Exact Belief\nPropagation algorithm that is very similar to Belief Propagation but is exact\neven for graphical models with cycles, while exhibiting soft short-circuiting,\namortized constant time complexity in the model size, and which can provide\nprobabilistic proof trees.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 04:31:34 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Ferreira", "Gabriel Azevedo", ""], ["Bertrand", "Quentin", ""], ["Maussion", "Charles", ""], ["Braz", "Rodrigo de Salvo", ""]]}, {"id": "1707.08734", "submitter": "EPTCS", "authors": "Krzysztof R. Apt (CWI), Dominik Wojtczak (University of Liverpool)", "title": "Common Knowledge in a Logic of Gossips", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 10-27", "doi": "10.4204/EPTCS.251.2", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip protocols aim at arriving, by means of point-to-point or group\ncommunications, at a situation in which all the agents know each other secrets.\nRecently a number of authors studied distributed epistemic gossip protocols.\nThese protocols use as guards formulas from a simple epistemic logic, which\nmakes their analysis and verification substantially easier.\n  We study here common knowledge in the context of such a logic. First, we\nanalyze when it can be reduced to iterated knowledge. Then we show that the\nsemantics and truth for formulas without nested common knowledge operator are\ndecidable. This implies that implementability, partial correctness and\ntermination of distributed epistemic gossip protocols that use non-nested\ncommon knowledge operator is decidable, as well. Given that common knowledge is\nequivalent to an infinite conjunction of nested knowledge, these results are\nnon-trivial generalizations of the corresponding decidability results for the\noriginal epistemic logic, established in (Apt & Wojtczak, 2016).\n  K. R. Apt & D. Wojtczak (2016): On Decidability of a Logic of Gossips. In\nProc. of JELIA 2016, pp. 18-33, doi:10.1007/ 978-3-319-48758-8_2.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:45:05 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Apt", "Krzysztof R.", "", "CWI"], ["Wojtczak", "Dominik", "", "University of Liverpool"]]}, {"id": "1707.08735", "submitter": "EPTCS", "authors": "Francesco Belardinelli (Labortoire IBISC, UEVE and IRIT Toulouse),\n  Hans van Ditmarsch (LORIA \\^A-- CNRS, Universit\\'e de Lorraine,\n  Vandoeuvre-l\\`es-Nancy, France), Wiebe van der Hoek (Department of Computing,\n  University of Liverpool, Liverpool, UK)", "title": "A Logic for Global and Local Announcements", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 28-42", "doi": "10.4204/EPTCS.251.3", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce {\\em global and local announcement logic} (GLAL),\na dynamic epistemic logic with two distinct announcement operators --\n$[\\phi]^+_A$ and $[\\phi]^-_A$ indexed to a subset $A$ of the set $Ag$ of all\nagents -- for global and local announcements respectively. The boundary case\n$[\\phi]^+_{Ag}$ corresponds to the public announcement of $\\phi$, as known from\nthe literature. Unlike standard public announcements, which are {\\em model\ntransformers}, the global and local announcements are {\\em pointed model\ntransformers}. In particular, the update induced by the announcement may be\ndifferent in different states of the model. Therefore, the resulting\ncomputations are trees of models, rather than the typical sequences. A\nconsequence of our semantics is that modally bisimilar states may be\ndistinguished in our logic. Then, we provide a stronger notion of bisimilarity\nand we show that it preserves modal equivalence in GLAL. Additionally, we show\nthat GLAL is strictly more expressive than public announcement logic with\ncommon knowledge. We prove a wide range of validities for GLAL involving the\ninteraction between dynamics and knowledge, and show that the satisfiability\nproblem for GLAL is decidable. We illustrate the formal machinery by means of\ndetailed epistemic scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:45:23 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Belardinelli", "Francesco", "", "Labortoire IBISC, UEVE and IRIT Toulouse"], ["van Ditmarsch", "Hans", "", "LORIA \u00c2-- CNRS, Universit\u00e9 de Lorraine,\n  Vandoeuvre-l\u00e8s-Nancy, France"], ["van der Hoek", "Wiebe", "", "Department of Computing,\n  University of Liverpool, Liverpool, UK"]]}, {"id": "1707.08736", "submitter": "EPTCS", "authors": "Francesco Belardinelli (IBISC, Universit\\'e d'Evry and IRIT, CNRS,\n  Toulouse), Umberto Grandi (IRIT, University of Toulouse), Andreas Herzig\n  (IRIT, CNRS, Toulouse), Dominique Longin (IRIT, CNRS, Toulouse), Emiliano\n  Lorini (IRIT, CNRS, Toulouse), Arianna Novaro (IRIT, University of Toulouse),\n  Laurent Perrussel (IRIT, University of Toulouse)", "title": "Relaxing Exclusive Control in Boolean Games", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 43-56", "doi": "10.4204/EPTCS.251.4", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the typical framework for boolean games (BG) each player can change the\ntruth value of some propositional atoms, while attempting to make her goal\ntrue. In standard BG goals are propositional formulas, whereas in iterated BG\ngoals are formulas of Linear Temporal Logic. Both notions of BG are\ncharacterised by the fact that agents have exclusive control over their set of\natoms, meaning that no two agents can control the same atom. In the present\ncontribution we drop the exclusivity assumption and explore structures where an\natom can be controlled by multiple agents. We introduce Concurrent Game\nStructures with Shared Propositional Control (CGS-SPC) and show that they ac-\ncount for several classes of repeated games, including iterated boolean games,\ninfluence games, and aggregation games. Our main result shows that, as far as\nverification is concerned, CGS-SPC can be reduced to concurrent game structures\nwith exclusive control. This result provides a polynomial reduction for the\nmodel checking problem of specifications in Alternating-time Temporal Logic on\nCGS-SPC.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:45:44 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Belardinelli", "Francesco", "", "IBISC, Universit\u00e9 d'Evry and IRIT, CNRS,\n  Toulouse"], ["Grandi", "Umberto", "", "IRIT, University of Toulouse"], ["Herzig", "Andreas", "", "IRIT, CNRS, Toulouse"], ["Longin", "Dominique", "", "IRIT, CNRS, Toulouse"], ["Lorini", "Emiliano", "", "IRIT, CNRS, Toulouse"], ["Novaro", "Arianna", "", "IRIT, University of Toulouse"], ["Perrussel", "Laurent", "", "IRIT, University of Toulouse"]]}, {"id": "1707.08740", "submitter": "EPTCS", "authors": "Weiwei Chen (Sun Yat-sen University. ILLC, University of Amsterdam),\n  Ulle Endriss (ILLC, University of Amsterdam)", "title": "Preservation of Semantic Properties during the Aggregation of Abstract\n  Argumentation Frameworks", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 118-133", "doi": "10.4204/EPTCS.251.9", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An abstract argumentation framework can be used to model the argumentative\nstance of an agent at a high level of abstraction, by indicating for every pair\nof arguments that is being considered in a debate whether the first attacks the\nsecond. When modelling a group of agents engaged in a debate, we may wish to\naggregate their individual argumentation frameworks to obtain a single such\nframework that reflects the consensus of the group. Even when agents disagree\non many details, there may well be high-level agreement on important semantic\nproperties, such as the acceptability of a given argument. Using techniques\nfrom social choice theory, we analyse under what circumstances such semantic\nproperties agreed upon by the individual agents can be preserved under\naggregation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:47:12 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Chen", "Weiwei", "", "Sun Yat-sen University. ILLC, University of Amsterdam"], ["Endriss", "Ulle", "", "ILLC, University of Amsterdam"]]}, {"id": "1707.08741", "submitter": "EPTCS", "authors": "Zo\\'e Christoff (University of Bayreuth), Davide Grossi (University of\n  Liverpool)", "title": "Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 134-150", "doi": "10.4204/EPTCS.251.10", "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides an analysis of the voting method known as delegable proxy\nvoting, or liquid democracy. The analysis first positions liquid democracy\nwithin the theory of binary aggregation. It then focuses on two issues of the\nsystem: the occurrence of delegation cycles; and the effect of delegations on\nindividual rationality when voting on logically interdependent propositions. It\nfinally points to proposals on how the system may be modified in order to\naddress the above issues.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:47:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Christoff", "Zo\u00e9", "", "University of Bayreuth"], ["Grossi", "Davide", "", "University of\n  Liverpool"]]}, {"id": "1707.08750", "submitter": "EPTCS", "authors": "Joseph Y. Halpern (Cornell University), Ron van der Meyden (University\n  of New South Wales), Riccardo Pucella (Forrester Research)", "title": "An Epistemic Foundation for Authentication Logics (Extended Abstract)", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 306-323", "doi": "10.4204/EPTCS.251.21", "report-no": null, "categories": "cs.CR cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been many attempts, going back to BAN logic, to base\nreasoning about security protocols on epistemic notions, they have not been all\nthat successful. Arguably, this has been due to the particular logics chosen.\nWe present a simple logic based on the well-understood modal operators of\nknowledge, time, and probability, and show that it is able to handle issues\nthat have often been swept under the rug by other approaches, while being\nflexible enough to capture all the higher- level security notions that appear\nin BAN logic. Moreover, while still assuming that the knowledge operator allows\nfor unbounded computation, it can handle the fact that a computationally\nbounded agent cannot decrypt messages in a natural way, by distinguishing\nstrings and message terms. We demonstrate that our logic can capture BAN logic\nnotions by providing a translation of the BAN operators into our logic,\ncapturing belief by a form of probabilistic knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:50:40 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Halpern", "Joseph Y.", "", "Cornell University"], ["van der Meyden", "Ron", "", "University\n  of New South Wales"], ["Pucella", "Riccardo", "", "Forrester Research"]]}, {"id": "1707.08755", "submitter": "EPTCS", "authors": "Omer Lev (University of Toronto), Moshe Tennenholtz (Technion)", "title": "Group Recommendations: Axioms, Impossibilities, and Random Walks", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 382-397", "doi": "10.4204/EPTCS.251.28", "report-no": null, "categories": "cs.SI cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an axiomatic approach to group recommendations, in line of\nprevious work on the axiomatic treatment of trust-based recommendation systems,\nranking systems, and other foundational work on the axiomatic approach to\ninternet mechanisms in social choice settings. In group recommendations we wish\nto recommend to a group of agents, consisting of both opinionated and undecided\nmembers, a joint choice that would be acceptable to them. Such a system has\nmany applications, such as choosing a movie or a restaurant to go to with a\ngroup of friends, recommending games for online game players, & other communal\nactivities.\n  Our method utilizes a given social graph to extract information on the\nundecided, relying on the agents influencing them. We first show that a set of\nfairly natural desired requirements (a.k.a axioms) leads to an impossibility,\nrendering mutual satisfaction of them unreachable. However, we also show a\nmodified set of axioms that fully axiomatize a group variant of the random-walk\nrecommendation system, expanding a previous result from the individual\nrecommendation case.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:52:24 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Lev", "Omer", "", "University of Toronto"], ["Tennenholtz", "Moshe", "", "Technion"]]}, {"id": "1707.08759", "submitter": "EPTCS", "authors": "Pavel Naumov (Vassar College), Jia Tao (Lafayette College)", "title": "Together We Know How to Achieve: An Epistemic Logic of Know-How\n  (Extended Abstract)", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 441-453", "doi": "10.4204/EPTCS.251.32", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of a coalition strategy to achieve a goal does not necessarily\nmean that the coalition has enough information to know how to follow the\nstrategy. Neither does it mean that the coalition knows that such a strategy\nexists. The paper studies an interplay between the distributed knowledge,\ncoalition strategies, and coalition \"know-how\" strategies. The main technical\nresult is a sound and complete trimodal logical system that describes the\nproperties of this interplay.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:53:29 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Naumov", "Pavel", "", "Vassar College"], ["Tao", "Jia", "", "Lafayette College"]]}, {"id": "1707.08762", "submitter": "EPTCS", "authors": "Chenwei Shi (ILLC), Sonja Smets (ILLC), Fernando R.\n  Vel\\'azquez-Quesada (ILLC)", "title": "Argument-based Belief in Topological Structures", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 489-503", "doi": "10.4204/EPTCS.251.36", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper combines two studies: a topological semantics for epistemic\nnotions and abstract argumentation theory. In our combined setting, we use a\ntopological semantics to represent the structure of an agent's collection of\nevidence, and we use argumentation theory to single out the relevant sets of\nevidence through which a notion of beliefs grounded on arguments is defined. We\ndiscuss the formal properties of this newly defined notion, providing also a\nformal language with a matching modality together with a sound and complete\naxiom system for it. Despite the fact that our agent can combine her evidence\nin a 'rational' way (captured via the topological structure), argument-based\nbeliefs are not closed under conjunction. This illustrates the difference\nbetween an agent's reasoning abilities (i.e. the way she is able to combine her\navailable evidence) and the closure properties of her beliefs. We use this\npoint to argue for why the failure of closure under conjunction of belief\nshould not bear the burden of the failure of rationality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:54:17 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Shi", "Chenwei", "", "ILLC"], ["Smets", "Sonja", "", "ILLC"], ["Vel\u00e1zquez-Quesada", "Fernando R.", "", "ILLC"]]}, {"id": "1707.08763", "submitter": "EPTCS", "authors": "Rafal Urbaniak (Ghent University (Belgium) and University of Gdansk\n  (Poland))", "title": "Reconciling Bayesian Epistemology and Narration-based Approaches to\n  Judiciary Fact-finding", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 504-514", "doi": "10.4204/EPTCS.251.37", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal probabilism (LP) claims the degrees of conviction in juridical\nfact-finding are to be modeled exactly the way degrees of beliefs are modeled\nin standard bayesian epistemology. Classical legal probabilism (CLP) adds that\nthe conviction is justified if the credence in guilt given the evidence is\nabove an appropriate guilt probability threshold. The views are challenged on\nvarious counts, especially by the proponents of the so-called narrative\napproach, on which the fact-finders' decision is the result of a dynamic\ninterplay between competing narratives of what happened. I develop a way a\nbayesian epistemologist can make sense of the narrative approach. I do so by\nformulating a probabilistic framework for evaluating competing narrations in\nterms of formal explications of the informal evaluation criteria used in the\nnarrative approach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:54:35 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Urbaniak", "Rafal", "", "Ghent University"]]}, {"id": "1707.08764", "submitter": "EPTCS", "authors": "Yanjing Wang (Peking University)", "title": "A New Modal Framework for Epistemic Logic", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 515-534", "doi": "10.4204/EPTCS.251.38", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years witnessed a growing interest in non-standard epistemic logics of\nknowing whether, knowing how, knowing what, knowing why and so on. The new\nepistemic modalities introduced in those logics all share, in their semantics,\nthe general schema of $\\exists x \\Box \\phi$, e.g., knowing how to achieve\n$\\phi$ roughly means that there exists a way such that you know that it is a\nway to ensure that $\\phi$. Moreover, the resulting logics are decidable.\nInspired by those particular logics, in this work, we propose a very general\nand powerful framework based on quantifier-free predicate language extended by\na new modality $\\Box^x$, which packs exactly $\\exists x \\Box$ together. We show\nthat the resulting language, though much more expressive, shares many good\nproperties of the basic propositional modal logic over arbitrary models, such\nas finite-tree-model property and van Benthem-like characterization w.r.t.\\\nfirst-order modal logic. We axiomatize the logic over S5 frames with intuitive\naxioms to capture the interaction between $\\Box^x$ and know-that operator in an\nepistemic setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:54:50 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Wang", "Yanjing", "", "Peking University"]]}, {"id": "1707.08783", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi, Stefano Li Pira", "title": "Analysis of Italian Word Embeddings", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze the performances of two of the most used word\nembeddings algorithms, skip-gram and continuous bag of words on Italian\nlanguage. These algorithms have many hyper-parameter that have to be carefully\ntuned in order to obtain accurate word representation in vectorial space. We\nprovide an accurate analysis and an evaluation, showing what are the best\nconfiguration of parameters for specific tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 08:56:29 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 12:37:43 GMT"}, {"version": "v3", "created": "Fri, 11 Aug 2017 09:56:35 GMT"}, {"version": "v4", "created": "Thu, 30 Nov 2017 08:57:14 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Tripodi", "Rocco", ""], ["Pira", "Stefano Li", ""]]}, {"id": "1707.08817", "submitter": "Mel Vecerik", "authors": "Mel Vecerik, Todd Hester, Jonathan Scholz, Fumin Wang, Olivier\n  Pietquin, Bilal Piot, Nicolas Heess, Thomas Roth\\\"orl, Thomas Lampe, Martin\n  Riedmiller", "title": "Leveraging Demonstrations for Deep Reinforcement Learning on Robotics\n  Problems with Sparse Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general and model-free approach for Reinforcement Learning (RL)\non real robotics with sparse rewards. We build upon the Deep Deterministic\nPolicy Gradient (DDPG) algorithm to use demonstrations. Both demonstrations and\nactual interactions are used to fill a replay buffer and the sampling ratio\nbetween demonstrations and transitions is automatically tuned via a prioritized\nreplay mechanism. Typically, carefully engineered shaping rewards are required\nto enable the agents to efficiently explore on high dimensional control\nproblems such as robotics. They are also required for model-based acceleration\nmethods relying on local solvers such as iLQG (e.g. Guided Policy Search and\nNormalized Advantage Function). The demonstrations replace the need for\ncarefully engineered rewards, and reduce the exploration problem encountered by\nclassical RL approaches in these domains. Demonstrations are collected by a\nrobot kinesthetically force-controlled by a human demonstrator. Results on four\nsimulated insertion tasks show that DDPG from demonstrations out-performs DDPG,\nand does not require engineered rewards. Finally, we demonstrate the method on\na real robotics task consisting of inserting a clip (flexible object) into a\nrigid object.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 11:16:53 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 13:38:52 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vecerik", "Mel", ""], ["Hester", "Todd", ""], ["Scholz", "Jonathan", ""], ["Wang", "Fumin", ""], ["Pietquin", "Olivier", ""], ["Piot", "Bilal", ""], ["Heess", "Nicolas", ""], ["Roth\u00f6rl", "Thomas", ""], ["Lampe", "Thomas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1707.08852", "submitter": "Varun Gangal", "authors": "Dongyeop Kang, Varun Gangal, Ang Lu, Zheng Chen, Eduard Hovy", "title": "Detecting and Explaining Causes From Text For a Time Series Event", "comments": "Accepted at EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining underlying causes or effects about events is a challenging but\nvaluable task. We define a novel problem of generating explanations of a time\nseries event by (1) searching cause and effect relationships of the time series\nwith textual data and (2) constructing a connecting chain between them to\ngenerate an explanation. To detect causal features from text, we propose a\nnovel method based on the Granger causality of time series between features\nextracted from text such as N-grams, topics, sentiments, and their composition.\nThe generation of the sequence of causal entities requires a commonsense\ncausative knowledge base with efficient reasoning. To ensure good\ninterpretability and appropriate lexical usage we combine symbolic and neural\nrepresentations, using a neural reasoning algorithm trained on commonsense\ncausal tuples to predict the next cause step. Our quantitative and human\nanalysis show empirical evidence that our method successfully extracts\nmeaningful causality relationships between time series with textual features\nand generates appropriate explanation between them.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 13:14:57 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kang", "Dongyeop", ""], ["Gangal", "Varun", ""], ["Lu", "Ang", ""], ["Chen", "Zheng", ""], ["Hovy", "Eduard", ""]]}, {"id": "1707.08866", "submitter": "YiYao Huang", "authors": "Yi Yao Huang, William Yang Wang", "title": "Deep Residual Learning for Weakly-Supervised Relation Extraction", "comments": "Accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual learning (ResNet) is a new method for training very deep neural\nnetworks using identity map-ping for shortcut connections. ResNet has won the\nImageNet ILSVRC 2015 classification task, and achieved state-of-the-art\nperformances in many computer vision tasks. However, the effect of residual\nlearning on noisy natural language processing tasks is still not well\nunderstood. In this paper, we design a novel convolutional neural network (CNN)\nwith residual learning, and investigate its impacts on the task of distantly\nsupervised noisy relation extraction. In contradictory to popular beliefs that\nResNet only works well for very deep networks, we found that even with 9 layers\nof CNNs, using identity mapping could significantly improve the performance for\ndistantly-supervised relation extraction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 13:56:36 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Huang", "Yi Yao", ""], ["Wang", "William Yang", ""]]}, {"id": "1707.08879", "submitter": "Ankit Anand", "authors": "Ankit Anand, Ritesh Noothigattu, Parag Singla and Mausam", "title": "Non-Count Symmetries in Boolean & Multi-Valued Prob. Graphical Models", "comments": "9 pages, 5 figures", "journal-ref": "Proceedings of the 20th International Conference on Artificial\n  Intelligence and Statistics, PMLR 54: 1541-1549 (2017)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifted inference algorithms commonly exploit symmetries in a probabilistic\ngraphical model (PGM) for efficient inference. However, existing algorithms for\nBoolean-valued domains can identify only those pairs of states as symmetric, in\nwhich the number of ones and zeros match exactly (count symmetries). Moreover,\nalgorithms for lifted inference in multi-valued domains also compute a\nmulti-valued extension of count symmetries only. These algorithms miss many\nsymmetries in a domain. In this paper, we present first algorithms to compute\nnon-count symmetries in both Boolean-valued and multi-valued domains. Our\nmethods can also find symmetries between multi-valued variables that have\ndifferent domain cardinalities. The key insight in the algorithms is that they\nchange the unit of symmetry computation from a variable to a variable-value\n(VV) pair. Our experiments find that exploiting these symmetries in MCMC can\nobtain substantial computational gains over existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 14:28:04 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Anand", "Ankit", ""], ["Noothigattu", "Ritesh", ""], ["Singla", "Parag", ""], ["Mausam", "", ""]]}, {"id": "1707.08901", "submitter": "Alessandro Valitutti", "authors": "Alessandro Valitutti and Giuseppe Trautteur", "title": "Providing Self-Aware Systems with Reflexivity", "comments": "12 pages plus bibliography, appendices with code description, code of\n  the proof-of-concept implementation, and examples of execution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of self-aware systems inspired by ideas from\nhigher-order theories of consciousness. First, we discussed the crucial\ndistinction between introspection and reflexion. Then, we focus on\ncomputational reflexion as a mechanism by which a computer program can inspect\nits own code at every stage of the computation. Finally, we provide a formal\ndefinition and a proof-of-concept implementation of computational reflexion,\nviewed as an enriched form of program interpretation and a way to dynamically\n\"augment\" a computational process.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 15:05:27 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Valitutti", "Alessandro", ""], ["Trautteur", "Giuseppe", ""]]}, {"id": "1707.08912", "submitter": "Clark Alexander", "authors": "Clark Alexander, Sofya Akhmametyeva", "title": "A Family of Metrics for Clustering Algorithms", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the motivation for scoring clustering algorithms and a metric $M : A\n\\rightarrow \\mathbb{N}$ from the set of clustering algorithms to the natural\nnumbers which we realize as \\begin{equation} M(A) = \\sum_i \\alpha_i |f_i -\n\\beta_i|^{w_i} \\end{equation} where $\\alpha_i,\\beta_i,w_i$ are parameters used\nfor scoring the feature $f_i$, which is computed empirically.. We give a method\nby which one can score features such as stability, noise sensitivity, etc and\nderive the necessary parameters. We conclude by giving a sample set of scores.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 15:49:07 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Alexander", "Clark", ""], ["Akhmametyeva", "Sofya", ""]]}, {"id": "1707.09079", "submitter": "Anestis Fachantidis", "authors": "Anestis Fachantidis, Matthew E. Taylor, and Ioannis Vlahavas", "title": "Learning to Teach Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": "10.3390/make1010002", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the transfer learning model of action advice under a\nbudget. We focus on reinforcement learning teachers providing action advice to\nheterogeneous students playing the game of Pac-Man under a limited advice\nbudget. First, we examine several critical factors affecting advice quality in\nthis setting, such as the average performance of the teacher, its variance and\nthe importance of reward discounting in advising. The experiments show the\nnon-trivial importance of the coefficient of variation (CV) as a statistic for\nchoosing policies that generate advice. The CV statistic relates variance to\nthe corresponding mean. Second, the article studies policy learning for\ndistributing advice under a budget. Whereas most methods in the relevant\nliterature rely on heuristics for advice distribution we formulate the problem\nas a learning one and propose a novel RL algorithm capable of learning when to\nadvise, adapting to the student and the task at hand. Furthermore, we argue\nthat learning to advise under a budget is an instance of a more generic\nlearning problem: Constrained Exploitation Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 00:33:53 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Fachantidis", "Anestis", ""], ["Taylor", "Matthew E.", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "1707.09095", "submitter": "Tansu Alpcan", "authors": "Tansu Alpcan, Sarah M. Erfani, Christopher Leckie", "title": "Toward the Starting Line: A Systems Engineering Approach to Strong AI", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial General Intelligence (AGI) or Strong AI aims to create machines\nwith human-like or human-level intelligence, which is still a very ambitious\ngoal when compared to the existing computing and AI systems. After many hype\ncycles and lessons from AI history, it is clear that a big conceptual leap is\nneeded for crossing the starting line to kick-start mainstream AGI research.\nThis position paper aims to make a small conceptual contribution toward\nreaching that starting line. After a broad analysis of the AGI problem from\ndifferent perspectives, a system-theoretic and engineering-based research\napproach is introduced, which builds upon the existing mainstream AI and\nsystems foundations. Several promising cross-fertilization opportunities\nbetween systems disciplines and AI research are identified. Specific potential\nresearch directions are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 03:28:16 GMT"}, {"version": "v2", "created": "Wed, 18 Oct 2017 06:40:51 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Alpcan", "Tansu", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""]]}, {"id": "1707.09098", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Hao Li, Zhou Zhao, Bin Cao, Deng Cai, Xiaofei He", "title": "MEMEN: Multi-layer Embedding with Memory Networks for Machine\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension(MC) style question answering is a representative\nproblem in natural language processing. Previous methods rarely spend time on\nthe improvement of encoding layer, especially the embedding of syntactic\ninformation and name entity of the words, which are very crucial to the quality\nof encoding. Moreover, existing attention methods represent each query word as\na vector or use a single vector to represent the whole query sentence, neither\nof them can handle the proper weight of the key words in query sentence. In\nthis paper, we introduce a novel neural network architecture called Multi-layer\nEmbedding with Memory Network(MEMEN) for machine reading task. In the encoding\nlayer, we employ classic skip-gram model to the syntactic and semantic\ninformation of the words to train a new kind of embedding layer. We also\npropose a memory network of full-orientation matching of the query and passage\nto catch more pivotal information. Experiments show that our model has\ncompetitive results both from the perspectives of precision and efficiency in\nStanford Question Answering Dataset(SQuAD) among all published results and\nachieves the state-of-the-art results on TriviaQA dataset.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 03:41:18 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Pan", "Boyuan", ""], ["Li", "Hao", ""], ["Zhao", "Zhou", ""], ["Cao", "Bin", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1707.09198", "submitter": "Fengqi You", "authors": "Chao Ning and Fengqi You", "title": "Data-Driven Stochastic Robust Optimization: A General Computational\n  Framework and Algorithm for Optimization under Uncertainty in the Big Data\n  Era", "comments": null, "journal-ref": "Computers & Chemical Engineering, Volume 111, Pages 115-133, 4\n  March 2018,", "doi": "10.1016/j.compchemeng.2017.12.015", "report-no": null, "categories": "cs.LG cs.AI cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel data-driven stochastic robust optimization (DDSRO) framework is\nproposed for optimization under uncertainty leveraging labeled multi-class\nuncertainty data. Uncertainty data in large datasets are often collected from\nvarious conditions, which are encoded by class labels. Machine learning methods\nincluding Dirichlet process mixture model and maximum likelihood estimation are\nemployed for uncertainty modeling. A DDSRO framework is further proposed based\non the data-driven uncertainty model through a bi-level optimization structure.\nThe outer optimization problem follows a two-stage stochastic programming\napproach to optimize the expected objective across different data classes;\nadaptive robust optimization is nested as the inner problem to ensure the\nrobustness of the solution while maintaining computational tractability. A\ndecomposition-based algorithm is further developed to solve the resulting\nmulti-level optimization problem efficiently. Case studies on process network\ndesign and planning are presented to demonstrate the applicability of the\nproposed framework and algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 11:43:33 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 21:47:10 GMT"}, {"version": "v3", "created": "Thu, 12 Oct 2017 10:26:54 GMT"}, {"version": "v4", "created": "Fri, 29 Dec 2017 14:15:04 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Ning", "Chao", ""], ["You", "Fengqi", ""]]}, {"id": "1707.09219", "submitter": "Isabeau Pr\\'emont-Schwarz", "authors": "Isabeau Pr\\'emont-Schwarz, Alexander Ilin, Tele Hotloo Hao, Antti\n  Rasmus, Rinu Boney, Harri Valpola", "title": "Recurrent Ladder Networks", "comments": "9 pages, 9 figures, 7-page appendix, fixed fig 9 (c)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a recurrent extension of the Ladder networks whose structure is\nmotivated by the inference required in hierarchical latent variable models. We\ndemonstrate that the recurrent Ladder is able to handle a wide variety of\ncomplex learning tasks that benefit from iterative inference and temporal\nmodeling. The architecture shows close-to-optimal results on temporal modeling\nof video data, competitive results on music modeling, and improved perceptual\ngrouping based on higher order abstractions, such as stochastic textures and\nmotion cues. We present results for fully supervised, semi-supervised, and\nunsupervised tasks. The results suggest that the proposed architecture and\nprinciples are powerful tools for learning a hierarchy of abstractions,\nlearning iterative inference and handling temporal information.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 13:19:11 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 15:14:19 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 13:43:12 GMT"}, {"version": "v4", "created": "Mon, 18 Dec 2017 06:43:47 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Pr\u00e9mont-Schwarz", "Isabeau", ""], ["Ilin", "Alexander", ""], ["Hao", "Tele Hotloo", ""], ["Rasmus", "Antti", ""], ["Boney", "Rinu", ""], ["Valpola", "Harri", ""]]}, {"id": "1707.09324", "submitter": "Sylwia Polberg", "authors": "Sylwia Polberg and Anthony Hunter", "title": "Empirical Evaluation of Abstract Argumentation: Supporting the Need for\n  Bipolar and Probabilistic Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialogical argumentation it is often assumed that the involved parties\nalways correctly identify the intended statements posited by each other,\nrealize all of the associated relations, conform to the three acceptability\nstates (accepted, rejected, undecided), adjust their views when new and correct\ninformation comes in, and that a framework handling only attack relations is\nsufficient to represent their opinions. Although it is natural to make these\nassumptions as a starting point for further research, removing them or even\nacknowledging that such removal should happen is more challenging for some of\nthese concepts than for others. Probabilistic argumentation is one of the\napproaches that can be harnessed for more accurate user modelling. The\nepistemic approach allows us to represent how much a given argument is believed\nby a given person, offering us the possibility to express more than just three\nagreement states. It is equipped with a wide range of postulates, including\nthose that do not make any restrictions concerning how initial arguments should\nbe viewed, thus potentially being more adequate for handling beliefs of the\npeople that have not fully disclosed their opinions in comparison to Dung's\nsemantics. The constellation approach can be used to represent the views of\ndifferent people concerning the structure of the framework we are dealing with,\nincluding cases in which not all relations are acknowledged or when they are\nseen differently than intended. Finally, bipolar argumentation frameworks can\nbe used to express both positive and negative relations between arguments. In\nthis paper we describe the results of an experiment in which participants\njudged dialogues in terms of agreement and structure. We compare our findings\nwith the aforementioned assumptions as well as with the constellation and\nepistemic approaches to probabilistic argumentation and bipolar argumentation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 16:51:00 GMT"}, {"version": "v2", "created": "Fri, 8 Dec 2017 14:38:56 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Polberg", "Sylwia", ""], ["Hunter", "Anthony", ""]]}, {"id": "1707.09376", "submitter": "Blaz Meden", "authors": "Bla\\v{z} Meden, Refik Can Mall{\\i}, Sebastjan Fabijan, Haz{\\i}m Kemal\n  Ekenel, Vitomir \\v{S}truc, Peter Peer", "title": "Face Deidentification with Generative Deep Neural Networks", "comments": "IET Signal Processing Special Issue on Deidentification 2017", "journal-ref": null, "doi": "10.1049/iet-spr.2017.0049", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face deidentification is an active topic amongst privacy and security\nresearchers. Early deidentification methods relying on image blurring or\npixelization were replaced in recent years with techniques based on formal\nanonymity models that provide privacy guaranties and at the same time aim at\nretaining certain characteristics of the data even after deidentification. The\nlatter aspect is particularly important, as it allows to exploit the\ndeidentified data in applications for which identity information is irrelevant.\nIn this work we present a novel face deidentification pipeline, which ensures\nanonymity by synthesizing artificial surrogate faces using generative neural\nnetworks (GNNs). The generated faces are used to deidentify subjects in images\nor video, while preserving non-identity-related aspects of the data and\nconsequently enabling data utilization. Since generative networks are very\nadaptive and can utilize a diverse set of parameters (pertaining to the\nappearance of the generated output in terms of facial expressions, gender,\nrace, etc.), they represent a natural choice for the problem of face\ndeidentification. To demonstrate the feasibility of our approach, we perform\nexperiments using automated recognition tools and human annotators. Our results\nshow that the recognition performance on deidentified images is close to\nchance, suggesting that the deidentification process based on GNNs is highly\neffective.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 18:39:09 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Meden", "Bla\u017e", ""], ["Mall\u0131", "Refik Can", ""], ["Fabijan", "Sebastjan", ""], ["Ekenel", "Haz\u0131m Kemal", ""], ["\u0160truc", "Vitomir", ""], ["Peer", "Peter", ""]]}, {"id": "1707.09378", "submitter": "EPTCS", "authors": "Konstantin Genin (Carnegie Mellon University), Kevin T. Kelly\n  (Carnegie Mellon University)", "title": "The Topology of Statistical Verifiability", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 236-250", "doi": "10.4204/EPTCS.251.17", "report-no": null, "categories": "cs.LG cs.AI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological models of empirical and formal inquiry are increasingly\nprevalent. They have emerged in such diverse fields as domain theory [1, 16],\nformal learning theory [18], epistemology and philosophy of science [10, 15, 8,\n9, 2], statistics [6, 7] and modal logic [17, 4]. In those applications, open\nsets are typically interpreted as hypotheses deductively verifiable by true\npropositional information that rules out relevant possibilities. However, in\nstatistical data analysis, one routinely receives random samples logically\ncompatible with every statistical hypothesis. We bridge the gap between\npropositional and statistical data by solving for the unique topology on\nprobability measures in which the open sets are exactly the statistically\nverifiable hypotheses. Furthermore, we extend that result to a topological\ncharacterization of learnability in the limit from statistical data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:49:20 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Genin", "Konstantin", "", "Carnegie Mellon University"], ["Kelly", "Kevin T.", "", "Carnegie Mellon University"]]}, {"id": "1707.09405", "submitter": "Qifeng Chen", "authors": "Qifeng Chen and Vladlen Koltun", "title": "Photographic Image Synthesis with Cascaded Refinement Networks", "comments": "Published at the International Conference on Computer Vision (ICCV\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to synthesizing photographic images conditioned on\nsemantic layouts. Given a semantic label map, our approach produces an image\nwith photographic appearance that conforms to the input layout. The approach\nthus functions as a rendering engine that takes a two-dimensional semantic\nspecification of the scene and produces a corresponding photographic image.\nUnlike recent and contemporaneous work, our approach does not rely on\nadversarial training. We show that photographic images can be synthesized from\nsemantic layouts by a single feedforward network with appropriate structure,\ntrained end-to-end with a direct regression objective. The presented approach\nscales seamlessly to high resolutions; we demonstrate this by synthesizing\nphotographic images at 2-megapixel resolution, the full resolution of our\ntraining data. Extensive perceptual experiments on datasets of outdoor and\nindoor scenes demonstrate that images synthesized by the presented approach are\nconsiderably more realistic than alternative approaches. The results are shown\nin the supplementary video at https://youtu.be/0fhUJT21-bs\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 20:24:44 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Chen", "Qifeng", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1707.09422", "submitter": "Prasad Calyam", "authors": "Andrew Crutcher, Caleb Koch, Kyle Coleman, Jon Patman, Flavio\n  Esposito, Prasad Calyam", "title": "Hyperprofile-based Computation Offloading for Mobile Edge Networks", "comments": "5 pages, NSF REU Site publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies, researchers have developed various computation offloading\nframeworks for bringing cloud services closer to the user via edge networks.\nSpecifically, an edge device needs to offload computationally intensive tasks\nbecause of energy and processing constraints. These constraints present the\nchallenge of identifying which edge nodes should receive tasks to reduce\noverall resource consumption. We propose a unique solution to this problem\nwhich incorporates elements from Knowledge-Defined Networking (KDN) to make\nintelligent predictions about offloading costs based on historical data. Each\nserver instance can be represented in a multidimensional feature space where\neach dimension corresponds to a predicted metric. We compute features for a\n\"hyperprofile\" and position nodes based on the predicted costs of offloading a\nparticular task. We then perform a k-Nearest Neighbor (kNN) query within the\nhyperprofile to select nodes for offloading computation. This paper formalizes\nour hyperprofile-based solution and explores the viability of using machine\nlearning (ML) techniques to predict metrics useful for computation offloading.\nWe also investigate the effects of using different distance metrics for the\nqueries. Our results show various network metrics can be modeled accurately\nwith regression, and there are circumstances where kNN queries using Euclidean\ndistance as opposed to rectilinear distance is more favorable.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 21:28:45 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Crutcher", "Andrew", ""], ["Koch", "Caleb", ""], ["Coleman", "Kyle", ""], ["Patman", "Jon", ""], ["Esposito", "Flavio", ""], ["Calyam", "Prasad", ""]]}, {"id": "1707.09457", "submitter": "Kai-Wei Chang", "authors": "Jieyu Zhao and Tianlu Wang and Mark Yatskar and Vicente Ordonez and\n  Kai-Wei Chang", "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using\n  Corpus-level Constraints", "comments": "11 pages, published in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is increasingly being used to define rich visual recognition\nproblems with supporting image collections sourced from the web. Structured\nprediction models are used in these tasks to take advantage of correlations\nbetween co-occurring labels and visual input but risk inadvertently encoding\nsocial biases found in web corpora. In this work, we study data and models\nassociated with multilabel object classification and visual semantic role\nlabeling. We find that (a) datasets for these tasks contain significant gender\nbias and (b) models trained on these datasets further amplify existing bias.\nFor example, the activity cooking is over 33% more likely to involve females\nthan males in a training set, and a trained model further amplifies the\ndisparity to 68% at test time. We propose to inject corpus-level constraints\nfor calibrating existing structured prediction models and design an algorithm\nbased on Lagrangian relaxation for collective inference. Our method results in\nalmost no performance loss for the underlying recognition task but decreases\nthe magnitude of bias amplification by 47.5% and 40.5% for multilabel\nclassification and visual semantic role labeling, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 03:38:32 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Zhao", "Jieyu", ""], ["Wang", "Tianlu", ""], ["Yatskar", "Mark", ""], ["Ordonez", "Vicente", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1707.09487", "submitter": "Nikolaos K Tselios", "authors": "Nikolaos Tselios, Manolis Maragoudakis", "title": "Method and apparatus for automatic text input insertion in digital\n  devices with a restricted number of keys", "comments": "European patent office", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A device which contains number of symbol input keys, where the number of\navailable keys is less than the number of symbols of an alphabet of any given\nlanguage, screen, and dynamic reordering table of the symbols which are mapped\nonto those keys, according to a disambiguation method based on the previously\nentered symbols. The device incorporates a previously entered keystrokes\ntracking mechanism, and the key selected by the user detector, as well as a\nmechanism to select the dynamic symbol reordering mapped onto this key\naccording to the information contained to the reordering table. The reordering\ntable occurs from a disambiguation method which reorders the symbol appearance.\nThe reordering information occurs from Bayesian Belief network construction and\ntraining from text corpora of the specific language.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 09:39:17 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Tselios", "Nikolaos", ""], ["Maragoudakis", "Manolis", ""]]}, {"id": "1707.09585", "submitter": "Avi Ben-Cohen", "authors": "Avi Ben-Cohen, Eyal Klang, Stephen P. Raskin, Michal Marianne Amitai,\n  and Hayit Greenspan", "title": "Virtual PET Images from CT Data Using Deep Convolutional Networks:\n  Initial Results", "comments": "To be presented at SASHIMI2017: Simulation and Synthesis in Medical\n  Imaging, MICCAI 2017", "journal-ref": null, "doi": "10.1007/978-3-319-68127-6_6", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel system for PET estimation using CT scans. We\nexplore the use of fully convolutional networks (FCN) and conditional\ngenerative adversarial networks (GAN) to export PET data from CT data. Our\ndataset includes 25 pairs of PET and CT scans where 17 were used for training\nand 8 for testing. The system was tested for detection of malignant tumors in\nthe liver region. Initial results look promising showing high detection\nperformance with a TPR of 92.3% and FPR of 0.25 per case. Future work entails\nexpansion of the current system to the entire body using a much larger dataset.\nSuch a system can be used for tumor detection and drug treatment evaluation in\na CT-only environment instead of the expansive and radioactive PET-CT scan.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 06:43:42 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ben-Cohen", "Avi", ""], ["Klang", "Eyal", ""], ["Raskin", "Stephen P.", ""], ["Amitai", "Michal Marianne", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1707.09627", "submitter": "Kevin Ellis", "authors": "Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum", "title": "Learning to Infer Graphics Programs from Hand-Drawn Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a model that learns to convert simple hand drawings into\ngraphics programs written in a subset of \\LaTeX. The model combines techniques\nfrom deep learning and program synthesis. We learn a convolutional neural\nnetwork that proposes plausible drawing primitives that explain an image. These\ndrawing primitives are like a trace of the set of primitive commands issued by\na graphics program. We learn a model that uses program synthesis techniques to\nrecover a graphics program from that trace. These programs have constructs like\nvariable bindings, iterative loops, or simple kinds of conditionals. With a\ngraphics program in hand, we can correct errors made by the deep network,\nmeasure similarity between drawings by use of similar high-level geometric\nstructures, and extrapolate drawings. Taken together these results are a step\ntowards agents that induce useful, human-readable programs from perceptual\ninput.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 14:46:14 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 00:34:18 GMT"}, {"version": "v3", "created": "Tue, 29 Aug 2017 17:39:23 GMT"}, {"version": "v4", "created": "Sun, 5 Nov 2017 17:47:27 GMT"}, {"version": "v5", "created": "Fri, 26 Oct 2018 22:39:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Ellis", "Kevin", ""], ["Ritchie", "Daniel", ""], ["Solar-Lezama", "Armando", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1707.09661", "submitter": "Michael Cook", "authors": "Michael Cook", "title": "A Vision For Continuous Automated Game Design", "comments": "Published in the proceedings of the Experimental AI in Games workshop\n  at AIIDE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ANGELINA is an automated game design system which has previously been built\nas a single software block which designs games from start to finish. In this\npaper we outline a roadmap for the development of a new version of ANGELINA,\ndesigned to iterate on games in different ways to produce a continuous creative\nprocess that will improve the quality of its work, but more importantly improve\nthe perception of the software as being an independently creative piece of\nsoftware. We provide an initial report of the system's structure here as well\nas results from the first working module of the system.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jul 2017 19:53:40 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Cook", "Michael", ""]]}, {"id": "1707.09704", "submitter": "Liang Zhou", "authors": "Liang Zhou", "title": "Cost and Actual Causation", "comments": "37 pages, 2 Appendixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I propose the purpose our concept of actual causation serves is minimizing\nvarious cost in intervention practice. Actual causation has three features:\nnonredundant sufficiency, continuity and abnormality; these features correspond\nto the minimization of exploitative cost, exploratory cost and risk cost in\nintervention practice. Incorporating these three features, a definition of\nactual causation is given. I test the definition in 66 causal cases from actual\ncausation literature and show that this definition's application fit intuition\nbetter than some other causal modelling based definitions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 03:02:44 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Zhou", "Liang", ""]]}, {"id": "1707.09706", "submitter": "Jing Mei", "authors": "Jing Mei, Eryu Xia, Xiang Li, Guotong Xie", "title": "Developing Knowledge-enhanced Chronic Disease Risk Prediction Models\n  from Regional EHR Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine requires the precision disease risk prediction models. In\nliterature, there have been a lot well-established (inter-)national risk\nmodels, but when applying them into the local population, the prediction\nperformance becomes unsatisfactory. To address the localization issue, this\npaper exploits the way to develop knowledge-enhanced localized risk models. On\nthe one hand, we tune models by learning from regional Electronic Health Record\n(EHR) repositories, and on the other hand, we propose knowledge injection into\nthe EHR data learning process. For experiments, we leverage the Pooled Cohort\nEquations (PCE, as recommended in ACC/AHA guidelines to estimate the risk of\nASCVD) to develop a localized ASCVD risk prediction model in diabetes. The\nexperimental results show that, if directly using the PCE algorithm on our\ncohort, the AUC is only 0.653, while our knowledge-enhanced localized risk\nmodel can achieve higher prediction performance with AUC of 0.723 (improved by\n10.7%).\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 03:12:05 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Mei", "Jing", ""], ["Xia", "Eryu", ""], ["Li", "Xiang", ""], ["Xie", "Guotong", ""]]}, {"id": "1707.09790", "submitter": "Carsten Eickhoff", "authors": "Zsolt Mezei, Carsten Eickhoff", "title": "Evaluating Music Recommender Systems for Groups", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation to groups of users is a challenging and currently only\npassingly studied task. Especially the evaluation aspect often appears ad-hoc\nand instead of truly evaluating on groups of users, synthesizes groups by\nmerging individual preferences.\n  In this paper, we present a user study, recording the individual and shared\npreferences of actual groups of participants, resulting in a robust,\nstandardized evaluation benchmark. Using this benchmarking dataset, that we\nshare with the research community, we compare the respective performance of a\nwide range of music group recommendation techniques proposed in the\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 10:00:55 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Mezei", "Zsolt", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1707.09899", "submitter": "Ashwinkumar Ganesan", "authors": "Prutha Date, Ashwinkumar Ganesan, Tim Oates", "title": "Fashioning with Networks: Neural Style Transfer to Design Clothes", "comments": "ML4Fashion 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have been highly successful in performing a\nhost of computer vision tasks such as object recognition, object detection,\nimage segmentation and texture synthesis. In 2015, Gatys et. al [7] show how\nthe style of a painter can be extracted from an image of the painting and\napplied to another normal photograph, thus recreating the photo in the style of\nthe painter. The method has been successfully applied to a wide range of images\nand has since spawned multiple applications and mobile apps. In this paper, the\nneural style transfer algorithm is applied to fashion so as to synthesize new\ncustom clothes. We construct an approach to personalize and generate new custom\nclothes based on a users preference and by learning the users fashion choices\nfrom a limited set of clothes from their closet. The approach is evaluated by\nanalyzing the generated images of clothes and how well they align with the\nusers fashion style.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:54:11 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Date", "Prutha", ""], ["Ganesan", "Ashwinkumar", ""], ["Oates", "Tim", ""]]}, {"id": "1707.09938", "submitter": "Jong Chul Ye", "authors": "Eunhee Kang, Jaejun Yoo, and Jong Chul Ye", "title": "Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet\n  Residual Network", "comments": "This will appear in IEEE Transaction on Medical Imaging, a special\n  issue of Machine Learning for Image Reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\nare computationally expensive. To address this problem, we recently proposed a\ndeep convolutional neural network (CNN) for low-dose X-ray CT and won the\nsecond place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the\ntexture were not fully recovered. To address this problem, here we propose a\nnovel framelet-based denoising algorithm using wavelet residual network which\nsynergistically combines the expressive power of deep learning and the\nperformance guarantee from the framelet-based denoising algorithms. The new\nalgorithms were inspired by the recent interpretation of the deep convolutional\nneural network (CNN) as a cascaded convolution framelet signal representation.\nExtensive experimental results confirm that the proposed networks have\nsignificantly improved performance and preserves the detail texture of the\noriginal images.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 16:17:31 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 16:10:04 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 07:46:15 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Kang", "Eunhee", ""], ["Yoo", "Jaejun", ""], ["Ye", "Jong Chul", ""]]}]