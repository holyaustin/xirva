[{"id": "1606.00002", "submitter": "Hasan Dalman Dr", "authors": "Hasan Dalman", "title": "Uncertain programming model for multi-item solid transportation problem", "comments": null, "journal-ref": null, "doi": "10.1007/s13042-016-0538-7", "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an uncertain Multi-objective Multi-item Solid Transportation\nProblem (MMSTP) based on uncertainty theory is presented. In the model,\ntransportation costs, supplies, demands and conveyances parameters are taken to\nbe uncertain parameters. There are restrictions on some items and conveyances\nof the model. Therefore, some particular items cannot be transported by some\nexceptional conveyances. Using the advantage of uncertainty theory, the MMSTP\nis first converted into an equivalent deterministic MMSTP. By applying convex\ncombination method and minimizing distance function method, the deterministic\nMMSTP is reduced into single objective programming problems. Thus, both single\nobjective programming problems are solved using Maple 18.02 optimization\ntoolbox. Finally, a numerical example is given to illustrate the performance of\nthe models.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 21:32:48 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Dalman", "Hasan", ""]]}, {"id": "1606.00058", "submitter": "Aleksander Lodwich", "authors": "Aleksander Lodwich", "title": "How to avoid ethically relevant Machine Consciousness", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the root cause of systems perceiving the self experience\nand how to exploit adaptive and learning features without introducing ethically\nproblematic system properties.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 21:52:13 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 10:53:16 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Lodwich", "Aleksander", ""]]}, {"id": "1606.00068", "submitter": "Marco Cusumano-Towner", "authors": "Marco F Cusumano-Towner, Vikash K Mansinghka", "title": "Quantifying the probable approximation error of probabilistic inference\n  programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new technique for quantifying the approximation error\nof a broad class of probabilistic inference programs, including ones based on\nboth variational and Monte Carlo approaches. The key idea is to derive a\nsubjective bound on the symmetrized KL divergence between the distribution\nachieved by an approximate inference program and its true target distribution.\nThe bound's validity (and subjectivity) rests on the accuracy of two auxiliary\nprobabilistic programs: (i) a \"reference\" inference program that defines a gold\nstandard of accuracy and (ii) a \"meta-inference\" program that answers the\nquestion \"what internal random choices did the original approximate inference\nprogram probably make given that it produced a particular result?\" The paper\nincludes empirical results on inference problems drawn from linear regression,\nDirichlet process mixture modeling, HMMs, and Bayesian networks. The\nexperiments show that the technique is robust to the quality of the reference\ninference program and that it can detect implementation bugs that are not\napparent from predictive performance.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 22:37:43 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Cusumano-Towner", "Marco F", ""], ["Mansinghka", "Vikash K", ""]]}, {"id": "1606.00075", "submitter": "Yura Perov N", "authors": "Yura N Perov", "title": "Applications of Probabilistic Programming (Master's thesis, 2015)", "comments": "Supervisor: Frank Wood. The thesis was prepared in the Department of\n  Engineering Science at the University of Oxford", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis describes work on two applications of probabilistic programming:\nthe learning of probabilistic program code given specifications, in particular\nprogram code of one-dimensional samplers; and the facilitation of sequential\nMonte Carlo inference with help of data-driven proposals. The latter is\npresented with experimental results on a linear Gaussian model and a\nnon-parametric dependent Dirichlet process mixture of objects model for object\nrecognition and tracking.\n  In Chapter 1 we provide a brief introduction to probabilistic programming.\n  In Chapter 2 we present an approach to automatic discovery of samplers in the\nform of probabilistic programs. We formulate a Bayesian approach to this\nproblem by specifying a grammar-based prior over probabilistic program code. We\nuse an approximate Bayesian computation method to learn the programs, whose\nexecutions generate samples that statistically match observed data or\nanalytical characteristics of distributions of interest. In our experiments we\nleverage different probabilistic programming systems to perform Markov chain\nMonte Carlo sampling over the space of programs. Experimental results have\ndemonstrated that, using the proposed methodology, we can learn approximate and\neven some exact samplers. Finally, we show that our results are competitive\nwith regard to genetic programming methods.\n  In Chapter 3, we describe a way to facilitate sequential Monte Carlo\ninference in probabilistic programming using data-driven proposals. In\nparticular, we develop a distance-based proposal for the non-parametric\ndependent Dirichlet process mixture of objects model. We implement this\napproach in the probabilistic programming system Anglican, and show that for\nthat model data-driven proposals provide significant performance improvements.\nWe also explore the possibility of using neural networks to improve data-driven\nproposals.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 23:48:55 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 19:41:59 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Perov", "Yura N", ""]]}, {"id": "1606.00117", "submitter": "John Dickerson", "authors": "Benjamin Plaut, John P. Dickerson, Tuomas Sandholm", "title": "Hardness of the Pricing Problem for Chains in Barter Exchanges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kidney exchange is a barter market where patients trade willing but medically\nincompatible donors. These trades occur via cycles, where each patient-donor\npair both gives and receives a kidney, and via chains, which begin with an\naltruistic donor who does not require a kidney in return. For logistical\nreasons, the maximum length of a cycle is typically limited to a small\nconstant, while chains can be much longer. Given a compatibility graph of\npatient-donor pairs, altruists, and feasible potential transplants between\nthem, finding even a maximum-cardinality set of vertex-disjoint cycles and\nchains is NP-hard. There has been much work on developing provably optimal\nsolvers that are efficient in practice. One of the leading techniques has been\nbranch and price, where column generation is used to incrementally bring cycles\nand chains into the optimization model on an as-needed basis. In particular,\nonly positive-price columns need to be brought into the model. We prove that\nfinding a positive-price chain is NP-complete. This shows incorrectness of two\nleading branch-and-price solvers that suggested polynomial-time chain pricing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 04:49:08 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Plaut", "Benjamin", ""], ["Dickerson", "John P.", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "1606.00133", "submitter": "Jae Hee Lee", "authors": "Frank Dylla, Jae Hee Lee, Till Mossakowski, Thomas Schneider, Andr\\'e\n  Van Delden, Jasper Van De Ven, Diedrich Wolter", "title": "A Survey of Qualitative Spatial and Temporal Calculi -- Algebraic and\n  Computational Properties", "comments": "Submitted to ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative Spatial and Temporal Reasoning (QSTR) is concerned with symbolic\nknowledge representation, typically over infinite domains. The motivations for\nemploying QSTR techniques range from exploiting computational properties that\nallow efficient reasoning to capture human cognitive concepts in a\ncomputational framework. The notion of a qualitative calculus is one of the\nmost prominent QSTR formalisms. This article presents the first overview of all\nqualitative calculi developed to date and their computational properties,\ntogether with generalized definitions of the fundamental concepts and methods,\nwhich now encompass all existing calculi. Moreover, we provide a classification\nof calculi according to their algebraic properties.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 06:46:51 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Dylla", "Frank", ""], ["Lee", "Jae Hee", ""], ["Mossakowski", "Till", ""], ["Schneider", "Thomas", ""], ["Van Delden", "Andr\u00e9", ""], ["Van De Ven", "Jasper", ""], ["Wolter", "Diedrich", ""]]}, {"id": "1606.00339", "submitter": "Christian Stra{\\ss}er", "authors": "Mathieu Beirlaen and Christian Stra{\\ss}er", "title": "A structured argumentation framework for detaching conditional\n  obligations", "comments": "This is our submission to DEON 2016, including the technical appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general formal argumentation system for dealing with the\ndetachment of conditional obligations. Given a set of facts, constraints, and\nconditional obligations, we answer the question whether an unconditional\nobligation is detachable by considering reasons for and against its detachment.\nFor the evaluation of arguments in favor of detaching obligations we use a\nDung-style argumentation-theoretical semantics. We illustrate the modularity of\nthe general framework by considering some extensions, and we compare the\nframework to some related approaches from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 16:04:47 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Beirlaen", "Mathieu", ""], ["Stra\u00dfer", "Christian", ""]]}, {"id": "1606.00401", "submitter": "Benjamin Cowley PhD", "authors": "Benjamin Ultan Cowley", "title": "How to advance general game playing artificial intelligence by player\n  modelling", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General game playing artificial intelligence has recently seen important\nadvances due to the various techniques known as 'deep learning'. However the\nadvances conceal equally important limitations in their reliance on: massive\ndata sets; fortuitously constructed problems; and absence of any human-level\ncomplexity, including other human opponents. On the other hand, deep learning\nsystems which do beat human champions, such as in Go, do not generalise well.\nThe power of deep learning simultaneously exposes its weakness. Given that deep\nlearning is mostly clever reconfigurations of well-established methods, moving\nbeyond the state of art calls for forward-thinking visionary solutions, not\njust more of the same. I present the argument that general game playing\nartificial intelligence will require a generalised player model. This is\nbecause games are inherently human artefacts which therefore, as a class of\nproblems, contain cases which require a human-style problem solving approach. I\nrelate this argument to the performance of state of art general game playing\nagents. I then describe a concept for a formal category theoretic basis to a\ngeneralised player model. This formal model approach integrates my existing\n'Behavlets' method for psychologically-derived player modelling:\n  Cowley, B., Charles, D. (2016). Behavlets: a Method for Practical Player\nModelling using Psychology-Based Player Traits and Domain Specific Features.\nUser Modeling and User-Adapted Interaction, 26(2), 257-306.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 19:07:48 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 13:15:53 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2016 12:18:24 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Cowley", "Benjamin Ultan", ""]]}, {"id": "1606.00496", "submitter": "Paulo Adeodato Prof.", "authors": "Paulo J. L. Adeodato and S\\'ilvio B. Melo", "title": "On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for\n  binary classification", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary decisions are very common in artificial intelligence. Applying a\nthreshold on the continuous score gives the human decider the power to control\nthe operating point to separate the two classes. The classifier,s\ndiscriminating power is measured along the continuous range of the score by the\nArea Under the ROC curve (AUC_ROC) in most application fields. Only finances\nuses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance.\nThis paper proposes the Area Under the KS curve (AUC_KS) for performance\nassessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the\nAUC_ROC. That is even more important for ROC averaging in ensembles of\nclassifiers or n fold cross-validation. The proof is geometrically inspired on\nrotating all KS curve to make it lie on the top of the ROC chance diagonal. On\nthe practical side, the independent variable on the abscissa on the KS curve\nsimplifies the calculation of the AUC_ROC. On the theoretical side, this\nresearch gives insights on probabilistic interpretations of classifiers\nassessment and integrates the existing body of knowledge of the information\ntheoretical ROC approach with the proposed statistical approach based on the\nthoroughly known KS distribution.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 23:12:53 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Adeodato", "Paulo J. L.", ""], ["Melo", "S\u00edlvio B.", ""]]}, {"id": "1606.00561", "submitter": "Anas Shatnawi", "authors": "Anas Shatnawi (MAREL), Abdelhak Seriai (MAREL), Houari Sahraoui\n  (GEODES), Zakarea Al-Shara (MAREL)", "title": "Mining Software Components from Object-Oriented APIs", "comments": null, "journal-ref": "International Conference on Software Reuse, Jan 2015, Miami, FL,\n  United States. SpringerLink, Lecture Notes in Computer Science (8919),\n  pp.330-347, 2014, Software Reuse for Dynamic Systems in the Cloud and Beyond", "doi": "10.1007/978-3-319-14130-5_23", "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-oriented Application Programing Interfaces (APIs) support software\nreuse by providing pre-implemented functionalities. Due to the huge number of\nincluded classes, reusing and understanding large APIs is a complex task.\nOtherwise, software components are admitted to be more reusable and\nunderstandable entities than object-oriented ones. Thus, in this paper, we\npropose an approach for reengineering object-oriented APIs into component-based\nones. We mine components as a group of classes based on the frequency they are\nused together and their ability to form a quality-centric component. To\nvalidate our approach, we experimented on 100 Java applications that used\nAndroid APIs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 07:08:01 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Shatnawi", "Anas", "", "MAREL"], ["Seriai", "Abdelhak", "", "MAREL"], ["Sahraoui", "Houari", "", "GEODES"], ["Al-Shara", "Zakarea", "", "MAREL"]]}, {"id": "1606.00626", "submitter": "Patrick O. Glauner", "authors": "Patrick Glauner, Jorge Augusto Meira, Petko Valtchev, Radu State,\n  Franck Bettinger", "title": "The Challenge of Non-Technical Loss Detection using Artificial\n  Intelligence: A Survey", "comments": null, "journal-ref": "International Journal of Computational Intelligence Systems\n  (IJCIS), vol. 10, issue 1, pp. 760-775, 2017", "doi": "10.2991/ijcis.2017.10.1.51", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of non-technical losses (NTL) which include electricity theft,\nfaulty meters or billing errors has attracted increasing attention from\nresearchers in electrical engineering and computer science. NTLs cause\nsignificant harm to the economy, as in some countries they may range up to 40%\nof the total electricity distributed. The predominant research direction is\nemploying artificial intelligence to predict whether a customer causes NTL.\nThis paper first provides an overview of how NTLs are defined and their impact\non economies, which include loss of revenue and profit of electricity providers\nand decrease of the stability and reliability of electrical power grids. It\nthen surveys the state-of-the-art research efforts in a up-to-date and\ncomprehensive review of algorithms, features and data sets used. It finally\nidentifies the key scientific and engineering challenges in NTL detection and\nsuggests how they could be addressed in the future.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 11:14:47 GMT"}, {"version": "v2", "created": "Sat, 22 Jul 2017 22:30:28 GMT"}, {"version": "v3", "created": "Tue, 25 Jul 2017 04:25:54 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Glauner", "Patrick", ""], ["Meira", "Jorge Augusto", ""], ["Valtchev", "Petko", ""], ["State", "Radu", ""], ["Bettinger", "Franck", ""]]}, {"id": "1606.00652", "submitter": "Jarryd Martin", "authors": "Jarryd Martin, Tom Everitt, Marcus Hutter", "title": "Death and Suicide in Universal Artificial Intelligence", "comments": "Conference: Artificial General Intelligence (AGI) 2016 13 pages, 2\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a general paradigm for studying intelligent\nbehaviour, with applications ranging from artificial intelligence to psychology\nand economics. AIXI is a universal solution to the RL problem; it can learn any\ncomputable environment. A technical subtlety of AIXI is that it is defined\nusing a mixture over semimeasures that need not sum to 1, rather than over\nproper probability measures. In this work we argue that the shortfall of a\nsemimeasure can naturally be interpreted as the agent's estimate of the\nprobability of its death. We formally define death for generally intelligent\nagents like AIXI, and prove a number of related theorems about their behaviour.\nNotable discoveries include that agent behaviour can change radically under\npositive linear transformations of the reward signal (from suicidal to\ndogmatically self-preserving), and that the agent's posterior belief that it\nwill survive increases over time.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 12:48:39 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Martin", "Jarryd", ""], ["Everitt", "Tom", ""], ["Hutter", "Marcus", ""]]}, {"id": "1606.00776", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Tim Klinger, Gerald Tesauro, Kartik Talamadupula,\n  Bowen Zhou, Yoshua Bengio, Aaron Courville", "title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation", "comments": "21 pages, 2 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 17:37:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 02:01:16 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Klinger", "Tim", ""], ["Tesauro", "Gerald", ""], ["Talamadupula", "Kartik", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1606.00787", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Eric Xing", "title": "Post-Inference Prior Swapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Bayesian methods are praised for their ability to incorporate useful\nprior knowledge, in practice, convenient priors that allow for computationally\ncheap or tractable inference are commonly used. In this paper, we investigate\nthe following question: for a given model, is it possible to compute an\ninference result with any convenient false prior, and afterwards, given any\ntarget prior of interest, quickly transform this result into the target\nposterior? A potential solution is to use importance sampling (IS). However, we\ndemonstrate that IS will fail for many choices of the target prior, depending\non its parametric form and similarity to the false prior. Instead, we propose\nprior swapping, a method that leverages the pre-inferred false posterior to\nefficiently generate accurate posterior samples under arbitrary target priors.\nPrior swapping lets us apply less-costly inference algorithms to certain\nmodels, and incorporate new or updated prior information \"post-inference\". We\ngive theoretical guarantees about our method, and demonstrate it empirically on\na number of models and priors.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 18:20:35 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 18:01:17 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Neiswanger", "Willie", ""], ["Xing", "Eric", ""]]}, {"id": "1606.00917", "submitter": "Faizan Javed", "authors": "Faizan Javed, Matt McNair, Ferosh Jacob, Meng Zhao", "title": "Towards a Job Title Classification System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document classification for text, images and other applicable entities has\nlong been a focus of research in academia and also finds application in many\nindustrial settings. Amidst a plethora of approaches to solve such problems,\nmachine-learning techniques have found success in a variety of scenarios. In\nthis paper we discuss the design of a machine learning-based semi-supervised\njob title classification system for the online job recruitment domain currently\nin production at CareerBuilder.com and propose enhancements to it. The system\nleverages a varied collection of classification as well clustering algorithms.\nThese algorithms are encompassed in an architecture that facilitates leveraging\nexisting off-the-shelf machine learning tools and techniques while keeping into\nconsideration the challenges of constructing a scalable classification system\nfor a large taxonomy of categories. As a continuously evolving system that is\nstill under development we first discuss the existing semi-supervised\nclassification system which is composed of both clustering and classification\ncomponents in a proximity-based classifier setup and results of which are\nalready used across numerous products at CareerBuilder. We then elucidate our\nlong-term goals for job title classification and propose enhancements to the\nexisting system in the form of a two-stage coarse and fine level classifier\naugmentation to construct a cascade of hierarchical vertical classifiers.\nPreliminary results are presented using experimental evaluation on real world\nindustrial data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 22:01:50 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Javed", "Faizan", ""], ["McNair", "Matt", ""], ["Jacob", "Ferosh", ""], ["Zhao", "Meng", ""]]}, {"id": "1606.00927", "submitter": "Hasan Dalman", "authors": "Hasan Dalman", "title": "An interactive fuzzy goal programming algorithm to solve decentralized\n  bi-level multiobjective fractional programming problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fuzzy goal programming based on Taylor series for\nsolving decentralized bi-level multiobjective fractional programming (DBLMOFP)\nproblem. In the proposed approach, all of the membership functions are\nassociated with the fuzzy goals of each objective at the both levels and also\nthe fractional membership functions are converted to linear functions using the\nTaylor series approach. Then a fuzzy goal programming is proposed to reach the\nhighest degree of each of the membership goals by taking the most satisfactory\nsolution for all decision makers at the both levels. Finally, a numerical\nexample is presented to illustrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 22:47:57 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Dalman", "Hasan", ""]]}, {"id": "1606.00979", "submitter": "Kang Liu", "authors": "Yuanzhe Zhang, Kang Liu, Shizhu He, Guoliang Ji, Zhanyi Liu, Hua Wu,\n  Jun Zhao", "title": "Question Answering over Knowledge Base with Neural Attention Combining\n  Global Knowledge Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge bases (KBs) on the web, how to take full\nadvantage of them becomes increasingly important. Knowledge base-based question\nanswering (KB-QA) is one of the most promising approaches to access the\nsubstantial knowledge. Meantime, as the neural network-based (NN-based) methods\ndevelop, NN-based KB-QA has already achieved impressive results. However,\nprevious work did not put emphasis on question representation, and the question\nis converted into a fixed vector regardless of its candidate answers. This\nsimple representation strategy is unable to express the proper information of\nthe question. Hence, we present a neural attention-based model to represent the\nquestions dynamically according to the different focuses of various candidate\nanswer aspects. In addition, we leverage the global knowledge inside the\nunderlying KB, aiming at integrating the rich KB information into the\nrepresentation of the answers. And it also alleviates the out of vocabulary\n(OOV) problem, which helps the attention model to represent the question more\nprecisely. The experimental results on WEBQUESTIONS demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 06:40:14 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Zhang", "Yuanzhe", ""], ["Liu", "Kang", ""], ["He", "Shizhu", ""], ["Ji", "Guoliang", ""], ["Liu", "Zhanyi", ""], ["Wu", "Hua", ""], ["Zhao", "Jun", ""]]}, {"id": "1606.01015", "submitter": "Jordan Henrio", "authors": "Jordan Henrio, Thomas Henn, Tomoharu Nakashima, Hidehisa Akiyama", "title": "Selecting the Best Player Formation for Corner-Kick Situations Based on\n  Bayes' Estimation", "comments": "12 pages, 7 figures, RoboCup Symposium 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of the Soccer simulation 2D league of the RoboCup project,\nappropriate player positioning against a given opponent team is an important\nfactor of soccer team performance. This work proposes a model which decides the\nstrategy that should be applied regarding a particular opponent team. This task\ncan be realized by applying preliminary a learning phase where the model\ndetermines the most effective strategies against clusters of opponent teams.\nThe model determines the best strategies by using sequential Bayes' estimators.\nAs a first trial of the system, the proposed model is used to determine the\nassociation of player formations against opponent teams in the particular\nsituation of corner-kick. The implemented model shows satisfying abilities to\ncompare player formations that are similar to each other in terms of\nperformance and determines the right ranking even by running a decent number of\nsimulation games.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 09:31:13 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Henrio", "Jordan", ""], ["Henn", "Thomas", ""], ["Nakashima", "Tomoharu", ""], ["Akiyama", "Hidehisa", ""]]}, {"id": "1606.01113", "submitter": "Kuang Zhou", "authors": "Kuang Zhou (DRUID), Arnaud Martin (DRUID), Quan Pan, Zhun-Ga Liu", "title": "ECMdd: Evidential c-medoids clustering with multiple prototypes", "comments": null, "journal-ref": "Pattern Recognition, Elsevier, 2016", "doi": "10.1016/j.patcog.2016.05.005", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a new prototype-based clustering method named Evidential\nC-Medoids (ECMdd), which belongs to the family of medoid-based clustering for\nproximity data, is proposed as an extension of Fuzzy C-Medoids (FCMdd) on the\ntheoretical framework of belief functions. In the application of FCMdd and\noriginal ECMdd, a single medoid (prototype), which is supposed to belong to the\nobject set, is utilized to represent one class. For the sake of clarity, this\nkind of ECMdd using a single medoid is denoted by sECMdd. In real clustering\napplications, using only one pattern to capture or interpret a class may not\nadequately model different types of group structure and hence limits the\nclustering performance. In order to address this problem, a variation of ECMdd\nusing multiple weighted medoids, denoted by wECMdd, is presented. Unlike\nsECMdd, in wECMdd objects in each cluster carry various weights describing\ntheir degree of representativeness for that class. This mechanism enables each\nclass to be represented by more than one object. Experimental results in\nsynthetic and real data sets clearly demonstrate the superiority of sECMdd and\nwECMdd. Moreover, the clustering results by wECMdd can provide richer\ninformation for the inner structure of the detected classes with the help of\nprototype weights.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 14:44:15 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Zhou", "Kuang", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"], ["Pan", "Quan", ""], ["Liu", "Zhun-Ga", ""]]}, {"id": "1606.01116", "submitter": "Kuang Zhou", "authors": "Kuang Zhou (DRUID), Arnaud Martin (DRUID), Quan Pan", "title": "The belief noisy-or model applied to network reliability analysis", "comments": null, "journal-ref": "International Journal of Uncertainty, Fuzziness and\n  Knowledge-Based Systems, World Scientific Publishing, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One difficulty faced in knowledge engineering for Bayesian Network (BN) is\nthe quan-tification step where the Conditional Probability Tables (CPTs) are\ndetermined. The number of parameters included in CPTs increases exponentially\nwith the number of parent variables. The most common solution is the\napplication of the so-called canonical gates. The Noisy-OR (NOR) gate, which\ntakes advantage of the independence of causal interactions, provides a\nlogarithmic reduction of the number of parameters required to specify a CPT. In\nthis paper, an extension of NOR model based on the theory of belief functions,\nnamed Belief Noisy-OR (BNOR), is proposed. BNOR is capable of dealing with both\naleatory and epistemic uncertainty of the network. Compared with NOR, more rich\ninformation which is of great value for making decisions can be got when the\navailable knowledge is uncertain. Specially, when there is no epistemic\nuncertainty, BNOR degrades into NOR. Additionally, different structures of BNOR\nare presented in this paper in order to meet various needs of engineers. The\napplication of BNOR model on the reliability evaluation problem of networked\nsystems demonstrates its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 14:47:12 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Zhou", "Kuang", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"], ["Pan", "Quan", ""]]}, {"id": "1606.01245", "submitter": "Fanhua Shang", "authors": "Fanhua Shang and Yuanyuan Liu and James Cheng", "title": "Scalable Algorithms for Tractable Schatten Quasi-Norm Minimization", "comments": "16 pages, 5 figures, Appears in Proceedings of the 30th AAAI\n  Conference on Artificial Intelligence (AAAI), Phoenix, Arizona, USA, pp.\n  2016--2022, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Schatten-p quasi-norm $(0<p<1)$ is usually used to replace the standard\nnuclear norm in order to approximate the rank function more accurately.\nHowever, existing Schatten-p quasi-norm minimization algorithms involve\nsingular value decomposition (SVD) or eigenvalue decomposition (EVD) in each\niteration, and thus may become very slow and impractical for large-scale\nproblems. In this paper, we first define two tractable Schatten quasi-norms,\ni.e., the Frobenius/nuclear hybrid and bi-nuclear quasi-norms, and then prove\nthat they are in essence the Schatten-2/3 and 1/2 quasi-norms, respectively,\nwhich lead to the design of very efficient algorithms that only need to update\ntwo much smaller factor matrices. We also design two efficient proximal\nalternating linearized minimization algorithms for solving representative\nmatrix completion problems. Finally, we provide the global convergence and\nperformance guarantees for our algorithms, which have better convergence\nproperties than existing algorithms. Experimental results on synthetic and\nreal-world data show that our algorithms are more accurate than the\nstate-of-the-art methods, and are orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 03:28:41 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Cheng", "James", ""]]}, {"id": "1606.01269", "submitter": "Jason Williams", "authors": "Jason D. Williams and Geoffrey Zweig", "title": "End-to-end LSTM-based dialog control optimized with supervised and\n  reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model for end-to-end learning of task-oriented dialog\nsystems. The main component of the model is a recurrent neural network (an\nLSTM), which maps from raw dialog history directly to a distribution over\nsystem actions. The LSTM automatically infers a representation of dialog\nhistory, which relieves the system developer of much of the manual feature\nengineering of dialog state. In addition, the developer can provide software\nthat expresses business rules and provides access to programmatic APIs,\nenabling the LSTM to take actions in the real world on behalf of the user. The\nLSTM can be optimized using supervised learning (SL), where a domain expert\nprovides example dialogs which the LSTM should imitate; or using reinforcement\nlearning (RL), where the system improves by interacting directly with end\nusers. Experiments show that SL and RL are complementary: SL alone can derive a\nreasonable initial policy from a small number of training dialogs; and starting\nRL optimization with a policy trained with SL substantially accelerates the\nlearning rate of RL.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 20:32:52 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Williams", "Jason D.", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1606.01307", "submitter": "Pedro Felzenszwalb", "authors": "Jeroen Chua, Pedro F. Felzenszwalb", "title": "Scene Grammars, Factor Graphs, and Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general framework for probabilistic modeling of complex scenes\nand inference from ambiguous observations. The approach is motivated by\napplications in image analysis and is based on the use of priors defined by\nstochastic grammars. We define a class of grammars that capture relationships\nbetween the objects in a scene and provide important contextual cues for\nstatistical inference. The distribution over scenes defined by a probabilistic\nscene grammar can be represented by a graphical model and this construction can\nbe used for efficient inference with loopy belief propagation.\n  We show experimental results with two different applications. One application\ninvolves the reconstruction of binary contour maps. Another application\ninvolves detecting and localizing faces in images. In both applications the\nsame framework leads to robust inference algorithms that can effectively\ncombine local information to reason about a scene.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 23:49:02 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 22:44:27 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 16:06:15 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Chua", "Jeroen", ""], ["Felzenszwalb", "Pedro F.", ""]]}, {"id": "1606.01380", "submitter": "Okan A\\c{s}{\\i}k", "authors": "Okan A\\c{s}{\\i}k and H. Levent Ak{\\i}n", "title": "Effective Multi-Robot Spatial Task Allocation using Model Approximations", "comments": "RoboCup 2016 Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world multi-agent planning problems cannot be solved using\ndecision-theoretic planning methods due to the exponential complexity. We\napproximate firefighting in rescue simulation as a spatially distributed task\nand model with multi-agent Markov decision process. We use recent approximation\nmethods for spatial task problems to reduce the model complexity. Our\napproximations are single-agent, static task, shortest path pruning, dynamic\nplanning horizon, and task clustering. We create scenarios from RoboCup Rescue\nSimulation maps and evaluate our methods on these graph worlds. The results\nshow that our approach is faster and better than comparable methods and has\nnegligible performance loss compared to the optimal policy. We also show that\nour method has a similar performance as DCOP methods on example RCRS scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 14:12:32 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["A\u015f\u0131k", "Okan", ""], ["Ak\u0131n", "H. Levent", ""]]}, {"id": "1606.01404", "submitter": "Tim Rockt\\\"aschel", "authors": "Vladyslav Kolesnyk, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "Generating Natural Language Inference Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason with natural language is a fundamental prerequisite for\nmany NLP tasks such as information extraction, machine translation and question\nanswering. To quantify this ability, systems are commonly tested whether they\ncan recognize textual entailment, i.e., whether one sentence can be inferred\nfrom another one. However, in most NLP applications only single source\nsentences instead of sentence pairs are available. Hence, we propose a new task\nthat measures how well a model can generate an entailed sentence from a source\nsentence. We take entailment-pairs of the Stanford Natural Language Inference\ncorpus and train an LSTM with attention. On a manually annotated test set we\nfound that 82% of generated sentences are correct, an improvement of 10.3% over\nan LSTM baseline. A qualitative analysis shows that this model is not only\ncapable of shortening input sentences, but also inferring new statements via\nparaphrasing and phrase entailment. We then apply this model recursively to\ninput-output pairs, thereby generating natural language inference chains that\ncan be used to automatically construct an entailment graph from source\nsentences. Finally, by swapping source and target sentences we can also train a\nmodel that given an input sentence invents additional information to generate a\nnew sentence.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 18:34:51 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Kolesnyk", "Vladyslav", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1606.01412", "submitter": "Krzysztof Krawiec", "authors": "Krzysztof Krawiec and Jerry Swan", "title": "Distance Metric Ensemble Learning and the Andrews-Curtis Conjecture", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the search for a counterexample to the Poincar\\'e conjecture in\nthree and four dimensions, the Andrews-Curtis conjecture was proposed in 1965.\nIt is now generally suspected that the Andrews-Curtis conjecture is false, but\nsmall potential counterexamples are not so numerous, and previous work has\nattempted to eliminate some via combinatorial search. Progress has however been\nlimited, with the most successful approach (breadth-first-search using\nsecondary storage) being neither scalable nor heuristically-informed. A\nprevious empirical analysis of problem structure examined several heuristic\nmeasures of search progress and determined that none of them provided any\nuseful guidance for search. In this article, we induce new quality measures\ndirectly from the problem structure and combine them to produce a more\neffective search driver via ensemble machine learning. By this means, we\neliminate 19 potential counterexamples, the status of which had been unknown\nfor some years.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 20:06:03 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Krawiec", "Krzysztof", ""], ["Swan", "Jerry", ""]]}, {"id": "1606.01515", "submitter": "EPTCS", "authors": "Dimitri Kartsaklis (Queen Mary University of London)", "title": "Coordination in Categorical Compositional Distributional Semantics", "comments": "In Proceedings SLPCS 2016, arXiv:1608.01018", "journal-ref": "EPTCS 221, 2016, pp. 29-38", "doi": "10.4204/EPTCS.221.4", "report-no": null, "categories": "cs.CL cs.AI math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem with categorical compositional distributional semantics is\nthe representation of words that are considered semantically vacuous from a\ndistributional perspective, such as determiners, prepositions, relative\npronouns or coordinators. This paper deals with the topic of coordination\nbetween identical syntactic types, which accounts for the majority of\ncoordination cases in language. By exploiting the compact closed structure of\nthe underlying category and Frobenius operators canonically induced over the\nfixed basis of finite-dimensional vector spaces, we provide a morphism as\nrepresentation of a coordinator tensor, and we show how it lifts from atomic\ntypes to compound types. Linguistic intuitions are provided, and the importance\nof the Frobenius operators as an addition to the compact closed setting with\nregard to language is discussed.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 14:26:56 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 00:41:00 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Kartsaklis", "Dimitri", "", "Queen Mary University of London"]]}, {"id": "1606.01540", "submitter": "John Schulman", "authors": "Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John\n  Schulman, Jie Tang, Wojciech Zaremba", "title": "OpenAI Gym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenAI Gym is a toolkit for reinforcement learning research. It includes a\ngrowing collection of benchmark problems that expose a common interface, and a\nwebsite where people can share their results and compare the performance of\nalgorithms. This whitepaper discusses the components of OpenAI Gym and the\ndesign decisions that went into the software.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 17:54:48 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Brockman", "Greg", ""], ["Cheung", "Vicki", ""], ["Pettersson", "Ludwig", ""], ["Schneider", "Jonas", ""], ["Schulman", "John", ""], ["Tang", "Jie", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1606.01623", "submitter": "John Dickerson", "authors": "John P. Dickerson, David F. Manlove, Benjamin Plaut, Tuomas Sandholm,\n  James Trimble", "title": "Position-Indexed Formulations for Kidney Exchange", "comments": "Appeared at the ACM Conference on Economics and Computation (EC-16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A kidney exchange is an organized barter market where patients in need of a\nkidney swap willing but incompatible donors. Determining an optimal set of\nexchanges is theoretically and empirically hard. Traditionally, exchanges took\nplace in cycles, with each participating patient-donor pair both giving and\nreceiving a kidney. The recent introduction of chains, where a donor without a\npaired patient triggers a sequence of donations without requiring a kidney in\nreturn, increased the efficacy of fielded kidney exchanges---while also\ndramatically raising the empirical computational hardness of clearing the\nmarket in practice. While chains can be quite long, unbounded-length chains are\nnot desirable: planned donations can fail before transplant for a variety of\nreasons, and the failure of a single donation causes the rest of that chain to\nfail, so parallel shorter chains are better in practice.\n  In this paper, we address the tractable clearing of kidney exchanges with\nshort cycles and chains that are long but bounded. This corresponds to the\npractice at most modern fielded kidney exchanges. We introduce three new\ninteger programming formulations, two of which are compact. Furthermore, one of\nthese models has a linear programming relaxation that is exactly as tight as\nthe previous tightest formulation (which was not compact) for instances in\nwhich each donor has a paired patient. On real data from the UNOS nationwide\nexchange in the United States and the NLDKSS nationwide exchange in the United\nKingdom, as well as on generated realistic large-scale data, we show that our\nnew models are competitive with all existing solvers---in many cases\noutperforming all other solvers by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 06:16:36 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 22:39:37 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Dickerson", "John P.", ""], ["Manlove", "David F.", ""], ["Plaut", "Benjamin", ""], ["Sandholm", "Tuomas", ""], ["Trimble", "James", ""]]}, {"id": "1606.01847", "submitter": "Marcus Rohrbach", "authors": "Akira Fukui, Dong Huk Park, Daylen Yang, Anna Rohrbach, Trevor\n  Darrell, and Marcus Rohrbach", "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and\n  Visual Grounding", "comments": "Accepted to EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling textual or visual information with vector representations trained\nfrom large language or visual datasets has been successfully explored in recent\nyears. However, tasks such as visual question answering require combining these\nvector representations with each other. Approaches to multimodal pooling\ninclude element-wise product or sum, as well as concatenation of the visual and\ntextual representations. We hypothesize that these methods are not as\nexpressive as an outer product of the visual and textual vectors. As the outer\nproduct is typically infeasible due to its high dimensionality, we instead\npropose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and\nexpressively combine multimodal features. We extensively evaluate MCB on the\nvisual question answering and grounding tasks. We consistently show the benefit\nof MCB over ablations without MCB. For visual question answering, we present an\narchitecture which uses MCB twice, once for predicting attention over spatial\nfeatures and again to combine the attended representation with the question\nrepresentation. This model outperforms the state-of-the-art on the Visual7W\ndataset and the VQA challenge.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 17:59:56 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 19:52:41 GMT"}, {"version": "v3", "created": "Sat, 24 Sep 2016 01:58:59 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Fukui", "Akira", ""], ["Park", "Dong Huk", ""], ["Yang", "Daylen", ""], ["Rohrbach", "Anna", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1606.01855", "submitter": "Aaron Schein", "authors": "Aaron Schein, Mingyuan Zhou, David M. Blei, Hanna Wallach", "title": "Bayesian Poisson Tucker Decomposition for Learning the Structure of\n  International Relations", "comments": "To appear in Proceedings of the 33rd International Conference on\n  Machine Learning (ICML 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Bayesian Poisson Tucker decomposition (BPTD) for modeling\ncountry--country interaction event data. These data consist of interaction\nevents of the form \"country $i$ took action $a$ toward country $j$ at time\n$t$.\" BPTD discovers overlapping country--community memberships, including the\nnumber of latent communities. In addition, it discovers directed\ncommunity--community interaction networks that are specific to \"topics\" of\naction types and temporal \"regimes.\" We show that BPTD yields an efficient MCMC\ninference algorithm and achieves better predictive performance than related\nmodels. We also demonstrate that it discovers interpretable latent structure\nthat agrees with our knowledge of international relations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 18:34:56 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Schein", "Aaron", ""], ["Zhou", "Mingyuan", ""], ["Blei", "David M.", ""], ["Wallach", "Hanna", ""]]}, {"id": "1606.01868", "submitter": "Marc G. Bellemare", "authors": "Marc G. Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul,\n  David Saxton, Remi Munos", "title": "Unifying Count-Based Exploration and Intrinsic Motivation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an agent's uncertainty about its environment and the problem of\ngeneralizing this uncertainty across observations. Specifically, we focus on\nthe problem of exploration in non-tabular reinforcement learning. Drawing\ninspiration from the intrinsic motivation literature, we use density models to\nmeasure uncertainty, and propose a novel algorithm for deriving a pseudo-count\nfrom an arbitrary density model. This technique enables us to generalize\ncount-based exploration algorithms to the non-tabular case. We apply our ideas\nto Atari 2600 games, providing sensible pseudo-counts from raw pixels. We\ntransform these pseudo-counts into intrinsic rewards and obtain significantly\nimproved exploration in a number of hard games, including the infamously\ndifficult Montezuma's Revenge.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 19:21:32 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 21:16:21 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Bellemare", "Marc G.", ""], ["Srinivasan", "Sriram", ""], ["Ostrovski", "Georg", ""], ["Schaul", "Tom", ""], ["Saxton", "David", ""], ["Munos", "Remi", ""]]}, {"id": "1606.01885", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Learning to Optimize", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm design is a laborious process and often requires many iterations of\nideation and validation. In this paper, we explore automating algorithm design\nand present a method to learn an optimization algorithm, which we believe to be\nthe first method that can automatically discover a better algorithm. We\napproach this problem from a reinforcement learning perspective and represent\nany particular optimization algorithm as a policy. We learn an optimization\nalgorithm using guided policy search and demonstrate that the resulting\nalgorithm outperforms existing hand-engineered algorithms in terms of\nconvergence speed and/or the final objective value.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 19:50:47 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1606.01924", "submitter": "Robert Rovetto", "authors": "Robert John Rovetto, T.S. Kelso", "title": "Preliminaries of a Space Situational Awareness Ontology", "comments": "Paper presented at 26th AIAA/AAS Space Flight Mechanics meeting,\n  Napa, CA. USA, February 14-18, 2016. Forthcoming in Advances in the\n  Astronautics, Univelt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space situational awareness (SSA) is vital for international safety and\nsecurity, and the future of space travel. By improving SSA data-sharing we\nimprove global SSA. Computational ontology may provide one means toward that\ngoal. This paper develops the ontology of the SSA domain and takes steps in the\ncreation of the space situational awareness ontology. Ontology objectives,\nrequirements and desiderata are outlined; and both the SSA domain and the\ndiscipline of ontology are described. The purposes of the ontology include:\nexploring the potential for ontology development and engineering to (i)\nrepresent SSA data, general domain knowledge, objects and relationships (ii)\nannotate and express the meaning of that data, and (iii) foster SSA\ndata-exchange and integration among SSA actors, orbital debris databases, space\nobject catalogs and other SSA data repositories. By improving SSA via data- and\nknowledge-sharing, we can (iv) expand our scientific knowledge of the space\nenvironment, (v) advance our capacity for planetary defense from near-Earth\nobjects, and (vi) ensure the future of safe space flight for generations to\ncome.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 19:37:14 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 00:38:21 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Rovetto", "Robert John", ""], ["Kelso", "T. S.", ""]]}, {"id": "1606.01930", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Loreto Bravo", "title": "Consistency and Trust in Peer Data Exchange Systems", "comments": "To appear in Theory and Practice of Logic Programming (TPLP). It\n  includes appendix that will be published only in electronic format", "journal-ref": null, "doi": "10.1017/S147106841600017X", "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a semantics for \"peer data exchange systems\" where\ndifferent peers are related by data exchange constraints and trust\nrelationships. These two elements plus the data at the peers' sites and their\nlocal integrity constraints are made compatible via a semantics that\ncharacterizes sets of \"solution instances\" for the peers. They are the intended\n-possibly virtual- instances for a peer that are obtained through a data repair\nsemantics that we introduce and investigate. The semantically correct answers\nfrom a peer to a query, the so-called \"peer consistent answers\", are defined as\nthose answers that are invariant under all its different solution instances. We\nshow that solution instances can be specified as the models of logic programs\nwith a stable model semantics. The repair semantics is based on null values as\nused in SQL databases, and is also of independent interest for repairs of\nsingle databases with respect to integrity constraints.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 20:26:42 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Bravo", "Loreto", ""]]}, {"id": "1606.01949", "submitter": "Andrea Monacchi", "authors": "Andrea Monacchi, Wilfried Elmenreich", "title": "Assisted Energy Management in Smart Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand response provides utilities with a mechanism to share with end users\nthe stochasticity resulting from the use of renewable sources. Pricing is\naccordingly used to reflect energy availability, to allocate such a limited\nresource to those loads that value it most. However, the strictly competitive\nmechanism can result in service interruption in presence of competing demand.\nTo solve this issue we investigate on the use of forward contracts, i.e.,\nservice level agreements priced to reflect the expectation of future supply and\ndemand curves. Given the limited resources of microgrids, service interruption\nis an opposite objective to the one of service availability. We firstly design\npolicy-based brokers and identify then a learning broker based on artificial\nneural networks. We show the latter being progressively minimizing the\nreimbursement costs and maximizing the overall profit.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 21:36:02 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Monacchi", "Andrea", ""], ["Elmenreich", "Wilfried", ""]]}, {"id": "1606.02032", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Shi-Jim Yen, Ting-Han Wei, I-Chen Wu,\n  Ping-Chiang Chou, Chun-Hsun Chou, Ming-Wan Wang, and Tai-Hsiung Yang", "title": "Human vs. Computer Go: Review and Prospect", "comments": "This article is with 6 pages and 3 figures. And, it is accepted and\n  will be published in IEEE Computational Intelligence Magazine in August, 2016", "journal-ref": null, "doi": "10.1109/MCI.2016.2572559", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Google DeepMind challenge match in March 2016 was a historic achievement\nfor computer Go development. This article discusses the development of\ncomputational intelligence (CI) and its relative strength in comparison with\nhuman intelligence for the game of Go. We first summarize the milestones\nachieved for computer Go from 1998 to 2016. Then, the computer Go programs that\nhave participated in previous IEEE CIS competitions as well as methods and\ntechniques used in AlphaGo are briefly introduced. Commentaries from three\nhigh-level professional Go players on the five AlphaGo versus Lee Sedol games\nare also included. We conclude that AlphaGo beating Lee Sedol is a huge\nachievement in artificial intelligence (AI) based largely on CI methods. In the\nfuture, powerful computer Go programs such as AlphaGo are expected to be\ninstrumental in promoting Go education and AI real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 05:13:37 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Yen", "Shi-Jim", ""], ["Wei", "Ting-Han", ""], ["Wu", "I-Chen", ""], ["Chou", "Ping-Chiang", ""], ["Chou", "Chun-Hsun", ""], ["Wang", "Ming-Wan", ""], ["Yang", "Tai-Hsiung", ""]]}, {"id": "1606.02041", "submitter": "Nils Hammerla", "authors": "Katherine Middleton, Mobasher Butt, Nils Hammerla, Steven Hamblin,\n  Karan Mehta, Ali Parsa", "title": "Sorting out symptoms: design and evaluation of the 'babylon check'\n  automated triage system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior to seeking professional medical care it is increasingly common for\npatients to use online resources such as automated symptom checkers. Many such\nsystems attempt to provide a differential diagnosis based on the symptoms\nelucidated from the user, which may lead to anxiety if life or limb-threatening\nconditions are part of the list, a phenomenon termed 'cyberchondria' [1].\nSystems that provide advice on where to seek help, rather than a diagnosis, are\nequally popular, and in our view provide the most useful information. In this\ntechnical report we describe how such a triage system can be modelled\ncomputationally, how medical insights can be translated into triage flows, and\nhow such systems can be validated and tested. We present babylon check, our\ncommercially deployed automated triage system, as a case study, and illustrate\nits performance in a large, semi-naturalistic deployment study.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 06:55:42 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Middleton", "Katherine", ""], ["Butt", "Mobasher", ""], ["Hammerla", "Nils", ""], ["Hamblin", "Steven", ""], ["Mehta", "Karan", ""], ["Parsa", "Ali", ""]]}, {"id": "1606.02096", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi, and George Fazekas, Mark Sandler", "title": "Towards Playlist Generation Algorithms Using RNNs Trained on\n  Within-Track Transitions", "comments": "4 pages, 2 figures, accepted to Workshop on Surprise, Opposition, and\n  Obstruction in Adaptive and Personalized Systems (SOAP) 2016, Halifax, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MM cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel playlist generation algorithm that focuses on the\nquality of transitions using a recurrent neural network (RNN). The proposed\nmodel assumes that optimal transitions between tracks can be modelled and\npredicted by internal transitions within music tracks. We introduce modelling\nsequences of high-level music descriptors using RNNs and discuss an experiment\ninvolving different similarity functions, where the sequences are provided by a\nmusical structural analysis algorithm. Qualitative observations show that the\nproposed approach can effectively model transitions of music tracks in\nplaylists.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 11:07:56 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Choi", "Keunwoo", ""], ["Fazekas", "George", ""], ["Sandler", "Mark", ""]]}, {"id": "1606.02221", "submitter": "Giuseppe De Nittis", "authors": "Nicola Basilico, Giuseppe De Nittis, Nicola Gatti", "title": "Multi-resource defensive strategies for patrolling games with alarm\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security Games employ game theoretical tools to derive resource allocation\nstrategies in security domains. Recent works considered the presence of alarm\nsystems, even suffering various forms of uncertainty, and showed that\ndisregarding alarm signals may lead to arbitrarily bad strategies. The central\nproblem with an alarm system, unexplored in other Security Games, is finding\nthe best strategy to respond to alarm signals for each mobile defensive\nresource. The literature provides results for the basic single-resource case,\nshowing that even in that case the problem is computationally hard. In this\npaper, we focus on the challenging problem of designing algorithms scaling with\nmultiple resources. First, we focus on finding the minimum number of resources\nassuring non-null protection to every target. Then, we deal with the\ncomputation of multi-resource strategies with different degrees of coordination\namong resources. For each considered problem, we provide a computational\nanalysis and propose algorithmic methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 17:10:16 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Basilico", "Nicola", ""], ["De Nittis", "Giuseppe", ""], ["Gatti", "Nicola", ""]]}, {"id": "1606.02231", "submitter": "Diego Fernandez Slezak", "authors": "Facundo Carrillo and Natalia Mota and Mauro Copelli and Sidarta\n  Ribeiro and Mariano Sigman and Guillermo Cecchi and Diego Fernandez Slezak", "title": "Emotional Intensity analysis in Bipolar subjects", "comments": "Presented at MLINI-2015 workshop, 2015 (arXiv:cs/0101200)", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/19", "categories": "cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive availability of digital repositories of human thought opens\nradical novel way of studying the human mind. Natural language processing tools\nand computational models have evolved such that many mental conditions are\npredicted by analysing speech. Transcription of interviews and discourses are\nanalyzed using syntactic, grammatical or sentiment analysis to infer the mental\nstate. Here we set to investigate if classification of Bipolar and control\nsubjects is possible. We develop the Emotion Intensity Index based on the\nDictionary of Affect, and find that subjects categories are distinguishable.\nUsing classical classification techniques we get more than 75\\% of labeling\nperformance. These results sumed to previous studies show that current\nautomated speech analysis is capable of identifying altered mental states\ntowards a quantitative psychiatry.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 17:44:44 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Carrillo", "Facundo", ""], ["Mota", "Natalia", ""], ["Copelli", "Mauro", ""], ["Ribeiro", "Sidarta", ""], ["Sigman", "Mariano", ""], ["Cecchi", "Guillermo", ""], ["Slezak", "Diego Fernandez", ""]]}, {"id": "1606.02239", "submitter": "Mohd Anuar Mat Isa Dr.", "authors": "Mohd Anuar Mat Isa, Ramlan Mahmod, Nur Izura Udzir, Jamalul-lail Ab\n  Manan, Audun J{\\o}sang, Ali Dehghan Tanha", "title": "A Formal Calculus for International Relations Computation and Evaluation", "comments": "keywords: Relation Algebra, International Relations, Defense,\n  Relation Calculus, Foreign Policy, Politics Economy, Dempster-Shafer,\n  Subjective Logic, Common Criteria. arXiv admin note: text overlap with\n  arXiv:1604.00980", "journal-ref": "Journal of Current Research in Science, Issn 2322-5009, 4(2),\n  2016: 177-194", "doi": "10.13140/RG.2.1.3796.6321", "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This publication presents a relation computation or calculus for\ninternational relations using a mathematical modeling. It examined trust for\ninternational relations and its calculus, which related to Bayesian inference,\nDempster-Shafer theory and subjective logic. Based on an observation in the\nliterature, we found no literature discussing the calculus method for the\ninternational relations. To bridge this research gap, we propose a relation\nalgebra method for international relations computation. The proposed method\nwill allow a relation computation which is previously subjective and\nincomputable. We also present three international relations as case studies to\ndemonstrate the proposed method is a real-world scenario. The method will\ndeliver the relation computation for the international relations that to\nsupport decision makers in a government such as foreign ministry, defense\nministry, presidential or prime minister office. The Department of Defense\n(DoD) may use our method to determine a nation that can be identified as a\nfriendly, neutral or hostile nation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 10:13:26 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Isa", "Mohd Anuar Mat", ""], ["Mahmod", "Ramlan", ""], ["Udzir", "Nur Izura", ""], ["Manan", "Jamalul-lail Ab", ""], ["J\u00f8sang", "Audun", ""], ["Tanha", "Ali Dehghan", ""]]}, {"id": "1606.02355", "submitter": "Tommaso Furlanello", "authors": "Tommaso Furlanello, Jiaping Zhao, Andrew M. Saxe, Laurent Itti, Bosco\n  S. Tjan", "title": "Active Long Term Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning in artificial neural networks suffers from interference\nand forgetting when different tasks are learned sequentially. This paper\nintroduces the Active Long Term Memory Networks (A-LTM), a model of sequential\nmulti-task deep learning that is able to maintain previously learned\nassociation between sensory input and behavioral output while acquiring knew\nknowledge. A-LTM exploits the non-convex nature of deep neural networks and\nactively maintains knowledge of previously learned, inactive tasks using a\ndistillation loss. Distortions of the learned input-output map are penalized\nbut hidden layers are free to transverse towards new local optima that are more\nfavorable for the multi-task objective. We re-frame the McClelland's seminal\nHippocampal theory with respect to Catastrophic Inference (CI) behavior\nexhibited by modern deep architectures trained with back-propagation and\ninhomogeneous sampling of latent factors across epochs. We present empirical\nresults of non-trivial CI during continual learning in Deep Linear Networks\ntrained on the same task, in Convolutional Neural Networks when the task shifts\nfrom predicting semantic to graphical factors and during domain adaptation from\nsimple to complex environments. We present results of the A-LTM model's ability\nto maintain viewpoint recognition learned in the highly controlled iLab-20M\ndataset with 10 object categories and 88 camera viewpoints, while adapting to\nthe unstructured domain of Imagenet with 1,000 object categories.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 23:43:42 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Furlanello", "Tommaso", ""], ["Zhao", "Jiaping", ""], ["Saxe", "Andrew M.", ""], ["Itti", "Laurent", ""], ["Tjan", "Bosco S.", ""]]}, {"id": "1606.02378", "submitter": "Arunkumar Byravan", "authors": "Arunkumar Byravan and Dieter Fox", "title": "SE3-Nets: Learning Rigid Body Motion using Deep Neural Networks", "comments": "8 pages. To appear at the IEEE International Conference on Robotics\n  and Automation (ICRA), 2017. V2 Update: Final version submitted to ICRA with\n  experiments testing the robustness of the system to noise and preliminary\n  results on real world data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SE3-Nets, which are deep neural networks designed to model and\nlearn rigid body motion from raw point cloud data. Based only on sequences of\ndepth images along with action vectors and point wise data associations,\nSE3-Nets learn to segment effected object parts and predict their motion\nresulting from the applied force. Rather than learning point wise flow vectors,\nSE3-Nets predict SE3 transformations for different parts of the scene. Using\nsimulated depth data of a table top scene and a robot manipulator, we show that\nthe structure underlying SE3-Nets enables them to generate a far more\nconsistent prediction of object motion than traditional flow based networks.\nAdditional experiments with a depth camera observing a Baxter robot pushing\nobjects on a table show that SE3-Nets also work well on real data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 02:36:11 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 17:32:22 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 22:41:40 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Byravan", "Arunkumar", ""], ["Fox", "Dieter", ""]]}, {"id": "1606.02382", "submitter": "Petteri Teikari", "authors": "Petteri Teikari, Marc Santos, Charissa Poon, Kullervo Hynynen", "title": "Deep Learning Convolutional Networks for Multiphoton Microscopy\n  Vasculature Segmentation", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increasing trend to use deep learning frameworks\nfor both 2D consumer images and for 3D medical images. However, there has been\nlittle effort to use deep frameworks for volumetric vascular segmentation. We\nwanted to address this by providing a freely available dataset of 12 annotated\ntwo-photon vasculature microscopy stacks. We demonstrated the use of deep\nlearning framework consisting both 2D and 3D convolutional filters (ConvNet).\nOur hybrid 2D-3D architecture produced promising segmentation result. We\nderived the architectures from Lee et al. who used the ZNN framework initially\ndesigned for electron microscope image segmentation. We hope that by sharing\nour volumetric vasculature datasets, we will inspire other researchers to\nexperiment with vasculature dataset and improve the used network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 02:57:00 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Teikari", "Petteri", ""], ["Santos", "Marc", ""], ["Poon", "Charissa", ""], ["Hynynen", "Kullervo", ""]]}, {"id": "1606.02396", "submitter": "Ardavan Saeedi", "authors": "Tejas D. Kulkarni, Ardavan Saeedi, Simanta Gautam, Samuel J. Gershman", "title": "Deep Successor Reinforcement Learning", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robust value functions given raw observations and rewards is now\npossible with model-free and model-based deep reinforcement learning\nalgorithms. There is a third alternative, called Successor Representations\n(SR), which decomposes the value function into two components -- a reward\npredictor and a successor map. The successor map represents the expected future\nstate occupancy from any given state and the reward predictor maps states to\nscalar rewards. The value function of a state can be computed as the inner\nproduct between the successor map and the reward weights. In this paper, we\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\nlearning framework. DSR has several appealing properties including: increased\nsensitivity to distal reward changes due to factorization of reward and world\ndynamics, and the ability to extract bottleneck states (subgoals) given\nsuccessor maps trained under a random policy. We show the efficacy of our\napproach on two diverse environments given raw pixel observations -- simple\ngrid-world domains (MazeBase) and the Doom game engine.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 04:48:49 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Saeedi", "Ardavan", ""], ["Gautam", "Simanta", ""], ["Gershman", "Samuel J.", ""]]}, {"id": "1606.02407", "submitter": "Rathinakumar Appuswamy", "authors": "Rathinakumar Appuswamy, Tapan Nayak, John Arthur, Steven Esser, Paul\n  Merolla, Jeffrey Mckinstry, Timothy Melano, Myron Flickner, Dharmendra Modha", "title": "Structured Convolution Matrices for Energy-efficient Deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a relationship between network representation in energy-efficient\nneuromorphic architectures and block Toplitz convolutional matrices. Inspired\nby this connection, we develop deep convolutional networks using a family of\nstructured convolutional matrices and achieve state-of-the-art trade-off\nbetween energy efficiency and classification accuracy for well-known image\nrecognition tasks. We also put forward a novel method to train binary\nconvolutional networks by utilising an existing connection between\nnoisy-rectified linear units and binary activations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 05:31:43 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Appuswamy", "Rathinakumar", ""], ["Nayak", "Tapan", ""], ["Arthur", "John", ""], ["Esser", "Steven", ""], ["Merolla", "Paul", ""], ["Mckinstry", "Jeffrey", ""], ["Melano", "Timothy", ""], ["Flickner", "Myron", ""], ["Modha", "Dharmendra", ""]]}, {"id": "1606.02421", "submitter": "Igor Colin", "authors": "Igor Colin, Aur\\'elien Bellet, Joseph Salmon, St\\'ephan\n  Cl\\'emen\\c{c}on", "title": "Gossip Dual Averaging for Decentralized Optimization of Pairwise\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized networks (of sensors, connected objects, etc.), there is an\nimportant need for efficient algorithms to optimize a global cost function, for\ninstance to learn a global model from the local data collected by each\ncomputing unit. In this paper, we address the problem of decentralized\nminimization of pairwise functions of the data points, where these points are\ndistributed over the nodes of a graph defining the communication topology of\nthe network. This general problem finds applications in ranking, distance\nmetric learning and graph inference, among others. We propose new gossip\nalgorithms based on dual averaging which aims at solving such problems both in\nsynchronous and asynchronous settings. The proposed framework is flexible\nenough to deal with constrained and regularized variants of the optimization\nproblem. Our theoretical analysis reveals that the proposed algorithms preserve\nthe convergence rate of centralized dual averaging up to an additive bias term.\nWe present numerical simulations on Area Under the ROC Curve (AUC) maximization\nand metric learning problems which illustrate the practical interest of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 07:01:47 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Colin", "Igor", ""], ["Bellet", "Aur\u00e9lien", ""], ["Salmon", "Joseph", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "1606.02447", "submitter": "Sida Wang", "authors": "Sida I. Wang and Percy Liang and Christopher D. Manning", "title": "Learning Language Games through Interaction", "comments": "11 pages, ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new language learning setting relevant to building adaptive\nnatural language interfaces. It is inspired by Wittgenstein's language games: a\nhuman wishes to accomplish some task (e.g., achieving a certain configuration\nof blocks), but can only communicate with a computer, who performs the actual\nactions (e.g., removing all red blocks). The computer initially knows nothing\nabout language and therefore must learn it from scratch through interaction,\nwhile the human adapts to the computer's capabilities. We created a game in a\nblocks world and collected interactions from 100 people playing it. First, we\nanalyze the humans' strategies, showing that using compositionality and\navoiding synonyms correlates positively with task performance. Second, we\ncompare computer strategies, showing how to quickly learn a semantic parsing\nmodel from scratch, and that modeling pragmatics further accelerates learning\nfor successful players.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 08:27:09 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Wang", "Sida I.", ""], ["Liang", "Percy", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1606.02485", "submitter": "Laurel Riek", "authors": "Cory J. Hayes, Maryam Moosaei, Laurel D. Riek", "title": "Exploring Implicit Human Responses to Robot Mistakes in a Learning from\n  Demonstration Task", "comments": "7 pages, 2 figures, IEEE RO-MAN 2016, IEEE International Symposium on\n  Robot and Human Interactive Communication (RO-MAN 2016)", "journal-ref": null, "doi": "10.1109/ROMAN.2016.7745138", "report-no": null, "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As robots enter human environments, they will be expected to accomplish a\ntremendous range of tasks. It is not feasible for robot designers to\npre-program these behaviors or know them in advance, so one way to address this\nis through end-user programming, such as via learning from demonstration (LfD).\nWhile significant work has been done on the mechanics of enabling robot\nlearning from human teachers, one unexplored aspect is enabling mutual feedback\nbetween both the human teacher and robot during the learning process, i.e.,\nimplicit learning. In this paper, we explore one aspect of this mutual\nunderstanding, grounding sequences, where both a human and robot provide\nnon-verbal feedback to signify their mutual understanding during interaction.\nWe conducted a study where people taught an autonomous humanoid robot a dance,\nand performed gesture analysis to measure people's responses to the robot\nduring correct and incorrect demonstrations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 10:07:01 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Hayes", "Cory J.", ""], ["Moosaei", "Maryam", ""], ["Riek", "Laurel D.", ""]]}, {"id": "1606.02542", "submitter": "Christian Walder Dr", "authors": "Christian Walder", "title": "Symbolic Music Data Version 1.0", "comments": "arXiv admin note: substantial text overlap with arXiv:1606.01368", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we introduce a new dataset designed for training machine\nlearning models of symbolic music data. Five datasets are provided, one of\nwhich is from a newly collected corpus of 20K midi files. We describe our\npreprocessing and cleaning pipeline, which includes the exclusion of a number\nof files based on scores from a previously developed probabilistic machine\nlearning model. We also define training, testing and validation splits for the\nnew dataset, based on a clustering scheme which we also describe. Some simple\nhistograms are included.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 13:19:01 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Walder", "Christian", ""]]}, {"id": "1606.02556", "submitter": "Diane Bouchacourt", "authors": "Diane Bouchacourt, M. Pawan Kumar, Sebastian Nowozin", "title": "DISCO Nets: DISsimilarity COefficient Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new type of probabilistic model which we call DISsimilarity\nCOefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample\nfrom a posterior distribution parametrised by a neural network. During\ntraining, DISCO Nets are learned by minimising the dissimilarity coefficient\nbetween the true distribution and the estimated distribution. This allows us to\ntailor the training to the loss related to the task at hand. We empirically\nshow that (i) by modeling uncertainty on the output value, DISCO Nets\noutperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets\naccurately model the uncertainty of the output, outperforming existing\nprobabilistic models based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 13:57:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 16:01:04 GMT"}, {"version": "v3", "created": "Thu, 16 Jun 2016 07:45:20 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 15:19:45 GMT"}, {"version": "v5", "created": "Fri, 28 Oct 2016 11:27:45 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Kumar", "M. Pawan", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "1606.02560", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao and Maxine Eskenazi", "title": "Towards End-to-End Learning for Dialog State Tracking and Management\n  using Deep Reinforcement Learning", "comments": "In proceeding of SIGDIAL 2016. Added changes based-on peer review,\n  including: 1. Added references, 2. fixed typos in text and figures, 3. added\n  minor change to introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an end-to-end framework for task-oriented dialog systems\nusing a variant of Deep Recurrent Q-Networks (DRQN). The model is able to\ninterface with a relational database and jointly learn policies for both\nlanguage understanding and dialog strategy. Moreover, we propose a hybrid\nalgorithm that combines the strength of reinforcement learning and supervised\nlearning to achieve faster learning speed. We evaluated the proposed model on a\n20 Question Game conversational game simulator. Results show that the proposed\nmethod outperforms the modular-based baseline and learns a distributed\nrepresentation of the latent dialog state.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:03:25 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2016 21:50:30 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1606.02562", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Kyusong Lee, Maxine Eskenazi", "title": "DialPort: Connecting the Spoken Dialog Research Community to Real User\n  Data", "comments": "Under Peer Review of SigDial 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a new spoken dialog portal that connects systems\nproduced by the spoken dialog academic research community and gives them access\nto real users. We introduce a distributed, multi-modal, multi-agent prototype\ndialog framework that affords easy integration with various remote resources,\nranging from end-to-end dialog systems to external knowledge APIs. To date, the\nDialPort portal has successfully connected to the multi-domain spoken dialog\nsystem at Cambridge University, the NOAA (National Oceanic and Atmospheric\nAdministration) weather API and the Yelp API.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:08:21 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lee", "Kyusong", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1606.02583", "submitter": "Dieter Vanderelst", "authors": "Dieter Vanderelst, Alan Winfield", "title": "The Dark Side of Ethical Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns over the risks associated with advances in Artificial Intelligence\nhave prompted calls for greater efforts toward robust and beneficial AI,\nincluding machine ethics. Recently, roboticists have responded by initiating\nthe development of so-called ethical robots. These robots would, ideally,\nevaluate the consequences of their actions and morally justify their choices.\nThis emerging field promises to develop extensively over the next years.\nHowever, in this paper, we point out an inherent limitation of the emerging\nfield of ethical robots. We show that building ethical robots also necessarily\nfacilitates the construction of unethical robots. In three experiments, we show\nthat it is remarkably easy to modify an ethical robot so that it behaves\ncompetitively, or even aggressively. The reason for this is that the specific\nAI, required to make an ethical robot, can always be exploited to make\nunethical robots. Hence, the development of ethical robots will not guarantee\nthe responsible deployment of AI. While advocating for ethical robots, we\nconclude that preventing the misuse of robots is beyond the scope of\nengineering, and requires instead governance frameworks underpinned by\nlegislation. Without this, the development of ethical robots will serve to\nincrease the risks of robotic malpractice instead of diminishing it.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:47:35 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Vanderelst", "Dieter", ""], ["Winfield", "Alan", ""]]}, {"id": "1606.02645", "submitter": "Jakub Kowalski", "authors": "Jakub Kowalski, Jakub Sutowicz, Marek Szyku{\\l}a", "title": "Simplified Boardgames", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize Simplified Boardgames language, which describes a subclass of\narbitrary board games. The language structure is based on the regular\nexpressions, which makes the rules easily machine-processable while keeping the\nrules concise and fairly human-readable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 17:29:17 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 14:02:55 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["Kowalski", "Jakub", ""], ["Sutowicz", "Jakub", ""], ["Szyku\u0142a", "Marek", ""]]}, {"id": "1606.02647", "submitter": "Marc G. Bellemare", "authors": "R\\'emi Munos, Tom Stepleton, Anna Harutyunyan, Marc G. Bellemare", "title": "Safe and Efficient Off-Policy Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we take a fresh look at some old and new algorithms for\noff-policy, return-based reinforcement learning. Expressing these in a common\nform, we derive a novel algorithm, Retrace($\\lambda$), with three desired\nproperties: (1) it has low variance; (2) it safely uses samples collected from\nany behaviour policy, whatever its degree of \"off-policyness\"; and (3) it is\nefficient as it makes the best use of samples collected from near on-policy\nbehaviour policies. We analyze the contractive nature of the related operator\nunder both off-policy policy evaluation and control settings and derive online\nsample-based algorithms. We believe this is the first return-based off-policy\ncontrol algorithm converging a.s. to $Q^*$ without the GLIE assumption (Greedy\nin the Limit with Infinite Exploration). As a corollary, we prove the\nconvergence of Watkins' Q($\\lambda$), which was an open problem since 1989. We\nillustrate the benefits of Retrace($\\lambda$) on a standard suite of Atari 2600\ngames.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 17:34:13 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 21:26:31 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Munos", "R\u00e9mi", ""], ["Stepleton", "Tom", ""], ["Harutyunyan", "Anna", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1606.02710", "submitter": "Berat Dogan", "authors": "Berat Do\\u{g}an", "title": "A Modified Vortex Search Algorithm for Numerical Function Optimization", "comments": "18 pages, 7 figures", "journal-ref": "International journal of Artificial Intelligence & Applications\n  (IJAIA), Volume 7, Number 3, May 2016", "doi": "10.5121/ijaia.2016.7304", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Vortex Search (VS) algorithm is one of the recently proposed\nmetaheuristic algorithms which was inspired from the vortical flow of the\nstirred fluids. Although the VS algorithm is shown to be a good candidate for\nthe solution of certain optimization problems, it also has some drawbacks. In\nthe VS algorithm, candidate solutions are generated around the current best\nsolution by using a Gaussian distribution at each iteration pass. This provides\nsimplicity to the algorithm but it also leads to some problems along.\nEspecially, for the functions those have a number of local minimum points, to\nselect a single point to generate candidate solutions leads the algorithm to\nbeing trapped into a local minimum point. Due to the adaptive step-size\nadjustment scheme used in the VS algorithm, the locality of the created\ncandidate solutions is increased at each iteration pass. Therefore, if the\nalgorithm cannot escape a local point as quickly as possible, it becomes much\nmore difficult for the algorithm to escape from that point in the latter\niterations. In this study, a modified Vortex Search algorithm (MVS) is proposed\nto overcome above mentioned drawback of the existing VS algorithm. In the MVS\nalgorithm, the candidate solutions are generated around a number of points at\neach iteration pass. Computational results showed that with the help of this\nmodification the global search ability of the existing VS algorithm is improved\nand the MVS algorithm outperformed the existing VS algorithm, PSO2011 and ABC\nalgorithms for the benchmark numerical function set.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 12:00:28 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Do\u011fan", "Berat", ""]]}, {"id": "1606.02767", "submitter": "Norbert B\\'atfai Ph.D.", "authors": "Norbert B\\'atfai", "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "comments": "11 pages, added a missing cc* value and the appearance of Table 1 is\n  improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the point of view of a programmer, the robopsychology is a synonym for\nthe activity is done by developers to implement their machine learning\napplications. This robopsychological approach raises some fundamental\ntheoretical questions of machine learning. Our discussion of these questions is\nconstrained to Turing machines. Alan Turing had given an algorithm (aka the\nTuring Machine) to describe algorithms. If it has been applied to describe\nitself then this brings us to Turing's notion of the universal machine. In the\npresent paper, we investigate algorithms to write algorithms. From a pedagogy\npoint of view, this way of writing programs can be considered as a combination\nof learning by listening and learning by doing due to it is based on applying\nagent technology and machine learning. As the main result we introduce the\nproblem of learning and then we show that it cannot easily be handled in\nreality therefore it is reasonable to use machine learning algorithm for\nlearning Turing machines.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 21:46:20 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 13:27:01 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["B\u00e1tfai", "Norbert", ""]]}, {"id": "1606.02807", "submitter": "Vivek Veeriah", "authors": "Vivek Veeriah, Patrick M. Pilarski, Richard S. Sutton", "title": "Face valuing: Training user interfaces with facial expressions and\n  reinforcement learning", "comments": "7 pages, 4 figures, IJCAI 2016 - Interactive Machine Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important application of interactive machine learning is extending or\namplifying the cognitive and physical capabilities of a human. To accomplish\nthis, machines need to learn about their human users' intentions and adapt to\ntheir preferences. In most current research, a user has conveyed preferences to\na machine using explicit corrective or instructive feedback; explicit feedback\nimposes a cognitive load on the user and is expensive in terms of human effort.\nThe primary objective of the current work is to demonstrate that a learning\nagent can reduce the amount of explicit feedback required for adapting to the\nuser's preferences pertaining to a task by learning to perceive a value of its\nbehavior from the human user, particularly from the user's facial\nexpressions---we call this face valuing. We empirically evaluate face valuing\non a grip selection task. Our preliminary results suggest that an agent can\nquickly adapt to a user's changing preferences with minimal explicit feedback\nby learning a value function that maps facial features extracted from a camera\nimage to expected future reward. We believe that an agent learning to perceive\na value from the body language of its human user is complementary to existing\ninteractive machine learning approaches and will help in creating successful\nhuman-machine interactive applications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 03:06:46 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Veeriah", "Vivek", ""], ["Pilarski", "Patrick M.", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1606.02825", "submitter": "Miroslav Dud\\'ik", "authors": "Christian Kroer, Miroslav Dud\\'ik, S\\'ebastien Lahaie, Sivaraman\n  Balakrishnan", "title": "Arbitrage-Free Combinatorial Market Making via Integer Programming", "comments": null, "journal-ref": null, "doi": "10.1145/2940716.2940767", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new combinatorial market maker that operates arbitrage-free\ncombinatorial prediction markets specified by integer programs. Although the\nproblem of arbitrage-free pricing, while maintaining a bound on the subsidy\nprovided by the market maker, is #P-hard in the worst case, we posit that the\ntypical case might be amenable to modern integer programming (IP) solvers. At\nthe crux of our method is the Frank-Wolfe (conditional gradient) algorithm\nwhich is used to implement a Bregman projection aligned with the market maker's\ncost function, using an IP solver as an oracle. We demonstrate the tractability\nand improved accuracy of our approach on real-world prediction market data from\ncombinatorial bets placed on the 2010 NCAA Men's Division I Basketball\nTournament, where the outcome space is of size 2^63. To our knowledge, this is\nthe first implementation and empirical evaluation of an arbitrage-free\ncombinatorial prediction market on this scale.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 04:59:50 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 13:48:30 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Kroer", "Christian", ""], ["Dud\u00edk", "Miroslav", ""], ["Lahaie", "S\u00e9bastien", ""], ["Balakrishnan", "Sivaraman", ""]]}, {"id": "1606.02854", "submitter": "Ioannis Partalas", "authors": "Ioannis Partalas, Georgios Balikas", "title": "e-Commerce product classification: our participation at cDiscount 2015\n  challenge", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes our participation in the cDiscount 2015 challenge where\nthe goal was to classify product items in a predefined taxonomy of products.\nOur best submission yielded an accuracy score of 64.20\\% in the private part of\nthe leaderboard and we were ranked 10th out of 175 participating teams. We\nfollowed a text classification approach employing mainly linear models. The\nfinal solution was a weighted voting system which combined a variety of trained\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 08:06:00 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Partalas", "Ioannis", ""], ["Balikas", "Georgios", ""]]}, {"id": "1606.02858", "submitter": "Danqi Chen", "authors": "Danqi Chen, Jason Bolton, Christopher D. Manning", "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", "comments": "ACL 2016, updated results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling a computer to understand a document so that it can answer\ncomprehension questions is a central, yet unsolved goal of NLP. A key factor\nimpeding its solution by machine learned systems is the limited availability of\nhuman-annotated data. Hermann et al. (2015) seek to solve this problem by\ncreating over a million training examples by pairing CNN and Daily Mail news\narticles with their summarized bullet points, and show that a neural network\ncan then be trained to give good performance on this task. In this paper, we\nconduct a thorough examination of this new reading comprehension task. Our\nprimary aim is to understand what depth of language understanding is required\nto do well on this task. We approach this from one side by doing a careful\nhand-analysis of a small subset of the problems and from the other by showing\nthat simple, carefully designed systems can obtain accuracies of 73.6% and\n76.6% on these two datasets, exceeding current state-of-the-art results by\n7-10% and approaching what we believe is the ceiling for performance on this\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 08:19:16 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 21:21:19 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Chen", "Danqi", ""], ["Bolton", "Jason", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1606.02877", "submitter": "Feng Wu", "authors": "Dongcai Lu, Feng Wu, Xiaoping Chen", "title": "Understanding User Instructions by Utilizing Open Knowledge for Service\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding user instructions in natural language is an active research\ntopic in AI and robotics. Typically, natural user instructions are high-level\nand can be reduced into low-level tasks expressed in common verbs (e.g.,\n`take', `get', `put'). For robots understanding such instructions, one of the\nkey challenges is to process high-level user instructions and achieve the\nspecified tasks with robots' primitive actions. To address this, we propose\nnovel algorithms by utilizing semantic roles of common verbs defined in\nsemantic dictionaries and integrating multiple open knowledge to generate task\nplans. Specifically, we present a new method for matching and recovering\nsemantics of user instructions and a novel task planner that exploits\nfunctional knowledge of robot's action model. To verify and evaluate our\napproach, we implemented a prototype system using knowledge from several open\nresources. Experiments on our system confirmed the correctness and efficiency\nof our algorithms. Notably, our system has been deployed in the KeJia robot,\nwhich participated the annual RoboCup@Home competitions in the past three years\nand achieved encouragingly high scores in the benchmark tests.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 09:02:16 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Lu", "Dongcai", ""], ["Wu", "Feng", ""], ["Chen", "Xiaoping", ""]]}, {"id": "1606.02899", "submitter": "Manuel Mazzara", "authors": "Jordi Vallverd\\'u, Max Talanov, Salvatore Distefano, Manuel Mazzara,\n  Alexander Tchitchigin, Ildar Nurgaliev", "title": "A Cognitive Architecture for the Implementation of Emotions in Computing\n  Systems", "comments": null, "journal-ref": "BICA, Volume 15, January 2016, Pages 34-40", "doi": "10.1016/j.bica.2015.11.002", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new neurobiologically-inspired affective cognitive\narchitecture: NEUCOGAR (NEUromodulating COGnitive ARchitecture). The objective\nof NEUCOGAR is the identification of a mapping from the influence of serotonin,\ndopamine and noradrenaline to the computing processes based on Von Neuman's\narchitecture, in order to implement affective phenomena which can operate on\nthe Turing's machine model. As basis of the modeling we use and extend the\nL\\\"ovheim Cube of Emotion with parameters of the Von Neumann architecture.\nValidation is conducted via simulation on a computing system of dopamine\nneuromodulation and its effects on the Cortex. In the experimental phase of the\nproject, the increase of computing power and storage redistribution due to\nemotion stimulus modulated by the dopamine system, confirmed the soundness of\nthe model.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 10:43:21 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Vallverd\u00fa", "Jordi", ""], ["Talanov", "Max", ""], ["Distefano", "Salvatore", ""], ["Mazzara", "Manuel", ""], ["Tchitchigin", "Alexander", ""], ["Nurgaliev", "Ildar", ""]]}, {"id": "1606.02979", "submitter": "Shaohua Li", "authors": "Shaohua Li, Tat-Seng Chua, Jun Zhu, Chunyan Miao", "title": "Generative Topic Embedding: a Continuous Representation of Documents\n  (Extended Version with Proofs)", "comments": "13 pages. The original version has been accepted in ACL 2016 as a\n  long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding maps words into a low-dimensional continuous embedding space\nby exploiting the local word collocation patterns in a small context window. On\nthe other hand, topic modeling maps documents onto a low-dimensional topic\nspace, by utilizing the global word collocation patterns in the same document.\nThese two types of patterns are complementary. In this paper, we propose a\ngenerative topic embedding model to combine the two types of patterns. In our\nmodel, topics are represented by embedding vectors, and are shared across\ndocuments. The probability of each word is influenced by both its local context\nand its topic. A variational inference method yields the topic embeddings as\nwell as the topic mixing proportions for each document. Jointly they represent\nthe document in a low-dimensional continuous space. In two document\nclassification tasks, our method performs better than eight existing methods,\nwith fewer features. In addition, we illustrate with an example that our method\ncan generate coherent topics even based on only one document.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 14:45:39 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 14:49:07 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Li", "Shaohua", ""], ["Chua", "Tat-Seng", ""], ["Zhu", "Jun", ""], ["Miao", "Chunyan", ""]]}, {"id": "1606.03002", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn and Tim Rockt\\\"aschel", "title": "MuFuRU: The Multi-Function Recurrent Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks such as the GRU and LSTM found wide adoption in\nnatural language processing and achieve state-of-the-art results for many\ntasks. These models are characterized by a memory state that can be written to\nand read from by applying gated composition operations to the current input and\nthe previous state. However, they only cover a small subset of potentially\nuseful compositions. We propose Multi-Function Recurrent Units (MuFuRUs) that\nallow for arbitrary differentiable functions as composition operations.\nFurthermore, MuFuRUs allow for an input- and state-dependent choice of these\ncomposition operations that is learned. Our experiments demonstrate that the\nadditional functionality helps in different sequence modeling tasks, including\nthe evaluation of propositional logic formulae, language modeling and sentiment\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 15:41:17 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1606.03044", "submitter": "Bob Sturm", "authors": "Bob L. Sturm", "title": "The \"Horse'' Inside: Seeking Causes Behind the Behaviours of Music\n  Content Analysis Systems", "comments": "32 pages, 17 figures, this work was accepted for publication in a\n  journal special issue in Apr. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building systems that possess the sensitivity and intelligence to identify\nand describe high-level attributes in music audio signals continues to be an\nelusive goal, but one that surely has broad and deep implications for a wide\nvariety of applications. Hundreds of papers have so far been published toward\nthis goal, and great progress appears to have been made. Some systems produce\nremarkable accuracies at recognising high-level semantic concepts, such as\nmusic style, genre and mood. However, it might be that these numbers do not\nmean what they seem. In this paper, we take a state-of-the-art music content\nanalysis system and investigate what causes it to achieve exceptionally high\nperformance in a benchmark music audio dataset. We dissect the system to\nunderstand its operation, determine its sensitivities and limitations, and\npredict the kinds of knowledge it could and could not possess about music. We\nperform a series of experiments to illuminate what the system has actually\nlearned to do, and to what extent it is performing the intended music listening\ntask. Our results demonstrate how the initial manifestation of music\nintelligence in this state-of-the-art can be deceptive. Our work provides\nconstructive directions toward developing music content analysis systems that\ncan address the music information and creation needs of real-world users.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 18:10:31 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Sturm", "Bob L.", ""]]}, {"id": "1606.03137", "submitter": "Dylan Hadfield-Menell", "authors": "Dylan Hadfield-Menell, Anca Dragan, Pieter Abbeel, Stuart Russell", "title": "Cooperative Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an autonomous system to be helpful to humans and to pose no unwarranted\nrisks, it needs to align its values with those of the humans in its environment\nin such a way that its actions contribute to the maximization of value for the\nhumans. We propose a formal definition of the value alignment problem as\ncooperative inverse reinforcement learning (CIRL). A CIRL problem is a\ncooperative, partial-information game with two agents, human and robot; both\nare rewarded according to the human's reward function, but the robot does not\ninitially know what this is. In contrast to classical IRL, where the human is\nassumed to act optimally in isolation, optimal CIRL solutions produce behaviors\nsuch as active teaching, active learning, and communicative actions that are\nmore effective in achieving value alignment. We show that computing optimal\njoint policies in CIRL games can be reduced to solving a POMDP, prove that\noptimality in isolation is suboptimal in CIRL, and derive an approximate CIRL\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 22:39:54 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 18:25:07 GMT"}, {"version": "v3", "created": "Sat, 12 Nov 2016 20:33:43 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Hadfield-Menell", "Dylan", ""], ["Dragan", "Anca", ""], ["Abbeel", "Pieter", ""], ["Russell", "Stuart", ""]]}, {"id": "1606.03152", "submitter": "Mehdi Fatemi", "authors": "Mehdi Fatemi, Layla El Asri, Hannes Schulz, Jing He, Kaheer Suleman", "title": "Policy Networks with Two-Stage Training for Dialogue Systems", "comments": "SIGDial 2016 (Submitted: May 2016; Accepted: Jun 30, 2016)", "journal-ref": "Proceedings of the SIGDIAL 2016 Conference, pages 101--110, Los\n  Angeles, USA, 13-15 September 2016. Association for Computational Linguistics", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to use deep policy networks which are trained with\nan advantage actor-critic method for statistically optimised dialogue systems.\nFirst, we show that, on summary state and action spaces, deep Reinforcement\nLearning (RL) outperforms Gaussian Processes methods. Summary state and action\nspaces lead to good performance but require pre-engineering effort, RL\nknowledge, and domain expertise. In order to remove the need to define such\nsummary spaces, we show that deep RL can also be trained efficiently on the\noriginal state and action spaces. Dialogue systems based on partially\nobservable Markov decision processes are known to require many dialogues to\ntrain, which makes them unappealing for practical deployment. We show that a\ndeep RL method based on an actor-critic architecture can exploit a small amount\nof data very efficiently. Indeed, with only a few hundred dialogues collected\nwith a handcrafted policy, the actor-critic deep learner is considerably\nbootstrapped from a combination of supervised and batch RL. In addition,\nconvergence to an optimal policy is significantly sped up compared to other\ndeep RL methods initialized on the data with batch RL. All experiments are\nperformed on a restaurant domain derived from the Dialogue State Tracking\nChallenge 2 (DSTC2) dataset.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 01:02:19 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 16:20:18 GMT"}, {"version": "v3", "created": "Sat, 20 Aug 2016 21:20:21 GMT"}, {"version": "v4", "created": "Mon, 12 Sep 2016 16:23:42 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Fatemi", "Mehdi", ""], ["Asri", "Layla El", ""], ["Schulz", "Hannes", ""], ["He", "Jing", ""], ["Suleman", "Kaheer", ""]]}, {"id": "1606.03191", "submitter": "Ai Munandar Tb", "authors": "Tb. Ai Munandar, Retantyo Wardoyo", "title": "Fuzzy-Klassen Model for Development Disparities Analysis based on Gross\n  Regional Domestic Product Sector of a Region", "comments": "6 Pages, 1 Figures, 5 Tables", "journal-ref": null, "doi": "10.5120/ijca2015905389", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of regional development imbalances quadrant has a very important\nmeaning in order to see the extent of achievement of the development of certain\nareas as well as the difference. Factors that could be used as a tool to\nmeasure the inequality of development is to look at the average growth and\ndevelopment contribution of each sector of Gross Regional Domestic Product\n(GRDP) based on the analyzed region and the reference region. This study\ndiscusses the development of a model to determine the regional development\nimbalances using fuzzy approach system, and the rules of typology Klassen. The\nmodel is then called fuzzy-Klassen. Implications Product Mamdani fuzzy system\nis used in the model as an inference engine to generate output after\ndefuzzyfication process. Application of MATLAB is used as a tool of analysis in\nthis study. The test a result of Kota Cilegon is shows that there are\nsignificant differences between traditional Klassen typology analyses with the\nresults of the model developed. Fuzzy model-Klassen shows GRDP sector\ninequality Cilegon City is dominated by Quadrant I (K4), where status is the\nsector forward and grows exponentially. While the traditional Klassen typology,\nhalf of GRDP sector is dominated by Quadrant IV (K4) with a sector that is\nlagging relative status.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 05:55:56 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Munandar", "Tb. Ai", ""], ["Wardoyo", "Retantyo", ""]]}, {"id": "1606.03229", "submitter": "Manuel Mazzara", "authors": "Michael W. Bridges, Salvatore Distefano, Manuel Mazzara, Marat\n  Minlebaev, Max Talanov, Jordi Vallverd\\'u", "title": "Towards Anthropo-inspired Computational Systems: the $P^3$ Model", "comments": null, "journal-ref": "In proceedings of the 9th International KES Conference on AGENTS\n  AND MULTI-AGENT SYSTEMS: TECHNOLOGIES AND APPLICATIONS, 2015", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a model which aim is providing a more coherent framework\nfor agents design. We identify three closely related anthropo-centered domains\nworking on separate functional levels. Abstracting from human physiology,\npsychology, and philosophy we create the $P^3$ model to be used as a multi-tier\napproach to deal with complex class of problems. The three layers identified in\nthis model have been named PhysioComputing, MindComputing, and MetaComputing.\nSeveral instantiations of this model are finally presented related to different\nIT areas such as artificial intelligence, distributed computing, software and\nservice engineering.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 08:39:22 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Bridges", "Michael W.", ""], ["Distefano", "Salvatore", ""], ["Mazzara", "Manuel", ""], ["Minlebaev", "Marat", ""], ["Talanov", "Max", ""], ["Vallverd\u00fa", "Jordi", ""]]}, {"id": "1606.03244", "submitter": "Martin Cooper", "authors": "Martin C. Cooper, Andreas Herzig, Faustine Maffre, Fr\\'ed\\'eric Maris\n  and Pierre R\\'egnier", "title": "Simple epistemic planning: generalised gossiping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gossip problem, in which information (known as secrets) must be shared\namong a certain number of agents using the minimum number of calls, is of\ninterest in the conception of communication networks and protocols. We extend\nthe gossip problem to arbitrary epistemic depths. For example, we may require\nnot only that all agents know all secrets but also that all agents know that\nall agents know all secrets. We give optimal protocols for various versions of\nthe generalised gossip problem, depending on the graph of communication links,\nin the case of two-way communications, one-way communications and parallel\ncommunication. We also study different variants which allow us to impose\nnegative goals such as that certain agents must not know certain secrets. We\nshow that in the presence of negative goals testing the existence of a\nsuccessful protocol is NP-complete whereas this is always polynomial-time in\nthe case of purely positive goals.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 09:31:26 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 15:49:20 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Cooper", "Martin C.", ""], ["Herzig", "Andreas", ""], ["Maffre", "Faustine", ""], ["Maris", "Fr\u00e9d\u00e9ric", ""], ["R\u00e9gnier", "Pierre", ""]]}, {"id": "1606.03254", "submitter": "Verena Rieser", "authors": "Dimitra Gkatzia and Oliver Lemon and Verena Rieser", "title": "Natural Language Generation enhances human decision-making with\n  uncertain information", "comments": "54th annual meeting of the Association for Computational Linguistics\n  (ACL), Berlin 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making is often dependent on uncertain data, e.g. data associated\nwith confidence scores or probabilities. We present a comparison of different\ninformation presentations for uncertain data and, for the first time, measure\ntheir effects on human decision-making. We show that the use of Natural\nLanguage Generation (NLG) improves decision-making under uncertainty, compared\nto state-of-the-art graphical-based representation methods. In a task-based\nstudy with 442 adults, we found that presentations using NLG lead to 24% better\ndecision-making on average than the graphical presentations, and to 44% better\ndecision-making when NLG is combined with graphics. We also show that women\nachieve significantly better results when presented with NLG output (an 87%\nincrease on average compared to graphical presentations).\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 10:12:13 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 10:11:49 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Gkatzia", "Dimitra", ""], ["Lemon", "Oliver", ""], ["Rieser", "Verena", ""]]}, {"id": "1606.03289", "submitter": "Jaroslav Bendik", "authors": "Jaroslav Bendik, Nikola Benes, Ivana Cerna, Jiri Barnat", "title": "Tunable Online MUS/MSS Enumeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In various areas of computer science, the problem of dealing with a set of\nconstraints arises. If the set of constraints is unsatisfiable, one may ask for\na minimal description of the reason for this unsatisifi- ability. Minimal\nunsatisifable subsets (MUSes) and maximal satisifiable subsets (MSSes) are two\nkinds of such minimal descriptions. The goal of this work is the enumeration of\nMUSes and MSSes for a given constraint system. As such full enumeration may be\nintractable in general, we focus on building an online algorithm, which\nproduces MUSes/MSSes in an on-the-fly manner as soon as they are discovered.\nThe problem has been studied before even in its online version. However, our\nalgorithm uses a novel approach that is able to outperform current state-of-the\nart algorithms for online MUS/MSS enumeration. Moreover, the performance of our\nalgorithm can be adjusted using tunable parameters. We evaluate the algorithm\non a set of benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 12:24:35 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Bendik", "Jaroslav", ""], ["Benes", "Nikola", ""], ["Cerna", "Ivana", ""], ["Barnat", "Jiri", ""]]}, {"id": "1606.03298", "submitter": "Brian Ruttenberg", "authors": "Avi Pfeffer, Brian Ruttenberg, William Kretschmer", "title": "Structured Factored Inference: A Framework for Automated Reasoning in\n  Probabilistic Programming Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning on large and complex real-world models is a computationally\ndifficult task, yet one that is required for effective use of many AI\napplications. A plethora of inference algorithms have been developed that work\nwell on specific models or only on parts of general models. Consequently, a\nsystem that can intelligently apply these inference algorithms to different\nparts of a model for fast reasoning is highly desirable. We introduce a new\nframework called structured factored inference (SFI) that provides the\nfoundation for such a system. Using models encoded in a probabilistic\nprogramming language, SFI provides a sound means to decompose a model into\nsub-models, apply an inference algorithm to each sub-model, and combine the\nresulting information to answer a query. Our results show that SFI is nearly as\naccurate as exact inference yet retains the benefits of approximate inference\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 12:53:01 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Pfeffer", "Avi", ""], ["Ruttenberg", "Brian", ""], ["Kretschmer", "William", ""]]}, {"id": "1606.03329", "submitter": "Jordi Levy", "authors": "Carlos Ans\\'otegui, Maria Luisa Bonet, Jes\\'us Gir\\'aldez-Cru, Jordi\n  Levy, Laurent Simon", "title": "Community Structure in Industrial SAT Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern SAT solvers have experienced a remarkable progress on solving\nindustrial instances. Most of the techniques have been developed after an\nintensive experimental process. It is believed that these techniques exploit\nthe underlying structure of industrial instances. However, there are few works\ntrying to exactly characterize the main features of this structure.\n  The research community on complex networks has developed techniques of\nanalysis and algorithms to study real-world graphs that can be used by the SAT\ncommunity. Recently, there have been some attempts to analyze the structure of\nindustrial SAT instances in terms of complex networks, with the aim of\nexplaining the success of SAT solving techniques, and possibly improving them.\n  In this paper, inspired by the results on complex networks, we study the\ncommunity structure, or modularity, of industrial SAT instances. In a graph\nwith clear community structure, or high modularity, we can find a partition of\nits nodes into communities such that most edges connect variables of the same\ncommunity. In our analysis, we represent SAT instances as graphs, and we show\nthat most application benchmarks are characterized by a high modularity. On the\ncontrary, random SAT instances are closer to the classical Erd\\\"os-R\\'enyi\nrandom graph model, where no structure can be observed. We also analyze how\nthis structure evolves by the effects of the execution of a CDCL SAT solver. In\nparticular, we use the community structure to detect that new clauses learned\nby the solver during the search contribute to destroy the original structure of\nthe formula. This is, learned clauses tend to contain variables of distinct\ncommunities.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 14:02:12 GMT"}, {"version": "v2", "created": "Sun, 3 Jul 2016 21:04:10 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 21:07:48 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ans\u00f3tegui", "Carlos", ""], ["Bonet", "Maria Luisa", ""], ["Gir\u00e1ldez-Cru", "Jes\u00fas", ""], ["Levy", "Jordi", ""], ["Simon", "Laurent", ""]]}, {"id": "1606.03335", "submitter": "Roman Bartusiak", "authors": "Roman Bartusiak, {\\L}ukasz Augustyniak, Tomasz Kajdanowicz,\n  Przemys{\\l}aw Kazienko, Maciej Piasecki", "title": "WordNet2Vec: Corpora Agnostic Word Vectorization Method", "comments": "29 pages, 16 figures, submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex nature of big data resources demands new methods for structuring\nespecially for textual content. WordNet is a good knowledge source for\ncomprehensive abstraction of natural language as its good implementations exist\nfor many languages. Since WordNet embeds natural language in the form of a\ncomplex network, a transformation mechanism WordNet2Vec is proposed in the\npaper. It creates vectors for each word from WordNet. These vectors encapsulate\ngeneral position - role of a given word towards all other words in the natural\nlanguage. Any list or set of such vectors contains knowledge about the context\nof its component within the whole language. Such word representation can be\neasily applied to many analytic tasks like classification or clustering. The\nusefulness of the WordNet2Vec method was demonstrated in sentiment analysis,\ni.e. classification with transfer learning for the real Amazon opinion textual\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 14:12:47 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Bartusiak", "Roman", ""], ["Augustyniak", "\u0141ukasz", ""], ["Kajdanowicz", "Tomasz", ""], ["Kazienko", "Przemys\u0142aw", ""], ["Piasecki", "Maciej", ""]]}, {"id": "1606.03402", "submitter": "Pavel Sountsov", "authors": "Pavel Sountsov, Sunita Sarawagi", "title": "Length bias in Encoder Decoder Models and a Case for Global Conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder networks are popular for modeling sequences probabilistically\nin many applications. These models use the power of the Long Short-Term Memory\n(LSTM) architecture to capture the full dependence among variables, unlike\nearlier models like CRFs that typically assumed conditional independence among\nnon-adjacent variables. However in practice encoder-decoder models exhibit a\nbias towards short sequences that surprisingly gets worse with increasing beam\nsize.\n  In this paper we show that such phenomenon is due to a discrepancy between\nthe full sequence margin and the per-element margin enforced by the locally\nconditioned training objective of a encoder-decoder model. The discrepancy more\nadversely impacts long sequences, explaining the bias towards predicting short\nsequences.\n  For the case where the predicted sequences come from a closed set, we show\nthat a globally conditioned model alleviates the above problems of\nencoder-decoder models. From a practical point of view, our proposed model also\neliminates the need for a beam-search during inference, which reduces to an\nefficient dot-product based search in a vector-space.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 17:30:46 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2016 17:33:58 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Sountsov", "Pavel", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1606.03432", "submitter": "Bryan He", "authors": "Bryan He, Christopher De Sa, Ioannis Mitliagkas, Christopher R\\'e", "title": "Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on\n  How Much", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling is a Markov Chain Monte Carlo sampling technique that\niteratively samples variables from their conditional distributions. There are\ntwo common scan orders for the variables: random scan and systematic scan. Due\nto the benefits of locality in hardware, systematic scan is commonly used, even\nthough most statistical guarantees are only for random scan. While it has been\nconjectured that the mixing times of random scan and systematic scan do not\ndiffer by more than a logarithmic factor, we show by counterexample that this\nis not the case, and we prove that that the mixing times do not differ by more\nthan a polynomial factor under mild conditions. To prove these relative bounds,\nwe introduce a method of augmenting the state space to study systematic scan\nusing conductance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 19:24:10 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["He", "Bryan", ""], ["De Sa", "Christopher", ""], ["Mitliagkas", "Ioannis", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1606.03475", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, Peter Szolovits", "title": "De-identification of Patient Notes with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 20:45:30 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Uzuner", "Ozlem", ""], ["Szolovits", "Peter", ""]]}, {"id": "1606.03476", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Stefano Ermon", "title": "Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider learning a policy from example expert behavior, without interaction\nwith the expert or access to reinforcement signal. One approach is to recover\nthe expert's cost function with inverse reinforcement learning, then extract a\npolicy from that cost function with reinforcement learning. This approach is\nindirect and can be slow. We propose a new general framework for directly\nextracting a policy from data, as if it were obtained by reinforcement learning\nfollowing inverse reinforcement learning. We show that a certain instantiation\nof our framework draws an analogy between imitation learning and generative\nadversarial networks, from which we derive a model-free imitation learning\nalgorithm that obtains significant performance gains over existing model-free\nmethods in imitating complex behaviors in large, high-dimensional environments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 20:51:29 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Ho", "Jonathan", ""], ["Ermon", "Stefano", ""]]}, {"id": "1606.03490", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton", "title": "The Mythos of Model Interpretability", "comments": "presented at 2016 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2016), New York, NY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 21:28:47 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 21:21:04 GMT"}, {"version": "v3", "created": "Mon, 6 Mar 2017 08:51:10 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Lipton", "Zachary C.", ""]]}, {"id": "1606.03568", "submitter": "Mikael K{\\aa}geb\\\"ack", "authors": "Mikael K{\\aa}geb\\\"ack, Hans Salomonsson", "title": "Word Sense Disambiguation using a Bidirectional LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a clean, yet effective, model for word sense\ndisambiguation. Our approach leverage a bidirectional long short-term memory\nnetwork which is shared between all words. This enables the model to share\nstatistical strength and to scale well with vocabulary size. The model is\ntrained end-to-end, directly from the raw text to sense labels, and makes\neffective use of word order. We evaluate our approach on two standard datasets,\nusing identical hyperparameter settings, which are in turn tuned on a third set\nof held out data. We employ no external resources (e.g. knowledge graphs,\npart-of-speech tagging, etc), language specific features, or hand crafted\nrules, but still achieve statistically equivalent results to the best\nstate-of-the-art systems, that employ no such limitations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 08:12:02 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 22:47:07 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["K\u00e5geb\u00e4ck", "Mikael", ""], ["Salomonsson", "Hans", ""]]}, {"id": "1606.03634", "submitter": "Lane A. Hemaspaandra", "authors": "Lane A. Hemaspaandra, David E. Narv\\'aez", "title": "The Opacity of Backbones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper approaches, using structural complexity theory, the question of\nwhether there is a chasm between knowing an object exists and getting one's\nhands on the object or its properties. In particular, we study the\nnontransparency of so-called backbones. A backbone of a boolean formula $F$ is\na collection $S$ of its variables for which there is a unique partial\nassignment $a_S$ such that $F[a_S]$ is satisfiable [MZK+99,WGS03]. We show\nthat, under the widely believed assumption that integer factoring is hard,\nthere exist sets of boolean formulas that have obvious, nontrivial backbones\nyet finding the values, $a_S$, of those backbones is intractable. We also show\nthat, under the same assumption, there exist sets of boolean formulas that\nobviously have large backbones yet producing such a backbone $S$ is\nintractable. Furthermore, we show that if integer factoring is not merely\nworst-case hard but is frequently hard, as is widely believed, then the\nfrequency of hardness in our two results is not too much less than that\nfrequency. These results hold more generally, namely, in the settings where,\nrespectively, one's assumption is that P $\\neq$ NP $\\cap$ coNP or that some\nproblem in NP $\\cap$ coNP is frequently hard.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 21:49:24 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 16:12:11 GMT"}, {"version": "v3", "created": "Sun, 18 Dec 2016 23:54:22 GMT"}, {"version": "v4", "created": "Sat, 28 Jan 2017 20:47:18 GMT"}, {"version": "v5", "created": "Mon, 14 Jan 2019 15:13:28 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Hemaspaandra", "Lane A.", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "1606.03662", "submitter": "Haishan Wu", "authors": "Mengwen Xu, Tianyi Wang, Zhengwei Wu, Jingbo Zhou, Jian Li, Haishan Wu", "title": "Store Location Selection via Mining Search Query Logs of Baidu Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing a good location when opening a new store is crucial for the future\nsuccess of a business. Traditional methods include offline manual survey, which\nis very time consuming, and analytic models based on census data, which are un-\nable to adapt to the dynamic market. The rapid increase of the availability of\nbig data from various types of mobile devices, such as online query data and\noffline positioning data, provides us with the possibility to develop automatic\nand accurate data-driven prediction models for business store placement. In\nthis paper, we propose a Demand Distribution Driven Store Placement (D3SP)\nframework for business store placement by mining search query data from Baidu\nMaps. D3SP first detects the spatial-temporal distributions of customer demands\non different business services via query data from Baidu Maps, the largest\nonline map search engine in China, and detects the gaps between demand and sup-\nply. Then we determine candidate locations via clustering such gaps. In the\nfinal stage, we solve the location optimization problem by predicting and\nranking the number of customers. We not only deploy supervised regression\nmodels to predict the number of customers, but also learn to rank models to\ndirectly rank the locations. We evaluate our framework on various types of\nbusinesses in real-world cases, and the experiments results demonstrate the\neffectiveness of our methods. D3SP as the core function for store placement has\nalready been implemented as a core component of our business analytics platform\nand could be potentially used by chain store merchants on Baidu Nuomi.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 03:42:10 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Xu", "Mengwen", ""], ["Wang", "Tianyi", ""], ["Wu", "Zhengwei", ""], ["Zhou", "Jingbo", ""], ["Li", "Jian", ""], ["Wu", "Haishan", ""]]}, {"id": "1606.03667", "submitter": "Ji He", "authors": "Ji He, Mari Ostendorf, Xiaodong He, Jianshu Chen, Jianfeng Gao, Lihong\n  Li, Li Deng", "title": "Deep Reinforcement Learning with a Combinatorial Action Space for\n  Predicting Popular Reddit Threads", "comments": "To be published in EMNLP 2016, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an online popularity prediction and tracking task as a benchmark\ntask for reinforcement learning with a combinatorial, natural language action\nspace. A specified number of discussion threads predicted to be popular are\nrecommended, chosen from a fixed window of recent comments to track. Novel deep\nreinforcement learning architectures are studied for effective modeling of the\nvalue function associated with actions comprised of interdependent sub-actions.\nThe proposed model, which represents dependence between sub-actions through a\nbi-directional LSTM, gives the best performance across different experimental\nconfigurations and domains, and it also generalizes well with varying numbers\nof recommendation requests.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 05:38:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 22:31:36 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2016 06:38:20 GMT"}, {"version": "v4", "created": "Sat, 17 Sep 2016 00:52:43 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["He", "Ji", ""], ["Ostendorf", "Mari", ""], ["He", "Xiaodong", ""], ["Chen", "Jianshu", ""], ["Gao", "Jianfeng", ""], ["Li", "Lihong", ""], ["Deng", "Li", ""]]}, {"id": "1606.03737", "submitter": "Carlos Caminha Neto", "authors": "Carlos Caminha, Vasco Furtado, Vl\\'adia Pinheiro, Caio Ponte", "title": "Detec\\c{c}\\~ao de comunidades em redes complexas para identificar\n  gargalos e desperd\\'icio de recursos em sistemas de \\^onibus", "comments": "11 pages in Portuguese e 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose here a methodology to help to understand the shortcomings of\npublic transportation in a city via the mining of complex networks representing\nthe supply and demand of public transport. We show how to build these networks\nbased upon data on smart card use in buses via the application of algorithms\nthat estimate an OD and reconstruct the complete itinerary of the passengers.\nThe overlapping of the two networks sheds light in potential overload and waste\nin the offer of resources that can be mitigated with strategies for balancing\nsupply and demand.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 16:17:57 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 18:44:08 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Caminha", "Carlos", ""], ["Furtado", "Vasco", ""], ["Pinheiro", "Vl\u00e1dia", ""], ["Ponte", "Caio", ""]]}, {"id": "1606.03777", "submitter": "Nikola Mrk\\v{s}i\\'c", "authors": "Nikola Mrk\\v{s}i\\'c and Diarmuid \\'O S\\'eaghdha and Tsung-Hsien Wen\n  and Blaise Thomson and Steve Young", "title": "Neural Belief Tracker: Data-Driven Dialogue State Tracking", "comments": "Accepted as a long paper for the 55th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core components of modern spoken dialogue systems is the belief\ntracker, which estimates the user's goal at every step of the dialogue.\nHowever, most current approaches have difficulty scaling to larger, more\ncomplex dialogue domains. This is due to their dependency on either: a) Spoken\nLanguage Understanding models that require large amounts of annotated training\ndata; or b) hand-crafted lexicons for capturing some of the linguistic\nvariation in users' language. We propose a novel Neural Belief Tracking (NBT)\nframework which overcomes these problems by building on recent advances in\nrepresentation learning. NBT models reason over pre-trained word vectors,\nlearning to compose them into distributed representations of user utterances\nand dialogue context. Our evaluation on two datasets shows that this approach\nsurpasses past limitations, matching the performance of state-of-the-art models\nwhich rely on hand-crafted semantic lexicons and outperforming them when such\nlexicons are not provided.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 22:59:14 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 15:15:03 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Wen", "Tsung-Hsien", ""], ["Thomson", "Blaise", ""], ["Young", "Steve", ""]]}, {"id": "1606.03784", "submitter": "Guido Zarrella", "authors": "Guido Zarrella and Amy Marsh", "title": "MITRE at SemEval-2016 Task 6: Transfer Learning for Stance Detection", "comments": "International Workshop on Semantic Evaluation 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe MITRE's submission to the SemEval-2016 Task 6, Detecting Stance\nin Tweets. This effort achieved the top score in Task A on supervised stance\ndetection, producing an average F1 score of 67.8 when assessing whether a tweet\nauthor was in favor or against a topic. We employed a recurrent neural network\ninitialized with features learned via distant supervision on two large\nunlabeled datasets. We trained embeddings of words and phrases with the\nword2vec skip-gram method, then used those features to learn sentence\nrepresentations via a hashtag prediction auxiliary task. These sentence vectors\nwere then fine-tuned for stance detection on several hundred labeled examples.\nThe result was a high performing system that used transfer learning to maximize\nthe value of the available training data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 00:12:49 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Zarrella", "Guido", ""], ["Marsh", "Amy", ""]]}, {"id": "1606.03832", "submitter": "Kuang Zhou", "authors": "Kuang Zhou (DRUID), Arnaud Martin (DRUID), Quan Pan, Zhun-Ga Liu", "title": "Evidential Label Propagation Algorithm for Graphs", "comments": "19th International Conference on Information Fusion, Jul 2016,\n  Heidelber, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection has attracted considerable attention crossing many areas\nas it can be used for discovering the structure and features of complex\nnetworks. With the increasing size of social networks in real world, community\ndetection approaches should be fast and accurate. The Label Propagation\nAlgorithm (LPA) is known to be one of the near-linear solutions and benefits of\neasy implementation, thus it forms a good basis for efficient community\ndetection methods. In this paper, we extend the update rule and propagation\ncriterion of LPA in the framework of belief functions. A new community\ndetection approach, called Evidential Label Propagation (ELP), is proposed as\nan enhanced version of conventional LPA. The node influence is first defined to\nguide the propagation process. The plausibility is used to determine the domain\nlabel of each node. The update order of nodes is discussed to improve the\nrobustness of the method. ELP algorithm will converge after the domain labels\nof all the nodes become unchanged. The mass assignments are calculated finally\nas memberships of nodes. The overlapping nodes and outliers can be detected\nsimultaneously through the proposed method. The experimental results\ndemonstrate the effectiveness of ELP.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 06:58:34 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Zhou", "Kuang", "", "DRUID"], ["Martin", "Arnaud", "", "DRUID"], ["Pan", "Quan", ""], ["Liu", "Zhun-Ga", ""]]}, {"id": "1606.03860", "submitter": "Yixin Wang", "authors": "Yixin Wang, Alp Kucukelbir, David M. Blei", "title": "Robust Probabilistic Modeling with Bayesian Data Reweighting", "comments": "In ICML 2017. Updated related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models analyze data by relying on a set of assumptions. Data\nthat exhibit deviations from these assumptions can undermine inference and\nprediction quality. Robust models offer protection against mismatch between a\nmodel's assumptions and reality. We propose a way to systematically detect and\nmitigate mismatch of a large class of probabilistic models. The idea is to\nraise the likelihood of each observation to a weight and then to infer both the\nlatent variables and the weights from data. Inferring the weights allows a\nmodel to identify observations that match its assumptions and down-weight\nothers. This enables robust inference and improves predictive accuracy. We\nstudy four different forms of mismatch with reality, ranging from missing\nlatent groups to structure misspecification. A Poisson factorization analysis\nof the Movielens 1M dataset shows the benefits of this approach in a practical\nscenario.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 08:56:35 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 21:13:37 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 16:44:54 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Wang", "Yixin", ""], ["Kucukelbir", "Alp", ""], ["Blei", "David M.", ""]]}, {"id": "1606.03864", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn", "title": "Neural Associative Memory for Dual-Sequence Modeling", "comments": "To appear in RepL4NLP at ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 09:08:04 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 07:59:18 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Weissenborn", "Dirk", ""]]}, {"id": "1606.03894", "submitter": "Amine Balafrej", "authors": "Amine Balafrej and Xavier Lorca and Charlotte Truchet", "title": "A Probabilistic-Based Model for Binary CSP", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": "16/2/DAPI", "categories": "cs.AI cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a probabilistic-based model for binary CSP that provides\na fine grained analysis of its internal structure. Assuming that a domain\nmodification could occur in the CSP, it shows how to express, in a predictive\nway, the probability that a domain value becomes inconsistent, then it express\nthe expectation of the number of arc-inconsistent values in each domain of the\nconstraint network. Thus, it express the expectation of the number of\narc-inconsistent values for the whole constraint network. Next, it provides\nbounds for each of these three probabilistic indicators. Finally, a polytime\nalgorithm, which propagates the probabilistic information, is presented.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 11:03:26 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Balafrej", "Amine", ""], ["Lorca", "Xavier", ""], ["Truchet", "Charlotte", ""]]}, {"id": "1606.03935", "submitter": "Matej Mihel\\v{c}i\\'c", "authors": "Matej Mihel\\v{c}i\\'c, Sa\\v{s}o D\\v{z}eroski, Nada Lavra\\v{c}, Tomislav\n  \\v{S}muc", "title": "A framework for redescription set construction", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2016.10.012", "report-no": null, "categories": "cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redescription mining is a field of knowledge discovery that aims at finding\ndifferent descriptions of similar subsets of instances in the data. These\ndescriptions are represented as rules inferred from one or more disjoint sets\nof attributes, called views. As such, they support knowledge discovery process\nand help domain experts in formulating new hypotheses or constructing new\nknowledge bases and decision support systems. In contrast to previous\napproaches that typically create one smaller set of redescriptions satisfying a\npre-defined set of constraints, we introduce a framework that creates large and\nheterogeneous redescription set from which user/expert can extract compact sets\nof differing properties, according to its own preferences. Construction of\nlarge and heterogeneous redescription set relies on CLUS-RM algorithm and a\nnovel, conjunctive refinement procedure that facilitates generation of larger\nand more accurate redescription sets. The work also introduces the variability\nof redescription accuracy when missing values are present in the data, which\nsignificantly extends applicability of the method. Crucial part of the\nframework is the redescription set extraction based on heuristic\nmulti-objective optimization procedure that allows user to define importance\nlevels towards one or more redescription quality criteria. We provide both\ntheoretical and empirical comparison of the novel framework against current\nstate of the art redescription mining algorithms and show that it represents\nmore efficient and versatile approach for mining redescriptions from data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 13:15:41 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 16:41:06 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Mihel\u010di\u0107", "Matej", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Lavra\u010d", "Nada", ""], ["\u0160muc", "Tomislav", ""]]}, {"id": "1606.03968", "submitter": "Stefano Soatto", "authors": "Jingming Dong, Xiaohan Fei, Stefano Soatto", "title": "Visual-Inertial-Semantic Scene Representation for 3-D Object Detection", "comments": "To appear in CVPR 2017", "journal-ref": null, "doi": null, "report-no": "CSD160005", "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a system to detect objects in three-dimensional space using video\nand inertial sensors (accelerometer and gyrometer), ubiquitous in modern mobile\nplatforms from phones to drones. Inertials afford the ability to impose\nclass-specific scale priors for objects, and provide a global orientation\nreference. A minimal sufficient representation, the posterior of semantic\n(identity) and syntactic (pose) attributes of objects in space, can be\ndecomposed into a geometric term, which can be maintained by a\nlocalization-and-mapping filter, and a likelihood function, which can be\napproximated by a discriminatively-trained convolutional neural network. The\nresulting system can process the video stream causally in real time, and\nprovides a representation of objects in the scene that is persistent:\nConfidence in the presence of objects grows with evidence, and objects\npreviously seen are kept in memory even when temporarily occluded, with their\nreturn into view automatically predicted to prime re-detection.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 14:22:10 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 20:25:26 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Dong", "Jingming", ""], ["Fei", "Xiaohan", ""], ["Soatto", "Stefano", ""]]}, {"id": "1606.03976", "submitter": "Fredrik D. Johansson", "authors": "Uri Shalit, Fredrik D. Johansson, David Sontag", "title": "Estimating individual treatment effect: generalization bounds and\n  algorithms", "comments": "Added name \"TARNet\" to refer to version with alpha = 0. Removed supp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is intense interest in applying machine learning to problems of causal\ninference in fields such as healthcare, economics and education. In particular,\nindividual-level causal inference has important applications such as precision\nmedicine. We give a new theoretical analysis and family of algorithms for\npredicting individual treatment effect (ITE) from observational data, under the\nassumption known as strong ignorability. The algorithms learn a \"balanced\"\nrepresentation such that the induced treated and control distributions look\nsimilar. We give a novel, simple and intuitive generalization-error bound\nshowing that the expected ITE estimation error of a representation is bounded\nby a sum of the standard generalization-error of that representation and the\ndistance between the treated and control distributions induced by the\nrepresentation. We use Integral Probability Metrics to measure distances\nbetween distributions, deriving explicit bounds for the Wasserstein and Maximum\nMean Discrepancy (MMD) distances. Experiments on real and simulated data show\nthe new algorithms match or outperform the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 14:40:57 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2016 13:13:05 GMT"}, {"version": "v3", "created": "Fri, 28 Oct 2016 18:17:38 GMT"}, {"version": "v4", "created": "Wed, 1 Mar 2017 15:44:15 GMT"}, {"version": "v5", "created": "Tue, 16 May 2017 15:11:15 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Shalit", "Uri", ""], ["Johansson", "Fredrik D.", ""], ["Sontag", "David", ""]]}, {"id": "1606.04000", "submitter": "Douglas Summers Stay", "authors": "Douglas Summers-Stay, Clare Voss and Taylor Cassidy", "title": "Using a Distributional Semantic Vector Space with a Knowledge Base for\n  Reasoning in Uncertain Conditions", "comments": null, "journal-ref": "Biologically Inspired Cognitive Architectures (2016), pp. 34-44", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inherent inflexibility and incompleteness of commonsense knowledge bases\n(KB) has limited their usefulness. We describe a system called Displacer for\nperforming KB queries extended with the analogical capabilities of the word2vec\ndistributional semantic vector space (DSVS). This allows the system to answer\nqueries with information which was not contained in the original KB in any\nform. By performing analogous queries on semantically related terms and mapping\ntheir answers back into the context of the original query using displacement\nvectors, we are able to give approximate answers to many questions which, if\nposed to the KB alone, would return no results.\n  We also show how the hand-curated knowledge in a KB can be used to increase\nthe accuracy of a DSVS in solving analogy problems. In these ways, a KB and a\nDSVS can make up for each other's weaknesses.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 15:45:00 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Summers-Stay", "Douglas", ""], ["Voss", "Clare", ""], ["Cassidy", "Taylor", ""]]}, {"id": "1606.04055", "submitter": "Saeid Parvandeh", "authors": "Saeid Parvandeh, Parya Soltani, Mohammadreza Boroumand, Fahimeh\n  Boroumand", "title": "A modified single and multi-objective bacteria foraging optimization for\n  the solution of quadratic assignment problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-polynomial hard (NP-hard) problems are challenging because no\npolynomial-time algorithm has yet been discovered to solve them in polynomial\ntime. The Bacteria Foraging Optimization (BFO) algorithm is one of the\nmetaheuristics algorithms that is mostly used for NP-hard problems. BFO is\ninspired by the behavior of the bacteria foraging such as Escherichia coli\n(E-coli). The aim of BFO is to eliminate those bacteria that have weak foraging\nproperties and maintain those bacteria that have breakthrough foraging\nproperties toward the optimum. Despite the strength of this algorithm, most of\nthe problems reaching optimal solutions are time-demanding or impossible. In\nthis paper, we modified single objective BFO by adding a mutation operator and\nmulti-objective BFO (MOBFO) by adding mutation and crossover from genetic\nalgorithm operators to update the solutions in each generation, and local tabu\nsearch algorithm to reach the local optimum solution. Additionally, we used a\nfast nondominated sort algorithm in MOBFO to find the best-nondominated\nsolutions in each generation. We evaluated the performance of the proposed\nalgorithms through a number of single and multi-objective Quadratic Assignment\nProblem (QAP) instances. The experimental results show that our approaches\noutperform some previous optimization algorithms in both convergent and\ndivergent solutions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 18:18:07 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 21:08:33 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Parvandeh", "Saeid", ""], ["Soltani", "Parya", ""], ["Boroumand", "Mohammadreza", ""], ["Boroumand", "Fahimeh", ""]]}, {"id": "1606.04087", "submitter": "Andr\\'e Karpi\\v{s}t\\v{s}enko", "authors": "Andre Karpistsenko", "title": "Networked Intelligence: Towards Autonomous Cyber Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing intelligent systems requires combining results from both industry\nand academia. In this report you find an overview of relevant research fields\nand industrially applicable technologies for building very large scale cyber\nphysical systems. A concept architecture is used to illustrate how existing\npieces may fit together, and the maturity of the subsystems is estimated.\n  The goal is to structure the developments and the challenge of machine\nintelligence for Consumer and Industrial Internet technologists, cyber physical\nsystems researchers and people interested in the convergence of data & Internet\nof Things. It can be used for planning developments of intelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 19:57:48 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 19:44:21 GMT"}, {"version": "v3", "created": "Mon, 20 Jun 2016 19:29:20 GMT"}, {"version": "v4", "created": "Wed, 29 Jun 2016 20:26:12 GMT"}, {"version": "v5", "created": "Mon, 11 Jul 2016 18:29:33 GMT"}, {"version": "v6", "created": "Sun, 28 Aug 2016 18:00:52 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Karpistsenko", "Andre", ""]]}, {"id": "1606.04165", "submitter": "Sarah Ostadabbas", "authors": "Katie Hoemann, Behnaz Rezaei, Stacy C. Marsella, Sarah Ostadabbas", "title": "Using Virtual Humans to Understand Real Ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human interactions are characterized by explicit as well as implicit channels\nof communication. While the explicit channel transmits overt messages, the\nimplicit ones transmit hidden messages about the communicator (e.g., his/her\nintentions and attitudes). There is a growing consensus that providing a\ncomputer with the ability to manipulate implicit affective cues should allow\nfor a more meaningful and natural way of studying particular non-verbal signals\nof human-human communications by human-computer interactions. In this pilot\nstudy, we created a non-dynamic human-computer interaction while manipulating\nthree specific non-verbal channels of communication: gaze pattern, facial\nexpression, and gesture. Participants rated the virtual agent on affective\ndimensional scales (pleasure, arousal, and dominance) while their physiological\nsignal (electrodermal activity, EDA) was captured during the interaction.\nAssessment of the behavioral data revealed a significant and complex three-way\ninteraction between gaze, gesture, and facial configuration on the dimension of\npleasure, as well as a main effect of gesture on the dimension of dominance.\nThese results suggest a complex relationship between different non-verbal cues\nand the social context in which they are interpreted. Qualifying considerations\nas well as possible next steps are further discussed in light of these\nexploratory findings.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 22:41:50 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Hoemann", "Katie", ""], ["Rezaei", "Behnaz", ""], ["Marsella", "Stacy C.", ""], ["Ostadabbas", "Sarah", ""]]}, {"id": "1606.04190", "submitter": "Carlos Caminha", "authors": "Carlos Caminha, Vasco Furtado, Vl\\'adia Pinheiro e Caio Ponte", "title": "Micro-interventions in urban transport from pattern discovery on the\n  flow of passengers and on the bus network", "comments": "arXiv admin note: substantial text overlap with arXiv:1606.03737", "journal-ref": null, "doi": "10.1109/ISC2.2016.7580776", "report-no": null, "categories": "cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a case study in a big metropolis, in which from\ndata collected by digital sensors, we tried to understand mobility patterns of\npersons using buses and how this can generate knowledge to suggest\ninterventions that are applied incrementally into the transportation network in\nuse. We have first estimated an Origin-Destination matrix of buses users from\ndatasets about the ticket validation and GPS positioning of buses. Then we\nrepresent the supply of buses with their routes through bus stops as a complex\nnetwork, which allowed us to understand the bottlenecks of the current scenario\nand, in particular, applying community discovery techniques, to identify\nclusters that the service supply infrastructure has. Finally, from the\nsuperimposing of the flow of people represented in the OriginDestination matrix\nin the supply network, we exemplify how micro-interventions can be prospected\nby means of an example of the introduction of express routes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 01:44:16 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Caminha", "Carlos", ""], ["Furtado", "Vasco", ""], ["Ponte", "Vl\u00e1dia Pinheiro e Caio", ""]]}, {"id": "1606.04216", "submitter": "Yura Perov N", "authors": "Mike Wu, Yura Perov, Frank Wood, Hongseok Yang", "title": "Spreadsheet Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spreadsheet workbook contents are simple programs. Because of this,\nprobabilistic programming techniques can be used to perform Bayesian inversion\nof spreadsheet computations. What is more, existing execution engines in\nspreadsheet applications such as Microsoft Excel can be made to do this using\nonly built-in functionality. We demonstrate this by developing a native Excel\nimplementation of both a particle Markov Chain Monte Carlo variant and\nblack-box variational inference for spreadsheet probabilistic programming. The\nresulting engine performs probabilistically coherent inference over spreadsheet\ncomputations, notably including spreadsheets that include user-defined\nblack-box functions. Spreadsheet engines that choose to integrate the\nfunctionality we describe in this paper will give their users the ability to\nboth easily develop probabilistic models and maintain them over time by\nincluding actuals via a simple user-interface mechanism. For spreadsheet\nend-users this would mean having access to efficient and probabilistically\ncoherent probabilistic modeling and inference for use in all kinds of decision\nmaking under uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 07:01:00 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Wu", "Mike", ""], ["Perov", "Yura", ""], ["Wood", "Frank", ""], ["Yang", "Hongseok", ""]]}, {"id": "1606.04250", "submitter": "Philipp Geiger", "authors": "Philipp Geiger, Katja Hofmann, Bernhard Sch\\\"olkopf", "title": "Experimental and causal view on information integration in autonomous\n  agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of digitally available but heterogeneous information about the\nworld is remarkable, and new technologies such as self-driving cars, smart\nhomes, or the internet of things may further increase it. In this paper we\npresent preliminary ideas about certain aspects of the problem of how such\nheterogeneous information can be harnessed by autonomous agents. After\ndiscussing potentials and limitations of some existing approaches, we\ninvestigate how \\emph{experiments} can help to obtain a better understanding of\nthe problem. Specifically, we present a simple agent that integrates video data\nfrom a different agent, and implement and evaluate a version of it on the novel\nexperimentation platform \\emph{Malmo}. The focus of a second investigation is\non how information about the hardware of different agents, the agents' sensory\ndata, and \\emph{causal} information can be utilized for knowledge transfer\nbetween agents and subsequently more data-efficient decision making. Finally,\nwe discuss potential future steps w.r.t.\\ theory and experimentation, and\nformulate open questions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 08:38:18 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 16:37:37 GMT"}, {"version": "v3", "created": "Tue, 13 Mar 2018 15:43:19 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Geiger", "Philipp", ""], ["Hofmann", "Katja", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1606.04327", "submitter": "Pawel Foremski", "authors": "Pawel Foremski, David Plonka, Arthur Berger", "title": "Entropy/IP: Uncovering Structure in IPv6 Addresses", "comments": "Paper presented at the ACM IMC 2016 in Santa Monica, USA\n  (https://dl.acm.org/citation.cfm?id=2987445). Live Demo site available at\n  http://www.entropy-ip.com/", "journal-ref": "IMC '16 Proceedings of the 2016 ACM on Internet Measurement\n  Conference, pp. 167-181", "doi": "10.1145/2987443.2987445", "report-no": null, "categories": "cs.NI cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Entropy/IP: a system that discovers Internet\naddress structure based on analyses of a subset of IPv6 addresses known to be\nactive, i.e., training data, gleaned by readily available passive and active\nmeans. The system is completely automated and employs a combination of\ninformation-theoretic and machine learning techniques to probabilistically\nmodel IPv6 addresses. We present results showing that our system is effective\nin exposing structural characteristics of portions of the IPv6 Internet address\nspace populated by active client, service, and router addresses.\n  In addition to visualizing the address structure for exploration, the system\nuses its models to generate candidate target addresses for scanning. For each\nof 15 evaluated datasets, we train on 1K addresses and generate 1M candidates\nfor scanning. We achieve some success in 14 datasets, finding up to 40% of the\ngenerated addresses to be active. In 11 of these datasets, we find active\nnetwork identifiers (e.g., /64 prefixes or `subnets') not seen in training.\nThus, we provide the first evidence that it is practical to discover subnets\nand hosts by scanning probabilistically selected areas of the IPv6 address\nspace not known to contain active hosts a priori.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 12:38:26 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 12:43:00 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Foremski", "Pawel", ""], ["Plonka", "David", ""], ["Berger", "Arthur", ""]]}, {"id": "1606.04345", "submitter": "Balazs Kegl", "authors": "Ak{\\i}n Kazak\\c{c}{\\i}and Mehdi Cherti and Bal\\'azs K\\'egl", "title": "Digits that are not: Generating new types through deep neural nets", "comments": "preprint ICCC'16, International Conference on Computational\n  Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an artificial creative agent, an essential driver of the search for\nnovelty is a value function which is often provided by the system designer or\nusers. We argue that an important barrier for progress in creativity research\nis the inability of these systems to develop their own notion of value for\nnovelty. We propose a notion of knowledge-driven creativity that circumvent the\nneed for an externally imposed value function, allowing the system to explore\nbased on what it has learned from a set of referential objects. The concept is\nillustrated by a specific knowledge model provided by a deep generative\nautoencoder. Using the described system, we train a knowledge model on a set of\ndigit images and we use the same model to build coherent sets of new digits\nthat do not belong to known digit types.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 13:29:13 GMT"}], "update_date": "2016-08-06", "authors_parsed": [["Cherti", "Ak\u0131n Kazak\u00e7\u0131and Mehdi", ""], ["K\u00e9gl", "Bal\u00e1zs", ""]]}, {"id": "1606.04397", "submitter": "Ulrich Furbach", "authors": "Ulrich Furbach and Florian Furbach and Christian Freksa", "title": "Relating Strong Spatial Cognition to Symbolic Problem Solving --- An\n  Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we discuss and analyse a shortest path finding approach using\nstrong spatial cognition. It is compared with a symbolic graph-based algorithm\nand it is shown that both approaches are similar with respect to structure and\ncomplexity. Nevertheless, the strong spatial cognition solution is easy to\nunderstand and even pops up immediately when one has to solve the problem.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 14:41:24 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Furbach", "Ulrich", ""], ["Furbach", "Florian", ""], ["Freksa", "Christian", ""]]}, {"id": "1606.04414", "submitter": "Jian Wu", "authors": "Jian Wu, Peter I. Frazier", "title": "The Parallel Knowledge Gradient Method for Batch Bayesian Optimization", "comments": "Minor edits and typo fixes. Please cite \"J. Wu and P. Frazier. The\n  parallel knowledge gradient method for batch bayesian optimization. In\n  Advances In Neural Information Processing Systems, pp. 3126-3134. 2016\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of black-box optimization, one can evaluate multiple\npoints simultaneously, e.g. when evaluating the performances of several\ndifferent neural network architectures in a parallel computing environment. In\nthis paper, we develop a novel batch Bayesian optimization algorithm --- the\nparallel knowledge gradient method. By construction, this method provides the\none-step Bayes-optimal batch of points to sample. We provide an efficient\nstrategy for computing this Bayes-optimal batch of points, and we demonstrate\nthat the parallel knowledge gradient method finds global optima significantly\nfaster than previous batch Bayesian optimization algorithms on both synthetic\ntest functions and when tuning hyperparameters of practical machine learning\nalgorithms, especially when function evaluations are noisy.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:12:01 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2016 05:47:09 GMT"}, {"version": "v3", "created": "Sat, 21 Jan 2017 20:49:18 GMT"}, {"version": "v4", "created": "Sun, 22 Apr 2018 23:44:15 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Wu", "Jian", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1606.04422", "submitter": "Artur Garcez", "authors": "Luciano Serafini and Artur d'Avila Garcez", "title": "Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and\n  Knowledge", "comments": "12 pages, 2 figs, 1 table, 27 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Logic Tensor Networks: a uniform framework for integrating\nautomatic learning and reasoning. A logic formalism called Real Logic is\ndefined on a first-order language whereby formulas have truth-value in the\ninterval [0,1] and semantics defined concretely on the domain of real numbers.\nLogical constants are interpreted as feature vectors of real numbers. Real\nLogic promotes a well-founded integration of deductive reasoning on a\nknowledge-base and efficient data-driven relational machine learning. We show\nhow Real Logic can be implemented in deep Tensor Neural Networks with the use\nof Google's tensorflow primitives. The paper concludes with experiments\napplying Logic Tensor Networks on a simple but representative example of\nknowledge completion.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:25:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 12:28:57 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Serafini", "Luciano", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1606.04442", "submitter": "Christian Szegedy", "authors": "Alex A. Alemi, Francois Chollet, Niklas Een, Geoffrey Irving,\n  Christian Szegedy and Josef Urban", "title": "DeepMath - Deep Sequence Models for Premise Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of neural sequence models for premise selection in\nautomated theorem proving, one of the main bottlenecks in the formalization of\nmathematics. We propose a two stage approach for this task that yields good\nresults for the premise selection task on the Mizar corpus while avoiding the\nhand-engineered features of existing state-of-the-art models. To our knowledge,\nthis is the first time deep learning has been applied to theorem proving on a\nlarge scale.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 16:27:41 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 19:35:16 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Alemi", "Alex A.", ""], ["Chollet", "Francois", ""], ["Een", "Niklas", ""], ["Irving", "Geoffrey", ""], ["Szegedy", "Christian", ""], ["Urban", "Josef", ""]]}, {"id": "1606.04486", "submitter": "Martin Mladenov", "authors": "Martin Mladenov and Leonard Kleinhans and Kristian Kersting", "title": "Lifted Convex Quadratic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symmetry is the essential element of lifted inference that has recently\ndemon- strated the possibility to perform very efficient inference in\nhighly-connected, but symmetric probabilistic models models. This raises the\nquestion, whether this holds for optimisation problems in general. Here we show\nthat for a large class of optimisation methods this is actually the case. More\nprecisely, we introduce the concept of fractional symmetries of convex\nquadratic programs (QPs), which lie at the heart of many machine learning\napproaches, and exploit it to lift, i.e., to compress QPs. These lifted QPs can\nthen be tackled with the usual optimization toolbox (off-the-shelf solvers,\ncutting plane algorithms, stochastic gradients etc.). If the original QP\nexhibits symmetry, then the lifted one will generally be more compact, and\nhence their optimization is likely to be more efficient.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 18:18:58 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Mladenov", "Martin", ""], ["Kleinhans", "Leonard", ""], ["Kersting", "Kristian", ""]]}, {"id": "1606.04512", "submitter": "Seyed Mehran Kazemi", "authors": "Seyed Mehran Kazemi and David Poole", "title": "Why is Compiling Lifted Inference into a Low-Level Language so\n  Effective?", "comments": "6 pages, 3 figures, accepted at IJCAI-16 Statistical Relational AI\n  (StaRAI) workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  First-order knowledge compilation techniques have proven efficient for lifted\ninference. They compile a relational probability model into a target circuit on\nwhich many inference queries can be answered efficiently. Early methods used\ndata structures as their target circuit. In our KR-2016 paper, we showed that\ncompiling to a low-level program instead of a data structure offers orders of\nmagnitude speedup, resulting in the state-of-the-art lifted inference\ntechnique. In this paper, we conduct experiments to address two questions\nregarding our KR-2016 results: 1- does the speedup come from more efficient\ncompilation or more efficient reasoning with the target circuit?, and 2- why\nare low-level programs more efficient target circuits than data structures?\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 19:13:30 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Kazemi", "Seyed Mehran", ""], ["Poole", "David", ""]]}, {"id": "1606.04589", "submitter": "Ram\\'on Pino P\\'erez", "authors": "Am\\'ilcar Mata D\\'iaz and Ram\\'on Pino P\\'erez", "title": "Impossibility in Belief Merging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of studying social properties of belief merging and having a\nbetter understanding of impossibility, we extend in three ways the framework of\nlogic-based merging introduced by Konieczny and Pino P\\'erez. First, at the\nlevel of representation of the information, we pass from belief bases to\ncomplex epistemic states. Second, the profiles are represented as functions of\nfinite societies to the set of epistemic states (a sort of vectors) and not as\nmultisets of epistemic states. Third, we extend the set of rational postulates\nin order to consider the epistemic versions of the classical postulates of\nSocial Choice Theory: Standard Domain, Pareto Property, Independence of\nIrrelevant Alternatives and Absence of Dictator. These epistemic versions of\nsocial postulates are given, essentially, in terms of the finite propositional\nlogic. We state some representation theorems for these operators. These\nextensions and representation theorems allow us to establish an epistemic and\nvery general version of Arrow's Impossibility Theorem. One of the interesting\nfeatures of our result, is that it holds for different representations of\nepistemic states; for instance conditionals, Ordinal Conditional functions and,\nof course, total preorders.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 23:05:39 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["D\u00edaz", "Am\u00edlcar Mata", ""], ["P\u00e9rez", "Ram\u00f3n Pino", ""]]}, {"id": "1606.04615", "submitter": "Ishan Durugkar", "authors": "Ishan P. Durugkar, Clemens Rosenbaum, Stefan Dernbach, Sridhar\n  Mahadevan", "title": "Deep Reinforcement Learning With Macro-Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been shown to be a powerful framework for\nlearning policies from complex high-dimensional sensory inputs to actions in\ncomplex tasks, such as the Atari domain. In this paper, we explore output\nrepresentation modeling in the form of temporal abstraction to improve\nconvergence and reliability of deep reinforcement learning approaches. We\nconcentrate on macro-actions, and evaluate these on different Atari 2600 games,\nwhere we show that they yield significant improvements in learning speed.\nAdditionally, we show that they can even achieve better scores than DQN. We\noffer analysis and explanation for both convergence and final results,\nrevealing a problem deep RL approaches have with sparse reward signals.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 01:57:40 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Durugkar", "Ishan P.", ""], ["Rosenbaum", "Clemens", ""], ["Dernbach", "Stefan", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1606.04686", "submitter": "Verena Rieser", "authors": "Verena Rieser and Oliver Lemon", "title": "Natural Language Generation as Planning under Uncertainty Using\n  Reinforcement Learning", "comments": "published EACL 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate a new model for Natural Language Generation (NLG) in\nSpoken Dialogue Systems, based on statistical planning, given noisy feedback\nfrom the current generation context (e.g. a user and a surface realiser). We\nstudy its use in a standard NLG problem: how to present information (in this\ncase a set of search results) to users, given the complex trade- offs between\nutterance length, amount of information conveyed, and cognitive load. We set\nthese trade-offs by analysing existing MATCH data. We then train a NLG pol- icy\nusing Reinforcement Learning (RL), which adapts its behaviour to noisy feed-\nback from the current generation context. This policy is compared to several\nbase- lines derived from previous work in this area. The learned policy\nsignificantly out- performs all the prior approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 09:05:56 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Rieser", "Verena", ""], ["Lemon", "Oliver", ""]]}, {"id": "1606.04695", "submitter": "Alexander Vezhnevets", "authors": "Alexander (Sasha) Vezhnevets, Volodymyr Mnih, John Agapiou, Simon\n  Osindero, Alex Graves, Oriol Vinyals, Koray Kavukcuoglu", "title": "Strategic Attentive Writer for Learning Macro-Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep recurrent neural network architecture that learns to\nbuild implicit plans in an end-to-end manner by purely interacting with an\nenvironment in reinforcement learning setting. The network builds an internal\nplan, which is continuously updated upon observation of the next input from the\nenvironment. It can also partition this internal representation into contiguous\nsub- sequences by learning for how long the plan can be committed to - i.e.\nfollowed without re-planing. Combining these properties, the proposed model,\ndubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally\nabstracted macro- actions of varying lengths that are solely learnt from data\nwithout any prior information. These macro-actions enable both structured\nexploration and economic computation. We experimentally demonstrate that STRAW\ndelivers strong improvements on several ATARI games by employing temporally\nextended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same\ntime a general algorithm that can be applied on any sequence data. To that end,\nwe also show that when trained on text prediction task, STRAW naturally\npredicts frequent n-grams (instead of macro-actions), demonstrating the\ngenerality of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 09:28:52 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Alexander", "", "", "Sasha"], ["Vezhnevets", "", ""], ["Mnih", "Volodymyr", ""], ["Agapiou", "John", ""], ["Osindero", "Simon", ""], ["Graves", "Alex", ""], ["Vinyals", "Oriol", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1606.04753", "submitter": "Matteo Turchetta", "authors": "Matteo Turchetta, Felix Berkenkamp, Andreas Krause", "title": "Safe Exploration in Finite Markov Decision Processes with Gaussian\n  Processes", "comments": "15 pages, extended version with proofs", "journal-ref": "Proc. of Advances in Neural Information Processing Systems (NIPS),\n  2016, pp. 4305-4313", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical reinforcement learning, when exploring an environment, agents\naccept arbitrary short term loss for long term gain. This is infeasible for\nsafety critical applications, such as robotics, where even a single unsafe\naction may cause system failure. In this paper, we address the problem of\nsafely exploring finite Markov decision processes (MDP). We define safety in\nterms of an, a priori unknown, safety constraint that depends on states and\nactions. We aim to explore the MDP under this constraint, assuming that the\nunknown function satisfies regularity conditions expressed via a Gaussian\nprocess prior. We develop a novel algorithm for this task and prove that it is\nable to completely explore the safely reachable part of the MDP without\nviolating the safety constraint. To achieve this, it cautiously explores safe\nstates and actions in order to gain statistical confidence about the safety of\nunvisited state-action pairs from noisy observations collected while navigating\nthe environment. Moreover, the algorithm explicitly considers reachability when\nexploring the MDP, ensuring that it does not get stuck in any state with no\nsafe way out. We demonstrate our method on digital terrain models for the task\nof exploring an unknown map with a rover.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 13:18:30 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 14:00:11 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Turchetta", "Matteo", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1606.04956", "submitter": "Ashton Anderson", "authors": "Ashton Anderson, Jon Kleinberg and Sendhil Mullainathan", "title": "Assessing Human Error Against a Benchmark of Perfection", "comments": "KDD 2016; 10 pages", "journal-ref": null, "doi": "10.1145/2939672.2939803", "report-no": null, "categories": "cs.AI cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of domains are providing us with detailed trace data on\nhuman decisions in settings where we can evaluate the quality of these\ndecisions via an algorithm. Motivated by this development, an emerging line of\nwork has begun to consider whether we can characterize and predict the kinds of\ndecisions where people are likely to make errors.\n  To investigate what a general framework for human error prediction might look\nlike, we focus on a model system with a rich history in the behavioral\nsciences: the decisions made by chess players as they select moves in a game.\nWe carry out our analysis at a large scale, employing datasets with several\nmillion recorded games, and using chess tablebases to acquire a form of ground\ntruth for a subset of chess positions that have been completely solved by\ncomputers but remain challenging even for the best players in the world.\n  We organize our analysis around three categories of features that we argue\nare present in most settings where the analysis of human error is applicable:\nthe skill of the decision-maker, the time available to make the decision, and\nthe inherent difficulty of the decision. We identify rich structure in all\nthree of these categories of features, and find strong evidence that in our\ndomain, features describing the inherent difficulty of an instance are\nsignificantly more powerful than features based on skill or time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 20:00:32 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Anderson", "Ashton", ""], ["Kleinberg", "Jon", ""], ["Mullainathan", "Sendhil", ""]]}, {"id": "1606.05124", "submitter": "Shashank Pathak", "authors": "Shashank Pathak, Antony Thomas, Asaf Feniger and Vadim Indelman", "title": "Robust Active Perception via Data-association aware Belief Space\n  planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a belief space planning (BSP) approach that advances the state of\nthe art by incorporating reasoning about data association (DA) within planning,\nwhile considering additional sources of uncertainty. Existing BSP approaches\ntypically assume data association is given and perfect, an assumption that can\nbe harder to justify while operating, in the presence of localization\nuncertainty, in ambiguous and perceptually aliased environments. In contrast,\nour data association aware belief space planning (DA-BSP) approach explicitly\nreasons about DA within belief evolution, and as such can better accommodate\nthese challenging real world scenarios. In particular, we show that due to\nperceptual aliasing, the posterior belief becomes a mixture of probability\ndistribution functions, and design cost functions that measure the expected\nlevel of ambiguity and posterior uncertainty. Using these and standard costs\n(e.g.~control penalty, distance to goal) within the objective function, yields\na general framework that reliably represents action impact, and in particular,\ncapable of active disambiguation. Our approach is thus applicable to robust\nactive perception and autonomous navigation in perceptually aliased\nenvironments. We demonstrate key aspects in basic and realistic simulations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 10:22:04 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Pathak", "Shashank", ""], ["Thomas", "Antony", ""], ["Feniger", "Asaf", ""], ["Indelman", "Vadim", ""]]}, {"id": "1606.05174", "submitter": "Tom Zahavy", "authors": "Nir Baram, Tom Zahavy, Shie Mannor", "title": "Deep Reinforcement Learning Discovers Internal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) is a trending field of research, showing\ngreat promise in challenging problems such as playing Atari, solving Go and\ncontrolling robots. While DRL agents perform well in practice we are still\nlacking the tools to analayze their performance. In this work we present the\nSemi-Aggregated MDP (SAMDP) model. A model best suited to describe policies\nexhibiting both spatial and temporal hierarchies. We describe its advantages\nfor analyzing trained policies over other modeling approaches, and show that\nunder the right state representation, like that of DQN agents, SAMDP can help\nto identify skills. We detail the automatic process of creating it from\nrecorded trajectories, up to presenting it on t-SNE maps. We explain how to\nevaluate its fitness and show surprising results indicating high compatibility\nwith the policy at hand. We conclude by showing how using the SAMDP model, an\nextra performance gain can be squeezed from the agent.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 13:09:16 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Baram", "Nir", ""], ["Zahavy", "Tom", ""], ["Mannor", "Shie", ""]]}, {"id": "1606.05312", "submitter": "Andr\\'e Barreto", "authors": "Andr\\'e Barreto, Will Dabney, R\\'emi Munos, Jonathan J. Hunt, Tom\n  Schaul, Hado van Hasselt, David Silver", "title": "Successor Features for Transfer in Reinforcement Learning", "comments": "Published at NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer in reinforcement learning refers to the notion that generalization\nshould occur not only within a task but also across tasks. We propose a\ntransfer framework for the scenario where the reward function changes between\ntasks but the environment's dynamics remain the same. Our approach rests on two\nkey ideas: \"successor features\", a value function representation that decouples\nthe dynamics of the environment from the rewards, and \"generalized policy\nimprovement\", a generalization of dynamic programming's policy improvement\noperation that considers a set of policies rather than a single one. Put\ntogether, the two ideas lead to an approach that integrates seamlessly within\nthe reinforcement learning framework and allows the free exchange of\ninformation across tasks. The proposed method also provides performance\nguarantees for the transferred policy even before any learning has taken place.\nWe derive two theorems that set our approach in firm theoretical ground and\npresent experiments that show that it successfully promotes transfer in\npractice, significantly outperforming alternative methods in a sequence of\nnavigation tasks and in the control of a simulated robotic arm.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 18:45:32 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 11:41:05 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Barreto", "Andr\u00e9", ""], ["Dabney", "Will", ""], ["Munos", "R\u00e9mi", ""], ["Hunt", "Jonathan J.", ""], ["Schaul", "Tom", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""]]}, {"id": "1606.05313", "submitter": "Jacob Steinhardt", "authors": "Jacob Steinhardt and Percy Liang", "title": "Unsupervised Risk Estimation Using Only Conditional Independence\n  Structure", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to estimate a model's test error from unlabeled data, on\ndistributions very different from the training distribution, while assuming\nonly that certain conditional independencies are preserved between train and\ntest. We do not need to assume that the optimal predictor is the same between\ntrain and test, or that the true distribution lies in any parametric family. We\ncan also efficiently differentiate the error estimate to perform unsupervised\ndiscriminative learning. Our technical tool is the method of moments, which\nallows us to exploit conditional independencies in the absence of a\nfully-specified model. Our framework encompasses a large family of losses\nincluding the log and exponential loss, and extends to structured output\nsettings such as hidden Markov models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 18:48:51 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1606.05336", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha\n  Sohl-Dickstein", "title": "On the Expressive Power of Deep Neural Networks", "comments": "Accepted to ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to the problem of neural network expressivity,\nwhich seeks to characterize how structural properties of a neural network\nfamily affect the functions it is able to compute. Our approach is based on an\ninterrelated set of measures of expressivity, unified by the novel notion of\ntrajectory length, which measures how the output of a network changes as the\ninput sweeps along a one-dimensional path. Our findings can be summarized as\nfollows:\n  (1) The complexity of the computed function grows exponentially with depth.\n  (2) All weights are not equal: trained networks are more sensitive to their\nlower (initial) layer weights.\n  (3) Regularizing on trajectory length (trajectory regularization) is a\nsimpler alternative to batch normalization, with the same performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 19:55:29 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2016 20:26:47 GMT"}, {"version": "v3", "created": "Wed, 17 Aug 2016 22:21:25 GMT"}, {"version": "v4", "created": "Mon, 3 Oct 2016 15:44:39 GMT"}, {"version": "v5", "created": "Wed, 1 Mar 2017 03:00:26 GMT"}, {"version": "v6", "created": "Sun, 18 Jun 2017 13:24:34 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Raghu", "Maithra", ""], ["Poole", "Ben", ""], ["Kleinberg", "Jon", ""], ["Ganguli", "Surya", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1606.05427", "submitter": "EPTCS", "authors": "Jasmin Christian Blanchette, Cezary Kaliszyk", "title": "Proceedings First International Workshop on Hammers for Type Theories", "comments": null, "journal-ref": "EPTCS 210, 2016", "doi": "10.4204/EPTCS.210", "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume of EPTCS contains the proceedings of the First Workshop on\nHammers for Type Theories (HaTT 2016), held on 1 July 2016 as part of the\nInternational Joint Conference on Automated Reasoning (IJCAR 2016) in Coimbra,\nPortugal. The proceedings contain four regular papers, as well as abstracts of\nthe two invited talks by Pierre Corbineau (Verimag, France) and Aleksy Schubert\n(University of Warsaw, Poland).\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 06:52:32 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Blanchette", "Jasmin Christian", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1606.05446", "submitter": "Chiara Ghidini", "authors": "Federico Chesani and Riccardo De Masellis and Chiara Di\n  Francescomarino and Chiara Ghidini and Paola Mello and Marco Montali and\n  Sergio Tessaris", "title": "Abducing Compliance of Incomplete Event Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to store data about business processes execution in so-called\nEvent Logs has brought to the diffusion of tools for the analysis of process\nexecutions and for the assessment of the goodness of a process model.\nNonetheless, these tools are often very rigid in dealing with with Event Logs\nthat include incomplete information about the process execution. Thus, while\nthe ability of handling incomplete event data is one of the challenges\nmentioned in the process mining manifesto, the evaluation of compliance of an\nexecution trace still requires an end-to-end complete trace to be performed.\n  This paper exploits the power of abduction to provide a flexible, yet\ncomputationally effective, framework to deal with different forms of\nincompleteness in an Event Log. Moreover it proposes a refinement of the\nclassical notion of compliance into strong and conditional compliance to take\ninto account incomplete logs. Finally, performances evaluation in an\nexperimental setting shows the feasibility of the presented approach.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 08:30:28 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Chesani", "Federico", ""], ["De Masellis", "Riccardo", ""], ["Di Francescomarino", "Chiara", ""], ["Ghidini", "Chiara", ""], ["Mello", "Paola", ""], ["Montali", "Marco", ""], ["Tessaris", "Sergio", ""]]}, {"id": "1606.05468", "submitter": "Sude Tavassoli", "authors": "Sude Tavassoli and Katharina Anna Zweig", "title": "Most central or least central? How much modeling decisions influence a\n  node's centrality ranking in multiplex networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand a node's centrality in a multiplex network, its centrality\nvalues in all the layers of the network can be aggregated. This requires a\nnormalization of the values, to allow their meaningful comparison and\naggregation over networks with different sizes and orders. The concrete choices\nof such preprocessing steps like normalization and aggregation are almost never\ndiscussed in network analytic papers. In this paper, we show that even sticking\nto the most simple centrality index (the degree) but using different, classic\nchoices of normalization and aggregation strategies, can turn a node from being\namong the most central to being among the least central. We present our results\nby using an aggregation operator which scales between different, classic\naggregation strategies based on three multiplex networks. We also introduce a\nnew visualization and characterization of a node's sensitivity to the choice of\na normalization and aggregation strategy in multiplex networks. The observed\nhigh sensitivity of single nodes to the specific choice of aggregation and\nnormalization strategies is of strong importance, especially for all kinds of\nintelligence-analytic software as it questions the interpretations of the\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 10:25:24 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Tavassoli", "Sude", ""], ["Zweig", "Katharina Anna", ""]]}, {"id": "1606.05506", "submitter": "Sebastian Stabinger MSc", "authors": "Sebastian Stabinger, Antonio Rodriguez-Sanchez, Justus Piater", "title": "Learning Abstract Classes using Deep Learning", "comments": "To be published in the proceedings of the International Conference on\n  Bio-inspired Information and Communications Technologies 2015", "journal-ref": null, "doi": "10.4108/eai.3-12-2015.2262468", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are generally good at learning abstract concepts about objects and\nscenes (e.g.\\ spatial orientation, relative sizes, etc.). Over the last years\nconvolutional neural networks have achieved almost human performance in\nrecognizing concrete classes (i.e.\\ specific object categories). This paper\ntests the performance of a current CNN (GoogLeNet) on the task of\ndifferentiating between abstract classes which are trivially differentiable for\nhumans. We trained and tested the CNN on the two abstract classes of horizontal\nand vertical orientation and determined how well the network is able to\ntransfer the learned classes to other, previously unseen objects.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 12:51:23 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""], ["Piater", "Justus", ""]]}, {"id": "1606.05593", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Adam White, Marlos C. Machado, Patrick M. Pilarski", "title": "Introspective Agents: Confidence Measures for General Value Functions", "comments": "Accepted for presentation at the Ninth Conference on Artificial\n  General Intelligence (AGI 2016), 4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents of general intelligence deployed in real-world scenarios must adapt to\never-changing environmental conditions. While such adaptive agents may leverage\nengineered knowledge, they will require the capacity to construct and evaluate\nknowledge themselves from their own experience in a bottom-up, constructivist\nfashion. This position paper builds on the idea of encoding knowledge as\ntemporally extended predictions through the use of general value functions.\nPrior work has focused on learning predictions about externally derived signals\nabout a task or environment (e.g. battery level, joint position). Here we\nadvocate that the agent should also predict internally generated signals\nregarding its own learning process - for example, an agent's confidence in its\nlearned predictions. Finally, we suggest how such information would be\nbeneficial in creating an introspective agent that is able to learn to make\ngood decisions in a complex, changing world.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 17:24:36 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Sherstan", "Craig", ""], ["White", "Adam", ""], ["Machado", "Marlos C.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1606.05597", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Adding Context to Concept Trees", "comments": null, "journal-ref": "International Journal of Intelligent Systems Design and Computing,\n  Inderscience, Vol. 3, No. 1, pp.84-100, 2019", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Concept Tree is a structure for storing knowledge where the trees are\nstored in a database called a Concept Base. It sits between the highly\ndistributed neural architectures and the distributed information systems, with\nthe intention of bringing brain-like and computer systems closer together.\nConcept Trees can grow from the semi-structured sources when consistent\nsequences of concepts are presented. Each tree ideally represents a single\ncohesive concept and the trees can link with each other for navigation and\nsemantic purposes. The trees are therefore also a type of semantic network and\nwould benefit from having a consistent level of context for each node. A\nconsistent build process is managed through a 'counting rule' and some other\nrules that can normalise the database structure. This restricted structure can\nthen be complimented and enriched by the more dynamic context. It is also\nsuggested to use the linking structure of the licas system [15] as a basis for\nthe context links, where the mathematical model is extended further to define\nthis. A number of tests have demonstrated the soundness of the architecture.\nBuilding the trees from text documents shows that the tree structure could be\ninherent in natural language. Then, two types of query language are described.\nBoth of these can perform consistent query processes to return knowledge to the\nuser and even enhance the query with new knowledge. This is supported even\nfurther with direct comparisons to a cognitive model, also being developed by\nthe author.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 17:32:11 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 10:58:32 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 15:54:50 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2018 14:49:17 GMT"}, {"version": "v5", "created": "Fri, 17 Jan 2020 10:08:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1606.05611", "submitter": "Karsten Schmidt", "authors": "Tim Zimmermann and Leo Kotschenreuther and Karsten Schmidt", "title": "Data-driven HR - R\\'esum\\'e Analysis Based on Natural Language\n  Processing and Machine Learning", "comments": "Research Prototype, Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recruiters usually spend less than a minute looking at each r\\'esum\\'e when\ndeciding whether it's worth continuing the recruitment process with the\ncandidate. Recruiters focus on keywords, and it's almost impossible to\nguarantee a fair process of candidate selection. The main scope of this paper\nis to tackle this issue by introducing a data-driven approach that shows how to\nprocess r\\'esum\\'es automatically and give recruiters more time to only examine\npromising candidates. Furthermore, we show how to leverage Machine Learning and\nNatural Language Processing in order to extract all required information from\nthe r\\'esum\\'es. Once the information is extracted, a ranking score is\ncalculated. The score describes how well the candidates fit based on their\neducation, work experience and skills. Later this paper illustrates a prototype\napplication that shows how this novel approach can increase the productivity of\nrecruiters. The application enables them to filter and rank candidates based on\npredefined job descriptions. Guided by the ranking, recruiters can get deeper\ninsights from candidate profiles and validate why and how the application\nranked them. This application shows how to improve the hiring process by giving\nan unbiased hiring decision support.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 17:52:31 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 20:48:05 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Zimmermann", "Tim", ""], ["Kotschenreuther", "Leo", ""], ["Schmidt", "Karsten", ""]]}, {"id": "1606.05725", "submitter": "Amirhossein Akbarnejad", "authors": "Amirhossein Akbarnejad, Mahdieh Soleymani Baghshah", "title": "An Efficient Large-scale Semi-supervised Multi-label Classifier Capable\n  of Handling Missing labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification has received considerable interest in recent\nyears. Multi-label classifiers have to address many problems including:\nhandling large-scale datasets with many instances and a large set of labels,\ncompensating missing label assignments in the training set, considering\ncorrelations between labels, as well as exploiting unlabeled data to improve\nprediction performance. To tackle datasets with a large set of labels,\nembedding-based methods have been proposed which seek to represent the label\nassignments in a low-dimensional space. Many state-of-the-art embedding-based\nmethods use a linear dimensionality reduction to represent the label\nassignments in a low-dimensional space. However, by doing so, these methods\nactually neglect the tail labels - labels that are infrequently assigned to\ninstances. We propose an embedding-based method that non-linearly embeds the\nlabel vectors using an stochastic approach, thereby predicting the tail labels\nmore accurately. Moreover, the proposed method have excellent mechanisms for\nhandling missing labels, dealing with large-scale datasets, as well as\nexploiting unlabeled data. With the best of our knowledge, our proposed method\nis the first multi-label classifier that simultaneously addresses all of the\nmentioned challenges. Experiments on real-world datasets show that our method\noutperforms stateof-the-art multi-label classifiers by a large margin, in terms\nof prediction performance, as well as training time.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2016 07:49:13 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Akbarnejad", "Amirhossein", ""], ["Baghshah", "Mahdieh Soleymani", ""]]}, {"id": "1606.05735", "submitter": "Muhammed Salman Shamsi", "authors": "Muhammed Salman Shamsi, Jhansi Lakshmi", "title": "A Comparative Analysis of classification data mining techniques :\n  Deriving key factors useful for predicting students performance", "comments": "6 pages, 6 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students opting for Engineering as their discipline is increasing rapidly.\nBut due to various factors and inappropriate primary education in India,\nfailure rates are high. Students are unable to excel in core engineering\nbecause of complex and mathematical subjects. Hence, they fail in such\nsubjects. With the help of data mining techniques, we can predict the\nperformance of students in terms of grades and failure in subjects. This paper\nperforms a comparative analysis of various classification techniques, such as\nNa\\\"ive Bayes, LibSVM, J48, Random Forest, and JRip and tries to choose best\namong these. Based on the results obtained, we found that Na\\\"ive Bayes is the\nmost accurate method in terms of students failure prediction and JRip is most\naccurate in terms of students grade prediction. We also found that JRip\nmarginally differs from Na\\\"ive Bayes in terms of accuracy for students failure\nprediction and gives us a set of rules from which we derive the key factors\ninfluencing students performance. Finally, we suggest various ways to mitigate\nthese factors. This study is limited to Indian Education system scenarios.\nHowever, the factors found can be helpful in other scenarios as well.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2016 10:06:44 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 14:47:28 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Shamsi", "Muhammed Salman", ""], ["Lakshmi", "Jhansi", ""]]}, {"id": "1606.05767", "submitter": "Naoto Yoshida", "authors": "Naoto Yoshida", "title": "On Reward Function for Survival", "comments": "Joint 8th International Conference on Soft Computing and Intelligent\n  Systems and 17th International Symposium on Advanced Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining a survival strategy (policy) is one of the fundamental problems of\nbiological agents. In this paper, we generalize the formulation of previous\nresearch related to the survival of an agent and we formulate the survival\nproblem as a maximization of the multi-step survival probability in future time\nsteps. We introduce a method for converting the maximization of multi-step\nsurvival probability into a classical reinforcement learning problem. Using\nthis conversion, the reward function (negative temporal cost function) is\nexpressed as the log of the temporal survival probability. And we show that the\nobjective function of the reinforcement learning in this sense is proportional\nto the variational lower bound of the original problem. Finally, We empirically\ndemonstrate that the agent learns survival behavior by using the reward\nfunction introduced in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2016 15:33:04 GMT"}, {"version": "v2", "created": "Sun, 24 Jul 2016 13:19:23 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Yoshida", "Naoto", ""]]}, {"id": "1606.06031", "submitter": "Sandro Pezzelle", "authors": "Denis Paperno (1), Germ\\'an Kruszewski (1), Angeliki Lazaridou (1),\n  Quan Ngoc Pham (1), Raffaella Bernardi (1), Sandro Pezzelle (1), Marco Baroni\n  (1), Gemma Boleda (1), Raquel Fern\\'andez (2) ((1) CIMeC - Center for\n  Mind/Brain Sciences, University of Trento, (2) Institute for Logic, Language\n  & Computation, University of Amsterdam)", "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context", "comments": "10 pages, Accepted as a long paper for ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LAMBADA, a dataset to evaluate the capabilities of computational\nmodels for text understanding by means of a word prediction task. LAMBADA is a\ncollection of narrative passages sharing the characteristic that human subjects\nare able to guess their last word if they are exposed to the whole passage, but\nnot if they only see the last sentence preceding the target word. To succeed on\nLAMBADA, computational models cannot simply rely on local context, but must be\nable to keep track of information in the broader discourse. We show that\nLAMBADA exemplifies a wide range of linguistic phenomena, and that none of\nseveral state-of-the-art language models reaches accuracy above 1% on this\nnovel benchmark. We thus propose LAMBADA as a challenging test set, meant to\nencourage the development of new models capable of genuine understanding of\nbroad context in natural language text.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 09:37:17 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Paperno", "Denis", ""], ["Kruszewski", "Germ\u00e1n", ""], ["Lazaridou", "Angeliki", ""], ["Pham", "Quan Ngoc", ""], ["Bernardi", "Raffaella", ""], ["Pezzelle", "Sandro", ""], ["Baroni", "Marco", ""], ["Boleda", "Gemma", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1606.06041", "submitter": "Jialin Liu Ph.D", "authors": "Jialin Liu, Diego Pe\\'rez-Lie\\'bana, Simon M. Lucas", "title": "Bandit-Based Random Mutation Hill-Climbing", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Random Mutation Hill-Climbing algorithm is a direct search technique\nmostly used in discrete domains. It repeats the process of randomly selecting a\nneighbour of a best-so-far solution and accepts the neighbour if it is better\nthan or equal to it. In this work, we propose to use a novel method to select\nthe neighbour solution using a set of independent multi- armed bandit-style\nselection units which results in a bandit-based Random Mutation Hill-Climbing\nalgorithm. The new algorithm significantly outperforms Random Mutation\nHill-Climbing in both OneMax (in noise-free and noisy cases) and Royal Road\nproblems (in the noise-free case). The algorithm shows particular promise for\ndiscrete optimisation problems where each fitness evaluation is expensive.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 09:53:29 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Liu", "Jialin", ""], ["Pe\u0155ez-Liebana", "Diego", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1606.06083", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Harish Karnick, Ashendra Bansal, Pradhuman Jhala", "title": "Product Classification in E-Commerce using Distributional Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Product classification is the task of automatically predicting a taxonomy\npath for a product in a predefined taxonomy hierarchy given a textual product\ndescription or title. For efficient product classification we require a\nsuitable representation for a document (the textual description of a product)\nfeature vector and efficient and fast algorithms for prediction. To address the\nabove challenges, we propose a new distributional semantics representation for\ndocument vector formation. We also develop a new two-level ensemble approach\nutilizing (with respect to the taxonomy tree) a path-wise, node-wise and\ndepth-wise classifiers for error reduction in the final product classification.\nOur experiments show the effectiveness of the distributional representation and\nthe ensemble approach on data sets from a leading e-commerce platform and\nachieve better results on various evaluation metrics compared to earlier\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 12:26:21 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 10:38:52 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Gupta", "Vivek", ""], ["Karnick", "Harish", ""], ["Bansal", "Ashendra", ""], ["Jhala", "Pradhuman", ""]]}, {"id": "1606.06126", "submitter": "Josiah Hanna", "authors": "Josiah P. Hanna, Peter Stone, Scott Niekum", "title": "Bootstrapping with Models: Confidence Intervals for Off-Policy\n  Evaluation", "comments": "Published in proceedings of the 16th International Conference on\n  Autonomous Agents and Multi-agent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an autonomous agent, executing a poor policy may be costly or even\ndangerous. For such agents, it is desirable to determine confidence interval\nlower bounds on the performance of any given policy without executing said\npolicy. Current methods for exact high confidence off-policy evaluation that\nuse importance sampling require a substantial amount of data to achieve a tight\nlower bound. Existing model-based methods only address the problem in discrete\nstate spaces. Since exact bounds are intractable for many domains we trade off\nstrict guarantees of safety for more data-efficient approximate bounds. In this\ncontext, we propose two bootstrapping off-policy evaluation methods which use\nlearned MDP transition models in order to estimate lower confidence bounds on\npolicy performance with limited data in both continuous and discrete state\nspaces. Since direct use of a model may introduce bias, we derive a theoretical\nupper bound on model bias for when the model transition function is estimated\nwith i.i.d. trajectories. This bound broadens our understanding of the\nconditions under which model-based methods have high bias. Finally, we\nempirically evaluate our proposed methods and analyze the settings in which\ndifferent bootstrapping off-policy confidence interval methods succeed and\nfail.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 14:06:22 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 23:26:07 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 17:13:08 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Hanna", "Josiah P.", ""], ["Stone", "Peter", ""], ["Niekum", "Scott", ""]]}, {"id": "1606.06197", "submitter": "Oiver Weede Prof. Dr.-Ing.", "authors": "Oliver Weede", "title": "Polymetric Rhythmic Feel for a Cognitive Drum Computer", "comments": null, "journal-ref": "Proc. 14th Int Conf on Culture and Computer Science, Berlin,\n  Germany, May 26-27, 2016, pp. 281-295", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a question about music cognition: how do we derive\npolymetric structures. A preference rule system is presented which is\nimplemented into a drum computer. The preference rule system allows inferring\nlocal polymetric structures, like two-over-three and three-over-two. By\nanalyzing the micro-timing of West African percussion music a timing pattern\nconsisting of six pulses was discovered. It integrates binary and ternary\nrhythmic feels. The presented drum computer integrates the discovered\nsuperimposed polymetric swing (timing and velocity) appropriate to the rhythmic\nsequence the user inputs. For binary sequences, the amount of binary swing is\nincreased and for ternary sequences, the ternary swing is increased.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 16:27:12 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 11:43:11 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Weede", "Oliver", ""]]}, {"id": "1606.06269", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller", "title": "Founded Semantics and Constraint Semantics of Logic Rules", "comments": null, "journal-ref": "Journal of Logic and Computation, Volume 30, Issue 8, December\n  2020, Pages 1609-1668", "doi": "10.1093/logcom/exaa056", "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic rules and inference are fundamental in computer science and have been\nstudied extensively. However, prior semantics of logic languages can have\nsubtle implications and can disagree significantly, on even very simple\nprograms, including in attempting to solve the well-known Russell's paradox.\nThese semantics are often non-intuitive and hard-to-understand when\nunrestricted negation is used in recursion.\n  This paper describes a simple new semantics for logic rules, founded\nsemantics, and its straightforward extension to another simple new semantics,\nconstraint semantics, that unify the core of different prior semantics. The new\nsemantics support unrestricted negation, as well as unrestricted existential\nand universal quantifications. They are uniquely expressive and intuitive by\nallowing assumptions about the predicates, rules, and reasoning to be specified\nexplicitly, as simple and precise binary choices. They are completely\ndeclarative and relate cleanly to prior semantics. In addition, founded\nsemantics can be computed in linear time in the size of the ground program.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 19:48:20 GMT"}, {"version": "v2", "created": "Sun, 11 Sep 2016 18:28:29 GMT"}, {"version": "v3", "created": "Sat, 15 Apr 2017 00:24:14 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 15:34:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1606.06355", "submitter": "Xiao Li", "authors": "Xiao Li and Calin Belta", "title": "A Hierarchical Reinforcement Learning Method for Persistent\n  Time-Sensitive Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has been applied to many interesting problems such as\nthe famous TD-gammon and the inverted helicopter flight. However, little effort\nhas been put into developing methods to learn policies for complex persistent\ntasks and tasks that are time-sensitive. In this paper, we take a step towards\nsolving this problem by using signal temporal logic (STL) as task\nspecification, and taking advantage of the temporal abstraction feature that\nthe options framework provide. We show via simulation that a relatively easy to\nimplement algorithm that combines STL and options can learn a satisfactory\npolicy with a small number of training cases\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 22:43:29 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Li", "Xiao", ""], ["Belta", "Calin", ""]]}, {"id": "1606.06357", "submitter": "Th\\'eo Trouillon", "authors": "Th\\'eo Trouillon, Johannes Welbl, Sebastian Riedel, \\'Eric Gaussier,\n  Guillaume Bouchard", "title": "Complex Embeddings for Simple Link Prediction", "comments": "10+2 pages, accepted at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical relational learning, the link prediction problem is key to\nautomatically understand the structure of large knowledge bases. As in previous\nstudies, we propose to solve this problem through latent factorization.\nHowever, here we make use of complex valued embeddings. The composition of\ncomplex embeddings can handle a large variety of binary relations, among them\nsymmetric and antisymmetric relations. Compared to state-of-the-art models such\nas Neural Tensor Network and Holographic Embeddings, our approach based on\ncomplex embeddings is arguably simpler, as it only uses the Hermitian dot\nproduct, the complex counterpart of the standard dot product between real\nvectors. Our approach is scalable to large datasets as it remains linear in\nboth space and time, while consistently outperforming alternative approaches on\nstandard link prediction benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 22:52:48 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Trouillon", "Th\u00e9o", ""], ["Welbl", "Johannes", ""], ["Riedel", "Sebastian", ""], ["Gaussier", "\u00c9ric", ""], ["Bouchard", "Guillaume", ""]]}, {"id": "1606.06368", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Martin Rinard, Percy Liang", "title": "Unanimous Prediction for 100% Precision with Application to Learning\n  Semantic Mappings", "comments": "ACL 2016, Removed the duplicate author name of the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we train a system that, on any new input, either says \"don't know\" or\nmakes a prediction that is guaranteed to be correct? We answer the question in\nthe affirmative provided our model family is well-specified. Specifically, we\nintroduce the unanimity principle: only predict when all models consistent with\nthe training data predict the same output. We operationalize this principle for\nsemantic parsing, the task of mapping utterances to logical forms. We develop a\nsimple, efficient method that reasons over the infinite set of all consistent\nmodels by only checking two of the models. We prove that our method obtains\n100% precision even with a modest amount of training data from a possibly\nadversarial distribution. Empirically, we demonstrate the effectiveness of our\napproach on the standard GeoQuery dataset.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 23:59:25 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2016 07:33:01 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Khani", "Fereshte", ""], ["Rinard", "Martin", ""], ["Liang", "Percy", ""]]}, {"id": "1606.06434", "submitter": "Prem Prakash Jayaraman", "authors": "Prem Prakash Jayaraman, and Jean-Paul Calbimonte, Hoan Nguyen Mau Quoc", "title": "The Schema Editor of OpenIoT for Semantic Sensor Networks", "comments": "First Joint International Workshop on SEMANTIC SENSOR NETWORKS AND\n  TERRA COGNITA, The 14th International Semantic Web Conference Workshops,\n  October 11-15, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies provide conceptual abstractions over data, in domains such as the\nInternet of Things, in a way that sensor data can be harvested and interpreted\nby people and applications. The Semantic Sensor Network (SSN) ontology is the\nde-facto standard for semantic representation of sensor observations and\nmetadata, and it is used at the core of the open source platform for the\nInternet of Things, OpenIoT. In this paper we present a Schema Editor that\nprovides an intuitive web interface for defining new types of sensors, and\nconcrete instances of them, using the SSN ontology as the core model. This\neditor is fully integrated with the OpenIoT platform for generating virtual\nsensor descriptions and automating their semantic annotation and registration\nprocess.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 06:20:22 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Jayaraman", "Prem Prakash", ""], ["Calbimonte", "Jean-Paul", ""], ["Quoc", "Hoan Nguyen Mau", ""]]}, {"id": "1606.06461", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Kairit Sirts, Lizhen Qu and Mark Johnson", "title": "Neighborhood Mixture Model for Knowledge Base Completion", "comments": "V1: In Proceedings of the 20th SIGNLL Conference on Computational\n  Natural Language Learning, CoNLL 2016. V2: Corrected citation to (Krompa{\\ss}\n  et al., 2015). V3: A revised version of our CoNLL 2016 paper to update latest\n  related work", "journal-ref": null, "doi": "10.18653/v1/K16-1005", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases are useful resources for many natural language processing\ntasks, however, they are far from complete. In this paper, we define a novel\nentity representation as a mixture of its neighborhood in the knowledge base\nand apply this technique on TransE-a well-known embedding model for knowledge\nbase completion. Experimental results show that the neighborhood information\nsignificantly helps to improve the results of the TransE model, leading to\nbetter performance than obtained by other state-of-the-art embedding models on\nthree benchmark datasets for triple classification, entity prediction and\nrelation prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 07:54:35 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 16:08:32 GMT"}, {"version": "v3", "created": "Thu, 9 Mar 2017 12:51:31 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Sirts", "Kairit", ""], ["Qu", "Lizhen", ""], ["Johnson", "Mark", ""]]}, {"id": "1606.06512", "submitter": "Krishnamurthy Dvijotham", "authors": "Krishnamurthy Dvijotham, Pascal Van Hentenryck, Michael Chertkov,\n  Sidhant Misra, Marc Vuffray", "title": "Graphical Models for Optimal Power Flow", "comments": "To appear in Proceedings of the 22nd International Conference on\n  Principles and Practice of Constraint Programming (CP 2016(", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI cs.CE math.OC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal power flow (OPF) is the central optimization problem in electric\npower grids. Although solved routinely in the course of power grid operations,\nit is known to be strongly NP-hard in general, and weakly NP-hard over tree\nnetworks. In this paper, we formulate the optimal power flow problem over tree\nnetworks as an inference problem over a tree-structured graphical model where\nthe nodal variables are low-dimensional vectors. We adapt the standard dynamic\nprogramming algorithm for inference over a tree-structured graphical model to\nthe OPF problem. Combining this with an interval discretization of the nodal\nvariables, we develop an approximation algorithm for the OPF problem. Further,\nwe use techniques from constraint programming (CP) to perform interval\ncomputations and adaptive bound propagation to obtain practically efficient\nalgorithms. Compared to previous algorithms that solve OPF with optimality\nguarantees using convex relaxations, our approach is able to work for arbitrary\ndistribution networks and handle mixed-integer optimization problems. Further,\nit can be implemented in a distributed message-passing fashion that is scalable\nand is suitable for \"smart grid\" applications like control of distributed\nenergy resources. We evaluate our technique numerically on several benchmark\nnetworks and show that practical OPF problems can be solved effectively using\nthis approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 11:04:10 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Dvijotham", "Krishnamurthy", ""], ["Van Hentenryck", "Pascal", ""], ["Chertkov", "Michael", ""], ["Misra", "Sidhant", ""], ["Vuffray", "Marc", ""]]}, {"id": "1606.06565", "submitter": "Jacob Steinhardt", "authors": "Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John\n  Schulman, Dan Man\\'e", "title": "Concrete Problems in AI Safety", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid progress in machine learning and artificial intelligence (AI) has\nbrought increasing attention to the potential impacts of AI technologies on\nsociety. In this paper we discuss one such potential impact: the problem of\naccidents in machine learning systems, defined as unintended and harmful\nbehavior that may emerge from poor design of real-world AI systems. We present\na list of five practical research problems related to accident risk,\ncategorized according to whether the problem originates from having the wrong\nobjective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an\nobjective function that is too expensive to evaluate frequently (\"scalable\nsupervision\"), or undesirable behavior during the learning process (\"safe\nexploration\" and \"distributional shift\"). We review previous work in these\nareas as well as suggesting research directions with a focus on relevance to\ncutting-edge AI systems. Finally, we consider the high-level question of how to\nthink most productively about the safety of forward-looking applications of AI.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 13:37:05 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 17:23:29 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Amodei", "Dario", ""], ["Olah", "Chris", ""], ["Steinhardt", "Jacob", ""], ["Christiano", "Paul", ""], ["Schulman", "John", ""], ["Man\u00e9", "Dan", ""]]}, {"id": "1606.06797", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani, Bela\\\"id Ahiod", "title": "\\'Etude de Probl\\`emes d'Optimisation Combinatoire \\`a Multiples\n  Composantes Interd\\'ependantes", "comments": "in French. Extended abstract presented at the URAC days meeting in\n  Rabat, Morocco. The meeting website is available at\n  https://sites.google.com/site/lriturac29/j-urac-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract presents an overview on NP-hard optimization problems\nwith multiple interdependent components. These problems occur in many\nreal-world applications: industrial applications, engineering, and logistics.\nThe fact that these problems are composed of many sub-problems that are NP-hard\nmakes them even more challenging to solve using exact algorithms. This is\nmainly due to the high complexity of this class of algorithms and the hardness\nof the problems themselves. The main source of difficulty of these problems is\nthe presence of internal dependencies between sub-problems. This aspect of\ninterdependence of components is presented, and some outlines on solving\napproaches are briefly introduced from a (meta)heuristics and evolutionary\ncomputation perspective.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 01:34:53 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Yafrani", "Mohamed El", ""], ["Ahiod", "Bela\u00efd", ""]]}, {"id": "1606.06888", "submitter": "Auke Wiggers", "authors": "Auke J. Wiggers and Frans A. Oliehoek and Diederik M. Roijers", "title": "Structure in the Value Function of Two-Player Zero-Sum Games of\n  Incomplete Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-sum stochastic games provide a rich model for competitive decision\nmaking. However, under general forms of state uncertainty as considered in the\nPartially Observable Stochastic Game (POSG), such decision making problems are\nstill not very well understood. This paper makes a contribution to the theory\nof zero-sum POSGs by characterizing structure in their value function. In\nparticular, we introduce a new formulation of the value function for zs-POSGs\nas a function of the \"plan-time sufficient statistics\" (roughly speaking the\ninformation distribution in the POSG), which has the potential to enable\ngeneralization over such information distributions. We further delineate this\ngeneralization capability by proving a structural result on the shape of value\nfunction: it exhibits concavity and convexity with respect to appropriately\nchosen marginals of the statistic space. This result is a key pre-cursor for\ndeveloping solution methods that may be able to exploit such structure.\nFinally, we show how these results allow us to reduce a zs-POSG to a\n\"centralized\" model with shared observations, thereby transferring results for\nthe latter, narrower class, to games with individual (private) observations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 10:41:04 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Wiggers", "Auke J.", ""], ["Oliehoek", "Frans A.", ""], ["Roijers", "Diederik M.", ""]]}, {"id": "1606.06897", "submitter": "Sanjay Sahay", "authors": "Ashu Sharma and Sanjay K. Sahay", "title": "An effective approach for classification of advanced malware with high\n  accuracy", "comments": "15 Pages, 14 figures", "journal-ref": "International Journal of Security and Its Applications, Vol. 10,\n  No. 4, pp.249-266, 2016", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combating malware is very important for software/systems security, but to\nprevent the software/systems from the advanced malware, viz. metamorphic\nmalware is a challenging task, as it changes the structure/code after each\ninfection. Therefore in this paper, we present a novel approach to detect the\nadvanced malware with high accuracy by analyzing the occurrence of opcodes\n(features) by grouping the executables. These groups are made on the basis of\nour earlier studies [1] that the difference between the sizes of any two\nmalware generated by popular advanced malware kits viz. PS-MPC, G2 and NGVCK\nare within 5 KB. On the basis of obtained promising features, we studied the\nperformance of thirteen classifiers using N-fold cross-validation available in\nmachine learning tool WEKA. Among these thirteen classifiers we studied\nin-depth top five classifiers (Random forest, LMT, NBT, J48 and FT) and obtain\nmore than 96.28% accuracy for the detection of unknown malware, which is better\nthan the maximum detection accuracy (95.9%) reported by Santos et al (2013). In\nthese top five classifiers, our approach obtained a detection accuracy of\n97.95% by the Random forest.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:00:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sharma", "Ashu", ""], ["Sahay", "Sanjay K.", ""]]}, {"id": "1606.06900", "submitter": "Panupong Pasupat", "authors": "Panupong Pasupat and Percy Liang", "title": "Inferring Logical Forms From Denotations", "comments": "Published at the Association for Computational Linguistics (ACL)\n  conference, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core problem in learning semantic parsers from denotations is picking out\nconsistent logical forms--those that yield the correct denotation--from a\ncombinatorially large space. To control the search space, previous work relied\non restricted set of rules, which limits expressivity. In this paper, we\nconsider a much more expressive class of logical forms, and show how to use\ndynamic programming to efficiently represent the complete set of consistent\nlogical forms. Expressivity also introduces many more spurious logical forms\nwhich are consistent with the correct denotation but do not represent the\nmeaning of the utterance. To address this, we generate fictitious worlds and\nuse crowdsourced denotations on these worlds to filter out spurious logical\nforms. On the WikiTableQuestions dataset, we increase the coverage of\nanswerable questions from 53.5% to 76%, and the additional crowdsourced\nsupervision lets us rule out 92.1% of spurious logical forms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:07:43 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 21:24:08 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Pasupat", "Panupong", ""], ["Liang", "Percy", ""]]}, {"id": "1606.06908", "submitter": "Sanjay Sahay", "authors": "Sanjay K. Sahay and Ashu Sharma", "title": "Grouping the executables to detect malware with high accuracy", "comments": "8 Pages, 13 Figures. arXiv admin note: text overlap with\n  arXiv:1606.06897", "journal-ref": "Elsevier, Procedia Computer Science, Vol. 78, pp. 667 - 674, 2016", "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metamorphic malware variants with the same malicious behavior (family),\ncan obfuscate themselves to look different from each other. This variation in\nstructure leads to a huge signature database for traditional signature matching\ntechniques to detect them. In order to effective and efficient detection of\nmalware in large amounts of executables, we need to partition these files into\ngroups which can identify their respective families. In addition, the grouping\ncriteria should be chosen such a way that, it can also be applied to unknown\nfiles encounter on computers for classification. This paper discusses the study\nof malware and benign executables in groups to detect unknown malware with high\naccuracy. We studied sizes of malware generated by three popular second\ngeneration malware (metamorphic malware) creator kits viz. G2, PS-MPC and\nNGVCK, and observed that the size variation in any two generated malware from\nsame kit is not much. Hence, we grouped the executables on the basis of malware\nsizes by using Optimal k-Means Clustering algorithm and used these obtained\ngroups to select promising features for training (Random forest, J48, LMT, FT\nand NBT) classifiers to detect variants of malware or unknown malware. We find\nthat detection of malware on the basis of their respected file sizes gives\naccuracy up to 99.11% from the classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 11:45:13 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Sahay", "Sanjay K.", ""], ["Sharma", "Ashu", ""]]}, {"id": "1606.06979", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson and Patrick M. Pilarski", "title": "Simultaneous Control and Human Feedback in the Training of a Robotic\n  Agent with Actor-Critic Reinforcement Learning", "comments": "7 pages, 3 figures, Accepted at the Interactive Machine Learning\n  Workshop at IJCAI 2016 (IML): Connecting Humans and Machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes a preliminary report on the advantages and\ndisadvantages of incorporating simultaneous human control and feedback signals\nin the training of a reinforcement learning robotic agent. While robotic\nhuman-machine interfaces have become increasingly complex in both form and\nfunction, control remains challenging for users. This has resulted in an\nincreasing gap between user control approaches and the number of robotic motors\nwhich can be controlled. One way to address this gap is to shift some autonomy\nto the robot. Semi-autonomous actions of the robotic agent can then be shaped\nby human feedback, simplifying user control. Most prior work on agent shaping\nby humans has incorporated training with feedback, or has included indirect\ncontrol signals. By contrast, in this paper we explore how a human can provide\nconcurrent feedback signals and real-time myoelectric control signals to train\na robot's actor-critic reinforcement learning control system. Using both a\nphysical and a simulated robotic system, we compare training performance on a\nsimple movement task when reward is derived from the environment, when reward\nis provided by the human, and combinations of these two approaches. Our results\nindicate that some benefit can be gained with the inclusion of human generated\nfeedback.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:09:04 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Mathewson", "Kory W.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1606.07025", "submitter": "Luis Mu\\~noz-Gonz\\'alez", "authors": "Luis Mu\\~noz-Gonz\\'alez, Daniele Sgandurra, Andrea Paudice, Emil C.\n  Lupu", "title": "Efficient Attack Graph Analysis through Approximate Inference", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attack graphs provide compact representations of the attack paths that an\nattacker can follow to compromise network resources by analysing network\nvulnerabilities and topology. These representations are a powerful tool for\nsecurity risk assessment. Bayesian inference on attack graphs enables the\nestimation of the risk of compromise to the system's components given their\nvulnerabilities and interconnections, and accounts for multi-step attacks\nspreading through the system. Whilst static analysis considers the risk posture\nat rest, dynamic analysis also accounts for evidence of compromise, e.g. from\nSIEM software or forensic investigation. However, in this context, exact\nBayesian inference techniques do not scale well. In this paper we show how\nLoopy Belief Propagation - an approximate inference technique - can be applied\nto attack graphs, and that it scales linearly in the number of nodes for both\nstatic and dynamic analysis, making such analyses viable for larger networks.\nWe experiment with different topologies and network clustering on synthetic\nBayesian attack graphs with thousands of nodes to show that the algorithm's\naccuracy is acceptable and converge to a stable solution. We compare sequential\nand parallel versions of Loopy Belief Propagation with exact inference\ntechniques for both static and dynamic analysis, showing the advantages of\napproximate inference techniques to scale to larger attack graphs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 17:48:17 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Sgandurra", "Daniele", ""], ["Paudice", "Andrea", ""], ["Lupu", "Emil C.", ""]]}, {"id": "1606.07035", "submitter": "Sara Magliacane", "authors": "Sara Magliacane, Tom Claassen, Joris M. Mooij", "title": "Ancestral Causal Inference", "comments": "In Proceedings of Advances in Neural Information Processing Systems\n  29 (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based causal discovery from limited data is a notoriously\ndifficult challenge due to the many borderline independence test decisions.\nSeveral approaches to improve the reliability of the predictions by exploiting\nredundancy in the independence information have been proposed recently. Though\npromising, existing approaches can still be greatly improved in terms of\naccuracy and scalability. We present a novel method that reduces the\ncombinatorial explosion of the search space by using a more coarse-grained\nrepresentation of causal information, drastically reducing computation time.\nAdditionally, we propose a method to score causal predictions based on their\nconfidence. Crucially, our implementation also allows one to easily combine\nobservational and interventional data and to incorporate various types of\navailable background knowledge. We prove soundness and asymptotic consistency\nof our method and demonstrate that it can outperform the state-of-the-art on\nsynthetic data, achieving a speedup of several orders of magnitude. We\nillustrate its practical feasibility by applying it on a challenging protein\ndata set.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 18:26:27 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 22:23:32 GMT"}, {"version": "v3", "created": "Thu, 26 Jan 2017 14:26:27 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Magliacane", "Sara", ""], ["Claassen", "Tom", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1606.07056", "submitter": "Abhay Prakash", "authors": "Abhay Prakash, Chris Brockett, Puneet Agrawal", "title": "Emulating Human Conversations using Convolutional Neural Network-based\n  IR", "comments": "5 pages, Neu-IR'16 SIGIR Workshop on Neural Information Retrieval,\n  July 21, 2016, Pisa, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents (\"bots\") are beginning to be widely used in\nconversational interfaces. To design a system that is capable of emulating\nhuman-like interactions, a conversational layer that can serve as a fabric for\nchat-like interaction with the agent is needed. In this paper, we introduce a\nmodel that employs Information Retrieval by utilizing convolutional deep\nstructured semantic neural network-based features in the ranker to present\nhuman-like responses in ongoing conversation with a user. In conversations,\naccounting for context is critical to the retrieval model; we show that our\ncontext-sensitive approach using a Convolutional Deep Structured Semantic Model\n(cDSSM) with character trigrams significantly outperforms several conventional\nbaselines in terms of the relevance of responses retrieved.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 19:55:24 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Prakash", "Abhay", ""], ["Brockett", "Chris", ""], ["Agrawal", "Puneet", ""]]}, {"id": "1606.07095", "submitter": "Michael Beeson", "authors": "Michael Beeson and Larry Wos", "title": "Finding Proofs in Tarskian Geometry", "comments": "32 pages, 4 figures, 4 tables. Supplementary computer code published\n  separately", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a project to use a theorem prover to find proofs of the theorems\nin Tarskian geometry. These theorems start with fundamental properties of\nbetweenness, proceed through the derivations of several famous theorems due to\nGupta and end with the derivation from Tarski's axioms of Hilbert's 1899 axioms\nfor geometry. They include the four challenge problems left unsolved by Quaife,\nwho two decades ago found some \\Otter proofs in Tarskian geometry (solving\nchallenges issued in Wos's 1998 book). There are 212 theorems in this\ncollection. We were able to find \\Otter proofs of all these theorems. We\ndeveloped a methodology for the automated preparation and checking of the input\nfiles for those theorems, to ensure that no human error has corrupted the\nformal development of an entire theory as embodied in two hundred input files\nand proofs. We distinguish between proofs that were found completely\nmechanically (without reference to the steps of a book proof) and proofs that\nwere constructed by some technique that involved a human knowing the steps of a\nbook proof. Proofs of length 40--100, roughly speaking, are difficult exercises\nfor a human, and proofs of 100-250 steps belong in a Ph.D. thesis or\npublication. 29 of the proofs in our collection are longer than 40 steps, and\nten are longer than 90 steps. We were able to derive completely mechanically\nall but 26 of the 183 theorems that have \"short\" proofs (40 or fewer deduction\nsteps). We found proofs of the rest, as well as the 29 \"hard\" theorems, using a\nmethod that requires consulting the book proof at the outset. Our \"subformula\nstrategy\" enabled us to prove four of the 29 hard theorems completely\nmechanically. These are Ph.D. level proofs, of length up to 108.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 20:39:23 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Beeson", "Michael", ""], ["Wos", "Larry", ""]]}, {"id": "1606.07137", "submitter": "Abeed Sarker", "authors": "Abeed Sarker", "title": "Automated Extraction of Number of Subjects in Randomised Controlled\n  Trials", "comments": "unpublished", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple approach for automatically extracting the number of\nsubjects involved in randomised controlled trials (RCT). Our approach first\napplies a set of rule-based techniques to extract candidate study sizes from\nthe abstracts of the articles. Supervised classification is then performed over\nthe candidates with support vector machines, using a small set of lexical,\nstructural, and contextual features. With only a small annotated training set\nof 201 RCTs, we obtained an accuracy of 88\\%. We believe that this system will\naid complex medical text processing tasks such as summarisation and question\nanswering.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 23:35:59 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Sarker", "Abeed", ""]]}, {"id": "1606.07149", "submitter": "Ivo Bukovsky Ph.D.", "authors": "Ivo Bukovsky and Noriyasu Homma", "title": "An Approach to Stable Gradient Descent Adaptation of Higher-Order Neural\n  Units", "comments": "2016, 13 pages", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems,ISSN:\n  2162-237X,2016", "doi": "10.1109/TNNLS.2016.2572310", "report-no": null, "categories": "cs.NE cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability evaluation of a weight-update system of higher-order neural units\n(HONUs) with polynomial aggregation of neural inputs (also known as classes of\npolynomial neural networks) for adaptation of both feedforward and recurrent\nHONUs by a gradient descent method is introduced. An essential core of the\napproach is based on spectral radius of a weight-update system, and it allows\nstability monitoring and its maintenance at every adaptation step individually.\nAssuring stability of the weight-update system (at every single adaptation\nstep) naturally results in adaptation stability of the whole neural\narchitecture that adapts to target data. As an aside, the used approach\nhighlights the fact that the weight optimization of HONU is a linear problem,\nso the proposed approach can be generally extended to any neural architecture\nthat is linear in its adaptable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 01:07:27 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Bukovsky", "Ivo", ""], ["Homma", "Noriyasu", ""]]}, {"id": "1606.07154", "submitter": "Mihajlo Grbovic", "authors": "Mihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan\n  Bhamidipati, Jaikit Savla, Varun Bhagwan, Doug Sharp", "title": "E-commerce in Your Inbox: Product Recommendations at Scale", "comments": "10 pages, 12 figures, Proceedings of the 21th ACM SIGKDD\n  International Conference on Knowledge Discovery and Data Mining (KDD 2015),\n  Sydney, Australia", "journal-ref": "Proceedings of the 21th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD 2015), Sydney, Australia", "doi": "10.1145/2783258.2788627.", "report-no": null, "categories": "cs.AI cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years online advertising has become increasingly ubiquitous and\neffective. Advertisements shown to visitors fund sites and apps that publish\ndigital content, manage social networks, and operate e-mail services. Given\nsuch large variety of internet resources, determining an appropriate type of\nadvertising for a given platform has become critical to financial success.\nNative advertisements, namely ads that are similar in look and feel to content,\nhave had great success in news and social feeds. However, to date there has not\nbeen a winning formula for ads in e-mail clients. In this paper we describe a\nsystem that leverages user purchase history determined from e-mail receipts to\ndeliver highly personalized product ads to Yahoo Mail users. We propose to use\na novel neural language-based algorithm specifically tailored for delivering\neffective product recommendations, which was evaluated against baselines that\nincluded showing popular products and products predicted based on\nco-occurrence. We conducted rigorous offline testing using a large-scale\nproduct purchase data set, covering purchases of more than 29 million users\nfrom 172 e-commerce websites. Ads in the form of product recommendations were\nsuccessfully tested on online traffic, where we observed a steady 9% lift in\nclick-through rates over other ad formats in mail, as well as comparable lift\nin conversion rates. Following successful tests, the system was launched into\nproduction during the holiday season of 2014.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 01:20:59 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Grbovic", "Mihajlo", ""], ["Radosavljevic", "Vladan", ""], ["Djuric", "Nemanja", ""], ["Bhamidipati", "Narayan", ""], ["Savla", "Jaikit", ""], ["Bhagwan", "Varun", ""], ["Sharp", "Doug", ""]]}, {"id": "1606.07233", "submitter": "Morten Goodwin Dr.", "authors": "Per-Arne Andersen, Christian Kr{\\aa}kevik, Morten Goodwin, Anis Yazidi", "title": "Adaptive Task Assignment in Online Learning Environments", "comments": "6th International Conference on Web Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of online learning, intelligent tutoring\nsystems are regaining increased attention. In this paper, we introduce adaptive\nalgorithms for personalized assignment of learning tasks to student so that to\nimprove his performance in online learning environments. As main contribution\nof this paper, we propose a a novel Skill-Based Task Selector (SBTS) algorithm\nwhich is able to approximate a student's skill level based on his performance\nand consequently suggest adequate assignments. The SBTS is inspired by the\nclass of multi-armed bandit algorithms. However, in contrast to standard\nmulti-armed bandit approaches, the SBTS aims at acquiring two criteria related\nto student learning, namely: which topics should the student work on, and what\nlevel of difficulty should the task be. The SBTS centers on innovative reward\nand punishment schemes in a task and skill matrix based on the student\nbehaviour.\n  To verify the algorithm, the complex student behaviour is modelled using a\nneighbour node selection approach based on empirical estimations of a students\nlearning curve. The algorithm is evaluated with a practical scenario from a\nbasic java programming course. The SBTS is able to quickly and accurately adapt\nto the composite student competency --- even with a multitude of student\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 09:09:49 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Andersen", "Per-Arne", ""], ["Kr\u00e5kevik", "Christian", ""], ["Goodwin", "Morten", ""], ["Yazidi", "Anis", ""]]}, {"id": "1606.07259", "submitter": "Niek Tax", "authors": "Niek Tax, Natalia Sidorova, Reinder Haakma, Wil M. P. van der Aalst", "title": "Log-based Evaluation of Label Splits for Process Models", "comments": "Paper accepted at the 20th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems, to appear\n  in Procedia Computer Science", "journal-ref": "Procedia Computer Science, 96 (2016) 63-72", "doi": "10.1016/j.procs.2016.08.096", "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining techniques aim to extract insights in processes from event\nlogs. One of the challenges in process mining is identifying interesting and\nmeaningful event labels that contribute to a better understanding of the\nprocess. Our application area is mining data from smart homes for elderly,\nwhere the ultimate goal is to signal deviations from usual behavior and provide\ntimely recommendations in order to extend the period of independent living.\nExtracting individual process models showing user behavior is an important\ninstrument in achieving this goal. However, the interpretation of sensor data\nat an appropriate abstraction level is not straightforward. For example, a\nmotion sensor in a bedroom can be triggered by tossing and turning in bed or by\ngetting up. We try to derive the actual activity depending on the context\n(time, previous events, etc.). In this paper we introduce the notion of label\nrefinements, which links more abstract event descriptions with their more\nrefined counterparts. We present a statistical evaluation method to determine\nthe usefulness of a label refinement for a given event log from a process\nperspective. Based on data from smart homes, we show how our statistical\nevaluation method for label refinements can be used in practice. Our method was\nable to select two label refinements out of a set of candidate label\nrefinements that both had a positive effect on model precision.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 10:29:48 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Tax", "Niek", ""], ["Sidorova", "Natalia", ""], ["Haakma", "Reinder", ""], ["van der Aalst", "Wil M. P.", ""]]}, {"id": "1606.07282", "submitter": "Irene C\\'ordoba", "authors": "Irene C\\'ordoba, Concha Bielza and Pedro Larra\\~naga", "title": "A review of Gaussian Markov models for conditional independence", "comments": "Fix author signature", "journal-ref": "Journal of Statistical Planning and Inference, 206:127-144, 2020", "doi": "10.1016/j.jspi.2019.09.008", "report-no": null, "categories": "stat.ME cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov models lie at the interface between statistical independence in a\nprobability distribution and graph separation properties. We review model\nselection and estimation in directed and undirected Markov models with Gaussian\nparametrization, emphasizing the main similarities and differences. These two\nmodel classes are similar but not equivalent, although they share a common\nintersection. We present the existing results from a historical perspective,\ntaking into account the amount of literature existing from both the artificial\nintelligence and statistics research communities, where these models were\noriginated. We cover classical topics such as maximum likelihood estimation and\nmodel selection via hypothesis testing, but also more modern approaches like\nregularization and Bayesian methods. We also discuss how the Markov models\nreviewed fit in the rich hierarchy of other, higher level Markov model classes.\nFinally, we close the paper overviewing relaxations of the Gaussian assumption\nand pointing out the main areas of application where these Markov models are\nnowadays used.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:12:20 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 16:27:04 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 11:10:43 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 08:35:01 GMT"}, {"version": "v5", "created": "Wed, 2 Oct 2019 08:33:09 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["C\u00f3rdoba", "Irene", ""], ["Bielza", "Concha", ""], ["Larra\u00f1aga", "Pedro", ""]]}, {"id": "1606.07295", "submitter": "EPTCS", "authors": "R Ramanujam (IMSc, Chennai, India)", "title": "Proceedings Fifteenth Conference on Theoretical Aspects of Rationality\n  and Knowledge", "comments": null, "journal-ref": "EPTCS 215, 2016", "doi": "10.4204/EPTCS.215", "report-no": null, "categories": "cs.GT cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 15th Conference on Theoretical Aspects of Rationality and Knowledge\n(TARK) took place in Carnegie Mellon University, Pittsburgh, USA from June 4 to\n6, 2015.\n  The mission of the TARK conferences is to bring together researchers from a\nwide variety of fields, including Artificial Intelligence, Cryptography,\nDistributed Computing, Economics and Game Theory, Linguistics, Philosophy, and\nPsychology, in order to further our understanding of interdisciplinary issues\ninvolving reasoning about rationality and knowledge.\n  These proceedings consist of a subset of the papers / abstracts presented at\nthe TARK conference.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:50:36 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Ramanujam", "R", "", "IMSc, Chennai, India"]]}, {"id": "1606.07356", "submitter": "Aishwarya Agrawal", "authors": "Aishwarya Agrawal, Dhruv Batra, Devi Parikh", "title": "Analyzing the Behavior of Visual Question Answering Models", "comments": "13 pages, 20 figures; To appear in EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a number of deep-learning based models have been proposed for the\ntask of Visual Question Answering (VQA). The performance of most models is\nclustered around 60-70%. In this paper we propose systematic methods to analyze\nthe behavior of these models as a first step towards recognizing their\nstrengths and weaknesses, and identifying the most fruitful directions for\nprogress. We analyze two models, one each from two major classes of VQA models\n-- with-attention and without-attention and show the similarities and\ndifferences in the behavior of these models. We also analyze the winning entry\nof the VQA Challenge 2016.\n  Our behavior analysis reveals that despite recent progress, today's VQA\nmodels are \"myopic\" (tend to fail on sufficiently novel instances), often \"jump\nto conclusions\" (converge on a predicted answer after 'listening' to just half\nthe question), and are \"stubborn\" (do not change their answers across images).\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 16:05:16 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 19:56:22 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Agrawal", "Aishwarya", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1606.07384", "submitter": "Yu Cheng", "authors": "Yu Cheng, Ilias Diakonikolas, Daniel Kane, Alistair Stewart", "title": "Robust Learning of Fixed-Structure Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning Bayesian networks in a robust model\nwhere an $\\epsilon$-fraction of the samples are adversarially corrupted. In\nthis work, we study the fully observable discrete case where the structure of\nthe network is given. Even in this basic setting, previous learning algorithms\neither run in exponential time or lose dimension-dependent factors in their\nerror guarantees. We provide the first computationally efficient robust\nlearning algorithm for this problem with dimension-independent error\nguarantees. Our algorithm has near-optimal sample complexity, runs in\npolynomial time, and achieves error that scales nearly-linearly with the\nfraction of adversarially corrupted samples. Finally, we show on both synthetic\nand semi-synthetic data that our algorithm performs well in practice.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 17:47:13 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 05:31:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Cheng", "Yu", ""], ["Diakonikolas", "Ilias", ""], ["Kane", "Daniel", ""], ["Stewart", "Alistair", ""]]}, {"id": "1606.07419", "submitter": "Pulkit Agrawal", "authors": "Pulkit Agrawal, Ashvin Nair, Pieter Abbeel, Jitendra Malik, Sergey\n  Levine", "title": "Learning to Poke by Poking: Experiential Learning of Intuitive Physics", "comments": null, "journal-ref": "NIPS 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an experiential learning paradigm for acquiring an internal\nmodel of intuitive physics. Our model is evaluated on a real-world robotic\nmanipulation task that requires displacing objects to target locations by\npoking. The robot gathered over 400 hours of experience by executing more than\n100K pokes on different objects. We propose a novel approach based on deep\nneural networks for modeling the dynamics of robot's interactions directly from\nimages, by jointly estimating forward and inverse models of dynamics. The\ninverse model objective provides supervision to construct informative visual\nfeatures, which the forward model can then predict and in turn regularize the\nfeature space for the inverse model. The interplay between these two objectives\ncreates useful, accurate models that can then be used for multi-step decision\nmaking. This formulation has the additional benefit that it is possible to\nlearn forward models in an abstract feature space and thus alleviate the need\nof predicting pixels. Our experiments show that this joint modeling approach\noutperforms alternative methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 19:42:57 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 22:53:52 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Agrawal", "Pulkit", ""], ["Nair", "Ashvin", ""], ["Abbeel", "Pieter", ""], ["Malik", "Jitendra", ""], ["Levine", "Sergey", ""]]}, {"id": "1606.07461", "submitter": "Alexander M. Rush", "authors": "Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, Alexander M.\n  Rush", "title": "LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in\n  Recurrent Neural Networks", "comments": "InfoVis 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks, and in particular long short-term memory (LSTM)\nnetworks, are a remarkably effective tool for sequence modeling that learn a\ndense black-box hidden representation of their sequential input. Researchers\ninterested in better understanding these models have studied the changes in\nhidden state representations over time and noticed some interpretable patterns\nbut also significant noise. In this work, we present LSTMVIS, a visual analysis\ntool for recurrent neural networks with a focus on understanding these hidden\nstate dynamics. The tool allows users to select a hypothesis input range to\nfocus on local state changes, to match these states changes to similar patterns\nin a large data set, and to align these results with structural annotations\nfrom their domain. We show several use cases of the tool for analyzing specific\nhidden state properties on dataset containing nesting, phrase structure, and\nchord progressions, and demonstrate how the tool can be used to isolate\npatterns for further statistical analysis. We characterize the domain, the\ndifferent stakeholders, and their goals and tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 20:20:39 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 15:11:54 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1606.07487", "submitter": "Santiago Ontanon", "authors": "Adam James Summerville, Sam Snodgrass, Michael Mateas, Santiago\n  Onta\\~n\\'on", "title": "The VGLC: The Video Game Level Corpus", "comments": "To appear in proceedings of the 7th Workshop on Procedural Content\n  Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Levels are a key component of many different video games, and a large body of\nwork has been produced on how to procedurally generate game levels. Recently,\nMachine Learning techniques have been applied to video game level generation\ntowards the purpose of automatically generating levels that have the properties\nof the training corpus. Towards that end we have made available a corpora of\nvideo game levels in an easy to parse format ideal for different machine\nlearning and other game AI research purposes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 21:36:36 GMT"}, {"version": "v2", "created": "Sun, 3 Jul 2016 20:04:55 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Summerville", "Adam James", ""], ["Snodgrass", "Sam", ""], ["Mateas", "Michael", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "1606.07493", "submitter": "Arjun Chandrasekaran", "authors": "Harsh Agrawal, Arjun Chandrasekaran, Dhruv Batra, Devi Parikh, Mohit\n  Bansal", "title": "Sort Story: Sorting Jumbled Images and Captions into Stories", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal common sense has applications in AI tasks such as QA, multi-document\nsummarization, and human-AI communication. We propose the task of sequencing --\ngiven a jumbled set of aligned image-caption pairs that belong to a story, the\ntask is to sort them such that the output sequence forms a coherent story. We\npresent multiple approaches, via unary (position) and pairwise (order)\npredictions, and their ensemble-based combinations, achieving strong results on\nthis task. We use both text-based and image-based features, which depict\ncomplementary improvements. Using qualitative examples, we demonstrate that our\nmodels have learnt interesting aspects of temporal common sense.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 21:54:44 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2016 05:26:43 GMT"}, {"version": "v3", "created": "Wed, 6 Jul 2016 19:56:36 GMT"}, {"version": "v4", "created": "Sat, 24 Sep 2016 00:37:27 GMT"}, {"version": "v5", "created": "Mon, 7 Nov 2016 18:48:13 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Agrawal", "Harsh", ""], ["Chandrasekaran", "Arjun", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Bansal", "Mohit", ""]]}, {"id": "1606.07514", "submitter": "EPTCS", "authors": "Sarit Kraus (Bar-Ilan University)", "title": "Human-Agent Decision-making: Combining Theory and Practice", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 13-27", "doi": "10.4204/EPTCS.215.2", "report-no": null, "categories": "cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive work has been conducted both in game theory and logic to model\nstrategic interaction. An important question is whether we can use these\ntheories to design agents for interacting with people? On the one hand, they\nprovide a formal design specification for agent strategies. On the other hand,\npeople do not necessarily adhere to playing in accordance with these\nstrategies, and their behavior is affected by a multitude of social and\npsychological factors. In this paper we will consider the question of whether\nstrategies implied by theories of strategic behavior can be used by automated\nagents that interact proficiently with people. We will focus on automated\nagents that we built that need to interact with people in two negotiation\nsettings: bargaining and deliberation. For bargaining we will study game-theory\nbased equilibrium agents and for argumentation we will discuss logic-based\nargumentation theory. We will also consider security games and persuasion games\nand will discuss the benefits of using equilibrium based agents.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:07 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Kraus", "Sarit", "", "Bar-Ilan University"]]}, {"id": "1606.07515", "submitter": "EPTCS", "authors": "Thomas {\\AA}gotnes (University of Bergen), Y\\`i N. W\\'ang (Zhejiang\n  University)", "title": "Resolving Distributed Knowledge", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 31-50", "doi": "10.4204/EPTCS.215.4", "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed knowledge is the sum of the knowledge in a group; what someone\nwho is able to discern between two possible worlds whenever any member of the\ngroup can discern between them, would know. Sometimes distributed knowledge is\nreferred to as the potential knowledge of a group, or the joint knowledge they\ncould obtain if they had unlimited means of communication. In epistemic logic,\nthe formula D_G{\\phi} is intended to express the fact that group G has\ndistributed knowledge of {\\phi}, that there is enough information in the group\nto infer {\\phi}. But this is not the same as reasoning about what happens if\nthe members of the group share their information. In this paper we introduce an\noperator R_G, such that R_G{\\phi} means that {\\phi} is true after G have shared\nall their information with each other - after G's distributed knowledge has\nbeen resolved. The R_G operators are called resolution operators. Semantically,\nwe say that an expression R_G{\\phi} is true iff {\\phi} is true in what van\nBenthem [11, p. 249] calls (G's) communication core; the model update obtained\nby removing links to states for members of G that are not linked by all members\nof G. We study logics with different combinations of resolution operators and\noperators for common and distributed knowledge. Of particular interest is the\nrelationship between distributed and common knowledge. The main results are\nsound and complete axiomatizations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:18 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["\u00c5gotnes", "Thomas", "", "University of Bergen"], ["W\u00e1ng", "Y\u00ec N.", "", "Zhejiang\n  University"]]}, {"id": "1606.07516", "submitter": "EPTCS", "authors": "Krzysztof R. Apt (Centrum Wiskunde Informatica), Davide Grossi\n  (University of Liverpool), Wiebe van der Hoek (University of Liverpool)", "title": "Epistemic Protocols for Distributed Gossiping", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 51-66", "doi": "10.4204/EPTCS.215.5", "report-no": null, "categories": "cs.AI cs.DC cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip protocols aim at arriving, by means of point-to-point or group\ncommunications, at a situation in which all the agents know each other's\nsecrets. We consider distributed gossip protocols which are expressed by means\nof epistemic logic. We provide an operational semantics of such protocols and\nset up an appropriate framework to argue about their correctness. Then we\nanalyze specific protocols for complete graphs and for directed rings.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:30:33 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Apt", "Krzysztof R.", "", "Centrum Wiskunde Informatica"], ["Grossi", "Davide", "", "University of Liverpool"], ["van der Hoek", "Wiebe", "", "University of Liverpool"]]}, {"id": "1606.07520", "submitter": "EPTCS", "authors": "Peter Fritz (University of Oslo), Harvey Lederman (New York\n  University)", "title": "Standard State Space Models of Unawareness (Extended Abstract)", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 141-158", "doi": "10.4204/EPTCS.215.11", "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impossibility theorem of Dekel, Lipman and Rustichini has been thought to\ndemonstrate that standard state-space models cannot be used to represent\nunawareness. We first show that Dekel, Lipman and Rustichini do not establish\nthis claim. We then distinguish three notions of awareness, and argue that\nalthough one of them may not be adequately modeled using standard state spaces,\nthere is no reason to think that standard state spaces cannot provide models of\nthe other two notions. In fact, standard space models of these forms of\nawareness are attractively simple. They allow us to prove completeness and\ndecidability results with ease, to carry over standard techniques from decision\ntheory, and to add propositional quantifiers straightforwardly.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:31:42 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Fritz", "Peter", "", "University of Oslo"], ["Lederman", "Harvey", "", "New York\n  University"]]}, {"id": "1606.07522", "submitter": "EPTCS", "authors": "Patrick Girard, Marcus Anthony Triplett", "title": "Ceteris paribus logic in counterfactual reasoning", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 176-193", "doi": "10.4204/EPTCS.215.13", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantics for counterfactuals due to David Lewis has been challenged on\nthe basis of unlikely, or impossible, events. Such events may skew a given\nsimilarity order in favour of those possible worlds which exhibit them. By\nupdating the relational structure of a model according to a ceteris paribus\nclause one forces out, in a natural manner, those possible worlds which do not\nsatisfy the requirements of the clause. We develop a ceteris paribus logic for\ncounterfactual reasoning capable of performing such actions, and offer several\nalternative (relaxed) interpretations of ceteris paribus. We apply this\nframework in a way which allows us to reason counterfactually without having\nour similarity order skewed by unlikely events. This continues the\ninvestigation of formal ceteris paribus reasoning, which has previously been\napplied to preferences, logics of game forms, and questions in decision-making,\namong other areas.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:05 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Girard", "Patrick", ""], ["Triplett", "Marcus Anthony", ""]]}, {"id": "1606.07523", "submitter": "EPTCS", "authors": "Omer Lev (Hebrew University and Microsoft Research, Israel), Moshe\n  Tennenholtz (Technion), Aviv Zohar (Hebrew University and Microsoft Research,\n  Israel)", "title": "An Axiomatic Approach to Routing", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 194-206", "doi": "10.4204/EPTCS.215.14", "report-no": null, "categories": "cs.GT cs.AI cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information delivery in a network of agents is a key issue for large, complex\nsystems that need to do so in a predictable, efficient manner. The delivery of\ninformation in such multi-agent systems is typically implemented through\nrouting protocols that determine how information flows through the network.\nDifferent routing protocols exist each with its own benefits, but it is\ngenerally unclear which properties can be successfully combined within a given\nalgorithm. We approach this problem from the axiomatic point of view, i.e., we\ntry to establish what are the properties we would seek to see in such a system,\nand examine the different properties which uniquely define common routing\nalgorithms used today.\n  We examine several desirable properties, such as robustness, which ensures\nadding nodes and edges does not change the routing in a radical, unpredictable\nways; and properties that depend on the operating environment, such as an\n\"economic model\", where nodes choose their paths based on the cost they are\ncharged to pass information to the next node. We proceed to fully characterize\nminimal spanning tree, shortest path, and weakest link routing algorithms,\nshowing a tight set of axioms for each.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:22 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Lev", "Omer", "", "Hebrew University and Microsoft Research, Israel"], ["Tennenholtz", "Moshe", "", "Technion"], ["Zohar", "Aviv", "", "Hebrew University and Microsoft Research,\n  Israel"]]}, {"id": "1606.07524", "submitter": "EPTCS", "authors": "Chanjuan Liu", "title": "Preference at First Sight", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 207-226", "doi": "10.4204/EPTCS.215.15", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decision-making and game scenarios in which an agent is limited\nby his/her computational ability to foresee all the available moves towards the\nfuture - that is, we study scenarios with short sight. We focus on how short\nsight affects the logical properties of decision making in multi-agent\nsettings. We start with single-agent sequential decision making (SSDM)\nprocesses, modeling them by a new structure of \"preference-sight trees\". Using\nthis model, we first explore the relation between a new natural solution\nconcept of Sight-Compatible Backward Induction (SCBI) and the histories\nproduced by classical Backward Induction (BI). In particular, we find necessary\nand sufficient conditions for the two analyses to be equivalent. Next, we study\nwhether larger sight always contributes to better outcomes. Then we develop a\nsimple logical special-purpose language to formally express some key properties\nof our preference-sight models. Lastly, we show how short-sight SSDM scenarios\ncall for substantial enrichments of existing fixed-point logics that have been\ndeveloped for the classical BI solution concept. We also discuss changes in\nearlier modal logics expressing \"surface reasoning\" about best actions in the\npresence of short sight. Our analysis may point the way to logical and\ncomputational analysis of more realistic game models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:31 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Liu", "Chanjuan", ""]]}, {"id": "1606.07525", "submitter": "EPTCS", "authors": "Yoram Moses", "title": "Relating Knowledge and Coordinated Action: The Knowledge of\n  Preconditions Principle", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 231-245", "doi": "10.4204/EPTCS.215.17", "report-no": null, "categories": "cs.MA cs.AI cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Knowledge of Preconditions principle (KoP) is proposed as a widely\napplicable connection between knowledge and action in multi-agent systems.\nRoughly speaking, it asserts that if some condition is a necessary condition\nfor performing a given action A, then knowing that this condition holds is also\na necessary condition for performing A. Since the specifications of tasks often\ninvolve necessary conditions for actions, the KoP principle shows that such\nspecifications induce knowledge preconditions for the actions. Distributed\nprotocols or multi-agent plans that satisfy the specifications must ensure that\nthis knowledge be attained, and that it is detected by the agents as a\ncondition for action. The knowledge of preconditions principle is formalised in\nthe runs and systems framework, and is proven to hold in a wide class of\nsettings. Well-known connections between knowledge and coordinated action are\nextended and shown to derive directly from the KoP principle: a \"common\nknowledge of preconditions\" principle is established showing that common\nknowledge is a necessary condition for performing simultaneous actions, and a\n\"nested knowledge of preconditions\" principle is proven, showing that\ncoordinating actions to be performed in linear temporal order requires a\ncorresponding form of nested knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:41 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Moses", "Yoram", ""]]}, {"id": "1606.07526", "submitter": "EPTCS", "authors": "Iris van de Pol (University of Amsterdam, ILLC), Iris van Rooij\n  (Radboud University Nijmegen, Donders Institute for Brain, Cognition and\n  Behaviour), Jakub Szymanik (University of Amsterdam, ILLC)", "title": "Parameterized Complexity Results for a Model of Theory of Mind Based on\n  Dynamic Epistemic Logic", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 246-263", "doi": "10.4204/EPTCS.215.18", "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a computational-level model of theory of mind\n(ToM) based on dynamic epistemic logic (DEL), and we analyze its computational\ncomplexity. The model is a special case of DEL model checking. We provide a\nparameterized complexity analysis, considering several aspects of DEL (e.g.,\nnumber of agents, size of preconditions, etc.) as parameters. We show that\nmodel checking for DEL is PSPACE-hard, also when restricted to single-pointed\nmodels and S5 relations, thereby solving an open problem in the literature. Our\napproach is aimed at formalizing current intractability claims in the cognitive\nscience literature regarding computational models of ToM.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:32:51 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["van de Pol", "Iris", "", "University of Amsterdam, ILLC"], ["van Rooij", "Iris", "", "Radboud University Nijmegen, Donders Institute for Brain, Cognition and\n  Behaviour"], ["Szymanik", "Jakub", "", "University of Amsterdam, ILLC"]]}, {"id": "1606.07528", "submitter": "EPTCS", "authors": "Quan Yu (Sun Yat-sen University, Qiannan Normal College for\n  Nationalities), Yanjun Li (Peking University, University of Groningen),\n  Yanjing Wang (Peking University)", "title": "A Dynamic Epistemic Framework for Conformant Planning", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 298-318", "doi": "10.4204/EPTCS.215.21", "report-no": null, "categories": "cs.AI cs.CC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a lightweight dynamic epistemic logical framework\nfor automated planning under initial uncertainty. We reduce plan verification\nand conformant planning to model checking problems of our logic. We show that\nthe model checking problem of the iteration-free fragment is PSPACE-complete.\nBy using two non-standard (but equivalent) semantics, we give novel model\nchecking algorithms to the full language and the iteration-free language.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:33:19 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Yu", "Quan", "", "Sun Yat-sen University, Qiannan Normal College for\n  Nationalities"], ["Li", "Yanjun", "", "Peking University, University of Groningen"], ["Wang", "Yanjing", "", "Peking University"]]}, {"id": "1606.07529", "submitter": "EPTCS", "authors": "Michael Mandler (Royal Holloway College, University of London)", "title": "The optimality of coarse categories in decision-making and information\n  storage", "comments": "In Proceedings TARK 2015, arXiv:1606.07295", "journal-ref": "EPTCS 215, 2016, pp. 227-230", "doi": "10.4204/EPTCS.215.16", "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent who lacks preferences and instead makes decisions using criteria\nthat are costly to create should select efficient sets of criteria, where the\ncost of making a given number of choice distinctions is minimized. Under mild\nconditions, efficiency requires that binary criteria with only two categories\nper criterion are chosen. When applied to the problem of determining the\noptimal number of digits in an information storage device, this result implies\nthat binary digits (bits) are the efficient solution, even when the marginal\ncost of using additional digits declines rapidly to 0. This short paper pays\nparticular attention to the symmetry conditions entailed when sets of criteria\nare efficient.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 00:39:09 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Mandler", "Michael", "", "Royal Holloway College, University of London"]]}, {"id": "1606.07533", "submitter": "EPTCS", "authors": "Valerio Capraro (CWI), Joseph Y. Halpern (Cornell University)", "title": "Translucent Players: Explaining Cooperative Behavior in Social Dilemmas", "comments": "In Proceedings TARK 2015, arXiv:1606.07295. The full version of the\n  paper is also on arxiv at arXiv:1410.3363", "journal-ref": "EPTCS 215, 2016, pp. 114-126", "doi": "10.4204/EPTCS.215.9", "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few decades, numerous experiments have shown that humans do not\nalways behave so as to maximize their material payoff. Cooperative behavior\nwhen non-cooperation is a dominant strategy (with respect to the material\npayoffs) is particularly puzzling. Here we propose a novel approach to explain\ncooperation, assuming what Halpern and Pass call translucent players.\nTypically, players are assumed to be opaque, in the sense that a deviation by\none player in a normal-form game does not affect the strategies used by other\nplayers. But a player may believe that if he switches from one strategy to\nanother, the fact that he chooses to switch may be visible to the other\nplayers. For example, if he chooses to defect in Prisoner's Dilemma, the other\nplayer may sense his guilt. We show that by assuming translucent players, we\ncan recover many of the regularities observed in human behavior in well-studied\ngames such as Prisoner's Dilemma, Traveler's Dilemma, Bertrand Competition, and\nthe Public Goods game.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 01:02:30 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Capraro", "Valerio", "", "CWI"], ["Halpern", "Joseph Y.", "", "Cornell University"]]}, {"id": "1606.07572", "submitter": "S Subhashree", "authors": "Subhashree S and P Sreenivasa Kumar", "title": "Enriching Linked Datasets with New Object Properties", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although several RDF knowledge bases are available through the LOD\ninitiative, the ontology schema of such linked datasets is not very rich. In\nparticular, they lack object properties. The problem of finding new object\nproperties (and their instances) between any two given classes has not been\ninvestigated in detail in the context of Linked Data. In this paper, we present\nDART (Detecting Arbitrary Relations for enriching T-Boxes of Linked Data) - an\nunsupervised solution to enrich the LOD cloud with new object properties\nbetween two given classes. DART exploits contextual similarity to identify text\npatterns from the web corpus that can potentially represent relations between\nindividuals. These text patterns are then clustered by means of paraphrase\ndetection to capture the object properties between the two given LOD classes.\nDART also performs fully automated mapping of the discovered relations to the\nproperties in the linked dataset. This serves many purposes such as\nidentification of completely new relations, elimination of irrelevant\nrelations, and generation of prospective property axioms. We have empirically\nevaluated our approach on several pairs of classes and found that the system\ncan indeed be used for enriching the linked datasets with new object properties\nand their instances. We compared DART with newOntExt system which is an\noffshoot of the NELL (Never-Ending Language Learning) effort. Our experiments\nreveal that DART gives better results than newOntExt with respect to both the\ncorrectness, as well as the number of relations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 06:00:42 GMT"}, {"version": "v2", "created": "Fri, 24 Mar 2017 04:49:49 GMT"}, {"version": "v3", "created": "Mon, 4 Sep 2017 11:12:42 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["S", "Subhashree", ""], ["Kumar", "P Sreenivasa", ""]]}, {"id": "1606.07695", "submitter": "Yong Xu", "authors": "Yong Xu, Qiang Huang, Wenwu Wang, Philip J. B. Jackson, Mark D.\n  Plumbley", "title": "Fully DNN-based Multi-label regression for audio tagging", "comments": "Submitted to DCASE2016 Workshop which is as a satellite event to the\n  2016 European Signal Processing Conference (EUSIPCO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic event detection for content analysis in most cases relies on lots of\nlabeled data. However, manually annotating data is a time-consuming task, which\nthus makes few annotated resources available so far. Unlike audio event\ndetection, automatic audio tagging, a multi-label acoustic event classification\ntask, only relies on weakly labeled data. This is highly desirable to some\npractical applications using audio analysis. In this paper we propose to use a\nfully deep neural network (DNN) framework to handle the multi-label\nclassification task in a regression way. Considering that only chunk-level\nrather than frame-level labels are available, the whole or almost whole frames\nof the chunk were fed into the DNN to perform a multi-label regression for the\nexpected tags. The fully DNN, which is regarded as an encoding function, can\nwell map the audio features sequence to a multi-tag vector. A deep pyramid\nstructure was also designed to extract more robust high-level features related\nto the target tags. Further improved methods were adopted, such as the Dropout\nand background noise aware training, to enhance its generalization capability\nfor new audio recordings in mismatched environments. Compared with the\nconventional Gaussian Mixture Model (GMM) and support vector machine (SVM)\nmethods, the proposed fully DNN-based method could well utilize the long-term\ntemporal information with the whole chunk as the input. The results show that\nour approach obtained a 15% relative improvement compared with the official\nGMM-based method of DCASE 2016 challenge.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 14:17:34 GMT"}, {"version": "v2", "created": "Sat, 13 Aug 2016 10:39:29 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Xu", "Yong", ""], ["Huang", "Qiang", ""], ["Wang", "Wenwu", ""], ["Jackson", "Philip J. B.", ""], ["Plumbley", "Mark D.", ""]]}, {"id": "1606.07711", "submitter": "Rocco Tripodi", "authors": "Rocco Tripodi and Marcello Pelillo", "title": "A Game-Theoretic Approach to Word Sense Disambiguation", "comments": "To be published in Computational Linguistics", "journal-ref": null, "doi": "10.1162/COLI_a_00274", "report-no": null, "categories": "cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new model for word sense disambiguation formulated in\nterms of evolutionary game theory, where each word to be disambiguated is\nrepresented as a node on a graph whose edges represent word relations and\nsenses are represented as classes. The words simultaneously update their class\nmembership preferences according to the senses that neighboring words are\nlikely to choose. We use distributional information to weigh the influence that\neach word has on the decisions of the others and semantic similarity\ninformation to measure the strength of compatibility among the choices. With\nthis information we can formulate the word sense disambiguation problem as a\nconstraint satisfaction problem and solve it using tools derived from game\ntheory, maintaining the textual coherence. The model is based on two ideas:\nsimilar words should be assigned to similar classes and the meaning of a word\ndoes not depend on all the words in a text but just on some of them. The paper\nprovides an in-depth motivation of the idea of modeling the word sense\ndisambiguation problem in terms of game theory, which is illustrated by an\nexample. The conclusion presents an extensive analysis on the combination of\nsimilarity measures to use in the framework and a comparison with\nstate-of-the-art systems. The results show that our model outperforms\nstate-of-the-art algorithms and can be applied to different tasks and in\ndifferent scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 14:45:27 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 05:31:31 GMT"}, {"version": "v3", "created": "Fri, 1 Jul 2016 12:19:13 GMT"}, {"version": "v4", "created": "Mon, 4 Jul 2016 13:19:29 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Tripodi", "Rocco", ""], ["Pelillo", "Marcello", ""]]}, {"id": "1606.07722", "submitter": "Kai-Chun Hsu", "authors": "Kai-Chun Hsu, Szu-Yu Chou, Yi-Hsuan Yang, Tai-Shih Chi", "title": "Neural Network Based Next-Song Recommendation", "comments": "5 pages, 3 figures, the 1st Workshop on Deep Learning for Recommender\n  Systems (DLRS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the next-item/basket recommendation system, which considers the\nsequential relation between bought items, has drawn attention of researchers.\nThe utilization of sequential patterns has boosted performance on several kinds\nof recommendation tasks. Inspired by natural language processing (NLP)\ntechniques, we propose a novel neural network (NN) based next-song recommender,\nCNN-rec, in this paper. Then, we compare the proposed system with several NN\nbased and classic recommendation systems on the next-song recommendation task.\nVerification results indicate the proposed system outperforms classic systems\nand has comparable performance with the state-of-the-art system.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 15:25:55 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Hsu", "Kai-Chun", ""], ["Chou", "Szu-Yu", ""], ["Yang", "Yi-Hsuan", ""], ["Chi", "Tai-Shih", ""]]}, {"id": "1606.07786", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Daniel Neil, Giacomo Indiveri, Shih-Chii Liu, Michael\n  Pfeiffer", "title": "Precise neural network computation with imprecise analog devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The operations used for neural network computation map favorably onto simple\nanalog circuits, which outshine their digital counterparts in terms of\ncompactness and efficiency. Nevertheless, such implementations have been\nlargely supplanted by digital designs, partly because of device mismatch\neffects due to material and fabrication imperfections. We propose a framework\nthat exploits the power of deep learning to compensate for this mismatch by\nincorporating the measured device variations as constraints in the neural\nnetwork training process. This eliminates the need for mismatch minimization\nstrategies and allows circuit complexity and power-consumption to be reduced to\na minimum. Our results, based on large-scale simulations as well as a prototype\nVLSI chip implementation indicate a processing efficiency comparable to current\nstate-of-art digital implementations. This method is suitable for future\ntechnology based on nanodevices with large variability, such as memristive\narrays.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 18:32:43 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 06:27:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Binas", "Jonathan", ""], ["Neil", "Daniel", ""], ["Indiveri", "Giacomo", ""], ["Liu", "Shih-Chii", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "1606.07841", "submitter": "Satya Gautam Vadlamudi", "authors": "Satya Gautam Vadlamudi, Tathagata Chakraborti, Yu Zhang, Subbarao\n  Kambhampati", "title": "Proactive Decision Support using Automated Planning", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proactive decision support (PDS) helps in improving the decision making\nexperience of human decision makers in human-in-the-loop planning environments.\nHere both the quality of the decisions and the ease of making them are\nenhanced. In this regard, we propose a PDS framework, named RADAR, based on the\nresearch in Automated Planning in AI, that aids the human decision maker with\nher plan to achieve her goals by providing alerts on: whether such a plan can\nsucceed at all, whether there exist any resource constraints that may foil her\nplan, etc. This is achieved by generating and analyzing the landmarks that must\nbe accomplished by any successful plan on the way to achieving the goals. Note\nthat, this approach also supports naturalistic decision making which is being\nacknowledged as a necessary element in proactive decision support, since it\nonly aids the human decision maker through suggestions and alerts rather than\nenforcing fixed plans or decisions. We demonstrate the utility of the proposed\nframework through search-and-rescue examples in a fire-fighting domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 21:54:28 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Vadlamudi", "Satya Gautam", ""], ["Chakraborti", "Tathagata", ""], ["Zhang", "Yu", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1606.07860", "submitter": "Carl Schultz", "authors": "Przemys{\\l}aw Andrzej Wa{\\l}\\k{e}ga, Carl Schultz, Mehul Bhatt", "title": "Non-Monotonic Spatial Reasoning with Answer Set Programming Modulo\n  Theories", "comments": "22 pages, 6 figures, Under consideration for publication in TPLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The systematic modelling of dynamic spatial systems is a key requirement in a\nwide range of application areas such as commonsense cognitive robotics,\ncomputer-aided architecture design, and dynamic geographic information systems.\nWe present ASPMT(QS), a novel approach and fully-implemented prototype for\nnon-monotonic spatial reasoning -a crucial requirement within dynamic spatial\nsystems- based on Answer Set Programming Modulo Theories (ASPMT).\n  ASPMT(QS) consists of a (qualitative) spatial representation module (QS) and\na method for turning tight ASPMT instances into Satisfiability Modulo Theories\n(SMT) instances in order to compute stable models by means of SMT solvers. We\nformalise and implement concepts of default spatial reasoning and spatial frame\naxioms. Spatial reasoning is performed by encoding spatial relations as systems\nof polynomial constraints, and solving via SMT with the theory of real\nnonlinear arithmetic. We empirically evaluate ASPMT(QS) in comparison with\nother contemporary spatial reasoning systems both within and outside the\ncontext of logic programming. ASPMT(QS) is currently the only existing system\nthat is capable of reasoning about indirect spatial effects (i.e., addressing\nthe ramification problem), and integrating geometric and qualitative spatial\ninformation within a non-monotonic spatial reasoning context.\n  This paper is under consideration for publication in TPLP.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 01:02:30 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 18:21:10 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Wa\u0142\u0119ga", "Przemys\u0142aw Andrzej", ""], ["Schultz", "Carl", ""], ["Bhatt", "Mehul", ""]]}, {"id": "1606.07908", "submitter": "Huy Phan", "authors": "Huy Phan, Lars Hertel, Marco Maass, Philipp Koch, Alfred Mertins", "title": "Label Tree Embeddings for Acoustic Scene Classification", "comments": "to appear in the Proceedings of ACM Multimedia 2016 (ACMMM 2016)", "journal-ref": null, "doi": "10.1145/2964284.2967268", "report-no": null, "categories": "cs.MM cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper an efficient approach for acoustic scene\nclassification by exploring the structure of class labels. Given a set of class\nlabels, a category taxonomy is automatically learned by collectively optimizing\na clustering of the labels into multiple meta-classes in a tree structure. An\nacoustic scene instance is then embedded into a low-dimensional feature\nrepresentation which consists of the likelihoods that it belongs to the\nmeta-classes. We demonstrate state-of-the-art results on two different datasets\nfor the acoustic scene classification task, including the DCASE 2013 and LITIS\nRouen datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 12:57:44 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 11:42:20 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Phan", "Huy", ""], ["Hertel", "Lars", ""], ["Maass", "Marco", ""], ["Koch", "Philipp", ""], ["Mertins", "Alfred", ""]]}, {"id": "1606.07955", "submitter": "Joseph Corneli", "authors": "Daniel Winterstein and Joseph Corneli", "title": "X575: writing rengas with web services", "comments": "4 pages; submitted to CC-NLG - Computational Creativity in Natural\n  Language Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our software system simulates the classical collaborative Japanese poetry\nform, renga, made of linked haikus. We used NLP methods wrapped up as web\nservices. Our experiments were only a partial success, since results fail to\nsatisfy classical constraints. To gather ideas for future work, we examine\nrelated research in semiotics, linguistics, and computing.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 20:04:42 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Winterstein", "Daniel", ""], ["Corneli", "Joseph", ""]]}, {"id": "1606.08104", "submitter": "Yifan Chen", "authors": "Yifan Chen, Xiang Zhao, Junjiao Gan, Junkai Ren, and Yang Fang", "title": "Content-Based Top-N Recommendation using Heterogeneous Relations", "comments": "13 pages, 8 figures, ADC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-$N$ recommender systems have been extensively studied. However, the\nsparsity of user-item activities has not been well resolved. While many hybrid\nsystems were proposed to address the cold-start problem, the profile\ninformation has not been sufficiently leveraged. Furthermore, the heterogeneity\nof profiles between users and items intensifies the challenge. In this paper,\nwe propose a content-based top-$N$ recommender system by learning the global\nterm weights in profiles. To achieve this, we bring in PathSim, which could\nwell measures the node similarity with heterogeneous relations (between users\nand items). Starting from the original TF-IDF value, the global term weights\ngradually converge, and eventually reflect both profile and activity\ninformation. To facilitate training, the derivative is reformulated into matrix\nform, which could easily be paralleled. We conduct extensive experiments, which\ndemonstrate the superiority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 00:58:16 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Chen", "Yifan", ""], ["Zhao", "Xiang", ""], ["Gan", "Junjiao", ""], ["Ren", "Junkai", ""], ["Fang", "Yang", ""]]}, {"id": "1606.08109", "submitter": "Alex Ushveridze", "authors": "Alex Ushveridze", "title": "Can Turing machine be curious about its Turing test results? Three\n  informal lectures on physics of intelligence", "comments": "79 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the nature of curiosity? Is there any scientific way to understand\nthe origin of this mysterious force that drives the behavior of even the\nstupidest naturally intelligent systems and is completely absent in their\nsmartest artificial analogs? Can we build AI systems that could be curious\nabout something, systems that would have an intrinsic motivation to learn? Is\nsuch a motivation quantifiable? Is it implementable? I will discuss this\nproblem from the standpoint of physics. The relationship between physics and\nintelligence is a consequence of the fact that correctly predicted information\nis nothing but an energy resource, and the process of thinking can be viewed as\na process of accumulating and spending this resource through the acts of\nperception and, respectively, decision making. The natural motivation of any\nautonomous system to keep this accumulation/spending balance as high as\npossible allows one to treat the problem of describing the dynamics of thinking\nprocesses as a resource optimization problem. Here I will propose and discuss a\nsimple theoretical model of such an autonomous system which I call the\nAutonomous Turing Machine (ATM). The potential attractiveness of ATM lies in\nthe fact that it is the model of a self-propelled AI for which the only\navailable energy resource is the information itself. For ATM, the problem of\noptimal thinking, learning, and decision-making becomes conceptually simple and\nmathematically well tractable. This circumstance makes the ATM an ideal\nplayground for studying the dynamics of intelligent behavior and allows one to\nquantify many seemingly unquantifiable features of genuine intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 01:53:02 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Ushveridze", "Alex", ""]]}, {"id": "1606.08130", "submitter": "Bart Bogaerts", "authors": "Bart Bogaerts, Eugenia Ternovska, David Mitchell", "title": "Propagators and Solvers for the Algebra of Modular Systems", "comments": "To appear in the proceedings of LPAR 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear in the proceedings of LPAR 21.\n  Solving complex problems can involve non-trivial combinations of distinct\nknowledge bases and problem solvers. The Algebra of Modular Systems is a\nknowledge representation framework that provides a method for formally\nspecifying such systems in purely semantic terms. Formally, an expression of\nthe algebra defines a class of structures. Many expressive formalism used in\npractice solve the model expansion task, where a structure is given on the\ninput and an expansion of this structure in the defined class of structures is\nsearched (this practice overcomes the common undecidability problem for\nexpressive logics). In this paper, we construct a solver for the model\nexpansion task for a complex modular systems from an expression in the algebra\nand black-box propagators or solvers for the primitive modules. To this end, we\ndefine a general notion of propagators equipped with an explanation mechanism,\nan extension of the alge- bra to propagators, and a lazy conflict-driven\nlearning algorithm. The result is a framework for seamlessly combining solving\ntechnology from different domains to produce a solver for a combined system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 05:53:57 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 07:50:50 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Bogaerts", "Bart", ""], ["Ternovska", "Eugenia", ""], ["Mitchell", "David", ""]]}, {"id": "1606.08140", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Kairit Sirts, Lizhen Qu and Mark Johnson", "title": "STransE: a novel embedding model of entities and relationships in\n  knowledge bases", "comments": "V1: In Proceedings of the 2016 Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies, NAACL HLT 2016. V2: Corrected citation to (Krompa{\\ss} et al.,\n  2015). V3: A revised version of our NAACL-HLT 2016 paper with additional\n  experimental results and latest related work", "journal-ref": null, "doi": "10.18653/v1/N16-1054", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases of real-world facts about entities and their relationships\nare useful resources for a variety of natural language processing tasks.\nHowever, because knowledge bases are typically incomplete, it is useful to be\nable to perform link prediction or knowledge base completion, i.e., predict\nwhether a relationship not in the knowledge base is likely to be true. This\npaper combines insights from several previous link prediction models into a new\nembedding model STransE that represents each entity as a low-dimensional\nvector, and each relation by two matrices and a translation vector. STransE is\na simple combination of the SE and TransE models, but it obtains better link\nprediction performance on two benchmark datasets than previous embedding\nmodels. Thus, STransE can serve as a new baseline for the more complex models\nin the link prediction task.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 06:50:10 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 16:24:49 GMT"}, {"version": "v3", "created": "Wed, 8 Mar 2017 16:57:40 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Sirts", "Kairit", ""], ["Qu", "Lizhen", ""], ["Johnson", "Mark", ""]]}, {"id": "1606.08333", "submitter": "Hans van Ditmarsch", "authors": "Thomas {\\AA}gotnes, Hans van Ditmarsch, Yanjing Wang", "title": "True Lies", "comments": null, "journal-ref": null, "doi": "10.1007/s11229-017-1423-y", "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A true lie is a lie that becomes true when announced. In a logic of\nannouncements, where the announcing agent is not modelled, a true lie is a\nformula (that is false and) that becomes true when announced. We investigate\ntrue lies and other types of interaction between announced formulas, their\npreconditions and their postconditions, in the setting of Gerbrandy's logic of\nbelieved announcements, wherein agents may have or obtain incorrect beliefs.\nOur results are on the satisfiability and validity of instantiations of these\nsemantically defined categories, on iterated announcements, including\narbitrarily often iterated announcements, and on syntactic characterization. We\nclose with results for iterated announcements in the logic of knowledge\n(instead of belief), and for lying as private announcements (instead of public\nannouncements) to different agents. Detailed examples illustrate our lying\nconcepts.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 15:59:32 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 16:08:35 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["\u00c5gotnes", "Thomas", ""], ["van Ditmarsch", "Hans", ""], ["Wang", "Yanjing", ""]]}, {"id": "1606.08359", "submitter": "Thomas Demeester", "authors": "Thomas Demeester and Tim Rockt\\\"aschel and Sebastian Riedel", "title": "Lifted Rule Injection for Relation Embeddings", "comments": "Camera-ready version for EMNLP 2016 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods based on representation learning currently hold the state-of-the-art\nin many natural language processing and knowledge base inference tasks. Yet, a\nmajor challenge is how to efficiently incorporate commonsense knowledge into\nsuch models. A recent approach regularizes relation and entity representations\nby propositionalization of first-order logic rules. However,\npropositionalization does not scale beyond domains with only few entities and\nrules. In this paper we present a highly efficient method for incorporating\nimplication rules into distributed representations for automated knowledge base\nconstruction. We map entity-tuple embeddings into an approximately Boolean\nspace and encourage a partial ordering over relation embeddings based on\nimplication rules mined from WordNet. Surprisingly, we find that the strong\nrestriction of the entity-tuple embedding space does not hurt the\nexpressiveness of the model and even acts as a regularizer that improves\ngeneralization. By incorporating few commonsense rules, we achieve an increase\nof 2 percentage points mean average precision over a matrix factorization\nbaseline, while observing a negligible increase in runtime.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 16:39:23 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 20:40:25 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Demeester", "Thomas", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1606.08362", "submitter": "Huy Nguyen", "authors": "Alina Ene, Huy L. Nguyen", "title": "A Reduction for Optimizing Lattice Submodular Functions with Diminishing\n  Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $f: \\mathbb{Z}_+^E \\rightarrow \\mathbb{R}_+$ is DR-submodular if\nit satisfies $f({\\bf x} + \\chi_i) -f ({\\bf x}) \\ge f({\\bf y} + \\chi_i) - f({\\bf\ny})$ for all ${\\bf x}\\le {\\bf y}, i\\in E$. Recently, the problem of maximizing\na DR-submodular function $f: \\mathbb{Z}_+^E \\rightarrow \\mathbb{R}_+$ subject\nto a budget constraint $\\|{\\bf x}\\|_1 \\leq B$ as well as additional constraints\nhas received significant attention \\cite{SKIK14,SY15,MYK15,SY16}.\n  In this note, we give a generic reduction from the DR-submodular setting to\nthe submodular setting. The running time of the reduction and the size of the\nresulting submodular instance depends only \\emph{logarithmically} on $B$. Using\nthis reduction, one can translate the results for unconstrained and constrained\nsubmodular maximization to the DR-submodular setting for many types of\nconstraints in a unified manner.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 16:44:44 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 19:49:59 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Ene", "Alina", ""], ["Nguyen", "Huy L.", ""]]}, {"id": "1606.08514", "submitter": "Sanjit Seshia", "authors": "Sanjit A. Seshia, Dorsa Sadigh, and S. Shankar Sastry", "title": "Towards Verified Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verified artificial intelligence (AI) is the goal of designing AI-based\nsystems that that have strong, ideally provable, assurances of correctness with\nrespect to mathematically-specified requirements. This paper considers Verified\nAI from a formal methods perspective. We describe five challenges for achieving\nVerified AI, and five corresponding principles for addressing these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 23:51:04 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2016 06:27:03 GMT"}, {"version": "v3", "created": "Sat, 21 Oct 2017 09:50:36 GMT"}, {"version": "v4", "created": "Thu, 23 Jul 2020 17:33:59 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Seshia", "Sanjit A.", ""], ["Sadigh", "Dorsa", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1606.08531", "submitter": "Bahare Fatemi", "authors": "Bahare Fatemi, Seyed Mehran Kazemi, David Poole", "title": "A Learning Algorithm for Relational Logistic Regression: Preliminary\n  Results", "comments": "In IJCAI-16 Statistical Relational AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Relational logistic regression (RLR) is a representation of conditional\nprobability in terms of weighted formulae for modelling multi-relational data.\nIn this paper, we develop a learning algorithm for RLR models. Learning an RLR\nmodel from data consists of two steps: 1- learning the set of formulae to be\nused in the model (a.k.a. structure learning) and learning the weight of each\nformula (a.k.a. parameter learning). For structure learning, we deploy Schmidt\nand Murphy's hierarchical assumption: first we learn a model with simple\nformulae, then more complex formulae are added iteratively only if all their\nsub-formulae have proven effective in previous learned models. For parameter\nlearning, we convert the problem into a non-relational learning problem and use\nan off-the-shelf logistic regression learning algorithm from Weka, an\nopen-source machine learning tool, to learn the weights. We also indicate how\nhidden features about the individuals can be incorporated into RLR to boost the\nlearning performance. We compare our learning algorithm to other structure and\nparameter learning algorithms in the literature, and compare the performance of\nRLR models to standard logistic regression and RDN-Boost on a modified version\nof the MovieLens data-set.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 01:43:38 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Fatemi", "Bahare", ""], ["Kazemi", "Seyed Mehran", ""], ["Poole", "David", ""]]}, {"id": "1606.08538", "submitter": "Bo Tang", "authors": "Bo Tang and Haibo He", "title": "A Local Density-Based Approach for Local Outlier Detection", "comments": "22 pages, 14 figures, submitted to Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple but effective density-based outlier detection\napproach with the local kernel density estimation (KDE). A Relative\nDensity-based Outlier Score (RDOS) is introduced to measure the local\noutlierness of objects, in which the density distribution at the location of an\nobject is estimated with a local KDE method based on extended nearest neighbors\nof the object. Instead of using only $k$ nearest neighbors, we further consider\nreverse nearest neighbors and shared nearest neighbors of an object for density\ndistribution estimation. Some theoretical properties of the proposed RDOS\nincluding its expected value and false alarm probability are derived. A\ncomprehensive experimental study on both synthetic and real-life data sets\ndemonstrates that our approach is more effective than state-of-the-art outlier\ndetection methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 02:23:58 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Tang", "Bo", ""], ["He", "Haibo", ""]]}, {"id": "1606.08777", "submitter": "Gemma Boleda", "authors": "Gemma Boleda and Sebastian Pad\\'o and Marco Baroni", "title": "\"Show me the cup\": Reference with Continuous Representations", "comments": null, "journal-ref": "In: Gelbukh A. (eds) Computational Linguistics and Intelligent\n  Text Processing. CICLing 2017. Lecture Notes in Computer Science, vol 10761.\n  Springer, Cham", "doi": "10.1007/978-3-319-77113-7_17", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most basic functions of language is to refer to objects in a\nshared scene. Modeling reference with continuous representations is challenging\nbecause it requires individuation, i.e., tracking and distinguishing an\narbitrary number of referents. We introduce a neural network model that, given\na definite description and a set of objects represented by natural images,\npoints to the intended object if the expression has a unique referent, or\nindicates a failure, if it does not. The model, directly trained on reference\nacts, is competitive with a pipeline manually engineered to perform the same\ntask, both when referents are purely visual, and when they are characterized by\na combination of visual and linguistic properties.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 16:31:50 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Boleda", "Gemma", ""], ["Pad\u00f3", "Sebastian", ""], ["Baroni", "Marco", ""]]}, {"id": "1606.08808", "submitter": "Miao Cheng", "authors": "Miao Cheng, Ah Chung Tsoi", "title": "Adaptive Training of Random Mapping for Data Quantization", "comments": "6 pages, 5 figures, 15.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data quantization learns encoding results of data with certain requirements,\nand provides a broad perspective of many real-world applications to data\nhandling. Nevertheless, the results of encoder is usually limited to\nmultivariate inputs with the random mapping, and side information of binary\ncodes are hardly to mostly depict the original data patterns as possible. In\nthe literature, cosine based random quantization has attracted much attentions\ndue to its intrinsic bounded results. Nevertheless, it usually suffers from the\nuncertain outputs, and information of original data fails to be fully preserved\nin the reduced codes. In this work, a novel binary embedding method, termed\nadaptive training quantization (ATQ), is proposed to learn the ideal transform\nof random encoder, where the limitation of cosine random mapping is tackled. As\nan adaptive learning idea, the reduced mapping is adaptively calculated with\nidea of data group, while the bias of random transform is to be improved to\nhold most matching information. Experimental results show that the proposed\nmethod is able to obtain outstanding performance compared with other random\nquantization methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 18:15:32 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 15:24:26 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Cheng", "Miao", ""], ["Tsoi", "Ah Chung", ""]]}, {"id": "1606.08842", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Nihar B. Shah and Kannan Ramchandran and Martin J.\n  Wainwright", "title": "Active Ranking from Pairwise Comparisons and when Parametric Assumptions\n  Don't Help", "comments": "improved log factor in main result; added discussion on comparison\n  probabilities close to zero; added numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider sequential or active ranking of a set of n items based on noisy\npairwise comparisons. Items are ranked according to the probability that a\ngiven item beats a randomly chosen item, and ranking refers to partitioning the\nitems into sets of pre-specified sizes according to their scores. This notion\nof ranking includes as special cases the identification of the top-k items and\nthe total ordering of the items. We first analyze a sequential ranking\nalgorithm that counts the number of comparisons won, and uses these counts to\ndecide whether to stop, or to compare another pair of items, chosen based on\nconfidence intervals specified by the data collected up to that point. We prove\nthat this algorithm succeeds in recovering the ranking using a number of\ncomparisons that is optimal up to logarithmic factors. This guarantee does not\nrequire any structural properties of the underlying pairwise probability\nmatrix, unlike a significant body of past work on pairwise ranking based on\nparametric models such as the Thurstone or Bradley-Terry-Luce models. It has\nbeen a long-standing open question as to whether or not imposing these\nparametric assumptions allows for improved ranking algorithms. For stochastic\ncomparison models, in which the pairwise probabilities are bounded away from\nzero, our second contribution is to resolve this issue by proving a lower bound\nfor parametric models. This shows, perhaps surprisingly, that these popular\nparametric modeling choices offer at most logarithmic gains for stochastic\ncomparisons.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 19:59:52 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 15:55:44 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Heckel", "Reinhard", ""], ["Shah", "Nihar B.", ""], ["Ramchandran", "Kannan", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1606.08866", "submitter": "Terence Parr", "authors": "Terence Parr and Jurgin Vinju", "title": "Technical Report: Towards a Universal Code Formatter through Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many declarative frameworks that allow us to implement code\nformatters relatively easily for any specific language, but constructing them\nis cumbersome. The first problem is that \"everybody\" wants to format their code\ndifferently, leading to either many formatter variants or a ridiculous number\nof configuration options. Second, the size of each implementation scales with a\nlanguage's grammar size, leading to hundreds of rules.\n  In this paper, we solve the formatter construction problem using a novel\napproach, one that automatically derives formatters for any given language\nwithout intervention from a language expert. We introduce a code formatter\ncalled CodeBuff that uses machine learning to abstract formatting rules from a\nrepresentative corpus, using a carefully designed feature set. Our experiments\non Java, SQL, and ANTLR grammars show that CodeBuff is efficient, has excellent\naccuracy, and is grammar invariant for a given language. It also generalizes to\na 4th language tested during manuscript preparation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 20:04:07 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Parr", "Terence", ""], ["Vinju", "Jurgin", ""]]}, {"id": "1606.08896", "submitter": "Joohyung Lee", "authors": "Joohyung Lee and Yi Wang", "title": "On the Semantic Relationship between Probabilistic Soft Logic and Markov\n  Logic", "comments": "In Working Notes of the 6th International Workshop on Statistical\n  Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Logic Networks (MLN) and Probabilistic Soft Logic (PSL) are widely\napplied formalisms in Statistical Relational Learning, an emerging area in\nArtificial Intelligence that is concerned with combining logical and\nstatistical AI. Despite their resemblance, the relationship has not been\nformally stated. In this paper, we describe the precise semantic relationship\nbetween them from a logical perspective. This is facilitated by first extending\nfuzzy logic to allow weights, which can be also viewed as a generalization of\nPSL, and then relate that generalization to MLN. We observe that the\nrelationship between PSL and MLN is analogous to the known relationship between\nfuzzy logic and Boolean logic, and furthermore the weight scheme of PSL is\nessentially a generalization of the weight scheme of MLN for the many-valued\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 21:43:19 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Lee", "Joohyung", ""], ["Wang", "Yi", ""]]}, {"id": "1606.08906", "submitter": "Aleksander Lodwich", "authors": "Aleksander Lodwich", "title": "Exploring high-level Perspectives on Self-Configuration Capabilities of\n  Systems", "comments": "46 pages, 62 figures", "journal-ref": null, "doi": "10.13140/RG.2.1.2945.6885", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of product performance repetitively introduces the need to make\nproducts adaptive in a more general sense. This more general idea is often\ncaptured under the term 'self-configuration'. Despite the importance of such\ncapability, research work on this feature appears isolated by technical\ndomains. It is not easy to tell quickly whether the approaches chosen in\ndifferent technological domains introduce new ideas or whether the differences\njust reflect domain idiosyncrasies. For the sake of easy identification of key\ndifferences between systems with self-configuring capabilities, I will explore\nhigher level concepts for understanding self-configuration, such as the\n{\\Omega}-units, in order to provide theoretical instruments for connecting\ndifferent areas of technology and research.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 22:36:38 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Lodwich", "Aleksander", ""]]}, {"id": "1606.08928", "submitter": "Annamalai Narayanan", "authors": "Annamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu and\n  Santhoshkumar Saminathan", "title": "subgraph2vec: Learning Distributed Representations of Rooted Sub-graphs\n  from Large Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present subgraph2vec, a novel approach for learning latent\nrepresentations of rooted subgraphs from large graphs inspired by recent\nadvancements in Deep Learning and Graph Kernels. These latent representations\nencode semantic substructure dependencies in a continuous vector space, which\nis easily exploited by statistical models for tasks such as graph\nclassification, clustering, link prediction and community detection.\nsubgraph2vec leverages on local information obtained from neighbourhoods of\nnodes to learn their latent representations in an unsupervised fashion. We\ndemonstrate that subgraph vectors learnt by our approach could be used in\nconjunction with classifiers such as CNNs, SVMs and relational data clustering\nalgorithms to achieve significantly superior accuracies. Also, we show that the\nsubgraph vectors could be used for building a deep learning variant of\nWeisfeiler-Lehman graph kernel. Our experiments on several benchmark and\nlarge-scale real-world datasets reveal that subgraph2vec achieves significant\nimprovements in accuracies over existing graph kernels on both supervised and\nunsupervised learning tasks. Specifically, on two realworld program analysis\ntasks, namely, code clone and malware detection, subgraph2vec outperforms\nstate-of-the-art kernels by more than 17% and 4%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 01:05:36 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Narayanan", "Annamalai", ""], ["Chandramohan", "Mahinthan", ""], ["Chen", "Lihui", ""], ["Liu", "Yang", ""], ["Saminathan", "Santhoshkumar", ""]]}, {"id": "1606.08954", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta and Miguel Ballesteros and Chris Dyer and Noah A.\n  Smith", "title": "Greedy, Joint Syntactic-Semantic Parsing with Stack LSTMs", "comments": "Proceedings of CoNLL 2016; 13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a transition-based parser that jointly produces syntactic and\nsemantic dependencies. It learns a representation of the entire algorithm\nstate, using stack long short-term memories. Our greedy inference algorithm has\nlinear time, including feature extraction. On the CoNLL 2008--9 English shared\ntasks, we obtain the best published parsing performance among models that\njointly learn syntax and semantics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 05:01:56 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 00:43:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Ballesteros", "Miguel", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1606.08962", "submitter": "Jagannath Roy", "authors": "Jagannath Roy, Kajal Chatterjee, Abhirup Bandhopadhyay, Samarjit Kar", "title": "Evaluation and selection of Medical Tourism sites: A rough AHP based\n  MABAC approach", "comments": "25 pages", "journal-ref": null, "doi": "10.1111/exsy.12232", "report-no": "14450977", "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel multiple criteria decision making (MCDM) methodology\nis presented for assessing and prioritizing medical tourism destinations in\nuncertain environment. A systematic evaluation and assessment method is\nproposed by integrating rough number based AHP (Analytic Hierarchy Process) and\nrough number based MABAC (Multi-Attributive Border Approximation area\nComparison). Rough number is used to aggregate individual judgments and\npreferences to deal with vagueness in decision making due to limited data.\nRough AHP analyzes the relative importance of criteria based on their\npreferences given by experts. Rough MABAC evaluates the alternative sites based\non the criteria weights. The proposed methodology is explained through a case\nstudy considering different cities for healthcare service in India. The\nvalidity of the obtained ranking for the given decision making problem is\nestablished by testing criteria proposed by Wang and Triantaphyllou (2008)\nalong with further analysis and discussion.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 06:00:32 GMT"}, {"version": "v2", "created": "Thu, 25 Aug 2016 07:07:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Roy", "Jagannath", ""], ["Chatterjee", "Kajal", ""], ["Bandhopadhyay", "Abhirup", ""], ["Kar", "Samarjit", ""]]}, {"id": "1606.08963", "submitter": "Nemanja Djuric", "authors": "Nemanja Djuric, Mihajlo Grbovic, Vladan Radosavljevic, Narayan\n  Bhamidipati, Slobodan Vucetic", "title": "Non-linear Label Ranking for Large-scale Prediction of Long-Term User\n  Interests", "comments": "28th AAAI Conference on Artificial Intelligence (AAAI-14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of personalization of online services from the\nviewpoint of ad targeting, where we seek to find the best ad categories to be\nshown to each user, resulting in improved user experience and increased\nadvertisers' revenue. We propose to address this problem as a task of ranking\nthe ad categories depending on a user's preference, and introduce a novel label\nranking approach capable of efficiently learning non-linear, highly accurate\nmodels in large-scale settings. Experiments on a real-world advertising data\nset with more than 3.2 million users show that the proposed algorithm\noutperforms the existing solutions in terms of both rank loss and top-K\nretrieval performance, strongly suggesting the benefit of using the proposed\nmodel on large-scale ranking problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 06:00:35 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Djuric", "Nemanja", ""], ["Grbovic", "Mihajlo", ""], ["Radosavljevic", "Vladan", ""], ["Bhamidipati", "Narayan", ""], ["Vucetic", "Slobodan", ""]]}, {"id": "1606.08965", "submitter": "Jagannath Roy", "authors": "Jagannath Roy, Krishnendu Adhikary, Samarjit Kar", "title": "Credibilistic TOPSIS Model for Evaluation and Selection of Municipal\n  Solid Waste Disposal Methods", "comments": null, "journal-ref": null, "doi": "10.1007/978-981-13-0215-2_17", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Municipal solid waste management (MSWM) is a challenging issue of urban\ndevelopment in developing countries. Each country having different\nsocio-economic-environmental background, might not accept a particular disposal\nmethod as the optimal choice. Selection of suitable disposal method in MSWM,\nunder vague and imprecise information can be considered as multi criteria\ndecision making problem (MCDM). In the present paper, TOPSIS (Technique for\nOrder Preference by Similarity to Ideal Solution) methodology is extended based\non credibility theory for evaluating the performances of MSW disposal methods\nunder some criteria fixed by experts. The proposed model helps decision makers\nto choose a preferable alternative for their municipal area. A sensitivity\nanalysis by our proposed model confirms this fact.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 06:13:22 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2016 16:54:48 GMT"}, {"version": "v3", "created": "Tue, 9 Aug 2016 18:44:35 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Roy", "Jagannath", ""], ["Adhikary", "Krishnendu", ""], ["Kar", "Samarjit", ""]]}, {"id": "1606.09140", "submitter": "Robin Hirsch", "authors": "Robin Hirsch, Marcel Jackson and Tomasz Kowalski", "title": "Algebraic foundations for qualitative calculi and networks", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A qualitative representation $\\phi$ is like an ordinary representation of a\nrelation algebra, but instead of requiring $(a; b)^\\phi = a^\\phi | b^\\phi$, as\nwe do for ordinary representations, we only require that $c^\\phi\\supseteq\na^\\phi | b^\\phi \\iff c\\geq a ; b$, for each $c$ in the algebra. A constraint\nnetwork is qualitatively satisfiable if its nodes can be mapped to elements of\na qualitative representation, preserving the constraints. If a constraint\nnetwork is satisfiable then it is clearly qualitatively satisfiable, but the\nconverse can fail. However, for a wide range of relation algebras including the\npoint algebra, the Allen Interval Algebra, RCC8 and many others, a network is\nsatisfiable if and only if it is qualitatively satisfiable.\n  Unlike ordinary composition, the weak composition arising from qualitative\nrepresentations need not be associative, so we can generalise by considering\nnetwork satisfaction problems over non-associative algebras. We prove that\ncomputationally, qualitative representations have many advantages over ordinary\nrepresentations: whereas many finite relation algebras have only infinite\nrepresentations, every finite qualitatively representable algebra has a finite\nqualitative representation; the representability problem for (the atom\nstructures of) finite non-associative algebras is NP-complete; the network\nsatisfaction problem over a finite qualitatively representable algebra is\nalways in NP; the validity of equations over qualitative representations is\nco-NP-complete. On the other hand we prove that there is no finite\naxiomatisation of the class of qualitatively representable algebras.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 15:00:48 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 11:44:51 GMT"}, {"version": "v3", "created": "Mon, 19 Jun 2017 16:33:39 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Hirsch", "Robin", ""], ["Jackson", "Marcel", ""], ["Kowalski", "Tomasz", ""]]}, {"id": "1606.09242", "submitter": "Yi Wu", "authors": "Yi Wu, Lei Li, Stuart Russell, Rastislav Bodik", "title": "Swift: Compiled Inference for Probabilistic Programming Languages", "comments": "IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A probabilistic program defines a probability measure over its semantic\nstructures. One common goal of probabilistic programming languages (PPLs) is to\ncompute posterior probabilities for arbitrary models and queries, given\nobserved evidence, using a generic inference engine. Most PPL inference\nengines---even the compiled ones---incur significant runtime interpretation\noverhead, especially for contingent and open-universe models. This paper\ndescribes Swift, a compiler for the BLOG PPL. Swift-generated code incorporates\noptimizations that eliminate interpretation overhead, maintain dynamic\ndependencies efficiently, and handle memory management for possible worlds of\nvarying sizes. Experiments comparing Swift with other PPL engines on a variety\nof inference problems demonstrate speedups ranging from 12x to 326x.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 08:30:54 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Wu", "Yi", ""], ["Li", "Lei", ""], ["Russell", "Stuart", ""], ["Bodik", "Rastislav", ""]]}, {"id": "1606.09274", "submitter": "Abigail See", "authors": "Abigail See, Minh-Thang Luong, Christopher D. Manning", "title": "Compression of Neural Machine Translation Models via Pruning", "comments": "Accepted to CoNLL 2016. 9 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT), like many other deep learning domains,\ntypically suffers from over-parameterization, resulting in large storage sizes.\nThis paper examines three simple magnitude-based pruning schemes to compress\nNMT models, namely class-blind, class-uniform, and class-distribution, which\ndiffer in terms of how pruning thresholds are computed for the different\nclasses of weights in the NMT architecture. We demonstrate the efficacy of\nweight pruning as a compression technique for a state-of-the-art NMT system. We\nshow that an NMT model with over 200 million parameters can be pruned by 40%\nwith very little performance loss as measured on the WMT'14 English-German\ntranslation task. This sheds light on the distribution of redundancy in the NMT\narchitecture. Our main result is that with retraining, we can recover and even\nsurpass the original performance with an 80%-pruned model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 20:36:23 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["See", "Abigail", ""], ["Luong", "Minh-Thang", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1606.09296", "submitter": "Mihajlo Grbovic", "authors": "Mihajlo Grbovic, Guy Halawi, Zohar Karnin, Yoelle Maarek", "title": "How Many Folders Do You Really Need?", "comments": "10 pages, 12 figures, Proceedings of the 23rd ACM International\n  Conference on Information and Knowledge Management (CIKM 2014), Shanghai,\n  China", "journal-ref": "Proceedings of the 23rd ACM International Conference on\n  Information and Knowledge Management (CIKM 2014), Shanghai, China", "doi": "10.1145/2661829.2662018.", "report-no": null, "categories": "cs.AI cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email classification is still a mostly manual task. Consequently, most Web\nmail users never define a single folder. Recently however, automatic\nclassification offering the same categories to all users has started to appear\nin some Web mail clients, such as AOL or Gmail. We adopt this approach, rather\nthan previous (unsuccessful) personalized approaches because of the change in\nthe nature of consumer email traffic, which is now dominated by (non-spam)\nmachine-generated email. We propose here a novel approach for (1) automatically\ndistinguishing between personal and machine-generated email and (2) classifying\nmessages into latent categories, without requiring users to have defined any\nfolder. We report how we have discovered that a set of 6 \"latent\" categories\n(one for human- and the others for machine-generated messages) can explain a\nsignificant portion of email traffic. We describe in details the steps involved\nin building a Web-scale email categorization system, from the collection of\nground-truth labels, the selection of features to the training of models.\nExperimental evaluation was performed on more than 500 billion messages\nreceived during a period of six months by users of Yahoo mail service, who\nelected to be part of such research studies. Our system achieved precision and\nrecall rates close to 90% and the latent categories we discovered were shown to\ncover 70% of both email traffic and email search queries. We believe that these\nresults pave the way for a change of approach in the Web mail industry, and\ncould support the invention of new large-scale email discovery paradigms that\nhad not been possible before.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 21:35:24 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Grbovic", "Mihajlo", ""], ["Halawi", "Guy", ""], ["Karnin", "Zohar", ""], ["Maarek", "Yoelle", ""]]}, {"id": "1606.09403", "submitter": "Long Duong", "authors": "Long Duong, Hiroshi Kanayama, Tengfei Ma, Steven Bird, Trevor Cohn", "title": "Learning Crosslingual Word Embeddings without Bilingual Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Crosslingual word embeddings represent lexical items from different languages\nin the same vector space, enabling transfer of NLP tools. However, previous\nattempts had expensive resource requirements, difficulty incorporating\nmonolingual data or were unable to handle polysemy. We address these drawbacks\nin our method which takes advantage of a high coverage dictionary in an EM\nstyle training algorithm over monolingual corpora in two languages. Our model\nachieves state-of-the-art performance on bilingual lexicon induction task\nexceeding models using large bilingual corpora, and competitive results on the\nmonolingual word similarity and cross-lingual document classification task.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 09:18:53 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Duong", "Long", ""], ["Kanayama", "Hiroshi", ""], ["Ma", "Tengfei", ""], ["Bird", "Steven", ""], ["Cohn", "Trevor", ""]]}, {"id": "1606.09449", "submitter": "Sebastian Ordyniak", "authors": "Bernhard Bliem, Sebastian Ordyniak, Stefan Woltran", "title": "Clique-Width and Directed Width Measures for Answer-Set Programming", "comments": "A short version of this paper has been accepted to ECAI 2016 and\n  TAASP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disjunctive Answer Set Programming (ASP) is a powerful declarative\nprogramming paradigm whose main decision problems are located on the second\nlevel of the polynomial hierarchy. Identifying tractable fragments and\ndeveloping efficient algorithms for such fragments are thus important\nobjectives in order to complement the sophisticated ASP systems available to\ndate. Hard problems can become tractable if some problem parameter is bounded\nby a fixed constant; such problems are then called fixed-parameter tractable\n(FPT). While several FPT results for ASP exist, parameters that relate to\ndirected or signed graphs representing the program at hand have been neglected\nso far. In this paper, we first give some negative observations showing that\ndirected width measures on the dependency graph of a program do not lead to FPT\nresults. We then consider the graph parameter of signed clique-width and\npresent a novel dynamic programming algorithm that is FPT w.r.t. this\nparameter. Clique-width is more general than the well-known treewidth, and, to\nthe best of our knowledge, ours is the first FPT algorithm for bounded\nclique-width for reasoning problems beyond SAT.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 12:14:33 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2016 12:00:28 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Bliem", "Bernhard", ""], ["Ordyniak", "Sebastian", ""], ["Woltran", "Stefan", ""]]}, {"id": "1606.09521", "submitter": "Rafael Pe\\~naloza", "authors": "Rafael Pe\\~naloza, Nico Potyka", "title": "Probabilistic Reasoning in the Description Logic ALCP with the Principle\n  of Maximum Entropy (Full Version)", "comments": "Full version of paper accepted at the Tenth International Conference\n  on Scalable Uncertainty Management (SUM 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question for knowledge representation is how to encode and handle\nuncertain knowledge adequately. We introduce the probabilistic description\nlogic ALCP that is designed for representing context-dependent knowledge, where\nthe actual context taking place is uncertain. ALCP allows the expression of\nlogical dependencies on the domain and probabilistic dependencies on the\npossible contexts. In order to draw probabilistic conclusions, we employ the\nprinciple of maximum entropy. We provide reasoning algorithms for this logic,\nand show that it satisfies several desirable properties of probabilistic\nlogics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 14:49:01 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Pe\u00f1aloza", "Rafael", ""], ["Potyka", "Nico", ""]]}, {"id": "1606.09577", "submitter": "Thomas Vacek Thomas Vacek", "authors": "Thomas Vacek", "title": "Ordering as privileged information", "comments": "10 pages, 1 table, 2 page appendix giving proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to accelerate the rate of convergence of the pattern recognition\ntask by directly minimizing the variance diameters of certain hypothesis\nspaces, which are critical quantities in fast-convergence results.We show that\nthe variance diameters can be controlled by dividing hypothesis spaces into\nmetric balls based on a new order metric. This order metric can be minimized as\nan ordinal regression problem, leading to a LUPI (Learning Using Privileged\nInformation) application where we take the privileged information as some\ndesired ordering, and construct a faster-converging hypothesis space by\nempirically restricting some larger hypothesis space according to that\nordering. We give a risk analysis of the approach. We discuss the difficulties\nwith model selection and give an innovative technique for selecting multiple\nmodel parameters. Finally, we provide some data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 17:06:30 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Vacek", "Thomas", ""]]}, {"id": "1606.09581", "submitter": "Sahil Sharma", "authors": "Sahil Sharma, Vinod Sharma and Atul Sharma", "title": "Performance Based Evaluation of Various Machine Learning Classification\n  Techniques for Chronic Kidney Disease Diagnosis", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": "International Journal of Modern Computer Science, Vol.4, Issue3,\n  June 2016, pp.11-16", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Areas where Artificial Intelligence (AI) & related fields are finding their\napplications are increasing day by day, moving from core areas of computer\nscience they are finding their applications in various other domains.In recent\ntimes Machine Learning i.e. a sub-domain of AI has been widely used in order to\nassist medical experts and doctors in the prediction, diagnosis and prognosis\nof various diseases and other medical disorders. In this manuscript the authors\napplied various machine learning algorithms to a problem in the domain of\nmedical diagnosis and analyzed their efficiency in predicting the results. The\nproblem selected for the study is the diagnosis of the Chronic Kidney\nDisease.The dataset used for the study consists of 400 instances and 24\nattributes. The authors evaluated 12 classification techniques by applying them\nto the Chronic Kidney Disease data. In order to calculate efficiency, results\nof the prediction by candidate methods were compared with the actual medical\nresults of the subject.The various metrics used for performance evaluation are\npredictive accuracy, precision, sensitivity and specificity. The results\nindicate that decision-tree performed best with nearly the accuracy of 98.6%,\nsensitivity of 0.9720, precision of 1 and specificity of 1.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 07:00:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 08:14:43 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Sharma", "Sahil", ""], ["Sharma", "Vinod", ""], ["Sharma", "Atul", ""]]}, {"id": "1606.09594", "submitter": "Ankit Anand", "authors": "Ankit Anand, Aditya Grover, Mausam, Parag Singla", "title": "Contextual Symmetries in Probabilistic Graphical Models", "comments": "9 Pages, 4 figures", "journal-ref": "IJCAI, 2016", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important approach for efficient inference in probabilistic graphical\nmodels exploits symmetries among objects in the domain. Symmetric variables\n(states) are collapsed into meta-variables (meta-states) and inference\nalgorithms are run over the lifted graphical model instead of the flat one. Our\npaper extends existing definitions of symmetry by introducing the novel notion\nof contextual symmetry. Two states that are not globally symmetric, can be\ncontextually symmetric under some specific assignment to a subset of variables,\nreferred to as the context variables. Contextual symmetry subsumes previous\nsymmetry definitions and can rep resent a large class of symmetries not\nrepresentable earlier. We show how to compute contextual symmetries by reducing\nit to the problem of graph isomorphism. We extend previous work on exploiting\nsymmetries in the MCMC framework to the case of contextual symmetries. Our\nexperiments on several domains of interest demonstrate that exploiting\ncontextual symmetries can result in significant computational gains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 18:03:42 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Anand", "Ankit", ""], ["Grover", "Aditya", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "1606.09632", "submitter": "Nihar Shah", "authors": "Nihar B. Shah, Sivaraman Balakrishnan, Martin J. Wainwright", "title": "A Permutation-based Model for Crowd Labeling: Optimal Estimation and\n  Robustness", "comments": "in IEEE Transactions on Information Theory (online), 2020", "journal-ref": null, "doi": "10.1109/TIT.2020.3045613", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of aggregating and denoising crowd-labeled data has gained increased\nsignificance with the advent of crowdsourcing platforms and massive datasets.\nWe propose a permutation-based model for crowd labeled data that is a\nsignificant generalization of the classical Dawid-Skene model, and introduce a\nnew error metric by which to compare different estimators. We derive global\nminimax rates for the permutation-based model that are sharp up to logarithmic\nfactors, and match the minimax lower bounds derived under the simpler\nDawid-Skene model. We then design two computationally-efficient estimators: the\nWAN estimator for the setting where the ordering of workers in terms of their\nabilities is approximately known, and the OBI-WAN estimator where that is not\nknown. For each of these estimators, we provide non-asymptotic bounds on their\nperformance. We conduct synthetic simulations and experiments on real-world\ncrowdsourcing data, and the experimental results corroborate our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 19:40:56 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 04:58:30 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 18:18:41 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Shah", "Nihar B.", ""], ["Balakrishnan", "Sivaraman", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1606.09637", "submitter": "David Smith", "authors": "David Smith, Parag Singla, Vibhav Gogate", "title": "Lifted Region-Based Belief Propagation", "comments": "Sixth International Workshop on Statistical Relational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the intractable nature of exact lifted inference, research has\nrecently focused on the discovery of accurate and efficient approximate\ninference algorithms in Statistical Relational Models (SRMs), such as Lifted\nFirst-Order Belief Propagation. FOBP simulates propositional factor graph\nbelief propagation without constructing the ground factor graph by identifying\nand lifting over redundant message computations. In this work, we propose a\ngeneralization of FOBP called Lifted Generalized Belief Propagation, in which\nboth the region structure and the message structure can be lifted. This\napproach allows more of the inference to be performed intra-region (in the\nexact inference step of BP), thereby allowing simulation of propagation on a\ngraph structure with larger region scopes and fewer edges, while still\nmaintaining tractability. We demonstrate that the resulting algorithm converges\nin fewer iterations to more accurate results on a variety of SRMs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 19:50:33 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Smith", "David", ""], ["Singla", "Parag", ""], ["Gogate", "Vibhav", ""]]}]